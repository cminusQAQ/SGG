2022-10-10 09:49:03 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-10 09:49:03 - utils.py[line:261] - INFO: Start init
2022-10-10 09:49:04 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-10 09:49:04 - utils.py[line:261] - INFO: Start init
2022-10-10 09:49:04 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-10 09:49:04 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-10 09:49:04 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-10 09:49:04 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-10 09:49:16 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 3000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 2, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 3000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=2, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480', save_interval=10, save_interval_updates=3000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=3000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-10 09:49:17 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-10 09:49:17 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-10-10 09:49:27 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-10-10 09:49:27 - train.py[line:118] - INFO: task: VqaGenTask
2022-10-10 09:49:27 - train.py[line:119] - INFO: model: OFAModel
2022-10-10 09:49:27 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-10-10 09:49:27 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-10-10 09:49:27 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-10 09:49:28 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-10-10 09:49:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-10-10 09:49:29 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-10 09:49:29 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-10 09:49:29 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-10 09:49:29 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-10 09:49:29 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-10-10 09:49:29 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-10-10 09:49:29 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt
Traceback (most recent call last):
  File "../../train.py", line 632, in <module>
    cli_main()
  File "../../train.py", line 625, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 177, in main
    disable_iterator_cache=True,
  File "/data/private/yutianyu/OFA/utils/checkpoint_utils.py", line 254, in load_checkpoint
    reset_meters=reset_meters,
  File "/data/private/yutianyu/OFA/trainer.py", line 474, in load_checkpoint
    filename, load_on_all_ranks=load_on_all_ranks
  File "/data/private/yutianyu/OFA/utils/checkpoint_utils.py", line 330, in load_checkpoint_to_cpu
    state = torch.load(f, map_location=torch.device("cpu"))
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/serialization.py", line 585, in load
    with _open_zipfile_reader(opened_file) as opened_zipfile:
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/serialization.py", line 242, in __init__
    super(_open_zipfile_reader, self).__init__(torch._C.PyTorchFileReader(name_or_buffer))
RuntimeError: [enforce fail at inline_container.cc:145] . PytorchStreamReader failed reading zip archive: failed finding central directory
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--batch-size=20', '--batch-size-valid=15', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=5e-5', '--max-epoch=2', '--warmup-ratio=0.04', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=3000', '--validate-interval-updates=3000', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', '--valid-batch-size=51', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=allcand', '--num-workers=5']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 2814773
Killing subprocess 2814774
2022-10-10 09:55:17 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-10 09:55:17 - utils.py[line:261] - INFO: Start init
2022-10-10 09:55:20 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-10 09:55:20 - utils.py[line:261] - INFO: Start init
2022-10-10 09:55:20 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-10 09:55:20 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-10 09:55:20 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-10 09:55:20 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-10 09:55:36 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 3000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 2, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 3000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=2, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480', save_interval=10, save_interval_updates=3000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=3000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-10 09:55:36 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-10 09:55:36 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-10 09:55:48 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-10-10 09:55:48 - train.py[line:118] - INFO: task: VqaGenTask
2022-10-10 09:55:48 - train.py[line:119] - INFO: model: OFAModel
2022-10-10 09:55:48 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-10-10 09:55:48 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-10-10 09:55:48 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-10 09:55:48 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-10-10 09:55:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-10-10 09:55:50 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-10 09:55:50 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-10 09:55:50 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-10 09:55:50 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-10 09:55:50 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-10-10 09:55:50 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-10-10 09:55:50 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt
2022-10-10 09:56:07 - trainer.py[line:605] - INFO: Loading EMA from checkpoint
2022-10-10 09:56:08 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-10-10 09:56:08 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-10-10 09:56:09 - trainer.py[line:612] - INFO: Loading EMA fp32 params from checkpoint
2022-10-10 09:56:09 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt (epoch 8 @ 0 updates)
2022-10-10 09:56:09 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E0.tsv slice_id 0 row count 1156400 total row count 2312800
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k50alpha1.0_train_NA1_E0.tsv slice_id 1 row count 1156400 total row count 2312800
2022-10-10 09:56:14 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 115640, warmup steps 4625, warmup_factor 0.00021621621621621621
Total steps 115640, warmup steps 4625, warmup_factor 0.00021621621621621621
2022-10-10 09:56:16 - trainer.py[line:707] - INFO: begin training epoch 1
2022-10-10 09:56:16 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 09:56:50 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 57820 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=52.8, ups=0.48, wpb=108.9, bsz=40, num_updates=10, lr=1.08108e-07, gnorm=2.332, clip=100, loss_scale=128, train_wall=29, gb_free=10.5, ema_decay=0.9999, wall=61
2022-10-10 09:57:08 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 57820 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=63.3, ups=0.57, wpb=110.9, bsz=40, num_updates=20, lr=2.16216e-07, gnorm=1.94, clip=100, loss_scale=128, train_wall=17, gb_free=10.6, ema_decay=0.9999, wall=78
2022-10-10 09:57:25 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 57820 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=63, ups=0.57, wpb=110, bsz=40, num_updates=30, lr=3.24324e-07, gnorm=2.102, clip=100, loss_scale=128, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=96
2022-10-10 09:57:43 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 57820 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=61.3, ups=0.57, wpb=107.7, bsz=40, num_updates=40, lr=4.32432e-07, gnorm=2.31, clip=100, loss_scale=128, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=113
2022-10-10 09:58:00 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 57820 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=63.9, ups=0.58, wpb=110, bsz=40, num_updates=50, lr=5.40541e-07, gnorm=2.32, clip=100, loss_scale=128, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=131
2022-10-10 09:58:19 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 57820 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.585, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=57, ups=0.52, wpb=109.1, bsz=40, num_updates=60, lr=6.48649e-07, gnorm=2.054, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, ema_decay=0.9999, wall=150
2022-10-10 09:58:38 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 57820 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=59.4, ups=0.54, wpb=109.8, bsz=40, num_updates=70, lr=7.56757e-07, gnorm=2.253, clip=100, loss_scale=128, train_wall=18, gb_free=10.7, ema_decay=0.9999, wall=168
2022-10-10 09:58:56 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 57820 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=61, ups=0.55, wpb=110.4, bsz=40, num_updates=80, lr=8.64865e-07, gnorm=2.036, clip=100, loss_scale=128, train_wall=18, gb_free=10.9, ema_decay=0.9999, wall=186
2022-10-10 09:59:14 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 57820 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=60.8, ups=0.56, wpb=109.3, bsz=40, num_updates=90, lr=9.72973e-07, gnorm=1.923, clip=100, loss_scale=128, train_wall=18, gb_free=10.9, ema_decay=0.9999, wall=204
2022-10-10 09:59:33 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 57820 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=56.8, ups=0.52, wpb=108.8, bsz=40, num_updates=100, lr=1.08108e-06, gnorm=1.898, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, ema_decay=0.9999, wall=224
2022-10-10 09:59:52 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 57820 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=58.2, ups=0.54, wpb=108.7, bsz=40, num_updates=110, lr=1.18919e-06, gnorm=1.88, clip=100, loss_scale=128, train_wall=18, gb_free=10.8, ema_decay=0.9999, wall=242
2022-10-10 10:00:11 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 57820 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.605, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=57.3, ups=0.53, wpb=108.8, bsz=40, num_updates=120, lr=1.2973e-06, gnorm=1.903, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, ema_decay=0.9999, wall=261
2022-10-10 10:00:29 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 57820 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=59.2, ups=0.54, wpb=109.5, bsz=40, num_updates=130, lr=1.40541e-06, gnorm=1.543, clip=90, loss_scale=128, train_wall=18, gb_free=10.2, ema_decay=0.9999, wall=280
2022-10-10 10:00:47 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 57820 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=61.5, ups=0.56, wpb=110.7, bsz=40, num_updates=140, lr=1.51351e-06, gnorm=1.626, clip=80, loss_scale=128, train_wall=18, gb_free=10.7, ema_decay=0.9999, wall=298
2022-10-10 10:01:05 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 57820 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=61.3, ups=0.56, wpb=110.4, bsz=40, num_updates=150, lr=1.62162e-06, gnorm=1.457, clip=70, loss_scale=128, train_wall=18, gb_free=10.6, ema_decay=0.9999, wall=316
2022-10-10 10:01:23 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 57820 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=60.4, ups=0.56, wpb=108.1, bsz=40, num_updates=160, lr=1.72973e-06, gnorm=1.218, clip=70, loss_scale=128, train_wall=18, gb_free=10.6, ema_decay=0.9999, wall=334
2022-10-10 10:01:41 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 57820 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=61.3, ups=0.56, wpb=110, bsz=40, num_updates=170, lr=1.83784e-06, gnorm=1.286, clip=60, loss_scale=128, train_wall=18, gb_free=10.7, ema_decay=0.9999, wall=352
2022-10-10 10:01:59 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 57820 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=62.7, ups=0.57, wpb=111, bsz=40, num_updates=180, lr=1.94595e-06, gnorm=1.111, clip=50, loss_scale=128, train_wall=18, gb_free=10.7, ema_decay=0.9999, wall=369
2022-10-10 10:02:17 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 57820 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=60.8, ups=0.56, wpb=109.3, bsz=40, num_updates=190, lr=2.05405e-06, gnorm=1.278, clip=60, loss_scale=128, train_wall=18, gb_free=10.8, ema_decay=0.9999, wall=387
2022-10-10 10:02:33 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 57820 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=68.5, ups=0.62, wpb=109.8, bsz=40, num_updates=200, lr=2.16216e-06, gnorm=1.311, clip=80, loss_scale=128, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=403
2022-10-10 10:02:51 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 57820 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=61.7, ups=0.56, wpb=109.9, bsz=40, num_updates=210, lr=2.27027e-06, gnorm=1.299, clip=70, loss_scale=128, train_wall=18, gb_free=10.7, ema_decay=0.9999, wall=421
2022-10-10 10:03:11 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 57820 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=54.5, ups=0.5, wpb=109.9, bsz=40, num_updates=220, lr=2.37838e-06, gnorm=1.194, clip=60, loss_scale=128, train_wall=20, gb_free=10.7, ema_decay=0.9999, wall=441
2022-10-10 10:03:31 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 57820 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=53.7, ups=0.5, wpb=107.6, bsz=40, num_updates=230, lr=2.48649e-06, gnorm=1.524, clip=100, loss_scale=128, train_wall=20, gb_free=10.7, ema_decay=0.9999, wall=462
2022-10-10 10:03:50 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 57820 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=58, ups=0.52, wpb=110.5, bsz=40, num_updates=240, lr=2.59459e-06, gnorm=1.094, clip=50, loss_scale=128, train_wall=19, gb_free=10.7, ema_decay=0.9999, wall=481
2022-10-10 10:04:09 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 57820 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=58.9, ups=0.54, wpb=109.8, bsz=40, num_updates=250, lr=2.7027e-06, gnorm=1.101, clip=60, loss_scale=128, train_wall=18, gb_free=10.6, ema_decay=0.9999, wall=499
2022-10-10 10:04:29 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 57820 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=55.9, ups=0.51, wpb=109.9, bsz=40, num_updates=260, lr=2.81081e-06, gnorm=1.166, clip=40, loss_scale=128, train_wall=19, gb_free=10.7, ema_decay=0.9999, wall=519
2022-10-10 10:04:48 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 57820 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=57, ups=0.52, wpb=110.5, bsz=40, num_updates=270, lr=2.91892e-06, gnorm=1.031, clip=70, loss_scale=128, train_wall=19, gb_free=10.7, ema_decay=0.9999, wall=539
2022-10-10 10:05:07 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 57820 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=58.1, ups=0.53, wpb=109.1, bsz=40, num_updates=280, lr=3.02703e-06, gnorm=1.256, clip=90, loss_scale=128, train_wall=19, gb_free=10.8, ema_decay=0.9999, wall=557
2022-10-10 10:05:25 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 57820 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=58.9, ups=0.54, wpb=109.4, bsz=40, num_updates=290, lr=3.13514e-06, gnorm=1.083, clip=40, loss_scale=128, train_wall=18, gb_free=10.7, ema_decay=0.9999, wall=576
2022-10-10 10:05:44 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 57820 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=59.6, ups=0.53, wpb=111.7, bsz=40, num_updates=300, lr=3.24324e-06, gnorm=1.127, clip=50, loss_scale=128, train_wall=19, gb_free=10.7, ema_decay=0.9999, wall=595
2022-10-10 10:06:00 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 57820 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=69.4, ups=0.64, wpb=109.1, bsz=40, num_updates=310, lr=3.35135e-06, gnorm=1.01, clip=40, loss_scale=128, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=610
2022-10-10 10:06:16 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 57820 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=70.7, ups=0.64, wpb=110.9, bsz=40, num_updates=320, lr=3.45946e-06, gnorm=1.228, clip=80, loss_scale=128, train_wall=16, gb_free=10.9, ema_decay=0.9999, wall=626
2022-10-10 10:06:33 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 57820 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=64.5, ups=0.59, wpb=109.2, bsz=40, num_updates=330, lr=3.56757e-06, gnorm=1.069, clip=50, loss_scale=128, train_wall=17, gb_free=10.8, ema_decay=0.9999, wall=643
2022-10-10 10:06:50 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 57820 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=64.5, ups=0.59, wpb=109, bsz=40, num_updates=340, lr=3.67568e-06, gnorm=1.003, clip=50, loss_scale=128, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=660
2022-10-10 10:07:06 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 57820 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=66.2, ups=0.6, wpb=109.9, bsz=40, num_updates=350, lr=3.78378e-06, gnorm=1.117, clip=50, loss_scale=128, train_wall=16, gb_free=10.5, ema_decay=0.9999, wall=677
2022-10-10 10:07:23 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 57820 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=63.9, ups=0.58, wpb=110, bsz=40, num_updates=360, lr=3.89189e-06, gnorm=1.009, clip=40, loss_scale=128, train_wall=17, gb_free=11.1, ema_decay=0.9999, wall=694
2022-10-10 10:07:41 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 57820 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=63, ups=0.57, wpb=110.3, bsz=40, num_updates=370, lr=4e-06, gnorm=1.054, clip=50, loss_scale=128, train_wall=17, gb_free=10.5, ema_decay=0.9999, wall=711
2022-10-10 10:07:59 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 57820 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=62.3, ups=0.56, wpb=110.4, bsz=40, num_updates=380, lr=4.10811e-06, gnorm=0.987, clip=50, loss_scale=128, train_wall=18, gb_free=10.6, ema_decay=0.9999, wall=729
2022-10-10 10:08:17 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 57820 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=59.7, ups=0.55, wpb=109, bsz=40, num_updates=390, lr=4.21622e-06, gnorm=1.102, clip=60, loss_scale=128, train_wall=18, gb_free=10.5, ema_decay=0.9999, wall=747
2022-10-10 10:08:35 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 57820 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=59, ups=0.54, wpb=109.3, bsz=40, num_updates=400, lr=4.32432e-06, gnorm=1.039, clip=70, loss_scale=128, train_wall=18, gb_free=10.6, ema_decay=0.9999, wall=766
2022-10-10 10:08:54 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 57820 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=58.9, ups=0.53, wpb=110.4, bsz=40, num_updates=410, lr=4.43243e-06, gnorm=1.058, clip=70, loss_scale=128, train_wall=19, gb_free=10.8, ema_decay=0.9999, wall=785
2022-10-10 10:09:12 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 57820 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=62.3, ups=0.57, wpb=109.6, bsz=40, num_updates=420, lr=4.54054e-06, gnorm=1.021, clip=50, loss_scale=128, train_wall=17, gb_free=10.8, ema_decay=0.9999, wall=802
2022-10-10 10:09:29 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 57820 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=64, ups=0.58, wpb=109.9, bsz=40, num_updates=430, lr=4.64865e-06, gnorm=1.057, clip=50, loss_scale=128, train_wall=17, gb_free=10.6, ema_decay=0.9999, wall=819
2022-10-10 10:09:48 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 57820 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=58, ups=0.53, wpb=110.3, bsz=40, num_updates=440, lr=4.75676e-06, gnorm=0.925, clip=20, loss_scale=128, train_wall=19, gb_free=10.4, ema_decay=0.9999, wall=838
2022-10-10 10:10:07 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 57820 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=58.1, ups=0.53, wpb=108.7, bsz=40, num_updates=450, lr=4.86486e-06, gnorm=0.932, clip=20, loss_scale=128, train_wall=19, gb_free=10.7, ema_decay=0.9999, wall=857
2022-10-10 10:10:24 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 57820 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=63.5, ups=0.58, wpb=109.7, bsz=40, num_updates=460, lr=4.97297e-06, gnorm=0.932, clip=30, loss_scale=128, train_wall=17, gb_free=10.6, ema_decay=0.9999, wall=874
2022-10-10 10:10:42 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 57820 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=60.3, ups=0.55, wpb=110.2, bsz=40, num_updates=470, lr=5.08108e-06, gnorm=0.917, clip=30, loss_scale=128, train_wall=18, gb_free=10.8, ema_decay=0.9999, wall=893
2022-10-10 10:11:00 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 57820 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=60.3, ups=0.55, wpb=108.8, bsz=40, num_updates=480, lr=5.18919e-06, gnorm=0.932, clip=20, loss_scale=128, train_wall=18, gb_free=10.4, ema_decay=0.9999, wall=911
2022-10-10 10:11:17 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 57820 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=66.1, ups=0.6, wpb=110.1, bsz=40, num_updates=490, lr=5.2973e-06, gnorm=0.881, clip=20, loss_scale=128, train_wall=16, gb_free=11, ema_decay=0.9999, wall=927
2022-10-10 10:11:34 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 57820 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=66.2, ups=0.6, wpb=110.4, bsz=40, num_updates=500, lr=5.40541e-06, gnorm=0.878, clip=10, loss_scale=128, train_wall=17, gb_free=10.9, ema_decay=0.9999, wall=944
2022-10-10 10:11:50 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 57820 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=65, ups=0.6, wpb=108.7, bsz=40, num_updates=510, lr=5.51351e-06, gnorm=0.892, clip=30, loss_scale=128, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=961
2022-10-10 10:12:07 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 57820 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=66.2, ups=0.61, wpb=109.3, bsz=40, num_updates=520, lr=5.62162e-06, gnorm=0.863, clip=30, loss_scale=256, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=977
2022-10-10 10:12:23 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 57820 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=68.2, ups=0.62, wpb=109.5, bsz=40, num_updates=530, lr=5.72973e-06, gnorm=0.858, clip=30, loss_scale=256, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=993
2022-10-10 10:12:40 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 57820 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=66.6, ups=0.6, wpb=110.5, bsz=40, num_updates=540, lr=5.83784e-06, gnorm=0.762, clip=0, loss_scale=256, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=1010
2022-10-10 10:12:56 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 57820 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=65.8, ups=0.6, wpb=110.2, bsz=40, num_updates=550, lr=5.94595e-06, gnorm=0.84, clip=20, loss_scale=256, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=1027
2022-10-10 10:13:13 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 57820 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=66, ups=0.6, wpb=109.7, bsz=40, num_updates=560, lr=6.05405e-06, gnorm=0.915, clip=30, loss_scale=256, train_wall=17, gb_free=10.8, ema_decay=0.9999, wall=1043
2022-10-10 10:13:29 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 57820 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=68.6, ups=0.63, wpb=108.6, bsz=40, num_updates=570, lr=6.16216e-06, gnorm=0.863, clip=10, loss_scale=256, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=1059
2022-10-10 10:13:45 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 57820 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=66.7, ups=0.61, wpb=109.5, bsz=40, num_updates=580, lr=6.27027e-06, gnorm=1.028, clip=60, loss_scale=256, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=1076
2022-10-10 10:14:01 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 57820 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=68.2, ups=0.62, wpb=110.4, bsz=40, num_updates=590, lr=6.37838e-06, gnorm=1.001, clip=40, loss_scale=256, train_wall=16, gb_free=11.1, ema_decay=0.9999, wall=1092
2022-10-10 10:14:18 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 57820 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=65.6, ups=0.6, wpb=109.7, bsz=40, num_updates=600, lr=6.48649e-06, gnorm=0.857, clip=30, loss_scale=256, train_wall=17, gb_free=10.5, ema_decay=0.9999, wall=1109
2022-10-10 10:14:35 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 57820 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=65.1, ups=0.59, wpb=109.6, bsz=40, num_updates=610, lr=6.59459e-06, gnorm=0.937, clip=50, loss_scale=256, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=1125
2022-10-10 10:14:52 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 57820 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=65.5, ups=0.6, wpb=109.4, bsz=40, num_updates=620, lr=6.7027e-06, gnorm=0.996, clip=50, loss_scale=256, train_wall=17, gb_free=10.9, ema_decay=0.9999, wall=1142
2022-10-10 10:15:09 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 57820 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=64.1, ups=0.59, wpb=109.1, bsz=40, num_updates=630, lr=6.81081e-06, gnorm=0.938, clip=30, loss_scale=256, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=1159
2022-10-10 10:15:26 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 57820 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=64.2, ups=0.59, wpb=108.9, bsz=40, num_updates=640, lr=6.91892e-06, gnorm=0.941, clip=30, loss_scale=256, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=1176
2022-10-10 10:15:42 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 57820 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=65.1, ups=0.6, wpb=108.6, bsz=40, num_updates=650, lr=7.02703e-06, gnorm=1.021, clip=80, loss_scale=256, train_wall=17, gb_free=10.8, ema_decay=0.9999, wall=1193
2022-10-10 10:15:59 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 57820 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=66.3, ups=0.61, wpb=108.6, bsz=40, num_updates=660, lr=7.13514e-06, gnorm=0.93, clip=20, loss_scale=256, train_wall=16, gb_free=10.9, ema_decay=0.9999, wall=1209
2022-10-10 10:16:15 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 57820 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=68.3, ups=0.62, wpb=110.8, bsz=40, num_updates=670, lr=7.24324e-06, gnorm=0.993, clip=50, loss_scale=256, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=1226
2022-10-10 10:16:32 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 57820 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=64.7, ups=0.59, wpb=110.6, bsz=40, num_updates=680, lr=7.35135e-06, gnorm=1.066, clip=60, loss_scale=256, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=1243
2022-10-10 10:16:48 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 57820 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=68.6, ups=0.62, wpb=111.4, bsz=40, num_updates=690, lr=7.45946e-06, gnorm=1.012, clip=60, loss_scale=256, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=1259
2022-10-10 10:17:06 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 57820 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=60.7, ups=0.55, wpb=109.5, bsz=40, num_updates=700, lr=7.56757e-06, gnorm=0.944, clip=40, loss_scale=256, train_wall=18, gb_free=10.7, ema_decay=0.9999, wall=1277
2022-10-10 10:17:24 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 57820 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=63.4, ups=0.58, wpb=108.7, bsz=40, num_updates=710, lr=7.67568e-06, gnorm=1.075, clip=60, loss_scale=256, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=1294
2022-10-10 10:17:41 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 57820 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=64.7, ups=0.59, wpb=109.4, bsz=40, num_updates=720, lr=7.78378e-06, gnorm=1.054, clip=70, loss_scale=256, train_wall=17, gb_free=10.5, ema_decay=0.9999, wall=1311
2022-10-10 10:17:58 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 57820 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=64.7, ups=0.59, wpb=110.6, bsz=40, num_updates=730, lr=7.89189e-06, gnorm=0.972, clip=40, loss_scale=256, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=1328
2022-10-10 10:18:15 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 57820 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=63.1, ups=0.57, wpb=109.9, bsz=40, num_updates=740, lr=8e-06, gnorm=1.109, clip=60, loss_scale=256, train_wall=17, gb_free=10.5, ema_decay=0.9999, wall=1346
2022-10-10 10:18:32 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 57820 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=64, ups=0.58, wpb=110.2, bsz=40, num_updates=750, lr=8.10811e-06, gnorm=0.93, clip=30, loss_scale=256, train_wall=17, gb_free=10.6, ema_decay=0.9999, wall=1363
2022-10-10 10:18:50 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 57820 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=61.3, ups=0.56, wpb=109.6, bsz=40, num_updates=760, lr=8.21622e-06, gnorm=1.131, clip=70, loss_scale=256, train_wall=18, gb_free=10.6, ema_decay=0.9999, wall=1381
2022-10-10 10:19:08 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 57820 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=60, ups=0.56, wpb=107.4, bsz=40, num_updates=770, lr=8.32432e-06, gnorm=1.156, clip=70, loss_scale=256, train_wall=18, gb_free=10.6, ema_decay=0.9999, wall=1399
2022-10-10 10:19:24 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 57820 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=67.6, ups=0.62, wpb=109.3, bsz=40, num_updates=780, lr=8.43243e-06, gnorm=0.997, clip=40, loss_scale=256, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=1415
2022-10-10 10:19:42 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 57820 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=62.3, ups=0.56, wpb=110.7, bsz=40, num_updates=790, lr=8.54054e-06, gnorm=0.921, clip=30, loss_scale=256, train_wall=18, gb_free=10.2, ema_decay=0.9999, wall=1433
2022-10-10 10:20:00 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 57820 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=61.8, ups=0.57, wpb=108.3, bsz=40, num_updates=800, lr=8.64865e-06, gnorm=1.052, clip=60, loss_scale=256, train_wall=17, gb_free=10.6, ema_decay=0.9999, wall=1450
2022-10-10 10:20:17 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 57820 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=63.9, ups=0.59, wpb=108.5, bsz=40, num_updates=810, lr=8.75676e-06, gnorm=1.116, clip=50, loss_scale=256, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=1467
2022-10-10 10:20:35 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 57820 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=61.1, ups=0.56, wpb=109.5, bsz=40, num_updates=820, lr=8.86486e-06, gnorm=1.077, clip=70, loss_scale=256, train_wall=18, gb_free=10.8, ema_decay=0.9999, wall=1485
2022-10-10 10:20:51 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 57820 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=64.7, ups=0.59, wpb=108.9, bsz=40, num_updates=830, lr=8.97297e-06, gnorm=0.979, clip=30, loss_scale=256, train_wall=17, gb_free=10.5, ema_decay=0.9999, wall=1502
2022-10-10 10:21:08 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 57820 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=66.8, ups=0.61, wpb=110.2, bsz=40, num_updates=840, lr=9.08108e-06, gnorm=1.088, clip=50, loss_scale=256, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=1518
2022-10-10 10:21:24 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 57820 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=66.2, ups=0.61, wpb=109.3, bsz=40, num_updates=850, lr=9.18919e-06, gnorm=1.194, clip=60, loss_scale=256, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=1535
2022-10-10 10:21:41 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 57820 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=68.3, ups=0.62, wpb=110.9, bsz=40, num_updates=860, lr=9.2973e-06, gnorm=1.061, clip=60, loss_scale=256, train_wall=16, gb_free=11.1, ema_decay=0.9999, wall=1551
2022-10-10 10:21:58 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 57820 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=63.2, ups=0.57, wpb=110.5, bsz=40, num_updates=870, lr=9.40541e-06, gnorm=1.015, clip=50, loss_scale=256, train_wall=17, gb_free=11.1, ema_decay=0.9999, wall=1569
2022-10-10 10:22:16 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 57820 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=62.3, ups=0.57, wpb=109.4, bsz=40, num_updates=880, lr=9.51351e-06, gnorm=1.238, clip=100, loss_scale=256, train_wall=17, gb_free=10.5, ema_decay=0.9999, wall=1586
2022-10-10 10:22:33 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 57820 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=63.7, ups=0.59, wpb=107.7, bsz=40, num_updates=890, lr=9.62162e-06, gnorm=1.047, clip=70, loss_scale=256, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=1603
2022-10-10 10:22:50 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 57820 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=61.8, ups=0.57, wpb=109.1, bsz=40, num_updates=900, lr=9.72973e-06, gnorm=1.153, clip=80, loss_scale=256, train_wall=17, gb_free=10.3, ema_decay=0.9999, wall=1621
2022-10-10 10:23:08 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 57820 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=62.7, ups=0.57, wpb=109.6, bsz=40, num_updates=910, lr=9.83784e-06, gnorm=1.113, clip=70, loss_scale=256, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=1638
2022-10-10 10:23:26 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 57820 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=59.1, ups=0.55, wpb=108.3, bsz=40, num_updates=920, lr=9.94595e-06, gnorm=1.08, clip=70, loss_scale=256, train_wall=18, gb_free=10.7, ema_decay=0.9999, wall=1657
2022-10-10 10:23:43 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 57820 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=66.6, ups=0.61, wpb=109.5, bsz=40, num_updates=930, lr=1.00541e-05, gnorm=1.185, clip=70, loss_scale=256, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=1673
2022-10-10 10:23:59 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 57820 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=67.6, ups=0.62, wpb=109.1, bsz=40, num_updates=940, lr=1.01622e-05, gnorm=1.364, clip=80, loss_scale=256, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=1689
2022-10-10 10:24:15 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 57820 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=66.4, ups=0.6, wpb=109.8, bsz=40, num_updates=950, lr=1.02703e-05, gnorm=1.193, clip=90, loss_scale=256, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=1706
2022-10-10 10:24:33 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 57820 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=63.9, ups=0.58, wpb=110.6, bsz=40, num_updates=960, lr=1.03784e-05, gnorm=1.145, clip=70, loss_scale=256, train_wall=17, gb_free=10.6, ema_decay=0.9999, wall=1723
2022-10-10 10:24:49 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 57820 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=66.8, ups=0.61, wpb=108.8, bsz=40, num_updates=970, lr=1.04865e-05, gnorm=1.23, clip=90, loss_scale=256, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=1739
2022-10-10 10:25:06 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 57820 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=63.7, ups=0.58, wpb=109.4, bsz=40, num_updates=980, lr=1.05946e-05, gnorm=1.099, clip=80, loss_scale=256, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=1757
2022-10-10 10:25:23 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 57820 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=64.9, ups=0.59, wpb=109.3, bsz=40, num_updates=990, lr=1.07027e-05, gnorm=1.173, clip=70, loss_scale=256, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=1773
2022-10-10 10:25:40 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 57820 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=65.8, ups=0.6, wpb=110.1, bsz=40, num_updates=1000, lr=1.08108e-05, gnorm=1.199, clip=70, loss_scale=256, train_wall=17, gb_free=10.8, ema_decay=0.9999, wall=1790
2022-10-10 10:25:57 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 57820 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=63.1, ups=0.58, wpb=108, bsz=40, num_updates=1010, lr=1.09189e-05, gnorm=1.207, clip=70, loss_scale=256, train_wall=17, gb_free=10.3, ema_decay=0.9999, wall=1807
2022-10-10 10:26:14 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 57820 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=62.5, ups=0.58, wpb=108.3, bsz=40, num_updates=1020, lr=1.1027e-05, gnorm=1.169, clip=80, loss_scale=256, train_wall=17, gb_free=10.9, ema_decay=0.9999, wall=1825
2022-10-10 10:26:31 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 57820 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=66.7, ups=0.61, wpb=110, bsz=40, num_updates=1030, lr=1.11351e-05, gnorm=1.112, clip=80, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=1841
2022-10-10 10:26:47 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 57820 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=66.5, ups=0.61, wpb=109.9, bsz=40, num_updates=1040, lr=1.12432e-05, gnorm=1.138, clip=50, loss_scale=512, train_wall=16, gb_free=10.5, ema_decay=0.9999, wall=1858
2022-10-10 10:27:04 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 57820 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=67.2, ups=0.61, wpb=109.7, bsz=40, num_updates=1050, lr=1.13514e-05, gnorm=1.12, clip=60, loss_scale=512, train_wall=16, gb_free=11, ema_decay=0.9999, wall=1874
2022-10-10 10:27:21 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 57820 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=63.2, ups=0.57, wpb=110.4, bsz=40, num_updates=1060, lr=1.14595e-05, gnorm=1.117, clip=90, loss_scale=512, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=1891
2022-10-10 10:27:38 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 57820 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=64.3, ups=0.58, wpb=110.1, bsz=40, num_updates=1070, lr=1.15676e-05, gnorm=0.997, clip=50, loss_scale=512, train_wall=17, gb_free=10.5, ema_decay=0.9999, wall=1909
2022-10-10 10:27:55 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 57820 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=65.9, ups=0.6, wpb=109.6, bsz=40, num_updates=1080, lr=1.16757e-05, gnorm=1.203, clip=80, loss_scale=512, train_wall=16, gb_free=10.4, ema_decay=0.9999, wall=1925
2022-10-10 10:28:12 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 57820 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=63.6, ups=0.58, wpb=108.8, bsz=40, num_updates=1090, lr=1.17838e-05, gnorm=1.212, clip=80, loss_scale=512, train_wall=17, gb_free=10.5, ema_decay=0.9999, wall=1942
2022-10-10 10:28:28 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 57820 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=71.2, ups=0.64, wpb=111, bsz=40, num_updates=1100, lr=1.18919e-05, gnorm=1.263, clip=80, loss_scale=512, train_wall=15, gb_free=11.1, ema_decay=0.9999, wall=1958
2022-10-10 10:28:43 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 57820 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=69.8, ups=0.63, wpb=110.3, bsz=40, num_updates=1110, lr=1.2e-05, gnorm=1.278, clip=80, loss_scale=512, train_wall=16, gb_free=10.9, ema_decay=0.9999, wall=1974
2022-10-10 10:29:00 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 57820 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=65.3, ups=0.6, wpb=108.2, bsz=40, num_updates=1120, lr=1.21081e-05, gnorm=1.258, clip=80, loss_scale=512, train_wall=16, gb_free=10.8, ema_decay=0.9999, wall=1990
2022-10-10 10:29:17 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 57820 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=62, ups=0.57, wpb=108.8, bsz=40, num_updates=1130, lr=1.22162e-05, gnorm=1.078, clip=60, loss_scale=512, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=2008
2022-10-10 10:29:39 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 57820 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=50.4, ups=0.46, wpb=109, bsz=40, num_updates=1140, lr=1.23243e-05, gnorm=1.2, clip=80, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=2030
2022-10-10 10:29:55 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 57820 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=69.7, ups=0.63, wpb=110.1, bsz=40, num_updates=1150, lr=1.24324e-05, gnorm=1.141, clip=70, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=2045
2022-10-10 10:30:10 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 57820 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=71.3, ups=0.65, wpb=109.8, bsz=40, num_updates=1160, lr=1.25405e-05, gnorm=1.031, clip=70, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=2061
2022-10-10 10:30:27 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 57820 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=69.4, ups=0.63, wpb=110.2, bsz=40, num_updates=1170, lr=1.26486e-05, gnorm=1.183, clip=70, loss_scale=512, train_wall=16, gb_free=10.5, ema_decay=0.9999, wall=2077
2022-10-10 10:30:42 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 57820 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=68.7, ups=0.63, wpb=108.7, bsz=40, num_updates=1180, lr=1.27568e-05, gnorm=1.211, clip=70, loss_scale=512, train_wall=16, gb_free=10.9, ema_decay=0.9999, wall=2093
2022-10-10 10:30:58 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 57820 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=72.5, ups=0.66, wpb=109.5, bsz=40, num_updates=1190, lr=1.28649e-05, gnorm=1.251, clip=90, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=2108
2022-10-10 10:31:12 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 57820 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=74.5, ups=0.69, wpb=107.7, bsz=40, num_updates=1200, lr=1.2973e-05, gnorm=1.119, clip=90, loss_scale=512, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=2122
2022-10-10 10:31:27 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 57820 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=71.4, ups=0.65, wpb=110.5, bsz=40, num_updates=1210, lr=1.30811e-05, gnorm=1.175, clip=90, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=2138
2022-10-10 10:31:42 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 57820 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=78, ups=0.71, wpb=110.2, bsz=40, num_updates=1220, lr=1.31892e-05, gnorm=1.052, clip=60, loss_scale=512, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=2152
2022-10-10 10:31:58 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 57820 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=67.5, ups=0.62, wpb=108.1, bsz=40, num_updates=1230, lr=1.32973e-05, gnorm=1.319, clip=100, loss_scale=512, train_wall=16, gb_free=10.8, ema_decay=0.9999, wall=2168
2022-10-10 10:32:12 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 57820 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=75.6, ups=0.69, wpb=109.7, bsz=40, num_updates=1240, lr=1.34054e-05, gnorm=1.078, clip=60, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2183
2022-10-10 10:32:27 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 57820 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=75.6, ups=0.69, wpb=109.7, bsz=40, num_updates=1250, lr=1.35135e-05, gnorm=1.091, clip=70, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2197
2022-10-10 10:32:41 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 57820 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=74, ups=0.68, wpb=109.6, bsz=40, num_updates=1260, lr=1.36216e-05, gnorm=1.132, clip=90, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=2212
2022-10-10 10:32:55 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 57820 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=80.2, ups=0.72, wpb=111.2, bsz=40, num_updates=1270, lr=1.37297e-05, gnorm=1.041, clip=60, loss_scale=512, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=2226
2022-10-10 10:33:10 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 57820 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=76.8, ups=0.7, wpb=109.8, bsz=40, num_updates=1280, lr=1.38378e-05, gnorm=1.102, clip=70, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2240
2022-10-10 10:33:24 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 57820 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=74.3, ups=0.68, wpb=109.3, bsz=40, num_updates=1290, lr=1.39459e-05, gnorm=1.215, clip=90, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=2255
2022-10-10 10:33:39 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 57820 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=77.3, ups=0.7, wpb=109.9, bsz=40, num_updates=1300, lr=1.40541e-05, gnorm=1.083, clip=70, loss_scale=512, train_wall=14, gb_free=10.8, ema_decay=0.9999, wall=2269
2022-10-10 10:33:52 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 57820 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=79.7, ups=0.73, wpb=109.8, bsz=40, num_updates=1310, lr=1.41622e-05, gnorm=1.201, clip=90, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2283
2022-10-10 10:34:06 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 57820 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=79.7, ups=0.73, wpb=108.8, bsz=40, num_updates=1320, lr=1.42703e-05, gnorm=1.188, clip=70, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=2296
2022-10-10 10:34:20 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 57820 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=78.1, ups=0.71, wpb=110.7, bsz=40, num_updates=1330, lr=1.43784e-05, gnorm=1.09, clip=50, loss_scale=512, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=2311
2022-10-10 10:34:34 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 57820 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=80.9, ups=0.74, wpb=109.9, bsz=40, num_updates=1340, lr=1.44865e-05, gnorm=1.107, clip=70, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=2324
2022-10-10 10:34:48 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 57820 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=79.3, ups=0.72, wpb=109.5, bsz=40, num_updates=1350, lr=1.45946e-05, gnorm=1.194, clip=80, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2338
2022-10-10 10:35:01 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 57820 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=84.5, ups=0.77, wpb=110.2, bsz=40, num_updates=1360, lr=1.47027e-05, gnorm=1.35, clip=100, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=2351
2022-10-10 10:35:14 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 57820 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=79.5, ups=0.73, wpb=109.5, bsz=40, num_updates=1370, lr=1.48108e-05, gnorm=1.051, clip=70, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2365
2022-10-10 10:35:28 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 57820 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=78.6, ups=0.72, wpb=109.1, bsz=40, num_updates=1380, lr=1.49189e-05, gnorm=1.096, clip=70, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2379
2022-10-10 10:35:41 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 57820 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=83.1, ups=0.76, wpb=109.2, bsz=40, num_updates=1390, lr=1.5027e-05, gnorm=1.127, clip=80, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=2392
2022-10-10 10:35:55 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 57820 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=81.2, ups=0.74, wpb=109.7, bsz=40, num_updates=1400, lr=1.51351e-05, gnorm=1.148, clip=60, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=2405
2022-10-10 10:36:08 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 57820 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=83.5, ups=0.75, wpb=111.4, bsz=40, num_updates=1410, lr=1.52432e-05, gnorm=1.084, clip=60, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=2419
2022-10-10 10:36:23 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 57820 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=74.9, ups=0.68, wpb=110, bsz=40, num_updates=1420, lr=1.53514e-05, gnorm=1.242, clip=80, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=2433
2022-10-10 10:36:37 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 57820 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=80.4, ups=0.72, wpb=111.6, bsz=40, num_updates=1430, lr=1.54595e-05, gnorm=1.145, clip=80, loss_scale=512, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=2447
2022-10-10 10:36:50 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 57820 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=82.5, ups=0.75, wpb=109.4, bsz=40, num_updates=1440, lr=1.55676e-05, gnorm=1.12, clip=60, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=2461
2022-10-10 10:37:04 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 57820 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=78, ups=0.71, wpb=110.5, bsz=40, num_updates=1450, lr=1.56757e-05, gnorm=1.136, clip=70, loss_scale=512, train_wall=14, gb_free=10.4, ema_decay=0.9999, wall=2475
2022-10-10 10:37:18 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 57820 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=79.7, ups=0.71, wpb=112, bsz=40, num_updates=1460, lr=1.57838e-05, gnorm=0.992, clip=30, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2489
2022-10-10 10:37:32 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 57820 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=80.1, ups=0.73, wpb=110.1, bsz=40, num_updates=1470, lr=1.58919e-05, gnorm=1.129, clip=60, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2503
2022-10-10 10:37:46 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 57820 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=76.8, ups=0.7, wpb=109.8, bsz=40, num_updates=1480, lr=1.6e-05, gnorm=1.068, clip=50, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2517
2022-10-10 10:38:01 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 57820 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=75.8, ups=0.69, wpb=110.1, bsz=40, num_updates=1490, lr=1.61081e-05, gnorm=0.994, clip=50, loss_scale=512, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=2531
2022-10-10 10:38:15 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 57820 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=80.9, ups=0.73, wpb=110.7, bsz=40, num_updates=1500, lr=1.62162e-05, gnorm=1.028, clip=60, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2545
2022-10-10 10:38:28 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 57820 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=81, ups=0.74, wpb=109.6, bsz=40, num_updates=1510, lr=1.63243e-05, gnorm=1.087, clip=50, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=2559
2022-10-10 10:38:42 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 57820 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=77.9, ups=0.72, wpb=108.5, bsz=40, num_updates=1520, lr=1.64324e-05, gnorm=1.132, clip=50, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2573
2022-10-10 10:38:57 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 57820 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=74.5, ups=0.68, wpb=110.4, bsz=40, num_updates=1530, lr=1.65405e-05, gnorm=0.977, clip=30, loss_scale=512, train_wall=15, gb_free=9.9, ema_decay=0.9999, wall=2587
2022-10-10 10:39:10 - progress_bar.py[line:274] - INFO: epoch 001:   1540 / 57820 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=82.2, ups=0.75, wpb=110.2, bsz=40, num_updates=1540, lr=1.66486e-05, gnorm=1.017, clip=50, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=2601
2022-10-10 10:39:24 - progress_bar.py[line:274] - INFO: epoch 001:   1550 / 57820 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=79.4, ups=0.73, wpb=109.3, bsz=40, num_updates=1550, lr=1.67568e-05, gnorm=1.147, clip=70, loss_scale=1024, train_wall=14, gb_free=10.9, ema_decay=0.9999, wall=2615
2022-10-10 10:39:27 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 10:39:40 - progress_bar.py[line:274] - INFO: epoch 001:   1561 / 57820 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=69.4, ups=0.63, wpb=109.5, bsz=40, num_updates=1560, lr=1.68649e-05, gnorm=1.147, clip=70, loss_scale=512, train_wall=16, gb_free=10.8, ema_decay=0.9999, wall=2630
2022-10-10 10:39:54 - progress_bar.py[line:274] - INFO: epoch 001:   1571 / 57820 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=78.5, ups=0.71, wpb=109.9, bsz=40, num_updates=1570, lr=1.6973e-05, gnorm=1.115, clip=60, loss_scale=512, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=2644
2022-10-10 10:40:08 - progress_bar.py[line:274] - INFO: epoch 001:   1581 / 57820 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=76.7, ups=0.69, wpb=110.8, bsz=40, num_updates=1580, lr=1.70811e-05, gnorm=1.248, clip=100, loss_scale=512, train_wall=14, gb_free=10.8, ema_decay=0.9999, wall=2659
2022-10-10 10:40:22 - progress_bar.py[line:274] - INFO: epoch 001:   1591 / 57820 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=78.1, ups=0.72, wpb=108.1, bsz=40, num_updates=1590, lr=1.71892e-05, gnorm=1.122, clip=60, loss_scale=512, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=2673
2022-10-10 10:40:36 - progress_bar.py[line:274] - INFO: epoch 001:   1601 / 57820 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=79.1, ups=0.72, wpb=109.2, bsz=40, num_updates=1600, lr=1.72973e-05, gnorm=1.274, clip=80, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2686
2022-10-10 10:40:50 - progress_bar.py[line:274] - INFO: epoch 001:   1611 / 57820 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=79.8, ups=0.73, wpb=109.8, bsz=40, num_updates=1610, lr=1.74054e-05, gnorm=1.085, clip=50, loss_scale=512, train_wall=14, gb_free=10.8, ema_decay=0.9999, wall=2700
2022-10-10 10:41:04 - progress_bar.py[line:274] - INFO: epoch 001:   1621 / 57820 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=78.2, ups=0.71, wpb=109.6, bsz=40, num_updates=1620, lr=1.75135e-05, gnorm=1.065, clip=60, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2714
2022-10-10 10:41:19 - progress_bar.py[line:274] - INFO: epoch 001:   1631 / 57820 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=73.7, ups=0.67, wpb=110.4, bsz=40, num_updates=1630, lr=1.76216e-05, gnorm=1.03, clip=50, loss_scale=512, train_wall=15, gb_free=10.6, ema_decay=0.9999, wall=2729
2022-10-10 10:41:33 - progress_bar.py[line:274] - INFO: epoch 001:   1641 / 57820 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=79.5, ups=0.73, wpb=109.4, bsz=40, num_updates=1640, lr=1.77297e-05, gnorm=1.028, clip=50, loss_scale=512, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=2743
2022-10-10 10:41:48 - progress_bar.py[line:274] - INFO: epoch 001:   1651 / 57820 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=73.4, ups=0.66, wpb=110.9, bsz=40, num_updates=1650, lr=1.78378e-05, gnorm=1.135, clip=70, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=2758
2022-10-10 10:42:02 - progress_bar.py[line:274] - INFO: epoch 001:   1661 / 57820 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=75.6, ups=0.69, wpb=109.9, bsz=40, num_updates=1660, lr=1.79459e-05, gnorm=1.036, clip=60, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2773
2022-10-10 10:42:17 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 57820 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=75.8, ups=0.69, wpb=109.4, bsz=40, num_updates=1670, lr=1.80541e-05, gnorm=1.099, clip=70, loss_scale=512, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=2787
2022-10-10 10:42:31 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 57820 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=78.5, ups=0.71, wpb=109.9, bsz=40, num_updates=1680, lr=1.81622e-05, gnorm=1.043, clip=60, loss_scale=512, train_wall=14, gb_free=10.8, ema_decay=0.9999, wall=2801
2022-10-10 10:42:45 - progress_bar.py[line:274] - INFO: epoch 001:   1691 / 57820 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=77.7, ups=0.71, wpb=109.2, bsz=40, num_updates=1690, lr=1.82703e-05, gnorm=1.265, clip=90, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2815
2022-10-10 10:43:00 - progress_bar.py[line:274] - INFO: epoch 001:   1701 / 57820 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=71.5, ups=0.65, wpb=109.5, bsz=40, num_updates=1700, lr=1.83784e-05, gnorm=1.255, clip=90, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=2831
2022-10-10 10:43:15 - progress_bar.py[line:274] - INFO: epoch 001:   1711 / 57820 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=72.9, ups=0.67, wpb=108.1, bsz=40, num_updates=1710, lr=1.84865e-05, gnorm=1.178, clip=70, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=2845
2022-10-10 10:43:30 - progress_bar.py[line:274] - INFO: epoch 001:   1721 / 57820 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=73.1, ups=0.67, wpb=108.5, bsz=40, num_updates=1720, lr=1.85946e-05, gnorm=1.02, clip=60, loss_scale=512, train_wall=15, gb_free=10.5, ema_decay=0.9999, wall=2860
2022-10-10 10:43:44 - progress_bar.py[line:274] - INFO: epoch 001:   1731 / 57820 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=74.9, ups=0.68, wpb=110.1, bsz=40, num_updates=1730, lr=1.87027e-05, gnorm=1.046, clip=60, loss_scale=512, train_wall=15, gb_free=11.1, ema_decay=0.9999, wall=2875
2022-10-10 10:43:59 - progress_bar.py[line:274] - INFO: epoch 001:   1741 / 57820 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=75.1, ups=0.69, wpb=109.1, bsz=40, num_updates=1740, lr=1.88108e-05, gnorm=1.266, clip=70, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2889
2022-10-10 10:44:13 - progress_bar.py[line:274] - INFO: epoch 001:   1751 / 57820 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=76.6, ups=0.7, wpb=109, bsz=40, num_updates=1750, lr=1.89189e-05, gnorm=1.183, clip=70, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2904
2022-10-10 10:44:27 - progress_bar.py[line:274] - INFO: epoch 001:   1761 / 57820 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=79.8, ups=0.72, wpb=110.6, bsz=40, num_updates=1760, lr=1.9027e-05, gnorm=1.057, clip=50, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2918
2022-10-10 10:44:41 - progress_bar.py[line:274] - INFO: epoch 001:   1771 / 57820 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=77.6, ups=0.71, wpb=109.6, bsz=40, num_updates=1770, lr=1.91351e-05, gnorm=1.19, clip=90, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=2932
2022-10-10 10:44:56 - progress_bar.py[line:274] - INFO: epoch 001:   1781 / 57820 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=74.2, ups=0.68, wpb=109.3, bsz=40, num_updates=1780, lr=1.92432e-05, gnorm=1.082, clip=80, loss_scale=512, train_wall=15, gb_free=10.8, ema_decay=0.9999, wall=2946
2022-10-10 10:45:10 - progress_bar.py[line:274] - INFO: epoch 001:   1791 / 57820 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=81, ups=0.74, wpb=109.9, bsz=40, num_updates=1790, lr=1.93514e-05, gnorm=1.035, clip=50, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=2960
2022-10-10 10:45:24 - progress_bar.py[line:274] - INFO: epoch 001:   1801 / 57820 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=72.7, ups=0.67, wpb=108.5, bsz=40, num_updates=1800, lr=1.94595e-05, gnorm=1.031, clip=50, loss_scale=512, train_wall=15, gb_free=10.6, ema_decay=0.9999, wall=2975
2022-10-10 10:45:38 - progress_bar.py[line:274] - INFO: epoch 001:   1811 / 57820 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=80.5, ups=0.73, wpb=110.1, bsz=40, num_updates=1810, lr=1.95676e-05, gnorm=1.058, clip=60, loss_scale=512, train_wall=14, gb_free=11, ema_decay=0.9999, wall=2989
2022-10-10 10:45:52 - progress_bar.py[line:274] - INFO: epoch 001:   1821 / 57820 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=78.9, ups=0.71, wpb=110.6, bsz=40, num_updates=1820, lr=1.96757e-05, gnorm=1.174, clip=70, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=3003
2022-10-10 10:46:06 - progress_bar.py[line:274] - INFO: epoch 001:   1831 / 57820 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=78.9, ups=0.72, wpb=109.9, bsz=40, num_updates=1830, lr=1.97838e-05, gnorm=0.993, clip=40, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=3017
2022-10-10 10:46:20 - progress_bar.py[line:274] - INFO: epoch 001:   1841 / 57820 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=80.4, ups=0.73, wpb=110.6, bsz=40, num_updates=1840, lr=1.98919e-05, gnorm=1.007, clip=60, loss_scale=512, train_wall=14, gb_free=11, ema_decay=0.9999, wall=3030
2022-10-10 10:46:34 - progress_bar.py[line:274] - INFO: epoch 001:   1851 / 57820 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=76.8, ups=0.7, wpb=110.1, bsz=40, num_updates=1850, lr=2e-05, gnorm=0.951, clip=40, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=3045
2022-10-10 10:46:48 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 57820 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=80.7, ups=0.75, wpb=107.8, bsz=40, num_updates=1860, lr=2.01081e-05, gnorm=1.256, clip=80, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=3058
2022-10-10 10:47:01 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 57820 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=80.5, ups=0.73, wpb=110.5, bsz=40, num_updates=1870, lr=2.02162e-05, gnorm=1.08, clip=60, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=3072
2022-10-10 10:47:16 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 57820 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=77, ups=0.7, wpb=110, bsz=40, num_updates=1880, lr=2.03243e-05, gnorm=1.179, clip=50, loss_scale=512, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=3086
2022-10-10 10:47:30 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 57820 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=73.9, ups=0.68, wpb=109.2, bsz=40, num_updates=1890, lr=2.04324e-05, gnorm=1.074, clip=60, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=3101
2022-10-10 10:47:45 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 57820 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=75.3, ups=0.68, wpb=110.7, bsz=40, num_updates=1900, lr=2.05405e-05, gnorm=1.056, clip=70, loss_scale=512, train_wall=15, gb_free=9.9, ema_decay=0.9999, wall=3116
2022-10-10 10:47:59 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 57820 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=77, ups=0.7, wpb=109.3, bsz=40, num_updates=1910, lr=2.06486e-05, gnorm=0.98, clip=50, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=3130
2022-10-10 10:48:15 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 57820 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=73.2, ups=0.66, wpb=110.8, bsz=40, num_updates=1920, lr=2.07568e-05, gnorm=1.105, clip=80, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=3145
2022-10-10 10:48:28 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 57820 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=80.2, ups=0.74, wpb=108.8, bsz=40, num_updates=1930, lr=2.08649e-05, gnorm=1.095, clip=90, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=3159
2022-10-10 10:48:43 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 57820 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=75.6, ups=0.68, wpb=111.3, bsz=40, num_updates=1940, lr=2.0973e-05, gnorm=1.066, clip=60, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=3173
2022-10-10 10:48:57 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 57820 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=77.9, ups=0.7, wpb=111, bsz=40, num_updates=1950, lr=2.10811e-05, gnorm=1.192, clip=90, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=3188
2022-10-10 10:49:12 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 57820 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=76.5, ups=0.69, wpb=111.1, bsz=40, num_updates=1960, lr=2.11892e-05, gnorm=1.003, clip=40, loss_scale=512, train_wall=14, gb_free=10.4, ema_decay=0.9999, wall=3202
2022-10-10 10:49:25 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 57820 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=79.4, ups=0.73, wpb=109.5, bsz=40, num_updates=1970, lr=2.12973e-05, gnorm=0.99, clip=50, loss_scale=512, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=3216
2022-10-10 10:49:40 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 57820 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=74.6, ups=0.69, wpb=108.6, bsz=40, num_updates=1980, lr=2.14054e-05, gnorm=0.892, clip=40, loss_scale=512, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=3230
2022-10-10 10:49:54 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 57820 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=78.5, ups=0.72, wpb=109.2, bsz=40, num_updates=1990, lr=2.15135e-05, gnorm=1.203, clip=70, loss_scale=512, train_wall=14, gb_free=10.9, ema_decay=0.9999, wall=3244
2022-10-10 10:50:07 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 57820 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=84, ups=0.77, wpb=108.4, bsz=40, num_updates=2000, lr=2.16216e-05, gnorm=1.129, clip=70, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=3257
2022-10-10 10:50:21 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 57820 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=79.8, ups=0.73, wpb=109.9, bsz=40, num_updates=2010, lr=2.17297e-05, gnorm=0.926, clip=30, loss_scale=512, train_wall=14, gb_free=10.8, ema_decay=0.9999, wall=3271
2022-10-10 10:50:34 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 57820 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=78.7, ups=0.73, wpb=108.5, bsz=40, num_updates=2020, lr=2.18378e-05, gnorm=1, clip=50, loss_scale=512, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=3285
2022-10-10 10:50:49 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 57820 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=72.7, ups=0.67, wpb=108.4, bsz=40, num_updates=2030, lr=2.19459e-05, gnorm=0.943, clip=20, loss_scale=512, train_wall=15, gb_free=10.8, ema_decay=0.9999, wall=3300
2022-10-10 10:51:05 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 57820 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=71.5, ups=0.66, wpb=109.1, bsz=40, num_updates=2040, lr=2.20541e-05, gnorm=1.109, clip=70, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=3315
2022-10-10 10:51:19 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 57820 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=73.9, ups=0.68, wpb=108.4, bsz=40, num_updates=2050, lr=2.21622e-05, gnorm=0.996, clip=40, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=3330
2022-10-10 10:51:34 - progress_bar.py[line:274] - INFO: epoch 001:   2061 / 57820 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=74, ups=0.66, wpb=111.4, bsz=40, num_updates=2060, lr=2.22703e-05, gnorm=1.047, clip=50, loss_scale=512, train_wall=15, gb_free=10.8, ema_decay=0.9999, wall=3345
2022-10-10 10:51:43 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 10:51:51 - progress_bar.py[line:274] - INFO: epoch 001:   2072 / 57820 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=65.1, ups=0.6, wpb=109, bsz=40, num_updates=2070, lr=2.23784e-05, gnorm=1.14, clip=70, loss_scale=512, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=3361
2022-10-10 10:52:06 - progress_bar.py[line:274] - INFO: epoch 001:   2082 / 57820 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=75.7, ups=0.69, wpb=109.7, bsz=40, num_updates=2080, lr=2.24865e-05, gnorm=1.175, clip=70, loss_scale=512, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=3376
2022-10-10 10:52:20 - progress_bar.py[line:274] - INFO: epoch 001:   2092 / 57820 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=76, ups=0.69, wpb=109.9, bsz=40, num_updates=2090, lr=2.25946e-05, gnorm=1.105, clip=70, loss_scale=512, train_wall=14, gb_free=10.8, ema_decay=0.9999, wall=3390
2022-10-10 10:52:37 - progress_bar.py[line:274] - INFO: epoch 001:   2102 / 57820 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=65.8, ups=0.6, wpb=110.3, bsz=40, num_updates=2100, lr=2.27027e-05, gnorm=1.278, clip=80, loss_scale=512, train_wall=17, gb_free=10.5, ema_decay=0.9999, wall=3407
2022-10-10 10:52:54 - progress_bar.py[line:274] - INFO: epoch 001:   2112 / 57820 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=64.7, ups=0.6, wpb=108.8, bsz=40, num_updates=2110, lr=2.28108e-05, gnorm=1.028, clip=50, loss_scale=512, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=3424
2022-10-10 10:53:10 - progress_bar.py[line:274] - INFO: epoch 001:   2122 / 57820 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=65.3, ups=0.59, wpb=110.2, bsz=40, num_updates=2120, lr=2.29189e-05, gnorm=1.074, clip=60, loss_scale=512, train_wall=17, gb_free=10.6, ema_decay=0.9999, wall=3441
2022-10-10 10:53:27 - progress_bar.py[line:274] - INFO: epoch 001:   2132 / 57820 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=64.8, ups=0.59, wpb=108.9, bsz=40, num_updates=2130, lr=2.3027e-05, gnorm=1.161, clip=60, loss_scale=512, train_wall=17, gb_free=10.6, ema_decay=0.9999, wall=3458
2022-10-10 10:53:44 - progress_bar.py[line:274] - INFO: epoch 001:   2142 / 57820 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=67, ups=0.61, wpb=109.3, bsz=40, num_updates=2140, lr=2.31351e-05, gnorm=1.062, clip=70, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=3474
2022-10-10 10:54:00 - progress_bar.py[line:274] - INFO: epoch 001:   2152 / 57820 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=65.1, ups=0.6, wpb=108.3, bsz=40, num_updates=2150, lr=2.32432e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=17, gb_free=10.4, ema_decay=0.9999, wall=3491
2022-10-10 10:54:16 - progress_bar.py[line:274] - INFO: epoch 001:   2162 / 57820 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=66.6, ups=0.62, wpb=107.6, bsz=40, num_updates=2160, lr=2.33514e-05, gnorm=1.086, clip=70, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=3507
2022-10-10 10:54:33 - progress_bar.py[line:274] - INFO: epoch 001:   2172 / 57820 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=67.1, ups=0.61, wpb=110.8, bsz=40, num_updates=2170, lr=2.34595e-05, gnorm=0.957, clip=20, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=3523
2022-10-10 10:54:49 - progress_bar.py[line:274] - INFO: epoch 001:   2182 / 57820 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=68.5, ups=0.62, wpb=110.9, bsz=40, num_updates=2180, lr=2.35676e-05, gnorm=0.846, clip=10, loss_scale=512, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=3540
2022-10-10 10:55:04 - progress_bar.py[line:274] - INFO: epoch 001:   2192 / 57820 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=70.9, ups=0.66, wpb=108.2, bsz=40, num_updates=2190, lr=2.36757e-05, gnorm=0.903, clip=20, loss_scale=512, train_wall=15, gb_free=10.9, ema_decay=0.9999, wall=3555
2022-10-10 10:55:20 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 57820 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=68.5, ups=0.62, wpb=110, bsz=40, num_updates=2200, lr=2.37838e-05, gnorm=1.062, clip=50, loss_scale=512, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=3571
2022-10-10 10:55:37 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 57820 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=65.2, ups=0.6, wpb=109.5, bsz=40, num_updates=2210, lr=2.38919e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=17, gb_free=10.5, ema_decay=0.9999, wall=3588
2022-10-10 10:55:54 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 57820 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=66.6, ups=0.61, wpb=109.6, bsz=40, num_updates=2220, lr=2.4e-05, gnorm=1.103, clip=70, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=3604
2022-10-10 10:56:09 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 57820 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=70.8, ups=0.64, wpb=110.5, bsz=40, num_updates=2230, lr=2.41081e-05, gnorm=0.953, clip=30, loss_scale=512, train_wall=15, gb_free=10.6, ema_decay=0.9999, wall=3620
2022-10-10 10:56:25 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=68.9, ups=0.63, wpb=109.7, bsz=40, num_updates=2240, lr=2.42162e-05, gnorm=0.945, clip=20, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=3636
2022-10-10 10:56:41 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 57820 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=68.1, ups=0.63, wpb=108.9, bsz=40, num_updates=2250, lr=2.43243e-05, gnorm=1.13, clip=60, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=3652
2022-10-10 10:56:58 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 57820 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=64.2, ups=0.59, wpb=109, bsz=40, num_updates=2260, lr=2.44324e-05, gnorm=1.081, clip=80, loss_scale=512, train_wall=17, gb_free=10.5, ema_decay=0.9999, wall=3669
2022-10-10 10:57:13 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 57820 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=73.7, ups=0.68, wpb=108.5, bsz=40, num_updates=2270, lr=2.45405e-05, gnorm=1.082, clip=50, loss_scale=512, train_wall=15, gb_free=10.4, ema_decay=0.9999, wall=3683
2022-10-10 10:57:29 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 57820 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=68.7, ups=0.63, wpb=108.5, bsz=40, num_updates=2280, lr=2.46486e-05, gnorm=1.061, clip=50, loss_scale=512, train_wall=16, gb_free=9.9, ema_decay=0.9999, wall=3699
2022-10-10 10:57:44 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 57820 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=70.8, ups=0.64, wpb=109.8, bsz=40, num_updates=2290, lr=2.47568e-05, gnorm=1.019, clip=60, loss_scale=512, train_wall=15, gb_free=10.9, ema_decay=0.9999, wall=3715
2022-10-10 10:58:00 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 57820 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=70, ups=0.64, wpb=109.5, bsz=40, num_updates=2300, lr=2.48649e-05, gnorm=1.027, clip=60, loss_scale=512, train_wall=16, gb_free=11.2, ema_decay=0.9999, wall=3730
2022-10-10 10:58:16 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 57820 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=69.8, ups=0.63, wpb=110.2, bsz=40, num_updates=2310, lr=2.4973e-05, gnorm=1.178, clip=80, loss_scale=512, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=3746
2022-10-10 10:58:31 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 57820 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=70.8, ups=0.65, wpb=108.5, bsz=40, num_updates=2320, lr=2.50811e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=3762
2022-10-10 10:58:47 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 57820 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=68.3, ups=0.62, wpb=109.6, bsz=40, num_updates=2330, lr=2.51892e-05, gnorm=1.031, clip=50, loss_scale=512, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=3778
2022-10-10 10:59:04 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 57820 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=65.8, ups=0.6, wpb=109.4, bsz=40, num_updates=2340, lr=2.52973e-05, gnorm=0.999, clip=50, loss_scale=512, train_wall=17, gb_free=10.8, ema_decay=0.9999, wall=3794
2022-10-10 10:59:20 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 57820 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=65.2, ups=0.6, wpb=108.6, bsz=40, num_updates=2350, lr=2.54054e-05, gnorm=1.051, clip=50, loss_scale=512, train_wall=17, gb_free=10.6, ema_decay=0.9999, wall=3811
2022-10-10 10:59:36 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 57820 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=70.6, ups=0.64, wpb=110.7, bsz=40, num_updates=2360, lr=2.55135e-05, gnorm=0.997, clip=30, loss_scale=512, train_wall=16, gb_free=10.5, ema_decay=0.9999, wall=3827
2022-10-10 10:59:53 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 57820 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=64.1, ups=0.59, wpb=108.5, bsz=40, num_updates=2370, lr=2.56216e-05, gnorm=1.055, clip=50, loss_scale=512, train_wall=17, gb_free=10.6, ema_decay=0.9999, wall=3843
2022-10-10 11:00:09 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 57820 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=68.7, ups=0.62, wpb=110, bsz=40, num_updates=2380, lr=2.57297e-05, gnorm=1.002, clip=20, loss_scale=512, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=3860
2022-10-10 11:00:24 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 57820 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=75.4, ups=0.69, wpb=109.5, bsz=40, num_updates=2390, lr=2.58378e-05, gnorm=0.995, clip=50, loss_scale=512, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=3874
2022-10-10 11:00:39 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 57820 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=71.2, ups=0.66, wpb=108.2, bsz=40, num_updates=2400, lr=2.59459e-05, gnorm=0.996, clip=50, loss_scale=512, train_wall=15, gb_free=10.9, ema_decay=0.9999, wall=3889
2022-10-10 11:00:54 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=71.3, ups=0.65, wpb=109.2, bsz=40, num_updates=2410, lr=2.60541e-05, gnorm=0.876, clip=20, loss_scale=512, train_wall=15, gb_free=10.8, ema_decay=0.9999, wall=3905
2022-10-10 11:01:10 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=69, ups=0.63, wpb=109.1, bsz=40, num_updates=2420, lr=2.61622e-05, gnorm=0.928, clip=40, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=3920
2022-10-10 11:01:25 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 57820 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=72.8, ups=0.66, wpb=109.9, bsz=40, num_updates=2430, lr=2.62703e-05, gnorm=1.039, clip=60, loss_scale=512, train_wall=15, gb_free=11.1, ema_decay=0.9999, wall=3936
2022-10-10 11:01:41 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 57820 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=70.9, ups=0.64, wpb=109.9, bsz=40, num_updates=2440, lr=2.63784e-05, gnorm=0.989, clip=40, loss_scale=512, train_wall=15, gb_free=10.9, ema_decay=0.9999, wall=3951
2022-10-10 11:01:56 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 57820 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=70.3, ups=0.64, wpb=109.3, bsz=40, num_updates=2450, lr=2.64865e-05, gnorm=0.97, clip=50, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=3967
2022-10-10 11:02:12 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 57820 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=70.2, ups=0.64, wpb=109.4, bsz=40, num_updates=2460, lr=2.65946e-05, gnorm=0.981, clip=30, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=3982
2022-10-10 11:02:27 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 57820 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=69.8, ups=0.64, wpb=109.8, bsz=40, num_updates=2470, lr=2.67027e-05, gnorm=0.885, clip=30, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=3998
2022-10-10 11:02:44 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=65.2, ups=0.6, wpb=109.6, bsz=40, num_updates=2480, lr=2.68108e-05, gnorm=1.024, clip=40, loss_scale=512, train_wall=17, gb_free=10.7, ema_decay=0.9999, wall=4015
2022-10-10 11:03:00 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 57820 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=69.7, ups=0.63, wpb=109.9, bsz=40, num_updates=2490, lr=2.69189e-05, gnorm=1.167, clip=80, loss_scale=512, train_wall=16, gb_free=10.5, ema_decay=0.9999, wall=4030
2022-10-10 11:03:16 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 57820 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=70.1, ups=0.64, wpb=109.3, bsz=40, num_updates=2500, lr=2.7027e-05, gnorm=1.06, clip=50, loss_scale=512, train_wall=15, gb_free=10.8, ema_decay=0.9999, wall=4046
2022-10-10 11:03:32 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 57820 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=67.4, ups=0.62, wpb=109.2, bsz=40, num_updates=2510, lr=2.71351e-05, gnorm=0.918, clip=40, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=4062
2022-10-10 11:03:48 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 57820 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=68.7, ups=0.63, wpb=109.8, bsz=40, num_updates=2520, lr=2.72432e-05, gnorm=0.99, clip=40, loss_scale=512, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=4078
2022-10-10 11:04:03 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 57820 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=73.9, ups=0.67, wpb=111.1, bsz=40, num_updates=2530, lr=2.73514e-05, gnorm=0.975, clip=50, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=4093
2022-10-10 11:04:17 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=79.1, ups=0.73, wpb=108.8, bsz=40, num_updates=2540, lr=2.74595e-05, gnorm=0.908, clip=30, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=4107
2022-10-10 11:04:32 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 57820 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=72.3, ups=0.65, wpb=111, bsz=40, num_updates=2550, lr=2.75676e-05, gnorm=1.026, clip=50, loss_scale=512, train_wall=15, gb_free=10.6, ema_decay=0.9999, wall=4122
2022-10-10 11:04:48 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 57820 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=68.2, ups=0.63, wpb=108.9, bsz=40, num_updates=2560, lr=2.76757e-05, gnorm=1.005, clip=30, loss_scale=512, train_wall=16, gb_free=10.9, ema_decay=0.9999, wall=4138
2022-10-10 11:05:03 - progress_bar.py[line:274] - INFO: epoch 001:   2572 / 57820 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=75.4, ups=0.68, wpb=110.5, bsz=40, num_updates=2570, lr=2.77838e-05, gnorm=0.964, clip=30, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=4153
2022-10-10 11:05:17 - progress_bar.py[line:274] - INFO: epoch 001:   2582 / 57820 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=75.9, ups=0.69, wpb=110.6, bsz=40, num_updates=2580, lr=2.78919e-05, gnorm=0.886, clip=30, loss_scale=1024, train_wall=14, gb_free=10, ema_decay=0.9999, wall=4168
2022-10-10 11:05:33 - progress_bar.py[line:274] - INFO: epoch 001:   2592 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=70, ups=0.63, wpb=110.9, bsz=40, num_updates=2590, lr=2.8e-05, gnorm=0.839, clip=10, loss_scale=1024, train_wall=16, gb_free=10.5, ema_decay=0.9999, wall=4184
2022-10-10 11:05:49 - progress_bar.py[line:274] - INFO: epoch 001:   2602 / 57820 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=68.6, ups=0.63, wpb=108.3, bsz=40, num_updates=2600, lr=2.81081e-05, gnorm=0.926, clip=40, loss_scale=1024, train_wall=16, gb_free=10.8, ema_decay=0.9999, wall=4199
2022-10-10 11:06:05 - progress_bar.py[line:274] - INFO: epoch 001:   2612 / 57820 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=68, ups=0.63, wpb=108.8, bsz=40, num_updates=2610, lr=2.82162e-05, gnorm=0.966, clip=30, loss_scale=1024, train_wall=16, gb_free=10.5, ema_decay=0.9999, wall=4215
2022-10-10 11:06:20 - progress_bar.py[line:274] - INFO: epoch 001:   2622 / 57820 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=73, ups=0.66, wpb=110.2, bsz=40, num_updates=2620, lr=2.83243e-05, gnorm=0.903, clip=40, loss_scale=1024, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=4230
2022-10-10 11:06:35 - progress_bar.py[line:274] - INFO: epoch 001:   2632 / 57820 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=72, ups=0.65, wpb=110.2, bsz=40, num_updates=2630, lr=2.84324e-05, gnorm=0.802, clip=30, loss_scale=1024, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=4246
2022-10-10 11:06:50 - progress_bar.py[line:274] - INFO: epoch 001:   2642 / 57820 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=72.6, ups=0.66, wpb=109.3, bsz=40, num_updates=2640, lr=2.85405e-05, gnorm=0.862, clip=20, loss_scale=1024, train_wall=15, gb_free=10.9, ema_decay=0.9999, wall=4261
2022-10-10 11:07:06 - progress_bar.py[line:274] - INFO: epoch 001:   2652 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=72.3, ups=0.65, wpb=110.8, bsz=40, num_updates=2650, lr=2.86486e-05, gnorm=0.898, clip=30, loss_scale=1024, train_wall=15, gb_free=10.8, ema_decay=0.9999, wall=4276
2022-10-10 11:07:18 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 11:07:22 - progress_bar.py[line:274] - INFO: epoch 001:   2663 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=67, ups=0.61, wpb=110.7, bsz=40, num_updates=2660, lr=2.87568e-05, gnorm=0.834, clip=20, loss_scale=512, train_wall=16, gb_free=11, ema_decay=0.9999, wall=4293
2022-10-10 11:07:38 - progress_bar.py[line:274] - INFO: epoch 001:   2673 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=71.1, ups=0.64, wpb=110.4, bsz=40, num_updates=2670, lr=2.88649e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=4308
2022-10-10 11:07:54 - progress_bar.py[line:274] - INFO: epoch 001:   2683 / 57820 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=67.1, ups=0.61, wpb=110.4, bsz=40, num_updates=2680, lr=2.8973e-05, gnorm=0.973, clip=50, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=4325
2022-10-10 11:08:11 - progress_bar.py[line:274] - INFO: epoch 001:   2693 / 57820 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=67.3, ups=0.61, wpb=110, bsz=40, num_updates=2690, lr=2.90811e-05, gnorm=0.919, clip=50, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=4341
2022-10-10 11:08:26 - progress_bar.py[line:274] - INFO: epoch 001:   2703 / 57820 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=71.5, ups=0.66, wpb=109.1, bsz=40, num_updates=2700, lr=2.91892e-05, gnorm=0.977, clip=20, loss_scale=512, train_wall=15, gb_free=10.5, ema_decay=0.9999, wall=4356
2022-10-10 11:08:41 - progress_bar.py[line:274] - INFO: epoch 001:   2713 / 57820 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=73.8, ups=0.67, wpb=110.4, bsz=40, num_updates=2710, lr=2.92973e-05, gnorm=0.953, clip=60, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=4371
2022-10-10 11:08:56 - progress_bar.py[line:274] - INFO: epoch 001:   2723 / 57820 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=74.2, ups=0.67, wpb=110.3, bsz=40, num_updates=2720, lr=2.94054e-05, gnorm=0.846, clip=30, loss_scale=512, train_wall=15, gb_free=10.8, ema_decay=0.9999, wall=4386
2022-10-10 11:09:11 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 57820 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=72.7, ups=0.65, wpb=111.1, bsz=40, num_updates=2730, lr=2.95135e-05, gnorm=1.011, clip=40, loss_scale=512, train_wall=15, gb_free=10.4, ema_decay=0.9999, wall=4401
2022-10-10 11:09:26 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 57820 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=74, ups=0.68, wpb=109, bsz=40, num_updates=2740, lr=2.96216e-05, gnorm=0.841, clip=10, loss_scale=512, train_wall=15, gb_free=10.8, ema_decay=0.9999, wall=4416
2022-10-10 11:09:41 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 57820 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=70.3, ups=0.65, wpb=108.9, bsz=40, num_updates=2750, lr=2.97297e-05, gnorm=0.99, clip=30, loss_scale=512, train_wall=15, gb_free=10.6, ema_decay=0.9999, wall=4432
2022-10-10 11:09:58 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=67.5, ups=0.61, wpb=110, bsz=40, num_updates=2760, lr=2.98378e-05, gnorm=0.995, clip=40, loss_scale=512, train_wall=16, gb_free=10.9, ema_decay=0.9999, wall=4448
2022-10-10 11:10:13 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 57820 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=73.4, ups=0.67, wpb=109.7, bsz=40, num_updates=2770, lr=2.99459e-05, gnorm=0.818, clip=20, loss_scale=512, train_wall=15, gb_free=10.8, ema_decay=0.9999, wall=4463
2022-10-10 11:10:28 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=71, ups=0.64, wpb=111.1, bsz=40, num_updates=2780, lr=3.00541e-05, gnorm=0.879, clip=30, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=4479
2022-10-10 11:10:44 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=68.2, ups=0.62, wpb=109.9, bsz=40, num_updates=2790, lr=3.01622e-05, gnorm=0.926, clip=30, loss_scale=512, train_wall=16, gb_free=10.5, ema_decay=0.9999, wall=4495
2022-10-10 11:11:01 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=67.2, ups=0.62, wpb=108.7, bsz=40, num_updates=2800, lr=3.02703e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=4511
2022-10-10 11:11:16 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 57820 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=70, ups=0.64, wpb=110.1, bsz=40, num_updates=2810, lr=3.03784e-05, gnorm=0.894, clip=30, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=4527
2022-10-10 11:11:33 - progress_bar.py[line:274] - INFO: epoch 001:   2823 / 57820 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=64.8, ups=0.59, wpb=109.4, bsz=40, num_updates=2820, lr=3.04865e-05, gnorm=0.965, clip=50, loss_scale=512, train_wall=17, gb_free=10.8, ema_decay=0.9999, wall=4544
2022-10-10 11:11:50 - progress_bar.py[line:274] - INFO: epoch 001:   2833 / 57820 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=67.4, ups=0.61, wpb=110.1, bsz=40, num_updates=2830, lr=3.05946e-05, gnorm=0.992, clip=50, loss_scale=512, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=4560
2022-10-10 11:12:06 - progress_bar.py[line:274] - INFO: epoch 001:   2843 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=68.8, ups=0.62, wpb=110.5, bsz=40, num_updates=2840, lr=3.07027e-05, gnorm=0.798, clip=10, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=4576
2022-10-10 11:12:21 - progress_bar.py[line:274] - INFO: epoch 001:   2853 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=73, ups=0.66, wpb=111.2, bsz=40, num_updates=2850, lr=3.08108e-05, gnorm=0.774, clip=20, loss_scale=512, train_wall=15, gb_free=10.7, ema_decay=0.9999, wall=4591
2022-10-10 11:12:37 - progress_bar.py[line:274] - INFO: epoch 001:   2863 / 57820 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=69.2, ups=0.63, wpb=109.4, bsz=40, num_updates=2860, lr=3.09189e-05, gnorm=0.807, clip=10, loss_scale=512, train_wall=16, gb_free=11, ema_decay=0.9999, wall=4607
2022-10-10 11:12:53 - progress_bar.py[line:274] - INFO: epoch 001:   2873 / 57820 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=68.5, ups=0.63, wpb=108.8, bsz=40, num_updates=2870, lr=3.1027e-05, gnorm=0.988, clip=30, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=4623
2022-10-10 11:13:08 - progress_bar.py[line:274] - INFO: epoch 001:   2883 / 57820 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=69.2, ups=0.63, wpb=109.1, bsz=40, num_updates=2880, lr=3.11351e-05, gnorm=0.871, clip=20, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=4639
2022-10-10 11:13:24 - progress_bar.py[line:274] - INFO: epoch 001:   2893 / 57820 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=70.3, ups=0.63, wpb=110.7, bsz=40, num_updates=2890, lr=3.12432e-05, gnorm=0.976, clip=50, loss_scale=512, train_wall=16, gb_free=10.9, ema_decay=0.9999, wall=4655
2022-10-10 11:13:40 - progress_bar.py[line:274] - INFO: epoch 001:   2903 / 57820 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=68.1, ups=0.62, wpb=109.1, bsz=40, num_updates=2900, lr=3.13514e-05, gnorm=0.79, clip=0, loss_scale=512, train_wall=16, gb_free=10.5, ema_decay=0.9999, wall=4671
2022-10-10 11:13:55 - progress_bar.py[line:274] - INFO: epoch 001:   2913 / 57820 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=73.6, ups=0.67, wpb=109.8, bsz=40, num_updates=2910, lr=3.14595e-05, gnorm=0.881, clip=10, loss_scale=512, train_wall=15, gb_free=10.6, ema_decay=0.9999, wall=4686
2022-10-10 11:14:09 - progress_bar.py[line:274] - INFO: epoch 001:   2923 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=82.8, ups=0.75, wpb=110.8, bsz=40, num_updates=2920, lr=3.15676e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=4699
2022-10-10 11:14:21 - progress_bar.py[line:274] - INFO: epoch 001:   2933 / 57820 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=86.4, ups=0.8, wpb=107.6, bsz=40, num_updates=2930, lr=3.16757e-05, gnorm=1.091, clip=60, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=4712
2022-10-10 11:14:38 - progress_bar.py[line:274] - INFO: epoch 001:   2943 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=66.6, ups=0.61, wpb=110, bsz=40, num_updates=2940, lr=3.17838e-05, gnorm=1.006, clip=40, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=4728
2022-10-10 11:14:54 - progress_bar.py[line:274] - INFO: epoch 001:   2953 / 57820 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=66.2, ups=0.6, wpb=109.9, bsz=40, num_updates=2950, lr=3.18919e-05, gnorm=1.087, clip=60, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=4745
2022-10-10 11:15:11 - progress_bar.py[line:274] - INFO: epoch 001:   2963 / 57820 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=65.5, ups=0.6, wpb=108.9, bsz=40, num_updates=2960, lr=3.2e-05, gnorm=0.908, clip=30, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=4761
2022-10-10 11:15:27 - progress_bar.py[line:274] - INFO: epoch 001:   2973 / 57820 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=67.5, ups=0.62, wpb=108.2, bsz=40, num_updates=2970, lr=3.21081e-05, gnorm=0.911, clip=50, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=4777
2022-10-10 11:15:43 - progress_bar.py[line:274] - INFO: epoch 001:   2983 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=67.8, ups=0.61, wpb=111.2, bsz=40, num_updates=2980, lr=3.22162e-05, gnorm=0.849, clip=10, loss_scale=512, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=4794
2022-10-10 11:16:00 - progress_bar.py[line:274] - INFO: epoch 001:   2993 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=67.9, ups=0.61, wpb=110.5, bsz=40, num_updates=2990, lr=3.23243e-05, gnorm=0.915, clip=40, loss_scale=512, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=4810
2022-10-10 11:16:16 - progress_bar.py[line:274] - INFO: epoch 001:   3003 / 57820 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=65.2, ups=0.6, wpb=109, bsz=40, num_updates=3000, lr=3.24324e-05, gnorm=0.939, clip=30, loss_scale=512, train_wall=17, gb_free=10.6, ema_decay=0.9999, wall=4827
2022-10-10 11:16:16 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-10 11:16:16 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 11:16:19 - train.py[line:549] - INFO: 0 / 4988
2022-10-10 11:16:19 - train.py[line:551] - INFO: load:1.66 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-10 11:20:47 - train.py[line:549] - INFO: 200 / 4988
2022-10-10 11:20:47 - train.py[line:551] - INFO: load:1.90 valid_run:267.80 task_valid:250.79 collect_output:13.51
2022-10-10 11:24:49 - train.py[line:549] - INFO: 400 / 4988
2022-10-10 11:24:49 - train.py[line:551] - INFO: load:2.10 valid_run:509.02 task_valid:471.07 collect_output:31.05
2022-10-10 11:29:00 - train.py[line:549] - INFO: 600 / 4988
2022-10-10 11:29:00 - train.py[line:551] - INFO: load:2.26 valid_run:760.02 task_valid:700.47 collect_output:49.31
2022-10-10 11:33:06 - train.py[line:549] - INFO: 800 / 4988
2022-10-10 11:33:06 - train.py[line:551] - INFO: load:2.50 valid_run:1005.30 task_valid:931.27 collect_output:60.45
2022-10-10 11:36:59 - train.py[line:549] - INFO: 1000 / 4988
2022-10-10 11:36:59 - train.py[line:551] - INFO: load:2.76 valid_run:1238.36 task_valid:1150.44 collect_output:71.39
2022-10-10 11:41:12 - train.py[line:549] - INFO: 1200 / 4988
2022-10-10 11:41:12 - train.py[line:551] - INFO: load:2.96 valid_run:1490.79 task_valid:1384.44 collect_output:86.51
2022-10-10 11:45:22 - train.py[line:549] - INFO: 1400 / 4988
2022-10-10 11:45:22 - train.py[line:551] - INFO: load:3.11 valid_run:1741.17 task_valid:1614.71 collect_output:103.46
2022-10-10 11:49:24 - train.py[line:549] - INFO: 1600 / 4988
2022-10-10 11:49:24 - train.py[line:551] - INFO: load:3.36 valid_run:1982.10 task_valid:1836.12 collect_output:119.81
2022-10-10 11:53:30 - train.py[line:549] - INFO: 1800 / 4988
2022-10-10 11:53:30 - train.py[line:551] - INFO: load:3.58 valid_run:2227.87 task_valid:2060.42 collect_output:137.79
2022-10-10 11:56:33 - train.py[line:549] - INFO: 2000 / 4988
2022-10-10 11:56:33 - train.py[line:551] - INFO: load:3.63 valid_run:2410.73 task_valid:2233.76 collect_output:144.81
2022-10-10 11:59:32 - train.py[line:549] - INFO: 2200 / 4988
2022-10-10 11:59:32 - train.py[line:551] - INFO: load:3.72 valid_run:2590.12 task_valid:2405.99 collect_output:149.96
2022-10-10 12:02:34 - train.py[line:549] - INFO: 2400 / 4988
2022-10-10 12:02:34 - train.py[line:551] - INFO: load:3.78 valid_run:2771.93 task_valid:2579.50 collect_output:156.27
2022-10-10 12:05:35 - train.py[line:549] - INFO: 2600 / 4988
2022-10-10 12:05:35 - train.py[line:551] - INFO: load:3.83 valid_run:2952.70 task_valid:2751.69 collect_output:162.66
2022-10-10 12:08:45 - train.py[line:549] - INFO: 2800 / 4988
2022-10-10 12:08:45 - train.py[line:551] - INFO: load:3.88 valid_run:3142.67 task_valid:2934.26 collect_output:168.04
2022-10-10 12:12:01 - train.py[line:549] - INFO: 3000 / 4988
2022-10-10 12:12:01 - train.py[line:551] - INFO: load:3.94 valid_run:3338.67 task_valid:3124.09 collect_output:172.31
2022-10-10 12:15:14 - train.py[line:549] - INFO: 3200 / 4988
2022-10-10 12:15:14 - train.py[line:551] - INFO: load:4.01 valid_run:3531.02 task_valid:3306.23 collect_output:180.59
2022-10-10 12:18:29 - train.py[line:549] - INFO: 3400 / 4988
2022-10-10 12:18:29 - train.py[line:551] - INFO: load:4.07 valid_run:3726.26 task_valid:3492.92 collect_output:186.84
2022-10-10 12:21:36 - train.py[line:549] - INFO: 3600 / 4988
2022-10-10 12:21:36 - train.py[line:551] - INFO: load:4.11 valid_run:3912.79 task_valid:3670.25 collect_output:194.09
2022-10-10 12:24:46 - train.py[line:549] - INFO: 3800 / 4988
2022-10-10 12:24:46 - train.py[line:551] - INFO: load:4.17 valid_run:4103.03 task_valid:3845.02 collect_output:207.37
2022-10-10 12:27:46 - train.py[line:549] - INFO: 4000 / 4988
2022-10-10 12:27:46 - train.py[line:551] - INFO: load:4.27 valid_run:4282.53 task_valid:4014.73 collect_output:215.21
2022-10-10 12:31:01 - train.py[line:549] - INFO: 4200 / 4988
2022-10-10 12:31:01 - train.py[line:551] - INFO: load:4.32 valid_run:4477.50 task_valid:4196.04 collect_output:226.80
2022-10-10 12:34:19 - train.py[line:549] - INFO: 4400 / 4988
2022-10-10 12:34:19 - train.py[line:551] - INFO: load:4.36 valid_run:4675.53 task_valid:4383.04 collect_output:235.75
2022-10-10 12:37:29 - train.py[line:549] - INFO: 4600 / 4988
2022-10-10 12:37:29 - train.py[line:551] - INFO: load:4.47 valid_run:4865.75 task_valid:4552.74 collect_output:254.10
2022-10-10 12:40:25 - train.py[line:549] - INFO: 4800 / 4988
2022-10-10 12:40:25 - train.py[line:551] - INFO: load:4.50 valid_run:5040.96 task_valid:4717.31 collect_output:262.74

====================================================================================================
SGG eval:     R @ 50: 0.6688;     R @ 100: 0.7015;     R @ 500: 0.7222;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4664;    mR @ 100: 0.5121;    mR @ 500: 0.5501;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.8125) (covering:0.5143) (eating:0.8235) (flying in:0.7727) (growing on:0.3750) (hanging from:0.4355) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9467) (says:0.0000) (sitting on:0.7602) (standing on:0.4263) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6688;     R @ 100: 0.7015;     R @ 500: 0.7222;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4664;    mR @ 100: 0.5121;    mR @ 500: 0.5501;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.8125) (covering:0.5143) (eating:0.8235) (flying in:0.7727) (growing on:0.3750) (hanging from:0.4355) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9467) (says:0.0000) (sitting on:0.7602) (standing on:0.4263) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 12:43:24 - train.py[line:487] - INFO: 0.7014710211357269
2022-10-10 12:43:24 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-10 12:43:24 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.357 | loss_v1 0 | loss_v2 0 | nll_loss 0.206 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.701471 | ppl 1.15 | vqa_score 0.5563 | wps 85.9 | wpb 89.9 | bsz 30 | num_updates 3000
2022-10-10 12:43:24 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3000 updates
2022-10-10 12:43:24 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-10 12:43:31 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-10 12:43:38 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 0.7014710211357269) (writing took 13.914274592883885 seconds)
2022-10-10 12:43:51 - progress_bar.py[line:274] - INFO: epoch 001:   3013 / 57820 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=0.2, ups=0, wpb=111.7, bsz=40, num_updates=3010, lr=3.25405e-05, gnorm=0.842, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=10081
2022-10-10 12:44:03 - progress_bar.py[line:274] - INFO: epoch 001:   3023 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.4, ups=0.8, wpb=109.6, bsz=40, num_updates=3020, lr=3.26486e-05, gnorm=0.737, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10094
2022-10-10 12:44:16 - progress_bar.py[line:274] - INFO: epoch 001:   3033 / 57820 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=83.8, ups=0.78, wpb=107.5, bsz=40, num_updates=3030, lr=3.27568e-05, gnorm=0.869, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=10107
2022-10-10 12:44:29 - progress_bar.py[line:274] - INFO: epoch 001:   3043 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.9, ups=0.79, wpb=109.7, bsz=40, num_updates=3040, lr=3.28649e-05, gnorm=0.851, clip=30, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=10119
2022-10-10 12:44:41 - progress_bar.py[line:274] - INFO: epoch 001:   3053 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.7, ups=0.8, wpb=108.2, bsz=40, num_updates=3050, lr=3.2973e-05, gnorm=0.786, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10132
2022-10-10 12:44:53 - progress_bar.py[line:274] - INFO: epoch 001:   3063 / 57820 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=91.4, ups=0.83, wpb=109.7, bsz=40, num_updates=3060, lr=3.30811e-05, gnorm=0.953, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10144
2022-10-10 12:45:07 - progress_bar.py[line:274] - INFO: epoch 001:   3073 / 57820 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=83, ups=0.76, wpb=108.8, bsz=40, num_updates=3070, lr=3.31892e-05, gnorm=0.882, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=10157
2022-10-10 12:45:19 - progress_bar.py[line:274] - INFO: epoch 001:   3083 / 57820 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87.8, ups=0.81, wpb=108.5, bsz=40, num_updates=3080, lr=3.32973e-05, gnorm=0.91, clip=30, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=10169
2022-10-10 12:45:31 - progress_bar.py[line:274] - INFO: epoch 001:   3093 / 57820 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=88.4, ups=0.81, wpb=109.5, bsz=40, num_updates=3090, lr=3.34054e-05, gnorm=0.977, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10182
2022-10-10 12:45:44 - progress_bar.py[line:274] - INFO: epoch 001:   3103 / 57820 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=88.5, ups=0.81, wpb=109.6, bsz=40, num_updates=3100, lr=3.35135e-05, gnorm=0.82, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=10194
2022-10-10 12:45:56 - progress_bar.py[line:274] - INFO: epoch 001:   3113 / 57820 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=88.2, ups=0.8, wpb=109.7, bsz=40, num_updates=3110, lr=3.36216e-05, gnorm=0.923, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=10207
2022-10-10 12:46:08 - progress_bar.py[line:274] - INFO: epoch 001:   3123 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=90.6, ups=0.82, wpb=109.9, bsz=40, num_updates=3120, lr=3.37297e-05, gnorm=0.771, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10219
2022-10-10 12:46:21 - progress_bar.py[line:274] - INFO: epoch 001:   3133 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.2, ups=0.79, wpb=109, bsz=40, num_updates=3130, lr=3.38378e-05, gnorm=0.749, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=10231
2022-10-10 12:46:33 - progress_bar.py[line:274] - INFO: epoch 001:   3143 / 57820 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=92.4, ups=0.84, wpb=110.3, bsz=40, num_updates=3140, lr=3.39459e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10243
2022-10-10 12:46:45 - progress_bar.py[line:274] - INFO: epoch 001:   3153 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.7, ups=0.8, wpb=111.2, bsz=40, num_updates=3150, lr=3.40541e-05, gnorm=0.925, clip=30, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=10256
2022-10-10 12:46:58 - progress_bar.py[line:274] - INFO: epoch 001:   3163 / 57820 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.3, ups=0.77, wpb=111.4, bsz=40, num_updates=3160, lr=3.41622e-05, gnorm=0.872, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=10269
2022-10-10 12:47:11 - progress_bar.py[line:274] - INFO: epoch 001:   3173 / 57820 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=88.6, ups=0.79, wpb=111.4, bsz=40, num_updates=3170, lr=3.42703e-05, gnorm=0.887, clip=30, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=10281
2022-10-10 12:47:24 - progress_bar.py[line:274] - INFO: epoch 001:   3183 / 57820 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=85.5, ups=0.78, wpb=109, bsz=40, num_updates=3180, lr=3.43784e-05, gnorm=0.848, clip=10, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=10294
2022-10-10 12:47:36 - progress_bar.py[line:274] - INFO: epoch 001:   3193 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87, ups=0.8, wpb=108.8, bsz=40, num_updates=3190, lr=3.44865e-05, gnorm=0.782, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10307
2022-10-10 12:47:49 - progress_bar.py[line:274] - INFO: epoch 001:   3203 / 57820 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=85.7, ups=0.79, wpb=108, bsz=40, num_updates=3200, lr=3.45946e-05, gnorm=0.911, clip=30, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=10319
2022-10-10 12:48:01 - progress_bar.py[line:274] - INFO: epoch 001:   3213 / 57820 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=88.1, ups=0.81, wpb=109, bsz=40, num_updates=3210, lr=3.47027e-05, gnorm=0.802, clip=0, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=10332
2022-10-10 12:48:14 - progress_bar.py[line:274] - INFO: epoch 001:   3223 / 57820 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=88.6, ups=0.81, wpb=110, bsz=40, num_updates=3220, lr=3.48108e-05, gnorm=0.745, clip=20, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=10344
2022-10-10 12:48:22 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 12:48:27 - progress_bar.py[line:274] - INFO: epoch 001:   3234 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=81.1, ups=0.74, wpb=109.3, bsz=40, num_updates=3230, lr=3.49189e-05, gnorm=0.879, clip=20, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=10358
2022-10-10 12:48:40 - progress_bar.py[line:274] - INFO: epoch 001:   3244 / 57820 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=86.6, ups=0.79, wpb=108.9, bsz=40, num_updates=3240, lr=3.5027e-05, gnorm=0.976, clip=40, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=10370
2022-10-10 12:48:53 - progress_bar.py[line:274] - INFO: epoch 001:   3254 / 57820 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=86.7, ups=0.78, wpb=110.5, bsz=40, num_updates=3250, lr=3.51351e-05, gnorm=0.953, clip=20, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=10383
2022-10-10 12:49:05 - progress_bar.py[line:274] - INFO: epoch 001:   3264 / 57820 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.3, ups=0.8, wpb=108.8, bsz=40, num_updates=3260, lr=3.52432e-05, gnorm=0.77, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=10396
2022-10-10 12:49:17 - progress_bar.py[line:274] - INFO: epoch 001:   3274 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=91.1, ups=0.83, wpb=109.7, bsz=40, num_updates=3270, lr=3.53514e-05, gnorm=0.742, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10408
2022-10-10 12:49:30 - progress_bar.py[line:274] - INFO: epoch 001:   3284 / 57820 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=85.9, ups=0.78, wpb=109.9, bsz=40, num_updates=3280, lr=3.54595e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=10420
2022-10-10 12:49:43 - progress_bar.py[line:274] - INFO: epoch 001:   3294 / 57820 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87.6, ups=0.79, wpb=110.6, bsz=40, num_updates=3290, lr=3.55676e-05, gnorm=0.896, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=10433
2022-10-10 12:49:55 - progress_bar.py[line:274] - INFO: epoch 001:   3304 / 57820 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=88.2, ups=0.81, wpb=109.4, bsz=40, num_updates=3300, lr=3.56757e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10445
2022-10-10 12:50:08 - progress_bar.py[line:274] - INFO: epoch 001:   3314 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.5, ups=0.8, wpb=109.6, bsz=40, num_updates=3310, lr=3.57838e-05, gnorm=0.731, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10458
2022-10-10 12:50:20 - progress_bar.py[line:274] - INFO: epoch 001:   3324 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.4, ups=0.79, wpb=110.2, bsz=40, num_updates=3320, lr=3.58919e-05, gnorm=0.689, clip=0, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=10471
2022-10-10 12:50:33 - progress_bar.py[line:274] - INFO: epoch 001:   3334 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=88, ups=0.8, wpb=110, bsz=40, num_updates=3330, lr=3.6e-05, gnorm=0.923, clip=30, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=10483
2022-10-10 12:50:45 - progress_bar.py[line:274] - INFO: epoch 001:   3344 / 57820 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=88.3, ups=0.8, wpb=109.7, bsz=40, num_updates=3340, lr=3.61081e-05, gnorm=0.894, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=10496
2022-10-10 12:50:57 - progress_bar.py[line:274] - INFO: epoch 001:   3354 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=88.9, ups=0.81, wpb=109.8, bsz=40, num_updates=3350, lr=3.62162e-05, gnorm=0.863, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=10508
2022-10-10 12:51:10 - progress_bar.py[line:274] - INFO: epoch 001:   3364 / 57820 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87.2, ups=0.79, wpb=109.7, bsz=40, num_updates=3360, lr=3.63243e-05, gnorm=0.882, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10521
2022-10-10 12:51:23 - progress_bar.py[line:274] - INFO: epoch 001:   3374 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87, ups=0.79, wpb=110.3, bsz=40, num_updates=3370, lr=3.64324e-05, gnorm=0.721, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=10533
2022-10-10 12:51:36 - progress_bar.py[line:274] - INFO: epoch 001:   3384 / 57820 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87.1, ups=0.79, wpb=110.6, bsz=40, num_updates=3380, lr=3.65405e-05, gnorm=0.769, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=10546
2022-10-10 12:51:48 - progress_bar.py[line:274] - INFO: epoch 001:   3394 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=89, ups=0.8, wpb=111.5, bsz=40, num_updates=3390, lr=3.66486e-05, gnorm=0.737, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=10558
2022-10-10 12:52:01 - progress_bar.py[line:274] - INFO: epoch 001:   3404 / 57820 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87.8, ups=0.8, wpb=109.7, bsz=40, num_updates=3400, lr=3.67568e-05, gnorm=0.892, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=10571
2022-10-10 12:52:13 - progress_bar.py[line:274] - INFO: epoch 001:   3414 / 57820 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87.5, ups=0.81, wpb=108.5, bsz=40, num_updates=3410, lr=3.68649e-05, gnorm=0.873, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=10583
2022-10-10 12:52:25 - progress_bar.py[line:274] - INFO: epoch 001:   3424 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.8, ups=0.81, wpb=111.2, bsz=40, num_updates=3420, lr=3.6973e-05, gnorm=0.817, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10596
2022-10-10 12:52:38 - progress_bar.py[line:274] - INFO: epoch 001:   3434 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=88.2, ups=0.8, wpb=110, bsz=40, num_updates=3430, lr=3.70811e-05, gnorm=0.753, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10608
2022-10-10 12:52:50 - progress_bar.py[line:274] - INFO: epoch 001:   3444 / 57820 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87.5, ups=0.8, wpb=109.9, bsz=40, num_updates=3440, lr=3.71892e-05, gnorm=0.786, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10621
2022-10-10 12:53:03 - progress_bar.py[line:274] - INFO: epoch 001:   3454 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.6, ups=0.8, wpb=109.9, bsz=40, num_updates=3450, lr=3.72973e-05, gnorm=0.78, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=10633
2022-10-10 12:53:16 - progress_bar.py[line:274] - INFO: epoch 001:   3464 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=84.8, ups=0.78, wpb=109, bsz=40, num_updates=3460, lr=3.74054e-05, gnorm=0.736, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=10646
2022-10-10 12:53:28 - progress_bar.py[line:274] - INFO: epoch 001:   3474 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89, ups=0.81, wpb=109.7, bsz=40, num_updates=3470, lr=3.75135e-05, gnorm=0.753, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=10659
2022-10-10 12:53:41 - progress_bar.py[line:274] - INFO: epoch 001:   3484 / 57820 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=85.8, ups=0.78, wpb=109.5, bsz=40, num_updates=3480, lr=3.76216e-05, gnorm=0.906, clip=40, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=10671
2022-10-10 12:53:54 - progress_bar.py[line:274] - INFO: epoch 001:   3494 / 57820 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=86.9, ups=0.8, wpb=109.2, bsz=40, num_updates=3490, lr=3.77297e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=10684
2022-10-10 12:54:06 - progress_bar.py[line:274] - INFO: epoch 001:   3504 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.6, ups=0.8, wpb=109.6, bsz=40, num_updates=3500, lr=3.78378e-05, gnorm=0.753, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10697
2022-10-10 12:54:19 - progress_bar.py[line:274] - INFO: epoch 001:   3514 / 57820 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.7, ups=0.79, wpb=110.7, bsz=40, num_updates=3510, lr=3.79459e-05, gnorm=0.889, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=10709
2022-10-10 12:54:31 - progress_bar.py[line:274] - INFO: epoch 001:   3524 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.4, ups=0.82, wpb=108.8, bsz=40, num_updates=3520, lr=3.80541e-05, gnorm=0.828, clip=10, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=10721
2022-10-10 12:54:43 - progress_bar.py[line:274] - INFO: epoch 001:   3534 / 57820 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=89.7, ups=0.82, wpb=109.6, bsz=40, num_updates=3530, lr=3.81622e-05, gnorm=0.871, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=10734
2022-10-10 12:54:55 - progress_bar.py[line:274] - INFO: epoch 001:   3544 / 57820 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=88.9, ups=0.82, wpb=108.4, bsz=40, num_updates=3540, lr=3.82703e-05, gnorm=0.92, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10746
2022-10-10 12:55:08 - progress_bar.py[line:274] - INFO: epoch 001:   3554 / 57820 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.1, ups=0.78, wpb=110.2, bsz=40, num_updates=3550, lr=3.83784e-05, gnorm=0.848, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=10759
2022-10-10 12:55:21 - progress_bar.py[line:274] - INFO: epoch 001:   3564 / 57820 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.4, ups=0.8, wpb=108.4, bsz=40, num_updates=3560, lr=3.84865e-05, gnorm=0.832, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=10771
2022-10-10 12:55:34 - progress_bar.py[line:274] - INFO: epoch 001:   3574 / 57820 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=84.3, ups=0.77, wpb=109.1, bsz=40, num_updates=3570, lr=3.85946e-05, gnorm=0.836, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=10784
2022-10-10 12:55:46 - progress_bar.py[line:274] - INFO: epoch 001:   3584 / 57820 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87, ups=0.8, wpb=108.2, bsz=40, num_updates=3580, lr=3.87027e-05, gnorm=0.861, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=10797
2022-10-10 12:56:00 - progress_bar.py[line:274] - INFO: epoch 001:   3594 / 57820 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=81.3, ups=0.74, wpb=109.6, bsz=40, num_updates=3590, lr=3.88108e-05, gnorm=0.854, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=10810
2022-10-10 12:56:12 - progress_bar.py[line:274] - INFO: epoch 001:   3604 / 57820 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=88.9, ups=0.81, wpb=110, bsz=40, num_updates=3600, lr=3.89189e-05, gnorm=0.792, clip=20, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=10823
2022-10-10 12:56:25 - progress_bar.py[line:274] - INFO: epoch 001:   3614 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.1, ups=0.78, wpb=110.1, bsz=40, num_updates=3610, lr=3.9027e-05, gnorm=0.654, clip=0, loss_scale=512, train_wall=13, gb_free=10.2, ema_decay=0.9999, wall=10835
2022-10-10 12:56:38 - progress_bar.py[line:274] - INFO: epoch 001:   3624 / 57820 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.4, ups=0.78, wpb=110.2, bsz=40, num_updates=3620, lr=3.91351e-05, gnorm=0.76, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=10848
2022-10-10 12:56:50 - progress_bar.py[line:274] - INFO: epoch 001:   3634 / 57820 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=89.4, ups=0.82, wpb=109.3, bsz=40, num_updates=3630, lr=3.92432e-05, gnorm=0.857, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=10860
2022-10-10 12:57:02 - progress_bar.py[line:274] - INFO: epoch 001:   3644 / 57820 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.7, ups=0.8, wpb=108.9, bsz=40, num_updates=3640, lr=3.93514e-05, gnorm=0.882, clip=40, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=10873
2022-10-10 12:57:15 - progress_bar.py[line:274] - INFO: epoch 001:   3654 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.5, ups=0.8, wpb=109.9, bsz=40, num_updates=3650, lr=3.94595e-05, gnorm=0.746, clip=0, loss_scale=512, train_wall=12, gb_free=11.3, ema_decay=0.9999, wall=10885
2022-10-10 12:57:28 - progress_bar.py[line:274] - INFO: epoch 001:   3664 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.3, ups=0.79, wpb=108.6, bsz=40, num_updates=3660, lr=3.95676e-05, gnorm=0.684, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=10898
2022-10-10 12:57:40 - progress_bar.py[line:274] - INFO: epoch 001:   3674 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.5, ups=0.78, wpb=110.2, bsz=40, num_updates=3670, lr=3.96757e-05, gnorm=0.868, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=10911
2022-10-10 12:57:53 - progress_bar.py[line:274] - INFO: epoch 001:   3684 / 57820 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=88.7, ups=0.81, wpb=109.5, bsz=40, num_updates=3680, lr=3.97838e-05, gnorm=0.85, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=10923
2022-10-10 12:58:05 - progress_bar.py[line:274] - INFO: epoch 001:   3694 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.9, ups=0.79, wpb=111.4, bsz=40, num_updates=3690, lr=3.98919e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=10936
2022-10-10 12:58:18 - progress_bar.py[line:274] - INFO: epoch 001:   3704 / 57820 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=85.4, ups=0.78, wpb=109.5, bsz=40, num_updates=3700, lr=4e-05, gnorm=0.907, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=10949
2022-10-10 12:58:31 - progress_bar.py[line:274] - INFO: epoch 001:   3714 / 57820 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=89.5, ups=0.81, wpb=110.3, bsz=40, num_updates=3710, lr=4.01081e-05, gnorm=0.797, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10961
2022-10-10 12:58:44 - progress_bar.py[line:274] - INFO: epoch 001:   3724 / 57820 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=83.1, ups=0.76, wpb=109.1, bsz=40, num_updates=3720, lr=4.02162e-05, gnorm=0.787, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=10974
2022-10-10 12:58:57 - progress_bar.py[line:274] - INFO: epoch 001:   3734 / 57820 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87, ups=0.8, wpb=109.1, bsz=40, num_updates=3730, lr=4.03243e-05, gnorm=0.912, clip=40, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=10987
2022-10-10 12:59:09 - progress_bar.py[line:274] - INFO: epoch 001:   3744 / 57820 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=85.1, ups=0.79, wpb=108, bsz=40, num_updates=3740, lr=4.04324e-05, gnorm=0.784, clip=10, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=11000
2022-10-10 12:59:22 - progress_bar.py[line:274] - INFO: epoch 001:   3754 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85.1, ups=0.79, wpb=108.1, bsz=40, num_updates=3750, lr=4.05405e-05, gnorm=0.684, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11012
2022-10-10 12:59:34 - progress_bar.py[line:274] - INFO: epoch 001:   3764 / 57820 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=89.1, ups=0.82, wpb=109.3, bsz=40, num_updates=3760, lr=4.06486e-05, gnorm=0.733, clip=0, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11025
2022-10-10 12:59:46 - progress_bar.py[line:274] - INFO: epoch 001:   3774 / 57820 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=89.6, ups=0.82, wpb=109.5, bsz=40, num_updates=3770, lr=4.07568e-05, gnorm=0.785, clip=10, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11037
2022-10-10 12:59:59 - progress_bar.py[line:274] - INFO: epoch 001:   3784 / 57820 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=88.6, ups=0.81, wpb=109.9, bsz=40, num_updates=3780, lr=4.08649e-05, gnorm=0.806, clip=20, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11049
2022-10-10 13:00:12 - progress_bar.py[line:274] - INFO: epoch 001:   3794 / 57820 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=85.5, ups=0.79, wpb=108.1, bsz=40, num_updates=3790, lr=4.0973e-05, gnorm=0.87, clip=10, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11062
2022-10-10 13:00:15 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 13:00:25 - progress_bar.py[line:274] - INFO: epoch 001:   3805 / 57820 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=81.2, ups=0.75, wpb=108.8, bsz=40, num_updates=3800, lr=4.10811e-05, gnorm=0.817, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11075
2022-10-10 13:00:37 - progress_bar.py[line:274] - INFO: epoch 001:   3815 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.3, ups=0.8, wpb=108.6, bsz=40, num_updates=3810, lr=4.11892e-05, gnorm=0.862, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11088
2022-10-10 13:00:50 - progress_bar.py[line:274] - INFO: epoch 001:   3825 / 57820 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=88.4, ups=0.81, wpb=109.3, bsz=40, num_updates=3820, lr=4.12973e-05, gnorm=0.811, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11100
2022-10-10 13:01:03 - progress_bar.py[line:274] - INFO: epoch 001:   3835 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.4, ups=0.78, wpb=109.7, bsz=40, num_updates=3830, lr=4.14054e-05, gnorm=0.693, clip=10, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=11113
2022-10-10 13:01:15 - progress_bar.py[line:274] - INFO: epoch 001:   3845 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.3, ups=0.78, wpb=110.1, bsz=40, num_updates=3840, lr=4.15135e-05, gnorm=0.872, clip=20, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=11126
2022-10-10 13:01:28 - progress_bar.py[line:274] - INFO: epoch 001:   3855 / 57820 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=83.8, ups=0.77, wpb=108.8, bsz=40, num_updates=3850, lr=4.16216e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11139
2022-10-10 13:01:41 - progress_bar.py[line:274] - INFO: epoch 001:   3865 / 57820 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=86.1, ups=0.79, wpb=108.7, bsz=40, num_updates=3860, lr=4.17297e-05, gnorm=0.879, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11151
2022-10-10 13:01:53 - progress_bar.py[line:274] - INFO: epoch 001:   3875 / 57820 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.9, ups=0.82, wpb=109.4, bsz=40, num_updates=3870, lr=4.18378e-05, gnorm=0.828, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=11164
2022-10-10 13:02:06 - progress_bar.py[line:274] - INFO: epoch 001:   3885 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.4, ups=0.79, wpb=109.5, bsz=40, num_updates=3880, lr=4.19459e-05, gnorm=0.73, clip=20, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=11176
2022-10-10 13:02:18 - progress_bar.py[line:274] - INFO: epoch 001:   3895 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=89.5, ups=0.81, wpb=109.8, bsz=40, num_updates=3890, lr=4.20541e-05, gnorm=0.783, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=11189
2022-10-10 13:02:30 - progress_bar.py[line:274] - INFO: epoch 001:   3905 / 57820 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=90.5, ups=0.82, wpb=110.7, bsz=40, num_updates=3900, lr=4.21622e-05, gnorm=0.764, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11201
2022-10-10 13:02:43 - progress_bar.py[line:274] - INFO: epoch 001:   3915 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.5, ups=0.8, wpb=109, bsz=40, num_updates=3910, lr=4.22703e-05, gnorm=0.707, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11213
2022-10-10 13:02:55 - progress_bar.py[line:274] - INFO: epoch 001:   3925 / 57820 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=88.8, ups=0.82, wpb=108.6, bsz=40, num_updates=3920, lr=4.23784e-05, gnorm=0.828, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11226
2022-10-10 13:03:08 - progress_bar.py[line:274] - INFO: epoch 001:   3935 / 57820 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=89.1, ups=0.8, wpb=111.1, bsz=40, num_updates=3930, lr=4.24865e-05, gnorm=0.789, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11238
2022-10-10 13:03:20 - progress_bar.py[line:274] - INFO: epoch 001:   3945 / 57820 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.8, ups=0.81, wpb=108.3, bsz=40, num_updates=3940, lr=4.25946e-05, gnorm=0.792, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11250
2022-10-10 13:03:32 - progress_bar.py[line:274] - INFO: epoch 001:   3955 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=91.2, ups=0.82, wpb=111, bsz=40, num_updates=3950, lr=4.27027e-05, gnorm=0.709, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11263
2022-10-10 13:03:45 - progress_bar.py[line:274] - INFO: epoch 001:   3965 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.6, ups=0.79, wpb=108.6, bsz=40, num_updates=3960, lr=4.28108e-05, gnorm=0.776, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=11275
2022-10-10 13:03:57 - progress_bar.py[line:274] - INFO: epoch 001:   3975 / 57820 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=90.4, ups=0.83, wpb=109, bsz=40, num_updates=3970, lr=4.29189e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=11287
2022-10-10 13:04:10 - progress_bar.py[line:274] - INFO: epoch 001:   3985 / 57820 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.7, ups=0.8, wpb=111.4, bsz=40, num_updates=3980, lr=4.3027e-05, gnorm=0.66, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11300
2022-10-10 13:04:22 - progress_bar.py[line:274] - INFO: epoch 001:   3995 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=85, ups=0.78, wpb=109.4, bsz=40, num_updates=3990, lr=4.31351e-05, gnorm=0.799, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11313
2022-10-10 13:04:35 - progress_bar.py[line:274] - INFO: epoch 001:   4005 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.5, ups=0.81, wpb=108.3, bsz=40, num_updates=4000, lr=4.32432e-05, gnorm=0.701, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11325
2022-10-10 13:04:47 - progress_bar.py[line:274] - INFO: epoch 001:   4015 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=90, ups=0.82, wpb=110.3, bsz=40, num_updates=4010, lr=4.33514e-05, gnorm=0.88, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=11337
2022-10-10 13:04:59 - progress_bar.py[line:274] - INFO: epoch 001:   4025 / 57820 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=89.6, ups=0.81, wpb=110.7, bsz=40, num_updates=4020, lr=4.34595e-05, gnorm=0.849, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11350
2022-10-10 13:05:12 - progress_bar.py[line:274] - INFO: epoch 001:   4035 / 57820 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.2, ups=0.78, wpb=109.9, bsz=40, num_updates=4030, lr=4.35676e-05, gnorm=0.863, clip=30, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=11363
2022-10-10 13:05:25 - progress_bar.py[line:274] - INFO: epoch 001:   4045 / 57820 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=90.8, ups=0.82, wpb=111.1, bsz=40, num_updates=4040, lr=4.36757e-05, gnorm=0.887, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11375
2022-10-10 13:05:37 - progress_bar.py[line:274] - INFO: epoch 001:   4055 / 57820 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=88.8, ups=0.82, wpb=108.8, bsz=40, num_updates=4050, lr=4.37838e-05, gnorm=0.802, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11387
2022-10-10 13:05:49 - progress_bar.py[line:274] - INFO: epoch 001:   4065 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=90, ups=0.81, wpb=111.3, bsz=40, num_updates=4060, lr=4.38919e-05, gnorm=0.759, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11400
2022-10-10 13:06:01 - progress_bar.py[line:274] - INFO: epoch 001:   4075 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.4, ups=0.81, wpb=109.9, bsz=40, num_updates=4070, lr=4.4e-05, gnorm=0.683, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=11412
2022-10-10 13:06:14 - progress_bar.py[line:274] - INFO: epoch 001:   4085 / 57820 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=84.9, ups=0.78, wpb=108.8, bsz=40, num_updates=4080, lr=4.41081e-05, gnorm=0.779, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11425
2022-10-10 13:06:27 - progress_bar.py[line:274] - INFO: epoch 001:   4095 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.1, ups=0.8, wpb=110.8, bsz=40, num_updates=4090, lr=4.42162e-05, gnorm=0.72, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11437
2022-10-10 13:06:39 - progress_bar.py[line:274] - INFO: epoch 001:   4105 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=89.2, ups=0.81, wpb=110, bsz=40, num_updates=4100, lr=4.43243e-05, gnorm=0.807, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11450
2022-10-10 13:06:52 - progress_bar.py[line:274] - INFO: epoch 001:   4115 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=84.9, ups=0.78, wpb=109, bsz=40, num_updates=4110, lr=4.44324e-05, gnorm=0.801, clip=30, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=11463
2022-10-10 13:07:05 - progress_bar.py[line:274] - INFO: epoch 001:   4125 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.6, ups=0.79, wpb=109.9, bsz=40, num_updates=4120, lr=4.45405e-05, gnorm=0.807, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11475
2022-10-10 13:07:17 - progress_bar.py[line:274] - INFO: epoch 001:   4135 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.2, ups=0.81, wpb=109.6, bsz=40, num_updates=4130, lr=4.46486e-05, gnorm=0.751, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11488
2022-10-10 13:07:29 - progress_bar.py[line:274] - INFO: epoch 001:   4145 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=89.7, ups=0.82, wpb=109.5, bsz=40, num_updates=4140, lr=4.47568e-05, gnorm=0.912, clip=40, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11500
2022-10-10 13:07:42 - progress_bar.py[line:274] - INFO: epoch 001:   4155 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.8, ups=0.81, wpb=109.7, bsz=40, num_updates=4150, lr=4.48649e-05, gnorm=0.67, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=11512
2022-10-10 13:07:54 - progress_bar.py[line:274] - INFO: epoch 001:   4165 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=89.5, ups=0.81, wpb=110.2, bsz=40, num_updates=4160, lr=4.4973e-05, gnorm=0.694, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=11524
2022-10-10 13:08:06 - progress_bar.py[line:274] - INFO: epoch 001:   4175 / 57820 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.6, ups=0.81, wpb=108.6, bsz=40, num_updates=4170, lr=4.50811e-05, gnorm=0.933, clip=50, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11537
2022-10-10 13:08:19 - progress_bar.py[line:274] - INFO: epoch 001:   4185 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.8, ups=0.8, wpb=110.4, bsz=40, num_updates=4180, lr=4.51892e-05, gnorm=0.711, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11549
2022-10-10 13:08:31 - progress_bar.py[line:274] - INFO: epoch 001:   4195 / 57820 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=92.1, ups=0.84, wpb=109.3, bsz=40, num_updates=4190, lr=4.52973e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=11561
2022-10-10 13:08:43 - progress_bar.py[line:274] - INFO: epoch 001:   4205 / 57820 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.9, ups=0.8, wpb=110.6, bsz=40, num_updates=4200, lr=4.54054e-05, gnorm=0.648, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11574
2022-10-10 13:08:56 - progress_bar.py[line:274] - INFO: epoch 001:   4215 / 57820 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=90.5, ups=0.82, wpb=110.3, bsz=40, num_updates=4210, lr=4.55135e-05, gnorm=0.697, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11586
2022-10-10 13:09:09 - progress_bar.py[line:274] - INFO: epoch 001:   4225 / 57820 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=86, ups=0.78, wpb=110.3, bsz=40, num_updates=4220, lr=4.56216e-05, gnorm=0.812, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11599
2022-10-10 13:09:21 - progress_bar.py[line:274] - INFO: epoch 001:   4235 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.1, ups=0.8, wpb=108.5, bsz=40, num_updates=4230, lr=4.57297e-05, gnorm=0.715, clip=10, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=11611
2022-10-10 13:09:34 - progress_bar.py[line:274] - INFO: epoch 001:   4245 / 57820 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87, ups=0.78, wpb=111, bsz=40, num_updates=4240, lr=4.58378e-05, gnorm=0.765, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11624
2022-10-10 13:09:46 - progress_bar.py[line:274] - INFO: epoch 001:   4255 / 57820 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88, ups=0.8, wpb=110.1, bsz=40, num_updates=4250, lr=4.59459e-05, gnorm=0.604, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11637
2022-10-10 13:09:59 - progress_bar.py[line:274] - INFO: epoch 001:   4265 / 57820 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.4, ups=0.79, wpb=109.1, bsz=40, num_updates=4260, lr=4.60541e-05, gnorm=0.758, clip=30, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=11649
2022-10-10 13:10:12 - progress_bar.py[line:274] - INFO: epoch 001:   4275 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.6, ups=0.78, wpb=110.4, bsz=40, num_updates=4270, lr=4.61622e-05, gnorm=0.758, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=11662
2022-10-10 13:10:24 - progress_bar.py[line:274] - INFO: epoch 001:   4285 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.6, ups=0.8, wpb=111.5, bsz=40, num_updates=4280, lr=4.62703e-05, gnorm=0.737, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11675
2022-10-10 13:10:37 - progress_bar.py[line:274] - INFO: epoch 001:   4295 / 57820 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=86.7, ups=0.79, wpb=109.2, bsz=40, num_updates=4290, lr=4.63784e-05, gnorm=0.905, clip=20, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=11687
2022-10-10 13:10:49 - progress_bar.py[line:274] - INFO: epoch 001:   4305 / 57820 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87.6, ups=0.81, wpb=107.9, bsz=40, num_updates=4300, lr=4.64865e-05, gnorm=0.845, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11700
2022-10-10 13:11:02 - progress_bar.py[line:274] - INFO: epoch 001:   4315 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.1, ups=0.79, wpb=110.6, bsz=40, num_updates=4310, lr=4.65946e-05, gnorm=0.687, clip=10, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11712
2022-10-10 13:11:07 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 13:11:15 - progress_bar.py[line:274] - INFO: epoch 001:   4326 / 57820 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=80.3, ups=0.74, wpb=109, bsz=40, num_updates=4320, lr=4.67027e-05, gnorm=0.745, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11726
2022-10-10 13:11:28 - progress_bar.py[line:274] - INFO: epoch 001:   4336 / 57820 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.9, ups=0.79, wpb=109.6, bsz=40, num_updates=4330, lr=4.68108e-05, gnorm=0.751, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=11738
2022-10-10 13:11:41 - progress_bar.py[line:274] - INFO: epoch 001:   4346 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.6, ups=0.8, wpb=110.6, bsz=40, num_updates=4340, lr=4.69189e-05, gnorm=0.651, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11751
2022-10-10 13:11:53 - progress_bar.py[line:274] - INFO: epoch 001:   4356 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.4, ups=0.81, wpb=110.2, bsz=40, num_updates=4350, lr=4.7027e-05, gnorm=0.747, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11763
2022-10-10 13:12:05 - progress_bar.py[line:274] - INFO: epoch 001:   4366 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.3, ups=0.79, wpb=109.8, bsz=40, num_updates=4360, lr=4.71351e-05, gnorm=0.618, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11776
2022-10-10 13:12:18 - progress_bar.py[line:274] - INFO: epoch 001:   4376 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.4, ups=0.81, wpb=109.7, bsz=40, num_updates=4370, lr=4.72432e-05, gnorm=0.721, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11788
2022-10-10 13:12:30 - progress_bar.py[line:274] - INFO: epoch 001:   4386 / 57820 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87.5, ups=0.8, wpb=109.3, bsz=40, num_updates=4380, lr=4.73514e-05, gnorm=0.743, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11801
2022-10-10 13:12:43 - progress_bar.py[line:274] - INFO: epoch 001:   4396 / 57820 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=89, ups=0.8, wpb=111.6, bsz=40, num_updates=4390, lr=4.74595e-05, gnorm=0.747, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11813
2022-10-10 13:12:55 - progress_bar.py[line:274] - INFO: epoch 001:   4406 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.2, ups=0.81, wpb=109.5, bsz=40, num_updates=4400, lr=4.75676e-05, gnorm=0.711, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11826
2022-10-10 13:13:08 - progress_bar.py[line:274] - INFO: epoch 001:   4416 / 57820 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.4, ups=0.81, wpb=109.1, bsz=40, num_updates=4410, lr=4.76757e-05, gnorm=0.714, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11838
2022-10-10 13:13:20 - progress_bar.py[line:274] - INFO: epoch 001:   4426 / 57820 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.8, ups=0.8, wpb=110.4, bsz=40, num_updates=4420, lr=4.77838e-05, gnorm=0.708, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11851
2022-10-10 13:13:33 - progress_bar.py[line:274] - INFO: epoch 001:   4436 / 57820 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87.4, ups=0.8, wpb=108.7, bsz=40, num_updates=4430, lr=4.78919e-05, gnorm=0.805, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11863
2022-10-10 13:13:46 - progress_bar.py[line:274] - INFO: epoch 001:   4446 / 57820 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=84.9, ups=0.79, wpb=108.2, bsz=40, num_updates=4440, lr=4.8e-05, gnorm=0.751, clip=10, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=11876
2022-10-10 13:13:58 - progress_bar.py[line:274] - INFO: epoch 001:   4456 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.6, ups=0.8, wpb=108.6, bsz=40, num_updates=4450, lr=4.81081e-05, gnorm=0.67, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11889
2022-10-10 13:14:11 - progress_bar.py[line:274] - INFO: epoch 001:   4466 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.7, ups=0.8, wpb=110.9, bsz=40, num_updates=4460, lr=4.82162e-05, gnorm=0.724, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11901
2022-10-10 13:14:23 - progress_bar.py[line:274] - INFO: epoch 001:   4476 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.4, ups=0.78, wpb=111.1, bsz=40, num_updates=4470, lr=4.83243e-05, gnorm=0.722, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11914
2022-10-10 13:14:36 - progress_bar.py[line:274] - INFO: epoch 001:   4486 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.4, ups=0.78, wpb=110.8, bsz=40, num_updates=4480, lr=4.84324e-05, gnorm=0.763, clip=20, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=11927
2022-10-10 13:14:49 - progress_bar.py[line:274] - INFO: epoch 001:   4496 / 57820 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87, ups=0.8, wpb=108.6, bsz=40, num_updates=4490, lr=4.85405e-05, gnorm=0.712, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11939
2022-10-10 13:15:01 - progress_bar.py[line:274] - INFO: epoch 001:   4506 / 57820 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87.6, ups=0.81, wpb=107.5, bsz=40, num_updates=4500, lr=4.86486e-05, gnorm=0.717, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11952
2022-10-10 13:15:14 - progress_bar.py[line:274] - INFO: epoch 001:   4516 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87, ups=0.79, wpb=110.2, bsz=40, num_updates=4510, lr=4.87568e-05, gnorm=0.649, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=11964
2022-10-10 13:15:26 - progress_bar.py[line:274] - INFO: epoch 001:   4526 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.2, ups=0.79, wpb=110, bsz=40, num_updates=4520, lr=4.88649e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11977
2022-10-10 13:15:39 - progress_bar.py[line:274] - INFO: epoch 001:   4536 / 57820 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85.9, ups=0.79, wpb=109, bsz=40, num_updates=4530, lr=4.8973e-05, gnorm=0.781, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11990
2022-10-10 13:15:52 - progress_bar.py[line:274] - INFO: epoch 001:   4546 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=85.6, ups=0.79, wpb=107.9, bsz=40, num_updates=4540, lr=4.90811e-05, gnorm=0.761, clip=20, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=12002
2022-10-10 13:16:04 - progress_bar.py[line:274] - INFO: epoch 001:   4556 / 57820 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.8, ups=0.8, wpb=109.6, bsz=40, num_updates=4550, lr=4.91892e-05, gnorm=0.878, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12015
2022-10-10 13:16:17 - progress_bar.py[line:274] - INFO: epoch 001:   4566 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.7, ups=0.8, wpb=109.2, bsz=40, num_updates=4560, lr=4.92973e-05, gnorm=0.589, clip=10, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=12027
2022-10-10 13:16:29 - progress_bar.py[line:274] - INFO: epoch 001:   4576 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=89.5, ups=0.81, wpb=110.3, bsz=40, num_updates=4570, lr=4.94054e-05, gnorm=0.669, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12040
2022-10-10 13:16:41 - progress_bar.py[line:274] - INFO: epoch 001:   4586 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.3, ups=0.81, wpb=109.9, bsz=40, num_updates=4580, lr=4.95135e-05, gnorm=0.661, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=12052
2022-10-10 13:16:54 - progress_bar.py[line:274] - INFO: epoch 001:   4596 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85.4, ups=0.79, wpb=108.6, bsz=40, num_updates=4590, lr=4.96216e-05, gnorm=0.683, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12065
2022-10-10 13:17:07 - progress_bar.py[line:274] - INFO: epoch 001:   4606 / 57820 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.2, ups=0.79, wpb=109.7, bsz=40, num_updates=4600, lr=4.97297e-05, gnorm=0.802, clip=20, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=12077
2022-10-10 13:17:19 - progress_bar.py[line:274] - INFO: epoch 001:   4616 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.5, ups=0.82, wpb=108.2, bsz=40, num_updates=4610, lr=4.98378e-05, gnorm=0.69, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12089
2022-10-10 13:17:32 - progress_bar.py[line:274] - INFO: epoch 001:   4626 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.6, ups=0.79, wpb=110.2, bsz=40, num_updates=4620, lr=4.99459e-05, gnorm=0.667, clip=0, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=12102
2022-10-10 13:17:44 - progress_bar.py[line:274] - INFO: epoch 001:   4636 / 57820 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=88.5, ups=0.8, wpb=110, bsz=40, num_updates=4630, lr=4.99977e-05, gnorm=0.6, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=12115
2022-10-10 13:17:57 - progress_bar.py[line:274] - INFO: epoch 001:   4646 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.3, ups=0.8, wpb=109.2, bsz=40, num_updates=4640, lr=4.99932e-05, gnorm=0.777, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12127
2022-10-10 13:18:09 - progress_bar.py[line:274] - INFO: epoch 001:   4656 / 57820 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=90.6, ups=0.82, wpb=110.7, bsz=40, num_updates=4650, lr=4.99887e-05, gnorm=0.698, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12139
2022-10-10 13:18:22 - progress_bar.py[line:274] - INFO: epoch 001:   4666 / 57820 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=86.8, ups=0.79, wpb=109.9, bsz=40, num_updates=4660, lr=4.99842e-05, gnorm=0.726, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12152
2022-10-10 13:18:34 - progress_bar.py[line:274] - INFO: epoch 001:   4676 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.5, ups=0.78, wpb=110.5, bsz=40, num_updates=4670, lr=4.99797e-05, gnorm=0.643, clip=0, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=12165
2022-10-10 13:18:46 - progress_bar.py[line:274] - INFO: epoch 001:   4686 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=91.2, ups=0.83, wpb=110.4, bsz=40, num_updates=4680, lr=4.99752e-05, gnorm=0.653, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12177
2022-10-10 13:18:59 - progress_bar.py[line:274] - INFO: epoch 001:   4696 / 57820 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87.6, ups=0.8, wpb=109.4, bsz=40, num_updates=4690, lr=4.99707e-05, gnorm=0.782, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12189
2022-10-10 13:19:11 - progress_bar.py[line:274] - INFO: epoch 001:   4706 / 57820 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.4, ups=0.82, wpb=109.1, bsz=40, num_updates=4700, lr=4.99662e-05, gnorm=0.559, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=12202
2022-10-10 13:19:24 - progress_bar.py[line:274] - INFO: epoch 001:   4716 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=83.8, ups=0.76, wpb=109.8, bsz=40, num_updates=4710, lr=4.99617e-05, gnorm=0.731, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12215
2022-10-10 13:19:37 - progress_bar.py[line:274] - INFO: epoch 001:   4726 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.1, ups=0.82, wpb=108, bsz=40, num_updates=4720, lr=4.99572e-05, gnorm=0.789, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12227
2022-10-10 13:19:49 - progress_bar.py[line:274] - INFO: epoch 001:   4736 / 57820 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.5, ups=0.79, wpb=110.7, bsz=40, num_updates=4730, lr=4.99527e-05, gnorm=0.649, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12240
2022-10-10 13:20:02 - progress_bar.py[line:274] - INFO: epoch 001:   4746 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.9, ups=0.79, wpb=110.7, bsz=40, num_updates=4740, lr=4.99482e-05, gnorm=0.62, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12252
2022-10-10 13:20:14 - progress_bar.py[line:274] - INFO: epoch 001:   4756 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.2, ups=0.82, wpb=109.3, bsz=40, num_updates=4750, lr=4.99437e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12265
2022-10-10 13:20:27 - progress_bar.py[line:274] - INFO: epoch 001:   4766 / 57820 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.1, ups=0.79, wpb=108.6, bsz=40, num_updates=4760, lr=4.99392e-05, gnorm=0.744, clip=30, loss_scale=512, train_wall=13, gb_free=10.2, ema_decay=0.9999, wall=12277
2022-10-10 13:20:39 - progress_bar.py[line:274] - INFO: epoch 001:   4776 / 57820 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=92.3, ups=0.84, wpb=109.9, bsz=40, num_updates=4770, lr=4.99347e-05, gnorm=0.702, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12289
2022-10-10 13:20:51 - progress_bar.py[line:274] - INFO: epoch 001:   4786 / 57820 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=88.9, ups=0.81, wpb=109.9, bsz=40, num_updates=4780, lr=4.99302e-05, gnorm=0.75, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12301
2022-10-10 13:21:03 - progress_bar.py[line:274] - INFO: epoch 001:   4796 / 57820 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=88.1, ups=0.81, wpb=109, bsz=40, num_updates=4790, lr=4.99257e-05, gnorm=0.803, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=12314
2022-10-10 13:21:16 - progress_bar.py[line:274] - INFO: epoch 001:   4806 / 57820 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=89.9, ups=0.82, wpb=110, bsz=40, num_updates=4800, lr=4.99212e-05, gnorm=0.677, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12326
2022-10-10 13:21:29 - progress_bar.py[line:274] - INFO: epoch 001:   4816 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.1, ups=0.8, wpb=110.6, bsz=40, num_updates=4810, lr=4.99167e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=12339
2022-10-10 13:21:41 - progress_bar.py[line:274] - INFO: epoch 001:   4826 / 57820 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=86.5, ups=0.79, wpb=108.9, bsz=40, num_updates=4820, lr=4.99122e-05, gnorm=0.721, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12352
2022-10-10 13:21:54 - progress_bar.py[line:274] - INFO: epoch 001:   4836 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90.1, ups=0.81, wpb=110.9, bsz=40, num_updates=4830, lr=4.99077e-05, gnorm=0.579, clip=0, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=12364
2022-10-10 13:22:06 - progress_bar.py[line:274] - INFO: epoch 001:   4846 / 57820 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.2, ups=0.8, wpb=107.6, bsz=40, num_updates=4840, lr=4.99032e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12377
2022-10-10 13:22:19 - progress_bar.py[line:274] - INFO: epoch 001:   4856 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.6, ups=0.8, wpb=109.3, bsz=40, num_updates=4850, lr=4.98987e-05, gnorm=0.649, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12389
2022-10-10 13:22:31 - progress_bar.py[line:274] - INFO: epoch 001:   4866 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90.8, ups=0.82, wpb=110.8, bsz=40, num_updates=4860, lr=4.98942e-05, gnorm=0.711, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12401
2022-10-10 13:22:43 - progress_bar.py[line:274] - INFO: epoch 001:   4876 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=88.9, ups=0.8, wpb=111.3, bsz=40, num_updates=4870, lr=4.98897e-05, gnorm=0.69, clip=20, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12414
2022-10-10 13:22:56 - progress_bar.py[line:274] - INFO: epoch 001:   4886 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.6, ups=0.81, wpb=110.9, bsz=40, num_updates=4880, lr=4.98852e-05, gnorm=0.653, clip=10, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12426
2022-10-10 13:23:08 - progress_bar.py[line:274] - INFO: epoch 001:   4896 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.3, ups=0.8, wpb=107.5, bsz=40, num_updates=4890, lr=4.98806e-05, gnorm=0.705, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12439
2022-10-10 13:23:21 - progress_bar.py[line:274] - INFO: epoch 001:   4906 / 57820 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=88.1, ups=0.8, wpb=110, bsz=40, num_updates=4900, lr=4.98761e-05, gnorm=0.805, clip=10, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12451
2022-10-10 13:23:33 - progress_bar.py[line:274] - INFO: epoch 001:   4916 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=91.2, ups=0.82, wpb=111.6, bsz=40, num_updates=4910, lr=4.98716e-05, gnorm=0.624, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12463
2022-10-10 13:23:46 - progress_bar.py[line:274] - INFO: epoch 001:   4926 / 57820 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=85.3, ups=0.79, wpb=108.2, bsz=40, num_updates=4920, lr=4.98671e-05, gnorm=0.843, clip=20, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12476
2022-10-10 13:23:58 - progress_bar.py[line:274] - INFO: epoch 001:   4936 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=93.5, ups=0.84, wpb=111.8, bsz=40, num_updates=4930, lr=4.98626e-05, gnorm=0.734, clip=10, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=12488
2022-10-10 13:24:07 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 13:24:11 - progress_bar.py[line:274] - INFO: epoch 001:   4947 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=81.9, ups=0.74, wpb=110.1, bsz=40, num_updates=4940, lr=4.98581e-05, gnorm=0.648, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12502
2022-10-10 13:24:24 - progress_bar.py[line:274] - INFO: epoch 001:   4957 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=84.3, ups=0.77, wpb=108.8, bsz=40, num_updates=4950, lr=4.98536e-05, gnorm=0.68, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=12514
2022-10-10 13:24:36 - progress_bar.py[line:274] - INFO: epoch 001:   4967 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=90.1, ups=0.82, wpb=109.9, bsz=40, num_updates=4960, lr=4.98491e-05, gnorm=0.742, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12527
2022-10-10 13:24:48 - progress_bar.py[line:274] - INFO: epoch 001:   4977 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=90.4, ups=0.82, wpb=109.9, bsz=40, num_updates=4970, lr=4.98446e-05, gnorm=0.585, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12539
2022-10-10 13:25:01 - progress_bar.py[line:274] - INFO: epoch 001:   4987 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.3, ups=0.79, wpb=109, bsz=40, num_updates=4980, lr=4.98401e-05, gnorm=0.709, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12552
2022-10-10 13:25:14 - progress_bar.py[line:274] - INFO: epoch 001:   4997 / 57820 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.7, ups=0.79, wpb=109.7, bsz=40, num_updates=4990, lr=4.98356e-05, gnorm=0.745, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12564
2022-10-10 13:25:26 - progress_bar.py[line:274] - INFO: epoch 001:   5007 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.9, ups=0.79, wpb=109.8, bsz=40, num_updates=5000, lr=4.98311e-05, gnorm=0.713, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12577
2022-10-10 13:25:39 - progress_bar.py[line:274] - INFO: epoch 001:   5017 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.4, ups=0.79, wpb=109.9, bsz=40, num_updates=5010, lr=4.98266e-05, gnorm=0.673, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12590
2022-10-10 13:25:51 - progress_bar.py[line:274] - INFO: epoch 001:   5027 / 57820 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=89.6, ups=0.82, wpb=109.8, bsz=40, num_updates=5020, lr=4.98221e-05, gnorm=0.7, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=12602
2022-10-10 13:26:04 - progress_bar.py[line:274] - INFO: epoch 001:   5037 / 57820 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=89.3, ups=0.82, wpb=109.5, bsz=40, num_updates=5030, lr=4.98176e-05, gnorm=0.614, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12614
2022-10-10 13:26:16 - progress_bar.py[line:274] - INFO: epoch 001:   5047 / 57820 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.5, ups=0.8, wpb=109.2, bsz=40, num_updates=5040, lr=4.98131e-05, gnorm=0.492, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12627
2022-10-10 13:26:29 - progress_bar.py[line:274] - INFO: epoch 001:   5057 / 57820 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.6, ups=0.79, wpb=108.8, bsz=40, num_updates=5050, lr=4.98086e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=12639
2022-10-10 13:26:41 - progress_bar.py[line:274] - INFO: epoch 001:   5067 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.1, ups=0.81, wpb=110.6, bsz=40, num_updates=5060, lr=4.98041e-05, gnorm=0.769, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12652
2022-10-10 13:26:54 - progress_bar.py[line:274] - INFO: epoch 001:   5077 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.1, ups=0.8, wpb=109.1, bsz=40, num_updates=5070, lr=4.97996e-05, gnorm=0.569, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12664
2022-10-10 13:27:07 - progress_bar.py[line:274] - INFO: epoch 001:   5087 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86, ups=0.78, wpb=109.9, bsz=40, num_updates=5080, lr=4.97951e-05, gnorm=0.65, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12677
2022-10-10 13:27:19 - progress_bar.py[line:274] - INFO: epoch 001:   5097 / 57820 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=88.5, ups=0.81, wpb=109.1, bsz=40, num_updates=5090, lr=4.97906e-05, gnorm=0.736, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12689
2022-10-10 13:27:31 - progress_bar.py[line:274] - INFO: epoch 001:   5107 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88, ups=0.81, wpb=108.8, bsz=40, num_updates=5100, lr=4.97861e-05, gnorm=0.659, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12702
2022-10-10 13:27:44 - progress_bar.py[line:274] - INFO: epoch 001:   5117 / 57820 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=88.8, ups=0.8, wpb=111.1, bsz=40, num_updates=5110, lr=4.97816e-05, gnorm=0.667, clip=10, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=12714
2022-10-10 13:27:57 - progress_bar.py[line:274] - INFO: epoch 001:   5127 / 57820 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=84.1, ups=0.77, wpb=108.9, bsz=40, num_updates=5120, lr=4.97771e-05, gnorm=0.631, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12727
2022-10-10 13:28:09 - progress_bar.py[line:274] - INFO: epoch 001:   5137 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=91.7, ups=0.83, wpb=110.6, bsz=40, num_updates=5130, lr=4.97726e-05, gnorm=0.585, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12739
2022-10-10 13:28:22 - progress_bar.py[line:274] - INFO: epoch 001:   5147 / 57820 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=85.9, ups=0.79, wpb=109.1, bsz=40, num_updates=5140, lr=4.9768e-05, gnorm=0.692, clip=10, loss_scale=512, train_wall=13, gb_free=10.2, ema_decay=0.9999, wall=12752
2022-10-10 13:28:34 - progress_bar.py[line:274] - INFO: epoch 001:   5157 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.1, ups=0.81, wpb=108.8, bsz=40, num_updates=5150, lr=4.97635e-05, gnorm=0.718, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12765
2022-10-10 13:28:46 - progress_bar.py[line:274] - INFO: epoch 001:   5167 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.2, ups=0.83, wpb=107.5, bsz=40, num_updates=5160, lr=4.9759e-05, gnorm=0.559, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12777
2022-10-10 13:28:59 - progress_bar.py[line:274] - INFO: epoch 001:   5177 / 57820 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.1, ups=0.79, wpb=108.9, bsz=40, num_updates=5170, lr=4.97545e-05, gnorm=0.716, clip=0, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=12789
2022-10-10 13:29:11 - progress_bar.py[line:274] - INFO: epoch 001:   5187 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88, ups=0.8, wpb=109.9, bsz=40, num_updates=5180, lr=4.975e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=12802
2022-10-10 13:29:24 - progress_bar.py[line:274] - INFO: epoch 001:   5197 / 57820 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.4, ups=0.81, wpb=110.8, bsz=40, num_updates=5190, lr=4.97455e-05, gnorm=0.621, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12814
2022-10-10 13:29:36 - progress_bar.py[line:274] - INFO: epoch 001:   5207 / 57820 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.7, ups=0.79, wpb=109.8, bsz=40, num_updates=5200, lr=4.9741e-05, gnorm=0.633, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=12827
2022-10-10 13:29:49 - progress_bar.py[line:274] - INFO: epoch 001:   5217 / 57820 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87, ups=0.8, wpb=109.2, bsz=40, num_updates=5210, lr=4.97365e-05, gnorm=0.673, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12839
2022-10-10 13:30:01 - progress_bar.py[line:274] - INFO: epoch 001:   5227 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.3, ups=0.82, wpb=108.9, bsz=40, num_updates=5220, lr=4.9732e-05, gnorm=0.681, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12852
2022-10-10 13:30:14 - progress_bar.py[line:274] - INFO: epoch 001:   5237 / 57820 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.6, ups=0.79, wpb=112.1, bsz=40, num_updates=5230, lr=4.97275e-05, gnorm=0.608, clip=0, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=12864
2022-10-10 13:30:27 - progress_bar.py[line:274] - INFO: epoch 001:   5247 / 57820 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.1, ups=0.79, wpb=109.2, bsz=40, num_updates=5240, lr=4.9723e-05, gnorm=0.598, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12877
2022-10-10 13:30:39 - progress_bar.py[line:274] - INFO: epoch 001:   5257 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.4, ups=0.81, wpb=110.6, bsz=40, num_updates=5250, lr=4.97185e-05, gnorm=0.748, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12890
2022-10-10 13:30:52 - progress_bar.py[line:274] - INFO: epoch 001:   5267 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=84.1, ups=0.77, wpb=109.4, bsz=40, num_updates=5260, lr=4.9714e-05, gnorm=0.75, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12903
2022-10-10 13:31:06 - progress_bar.py[line:274] - INFO: epoch 001:   5277 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=82.5, ups=0.74, wpb=110.9, bsz=40, num_updates=5270, lr=4.97095e-05, gnorm=0.629, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12916
2022-10-10 13:31:18 - progress_bar.py[line:274] - INFO: epoch 001:   5287 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.4, ups=0.78, wpb=110.9, bsz=40, num_updates=5280, lr=4.9705e-05, gnorm=0.621, clip=10, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=12929
2022-10-10 13:31:31 - progress_bar.py[line:274] - INFO: epoch 001:   5297 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.4, ups=0.79, wpb=110.1, bsz=40, num_updates=5290, lr=4.97005e-05, gnorm=0.636, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12941
2022-10-10 13:31:44 - progress_bar.py[line:274] - INFO: epoch 001:   5307 / 57820 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=84.9, ups=0.78, wpb=108.9, bsz=40, num_updates=5300, lr=4.9696e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=12954
2022-10-10 13:31:57 - progress_bar.py[line:274] - INFO: epoch 001:   5317 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=82.9, ups=0.76, wpb=109.2, bsz=40, num_updates=5310, lr=4.96915e-05, gnorm=0.717, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12968
2022-10-10 13:32:09 - progress_bar.py[line:274] - INFO: epoch 001:   5327 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=90.3, ups=0.82, wpb=110.1, bsz=40, num_updates=5320, lr=4.9687e-05, gnorm=0.624, clip=0, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=12980
2022-10-10 13:32:22 - progress_bar.py[line:274] - INFO: epoch 001:   5337 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.3, ups=0.8, wpb=108.5, bsz=40, num_updates=5330, lr=4.96825e-05, gnorm=0.553, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12992
2022-10-10 13:32:35 - progress_bar.py[line:274] - INFO: epoch 001:   5347 / 57820 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.5, ups=0.79, wpb=110.1, bsz=40, num_updates=5340, lr=4.9678e-05, gnorm=0.754, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=13005
2022-10-10 13:32:47 - progress_bar.py[line:274] - INFO: epoch 001:   5357 / 57820 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.4, ups=0.81, wpb=109.7, bsz=40, num_updates=5350, lr=4.96735e-05, gnorm=0.601, clip=0, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=13018
2022-10-10 13:32:59 - progress_bar.py[line:274] - INFO: epoch 001:   5367 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.9, ups=0.81, wpb=109.6, bsz=40, num_updates=5360, lr=4.9669e-05, gnorm=0.603, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=13030
2022-10-10 13:33:12 - progress_bar.py[line:274] - INFO: epoch 001:   5377 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85, ups=0.79, wpb=107.9, bsz=40, num_updates=5370, lr=4.96645e-05, gnorm=0.712, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13043
2022-10-10 13:33:25 - progress_bar.py[line:274] - INFO: epoch 001:   5387 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85.9, ups=0.78, wpb=109.9, bsz=40, num_updates=5380, lr=4.966e-05, gnorm=0.589, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13055
2022-10-10 13:33:38 - progress_bar.py[line:274] - INFO: epoch 001:   5397 / 57820 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.4, ups=0.79, wpb=108.8, bsz=40, num_updates=5390, lr=4.96555e-05, gnorm=0.678, clip=0, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=13068
2022-10-10 13:33:51 - progress_bar.py[line:274] - INFO: epoch 001:   5407 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.4, ups=0.77, wpb=110.2, bsz=40, num_updates=5400, lr=4.96509e-05, gnorm=0.56, clip=0, loss_scale=512, train_wall=13, gb_free=11.1, ema_decay=0.9999, wall=13081
2022-10-10 13:34:03 - progress_bar.py[line:274] - INFO: epoch 001:   5417 / 57820 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.5, ups=0.79, wpb=110.1, bsz=40, num_updates=5410, lr=4.96464e-05, gnorm=0.595, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=13094
2022-10-10 13:34:16 - progress_bar.py[line:274] - INFO: epoch 001:   5427 / 57820 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=85.9, ups=0.78, wpb=110.5, bsz=40, num_updates=5420, lr=4.96419e-05, gnorm=0.522, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=13106
2022-10-10 13:34:29 - progress_bar.py[line:274] - INFO: epoch 001:   5437 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=84.5, ups=0.77, wpb=109.4, bsz=40, num_updates=5430, lr=4.96374e-05, gnorm=0.573, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=13119
2022-10-10 13:34:42 - progress_bar.py[line:274] - INFO: epoch 001:   5447 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.4, ups=0.78, wpb=110.3, bsz=40, num_updates=5440, lr=4.96329e-05, gnorm=0.697, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13132
2022-10-10 13:34:55 - progress_bar.py[line:274] - INFO: epoch 001:   5457 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=84.5, ups=0.78, wpb=108.9, bsz=40, num_updates=5450, lr=4.96284e-05, gnorm=0.638, clip=10, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=13145
2022-10-10 13:35:08 - progress_bar.py[line:274] - INFO: epoch 001:   5467 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.1, ups=0.77, wpb=111.2, bsz=40, num_updates=5460, lr=4.96239e-05, gnorm=0.593, clip=0, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=13158
2022-10-10 13:35:20 - progress_bar.py[line:274] - INFO: epoch 001:   5477 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.7, ups=0.82, wpb=109.6, bsz=40, num_updates=5470, lr=4.96194e-05, gnorm=0.675, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=13170
2022-10-10 13:35:32 - progress_bar.py[line:274] - INFO: epoch 001:   5487 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.6, ups=0.8, wpb=108.2, bsz=40, num_updates=5480, lr=4.96149e-05, gnorm=0.738, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=13183
2022-10-10 13:35:45 - progress_bar.py[line:274] - INFO: epoch 001:   5497 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.8, ups=0.8, wpb=109.3, bsz=40, num_updates=5490, lr=4.96104e-05, gnorm=0.621, clip=0, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=13195
2022-10-10 13:35:57 - progress_bar.py[line:274] - INFO: epoch 001:   5507 / 57820 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87, ups=0.8, wpb=108.3, bsz=40, num_updates=5500, lr=4.96059e-05, gnorm=0.611, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=13208
2022-10-10 13:36:09 - progress_bar.py[line:274] - INFO: epoch 001:   5517 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.9, ups=0.82, wpb=108.9, bsz=40, num_updates=5510, lr=4.96014e-05, gnorm=0.719, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=13220
2022-10-10 13:36:23 - progress_bar.py[line:274] - INFO: epoch 001:   5527 / 57820 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=84.4, ups=0.77, wpb=110, bsz=40, num_updates=5520, lr=4.95969e-05, gnorm=0.637, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13233
2022-10-10 13:36:35 - progress_bar.py[line:274] - INFO: epoch 001:   5537 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.7, ups=0.81, wpb=110.8, bsz=40, num_updates=5530, lr=4.95924e-05, gnorm=0.563, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=13245
2022-10-10 13:36:47 - progress_bar.py[line:274] - INFO: epoch 001:   5547 / 57820 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.9, ups=0.8, wpb=111, bsz=40, num_updates=5540, lr=4.95879e-05, gnorm=0.658, clip=0, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=13258
2022-10-10 13:37:00 - progress_bar.py[line:274] - INFO: epoch 001:   5557 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.6, ups=0.8, wpb=109.3, bsz=40, num_updates=5550, lr=4.95834e-05, gnorm=0.676, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=13270
2022-10-10 13:37:02 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 13:37:13 - progress_bar.py[line:274] - INFO: epoch 001:   5568 / 57820 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.12, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=81.6, ups=0.74, wpb=110.4, bsz=40, num_updates=5560, lr=4.95789e-05, gnorm=0.464, clip=0, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=13284
2022-10-10 13:37:26 - progress_bar.py[line:274] - INFO: epoch 001:   5578 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.1, ups=0.8, wpb=109.5, bsz=40, num_updates=5570, lr=4.95744e-05, gnorm=0.699, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=13296
2022-10-10 13:37:39 - progress_bar.py[line:274] - INFO: epoch 001:   5588 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=84.9, ups=0.78, wpb=108.7, bsz=40, num_updates=5580, lr=4.95699e-05, gnorm=0.679, clip=0, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=13309
2022-10-10 13:37:52 - progress_bar.py[line:274] - INFO: epoch 001:   5598 / 57820 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86, ups=0.78, wpb=110.7, bsz=40, num_updates=5590, lr=4.95654e-05, gnorm=0.668, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=13322
2022-10-10 13:38:04 - progress_bar.py[line:274] - INFO: epoch 001:   5608 / 57820 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.5, ups=0.79, wpb=109.7, bsz=40, num_updates=5600, lr=4.95609e-05, gnorm=0.646, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13335
2022-10-10 13:38:18 - progress_bar.py[line:274] - INFO: epoch 001:   5618 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=83.7, ups=0.76, wpb=110.5, bsz=40, num_updates=5610, lr=4.95564e-05, gnorm=0.549, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13348
2022-10-10 13:38:30 - progress_bar.py[line:274] - INFO: epoch 001:   5628 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=88, ups=0.8, wpb=110.6, bsz=40, num_updates=5620, lr=4.95519e-05, gnorm=0.615, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=13361
2022-10-10 13:38:43 - progress_bar.py[line:274] - INFO: epoch 001:   5638 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.7, ups=0.78, wpb=110.9, bsz=40, num_updates=5630, lr=4.95474e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13373
2022-10-10 13:38:56 - progress_bar.py[line:274] - INFO: epoch 001:   5648 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=82.1, ups=0.75, wpb=109.4, bsz=40, num_updates=5640, lr=4.95429e-05, gnorm=0.611, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13387
2022-10-10 13:39:09 - progress_bar.py[line:274] - INFO: epoch 001:   5658 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.8, ups=0.79, wpb=110.1, bsz=40, num_updates=5650, lr=4.95384e-05, gnorm=0.649, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13400
2022-10-10 13:39:22 - progress_bar.py[line:274] - INFO: epoch 001:   5668 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.9, ups=0.79, wpb=110.1, bsz=40, num_updates=5660, lr=4.95338e-05, gnorm=0.561, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=13412
2022-10-10 13:39:35 - progress_bar.py[line:274] - INFO: epoch 001:   5678 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=83.7, ups=0.76, wpb=109.7, bsz=40, num_updates=5670, lr=4.95293e-05, gnorm=0.681, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13425
2022-10-10 13:39:48 - progress_bar.py[line:274] - INFO: epoch 001:   5688 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=83.5, ups=0.76, wpb=110.5, bsz=40, num_updates=5680, lr=4.95248e-05, gnorm=0.633, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=13439
2022-10-10 13:40:01 - progress_bar.py[line:274] - INFO: epoch 001:   5698 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.7, ups=0.8, wpb=110.2, bsz=40, num_updates=5690, lr=4.95203e-05, gnorm=0.714, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=13451
2022-10-10 13:40:14 - progress_bar.py[line:274] - INFO: epoch 001:   5708 / 57820 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=82.3, ups=0.76, wpb=108.9, bsz=40, num_updates=5700, lr=4.95158e-05, gnorm=0.734, clip=20, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=13464
2022-10-10 13:40:27 - progress_bar.py[line:274] - INFO: epoch 001:   5718 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=84.6, ups=0.78, wpb=109.1, bsz=40, num_updates=5710, lr=4.95113e-05, gnorm=0.575, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13477
2022-10-10 13:40:40 - progress_bar.py[line:274] - INFO: epoch 001:   5728 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=84.1, ups=0.77, wpb=109.8, bsz=40, num_updates=5720, lr=4.95068e-05, gnorm=0.679, clip=0, loss_scale=512, train_wall=13, gb_free=11.1, ema_decay=0.9999, wall=13491
2022-10-10 13:40:53 - progress_bar.py[line:274] - INFO: epoch 001:   5738 / 57820 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.8, ups=0.79, wpb=109.5, bsz=40, num_updates=5730, lr=4.95023e-05, gnorm=0.621, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=13503
2022-10-10 13:41:06 - progress_bar.py[line:274] - INFO: epoch 001:   5748 / 57820 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=84.9, ups=0.78, wpb=109.5, bsz=40, num_updates=5740, lr=4.94978e-05, gnorm=0.616, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13516
2022-10-10 13:41:18 - progress_bar.py[line:274] - INFO: epoch 001:   5758 / 57820 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.2, ups=0.81, wpb=108, bsz=40, num_updates=5750, lr=4.94933e-05, gnorm=0.498, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=13528
2022-10-10 13:41:31 - progress_bar.py[line:274] - INFO: epoch 001:   5768 / 57820 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=83.6, ups=0.77, wpb=109.1, bsz=40, num_updates=5760, lr=4.94888e-05, gnorm=0.687, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13541
2022-10-10 13:41:43 - progress_bar.py[line:274] - INFO: epoch 001:   5778 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=88.7, ups=0.81, wpb=109.4, bsz=40, num_updates=5770, lr=4.94843e-05, gnorm=0.529, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=13554
2022-10-10 13:41:56 - progress_bar.py[line:274] - INFO: epoch 001:   5788 / 57820 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=84.7, ups=0.78, wpb=109, bsz=40, num_updates=5780, lr=4.94798e-05, gnorm=0.786, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13567
2022-10-10 13:42:09 - progress_bar.py[line:274] - INFO: epoch 001:   5798 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86, ups=0.77, wpb=111.5, bsz=40, num_updates=5790, lr=4.94753e-05, gnorm=0.685, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13580
2022-10-10 13:42:23 - progress_bar.py[line:274] - INFO: epoch 001:   5808 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=82.3, ups=0.75, wpb=109.7, bsz=40, num_updates=5800, lr=4.94708e-05, gnorm=0.534, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13593
2022-10-10 13:42:36 - progress_bar.py[line:274] - INFO: epoch 001:   5818 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=81.9, ups=0.73, wpb=111.9, bsz=40, num_updates=5810, lr=4.94663e-05, gnorm=0.543, clip=0, loss_scale=512, train_wall=14, gb_free=10.8, ema_decay=0.9999, wall=13607
2022-10-10 13:42:49 - progress_bar.py[line:274] - INFO: epoch 001:   5828 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.6, ups=0.8, wpb=110.2, bsz=40, num_updates=5820, lr=4.94618e-05, gnorm=0.569, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=13619
2022-10-10 13:43:01 - progress_bar.py[line:274] - INFO: epoch 001:   5838 / 57820 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.9, ups=0.8, wpb=111.3, bsz=40, num_updates=5830, lr=4.94573e-05, gnorm=0.553, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=13632
2022-10-10 13:43:14 - progress_bar.py[line:274] - INFO: epoch 001:   5848 / 57820 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85.1, ups=0.78, wpb=109.5, bsz=40, num_updates=5840, lr=4.94528e-05, gnorm=0.576, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13645
2022-10-10 13:43:27 - progress_bar.py[line:274] - INFO: epoch 001:   5858 / 57820 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=89.1, ups=0.8, wpb=111.4, bsz=40, num_updates=5850, lr=4.94483e-05, gnorm=0.517, clip=0, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=13657
2022-10-10 13:43:40 - progress_bar.py[line:274] - INFO: epoch 001:   5868 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=83.4, ups=0.77, wpb=108.6, bsz=40, num_updates=5860, lr=4.94438e-05, gnorm=0.607, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=13670
2022-10-10 13:43:54 - progress_bar.py[line:274] - INFO: epoch 001:   5878 / 57820 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=80.1, ups=0.73, wpb=110, bsz=40, num_updates=5870, lr=4.94393e-05, gnorm=0.553, clip=0, loss_scale=512, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=13684
2022-10-10 13:44:06 - progress_bar.py[line:274] - INFO: epoch 001:   5888 / 57820 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.121, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=86.4, ups=0.78, wpb=110.5, bsz=40, num_updates=5880, lr=4.94348e-05, gnorm=0.539, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=13697
2022-10-10 13:44:19 - progress_bar.py[line:274] - INFO: epoch 001:   5898 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.8, ups=0.79, wpb=109.8, bsz=40, num_updates=5890, lr=4.94303e-05, gnorm=0.472, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=13709
2022-10-10 13:44:32 - progress_bar.py[line:274] - INFO: epoch 001:   5908 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=82.5, ups=0.75, wpb=110.7, bsz=40, num_updates=5900, lr=4.94258e-05, gnorm=0.655, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=13723
2022-10-10 13:44:45 - progress_bar.py[line:274] - INFO: epoch 001:   5918 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85.1, ups=0.78, wpb=108.9, bsz=40, num_updates=5910, lr=4.94212e-05, gnorm=0.726, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13736
2022-10-10 13:44:58 - progress_bar.py[line:274] - INFO: epoch 001:   5928 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=84.1, ups=0.76, wpb=110, bsz=40, num_updates=5920, lr=4.94167e-05, gnorm=0.628, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=13749
2022-10-10 13:45:11 - progress_bar.py[line:274] - INFO: epoch 001:   5938 / 57820 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87, ups=0.79, wpb=109.5, bsz=40, num_updates=5930, lr=4.94122e-05, gnorm=0.77, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=13761
2022-10-10 13:45:24 - progress_bar.py[line:274] - INFO: epoch 001:   5948 / 57820 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=81.7, ups=0.75, wpb=108.9, bsz=40, num_updates=5940, lr=4.94077e-05, gnorm=0.721, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=13775
2022-10-10 13:45:37 - progress_bar.py[line:274] - INFO: epoch 001:   5958 / 57820 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=83.9, ups=0.77, wpb=109.5, bsz=40, num_updates=5950, lr=4.94032e-05, gnorm=0.781, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13788
2022-10-10 13:45:50 - progress_bar.py[line:274] - INFO: epoch 001:   5968 / 57820 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=83.8, ups=0.78, wpb=107.8, bsz=40, num_updates=5960, lr=4.93987e-05, gnorm=0.632, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13801
2022-10-10 13:46:04 - progress_bar.py[line:274] - INFO: epoch 001:   5978 / 57820 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=81.9, ups=0.75, wpb=108.8, bsz=40, num_updates=5970, lr=4.93942e-05, gnorm=0.733, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13814
2022-10-10 13:46:16 - progress_bar.py[line:274] - INFO: epoch 001:   5988 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.4, ups=0.79, wpb=108.3, bsz=40, num_updates=5980, lr=4.93897e-05, gnorm=0.555, clip=0, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=13827
2022-10-10 13:46:29 - progress_bar.py[line:274] - INFO: epoch 001:   5998 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=83.4, ups=0.77, wpb=109, bsz=40, num_updates=5990, lr=4.93852e-05, gnorm=0.53, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13840
2022-10-10 13:46:42 - progress_bar.py[line:274] - INFO: epoch 001:   6008 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.6, ups=0.79, wpb=110.4, bsz=40, num_updates=6000, lr=4.93807e-05, gnorm=0.512, clip=0, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=13852
2022-10-10 13:46:42 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-10 13:46:44 - train.py[line:549] - INFO: 0 / 4988
2022-10-10 13:46:44 - train.py[line:551] - INFO: load:1.62 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-10 13:46:45 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.86 GiB already allocated; 5.67 GiB free; 31.43 GiB reserved in total by PyTorch)
2022-10-10 13:46:45 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-10 13:46:45 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 9         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9071 MB |   10296 MB |    1561 TB |    1561 TB |
|       from large pool |    8926 MB |   10150 MB |    1561 TB |    1561 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9071 MB |   10296 MB |    1561 TB |    1561 TB |
|       from large pool |    8926 MB |   10150 MB |    1561 TB |    1561 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32186 MB |   35580 MB |  132954 MB |  100768 MB |
|       from large pool |   32040 MB |   35428 MB |  132668 MB |  100628 MB |
|       from small pool |     146 MB |     152 MB |     286 MB |     140 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   23114 MB |   23114 MB |    1608 TB |    1608 TB |
|       from large pool |   23113 MB |   23113 MB |    1608 TB |    1608 TB |
|       from small pool |       1 MB |       2 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |   59774 K  |   59770 K  |
|       from large pool |     563    |     575    |   24089 K  |   24088 K  |
|       from small pool |    3095    |    3114    |   35684 K  |   35681 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |   59774 K  |   59770 K  |
|       from large pool |     563    |     575    |   24089 K  |   24088 K  |
|       from small pool |    3095    |    3114    |   35684 K  |   35681 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     199    |     213    |     499    |     300    |
|       from large pool |     126    |     137    |     356    |     230    |
|       from small pool |      73    |      76    |     143    |      70    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     140    |     146    |   36869 K  |   36869 K  |
|       from large pool |      95    |      98    |   10761 K  |   10761 K  |
|       from small pool |      45    |      53    |   26108 K  |   26108 K  |
|===========================================================================|

2022-10-10 13:46:45 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-10 13:47:08 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.28 GiB (GPU 0; 39.59 GiB total capacity; 8.94 GiB already allocated; 6.27 GiB free; 30.84 GiB reserved in total by PyTorch)
2022-10-10 13:47:08 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 9         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9157 MB |   15474 MB |    1562 TB |    1562 TB |
|       from large pool |    9012 MB |   15329 MB |    1561 TB |    1561 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9157 MB |   15474 MB |    1562 TB |    1562 TB |
|       from large pool |    9012 MB |   15329 MB |    1561 TB |    1561 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   31578 MB |   37940 MB |  131336 MB |   99758 MB |
|       from large pool |   31432 MB |   37792 MB |  131050 MB |   99618 MB |
|       from small pool |     146 MB |     152 MB |     286 MB |     140 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22420 MB |   26894 MB |    1660 TB |    1660 TB |
|       from large pool |   22419 MB |   26892 MB |    1659 TB |    1659 TB |
|       from small pool |       1 MB |       2 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |   59898 K  |   59895 K  |
|       from large pool |     563    |     575    |   24124 K  |   24123 K  |
|       from small pool |    3106    |    3116    |   35774 K  |   35771 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |   59898 K  |   59895 K  |
|       from large pool |     563    |     575    |   24124 K  |   24123 K  |
|       from small pool |    3106    |    3116    |   35774 K  |   35771 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     200    |     208    |     463    |     263    |
|       from large pool |     127    |     132    |     320    |     193    |
|       from small pool |      73    |      76    |     143    |      70    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     147    |     154    |   36693 K  |   36693 K  |
|       from large pool |     105    |     109    |   10365 K  |   10365 K  |
|       from small pool |      42    |      51    |   26328 K  |   26328 K  |
|===========================================================================|

2022-10-10 13:47:08 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-10 13:47:08 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-10 13:49:54 - train.py[line:549] - INFO: 200 / 4988
2022-10-10 13:49:54 - train.py[line:551] - INFO: load:1.67 valid_run:189.76 task_valid:177.42 collect_output:8.07
2022-10-10 13:52:57 - train.py[line:549] - INFO: 400 / 4988
2022-10-10 13:52:57 - train.py[line:551] - INFO: load:1.78 valid_run:372.09 task_valid:346.10 collect_output:19.24
2022-10-10 13:55:57 - train.py[line:549] - INFO: 600 / 4988
2022-10-10 13:55:57 - train.py[line:551] - INFO: load:1.82 valid_run:552.92 task_valid:513.00 collect_output:31.02
2022-10-10 13:59:00 - train.py[line:549] - INFO: 800 / 4988
2022-10-10 13:59:00 - train.py[line:551] - INFO: load:1.85 valid_run:734.98 task_valid:681.69 collect_output:41.86
2022-10-10 14:02:01 - train.py[line:549] - INFO: 1000 / 4988
2022-10-10 14:02:02 - train.py[line:551] - INFO: load:1.93 valid_run:916.73 task_valid:851.15 collect_output:51.84
2022-10-10 14:05:03 - train.py[line:549] - INFO: 1200 / 4988
2022-10-10 14:05:03 - train.py[line:551] - INFO: load:2.02 valid_run:1098.35 task_valid:1018.98 collect_output:63.47
2022-10-10 14:08:02 - train.py[line:549] - INFO: 1400 / 4988
2022-10-10 14:08:02 - train.py[line:551] - INFO: load:2.08 valid_run:1276.55 task_valid:1184.74 collect_output:73.96
2022-10-10 14:10:56 - train.py[line:549] - INFO: 1600 / 4988
2022-10-10 14:10:56 - train.py[line:551] - INFO: load:2.15 valid_run:1450.68 task_valid:1345.34 collect_output:85.13
2022-10-10 14:13:51 - train.py[line:549] - INFO: 1800 / 4988
2022-10-10 14:13:51 - train.py[line:551] - INFO: load:2.23 valid_run:1625.87 task_valid:1510.13 collect_output:93.06
2022-10-10 14:16:47 - train.py[line:549] - INFO: 2000 / 4988
2022-10-10 14:16:47 - train.py[line:551] - INFO: load:2.29 valid_run:1802.02 task_valid:1677.14 collect_output:100.04
2022-10-10 14:19:42 - train.py[line:549] - INFO: 2200 / 4988
2022-10-10 14:19:42 - train.py[line:551] - INFO: load:2.37 valid_run:1976.22 task_valid:1840.49 collect_output:108.91
2022-10-10 14:22:37 - train.py[line:549] - INFO: 2400 / 4988
2022-10-10 14:22:37 - train.py[line:551] - INFO: load:2.44 valid_run:2151.26 task_valid:2004.59 collect_output:117.62
2022-10-10 14:25:31 - train.py[line:549] - INFO: 2600 / 4988
2022-10-10 14:25:31 - train.py[line:551] - INFO: load:2.53 valid_run:2325.64 task_valid:2163.97 collect_output:130.54
2022-10-10 14:28:23 - train.py[line:549] - INFO: 2800 / 4988
2022-10-10 14:28:23 - train.py[line:551] - INFO: load:2.57 valid_run:2497.58 task_valid:2325.69 collect_output:138.58
2022-10-10 14:31:17 - train.py[line:549] - INFO: 3000 / 4988
2022-10-10 14:31:17 - train.py[line:551] - INFO: load:2.65 valid_run:2670.58 task_valid:2488.98 collect_output:146.20
2022-10-10 14:34:10 - train.py[line:549] - INFO: 3200 / 4988
2022-10-10 14:34:10 - train.py[line:551] - INFO: load:2.72 valid_run:2844.19 task_valid:2653.07 collect_output:153.68
2022-10-10 14:37:07 - train.py[line:549] - INFO: 3400 / 4988
2022-10-10 14:37:07 - train.py[line:551] - INFO: load:2.77 valid_run:3020.44 task_valid:2817.67 collect_output:163.30
2022-10-10 14:40:03 - train.py[line:549] - INFO: 3600 / 4988
2022-10-10 14:40:03 - train.py[line:551] - INFO: load:2.83 valid_run:3196.20 task_valid:2985.86 collect_output:169.15
2022-10-10 14:42:57 - train.py[line:549] - INFO: 3800 / 4988
2022-10-10 14:42:57 - train.py[line:551] - INFO: load:2.86 valid_run:3370.34 task_valid:3147.26 collect_output:179.88
2022-10-10 14:45:50 - train.py[line:549] - INFO: 4000 / 4988
2022-10-10 14:45:50 - train.py[line:551] - INFO: load:2.89 valid_run:3543.43 task_valid:3310.67 collect_output:187.73
2022-10-10 14:48:48 - train.py[line:549] - INFO: 4200 / 4988
2022-10-10 14:48:48 - train.py[line:551] - INFO: load:2.96 valid_run:3721.19 task_valid:3476.69 collect_output:197.28
2022-10-10 14:51:40 - train.py[line:549] - INFO: 4400 / 4988
2022-10-10 14:51:40 - train.py[line:551] - INFO: load:3.04 valid_run:3893.17 task_valid:3640.38 collect_output:203.74
2022-10-10 14:54:33 - train.py[line:549] - INFO: 4600 / 4988
2022-10-10 14:54:33 - train.py[line:551] - INFO: load:3.08 valid_run:4066.12 task_valid:3804.26 collect_output:210.97
2022-10-10 14:57:29 - train.py[line:549] - INFO: 4800 / 4988
2022-10-10 14:57:29 - train.py[line:551] - INFO: load:3.15 valid_run:4242.16 task_valid:3970.75 collect_output:218.64

====================================================================================================
SGG eval:     R @ 50: 0.6554;     R @ 100: 0.6829;     R @ 500: 0.7049;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4417;    mR @ 100: 0.4701;    mR @ 500: 0.5249;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8659) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.3750) (hanging from:0.4355) (lying on:0.3000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9451) (says:0.0000) (sitting on:0.7409) (standing on:0.3493) (using:0.6000) (walking in:0.0000) (walking on:0.7568) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-10 15:00:24 - train.py[line:487] - INFO: 0.682929131652661
2022-10-10 15:00:24 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-10 15:00:24 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.34 | loss_v1 0 | loss_v2 0 | nll_loss 0.184 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.682929 | ppl 1.14 | vqa_score 0.5991 | wps 101.5 | wpb 89.9 | bsz 30 | num_updates 6000 | best_R@100 0.701471
2022-10-10 15:00:24 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2022-10-10 15:00:24 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480/checkpoint_1_6000.pt

====================================================================================================
SGG eval:     R @ 50: 0.6554;     R @ 100: 0.6829;     R @ 500: 0.7049;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4417;    mR @ 100: 0.4701;    mR @ 500: 0.5249;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8659) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.3750) (hanging from:0.4355) (lying on:0.3000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9451) (says:0.0000) (sitting on:0.7409) (standing on:0.3493) (using:0.6000) (walking in:0.0000) (walking on:0.7568) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-10 15:00:31 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-10 15:00:35 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.682929131652661) (writing took 10.474410207010806 seconds)
2022-10-10 15:00:47 - progress_bar.py[line:274] - INFO: epoch 001:   6018 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=0.2, ups=0, wpb=109.3, bsz=40, num_updates=6010, lr=4.93762e-05, gnorm=0.568, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=18298
2022-10-10 15:01:00 - progress_bar.py[line:274] - INFO: epoch 001:   6028 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.3, ups=0.8, wpb=108.6, bsz=40, num_updates=6020, lr=4.93717e-05, gnorm=0.62, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18310
2022-10-10 15:01:13 - progress_bar.py[line:274] - INFO: epoch 001:   6038 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.8, ups=0.79, wpb=110.5, bsz=40, num_updates=6030, lr=4.93672e-05, gnorm=0.648, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18323
2022-10-10 15:01:25 - progress_bar.py[line:274] - INFO: epoch 001:   6048 / 57820 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87, ups=0.79, wpb=109.7, bsz=40, num_updates=6040, lr=4.93627e-05, gnorm=0.566, clip=0, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=18336
2022-10-10 15:01:37 - progress_bar.py[line:274] - INFO: epoch 001:   6058 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=90.4, ups=0.82, wpb=110.2, bsz=40, num_updates=6050, lr=4.93582e-05, gnorm=0.691, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18348
2022-10-10 15:01:50 - progress_bar.py[line:274] - INFO: epoch 001:   6068 / 57820 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.6, ups=0.8, wpb=109.8, bsz=40, num_updates=6060, lr=4.93537e-05, gnorm=0.616, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18360
2022-10-10 15:01:57 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 15:02:04 - progress_bar.py[line:274] - INFO: epoch 001:   6079 / 57820 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=81.7, ups=0.74, wpb=110.1, bsz=40, num_updates=6070, lr=4.93492e-05, gnorm=0.548, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=18374
2022-10-10 15:02:16 - progress_bar.py[line:274] - INFO: epoch 001:   6089 / 57820 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=88.7, ups=0.81, wpb=109.1, bsz=40, num_updates=6080, lr=4.93447e-05, gnorm=0.584, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18386
2022-10-10 15:02:29 - progress_bar.py[line:274] - INFO: epoch 001:   6099 / 57820 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=84, ups=0.77, wpb=109.4, bsz=40, num_updates=6090, lr=4.93402e-05, gnorm=0.538, clip=0, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=18399
2022-10-10 15:02:41 - progress_bar.py[line:274] - INFO: epoch 001:   6109 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.7, ups=0.8, wpb=109.8, bsz=40, num_updates=6100, lr=4.93357e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18412
2022-10-10 15:02:54 - progress_bar.py[line:274] - INFO: epoch 001:   6119 / 57820 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.5, ups=0.8, wpb=107.3, bsz=40, num_updates=6110, lr=4.93312e-05, gnorm=0.587, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18424
2022-10-10 15:03:06 - progress_bar.py[line:274] - INFO: epoch 001:   6129 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.9, ups=0.81, wpb=111, bsz=40, num_updates=6120, lr=4.93267e-05, gnorm=0.633, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18437
2022-10-10 15:03:19 - progress_bar.py[line:274] - INFO: epoch 001:   6139 / 57820 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=90.7, ups=0.82, wpb=110.6, bsz=40, num_updates=6130, lr=4.93222e-05, gnorm=0.775, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18449
2022-10-10 15:03:32 - progress_bar.py[line:274] - INFO: epoch 001:   6149 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.7, ups=0.8, wpb=110.5, bsz=40, num_updates=6140, lr=4.93177e-05, gnorm=0.654, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18461
2022-10-10 15:03:44 - progress_bar.py[line:274] - INFO: epoch 001:   6159 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.2, ups=0.79, wpb=110.9, bsz=40, num_updates=6150, lr=4.93132e-05, gnorm=0.713, clip=10, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=18475
2022-10-10 15:03:57 - progress_bar.py[line:274] - INFO: epoch 001:   6169 / 57820 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=89.4, ups=0.82, wpb=109.4, bsz=40, num_updates=6160, lr=4.93087e-05, gnorm=0.658, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18487
2022-10-10 15:04:09 - progress_bar.py[line:274] - INFO: epoch 001:   6179 / 57820 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.2, ups=0.8, wpb=108.6, bsz=40, num_updates=6170, lr=4.93041e-05, gnorm=0.609, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=18499
2022-10-10 15:04:21 - progress_bar.py[line:274] - INFO: epoch 001:   6189 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.8, ups=0.8, wpb=109.4, bsz=40, num_updates=6180, lr=4.92996e-05, gnorm=0.554, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18512
2022-10-10 15:04:34 - progress_bar.py[line:274] - INFO: epoch 001:   6199 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.1, ups=0.79, wpb=110.8, bsz=40, num_updates=6190, lr=4.92951e-05, gnorm=0.665, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18524
2022-10-10 15:04:47 - progress_bar.py[line:274] - INFO: epoch 001:   6209 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.7, ups=0.79, wpb=109.1, bsz=40, num_updates=6200, lr=4.92906e-05, gnorm=0.57, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18537
2022-10-10 15:04:59 - progress_bar.py[line:274] - INFO: epoch 001:   6219 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.7, ups=0.82, wpb=107.2, bsz=40, num_updates=6210, lr=4.92861e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=18549
2022-10-10 15:05:11 - progress_bar.py[line:274] - INFO: epoch 001:   6229 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.9, ups=0.82, wpb=109.6, bsz=40, num_updates=6220, lr=4.92816e-05, gnorm=0.601, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18562
2022-10-10 15:05:24 - progress_bar.py[line:274] - INFO: epoch 001:   6239 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.9, ups=0.8, wpb=108.1, bsz=40, num_updates=6230, lr=4.92771e-05, gnorm=0.653, clip=10, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=18574
2022-10-10 15:05:36 - progress_bar.py[line:274] - INFO: epoch 001:   6249 / 57820 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.3, ups=0.81, wpb=109.2, bsz=40, num_updates=6240, lr=4.92726e-05, gnorm=0.69, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18586
2022-10-10 15:05:48 - progress_bar.py[line:274] - INFO: epoch 001:   6259 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.6, ups=0.8, wpb=108.5, bsz=40, num_updates=6250, lr=4.92681e-05, gnorm=0.679, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18599
2022-10-10 15:06:01 - progress_bar.py[line:274] - INFO: epoch 001:   6269 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=83.6, ups=0.77, wpb=109, bsz=40, num_updates=6260, lr=4.92636e-05, gnorm=0.611, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=18612
2022-10-10 15:06:14 - progress_bar.py[line:274] - INFO: epoch 001:   6279 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.2, ups=0.8, wpb=109, bsz=40, num_updates=6270, lr=4.92591e-05, gnorm=0.689, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18624
2022-10-10 15:06:26 - progress_bar.py[line:274] - INFO: epoch 001:   6289 / 57820 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=92.7, ups=0.84, wpb=110.1, bsz=40, num_updates=6280, lr=4.92546e-05, gnorm=0.481, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18636
2022-10-10 15:06:38 - progress_bar.py[line:274] - INFO: epoch 001:   6299 / 57820 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.2, ups=0.8, wpb=110.9, bsz=40, num_updates=6290, lr=4.92501e-05, gnorm=0.586, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18649
2022-10-10 15:06:51 - progress_bar.py[line:274] - INFO: epoch 001:   6309 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=90, ups=0.81, wpb=110.7, bsz=40, num_updates=6300, lr=4.92456e-05, gnorm=0.659, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18661
2022-10-10 15:07:03 - progress_bar.py[line:274] - INFO: epoch 001:   6319 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.3, ups=0.8, wpb=109.8, bsz=40, num_updates=6310, lr=4.92411e-05, gnorm=0.639, clip=10, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=18674
2022-10-10 15:07:16 - progress_bar.py[line:274] - INFO: epoch 001:   6329 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.5, ups=0.81, wpb=109.5, bsz=40, num_updates=6320, lr=4.92366e-05, gnorm=0.688, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18686
2022-10-10 15:07:28 - progress_bar.py[line:274] - INFO: epoch 001:   6339 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90.8, ups=0.82, wpb=110.3, bsz=40, num_updates=6330, lr=4.92321e-05, gnorm=0.624, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18698
2022-10-10 15:07:41 - progress_bar.py[line:274] - INFO: epoch 001:   6349 / 57820 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=85.1, ups=0.77, wpb=110.2, bsz=40, num_updates=6340, lr=4.92276e-05, gnorm=0.777, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18711
2022-10-10 15:07:53 - progress_bar.py[line:274] - INFO: epoch 001:   6359 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88, ups=0.8, wpb=109.7, bsz=40, num_updates=6350, lr=4.92231e-05, gnorm=0.616, clip=10, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=18724
2022-10-10 15:08:06 - progress_bar.py[line:274] - INFO: epoch 001:   6369 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.1, ups=0.81, wpb=109.1, bsz=40, num_updates=6360, lr=4.92186e-05, gnorm=0.662, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=18736
2022-10-10 15:08:18 - progress_bar.py[line:274] - INFO: epoch 001:   6379 / 57820 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=89.2, ups=0.81, wpb=110.4, bsz=40, num_updates=6370, lr=4.92141e-05, gnorm=0.53, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18749
2022-10-10 15:08:31 - progress_bar.py[line:274] - INFO: epoch 001:   6389 / 57820 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=86.9, ups=0.79, wpb=109.9, bsz=40, num_updates=6380, lr=4.92096e-05, gnorm=0.581, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18761
2022-10-10 15:08:44 - progress_bar.py[line:274] - INFO: epoch 001:   6399 / 57820 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.1, ups=0.78, wpb=109.2, bsz=40, num_updates=6390, lr=4.92051e-05, gnorm=0.588, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18774
2022-10-10 15:08:57 - progress_bar.py[line:274] - INFO: epoch 001:   6409 / 57820 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=84.8, ups=0.77, wpb=109.9, bsz=40, num_updates=6400, lr=4.92006e-05, gnorm=0.693, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18787
2022-10-10 15:09:09 - progress_bar.py[line:274] - INFO: epoch 001:   6419 / 57820 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90.2, ups=0.81, wpb=111.4, bsz=40, num_updates=6410, lr=4.91961e-05, gnorm=0.493, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18800
2022-10-10 15:09:22 - progress_bar.py[line:274] - INFO: epoch 001:   6429 / 57820 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=85.1, ups=0.79, wpb=107.5, bsz=40, num_updates=6420, lr=4.91916e-05, gnorm=0.659, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18812
2022-10-10 15:09:34 - progress_bar.py[line:274] - INFO: epoch 001:   6439 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.4, ups=0.8, wpb=109.9, bsz=40, num_updates=6430, lr=4.9187e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=18825
2022-10-10 15:09:47 - progress_bar.py[line:274] - INFO: epoch 001:   6449 / 57820 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=86.5, ups=0.78, wpb=111.4, bsz=40, num_updates=6440, lr=4.91825e-05, gnorm=0.534, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=18838
2022-10-10 15:10:00 - progress_bar.py[line:274] - INFO: epoch 001:   6459 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=83.9, ups=0.78, wpb=108.2, bsz=40, num_updates=6450, lr=4.9178e-05, gnorm=0.516, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18851
2022-10-10 15:10:13 - progress_bar.py[line:274] - INFO: epoch 001:   6469 / 57820 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.7, ups=0.79, wpb=109.4, bsz=40, num_updates=6460, lr=4.91735e-05, gnorm=0.522, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=18863
2022-10-10 15:10:26 - progress_bar.py[line:274] - INFO: epoch 001:   6479 / 57820 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=84.4, ups=0.78, wpb=108.4, bsz=40, num_updates=6470, lr=4.9169e-05, gnorm=0.494, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=18876
2022-10-10 15:10:38 - progress_bar.py[line:274] - INFO: epoch 001:   6489 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.5, ups=0.81, wpb=108.3, bsz=40, num_updates=6480, lr=4.91645e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18889
2022-10-10 15:10:51 - progress_bar.py[line:274] - INFO: epoch 001:   6499 / 57820 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=85.2, ups=0.78, wpb=109, bsz=40, num_updates=6490, lr=4.916e-05, gnorm=0.531, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18901
2022-10-10 15:11:04 - progress_bar.py[line:274] - INFO: epoch 001:   6509 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.9, ups=0.78, wpb=111, bsz=40, num_updates=6500, lr=4.91555e-05, gnorm=0.614, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18914
2022-10-10 15:11:16 - progress_bar.py[line:274] - INFO: epoch 001:   6519 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.8, ups=0.81, wpb=109.6, bsz=40, num_updates=6510, lr=4.9151e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18926
2022-10-10 15:11:29 - progress_bar.py[line:274] - INFO: epoch 001:   6529 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.4, ups=0.79, wpb=108.8, bsz=40, num_updates=6520, lr=4.91465e-05, gnorm=0.71, clip=10, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=18939
2022-10-10 15:11:43 - progress_bar.py[line:274] - INFO: epoch 001:   6539 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=77, ups=0.71, wpb=108.9, bsz=40, num_updates=6530, lr=4.9142e-05, gnorm=0.706, clip=0, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=18953
2022-10-10 15:11:56 - progress_bar.py[line:274] - INFO: epoch 001:   6549 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.2, ups=0.79, wpb=109.3, bsz=40, num_updates=6540, lr=4.91375e-05, gnorm=0.613, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18966
2022-10-10 15:12:09 - progress_bar.py[line:274] - INFO: epoch 001:   6559 / 57820 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=86.1, ups=0.78, wpb=110.5, bsz=40, num_updates=6550, lr=4.9133e-05, gnorm=0.543, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18979
2022-10-10 15:12:21 - progress_bar.py[line:274] - INFO: epoch 001:   6569 / 57820 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=85.5, ups=0.78, wpb=110.3, bsz=40, num_updates=6560, lr=4.91285e-05, gnorm=0.615, clip=0, loss_scale=512, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=18992
2022-10-10 15:12:34 - progress_bar.py[line:274] - INFO: epoch 001:   6579 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=91.3, ups=0.82, wpb=111.5, bsz=40, num_updates=6570, lr=4.9124e-05, gnorm=0.644, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=19004
2022-10-10 15:12:47 - progress_bar.py[line:274] - INFO: epoch 001:   6589 / 57820 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=80.9, ups=0.75, wpb=107.8, bsz=40, num_updates=6580, lr=4.91195e-05, gnorm=0.598, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19017
2022-10-10 15:13:00 - progress_bar.py[line:274] - INFO: epoch 001:   6599 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=86.1, ups=0.78, wpb=109.8, bsz=40, num_updates=6590, lr=4.9115e-05, gnorm=0.495, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19030
2022-10-10 15:13:12 - progress_bar.py[line:274] - INFO: epoch 001:   6609 / 57820 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.7, ups=0.8, wpb=109.2, bsz=40, num_updates=6600, lr=4.91105e-05, gnorm=0.68, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19043
2022-10-10 15:13:26 - progress_bar.py[line:274] - INFO: epoch 001:   6619 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.4, ups=0.78, wpb=108.8, bsz=40, num_updates=6610, lr=4.9106e-05, gnorm=0.559, clip=0, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=19055
2022-10-10 15:13:38 - progress_bar.py[line:274] - INFO: epoch 001:   6629 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.6, ups=0.8, wpb=109, bsz=40, num_updates=6620, lr=4.91015e-05, gnorm=0.593, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19068
2022-10-10 15:13:51 - progress_bar.py[line:274] - INFO: epoch 001:   6639 / 57820 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=83.9, ups=0.78, wpb=108.3, bsz=40, num_updates=6630, lr=4.9097e-05, gnorm=0.545, clip=10, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=19081
2022-10-10 15:13:58 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 15:14:04 - progress_bar.py[line:274] - INFO: epoch 001:   6650 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=84.6, ups=0.77, wpb=109.8, bsz=40, num_updates=6640, lr=4.90925e-05, gnorm=0.635, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19094
2022-10-10 15:14:16 - progress_bar.py[line:274] - INFO: epoch 001:   6660 / 57820 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.9, ups=0.81, wpb=108, bsz=40, num_updates=6650, lr=4.9088e-05, gnorm=0.619, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19107
2022-10-10 15:14:29 - progress_bar.py[line:274] - INFO: epoch 001:   6670 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88, ups=0.8, wpb=109.9, bsz=40, num_updates=6660, lr=4.90835e-05, gnorm=0.67, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19119
2022-10-10 15:14:41 - progress_bar.py[line:274] - INFO: epoch 001:   6680 / 57820 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.6, ups=0.8, wpb=110.6, bsz=40, num_updates=6670, lr=4.9079e-05, gnorm=0.526, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19132
2022-10-10 15:14:54 - progress_bar.py[line:274] - INFO: epoch 001:   6690 / 57820 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=84.6, ups=0.77, wpb=109.6, bsz=40, num_updates=6680, lr=4.90744e-05, gnorm=0.542, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=19145
2022-10-10 15:15:07 - progress_bar.py[line:274] - INFO: epoch 001:   6700 / 57820 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.8, ups=0.8, wpb=110.8, bsz=40, num_updates=6690, lr=4.90699e-05, gnorm=0.479, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19157
2022-10-10 15:15:20 - progress_bar.py[line:274] - INFO: epoch 001:   6710 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=84.6, ups=0.77, wpb=109.4, bsz=40, num_updates=6700, lr=4.90654e-05, gnorm=0.593, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19170
2022-10-10 15:15:33 - progress_bar.py[line:274] - INFO: epoch 001:   6720 / 57820 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.6, ups=0.81, wpb=109.9, bsz=40, num_updates=6710, lr=4.90609e-05, gnorm=0.534, clip=0, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=19183
2022-10-10 15:15:46 - progress_bar.py[line:274] - INFO: epoch 001:   6730 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=84.9, ups=0.77, wpb=110.5, bsz=40, num_updates=6720, lr=4.90564e-05, gnorm=0.637, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19196
2022-10-10 15:15:58 - progress_bar.py[line:274] - INFO: epoch 001:   6740 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90.1, ups=0.82, wpb=110.4, bsz=40, num_updates=6730, lr=4.90519e-05, gnorm=0.567, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=19208
2022-10-10 15:16:10 - progress_bar.py[line:274] - INFO: epoch 001:   6750 / 57820 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=88.1, ups=0.8, wpb=109.5, bsz=40, num_updates=6740, lr=4.90474e-05, gnorm=0.615, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19221
2022-10-10 15:16:23 - progress_bar.py[line:274] - INFO: epoch 001:   6760 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.1, ups=0.8, wpb=109.6, bsz=40, num_updates=6750, lr=4.90429e-05, gnorm=0.722, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19233
2022-10-10 15:16:36 - progress_bar.py[line:274] - INFO: epoch 001:   6770 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85.9, ups=0.78, wpb=109.5, bsz=40, num_updates=6760, lr=4.90384e-05, gnorm=0.577, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=19246
2022-10-10 15:16:49 - progress_bar.py[line:274] - INFO: epoch 001:   6780 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=82.1, ups=0.75, wpb=108.9, bsz=40, num_updates=6770, lr=4.90339e-05, gnorm=0.632, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=19260
2022-10-10 15:17:02 - progress_bar.py[line:274] - INFO: epoch 001:   6790 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=83.1, ups=0.77, wpb=107.8, bsz=40, num_updates=6780, lr=4.90294e-05, gnorm=0.605, clip=0, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=19272
2022-10-10 15:17:15 - progress_bar.py[line:274] - INFO: epoch 001:   6800 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85, ups=0.78, wpb=109.3, bsz=40, num_updates=6790, lr=4.90249e-05, gnorm=0.67, clip=0, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=19285
2022-10-10 15:17:27 - progress_bar.py[line:274] - INFO: epoch 001:   6810 / 57820 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.9, ups=0.81, wpb=110, bsz=40, num_updates=6800, lr=4.90204e-05, gnorm=0.66, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19298
2022-10-10 15:17:40 - progress_bar.py[line:274] - INFO: epoch 001:   6820 / 57820 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=88.7, ups=0.8, wpb=110.2, bsz=40, num_updates=6810, lr=4.90159e-05, gnorm=0.507, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19310
2022-10-10 15:17:53 - progress_bar.py[line:274] - INFO: epoch 001:   6830 / 57820 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=85.8, ups=0.78, wpb=109.6, bsz=40, num_updates=6820, lr=4.90114e-05, gnorm=0.591, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=19323
2022-10-10 15:18:05 - progress_bar.py[line:274] - INFO: epoch 001:   6840 / 57820 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=86.2, ups=0.79, wpb=109.5, bsz=40, num_updates=6830, lr=4.90069e-05, gnorm=0.595, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19336
2022-10-10 15:18:18 - progress_bar.py[line:274] - INFO: epoch 001:   6850 / 57820 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85.7, ups=0.78, wpb=110.2, bsz=40, num_updates=6840, lr=4.90024e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19349
2022-10-10 15:18:31 - progress_bar.py[line:274] - INFO: epoch 001:   6860 / 57820 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87, ups=0.78, wpb=110.9, bsz=40, num_updates=6850, lr=4.89979e-05, gnorm=0.501, clip=0, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=19361
2022-10-10 15:18:44 - progress_bar.py[line:274] - INFO: epoch 001:   6870 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85.9, ups=0.79, wpb=109, bsz=40, num_updates=6860, lr=4.89934e-05, gnorm=0.53, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19374
2022-10-10 15:18:56 - progress_bar.py[line:274] - INFO: epoch 001:   6880 / 57820 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.4, ups=0.8, wpb=108.9, bsz=40, num_updates=6870, lr=4.89889e-05, gnorm=0.61, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=19386
2022-10-10 15:19:09 - progress_bar.py[line:274] - INFO: epoch 001:   6890 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.4, ups=0.78, wpb=109.1, bsz=40, num_updates=6880, lr=4.89844e-05, gnorm=0.605, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19399
2022-10-10 15:19:21 - progress_bar.py[line:274] - INFO: epoch 001:   6900 / 57820 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.4, ups=0.8, wpb=109.6, bsz=40, num_updates=6890, lr=4.89799e-05, gnorm=0.537, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19412
2022-10-10 15:19:34 - progress_bar.py[line:274] - INFO: epoch 001:   6910 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.4, ups=0.79, wpb=108.7, bsz=40, num_updates=6900, lr=4.89754e-05, gnorm=0.585, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19424
2022-10-10 15:19:47 - progress_bar.py[line:274] - INFO: epoch 001:   6920 / 57820 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.9, ups=0.79, wpb=109.5, bsz=40, num_updates=6910, lr=4.89709e-05, gnorm=0.607, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=19437
2022-10-10 15:19:59 - progress_bar.py[line:274] - INFO: epoch 001:   6930 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.2, ups=0.81, wpb=109.6, bsz=40, num_updates=6920, lr=4.89664e-05, gnorm=0.61, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19449
2022-10-10 15:20:11 - progress_bar.py[line:274] - INFO: epoch 001:   6940 / 57820 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=90.3, ups=0.83, wpb=109.3, bsz=40, num_updates=6930, lr=4.89619e-05, gnorm=0.709, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=19461
2022-10-10 15:20:23 - progress_bar.py[line:274] - INFO: epoch 001:   6950 / 57820 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.6, ups=0.8, wpb=110.6, bsz=40, num_updates=6940, lr=4.89573e-05, gnorm=0.493, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19474
2022-10-10 15:20:36 - progress_bar.py[line:274] - INFO: epoch 001:   6960 / 57820 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=85.5, ups=0.77, wpb=110.3, bsz=40, num_updates=6950, lr=4.89528e-05, gnorm=0.526, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=19487
2022-10-10 15:20:49 - progress_bar.py[line:274] - INFO: epoch 001:   6970 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.7, ups=0.8, wpb=110.2, bsz=40, num_updates=6960, lr=4.89483e-05, gnorm=0.667, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=19499
2022-10-10 15:21:02 - progress_bar.py[line:274] - INFO: epoch 001:   6980 / 57820 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=84.9, ups=0.77, wpb=110.4, bsz=40, num_updates=6970, lr=4.89438e-05, gnorm=0.514, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19512
2022-10-10 15:21:14 - progress_bar.py[line:274] - INFO: epoch 001:   6990 / 57820 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=92.8, ups=0.84, wpb=110.9, bsz=40, num_updates=6980, lr=4.89393e-05, gnorm=0.574, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=19524
2022-10-10 15:21:27 - progress_bar.py[line:274] - INFO: epoch 001:   7000 / 57820 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=83.7, ups=0.75, wpb=111.1, bsz=40, num_updates=6990, lr=4.89348e-05, gnorm=0.471, clip=0, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=19538
2022-10-10 15:21:40 - progress_bar.py[line:274] - INFO: epoch 001:   7010 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87, ups=0.8, wpb=109.2, bsz=40, num_updates=7000, lr=4.89303e-05, gnorm=0.535, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19550
2022-10-10 15:21:52 - progress_bar.py[line:274] - INFO: epoch 001:   7020 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.8, ups=0.81, wpb=110.4, bsz=40, num_updates=7010, lr=4.89258e-05, gnorm=0.747, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19563
2022-10-10 15:22:04 - progress_bar.py[line:274] - INFO: epoch 001:   7030 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.3, ups=0.81, wpb=110.9, bsz=40, num_updates=7020, lr=4.89213e-05, gnorm=0.515, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19575
2022-10-10 15:22:17 - progress_bar.py[line:274] - INFO: epoch 001:   7040 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.7, ups=0.79, wpb=110.4, bsz=40, num_updates=7030, lr=4.89168e-05, gnorm=0.636, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=19588
2022-10-10 15:22:29 - progress_bar.py[line:274] - INFO: epoch 001:   7050 / 57820 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90.2, ups=0.82, wpb=109.7, bsz=40, num_updates=7040, lr=4.89123e-05, gnorm=0.584, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19600
2022-10-10 15:22:42 - progress_bar.py[line:274] - INFO: epoch 001:   7060 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=84.3, ups=0.77, wpb=110.2, bsz=40, num_updates=7050, lr=4.89078e-05, gnorm=0.51, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19613
2022-10-10 15:22:55 - progress_bar.py[line:274] - INFO: epoch 001:   7070 / 57820 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=89.5, ups=0.81, wpb=110.5, bsz=40, num_updates=7060, lr=4.89033e-05, gnorm=0.489, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19625
2022-10-10 15:23:07 - progress_bar.py[line:274] - INFO: epoch 001:   7080 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.7, ups=0.8, wpb=110.1, bsz=40, num_updates=7070, lr=4.88988e-05, gnorm=0.475, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=19638
2022-10-10 15:23:20 - progress_bar.py[line:274] - INFO: epoch 001:   7090 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.5, ups=0.79, wpb=109.4, bsz=40, num_updates=7080, lr=4.88943e-05, gnorm=0.522, clip=0, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=19650
2022-10-10 15:23:32 - progress_bar.py[line:274] - INFO: epoch 001:   7100 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87, ups=0.8, wpb=109, bsz=40, num_updates=7090, lr=4.88898e-05, gnorm=0.648, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=19663
2022-10-10 15:23:45 - progress_bar.py[line:274] - INFO: epoch 001:   7110 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=89.3, ups=0.82, wpb=109.1, bsz=40, num_updates=7100, lr=4.88853e-05, gnorm=0.489, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=19675
2022-10-10 15:23:58 - progress_bar.py[line:274] - INFO: epoch 001:   7120 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=83.6, ups=0.77, wpb=109.3, bsz=40, num_updates=7110, lr=4.88808e-05, gnorm=0.471, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19688
2022-10-10 15:24:11 - progress_bar.py[line:274] - INFO: epoch 001:   7130 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.6, ups=0.78, wpb=110.9, bsz=40, num_updates=7120, lr=4.88763e-05, gnorm=0.574, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=19701
2022-10-10 15:24:23 - progress_bar.py[line:274] - INFO: epoch 001:   7140 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.1, ups=0.81, wpb=109.2, bsz=40, num_updates=7130, lr=4.88718e-05, gnorm=0.445, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19713
2022-10-10 15:24:35 - progress_bar.py[line:274] - INFO: epoch 001:   7150 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.6, ups=0.81, wpb=110, bsz=40, num_updates=7140, lr=4.88673e-05, gnorm=0.567, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19726
2022-10-10 15:24:48 - progress_bar.py[line:274] - INFO: epoch 001:   7160 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=84.5, ups=0.78, wpb=108.8, bsz=40, num_updates=7150, lr=4.88628e-05, gnorm=0.543, clip=0, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=19739
2022-10-10 15:25:01 - progress_bar.py[line:274] - INFO: epoch 001:   7170 / 57820 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87, ups=0.8, wpb=109.2, bsz=40, num_updates=7160, lr=4.88583e-05, gnorm=0.593, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19751
2022-10-10 15:25:13 - progress_bar.py[line:274] - INFO: epoch 001:   7180 / 57820 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.4, ups=0.79, wpb=110.1, bsz=40, num_updates=7170, lr=4.88538e-05, gnorm=0.479, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19764
2022-10-10 15:25:26 - progress_bar.py[line:274] - INFO: epoch 001:   7190 / 57820 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.122, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.3, ups=0.79, wpb=110.3, bsz=40, num_updates=7180, lr=4.88493e-05, gnorm=0.448, clip=0, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=19777
2022-10-10 15:25:39 - progress_bar.py[line:274] - INFO: epoch 001:   7200 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=83, ups=0.75, wpb=109.9, bsz=40, num_updates=7190, lr=4.88448e-05, gnorm=0.533, clip=0, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=19790
2022-10-10 15:25:53 - progress_bar.py[line:274] - INFO: epoch 001:   7210 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=82.9, ups=0.75, wpb=109.9, bsz=40, num_updates=7200, lr=4.88402e-05, gnorm=0.506, clip=0, loss_scale=1024, train_wall=13, gb_free=11, ema_decay=0.9999, wall=19803
2022-10-10 15:26:05 - progress_bar.py[line:274] - INFO: epoch 001:   7220 / 57820 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.3, ups=0.81, wpb=107.9, bsz=40, num_updates=7210, lr=4.88357e-05, gnorm=0.428, clip=0, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=19815
2022-10-10 15:26:17 - progress_bar.py[line:274] - INFO: epoch 001:   7230 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.9, ups=0.81, wpb=109.2, bsz=40, num_updates=7220, lr=4.88312e-05, gnorm=0.479, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19828
2022-10-10 15:26:30 - progress_bar.py[line:274] - INFO: epoch 001:   7240 / 57820 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.116, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=88.1, ups=0.8, wpb=109.8, bsz=40, num_updates=7230, lr=4.88267e-05, gnorm=0.537, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19840
2022-10-10 15:26:43 - progress_bar.py[line:274] - INFO: epoch 001:   7250 / 57820 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=83.2, ups=0.76, wpb=110, bsz=40, num_updates=7240, lr=4.88222e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=19853
2022-10-10 15:26:55 - progress_bar.py[line:274] - INFO: epoch 001:   7260 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=89.6, ups=0.81, wpb=110.9, bsz=40, num_updates=7250, lr=4.88177e-05, gnorm=0.499, clip=0, loss_scale=1024, train_wall=12, gb_free=11, ema_decay=0.9999, wall=19866
2022-10-10 15:26:58 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 15:27:11 - progress_bar.py[line:274] - INFO: epoch 001:   7271 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=70, ups=0.63, wpb=110.2, bsz=40, num_updates=7260, lr=4.88132e-05, gnorm=0.399, clip=0, loss_scale=512, train_wall=16, gb_free=10.7, ema_decay=0.9999, wall=19882
2022-10-10 15:27:24 - progress_bar.py[line:274] - INFO: epoch 001:   7281 / 57820 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.3, ups=0.79, wpb=108.5, bsz=40, num_updates=7270, lr=4.88087e-05, gnorm=0.542, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19894
2022-10-10 15:27:36 - progress_bar.py[line:274] - INFO: epoch 001:   7291 / 57820 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=90, ups=0.82, wpb=109.1, bsz=40, num_updates=7280, lr=4.88042e-05, gnorm=0.517, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=19906
2022-10-10 15:27:48 - progress_bar.py[line:274] - INFO: epoch 001:   7301 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.4, ups=0.8, wpb=110.5, bsz=40, num_updates=7290, lr=4.87997e-05, gnorm=0.527, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19919
2022-10-10 15:28:01 - progress_bar.py[line:274] - INFO: epoch 001:   7311 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.1, ups=0.79, wpb=111, bsz=40, num_updates=7300, lr=4.87952e-05, gnorm=0.674, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=19932
2022-10-10 15:28:14 - progress_bar.py[line:274] - INFO: epoch 001:   7321 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.3, ups=0.78, wpb=109.2, bsz=40, num_updates=7310, lr=4.87907e-05, gnorm=0.621, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=19944
2022-10-10 15:28:26 - progress_bar.py[line:274] - INFO: epoch 001:   7331 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.2, ups=0.8, wpb=110.6, bsz=40, num_updates=7320, lr=4.87862e-05, gnorm=0.706, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19957
2022-10-10 15:28:39 - progress_bar.py[line:274] - INFO: epoch 001:   7341 / 57820 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.113, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=88.7, ups=0.81, wpb=109.6, bsz=40, num_updates=7330, lr=4.87817e-05, gnorm=0.515, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19969
2022-10-10 15:28:51 - progress_bar.py[line:274] - INFO: epoch 001:   7351 / 57820 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.4, ups=0.8, wpb=108.8, bsz=40, num_updates=7340, lr=4.87772e-05, gnorm=0.702, clip=0, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=19982
2022-10-10 15:29:04 - progress_bar.py[line:274] - INFO: epoch 001:   7361 / 57820 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=90.8, ups=0.82, wpb=110.9, bsz=40, num_updates=7350, lr=4.87727e-05, gnorm=0.741, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19994
2022-10-10 15:29:16 - progress_bar.py[line:274] - INFO: epoch 001:   7371 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.5, ups=0.79, wpb=108.7, bsz=40, num_updates=7360, lr=4.87682e-05, gnorm=0.73, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=20007
2022-10-10 15:29:29 - progress_bar.py[line:274] - INFO: epoch 001:   7381 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.9, ups=0.8, wpb=111, bsz=40, num_updates=7370, lr=4.87637e-05, gnorm=0.569, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20019
2022-10-10 15:29:42 - progress_bar.py[line:274] - INFO: epoch 001:   7391 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.6, ups=0.78, wpb=110, bsz=40, num_updates=7380, lr=4.87592e-05, gnorm=0.543, clip=10, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=20032
2022-10-10 15:29:54 - progress_bar.py[line:274] - INFO: epoch 001:   7401 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.2, ups=0.81, wpb=110.7, bsz=40, num_updates=7390, lr=4.87547e-05, gnorm=0.596, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20044
2022-10-10 15:30:07 - progress_bar.py[line:274] - INFO: epoch 001:   7411 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85.1, ups=0.77, wpb=110.1, bsz=40, num_updates=7400, lr=4.87502e-05, gnorm=0.455, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=20057
2022-10-10 15:30:20 - progress_bar.py[line:274] - INFO: epoch 001:   7421 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.1, ups=0.8, wpb=109.2, bsz=40, num_updates=7410, lr=4.87457e-05, gnorm=0.545, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20070
2022-10-10 15:30:32 - progress_bar.py[line:274] - INFO: epoch 001:   7431 / 57820 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=84.7, ups=0.77, wpb=109.5, bsz=40, num_updates=7420, lr=4.87412e-05, gnorm=0.499, clip=0, loss_scale=512, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=20083
2022-10-10 15:30:45 - progress_bar.py[line:274] - INFO: epoch 001:   7441 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=91.5, ups=0.82, wpb=111.3, bsz=40, num_updates=7430, lr=4.87367e-05, gnorm=0.496, clip=10, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=20095
2022-10-10 15:30:57 - progress_bar.py[line:274] - INFO: epoch 001:   7451 / 57820 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=90, ups=0.82, wpb=109.2, bsz=40, num_updates=7440, lr=4.87322e-05, gnorm=0.527, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20107
2022-10-10 15:31:09 - progress_bar.py[line:274] - INFO: epoch 001:   7461 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.9, ups=0.8, wpb=108.2, bsz=40, num_updates=7450, lr=4.87276e-05, gnorm=0.578, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20120
2022-10-10 15:31:22 - progress_bar.py[line:274] - INFO: epoch 001:   7471 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=82.8, ups=0.76, wpb=109.1, bsz=40, num_updates=7460, lr=4.87231e-05, gnorm=0.455, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=20133
2022-10-10 15:31:35 - progress_bar.py[line:274] - INFO: epoch 001:   7481 / 57820 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=88.5, ups=0.81, wpb=109.1, bsz=40, num_updates=7470, lr=4.87186e-05, gnorm=0.544, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20145
2022-10-10 15:31:47 - progress_bar.py[line:274] - INFO: epoch 001:   7491 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=86.8, ups=0.79, wpb=109.8, bsz=40, num_updates=7480, lr=4.87141e-05, gnorm=0.559, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=20158
2022-10-10 15:32:00 - progress_bar.py[line:274] - INFO: epoch 001:   7501 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.9, ups=0.82, wpb=109.8, bsz=40, num_updates=7490, lr=4.87096e-05, gnorm=0.644, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20170
2022-10-10 15:32:12 - progress_bar.py[line:274] - INFO: epoch 001:   7511 / 57820 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=90, ups=0.81, wpb=110.6, bsz=40, num_updates=7500, lr=4.87051e-05, gnorm=0.571, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=20182
2022-10-10 15:32:24 - progress_bar.py[line:274] - INFO: epoch 001:   7521 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.2, ups=0.8, wpb=109, bsz=40, num_updates=7510, lr=4.87006e-05, gnorm=0.555, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=20195
2022-10-10 15:32:37 - progress_bar.py[line:274] - INFO: epoch 001:   7531 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88, ups=0.8, wpb=109.7, bsz=40, num_updates=7520, lr=4.86961e-05, gnorm=0.57, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=20207
2022-10-10 15:32:50 - progress_bar.py[line:274] - INFO: epoch 001:   7541 / 57820 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=83.8, ups=0.77, wpb=109.1, bsz=40, num_updates=7530, lr=4.86916e-05, gnorm=0.639, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=20220
2022-10-10 15:33:03 - progress_bar.py[line:274] - INFO: epoch 001:   7551 / 57820 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=86.6, ups=0.79, wpb=109, bsz=40, num_updates=7540, lr=4.86871e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=20233
2022-10-10 15:33:15 - progress_bar.py[line:274] - INFO: epoch 001:   7561 / 57820 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=84.6, ups=0.78, wpb=108.1, bsz=40, num_updates=7550, lr=4.86826e-05, gnorm=0.527, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=20246
2022-10-10 15:33:28 - progress_bar.py[line:274] - INFO: epoch 001:   7571 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.9, ups=0.82, wpb=108.8, bsz=40, num_updates=7560, lr=4.86781e-05, gnorm=0.529, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20258
2022-10-10 15:33:40 - progress_bar.py[line:274] - INFO: epoch 001:   7581 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.4, ups=0.8, wpb=109.7, bsz=40, num_updates=7570, lr=4.86736e-05, gnorm=0.567, clip=0, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=20271
2022-10-10 15:33:53 - progress_bar.py[line:274] - INFO: epoch 001:   7591 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87, ups=0.79, wpb=110.6, bsz=40, num_updates=7580, lr=4.86691e-05, gnorm=0.485, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=20283
2022-10-10 15:34:05 - progress_bar.py[line:274] - INFO: epoch 001:   7601 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.8, ups=0.82, wpb=109.5, bsz=40, num_updates=7590, lr=4.86646e-05, gnorm=0.598, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=20295
2022-10-10 15:34:17 - progress_bar.py[line:274] - INFO: epoch 001:   7611 / 57820 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=89.7, ups=0.81, wpb=110.9, bsz=40, num_updates=7600, lr=4.86601e-05, gnorm=0.441, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20308
2022-10-10 15:34:30 - progress_bar.py[line:274] - INFO: epoch 001:   7621 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.8, ups=0.79, wpb=109.5, bsz=40, num_updates=7610, lr=4.86556e-05, gnorm=0.452, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=20320
2022-10-10 15:34:43 - progress_bar.py[line:274] - INFO: epoch 001:   7631 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.7, ups=0.8, wpb=108.9, bsz=40, num_updates=7620, lr=4.86511e-05, gnorm=0.586, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=20333
2022-10-10 15:34:55 - progress_bar.py[line:274] - INFO: epoch 001:   7641 / 57820 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=84.6, ups=0.78, wpb=109, bsz=40, num_updates=7630, lr=4.86466e-05, gnorm=0.661, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=20346
2022-10-10 15:35:08 - progress_bar.py[line:274] - INFO: epoch 001:   7651 / 57820 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87, ups=0.8, wpb=109.2, bsz=40, num_updates=7640, lr=4.86421e-05, gnorm=0.598, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20358
2022-10-10 15:35:21 - progress_bar.py[line:274] - INFO: epoch 001:   7661 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85, ups=0.78, wpb=109.5, bsz=40, num_updates=7650, lr=4.86376e-05, gnorm=0.474, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=20371
2022-10-10 15:35:33 - progress_bar.py[line:274] - INFO: epoch 001:   7671 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.2, ups=0.8, wpb=110, bsz=40, num_updates=7660, lr=4.86331e-05, gnorm=0.464, clip=0, loss_scale=512, train_wall=12, gb_free=10, ema_decay=0.9999, wall=20384
2022-10-10 15:35:46 - progress_bar.py[line:274] - INFO: epoch 001:   7681 / 57820 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.6, ups=0.8, wpb=109.9, bsz=40, num_updates=7670, lr=4.86286e-05, gnorm=0.462, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20396
2022-10-10 15:35:58 - progress_bar.py[line:274] - INFO: epoch 001:   7691 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=91.4, ups=0.83, wpb=109.7, bsz=40, num_updates=7680, lr=4.86241e-05, gnorm=0.464, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20408
2022-10-10 15:36:10 - progress_bar.py[line:274] - INFO: epoch 001:   7701 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.8, ups=0.8, wpb=109.4, bsz=40, num_updates=7690, lr=4.86196e-05, gnorm=0.472, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=20421
2022-10-10 15:36:23 - progress_bar.py[line:274] - INFO: epoch 001:   7711 / 57820 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=89.8, ups=0.82, wpb=109.2, bsz=40, num_updates=7700, lr=4.86151e-05, gnorm=0.542, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=20433
2022-10-10 15:36:35 - progress_bar.py[line:274] - INFO: epoch 001:   7721 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.3, ups=0.8, wpb=109.9, bsz=40, num_updates=7710, lr=4.86105e-05, gnorm=0.605, clip=10, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=20446
2022-10-10 15:36:48 - progress_bar.py[line:274] - INFO: epoch 001:   7731 / 57820 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.118, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=87.3, ups=0.8, wpb=109, bsz=40, num_updates=7720, lr=4.8606e-05, gnorm=0.419, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20458
2022-10-10 15:37:00 - progress_bar.py[line:274] - INFO: epoch 001:   7741 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.9, ups=0.8, wpb=109.3, bsz=40, num_updates=7730, lr=4.86015e-05, gnorm=0.691, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20471
2022-10-10 15:37:13 - progress_bar.py[line:274] - INFO: epoch 001:   7751 / 57820 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.8, ups=0.81, wpb=109, bsz=40, num_updates=7740, lr=4.8597e-05, gnorm=0.632, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=20483
2022-10-10 15:37:25 - progress_bar.py[line:274] - INFO: epoch 001:   7761 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90, ups=0.82, wpb=109.2, bsz=40, num_updates=7750, lr=4.85925e-05, gnorm=0.589, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=20495
2022-10-10 15:37:37 - progress_bar.py[line:274] - INFO: epoch 001:   7771 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.9, ups=0.82, wpb=108.7, bsz=40, num_updates=7760, lr=4.8588e-05, gnorm=0.487, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=20507
2022-10-10 15:37:50 - progress_bar.py[line:274] - INFO: epoch 001:   7781 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.6, ups=0.79, wpb=110.8, bsz=40, num_updates=7770, lr=4.85835e-05, gnorm=0.453, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=20520
2022-10-10 15:38:02 - progress_bar.py[line:274] - INFO: epoch 001:   7791 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.9, ups=0.8, wpb=110, bsz=40, num_updates=7780, lr=4.8579e-05, gnorm=0.637, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20533
2022-10-10 15:38:15 - progress_bar.py[line:274] - INFO: epoch 001:   7801 / 57820 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.9, ups=0.79, wpb=111.1, bsz=40, num_updates=7790, lr=4.85745e-05, gnorm=0.484, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=20545
2022-10-10 15:38:27 - progress_bar.py[line:274] - INFO: epoch 001:   7811 / 57820 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=88.5, ups=0.8, wpb=110, bsz=40, num_updates=7800, lr=4.857e-05, gnorm=0.457, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20558
2022-10-10 15:38:40 - progress_bar.py[line:274] - INFO: epoch 001:   7821 / 57820 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.9, ups=0.8, wpb=110.1, bsz=40, num_updates=7810, lr=4.85655e-05, gnorm=0.49, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20570
2022-10-10 15:38:52 - progress_bar.py[line:274] - INFO: epoch 001:   7831 / 57820 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=92.6, ups=0.84, wpb=109.9, bsz=40, num_updates=7820, lr=4.8561e-05, gnorm=0.44, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20582
2022-10-10 15:39:04 - progress_bar.py[line:274] - INFO: epoch 001:   7841 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86, ups=0.78, wpb=109.6, bsz=40, num_updates=7830, lr=4.85565e-05, gnorm=0.512, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=20595
2022-10-10 15:39:17 - progress_bar.py[line:274] - INFO: epoch 001:   7851 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=88.4, ups=0.81, wpb=109.7, bsz=40, num_updates=7840, lr=4.8552e-05, gnorm=0.499, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20607
2022-10-10 15:39:25 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 15:39:31 - progress_bar.py[line:274] - INFO: epoch 001:   7862 / 57820 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.12, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=78.7, ups=0.73, wpb=108.3, bsz=40, num_updates=7850, lr=4.85475e-05, gnorm=0.492, clip=0, loss_scale=512, train_wall=14, gb_free=10.4, ema_decay=0.9999, wall=20621
2022-10-10 15:39:43 - progress_bar.py[line:274] - INFO: epoch 001:   7872 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.3, ups=0.81, wpb=110.1, bsz=40, num_updates=7860, lr=4.8543e-05, gnorm=0.615, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20633
2022-10-10 15:39:55 - progress_bar.py[line:274] - INFO: epoch 001:   7882 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.1, ups=0.8, wpb=109, bsz=40, num_updates=7870, lr=4.85385e-05, gnorm=0.611, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20646
2022-10-10 15:40:08 - progress_bar.py[line:274] - INFO: epoch 001:   7892 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.8, ups=0.79, wpb=110.6, bsz=40, num_updates=7880, lr=4.8534e-05, gnorm=0.708, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=20659
2022-10-10 15:40:20 - progress_bar.py[line:274] - INFO: epoch 001:   7902 / 57820 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.8, ups=0.82, wpb=109.9, bsz=40, num_updates=7890, lr=4.85295e-05, gnorm=0.499, clip=0, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=20671
2022-10-10 15:40:33 - progress_bar.py[line:274] - INFO: epoch 001:   7912 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.4, ups=0.81, wpb=110.3, bsz=40, num_updates=7900, lr=4.8525e-05, gnorm=0.476, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=20683
2022-10-10 15:40:45 - progress_bar.py[line:274] - INFO: epoch 001:   7922 / 57820 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=88.6, ups=0.8, wpb=110.7, bsz=40, num_updates=7910, lr=4.85205e-05, gnorm=0.435, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20696
2022-10-10 15:40:58 - progress_bar.py[line:274] - INFO: epoch 001:   7932 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.7, ups=0.81, wpb=109.9, bsz=40, num_updates=7920, lr=4.8516e-05, gnorm=0.432, clip=0, loss_scale=512, train_wall=12, gb_free=11.3, ema_decay=0.9999, wall=20708
2022-10-10 15:41:11 - progress_bar.py[line:274] - INFO: epoch 001:   7942 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.4, ups=0.78, wpb=109.5, bsz=40, num_updates=7930, lr=4.85115e-05, gnorm=0.557, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=20721
2022-10-10 15:41:23 - progress_bar.py[line:274] - INFO: epoch 001:   7952 / 57820 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.8, ups=0.8, wpb=109.9, bsz=40, num_updates=7940, lr=4.8507e-05, gnorm=0.601, clip=10, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=20733
2022-10-10 15:41:36 - progress_bar.py[line:274] - INFO: epoch 001:   7962 / 57820 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87, ups=0.8, wpb=108.7, bsz=40, num_updates=7950, lr=4.85025e-05, gnorm=0.777, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=20746
2022-10-10 15:41:48 - progress_bar.py[line:274] - INFO: epoch 001:   7972 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90.5, ups=0.82, wpb=109.7, bsz=40, num_updates=7960, lr=4.8498e-05, gnorm=0.554, clip=0, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=20758
2022-10-10 15:42:00 - progress_bar.py[line:274] - INFO: epoch 001:   7982 / 57820 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.4, ups=0.82, wpb=108.7, bsz=40, num_updates=7970, lr=4.84934e-05, gnorm=0.575, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=20770
2022-10-10 15:42:12 - progress_bar.py[line:274] - INFO: epoch 001:   7992 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.4, ups=0.79, wpb=110.3, bsz=40, num_updates=7980, lr=4.84889e-05, gnorm=0.521, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20783
2022-10-10 15:42:25 - progress_bar.py[line:274] - INFO: epoch 001:   8002 / 57820 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.8, ups=0.81, wpb=108.9, bsz=40, num_updates=7990, lr=4.84844e-05, gnorm=0.528, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20795
2022-10-10 15:42:37 - progress_bar.py[line:274] - INFO: epoch 001:   8012 / 57820 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.2, ups=0.81, wpb=110.6, bsz=40, num_updates=8000, lr=4.84799e-05, gnorm=0.599, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=20808
2022-10-10 15:42:49 - progress_bar.py[line:274] - INFO: epoch 001:   8022 / 57820 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=90.2, ups=0.82, wpb=109.8, bsz=40, num_updates=8010, lr=4.84754e-05, gnorm=0.465, clip=0, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=20820
2022-10-10 15:43:02 - progress_bar.py[line:274] - INFO: epoch 001:   8032 / 57820 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.6, ups=0.79, wpb=110.8, bsz=40, num_updates=8020, lr=4.84709e-05, gnorm=0.446, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=20833
2022-10-10 15:43:14 - progress_bar.py[line:274] - INFO: epoch 001:   8042 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=93.4, ups=0.84, wpb=110.7, bsz=40, num_updates=8030, lr=4.84664e-05, gnorm=0.594, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20844
2022-10-10 15:43:26 - progress_bar.py[line:274] - INFO: epoch 001:   8052 / 57820 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.1, ups=0.8, wpb=110.3, bsz=40, num_updates=8040, lr=4.84619e-05, gnorm=0.532, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20857
2022-10-10 15:43:38 - progress_bar.py[line:274] - INFO: epoch 001:   8062 / 57820 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=93.8, ups=0.85, wpb=109.8, bsz=40, num_updates=8050, lr=4.84574e-05, gnorm=0.539, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=20869
2022-10-10 15:43:51 - progress_bar.py[line:274] - INFO: epoch 001:   8072 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87, ups=0.8, wpb=109.3, bsz=40, num_updates=8060, lr=4.84529e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20881
2022-10-10 15:43:56 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-10-10 15:44:04 - progress_bar.py[line:274] - INFO: epoch 001:   8083 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=80.6, ups=0.74, wpb=109.6, bsz=40, num_updates=8070, lr=4.84484e-05, gnorm=0.559, clip=10, loss_scale=256, train_wall=14, gb_free=11.1, ema_decay=0.9999, wall=20895
2022-10-10 15:44:17 - progress_bar.py[line:274] - INFO: epoch 001:   8093 / 57820 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=90.7, ups=0.82, wpb=110.5, bsz=40, num_updates=8080, lr=4.84439e-05, gnorm=0.408, clip=0, loss_scale=256, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=20907
2022-10-10 15:44:29 - progress_bar.py[line:274] - INFO: epoch 001:   8103 / 57820 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90.2, ups=0.81, wpb=111.4, bsz=40, num_updates=8090, lr=4.84394e-05, gnorm=0.495, clip=0, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20919
2022-10-10 15:44:41 - progress_bar.py[line:274] - INFO: epoch 001:   8113 / 57820 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.4, ups=0.81, wpb=108, bsz=40, num_updates=8100, lr=4.84349e-05, gnorm=0.511, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20932
2022-10-10 15:44:54 - progress_bar.py[line:274] - INFO: epoch 001:   8123 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.4, ups=0.8, wpb=108.5, bsz=40, num_updates=8110, lr=4.84304e-05, gnorm=0.639, clip=10, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=20944
2022-10-10 15:45:06 - progress_bar.py[line:274] - INFO: epoch 001:   8133 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.7, ups=0.82, wpb=109.3, bsz=40, num_updates=8120, lr=4.84259e-05, gnorm=0.606, clip=10, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=20956
2022-10-10 15:45:18 - progress_bar.py[line:274] - INFO: epoch 001:   8143 / 57820 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=90.1, ups=0.81, wpb=111.1, bsz=40, num_updates=8130, lr=4.84214e-05, gnorm=0.508, clip=0, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20969
2022-10-10 15:45:31 - progress_bar.py[line:274] - INFO: epoch 001:   8153 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=87.6, ups=0.8, wpb=109.7, bsz=40, num_updates=8140, lr=4.84169e-05, gnorm=0.499, clip=0, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=20981
2022-10-10 15:45:44 - progress_bar.py[line:274] - INFO: epoch 001:   8163 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.2, ups=0.78, wpb=110.1, bsz=40, num_updates=8150, lr=4.84124e-05, gnorm=0.495, clip=0, loss_scale=256, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=20994
2022-10-10 15:45:56 - progress_bar.py[line:274] - INFO: epoch 001:   8173 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.6, ups=0.81, wpb=109.6, bsz=40, num_updates=8160, lr=4.84079e-05, gnorm=0.523, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21007
2022-10-10 15:46:08 - progress_bar.py[line:274] - INFO: epoch 001:   8183 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.8, ups=0.81, wpb=109.3, bsz=40, num_updates=8170, lr=4.84034e-05, gnorm=0.509, clip=0, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21019
2022-10-10 15:46:21 - progress_bar.py[line:274] - INFO: epoch 001:   8193 / 57820 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.6, ups=0.81, wpb=109.8, bsz=40, num_updates=8180, lr=4.83989e-05, gnorm=0.487, clip=0, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21031
2022-10-10 15:46:34 - progress_bar.py[line:274] - INFO: epoch 001:   8203 / 57820 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=84.2, ups=0.77, wpb=109.8, bsz=40, num_updates=8190, lr=4.83944e-05, gnorm=0.541, clip=0, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=21044
2022-10-10 15:46:46 - progress_bar.py[line:274] - INFO: epoch 001:   8213 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.6, ups=0.81, wpb=109.9, bsz=40, num_updates=8200, lr=4.83899e-05, gnorm=0.499, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21057
2022-10-10 15:46:59 - progress_bar.py[line:274] - INFO: epoch 001:   8223 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.3, ups=0.79, wpb=108.9, bsz=40, num_updates=8210, lr=4.83854e-05, gnorm=0.568, clip=0, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=21069
2022-10-10 15:47:11 - progress_bar.py[line:274] - INFO: epoch 001:   8233 / 57820 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=88.9, ups=0.8, wpb=110.6, bsz=40, num_updates=8220, lr=4.83808e-05, gnorm=0.446, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21082
2022-10-10 15:47:23 - progress_bar.py[line:274] - INFO: epoch 001:   8243 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90.8, ups=0.82, wpb=110.5, bsz=40, num_updates=8230, lr=4.83763e-05, gnorm=0.451, clip=0, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21094
2022-10-10 15:47:36 - progress_bar.py[line:274] - INFO: epoch 001:   8253 / 57820 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.9, ups=0.78, wpb=110.7, bsz=40, num_updates=8240, lr=4.83718e-05, gnorm=0.481, clip=0, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=21107
2022-10-10 15:47:49 - progress_bar.py[line:274] - INFO: epoch 001:   8263 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.5, ups=0.8, wpb=109.2, bsz=40, num_updates=8250, lr=4.83673e-05, gnorm=0.471, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21119
2022-10-10 15:48:01 - progress_bar.py[line:274] - INFO: epoch 001:   8273 / 57820 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=91.3, ups=0.83, wpb=110.1, bsz=40, num_updates=8260, lr=4.83628e-05, gnorm=0.453, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21131
2022-10-10 15:48:13 - progress_bar.py[line:274] - INFO: epoch 001:   8283 / 57820 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.8, ups=0.8, wpb=109.5, bsz=40, num_updates=8270, lr=4.83583e-05, gnorm=0.609, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21144
2022-10-10 15:48:25 - progress_bar.py[line:274] - INFO: epoch 001:   8293 / 57820 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=91.3, ups=0.83, wpb=109.7, bsz=40, num_updates=8280, lr=4.83538e-05, gnorm=0.507, clip=0, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=21156
2022-10-10 15:48:38 - progress_bar.py[line:274] - INFO: epoch 001:   8303 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.4, ups=0.8, wpb=109.5, bsz=40, num_updates=8290, lr=4.83493e-05, gnorm=0.445, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21168
2022-10-10 15:48:50 - progress_bar.py[line:274] - INFO: epoch 001:   8313 / 57820 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=86.6, ups=0.79, wpb=109, bsz=40, num_updates=8300, lr=4.83448e-05, gnorm=0.562, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21181
2022-10-10 15:49:02 - progress_bar.py[line:274] - INFO: epoch 001:   8323 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=92.7, ups=0.83, wpb=111.8, bsz=40, num_updates=8310, lr=4.83403e-05, gnorm=0.582, clip=0, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21193
2022-10-10 15:49:15 - progress_bar.py[line:274] - INFO: epoch 001:   8333 / 57820 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.2, ups=0.82, wpb=108.3, bsz=40, num_updates=8320, lr=4.83358e-05, gnorm=0.51, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21205
2022-10-10 15:49:27 - progress_bar.py[line:274] - INFO: epoch 001:   8343 / 57820 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=89.2, ups=0.8, wpb=110.8, bsz=40, num_updates=8330, lr=4.83313e-05, gnorm=0.528, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21217
2022-10-10 15:49:39 - progress_bar.py[line:274] - INFO: epoch 001:   8353 / 57820 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=90.6, ups=0.82, wpb=110.8, bsz=40, num_updates=8340, lr=4.83268e-05, gnorm=0.448, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21230
2022-10-10 15:49:52 - progress_bar.py[line:274] - INFO: epoch 001:   8363 / 57820 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.7, ups=0.81, wpb=108.2, bsz=40, num_updates=8350, lr=4.83223e-05, gnorm=0.694, clip=10, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=21242
2022-10-10 15:50:04 - progress_bar.py[line:274] - INFO: epoch 001:   8373 / 57820 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.9, ups=0.8, wpb=108.9, bsz=40, num_updates=8360, lr=4.83178e-05, gnorm=0.421, clip=0, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=21255
2022-10-10 15:50:17 - progress_bar.py[line:274] - INFO: epoch 001:   8383 / 57820 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.9, ups=0.79, wpb=110.8, bsz=40, num_updates=8370, lr=4.83133e-05, gnorm=0.586, clip=10, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21267
2022-10-10 15:50:29 - progress_bar.py[line:274] - INFO: epoch 001:   8393 / 57820 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=88.5, ups=0.81, wpb=109.5, bsz=40, num_updates=8380, lr=4.83088e-05, gnorm=0.434, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21280
2022-10-10 15:50:42 - progress_bar.py[line:274] - INFO: epoch 001:   8403 / 57820 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.4, ups=0.8, wpb=109.9, bsz=40, num_updates=8390, lr=4.83043e-05, gnorm=0.534, clip=0, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=21292
2022-10-10 15:50:54 - progress_bar.py[line:274] - INFO: epoch 001:   8413 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=90.1, ups=0.81, wpb=110.9, bsz=40, num_updates=8400, lr=4.82998e-05, gnorm=0.472, clip=0, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21304
2022-10-10 15:51:06 - progress_bar.py[line:274] - INFO: epoch 001:   8423 / 57820 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=90.4, ups=0.83, wpb=109.5, bsz=40, num_updates=8410, lr=4.82953e-05, gnorm=0.455, clip=0, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21317
2022-10-10 15:51:19 - progress_bar.py[line:274] - INFO: epoch 001:   8433 / 57820 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.9, ups=0.8, wpb=109.3, bsz=40, num_updates=8420, lr=4.82908e-05, gnorm=0.516, clip=0, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21329
2022-10-10 15:51:31 - progress_bar.py[line:274] - INFO: epoch 001:   8443 / 57820 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.8, ups=0.8, wpb=110, bsz=40, num_updates=8430, lr=4.82863e-05, gnorm=0.577, clip=0, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21342
2022-10-10 15:51:44 - progress_bar.py[line:274] - INFO: epoch 001:   8453 / 57820 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=83.6, ups=0.77, wpb=109.1, bsz=40, num_updates=8440, lr=4.82818e-05, gnorm=0.653, clip=20, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=21355
2022-10-10 15:51:57 - progress_bar.py[line:274] - INFO: epoch 001:   8463 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.3, ups=0.81, wpb=110.1, bsz=40, num_updates=8450, lr=4.82773e-05, gnorm=0.452, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21367
2022-10-10 15:52:09 - progress_bar.py[line:274] - INFO: epoch 001:   8473 / 57820 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=86.8, ups=0.8, wpb=109, bsz=40, num_updates=8460, lr=4.82728e-05, gnorm=0.515, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21380
2022-10-10 15:52:22 - progress_bar.py[line:274] - INFO: epoch 001:   8483 / 57820 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=88.8, ups=0.81, wpb=109.6, bsz=40, num_updates=8470, lr=4.82683e-05, gnorm=0.483, clip=0, loss_scale=256, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=21392
2022-10-10 15:52:34 - progress_bar.py[line:274] - INFO: epoch 001:   8493 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.1, ups=0.79, wpb=110.6, bsz=40, num_updates=8480, lr=4.82637e-05, gnorm=0.554, clip=0, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=21405
2022-10-10 15:52:46 - progress_bar.py[line:274] - INFO: epoch 001:   8503 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90.2, ups=0.83, wpb=108.9, bsz=40, num_updates=8490, lr=4.82592e-05, gnorm=0.581, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21417
2022-10-10 15:52:59 - progress_bar.py[line:274] - INFO: epoch 001:   8513 / 57820 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.7, ups=0.81, wpb=111.3, bsz=40, num_updates=8500, lr=4.82547e-05, gnorm=0.583, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21429
2022-10-10 15:53:11 - progress_bar.py[line:274] - INFO: epoch 001:   8523 / 57820 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90.4, ups=0.83, wpb=108.4, bsz=40, num_updates=8510, lr=4.82502e-05, gnorm=0.518, clip=0, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=21441
2022-10-10 15:53:23 - progress_bar.py[line:274] - INFO: epoch 001:   8533 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89.2, ups=0.82, wpb=109, bsz=40, num_updates=8520, lr=4.82457e-05, gnorm=0.517, clip=0, loss_scale=256, train_wall=12, gb_free=11, ema_decay=0.9999, wall=21453
2022-10-10 15:53:36 - progress_bar.py[line:274] - INFO: epoch 001:   8543 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.6, ups=0.79, wpb=109, bsz=40, num_updates=8530, lr=4.82412e-05, gnorm=0.463, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21466
2022-10-10 15:53:48 - progress_bar.py[line:274] - INFO: epoch 001:   8553 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87, ups=0.79, wpb=109.5, bsz=40, num_updates=8540, lr=4.82367e-05, gnorm=0.515, clip=0, loss_scale=256, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=21479
2022-10-10 15:54:01 - progress_bar.py[line:274] - INFO: epoch 001:   8563 / 57820 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.8, ups=0.81, wpb=109.6, bsz=40, num_updates=8550, lr=4.82322e-05, gnorm=0.481, clip=0, loss_scale=256, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=21491
2022-10-10 15:54:13 - progress_bar.py[line:274] - INFO: epoch 001:   8573 / 57820 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.6, ups=0.81, wpb=109.6, bsz=40, num_updates=8560, lr=4.82277e-05, gnorm=0.515, clip=10, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21503
2022-10-10 15:54:25 - progress_bar.py[line:274] - INFO: epoch 001:   8583 / 57820 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.122, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=90.5, ups=0.83, wpb=109.1, bsz=40, num_updates=8570, lr=4.82232e-05, gnorm=0.46, clip=0, loss_scale=256, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=21515
2022-10-10 15:54:38 - progress_bar.py[line:274] - INFO: epoch 001:   8593 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=85.1, ups=0.79, wpb=107.6, bsz=40, num_updates=8580, lr=4.82187e-05, gnorm=0.483, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=21528
2022-10-10 15:54:50 - progress_bar.py[line:274] - INFO: epoch 001:   8603 / 57820 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.118, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=88.4, ups=0.8, wpb=110.9, bsz=40, num_updates=8590, lr=4.82142e-05, gnorm=0.379, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21541
2022-10-10 15:55:03 - progress_bar.py[line:274] - INFO: epoch 001:   8613 / 57820 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.122, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.7, ups=0.81, wpb=108.7, bsz=40, num_updates=8600, lr=4.82097e-05, gnorm=0.543, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21553
2022-10-10 15:55:15 - progress_bar.py[line:274] - INFO: epoch 001:   8623 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.6, ups=0.8, wpb=110.7, bsz=40, num_updates=8610, lr=4.82052e-05, gnorm=0.525, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21566
2022-10-10 15:55:27 - progress_bar.py[line:274] - INFO: epoch 001:   8633 / 57820 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=92, ups=0.83, wpb=111.1, bsz=40, num_updates=8620, lr=4.82007e-05, gnorm=0.544, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21578
2022-10-10 15:55:39 - progress_bar.py[line:274] - INFO: epoch 001:   8643 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90.3, ups=0.84, wpb=108.1, bsz=40, num_updates=8630, lr=4.81962e-05, gnorm=0.606, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21590
2022-10-10 15:55:52 - progress_bar.py[line:274] - INFO: epoch 001:   8653 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.9, ups=0.79, wpb=109.6, bsz=40, num_updates=8640, lr=4.81917e-05, gnorm=0.595, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=21602
2022-10-10 15:56:05 - progress_bar.py[line:274] - INFO: epoch 001:   8663 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.4, ups=0.79, wpb=108.6, bsz=40, num_updates=8650, lr=4.81872e-05, gnorm=0.575, clip=10, loss_scale=512, train_wall=13, gb_free=10.2, ema_decay=0.9999, wall=21615
2022-10-10 15:56:17 - progress_bar.py[line:274] - INFO: epoch 001:   8673 / 57820 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.5, ups=0.79, wpb=109.6, bsz=40, num_updates=8660, lr=4.81827e-05, gnorm=0.502, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=21628
2022-10-10 15:56:30 - progress_bar.py[line:274] - INFO: epoch 001:   8683 / 57820 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=89.1, ups=0.81, wpb=110.3, bsz=40, num_updates=8670, lr=4.81782e-05, gnorm=0.514, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21640
2022-10-10 15:56:42 - progress_bar.py[line:274] - INFO: epoch 001:   8693 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89.5, ups=0.82, wpb=109.5, bsz=40, num_updates=8680, lr=4.81737e-05, gnorm=0.559, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=21652
2022-10-10 15:56:54 - progress_bar.py[line:274] - INFO: epoch 001:   8703 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.5, ups=0.81, wpb=109.8, bsz=40, num_updates=8690, lr=4.81692e-05, gnorm=0.472, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=21665
2022-10-10 15:57:07 - progress_bar.py[line:274] - INFO: epoch 001:   8713 / 57820 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=85.7, ups=0.78, wpb=109.9, bsz=40, num_updates=8700, lr=4.81647e-05, gnorm=0.484, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=21678
2022-10-10 15:57:19 - progress_bar.py[line:274] - INFO: epoch 001:   8723 / 57820 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=90.1, ups=0.82, wpb=109.5, bsz=40, num_updates=8710, lr=4.81602e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=21690
2022-10-10 15:57:32 - progress_bar.py[line:274] - INFO: epoch 001:   8733 / 57820 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=90.2, ups=0.82, wpb=110.4, bsz=40, num_updates=8720, lr=4.81557e-05, gnorm=0.444, clip=0, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=21702
2022-10-10 15:57:44 - progress_bar.py[line:274] - INFO: epoch 001:   8743 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.1, ups=0.8, wpb=109.6, bsz=40, num_updates=8730, lr=4.81512e-05, gnorm=0.509, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=21715
2022-10-10 15:57:57 - progress_bar.py[line:274] - INFO: epoch 001:   8753 / 57820 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.7, ups=0.79, wpb=110.8, bsz=40, num_updates=8740, lr=4.81466e-05, gnorm=0.631, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21727
2022-10-10 15:58:09 - progress_bar.py[line:274] - INFO: epoch 001:   8763 / 57820 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=89, ups=0.8, wpb=111.1, bsz=40, num_updates=8750, lr=4.81421e-05, gnorm=0.588, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=21740
2022-10-10 15:58:22 - progress_bar.py[line:274] - INFO: epoch 001:   8773 / 57820 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.2, ups=0.78, wpb=109.9, bsz=40, num_updates=8760, lr=4.81376e-05, gnorm=0.564, clip=0, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=21753
2022-10-10 15:58:35 - progress_bar.py[line:274] - INFO: epoch 001:   8783 / 57820 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.2, ups=0.8, wpb=110.4, bsz=40, num_updates=8770, lr=4.81331e-05, gnorm=0.476, clip=10, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=21765
2022-10-10 15:58:47 - progress_bar.py[line:274] - INFO: epoch 001:   8793 / 57820 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=90.9, ups=0.82, wpb=111, bsz=40, num_updates=8780, lr=4.81286e-05, gnorm=0.399, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21777
2022-10-10 15:59:00 - progress_bar.py[line:274] - INFO: epoch 001:   8803 / 57820 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=85.9, ups=0.78, wpb=110, bsz=40, num_updates=8790, lr=4.81241e-05, gnorm=0.44, clip=0, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=21790
2022-10-10 15:59:12 - progress_bar.py[line:274] - INFO: epoch 001:   8813 / 57820 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90, ups=0.81, wpb=110.9, bsz=40, num_updates=8800, lr=4.81196e-05, gnorm=0.56, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21803
2022-10-10 15:59:24 - progress_bar.py[line:274] - INFO: epoch 001:   8823 / 57820 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=90.2, ups=0.83, wpb=109.3, bsz=40, num_updates=8810, lr=4.81151e-05, gnorm=0.536, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21815
2022-10-10 15:59:37 - progress_bar.py[line:274] - INFO: epoch 001:   8833 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.3, ups=0.79, wpb=110, bsz=40, num_updates=8820, lr=4.81106e-05, gnorm=0.547, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=21827
2022-10-10 15:59:49 - progress_bar.py[line:274] - INFO: epoch 001:   8843 / 57820 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=92.1, ups=0.84, wpb=109.2, bsz=40, num_updates=8830, lr=4.81061e-05, gnorm=0.504, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21839
2022-10-10 16:00:01 - progress_bar.py[line:274] - INFO: epoch 001:   8853 / 57820 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=90.5, ups=0.82, wpb=110.2, bsz=40, num_updates=8840, lr=4.81016e-05, gnorm=0.44, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21851
2022-10-10 16:00:13 - progress_bar.py[line:274] - INFO: epoch 001:   8863 / 57820 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=89, ups=0.81, wpb=110, bsz=40, num_updates=8850, lr=4.80971e-05, gnorm=0.543, clip=0, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=21864
2022-10-10 16:00:26 - progress_bar.py[line:274] - INFO: epoch 001:   8873 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.2, ups=0.78, wpb=109.5, bsz=40, num_updates=8860, lr=4.80926e-05, gnorm=0.495, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=21877
2022-10-10 16:00:39 - progress_bar.py[line:274] - INFO: epoch 001:   8883 / 57820 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.121, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=87.5, ups=0.8, wpb=109.7, bsz=40, num_updates=8870, lr=4.80881e-05, gnorm=0.47, clip=0, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=21889
2022-10-10 16:00:52 - progress_bar.py[line:274] - INFO: epoch 001:   8893 / 57820 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=85.7, ups=0.77, wpb=110.8, bsz=40, num_updates=8880, lr=4.80836e-05, gnorm=0.561, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=21902
2022-10-10 16:01:05 - progress_bar.py[line:274] - INFO: epoch 001:   8903 / 57820 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=82.3, ups=0.75, wpb=109.4, bsz=40, num_updates=8890, lr=4.80791e-05, gnorm=0.478, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=21915
2022-10-10 16:01:18 - progress_bar.py[line:274] - INFO: epoch 001:   8913 / 57820 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=83.9, ups=0.78, wpb=107.9, bsz=40, num_updates=8900, lr=4.80746e-05, gnorm=0.508, clip=0, loss_scale=512, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=21928
2022-10-10 16:01:30 - progress_bar.py[line:274] - INFO: epoch 001:   8923 / 57820 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=86.6, ups=0.79, wpb=109.7, bsz=40, num_updates=8910, lr=4.80701e-05, gnorm=0.602, clip=20, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=21941
2022-10-10 16:01:43 - progress_bar.py[line:274] - INFO: epoch 001:   8933 / 57820 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=88.5, ups=0.82, wpb=108.4, bsz=40, num_updates=8920, lr=4.80656e-05, gnorm=0.466, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21953
2022-10-10 16:01:56 - progress_bar.py[line:274] - INFO: epoch 001:   8943 / 57820 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=85.3, ups=0.78, wpb=109.2, bsz=40, num_updates=8930, lr=4.80611e-05, gnorm=0.614, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=21966
2022-10-10 16:02:08 - progress_bar.py[line:274] - INFO: epoch 001:   8953 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=86.1, ups=0.78, wpb=109.8, bsz=40, num_updates=8940, lr=4.80566e-05, gnorm=0.572, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=21979
2022-10-10 16:02:21 - progress_bar.py[line:274] - INFO: epoch 001:   8963 / 57820 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=86.8, ups=0.79, wpb=109.8, bsz=40, num_updates=8950, lr=4.80521e-05, gnorm=0.589, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=21991
2022-10-10 16:02:34 - progress_bar.py[line:274] - INFO: epoch 001:   8973 / 57820 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=82.8, ups=0.76, wpb=108.7, bsz=40, num_updates=8960, lr=4.80476e-05, gnorm=0.473, clip=0, loss_scale=512, train_wall=13, gb_free=11.1, ema_decay=0.9999, wall=22005
2022-10-10 16:02:47 - progress_bar.py[line:274] - INFO: epoch 001:   8983 / 57820 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=85.6, ups=0.78, wpb=109.7, bsz=40, num_updates=8970, lr=4.80431e-05, gnorm=0.547, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=22017
2022-10-10 16:02:59 - progress_bar.py[line:274] - INFO: epoch 001:   8993 / 57820 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.112, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=87.3, ups=0.79, wpb=109.8, bsz=40, num_updates=8980, lr=4.80386e-05, gnorm=0.39, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=22030
2022-10-10 16:03:13 - progress_bar.py[line:274] - INFO: epoch 001:   9003 / 57820 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=82.3, ups=0.76, wpb=108.5, bsz=40, num_updates=8990, lr=4.8034e-05, gnorm=0.541, clip=0, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=22043
2022-10-10 16:03:25 - progress_bar.py[line:274] - INFO: epoch 001:   9013 / 57820 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.5, ups=0.79, wpb=110.1, bsz=40, num_updates=9000, lr=4.80295e-05, gnorm=0.53, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=22056
2022-10-10 16:03:25 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-10 16:03:27 - train.py[line:549] - INFO: 0 / 4988
2022-10-10 16:03:27 - train.py[line:551] - INFO: load:1.42 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-10 16:06:27 - train.py[line:549] - INFO: 200 / 4988
2022-10-10 16:06:27 - train.py[line:551] - INFO: load:1.46 valid_run:180.39 task_valid:173.30 collect_output:5.03
2022-10-10 16:09:23 - train.py[line:549] - INFO: 400 / 4988
2022-10-10 16:09:23 - train.py[line:551] - INFO: load:1.52 valid_run:355.34 task_valid:339.55 collect_output:11.42
2022-10-10 16:12:22 - train.py[line:549] - INFO: 600 / 4988
2022-10-10 16:12:22 - train.py[line:551] - INFO: load:1.59 valid_run:534.94 task_valid:505.46 collect_output:22.80
2022-10-10 16:15:18 - train.py[line:549] - INFO: 800 / 4988
2022-10-10 16:15:18 - train.py[line:551] - INFO: load:1.63 valid_run:711.08 task_valid:670.87 collect_output:31.52
2022-10-10 16:18:16 - train.py[line:549] - INFO: 1000 / 4988
2022-10-10 16:18:16 - train.py[line:551] - INFO: load:1.69 valid_run:888.71 task_valid:839.07 collect_output:38.89
2022-10-10 16:21:14 - train.py[line:549] - INFO: 1200 / 4988
2022-10-10 16:21:14 - train.py[line:551] - INFO: load:1.73 valid_run:1066.56 task_valid:1006.57 collect_output:47.34
2022-10-10 16:24:15 - train.py[line:549] - INFO: 1400 / 4988
2022-10-10 16:24:15 - train.py[line:551] - INFO: load:1.76 valid_run:1247.13 task_valid:1176.75 collect_output:55.57
2022-10-10 16:27:12 - train.py[line:549] - INFO: 1600 / 4988
2022-10-10 16:27:12 - train.py[line:551] - INFO: load:1.85 valid_run:1424.00 task_valid:1341.90 collect_output:65.06
2022-10-10 16:30:08 - train.py[line:549] - INFO: 1800 / 4988
2022-10-10 16:30:08 - train.py[line:551] - INFO: load:1.91 valid_run:1599.59 task_valid:1507.07 collect_output:73.26
2022-10-10 16:33:01 - train.py[line:549] - INFO: 2000 / 4988
2022-10-10 16:33:01 - train.py[line:551] - INFO: load:2.01 valid_run:1773.19 task_valid:1672.63 collect_output:79.24
2022-10-10 16:36:03 - train.py[line:549] - INFO: 2200 / 4988
2022-10-10 16:36:03 - train.py[line:551] - INFO: load:2.13 valid_run:1954.45 task_valid:1844.38 collect_output:86.64
2022-10-10 16:39:04 - train.py[line:549] - INFO: 2400 / 4988
2022-10-10 16:39:04 - train.py[line:551] - INFO: load:2.17 valid_run:2135.64 task_valid:2015.71 collect_output:94.26
2022-10-10 16:42:10 - train.py[line:549] - INFO: 2600 / 4988
2022-10-10 16:42:10 - train.py[line:551] - INFO: load:2.22 valid_run:2321.93 task_valid:2193.18 collect_output:100.92
2022-10-10 16:45:16 - train.py[line:549] - INFO: 2800 / 4988
2022-10-10 16:45:16 - train.py[line:551] - INFO: load:2.30 valid_run:2506.95 task_valid:2368.66 collect_output:108.55
2022-10-10 16:48:19 - train.py[line:549] - INFO: 3000 / 4988
2022-10-10 16:48:19 - train.py[line:551] - INFO: load:2.39 valid_run:2690.15 task_valid:2544.19 collect_output:114.15
2022-10-10 16:51:15 - train.py[line:549] - INFO: 3200 / 4988
2022-10-10 16:51:15 - train.py[line:551] - INFO: load:2.47 valid_run:2866.37 task_valid:2711.23 collect_output:121.42
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 2815723
Killing subprocess 2815724
Main process received SIGINT, exiting
train_vqa_base_distributed-A100-node4-2.sh: line 176: a-decay=0.9999: command not found
