Traceback (most recent call last):
  File "../../train.py", line 443, in <module>
    open(os.path.join(script_path, f'../datasets/OFA_data/sgg/{split}/{template_prefix}_{name}_sample_st_ed_{img_cnt}.json')))
FileNotFoundError: [Errno 2] No such file or directory: '../../../datasets/OFA_data/sgg/1800_way/mask_val_sample_st_ed_1000.json'
Traceback (most recent call last):
  File "../../train.py", line 443, in <module>
    open(os.path.join(script_path, f'../datasets/OFA_data/sgg/{split}/{template_prefix}_{name}_sample_st_ed_{img_cnt}.json')))
FileNotFoundError: [Errno 2] No such file or directory: '../../../datasets/OFA_data/sgg/1800_way/mask_val_sample_st_ed_1000.json'
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_val_1000.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/1800_way_1000_val', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/1800_way_1000_val/1_B20_A1_E10_0.04_5e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--batch-size=20', '--batch-size-valid=96', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=5e-5', '--max-epoch=10', '--warmup-ratio=0.04', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=10', '--validate-interval-updates=10', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/1800_way_ans2label.pkl', '--valid-batch-size=51', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=beamsearch', '--num-workers=10']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 3142206
Killing subprocess 3142207
Traceback (most recent call last):
  File "../../train.py", line 443, in <module>
    open(os.path.join(script_path, f'../datasets/OFA_data/sgg/{split}/{template_prefix}_{name}_sample_st_ed_{img_cnt}.json')))
FileNotFoundError: [Errno 2] No such file or directory: '../../../datasets/OFA_data/sgg/1800_way/mask_val_sample_st_ed_1000.json'
Traceback (most recent call last):
  File "../../train.py", line 443, in <module>
    open(os.path.join(script_path, f'../datasets/OFA_data/sgg/{split}/{template_prefix}_{name}_sample_st_ed_{img_cnt}.json')))
FileNotFoundError: [Errno 2] No such file or directory: '../../../datasets/OFA_data/sgg/1800_way/mask_val_sample_st_ed_1000.json'
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_val_1000.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/1800_way_1000_val', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/1800_way_1000_val/1_B20_A1_E10_0.04_5e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--batch-size=20', '--batch-size-valid=96', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=5e-5', '--max-epoch=10', '--warmup-ratio=0.04', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=10', '--validate-interval-updates=10', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/1800_way_ans2label.pkl', '--valid-batch-size=51', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=beamsearch', '--num-workers=10']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 3143771
Killing subprocess 3143772
2022-09-27 10:51:38 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-09-27 10:51:38 - utils.py[line:261] - INFO: Start init
2022-09-27 10:51:38 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-09-27 10:51:38 - utils.py[line:261] - INFO: Start init
2022-09-27 10:51:39 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-09-27 10:51:39 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-09-27 10:51:39 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-09-27 10:51:39 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-09-27 10:51:43 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/1800_way_1000_val', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 10, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 10, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 96, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/1800_way_1000_val/1_B20_A1_E10_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 10, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/1800_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='96', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_val_1000.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=10, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=10, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/1800_way_1000_val/1_B20_A1_E10_0.04_5e-5_480', save_interval=10, save_interval_updates=10, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/1800_way_1000_val', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='beamsearch', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=10, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_val_1000.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/1800_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'beamsearch', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-09-27 10:51:43 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-09-27 10:51:43 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-09-27 10:51:48 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-09-27 10:51:48 - train.py[line:118] - INFO: task: VqaGenTask
2022-09-27 10:51:48 - train.py[line:119] - INFO: model: OFAModel
2022-09-27 10:51:48 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-09-27 10:51:48 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-09-27 10:51:48 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_val_1000.tsv slice_id 1 row count 225910 total row count 451820
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
file /data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_val_1000.tsv slice_id 0 row count 225910 total row count 451820
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-09-27 10:51:48 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-09-27 10:51:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-09-27 10:51:48 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-27 10:51:48 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-27 10:51:48 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-27 10:51:48 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-27 10:51:48 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-09-27 10:51:48 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-09-27 10:51:48 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2022-09-27 10:51:51 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-27 10:51:51 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-27 10:51:51 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-09-27 10:51:51 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-09-27 10:51:52 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-09-27 10:51:52 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E0.tsv slice_id 0 row count 858671 total row count 1717342
2022-09-27 10:51:53 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
file /data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E0.tsv slice_id 1 row count 858671 total row count 1717342
Total steps 429340, warmup steps 17173, warmup_factor 5.8230943923601e-05
2022-09-27 10:51:53 - trainer.py[line:707] - INFO: begin training epoch 1
2022-09-27 10:51:53 - train.py[line:312] - INFO: Start iterating over samples
Total steps 429340, warmup steps 17173, warmup_factor 5.8230943923601e-05
2022-09-27 10:52:08 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-09-27 10:52:13 - progress_bar.py[line:274] - INFO: epoch 001:     11 / 42934 loss=1.917, loss_v1=0, loss_v2=0, nll_loss=1.561, ntokens=105, nsentences=40, sample_size=105, sample_size_v1=0, sample_size_v2=0, ppl=2.95, wps=73.6, ups=0.7, wpb=105, bsz=40, num_updates=10, lr=2.91155e-08, gnorm=16.701, clip=100, loss_scale=64, train_wall=18, gb_free=9.8, ema_decay=0.9999, wall=25
2022-09-27 10:52:13 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-27 10:52:13 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-09-27 10:52:22 - train.py[line:549] - INFO: 0 / 2354
2022-09-27 10:52:22 - train.py[line:551] - INFO: load:6.48 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-27 10:56:20 - train.py[line:549] - INFO: 20 / 2354
2022-09-27 10:56:20 - train.py[line:551] - INFO: load:6.49 valid_run:237.54 task_valid:223.99 collect_output:13.24
2022-09-27 11:00:00 - train.py[line:549] - INFO: 40 / 2354
2022-09-27 11:00:00 - train.py[line:551] - INFO: load:6.49 valid_run:458.36 task_valid:443.75 collect_output:14.17
2022-09-27 11:03:35 - train.py[line:549] - INFO: 60 / 2354
2022-09-27 11:03:35 - train.py[line:551] - INFO: load:6.50 valid_run:672.58 task_valid:652.99 collect_output:19.01
2022-09-27 11:07:07 - train.py[line:549] - INFO: 80 / 2354
2022-09-27 11:07:07 - train.py[line:551] - INFO: load:6.51 valid_run:884.96 task_valid:863.72 collect_output:20.53
2022-09-27 11:11:15 - train.py[line:549] - INFO: 100 / 2354
2022-09-27 11:11:15 - train.py[line:551] - INFO: load:6.51 valid_run:1132.46 task_valid:1106.71 collect_output:24.90
2022-09-27 11:14:52 - train.py[line:549] - INFO: 120 / 2354
2022-09-27 11:14:52 - train.py[line:551] - INFO: load:6.52 valid_run:1349.52 task_valid:1323.55 collect_output:24.99
2022-09-27 11:18:22 - train.py[line:549] - INFO: 140 / 2354
2022-09-27 11:18:22 - train.py[line:551] - INFO: load:6.53 valid_run:1560.09 task_valid:1531.63 collect_output:27.35
2022-09-27 11:21:53 - train.py[line:549] - INFO: 160 / 2354
2022-09-27 11:21:53 - train.py[line:551] - INFO: load:6.54 valid_run:1771.16 task_valid:1733.91 collect_output:36.01
2022-09-27 11:25:30 - train.py[line:549] - INFO: 180 / 2354
2022-09-27 11:25:30 - train.py[line:551] - INFO: load:6.54 valid_run:1987.78 task_valid:1941.56 collect_output:44.84
2022-09-27 11:29:14 - train.py[line:549] - INFO: 200 / 2354
2022-09-27 11:29:14 - train.py[line:551] - INFO: load:6.55 valid_run:2211.77 task_valid:2146.90 collect_output:63.36
2022-09-27 11:32:38 - train.py[line:549] - INFO: 220 / 2354
2022-09-27 11:32:38 - train.py[line:551] - INFO: load:6.56 valid_run:2415.47 task_valid:2340.22 collect_output:73.61
2022-09-27 11:36:07 - train.py[line:549] - INFO: 240 / 2354
2022-09-27 11:36:07 - train.py[line:551] - INFO: load:6.57 valid_run:2625.18 task_valid:2534.19 collect_output:89.18
2022-09-27 11:39:43 - train.py[line:549] - INFO: 260 / 2354
2022-09-27 11:39:43 - train.py[line:551] - INFO: load:6.58 valid_run:2841.27 task_valid:2748.05 collect_output:91.25
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 3162027
Killing subprocess 3162028
Main process received SIGINT, exiting
2022-09-27 11:40:01 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-09-27 11:40:01 - utils.py[line:261] - INFO: Start init
2022-09-27 11:40:01 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-09-27 11:40:01 - utils.py[line:261] - INFO: Start init
2022-09-27 11:40:02 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-09-27 11:40:02 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-09-27 11:40:02 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-09-27 11:40:02 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-09-27 11:40:09 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/1800_way_1000_val', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 10, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 10000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 96, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/1800_way_1000_val/1_B20_A1_E10_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 10000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/1800_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='96', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_val_1000.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=10, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=10, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/1800_way_1000_val/1_B20_A1_E10_0.04_5e-5_480', save_interval=10, save_interval_updates=10000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/1800_way_1000_val', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='beamsearch', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=10000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_val_1000.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/1800_way/1800_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'beamsearch', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-09-27 11:40:09 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-09-27 11:40:09 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-09-27 11:40:14 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-09-27 11:40:14 - train.py[line:118] - INFO: task: VqaGenTask
2022-09-27 11:40:14 - train.py[line:119] - INFO: model: OFAModel
2022-09-27 11:40:14 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-09-27 11:40:14 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-09-27 11:40:14 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_val_1000.tsv slice_id 0 row count 225910 total row count 451820
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-09-27 11:40:15 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
file /data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_val_1000.tsv slice_id 1 row count 225910 total row count 451820
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-09-27 11:40:16 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-09-27 11:40:16 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-27 11:40:16 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-27 11:40:16 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-27 11:40:16 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-27 11:40:16 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-09-27 11:40:16 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-09-27 11:40:16 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2022-09-27 11:40:19 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-27 11:40:19 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-27 11:40:19 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-09-27 11:40:19 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-09-27 11:40:19 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-09-27 11:40:19 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E0.tsv slice_id 0 row count 858671 total row count 1717342
file /data/private/yutianyu/datasets/OFA_data/sgg/1800_way/mask_train_NA1_E0.tsv slice_id 1 row count 858671 total row count 1717342
2022-09-27 11:40:21 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 429340, warmup steps 17173, warmup_factor 5.8230943923601e-05
2022-09-27 11:40:21 - trainer.py[line:707] - INFO: begin training epoch 1
2022-09-27 11:40:21 - train.py[line:312] - INFO: Start iterating over samples
Total steps 429340, warmup steps 17173, warmup_factor 5.8230943923601e-05
2022-09-27 11:40:38 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-09-27 11:40:44 - progress_bar.py[line:274] - INFO: epoch 001:     11 / 42934 loss=1.917, loss_v1=0, loss_v2=0, nll_loss=1.561, ntokens=105, nsentences=40, sample_size=105, sample_size_v1=0, sample_size_v2=0, ppl=2.95, wps=75, ups=0.71, wpb=105, bsz=40, num_updates=10, lr=2.91155e-08, gnorm=16.682, clip=100, loss_scale=64, train_wall=17, gb_free=9.8, ema_decay=0.9999, wall=28
2022-09-27 11:40:56 - progress_bar.py[line:274] - INFO: epoch 001:     21 / 42934 loss=1.907, loss_v1=0, loss_v2=0, nll_loss=1.54, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=2.91, wps=85.5, ups=0.82, wpb=104.1, bsz=40, num_updates=20, lr=5.82309e-08, gnorm=16.25, clip=100, loss_scale=64, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=40
2022-09-27 11:41:08 - progress_bar.py[line:274] - INFO: epoch 001:     31 / 42934 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=1.722, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=3.3, wps=86, ups=0.84, wpb=102.7, bsz=40, num_updates=30, lr=8.73464e-08, gnorm=17.966, clip=100, loss_scale=64, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=52
2022-09-27 11:41:20 - progress_bar.py[line:274] - INFO: epoch 001:     41 / 42934 loss=2.012, loss_v1=0, loss_v2=0, nll_loss=1.636, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=3.11, wps=84, ups=0.82, wpb=102.3, bsz=40, num_updates=40, lr=1.16462e-07, gnorm=18.028, clip=100, loss_scale=64, train_wall=12, gb_free=10, ema_decay=0.9999, wall=64
2022-09-27 11:41:32 - progress_bar.py[line:274] - INFO: epoch 001:     51 / 42934 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=1.798, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=3.48, wps=90.8, ups=0.88, wpb=103.1, bsz=40, num_updates=50, lr=1.45577e-07, gnorm=19.809, clip=100, loss_scale=64, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=76
2022-09-27 11:41:43 - progress_bar.py[line:274] - INFO: epoch 001:     61 / 42934 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=1.659, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=3.16, wps=90.3, ups=0.88, wpb=102.9, bsz=40, num_updates=60, lr=1.74693e-07, gnorm=17.148, clip=100, loss_scale=64, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=87
2022-09-27 11:41:55 - progress_bar.py[line:274] - INFO: epoch 001:     71 / 42934 loss=1.981, loss_v1=0, loss_v2=0, nll_loss=1.608, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=3.05, wps=89.6, ups=0.87, wpb=102.5, bsz=40, num_updates=70, lr=2.03808e-07, gnorm=17.918, clip=100, loss_scale=64, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=99
2022-09-27 11:42:06 - progress_bar.py[line:274] - INFO: epoch 001:     81 / 42934 loss=2.003, loss_v1=0, loss_v2=0, nll_loss=1.629, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=3.09, wps=88.8, ups=0.86, wpb=103, bsz=40, num_updates=80, lr=2.32924e-07, gnorm=17.743, clip=100, loss_scale=64, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=110
2022-09-27 11:42:18 - progress_bar.py[line:274] - INFO: epoch 001:     91 / 42934 loss=1.991, loss_v1=0, loss_v2=0, nll_loss=1.634, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=3.1, wps=87.5, ups=0.85, wpb=103.5, bsz=40, num_updates=90, lr=2.62039e-07, gnorm=16.913, clip=100, loss_scale=64, train_wall=12, gb_free=8.4, ema_decay=0.9999, wall=122
2022-09-27 11:42:29 - progress_bar.py[line:274] - INFO: epoch 001:    101 / 42934 loss=1.919, loss_v1=0, loss_v2=0, nll_loss=1.552, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=2.93, wps=90.3, ups=0.88, wpb=102.8, bsz=40, num_updates=100, lr=2.91155e-07, gnorm=16.779, clip=100, loss_scale=64, train_wall=11, gb_free=8.6, ema_decay=0.9999, wall=133
2022-09-27 11:42:41 - progress_bar.py[line:274] - INFO: epoch 001:    111 / 42934 loss=1.831, loss_v1=0, loss_v2=0, nll_loss=1.458, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=87.3, ups=0.84, wpb=103.5, bsz=40, num_updates=110, lr=3.2027e-07, gnorm=14.463, clip=100, loss_scale=64, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=145
2022-09-27 11:42:53 - progress_bar.py[line:274] - INFO: epoch 001:    121 / 42934 loss=1.872, loss_v1=0, loss_v2=0, nll_loss=1.498, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=89.5, ups=0.87, wpb=102.9, bsz=40, num_updates=120, lr=3.49386e-07, gnorm=13.971, clip=100, loss_scale=64, train_wall=11, gb_free=8.3, ema_decay=0.9999, wall=157
2022-09-27 11:43:05 - progress_bar.py[line:274] - INFO: epoch 001:    131 / 42934 loss=1.81, loss_v1=0, loss_v2=0, nll_loss=1.445, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=82.3, ups=0.8, wpb=102.7, bsz=40, num_updates=130, lr=3.78501e-07, gnorm=12.96, clip=100, loss_scale=64, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=169
2022-09-27 11:43:17 - progress_bar.py[line:274] - INFO: epoch 001:    141 / 42934 loss=1.643, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=104.9, nsentences=40, sample_size=104.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=92.1, ups=0.88, wpb=104.9, bsz=40, num_updates=140, lr=4.07617e-07, gnorm=11.235, clip=100, loss_scale=64, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=181
2022-09-27 11:43:28 - progress_bar.py[line:274] - INFO: epoch 001:    151 / 42934 loss=1.743, loss_v1=0, loss_v2=0, nll_loss=1.374, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=85.3, ups=0.84, wpb=101.1, bsz=40, num_updates=150, lr=4.36732e-07, gnorm=11.501, clip=100, loss_scale=64, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=193
2022-09-27 11:43:41 - progress_bar.py[line:274] - INFO: epoch 001:    161 / 42934 loss=1.614, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=83.3, ups=0.8, wpb=104, bsz=40, num_updates=160, lr=4.65848e-07, gnorm=9.436, clip=100, loss_scale=64, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=205
2022-09-27 11:43:53 - progress_bar.py[line:274] - INFO: epoch 001:    171 / 42934 loss=1.635, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=86.2, ups=0.84, wpb=102.1, bsz=40, num_updates=170, lr=4.94963e-07, gnorm=9.546, clip=100, loss_scale=64, train_wall=12, gb_free=5.3, ema_decay=0.9999, wall=217
2022-09-27 11:44:04 - progress_bar.py[line:274] - INFO: epoch 001:    181 / 42934 loss=1.603, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=89, ups=0.86, wpb=102.9, bsz=40, num_updates=180, lr=5.24078e-07, gnorm=8.201, clip=100, loss_scale=64, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=228
2022-09-27 11:44:16 - progress_bar.py[line:274] - INFO: epoch 001:    191 / 42934 loss=1.623, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=87.7, ups=0.86, wpb=101.7, bsz=40, num_updates=190, lr=5.53194e-07, gnorm=8.403, clip=100, loss_scale=64, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=240
2022-09-27 11:44:29 - progress_bar.py[line:274] - INFO: epoch 001:    201 / 42934 loss=1.578, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=81.9, ups=0.8, wpb=102.5, bsz=40, num_updates=200, lr=5.82309e-07, gnorm=7.651, clip=100, loss_scale=64, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=253
2022-09-27 11:44:40 - progress_bar.py[line:274] - INFO: epoch 001:    211 / 42934 loss=1.567, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=87.7, ups=0.85, wpb=102.7, bsz=40, num_updates=210, lr=6.11425e-07, gnorm=7.631, clip=100, loss_scale=64, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=264
2022-09-27 11:44:52 - progress_bar.py[line:274] - INFO: epoch 001:    221 / 42934 loss=1.571, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=88.3, ups=0.87, wpb=101.7, bsz=40, num_updates=220, lr=6.4054e-07, gnorm=6.912, clip=100, loss_scale=64, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=276
2022-09-27 11:45:03 - progress_bar.py[line:274] - INFO: epoch 001:    231 / 42934 loss=1.478, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=89.4, ups=0.86, wpb=103.8, bsz=40, num_updates=230, lr=6.69656e-07, gnorm=6.352, clip=100, loss_scale=64, train_wall=12, gb_free=8.9, ema_decay=0.9999, wall=287
2022-09-27 11:45:15 - progress_bar.py[line:274] - INFO: epoch 001:    241 / 42934 loss=1.572, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=88.3, ups=0.87, wpb=101.5, bsz=40, num_updates=240, lr=6.98771e-07, gnorm=6.632, clip=100, loss_scale=64, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=299
2022-09-27 11:45:26 - progress_bar.py[line:274] - INFO: epoch 001:    251 / 42934 loss=1.436, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=92.4, ups=0.88, wpb=104.4, bsz=40, num_updates=250, lr=7.27887e-07, gnorm=6.233, clip=100, loss_scale=64, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=310
2022-09-27 11:45:38 - progress_bar.py[line:274] - INFO: epoch 001:    261 / 42934 loss=1.471, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=90.5, ups=0.87, wpb=104.1, bsz=40, num_updates=260, lr=7.57002e-07, gnorm=5.822, clip=100, loss_scale=64, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=322
2022-09-27 11:45:49 - progress_bar.py[line:274] - INFO: epoch 001:    271 / 42934 loss=1.458, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=91.1, ups=0.88, wpb=103.7, bsz=40, num_updates=270, lr=7.86118e-07, gnorm=6.241, clip=100, loss_scale=64, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=333
2022-09-27 11:46:01 - progress_bar.py[line:274] - INFO: epoch 001:    281 / 42934 loss=1.501, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=85.7, ups=0.86, wpb=99.8, bsz=40, num_updates=280, lr=8.15233e-07, gnorm=5.991, clip=100, loss_scale=64, train_wall=12, gb_free=9.1, ema_decay=0.9999, wall=345
2022-09-27 11:46:13 - progress_bar.py[line:274] - INFO: epoch 001:    291 / 42934 loss=1.516, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=87.2, ups=0.85, wpb=103.2, bsz=40, num_updates=290, lr=8.44349e-07, gnorm=5.869, clip=100, loss_scale=64, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=357
2022-09-27 11:46:24 - progress_bar.py[line:274] - INFO: epoch 001:    301 / 42934 loss=1.393, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=91.8, ups=0.89, wpb=103.1, bsz=40, num_updates=300, lr=8.73464e-07, gnorm=4.973, clip=100, loss_scale=64, train_wall=11, gb_free=10, ema_decay=0.9999, wall=368
2022-09-27 11:46:35 - progress_bar.py[line:274] - INFO: epoch 001:    311 / 42934 loss=1.364, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=104.9, nsentences=40, sample_size=104.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=91.5, ups=0.87, wpb=104.9, bsz=40, num_updates=310, lr=9.0258e-07, gnorm=4.675, clip=100, loss_scale=64, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=379
2022-09-27 11:46:48 - progress_bar.py[line:274] - INFO: epoch 001:    321 / 42934 loss=1.479, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=87.7, ups=0.86, wpb=101.9, bsz=40, num_updates=320, lr=9.31695e-07, gnorm=5.373, clip=100, loss_scale=64, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=391
2022-09-27 11:47:00 - progress_bar.py[line:274] - INFO: epoch 001:    331 / 42934 loss=1.324, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=90.4, ups=0.88, wpb=103, bsz=40, num_updates=330, lr=9.60811e-07, gnorm=4.959, clip=100, loss_scale=64, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=404
2022-09-27 11:47:11 - progress_bar.py[line:274] - INFO: epoch 001:    341 / 42934 loss=1.322, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=92.6, ups=0.89, wpb=103.6, bsz=40, num_updates=340, lr=9.89926e-07, gnorm=4.486, clip=100, loss_scale=64, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=415
2022-09-27 11:47:22 - progress_bar.py[line:274] - INFO: epoch 001:    351 / 42934 loss=1.414, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=89.5, ups=0.87, wpb=102.9, bsz=40, num_updates=350, lr=1.01904e-06, gnorm=4.702, clip=100, loss_scale=64, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=426
2022-09-27 11:47:34 - progress_bar.py[line:274] - INFO: epoch 001:    361 / 42934 loss=1.322, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=89.1, ups=0.87, wpb=102.5, bsz=40, num_updates=360, lr=1.04816e-06, gnorm=4.352, clip=100, loss_scale=64, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=438
2022-09-27 11:47:45 - progress_bar.py[line:274] - INFO: epoch 001:    371 / 42934 loss=1.267, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=90.2, ups=0.86, wpb=104.3, bsz=40, num_updates=370, lr=1.07727e-06, gnorm=4.094, clip=100, loss_scale=64, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=449
2022-09-27 11:47:57 - progress_bar.py[line:274] - INFO: epoch 001:    381 / 42934 loss=1.369, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=87.2, ups=0.85, wpb=102.4, bsz=40, num_updates=380, lr=1.10639e-06, gnorm=4.387, clip=100, loss_scale=64, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=461
2022-09-27 11:48:09 - progress_bar.py[line:274] - INFO: epoch 001:    391 / 42934 loss=1.28, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=89.6, ups=0.87, wpb=103.4, bsz=40, num_updates=390, lr=1.1355e-06, gnorm=4.102, clip=100, loss_scale=64, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=473
2022-09-27 11:48:20 - progress_bar.py[line:274] - INFO: epoch 001:    401 / 42934 loss=1.324, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=90.3, ups=0.88, wpb=102.6, bsz=40, num_updates=400, lr=1.16462e-06, gnorm=4.223, clip=100, loss_scale=64, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=484
2022-09-27 11:48:31 - progress_bar.py[line:274] - INFO: epoch 001:    411 / 42934 loss=1.272, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=92.5, ups=0.89, wpb=103.6, bsz=40, num_updates=410, lr=1.19373e-06, gnorm=4.125, clip=100, loss_scale=64, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=495
2022-09-27 11:48:43 - progress_bar.py[line:274] - INFO: epoch 001:    421 / 42934 loss=1.394, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=86.4, ups=0.85, wpb=101.4, bsz=40, num_updates=420, lr=1.22285e-06, gnorm=4.111, clip=100, loss_scale=64, train_wall=12, gb_free=8.8, ema_decay=0.9999, wall=507
2022-09-27 11:48:55 - progress_bar.py[line:274] - INFO: epoch 001:    431 / 42934 loss=1.33, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=86.7, ups=0.84, wpb=102.8, bsz=40, num_updates=430, lr=1.25197e-06, gnorm=4.063, clip=100, loss_scale=64, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=519
2022-09-27 11:49:06 - progress_bar.py[line:274] - INFO: epoch 001:    441 / 42934 loss=1.34, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=440, lr=1.28108e-06, gnorm=3.749, clip=100, loss_scale=64, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=530
2022-09-27 11:49:18 - progress_bar.py[line:274] - INFO: epoch 001:    451 / 42934 loss=1.252, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=90.7, ups=0.88, wpb=103.4, bsz=40, num_updates=450, lr=1.3102e-06, gnorm=3.699, clip=100, loss_scale=64, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=542
2022-09-27 11:49:29 - progress_bar.py[line:274] - INFO: epoch 001:    461 / 42934 loss=1.283, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=88.6, ups=0.87, wpb=102, bsz=40, num_updates=460, lr=1.33931e-06, gnorm=3.938, clip=100, loss_scale=64, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=553
2022-09-27 11:49:40 - progress_bar.py[line:274] - INFO: epoch 001:    471 / 42934 loss=1.26, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=91.1, ups=0.88, wpb=103.8, bsz=40, num_updates=470, lr=1.36843e-06, gnorm=3.502, clip=100, loss_scale=64, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=564
2022-09-27 11:49:52 - progress_bar.py[line:274] - INFO: epoch 001:    481 / 42934 loss=1.267, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=90.2, ups=0.88, wpb=102.7, bsz=40, num_updates=480, lr=1.39754e-06, gnorm=3.583, clip=100, loss_scale=64, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=576
2022-09-27 11:50:03 - progress_bar.py[line:274] - INFO: epoch 001:    491 / 42934 loss=1.326, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=89, ups=0.87, wpb=101.9, bsz=40, num_updates=490, lr=1.42666e-06, gnorm=3.667, clip=100, loss_scale=64, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=587
2022-09-27 11:50:15 - progress_bar.py[line:274] - INFO: epoch 001:    501 / 42934 loss=1.304, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=90.6, ups=0.89, wpb=102.2, bsz=40, num_updates=500, lr=1.45577e-06, gnorm=3.703, clip=100, loss_scale=64, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=599
2022-09-27 11:50:26 - progress_bar.py[line:274] - INFO: epoch 001:    511 / 42934 loss=1.294, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=88.5, ups=0.86, wpb=103.4, bsz=40, num_updates=510, lr=1.48489e-06, gnorm=3.591, clip=100, loss_scale=64, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=610
2022-09-27 11:50:38 - progress_bar.py[line:274] - INFO: epoch 001:    521 / 42934 loss=1.246, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=87.8, ups=0.85, wpb=103.2, bsz=40, num_updates=520, lr=1.514e-06, gnorm=3.715, clip=100, loss_scale=128, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=622
2022-09-27 11:50:49 - progress_bar.py[line:274] - INFO: epoch 001:    531 / 42934 loss=1.345, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=88.7, ups=0.87, wpb=101.5, bsz=40, num_updates=530, lr=1.54312e-06, gnorm=3.552, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=634
2022-09-27 11:51:01 - progress_bar.py[line:274] - INFO: epoch 001:    541 / 42934 loss=1.267, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=90.8, ups=0.88, wpb=102.8, bsz=40, num_updates=540, lr=1.57224e-06, gnorm=3.405, clip=100, loss_scale=128, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=645
2022-09-27 11:51:12 - progress_bar.py[line:274] - INFO: epoch 001:    551 / 42934 loss=1.27, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=87.8, ups=0.86, wpb=102.3, bsz=40, num_updates=550, lr=1.60135e-06, gnorm=3.133, clip=100, loss_scale=128, train_wall=12, gb_free=10, ema_decay=0.9999, wall=657
2022-09-27 11:51:24 - progress_bar.py[line:274] - INFO: epoch 001:    561 / 42934 loss=1.216, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=91.3, ups=0.87, wpb=104.5, bsz=40, num_updates=560, lr=1.63047e-06, gnorm=3.303, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=668
2022-09-27 11:51:36 - progress_bar.py[line:274] - INFO: epoch 001:    571 / 42934 loss=1.344, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=87.2, ups=0.86, wpb=101.6, bsz=40, num_updates=570, lr=1.65958e-06, gnorm=3.288, clip=100, loss_scale=128, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=680
2022-09-27 11:51:47 - progress_bar.py[line:274] - INFO: epoch 001:    581 / 42934 loss=1.267, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=104.9, nsentences=40, sample_size=104.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=91.4, ups=0.87, wpb=104.9, bsz=40, num_updates=580, lr=1.6887e-06, gnorm=3.234, clip=100, loss_scale=128, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=691
2022-09-27 11:51:59 - progress_bar.py[line:274] - INFO: epoch 001:    591 / 42934 loss=1.262, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=88.7, ups=0.87, wpb=102.3, bsz=40, num_updates=590, lr=1.71781e-06, gnorm=3.119, clip=100, loss_scale=128, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=703
2022-09-27 11:52:10 - progress_bar.py[line:274] - INFO: epoch 001:    601 / 42934 loss=1.38, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=90.4, ups=0.9, wpb=100.8, bsz=40, num_updates=600, lr=1.74693e-06, gnorm=3.678, clip=100, loss_scale=128, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=714
2022-09-27 11:52:21 - progress_bar.py[line:274] - INFO: epoch 001:    611 / 42934 loss=1.266, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=92.2, ups=0.9, wpb=102, bsz=40, num_updates=610, lr=1.77604e-06, gnorm=2.94, clip=100, loss_scale=128, train_wall=11, gb_free=8.3, ema_decay=0.9999, wall=725
2022-09-27 11:52:32 - progress_bar.py[line:274] - INFO: epoch 001:    621 / 42934 loss=1.25, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=92.1, ups=0.88, wpb=104.2, bsz=40, num_updates=620, lr=1.80516e-06, gnorm=3.089, clip=100, loss_scale=128, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=736
2022-09-27 11:52:44 - progress_bar.py[line:274] - INFO: epoch 001:    631 / 42934 loss=1.237, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=90, ups=0.87, wpb=103.9, bsz=40, num_updates=630, lr=1.83427e-06, gnorm=3.119, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=748
2022-09-27 11:52:55 - progress_bar.py[line:274] - INFO: epoch 001:    641 / 42934 loss=1.305, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=89.1, ups=0.87, wpb=101.9, bsz=40, num_updates=640, lr=1.86339e-06, gnorm=2.937, clip=100, loss_scale=128, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=759
2022-09-27 11:53:07 - progress_bar.py[line:274] - INFO: epoch 001:    651 / 42934 loss=1.264, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=88.9, ups=0.87, wpb=102.1, bsz=40, num_updates=650, lr=1.89251e-06, gnorm=3.076, clip=100, loss_scale=128, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=771
2022-09-27 11:53:18 - progress_bar.py[line:274] - INFO: epoch 001:    661 / 42934 loss=1.22, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=90.3, ups=0.88, wpb=102.6, bsz=40, num_updates=660, lr=1.92162e-06, gnorm=3.05, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=782
2022-09-27 11:53:30 - progress_bar.py[line:274] - INFO: epoch 001:    671 / 42934 loss=1.243, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=88.3, ups=0.87, wpb=101.9, bsz=40, num_updates=670, lr=1.95074e-06, gnorm=3.145, clip=100, loss_scale=128, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=794
2022-09-27 11:53:41 - progress_bar.py[line:274] - INFO: epoch 001:    681 / 42934 loss=1.314, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=680, lr=1.97985e-06, gnorm=3.089, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=805
2022-09-27 11:53:53 - progress_bar.py[line:274] - INFO: epoch 001:    691 / 42934 loss=1.295, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=84, ups=0.82, wpb=102.1, bsz=40, num_updates=690, lr=2.00897e-06, gnorm=3.154, clip=100, loss_scale=128, train_wall=12, gb_free=9.1, ema_decay=0.9999, wall=817
2022-09-27 11:54:05 - progress_bar.py[line:274] - INFO: epoch 001:    701 / 42934 loss=1.237, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=83, ups=0.81, wpb=102.4, bsz=40, num_updates=700, lr=2.03808e-06, gnorm=3.027, clip=100, loss_scale=128, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=829
2022-09-27 11:54:17 - progress_bar.py[line:274] - INFO: epoch 001:    711 / 42934 loss=1.322, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=88.2, ups=0.86, wpb=102.6, bsz=40, num_updates=710, lr=2.0672e-06, gnorm=3.234, clip=100, loss_scale=128, train_wall=12, gb_free=7.4, ema_decay=0.9999, wall=841
2022-09-27 11:54:29 - progress_bar.py[line:274] - INFO: epoch 001:    721 / 42934 loss=1.224, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=86.6, ups=0.85, wpb=101.7, bsz=40, num_updates=720, lr=2.09631e-06, gnorm=2.981, clip=100, loss_scale=128, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=853
2022-09-27 11:54:40 - progress_bar.py[line:274] - INFO: epoch 001:    731 / 42934 loss=1.331, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=89.5, ups=0.87, wpb=102.6, bsz=40, num_updates=730, lr=2.12543e-06, gnorm=3.314, clip=100, loss_scale=128, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=864
2022-09-27 11:54:52 - progress_bar.py[line:274] - INFO: epoch 001:    741 / 42934 loss=1.19, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=89.9, ups=0.87, wpb=103.2, bsz=40, num_updates=740, lr=2.15454e-06, gnorm=2.948, clip=100, loss_scale=128, train_wall=11, gb_free=8, ema_decay=0.9999, wall=876
2022-09-27 11:55:03 - progress_bar.py[line:274] - INFO: epoch 001:    751 / 42934 loss=1.278, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=92.9, ups=0.9, wpb=103.5, bsz=40, num_updates=750, lr=2.18366e-06, gnorm=3.235, clip=100, loss_scale=128, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=887
2022-09-27 11:55:14 - progress_bar.py[line:274] - INFO: epoch 001:    761 / 42934 loss=1.326, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=88.9, ups=0.88, wpb=101.1, bsz=40, num_updates=760, lr=2.21278e-06, gnorm=3.241, clip=100, loss_scale=128, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=898
2022-09-27 11:55:26 - progress_bar.py[line:274] - INFO: epoch 001:    771 / 42934 loss=1.195, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=90.4, ups=0.87, wpb=103.6, bsz=40, num_updates=770, lr=2.24189e-06, gnorm=3.206, clip=100, loss_scale=128, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=910
2022-09-27 11:55:37 - progress_bar.py[line:274] - INFO: epoch 001:    781 / 42934 loss=1.25, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=93.3, ups=0.91, wpb=102.3, bsz=40, num_updates=780, lr=2.27101e-06, gnorm=3.165, clip=100, loss_scale=128, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=921
2022-09-27 11:55:48 - progress_bar.py[line:274] - INFO: epoch 001:    791 / 42934 loss=1.206, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=93.3, ups=0.9, wpb=104.1, bsz=40, num_updates=790, lr=2.30012e-06, gnorm=2.835, clip=100, loss_scale=128, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=932
2022-09-27 11:55:59 - progress_bar.py[line:274] - INFO: epoch 001:    801 / 42934 loss=1.198, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=91.7, ups=0.88, wpb=104.4, bsz=40, num_updates=800, lr=2.32924e-06, gnorm=2.815, clip=100, loss_scale=128, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=943
2022-09-27 11:56:11 - progress_bar.py[line:274] - INFO: epoch 001:    811 / 42934 loss=1.179, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=90.4, ups=0.87, wpb=103.6, bsz=40, num_updates=810, lr=2.35835e-06, gnorm=2.802, clip=100, loss_scale=128, train_wall=11, gb_free=10, ema_decay=0.9999, wall=955
2022-09-27 11:56:22 - progress_bar.py[line:274] - INFO: epoch 001:    821 / 42934 loss=1.25, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=88.4, ups=0.87, wpb=102.1, bsz=40, num_updates=820, lr=2.38747e-06, gnorm=3.186, clip=100, loss_scale=128, train_wall=11, gb_free=8.1, ema_decay=0.9999, wall=966
2022-09-27 11:56:34 - progress_bar.py[line:274] - INFO: epoch 001:    831 / 42934 loss=1.198, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=91.3, ups=0.88, wpb=103.9, bsz=40, num_updates=830, lr=2.41658e-06, gnorm=3.085, clip=100, loss_scale=128, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=978
2022-09-27 11:56:45 - progress_bar.py[line:274] - INFO: epoch 001:    841 / 42934 loss=1.257, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=87.4, ups=0.87, wpb=100.3, bsz=40, num_updates=840, lr=2.4457e-06, gnorm=3.232, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=989
2022-09-27 11:56:57 - progress_bar.py[line:274] - INFO: epoch 001:    851 / 42934 loss=1.202, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=88.9, ups=0.86, wpb=103.6, bsz=40, num_updates=850, lr=2.47482e-06, gnorm=2.825, clip=100, loss_scale=128, train_wall=12, gb_free=9.1, ema_decay=0.9999, wall=1001
2022-09-27 11:57:08 - progress_bar.py[line:274] - INFO: epoch 001:    861 / 42934 loss=1.208, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=89.2, ups=0.88, wpb=101.5, bsz=40, num_updates=860, lr=2.50393e-06, gnorm=2.987, clip=100, loss_scale=128, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=1012
2022-09-27 11:57:19 - progress_bar.py[line:274] - INFO: epoch 001:    871 / 42934 loss=1.249, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=90.8, ups=0.88, wpb=102.6, bsz=40, num_updates=870, lr=2.53305e-06, gnorm=3.013, clip=100, loss_scale=128, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=1024
2022-09-27 11:57:31 - progress_bar.py[line:274] - INFO: epoch 001:    881 / 42934 loss=1.187, loss_v1=0, loss_v2=0, nll_loss=0.828, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=86.7, ups=0.85, wpb=101.7, bsz=40, num_updates=880, lr=2.56216e-06, gnorm=2.903, clip=100, loss_scale=128, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=1035
2022-09-27 11:57:42 - progress_bar.py[line:274] - INFO: epoch 001:    891 / 42934 loss=1.194, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=90.9, ups=0.89, wpb=101.6, bsz=40, num_updates=890, lr=2.59128e-06, gnorm=3.003, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=1047
2022-09-27 11:57:54 - progress_bar.py[line:274] - INFO: epoch 001:    901 / 42934 loss=1.222, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=86.9, ups=0.85, wpb=102.5, bsz=40, num_updates=900, lr=2.62039e-06, gnorm=2.969, clip=100, loss_scale=128, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=1058
2022-09-27 11:58:06 - progress_bar.py[line:274] - INFO: epoch 001:    911 / 42934 loss=1.196, loss_v1=0, loss_v2=0, nll_loss=0.835, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=89.2, ups=0.88, wpb=101.4, bsz=40, num_updates=910, lr=2.64951e-06, gnorm=3.052, clip=100, loss_scale=128, train_wall=11, gb_free=8.9, ema_decay=0.9999, wall=1070
2022-09-27 11:58:17 - progress_bar.py[line:274] - INFO: epoch 001:    921 / 42934 loss=1.162, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=93, ups=0.89, wpb=104.1, bsz=40, num_updates=920, lr=2.67862e-06, gnorm=3.076, clip=100, loss_scale=128, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=1081
2022-09-27 11:58:28 - progress_bar.py[line:274] - INFO: epoch 001:    931 / 42934 loss=1.227, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=90.5, ups=0.87, wpb=103.8, bsz=40, num_updates=930, lr=2.70774e-06, gnorm=3.183, clip=100, loss_scale=128, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=1092
2022-09-27 11:58:40 - progress_bar.py[line:274] - INFO: epoch 001:    941 / 42934 loss=1.204, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=104.6, nsentences=40, sample_size=104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=92, ups=0.88, wpb=104.6, bsz=40, num_updates=940, lr=2.73685e-06, gnorm=3.063, clip=100, loss_scale=128, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=1104
2022-09-27 11:58:51 - progress_bar.py[line:274] - INFO: epoch 001:    951 / 42934 loss=1.168, loss_v1=0, loss_v2=0, nll_loss=0.817, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=88.5, ups=0.87, wpb=102.1, bsz=40, num_updates=950, lr=2.76597e-06, gnorm=3.058, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=1115
2022-09-27 11:59:03 - progress_bar.py[line:274] - INFO: epoch 001:    961 / 42934 loss=1.156, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=89.3, ups=0.86, wpb=103.8, bsz=40, num_updates=960, lr=2.79509e-06, gnorm=2.948, clip=100, loss_scale=128, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=1127
2022-09-27 11:59:14 - progress_bar.py[line:274] - INFO: epoch 001:    971 / 42934 loss=1.203, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=970, lr=2.8242e-06, gnorm=3.004, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=1138
2022-09-27 11:59:26 - progress_bar.py[line:274] - INFO: epoch 001:    981 / 42934 loss=1.223, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=88.2, ups=0.87, wpb=101.1, bsz=40, num_updates=980, lr=2.85332e-06, gnorm=3.424, clip=100, loss_scale=128, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=1150
2022-09-27 11:59:37 - progress_bar.py[line:274] - INFO: epoch 001:    991 / 42934 loss=1.182, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=91.1, ups=0.89, wpb=102.9, bsz=40, num_updates=990, lr=2.88243e-06, gnorm=2.968, clip=100, loss_scale=128, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=1161
2022-09-27 11:59:49 - progress_bar.py[line:274] - INFO: epoch 001:   1001 / 42934 loss=1.218, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=87.7, ups=0.85, wpb=102.9, bsz=40, num_updates=1000, lr=2.91155e-06, gnorm=3.064, clip=100, loss_scale=128, train_wall=12, gb_free=8.9, ema_decay=0.9999, wall=1173
2022-09-27 12:00:00 - progress_bar.py[line:274] - INFO: epoch 001:   1011 / 42934 loss=1.15, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=88.5, ups=0.86, wpb=103.2, bsz=40, num_updates=1010, lr=2.94066e-06, gnorm=2.848, clip=100, loss_scale=128, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=1184
2022-09-27 12:00:12 - progress_bar.py[line:274] - INFO: epoch 001:   1021 / 42934 loss=1.088, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=91.4, ups=0.88, wpb=103.6, bsz=40, num_updates=1020, lr=2.96978e-06, gnorm=3.145, clip=100, loss_scale=128, train_wall=11, gb_free=8.4, ema_decay=0.9999, wall=1196
2022-09-27 12:00:23 - progress_bar.py[line:274] - INFO: epoch 001:   1031 / 42934 loss=1.199, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=87.9, ups=0.86, wpb=102.6, bsz=40, num_updates=1030, lr=2.99889e-06, gnorm=3.267, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=1207
2022-09-27 12:00:35 - progress_bar.py[line:274] - INFO: epoch 001:   1041 / 42934 loss=1.158, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=88.7, ups=0.87, wpb=101.7, bsz=40, num_updates=1040, lr=3.02801e-06, gnorm=3.029, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=1219
2022-09-27 12:00:46 - progress_bar.py[line:274] - INFO: epoch 001:   1051 / 42934 loss=1.162, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=90.7, ups=0.89, wpb=102.1, bsz=40, num_updates=1050, lr=3.05712e-06, gnorm=3.116, clip=100, loss_scale=256, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=1230
2022-09-27 12:00:58 - progress_bar.py[line:274] - INFO: epoch 001:   1061 / 42934 loss=1.202, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=89.4, ups=0.86, wpb=104, bsz=40, num_updates=1060, lr=3.08624e-06, gnorm=3.089, clip=100, loss_scale=256, train_wall=12, gb_free=8.5, ema_decay=0.9999, wall=1242
2022-09-27 12:01:09 - progress_bar.py[line:274] - INFO: epoch 001:   1071 / 42934 loss=1.214, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=91.1, ups=0.9, wpb=100.9, bsz=40, num_updates=1070, lr=3.11536e-06, gnorm=3.445, clip=100, loss_scale=256, train_wall=11, gb_free=9, ema_decay=0.9999, wall=1253
2022-09-27 12:01:21 - progress_bar.py[line:274] - INFO: epoch 001:   1081 / 42934 loss=1.17, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=88.5, ups=0.87, wpb=102.3, bsz=40, num_updates=1080, lr=3.14447e-06, gnorm=3.185, clip=100, loss_scale=256, train_wall=12, gb_free=7.6, ema_decay=0.9999, wall=1265
2022-09-27 12:01:32 - progress_bar.py[line:274] - INFO: epoch 001:   1091 / 42934 loss=1.165, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=88.4, ups=0.87, wpb=102.2, bsz=40, num_updates=1090, lr=3.17359e-06, gnorm=3.007, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=1276
2022-09-27 12:01:43 - progress_bar.py[line:274] - INFO: epoch 001:   1101 / 42934 loss=1.133, loss_v1=0, loss_v2=0, nll_loss=0.786, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=91.2, ups=0.88, wpb=103.4, bsz=40, num_updates=1100, lr=3.2027e-06, gnorm=3.026, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=1288
2022-09-27 12:01:55 - progress_bar.py[line:274] - INFO: epoch 001:   1111 / 42934 loss=1.132, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=104.6, nsentences=40, sample_size=104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=92.4, ups=0.88, wpb=104.6, bsz=40, num_updates=1110, lr=3.23182e-06, gnorm=2.697, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=1299
2022-09-27 12:02:06 - progress_bar.py[line:274] - INFO: epoch 001:   1121 / 42934 loss=1.11, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=87.5, ups=0.86, wpb=102.3, bsz=40, num_updates=1120, lr=3.26093e-06, gnorm=3.243, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=1311
2022-09-27 12:02:18 - progress_bar.py[line:274] - INFO: epoch 001:   1131 / 42934 loss=1.162, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=93.2, ups=0.9, wpb=104, bsz=40, num_updates=1130, lr=3.29005e-06, gnorm=3.307, clip=100, loss_scale=256, train_wall=11, gb_free=8.1, ema_decay=0.9999, wall=1322
2022-09-27 12:02:29 - progress_bar.py[line:274] - INFO: epoch 001:   1141 / 42934 loss=1.146, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=90.6, ups=0.87, wpb=104.4, bsz=40, num_updates=1140, lr=3.31916e-06, gnorm=3.227, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=1333
2022-09-27 12:02:41 - progress_bar.py[line:274] - INFO: epoch 001:   1151 / 42934 loss=1.128, loss_v1=0, loss_v2=0, nll_loss=0.764, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=90, ups=0.88, wpb=102.5, bsz=40, num_updates=1150, lr=3.34828e-06, gnorm=3.653, clip=100, loss_scale=256, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=1345
2022-09-27 12:02:52 - progress_bar.py[line:274] - INFO: epoch 001:   1161 / 42934 loss=1.134, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=86.7, ups=0.84, wpb=103.4, bsz=40, num_updates=1160, lr=3.37739e-06, gnorm=3.134, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=1357
2022-09-27 12:03:04 - progress_bar.py[line:274] - INFO: epoch 001:   1171 / 42934 loss=1.124, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=90.3, ups=0.88, wpb=102.8, bsz=40, num_updates=1170, lr=3.40651e-06, gnorm=2.932, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=1368
2022-09-27 12:03:15 - progress_bar.py[line:274] - INFO: epoch 001:   1181 / 42934 loss=1.138, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=91.1, ups=0.89, wpb=102.4, bsz=40, num_updates=1180, lr=3.43563e-06, gnorm=3.006, clip=100, loss_scale=256, train_wall=11, gb_free=8.4, ema_decay=0.9999, wall=1379
2022-09-27 12:03:27 - progress_bar.py[line:274] - INFO: epoch 001:   1191 / 42934 loss=1.131, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=87.8, ups=0.86, wpb=102.5, bsz=40, num_updates=1190, lr=3.46474e-06, gnorm=3.065, clip=100, loss_scale=256, train_wall=12, gb_free=8.9, ema_decay=0.9999, wall=1391
2022-09-27 12:03:38 - progress_bar.py[line:274] - INFO: epoch 001:   1201 / 42934 loss=1.142, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=87.7, ups=0.87, wpb=101.2, bsz=40, num_updates=1200, lr=3.49386e-06, gnorm=3.028, clip=100, loss_scale=256, train_wall=11, gb_free=8.4, ema_decay=0.9999, wall=1402
2022-09-27 12:03:50 - progress_bar.py[line:274] - INFO: epoch 001:   1211 / 42934 loss=1.154, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=89.1, ups=0.88, wpb=101.8, bsz=40, num_updates=1210, lr=3.52297e-06, gnorm=3.11, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=1414
2022-09-27 12:04:01 - progress_bar.py[line:274] - INFO: epoch 001:   1221 / 42934 loss=1.223, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=89.6, ups=0.88, wpb=102, bsz=40, num_updates=1220, lr=3.55209e-06, gnorm=3.693, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=1425
2022-09-27 12:04:13 - progress_bar.py[line:274] - INFO: epoch 001:   1231 / 42934 loss=1.108, loss_v1=0, loss_v2=0, nll_loss=0.76, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=90.9, ups=0.87, wpb=104.5, bsz=40, num_updates=1230, lr=3.5812e-06, gnorm=3.125, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=1437
2022-09-27 12:04:24 - progress_bar.py[line:274] - INFO: epoch 001:   1241 / 42934 loss=1.018, loss_v1=0, loss_v2=0, nll_loss=0.644, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=93.2, ups=0.9, wpb=104, bsz=40, num_updates=1240, lr=3.61032e-06, gnorm=2.933, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=1448
2022-09-27 12:04:35 - progress_bar.py[line:274] - INFO: epoch 001:   1251 / 42934 loss=1.155, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=94.7, ups=0.92, wpb=103.1, bsz=40, num_updates=1250, lr=3.63943e-06, gnorm=3.063, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=1459
2022-09-27 12:04:46 - progress_bar.py[line:274] - INFO: epoch 001:   1261 / 42934 loss=1.089, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=88.3, ups=0.86, wpb=102.2, bsz=40, num_updates=1260, lr=3.66855e-06, gnorm=3.238, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=1470
2022-09-27 12:04:58 - progress_bar.py[line:274] - INFO: epoch 001:   1271 / 42934 loss=1.086, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=91, ups=0.87, wpb=104.1, bsz=40, num_updates=1270, lr=3.69766e-06, gnorm=3.039, clip=100, loss_scale=256, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=1482
2022-09-27 12:05:09 - progress_bar.py[line:274] - INFO: epoch 001:   1281 / 42934 loss=1.157, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=88.7, ups=0.87, wpb=102, bsz=40, num_updates=1280, lr=3.72678e-06, gnorm=3.198, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=1493
2022-09-27 12:05:20 - progress_bar.py[line:274] - INFO: epoch 001:   1291 / 42934 loss=1.088, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=91.7, ups=0.89, wpb=102.6, bsz=40, num_updates=1290, lr=3.7559e-06, gnorm=3.459, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=1505
2022-09-27 12:05:32 - progress_bar.py[line:274] - INFO: epoch 001:   1301 / 42934 loss=1.029, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=87.7, ups=0.85, wpb=103.7, bsz=40, num_updates=1300, lr=3.78501e-06, gnorm=3.13, clip=100, loss_scale=256, train_wall=12, gb_free=10, ema_decay=0.9999, wall=1516
2022-09-27 12:05:44 - progress_bar.py[line:274] - INFO: epoch 001:   1311 / 42934 loss=1.123, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=90, ups=0.88, wpb=101.8, bsz=40, num_updates=1310, lr=3.81413e-06, gnorm=3.765, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=1528
2022-09-27 12:05:55 - progress_bar.py[line:274] - INFO: epoch 001:   1321 / 42934 loss=1.147, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=91.1, ups=0.89, wpb=102.4, bsz=40, num_updates=1320, lr=3.84324e-06, gnorm=3.435, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=1539
2022-09-27 12:06:06 - progress_bar.py[line:274] - INFO: epoch 001:   1331 / 42934 loss=1.075, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=91.9, ups=0.89, wpb=103.6, bsz=40, num_updates=1330, lr=3.87236e-06, gnorm=3.419, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=1550
2022-09-27 12:06:18 - progress_bar.py[line:274] - INFO: epoch 001:   1341 / 42934 loss=1.182, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=86.3, ups=0.86, wpb=100.4, bsz=40, num_updates=1340, lr=3.90147e-06, gnorm=3.735, clip=100, loss_scale=256, train_wall=12, gb_free=8, ema_decay=0.9999, wall=1562
2022-09-27 12:06:29 - progress_bar.py[line:274] - INFO: epoch 001:   1351 / 42934 loss=1.115, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=91.1, ups=0.9, wpb=101.1, bsz=40, num_updates=1350, lr=3.93059e-06, gnorm=3.506, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=1573
2022-09-27 12:06:40 - progress_bar.py[line:274] - INFO: epoch 001:   1361 / 42934 loss=1.08, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=93.7, ups=0.91, wpb=103.2, bsz=40, num_updates=1360, lr=3.9597e-06, gnorm=3.391, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=1584
2022-09-27 12:06:53 - progress_bar.py[line:274] - INFO: epoch 001:   1371 / 42934 loss=1.067, loss_v1=0, loss_v2=0, nll_loss=0.693, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=88, ups=0.86, wpb=102.6, bsz=40, num_updates=1370, lr=3.98882e-06, gnorm=3.242, clip=100, loss_scale=256, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=1596
2022-09-27 12:07:04 - progress_bar.py[line:274] - INFO: epoch 001:   1381 / 42934 loss=1.039, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=87.9, ups=0.85, wpb=103.2, bsz=40, num_updates=1380, lr=4.01794e-06, gnorm=3.236, clip=100, loss_scale=256, train_wall=12, gb_free=9, ema_decay=0.9999, wall=1609
2022-09-27 12:07:16 - progress_bar.py[line:274] - INFO: epoch 001:   1391 / 42934 loss=1.086, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=90, ups=0.88, wpb=102.5, bsz=40, num_updates=1390, lr=4.04705e-06, gnorm=3.143, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=1620
2022-09-27 12:07:27 - progress_bar.py[line:274] - INFO: epoch 001:   1401 / 42934 loss=1.131, loss_v1=0, loss_v2=0, nll_loss=0.757, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=88.6, ups=0.86, wpb=102.6, bsz=40, num_updates=1400, lr=4.07617e-06, gnorm=3.542, clip=100, loss_scale=256, train_wall=12, gb_free=10, ema_decay=0.9999, wall=1632
2022-09-27 12:07:39 - progress_bar.py[line:274] - INFO: epoch 001:   1411 / 42934 loss=1.071, loss_v1=0, loss_v2=0, nll_loss=0.689, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=87.6, ups=0.86, wpb=101.5, bsz=40, num_updates=1410, lr=4.10528e-06, gnorm=3.277, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=1643
2022-09-27 12:07:50 - progress_bar.py[line:274] - INFO: epoch 001:   1421 / 42934 loss=1.12, loss_v1=0, loss_v2=0, nll_loss=0.755, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=90.8, ups=0.89, wpb=101.6, bsz=40, num_updates=1420, lr=4.1344e-06, gnorm=3.4, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=1654
2022-09-27 12:08:01 - progress_bar.py[line:274] - INFO: epoch 001:   1431 / 42934 loss=1.038, loss_v1=0, loss_v2=0, nll_loss=0.67, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=93, ups=0.9, wpb=103.9, bsz=40, num_updates=1430, lr=4.16351e-06, gnorm=3.02, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=1665
2022-09-27 12:08:13 - progress_bar.py[line:274] - INFO: epoch 001:   1441 / 42934 loss=1.032, loss_v1=0, loss_v2=0, nll_loss=0.652, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=87.1, ups=0.85, wpb=102.5, bsz=40, num_updates=1440, lr=4.19263e-06, gnorm=3.401, clip=100, loss_scale=256, train_wall=12, gb_free=8.9, ema_decay=0.9999, wall=1677
2022-09-27 12:08:25 - progress_bar.py[line:274] - INFO: epoch 001:   1451 / 42934 loss=1.031, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=90.5, ups=0.87, wpb=103.5, bsz=40, num_updates=1450, lr=4.22174e-06, gnorm=3.057, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=1689
2022-09-27 12:08:36 - progress_bar.py[line:274] - INFO: epoch 001:   1461 / 42934 loss=0.978, loss_v1=0, loss_v2=0, nll_loss=0.607, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=94.2, ups=0.91, wpb=104.1, bsz=40, num_updates=1460, lr=4.25086e-06, gnorm=2.992, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=1700
2022-09-27 12:08:48 - progress_bar.py[line:274] - INFO: epoch 001:   1471 / 42934 loss=1.078, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=82.4, ups=0.81, wpb=102.3, bsz=40, num_updates=1470, lr=4.27997e-06, gnorm=3.255, clip=100, loss_scale=256, train_wall=12, gb_free=9.2, ema_decay=0.9999, wall=1712
2022-09-27 12:08:59 - progress_bar.py[line:274] - INFO: epoch 001:   1481 / 42934 loss=1.067, loss_v1=0, loss_v2=0, nll_loss=0.67, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=89.5, ups=0.88, wpb=101.5, bsz=40, num_updates=1480, lr=4.30909e-06, gnorm=3.088, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=1723
2022-09-27 12:09:11 - progress_bar.py[line:274] - INFO: epoch 001:   1491 / 42934 loss=1.088, loss_v1=0, loss_v2=0, nll_loss=0.721, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=89.9, ups=0.88, wpb=102.3, bsz=40, num_updates=1490, lr=4.33821e-06, gnorm=3.164, clip=100, loss_scale=256, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=1735
2022-09-27 12:09:23 - progress_bar.py[line:274] - INFO: epoch 001:   1501 / 42934 loss=1.026, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=84, ups=0.82, wpb=102.2, bsz=40, num_updates=1500, lr=4.36732e-06, gnorm=2.998, clip=100, loss_scale=256, train_wall=12, gb_free=7.6, ema_decay=0.9999, wall=1747
2022-09-27 12:09:35 - progress_bar.py[line:274] - INFO: epoch 001:   1511 / 42934 loss=1.039, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=88.1, ups=0.86, wpb=102.6, bsz=40, num_updates=1510, lr=4.39644e-06, gnorm=3.043, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=1759
2022-09-27 12:09:46 - progress_bar.py[line:274] - INFO: epoch 001:   1521 / 42934 loss=1.023, loss_v1=0, loss_v2=0, nll_loss=0.644, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=88.5, ups=0.86, wpb=102.7, bsz=40, num_updates=1520, lr=4.42555e-06, gnorm=2.987, clip=100, loss_scale=256, train_wall=12, gb_free=7.7, ema_decay=0.9999, wall=1770
2022-09-27 12:09:58 - progress_bar.py[line:274] - INFO: epoch 001:   1531 / 42934 loss=0.965, loss_v1=0, loss_v2=0, nll_loss=0.586, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89.1, ups=0.87, wpb=102.9, bsz=40, num_updates=1530, lr=4.45467e-06, gnorm=2.86, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=1782
2022-09-27 12:10:10 - progress_bar.py[line:274] - INFO: epoch 001:   1541 / 42934 loss=1.03, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=87.7, ups=0.86, wpb=102.2, bsz=40, num_updates=1540, lr=4.48378e-06, gnorm=3.176, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=1794
2022-09-27 12:10:21 - progress_bar.py[line:274] - INFO: epoch 001:   1551 / 42934 loss=1.033, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=89.1, ups=0.87, wpb=102.2, bsz=40, num_updates=1550, lr=4.5129e-06, gnorm=3.008, clip=100, loss_scale=512, train_wall=11, gb_free=9, ema_decay=0.9999, wall=1805
2022-09-27 12:10:32 - progress_bar.py[line:274] - INFO: epoch 001:   1561 / 42934 loss=1.055, loss_v1=0, loss_v2=0, nll_loss=0.689, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=90.8, ups=0.88, wpb=103, bsz=40, num_updates=1560, lr=4.54201e-06, gnorm=3.198, clip=100, loss_scale=512, train_wall=11, gb_free=8.9, ema_decay=0.9999, wall=1816
2022-09-27 12:10:43 - progress_bar.py[line:274] - INFO: epoch 001:   1571 / 42934 loss=1.059, loss_v1=0, loss_v2=0, nll_loss=0.69, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=93.8, ups=0.91, wpb=102.8, bsz=40, num_updates=1570, lr=4.57113e-06, gnorm=3.018, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=1827
2022-09-27 12:10:54 - progress_bar.py[line:274] - INFO: epoch 001:   1581 / 42934 loss=1.017, loss_v1=0, loss_v2=0, nll_loss=0.635, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=93, ups=0.9, wpb=102.9, bsz=40, num_updates=1580, lr=4.60024e-06, gnorm=3.01, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=1838
2022-09-27 12:11:02 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-27 12:11:07 - progress_bar.py[line:274] - INFO: epoch 001:   1592 / 42934 loss=1.011, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=84.7, ups=0.81, wpb=104.1, bsz=40, num_updates=1590, lr=4.62936e-06, gnorm=2.82, clip=100, loss_scale=256, train_wall=12, gb_free=10, ema_decay=0.9999, wall=1851
2022-09-27 12:11:18 - progress_bar.py[line:274] - INFO: epoch 001:   1602 / 42934 loss=0.952, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.4, ups=0.87, wpb=102.6, bsz=40, num_updates=1600, lr=4.65848e-06, gnorm=2.979, clip=100, loss_scale=256, train_wall=11, gb_free=9, ema_decay=0.9999, wall=1862
2022-09-27 12:11:29 - progress_bar.py[line:274] - INFO: epoch 001:   1612 / 42934 loss=1.06, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=1610, lr=4.68759e-06, gnorm=3.026, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=1874
2022-09-27 12:11:41 - progress_bar.py[line:274] - INFO: epoch 001:   1622 / 42934 loss=0.963, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=105.1, nsentences=40, sample_size=105.1, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=90.1, ups=0.86, wpb=105.1, bsz=40, num_updates=1620, lr=4.71671e-06, gnorm=3.098, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=1885
2022-09-27 12:11:52 - progress_bar.py[line:274] - INFO: epoch 001:   1632 / 42934 loss=0.976, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=105.9, nsentences=40, sample_size=105.9, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=93.3, ups=0.88, wpb=105.9, bsz=40, num_updates=1630, lr=4.74582e-06, gnorm=3.262, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=1897
2022-09-27 12:12:04 - progress_bar.py[line:274] - INFO: epoch 001:   1642 / 42934 loss=1, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=87.9, ups=0.86, wpb=101.8, bsz=40, num_updates=1640, lr=4.77494e-06, gnorm=3.062, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=1908
2022-09-27 12:12:16 - progress_bar.py[line:274] - INFO: epoch 001:   1652 / 42934 loss=1.033, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=89.5, ups=0.87, wpb=103.4, bsz=40, num_updates=1650, lr=4.80405e-06, gnorm=3.115, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=1920
2022-09-27 12:12:28 - progress_bar.py[line:274] - INFO: epoch 001:   1662 / 42934 loss=1.055, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=86.2, ups=0.84, wpb=102.1, bsz=40, num_updates=1660, lr=4.83317e-06, gnorm=2.883, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=1932
2022-09-27 12:12:39 - progress_bar.py[line:274] - INFO: epoch 001:   1672 / 42934 loss=1.042, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=93.4, ups=0.91, wpb=102.7, bsz=40, num_updates=1670, lr=4.86228e-06, gnorm=2.882, clip=100, loss_scale=256, train_wall=11, gb_free=8.3, ema_decay=0.9999, wall=1943
2022-09-27 12:12:50 - progress_bar.py[line:274] - INFO: epoch 001:   1682 / 42934 loss=1.052, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=88.8, ups=0.87, wpb=101.6, bsz=40, num_updates=1680, lr=4.8914e-06, gnorm=3.127, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=1954
2022-09-27 12:13:01 - progress_bar.py[line:274] - INFO: epoch 001:   1692 / 42934 loss=1.097, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=88.9, ups=0.88, wpb=100.9, bsz=40, num_updates=1690, lr=4.92051e-06, gnorm=3.257, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=1965
2022-09-27 12:13:13 - progress_bar.py[line:274] - INFO: epoch 001:   1702 / 42934 loss=1.024, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=88.3, ups=0.86, wpb=102.2, bsz=40, num_updates=1700, lr=4.94963e-06, gnorm=3.136, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=1977
2022-09-27 12:13:24 - progress_bar.py[line:274] - INFO: epoch 001:   1712 / 42934 loss=1.084, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=88.4, ups=0.87, wpb=101.9, bsz=40, num_updates=1710, lr=4.97875e-06, gnorm=3.332, clip=100, loss_scale=256, train_wall=11, gb_free=8.4, ema_decay=0.9999, wall=1989
2022-09-27 12:13:36 - progress_bar.py[line:274] - INFO: epoch 001:   1722 / 42934 loss=0.951, loss_v1=0, loss_v2=0, nll_loss=0.58, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=88.5, ups=0.86, wpb=103.1, bsz=40, num_updates=1720, lr=5.00786e-06, gnorm=2.926, clip=100, loss_scale=256, train_wall=12, gb_free=8.4, ema_decay=0.9999, wall=2000
2022-09-27 12:13:48 - progress_bar.py[line:274] - INFO: epoch 001:   1732 / 42934 loss=1.022, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=92.1, ups=0.89, wpb=103, bsz=40, num_updates=1730, lr=5.03698e-06, gnorm=2.937, clip=100, loss_scale=256, train_wall=11, gb_free=6.7, ema_decay=0.9999, wall=2011
2022-09-27 12:13:59 - progress_bar.py[line:274] - INFO: epoch 001:   1742 / 42934 loss=1.044, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=90.3, ups=0.88, wpb=102.4, bsz=40, num_updates=1740, lr=5.06609e-06, gnorm=2.918, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=2023
2022-09-27 12:14:10 - progress_bar.py[line:274] - INFO: epoch 001:   1752 / 42934 loss=1.023, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=90.7, ups=0.88, wpb=103, bsz=40, num_updates=1750, lr=5.09521e-06, gnorm=2.915, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=2034
2022-09-27 12:14:22 - progress_bar.py[line:274] - INFO: epoch 001:   1762 / 42934 loss=0.982, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=89, ups=0.87, wpb=102.4, bsz=40, num_updates=1760, lr=5.12432e-06, gnorm=2.992, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=2046
2022-09-27 12:14:33 - progress_bar.py[line:274] - INFO: epoch 001:   1772 / 42934 loss=1.068, loss_v1=0, loss_v2=0, nll_loss=0.695, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=91.7, ups=0.89, wpb=102.9, bsz=40, num_updates=1770, lr=5.15344e-06, gnorm=3.157, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=2057
2022-09-27 12:14:45 - progress_bar.py[line:274] - INFO: epoch 001:   1782 / 42934 loss=1.043, loss_v1=0, loss_v2=0, nll_loss=0.676, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=85.5, ups=0.82, wpb=103.7, bsz=40, num_updates=1780, lr=5.18255e-06, gnorm=2.847, clip=100, loss_scale=256, train_wall=12, gb_free=9.2, ema_decay=0.9999, wall=2069
2022-09-27 12:14:56 - progress_bar.py[line:274] - INFO: epoch 001:   1792 / 42934 loss=0.954, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=93.1, ups=0.89, wpb=104.3, bsz=40, num_updates=1790, lr=5.21167e-06, gnorm=2.848, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=2080
2022-09-27 12:15:08 - progress_bar.py[line:274] - INFO: epoch 001:   1802 / 42934 loss=1.006, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=90.1, ups=0.87, wpb=103.1, bsz=40, num_updates=1800, lr=5.24078e-06, gnorm=2.93, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=2092
2022-09-27 12:15:19 - progress_bar.py[line:274] - INFO: epoch 001:   1812 / 42934 loss=1.023, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=91.1, ups=0.88, wpb=103.5, bsz=40, num_updates=1810, lr=5.2699e-06, gnorm=2.862, clip=100, loss_scale=256, train_wall=11, gb_free=8.3, ema_decay=0.9999, wall=2103
2022-09-27 12:15:31 - progress_bar.py[line:274] - INFO: epoch 001:   1822 / 42934 loss=0.966, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89, ups=0.87, wpb=101.9, bsz=40, num_updates=1820, lr=5.29902e-06, gnorm=2.977, clip=100, loss_scale=256, train_wall=11, gb_free=7.6, ema_decay=0.9999, wall=2115
2022-09-27 12:15:42 - progress_bar.py[line:274] - INFO: epoch 001:   1832 / 42934 loss=0.976, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=91.5, ups=0.88, wpb=104.4, bsz=40, num_updates=1830, lr=5.32813e-06, gnorm=2.743, clip=100, loss_scale=256, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=2126
2022-09-27 12:15:53 - progress_bar.py[line:274] - INFO: epoch 001:   1842 / 42934 loss=0.993, loss_v1=0, loss_v2=0, nll_loss=0.621, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=91.4, ups=0.89, wpb=102.2, bsz=40, num_updates=1840, lr=5.35725e-06, gnorm=2.791, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=2137
2022-09-27 12:16:05 - progress_bar.py[line:274] - INFO: epoch 001:   1852 / 42934 loss=1.01, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=90.1, ups=0.88, wpb=102.5, bsz=40, num_updates=1850, lr=5.38636e-06, gnorm=3.122, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=2149
2022-09-27 12:16:16 - progress_bar.py[line:274] - INFO: epoch 001:   1862 / 42934 loss=1.059, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=89, ups=0.88, wpb=100.7, bsz=40, num_updates=1860, lr=5.41548e-06, gnorm=3.186, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=2160
2022-09-27 12:16:27 - progress_bar.py[line:274] - INFO: epoch 001:   1872 / 42934 loss=0.996, loss_v1=0, loss_v2=0, nll_loss=0.619, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=1870, lr=5.44459e-06, gnorm=3.007, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=2171
2022-09-27 12:16:38 - progress_bar.py[line:274] - INFO: epoch 001:   1882 / 42934 loss=0.999, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=91.8, ups=0.91, wpb=101.3, bsz=40, num_updates=1880, lr=5.47371e-06, gnorm=2.842, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=2182
2022-09-27 12:16:50 - progress_bar.py[line:274] - INFO: epoch 001:   1892 / 42934 loss=1.005, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=88.9, ups=0.86, wpb=103.2, bsz=40, num_updates=1890, lr=5.50282e-06, gnorm=3.002, clip=100, loss_scale=256, train_wall=12, gb_free=9.1, ema_decay=0.9999, wall=2194
2022-09-27 12:17:01 - progress_bar.py[line:274] - INFO: epoch 001:   1902 / 42934 loss=0.978, loss_v1=0, loss_v2=0, nll_loss=0.6, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=92.8, ups=0.9, wpb=103.4, bsz=40, num_updates=1900, lr=5.53194e-06, gnorm=2.857, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=2205
2022-09-27 12:17:13 - progress_bar.py[line:274] - INFO: epoch 001:   1912 / 42934 loss=0.957, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=88.5, ups=0.86, wpb=103.4, bsz=40, num_updates=1910, lr=5.56106e-06, gnorm=2.587, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=2217
2022-09-27 12:17:24 - progress_bar.py[line:274] - INFO: epoch 001:   1922 / 42934 loss=0.929, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=95.5, ups=0.92, wpb=104, bsz=40, num_updates=1920, lr=5.59017e-06, gnorm=2.757, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2228
2022-09-27 12:17:35 - progress_bar.py[line:274] - INFO: epoch 001:   1932 / 42934 loss=0.96, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=88.7, ups=0.85, wpb=104.7, bsz=40, num_updates=1930, lr=5.61929e-06, gnorm=2.89, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=2239
2022-09-27 12:17:47 - progress_bar.py[line:274] - INFO: epoch 001:   1942 / 42934 loss=1.028, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=93.3, ups=0.89, wpb=104.7, bsz=40, num_updates=1940, lr=5.6484e-06, gnorm=2.932, clip=100, loss_scale=256, train_wall=11, gb_free=9, ema_decay=0.9999, wall=2251
2022-09-27 12:17:58 - progress_bar.py[line:274] - INFO: epoch 001:   1952 / 42934 loss=0.984, loss_v1=0, loss_v2=0, nll_loss=0.608, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=90.7, ups=0.88, wpb=103.2, bsz=40, num_updates=1950, lr=5.67752e-06, gnorm=2.828, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=2262
2022-09-27 12:18:09 - progress_bar.py[line:274] - INFO: epoch 001:   1962 / 42934 loss=0.984, loss_v1=0, loss_v2=0, nll_loss=0.6, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=88.9, ups=0.87, wpb=102, bsz=40, num_updates=1960, lr=5.70663e-06, gnorm=2.608, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=2274
2022-09-27 12:18:21 - progress_bar.py[line:274] - INFO: epoch 001:   1972 / 42934 loss=0.991, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=104.8, nsentences=40, sample_size=104.8, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=89.5, ups=0.85, wpb=104.8, bsz=40, num_updates=1970, lr=5.73575e-06, gnorm=2.738, clip=100, loss_scale=256, train_wall=12, gb_free=9.1, ema_decay=0.9999, wall=2285
2022-09-27 12:18:33 - progress_bar.py[line:274] - INFO: epoch 001:   1982 / 42934 loss=0.992, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=90.1, ups=0.87, wpb=103.2, bsz=40, num_updates=1980, lr=5.76486e-06, gnorm=2.717, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2297
2022-09-27 12:18:44 - progress_bar.py[line:274] - INFO: epoch 001:   1992 / 42934 loss=0.998, loss_v1=0, loss_v2=0, nll_loss=0.642, ntokens=104.9, nsentences=40, sample_size=104.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=92.3, ups=0.88, wpb=104.9, bsz=40, num_updates=1990, lr=5.79398e-06, gnorm=2.751, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=2308
2022-09-27 12:18:56 - progress_bar.py[line:274] - INFO: epoch 001:   2002 / 42934 loss=0.983, loss_v1=0, loss_v2=0, nll_loss=0.629, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=88.5, ups=0.85, wpb=103.6, bsz=40, num_updates=2000, lr=5.82309e-06, gnorm=2.865, clip=100, loss_scale=256, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=2320
2022-09-27 12:19:07 - progress_bar.py[line:274] - INFO: epoch 001:   2012 / 42934 loss=0.969, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=87.1, ups=0.85, wpb=102.2, bsz=40, num_updates=2010, lr=5.85221e-06, gnorm=2.74, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=2332
2022-09-27 12:19:19 - progress_bar.py[line:274] - INFO: epoch 001:   2022 / 42934 loss=0.958, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=88.5, ups=0.86, wpb=103.5, bsz=40, num_updates=2020, lr=5.88133e-06, gnorm=2.745, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=2343
2022-09-27 12:19:31 - progress_bar.py[line:274] - INFO: epoch 001:   2032 / 42934 loss=0.981, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=105, nsentences=40, sample_size=105, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=91.3, ups=0.87, wpb=105, bsz=40, num_updates=2030, lr=5.91044e-06, gnorm=2.643, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=2355
2022-09-27 12:19:42 - progress_bar.py[line:274] - INFO: epoch 001:   2042 / 42934 loss=0.986, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=89.3, ups=0.87, wpb=102.1, bsz=40, num_updates=2040, lr=5.93956e-06, gnorm=2.767, clip=100, loss_scale=256, train_wall=11, gb_free=7.8, ema_decay=0.9999, wall=2366
2022-09-27 12:19:53 - progress_bar.py[line:274] - INFO: epoch 001:   2052 / 42934 loss=1.009, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=89.5, ups=0.88, wpb=101.5, bsz=40, num_updates=2050, lr=5.96867e-06, gnorm=2.635, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=2378
2022-09-27 12:20:05 - progress_bar.py[line:274] - INFO: epoch 001:   2062 / 42934 loss=0.948, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=87.5, ups=0.85, wpb=103, bsz=40, num_updates=2060, lr=5.99779e-06, gnorm=2.52, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=2389
2022-09-27 12:20:17 - progress_bar.py[line:274] - INFO: epoch 001:   2072 / 42934 loss=0.983, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=89.5, ups=0.87, wpb=102.6, bsz=40, num_updates=2070, lr=6.0269e-06, gnorm=2.716, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=2401
2022-09-27 12:20:28 - progress_bar.py[line:274] - INFO: epoch 001:   2082 / 42934 loss=0.972, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=88.5, ups=0.88, wpb=100.8, bsz=40, num_updates=2080, lr=6.05602e-06, gnorm=2.608, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=2412
2022-09-27 12:20:39 - progress_bar.py[line:274] - INFO: epoch 001:   2092 / 42934 loss=0.929, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=91.1, ups=0.88, wpb=103.2, bsz=40, num_updates=2090, lr=6.08513e-06, gnorm=2.685, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=2424
2022-09-27 12:20:51 - progress_bar.py[line:274] - INFO: epoch 001:   2102 / 42934 loss=0.983, loss_v1=0, loss_v2=0, nll_loss=0.608, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=87.3, ups=0.84, wpb=103.5, bsz=40, num_updates=2100, lr=6.11425e-06, gnorm=2.734, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=2435
2022-09-27 12:21:03 - progress_bar.py[line:274] - INFO: epoch 001:   2112 / 42934 loss=0.948, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=90.9, ups=0.88, wpb=103.2, bsz=40, num_updates=2110, lr=6.14336e-06, gnorm=2.675, clip=100, loss_scale=512, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=2447
2022-09-27 12:21:08 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-27 12:21:15 - progress_bar.py[line:274] - INFO: epoch 001:   2123 / 42934 loss=0.974, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=83, ups=0.8, wpb=103.5, bsz=40, num_updates=2120, lr=6.17248e-06, gnorm=2.863, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=2459
2022-09-27 12:21:26 - progress_bar.py[line:274] - INFO: epoch 001:   2133 / 42934 loss=0.955, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=93.2, ups=0.89, wpb=104.3, bsz=40, num_updates=2130, lr=6.2016e-06, gnorm=2.831, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=2470
2022-09-27 12:21:38 - progress_bar.py[line:274] - INFO: epoch 001:   2143 / 42934 loss=0.983, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=93, ups=0.89, wpb=104.2, bsz=40, num_updates=2140, lr=6.23071e-06, gnorm=2.785, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=2482
2022-09-27 12:21:49 - progress_bar.py[line:274] - INFO: epoch 001:   2153 / 42934 loss=1.003, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=90.4, ups=0.88, wpb=102.7, bsz=40, num_updates=2150, lr=6.25983e-06, gnorm=2.782, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=2493
2022-09-27 12:22:01 - progress_bar.py[line:274] - INFO: epoch 001:   2163 / 42934 loss=0.969, loss_v1=0, loss_v2=0, nll_loss=0.603, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=91, ups=0.87, wpb=104.3, bsz=40, num_updates=2160, lr=6.28894e-06, gnorm=2.806, clip=100, loss_scale=256, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=2505
2022-09-27 12:22:12 - progress_bar.py[line:274] - INFO: epoch 001:   2173 / 42934 loss=0.947, loss_v1=0, loss_v2=0, nll_loss=0.58, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=94, ups=0.9, wpb=104.3, bsz=40, num_updates=2170, lr=6.31806e-06, gnorm=2.55, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=2516
2022-09-27 12:22:24 - progress_bar.py[line:274] - INFO: epoch 001:   2183 / 42934 loss=0.915, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=104.6, nsentences=40, sample_size=104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=89.1, ups=0.85, wpb=104.6, bsz=40, num_updates=2180, lr=6.34717e-06, gnorm=2.619, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=2528
2022-09-27 12:22:35 - progress_bar.py[line:274] - INFO: epoch 001:   2193 / 42934 loss=0.981, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=88.8, ups=0.87, wpb=102.5, bsz=40, num_updates=2190, lr=6.37629e-06, gnorm=2.817, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=2539
2022-09-27 12:22:47 - progress_bar.py[line:274] - INFO: epoch 001:   2203 / 42934 loss=0.991, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=88.4, ups=0.87, wpb=101.4, bsz=40, num_updates=2200, lr=6.4054e-06, gnorm=2.738, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=2551
2022-09-27 12:22:58 - progress_bar.py[line:274] - INFO: epoch 001:   2213 / 42934 loss=1.027, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=90.9, ups=0.89, wpb=101.9, bsz=40, num_updates=2210, lr=6.43452e-06, gnorm=2.705, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2562
2022-09-27 12:23:09 - progress_bar.py[line:274] - INFO: epoch 001:   2223 / 42934 loss=1.021, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=91.3, ups=0.89, wpb=102.2, bsz=40, num_updates=2220, lr=6.46363e-06, gnorm=2.981, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2573
2022-09-27 12:23:21 - progress_bar.py[line:274] - INFO: epoch 001:   2233 / 42934 loss=0.987, loss_v1=0, loss_v2=0, nll_loss=0.604, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=89, ups=0.87, wpb=102.5, bsz=40, num_updates=2230, lr=6.49275e-06, gnorm=2.583, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2585
2022-09-27 12:23:32 - progress_bar.py[line:274] - INFO: epoch 001:   2243 / 42934 loss=0.943, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.9, ups=0.87, wpb=102.8, bsz=40, num_updates=2240, lr=6.52187e-06, gnorm=2.614, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=2596
2022-09-27 12:23:44 - progress_bar.py[line:274] - INFO: epoch 001:   2253 / 42934 loss=0.937, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.6, ups=0.87, wpb=102.3, bsz=40, num_updates=2250, lr=6.55098e-06, gnorm=2.569, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=2608
2022-09-27 12:23:56 - progress_bar.py[line:274] - INFO: epoch 001:   2263 / 42934 loss=0.96, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=86.6, ups=0.85, wpb=101.3, bsz=40, num_updates=2260, lr=6.5801e-06, gnorm=2.648, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=2620
2022-09-27 12:24:07 - progress_bar.py[line:274] - INFO: epoch 001:   2273 / 42934 loss=0.953, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.5, ups=0.87, wpb=103, bsz=40, num_updates=2270, lr=6.60921e-06, gnorm=2.694, clip=100, loss_scale=256, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=2631
2022-09-27 12:24:18 - progress_bar.py[line:274] - INFO: epoch 001:   2283 / 42934 loss=0.987, loss_v1=0, loss_v2=0, nll_loss=0.619, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=92.1, ups=0.89, wpb=103.3, bsz=40, num_updates=2280, lr=6.63833e-06, gnorm=2.908, clip=100, loss_scale=256, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=2642
2022-09-27 12:24:30 - progress_bar.py[line:274] - INFO: epoch 001:   2293 / 42934 loss=0.939, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=89.4, ups=0.89, wpb=100.6, bsz=40, num_updates=2290, lr=6.66744e-06, gnorm=2.675, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=2654
2022-09-27 12:24:41 - progress_bar.py[line:274] - INFO: epoch 001:   2303 / 42934 loss=0.967, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=90, ups=0.88, wpb=102.8, bsz=40, num_updates=2300, lr=6.69656e-06, gnorm=2.897, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=2665
2022-09-27 12:24:52 - progress_bar.py[line:274] - INFO: epoch 001:   2313 / 42934 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=92.7, ups=0.89, wpb=103.7, bsz=40, num_updates=2310, lr=6.72567e-06, gnorm=2.631, clip=100, loss_scale=256, train_wall=11, gb_free=8, ema_decay=0.9999, wall=2676
2022-09-27 12:25:04 - progress_bar.py[line:274] - INFO: epoch 001:   2323 / 42934 loss=0.922, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.5, ups=0.87, wpb=102.5, bsz=40, num_updates=2320, lr=6.75479e-06, gnorm=2.705, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=2688
2022-09-27 12:25:15 - progress_bar.py[line:274] - INFO: epoch 001:   2333 / 42934 loss=0.975, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=104.8, nsentences=40, sample_size=104.8, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=93, ups=0.89, wpb=104.8, bsz=40, num_updates=2330, lr=6.7839e-06, gnorm=2.866, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=2699
2022-09-27 12:25:27 - progress_bar.py[line:274] - INFO: epoch 001:   2343 / 42934 loss=0.953, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=91, ups=0.89, wpb=102.6, bsz=40, num_updates=2340, lr=6.81302e-06, gnorm=2.769, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=2711
2022-09-27 12:25:38 - progress_bar.py[line:274] - INFO: epoch 001:   2353 / 42934 loss=0.929, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=90.4, ups=0.88, wpb=102.9, bsz=40, num_updates=2350, lr=6.84214e-06, gnorm=2.812, clip=100, loss_scale=256, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=2722
2022-09-27 12:25:49 - progress_bar.py[line:274] - INFO: epoch 001:   2363 / 42934 loss=1.016, loss_v1=0, loss_v2=0, nll_loss=0.644, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=91.4, ups=0.89, wpb=102.7, bsz=40, num_updates=2360, lr=6.87125e-06, gnorm=2.887, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=2733
2022-09-27 12:26:01 - progress_bar.py[line:274] - INFO: epoch 001:   2373 / 42934 loss=0.974, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=88.1, ups=0.85, wpb=103.2, bsz=40, num_updates=2370, lr=6.90037e-06, gnorm=2.737, clip=100, loss_scale=256, train_wall=12, gb_free=10, ema_decay=0.9999, wall=2745
2022-09-27 12:26:12 - progress_bar.py[line:274] - INFO: epoch 001:   2383 / 42934 loss=0.951, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89.4, ups=0.87, wpb=102.3, bsz=40, num_updates=2380, lr=6.92948e-06, gnorm=2.603, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=2757
2022-09-27 12:26:24 - progress_bar.py[line:274] - INFO: epoch 001:   2393 / 42934 loss=0.967, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=89.3, ups=0.87, wpb=102.4, bsz=40, num_updates=2390, lr=6.9586e-06, gnorm=2.75, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=2768
2022-09-27 12:26:35 - progress_bar.py[line:274] - INFO: epoch 001:   2403 / 42934 loss=0.915, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=90.3, ups=0.88, wpb=102.8, bsz=40, num_updates=2400, lr=6.98771e-06, gnorm=2.733, clip=100, loss_scale=256, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=2779
2022-09-27 12:26:47 - progress_bar.py[line:274] - INFO: epoch 001:   2413 / 42934 loss=0.954, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=88.8, ups=0.85, wpb=104, bsz=40, num_updates=2410, lr=7.01683e-06, gnorm=2.808, clip=100, loss_scale=256, train_wall=12, gb_free=8.2, ema_decay=0.9999, wall=2791
2022-09-27 12:26:59 - progress_bar.py[line:274] - INFO: epoch 001:   2423 / 42934 loss=0.939, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=88.3, ups=0.85, wpb=103.4, bsz=40, num_updates=2420, lr=7.04594e-06, gnorm=2.72, clip=100, loss_scale=256, train_wall=12, gb_free=9.2, ema_decay=0.9999, wall=2803
2022-09-27 12:27:10 - progress_bar.py[line:274] - INFO: epoch 001:   2433 / 42934 loss=1.02, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=88.9, ups=0.87, wpb=101.6, bsz=40, num_updates=2430, lr=7.07506e-06, gnorm=2.874, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=2814
2022-09-27 12:27:22 - progress_bar.py[line:274] - INFO: epoch 001:   2443 / 42934 loss=0.956, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=2440, lr=7.10418e-06, gnorm=2.915, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2826
2022-09-27 12:27:33 - progress_bar.py[line:274] - INFO: epoch 001:   2453 / 42934 loss=0.947, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89.5, ups=0.86, wpb=104.3, bsz=40, num_updates=2450, lr=7.13329e-06, gnorm=2.652, clip=100, loss_scale=256, train_wall=12, gb_free=8.9, ema_decay=0.9999, wall=2837
2022-09-27 12:27:44 - progress_bar.py[line:274] - INFO: epoch 001:   2463 / 42934 loss=0.957, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=92.5, ups=0.9, wpb=102.9, bsz=40, num_updates=2460, lr=7.16241e-06, gnorm=2.809, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=2848
2022-09-27 12:27:57 - progress_bar.py[line:274] - INFO: epoch 001:   2473 / 42934 loss=0.955, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=89.1, ups=0.85, wpb=104.3, bsz=40, num_updates=2470, lr=7.19152e-06, gnorm=2.666, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=2860
2022-09-27 12:28:08 - progress_bar.py[line:274] - INFO: epoch 001:   2483 / 42934 loss=0.934, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=89, ups=0.86, wpb=102.9, bsz=40, num_updates=2480, lr=7.22064e-06, gnorm=2.696, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=2872
2022-09-27 12:28:20 - progress_bar.py[line:274] - INFO: epoch 001:   2493 / 42934 loss=0.967, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=88.2, ups=0.86, wpb=103, bsz=40, num_updates=2490, lr=7.24975e-06, gnorm=2.771, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=2884
2022-09-27 12:28:32 - progress_bar.py[line:274] - INFO: epoch 001:   2503 / 42934 loss=0.952, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=88.6, ups=0.87, wpb=101.5, bsz=40, num_updates=2500, lr=7.27887e-06, gnorm=2.467, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=2896
2022-09-27 12:28:44 - progress_bar.py[line:274] - INFO: epoch 001:   2513 / 42934 loss=0.992, loss_v1=0, loss_v2=0, nll_loss=0.619, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=89.3, ups=0.87, wpb=103.1, bsz=40, num_updates=2510, lr=7.30798e-06, gnorm=2.562, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=2908
2022-09-27 12:28:55 - progress_bar.py[line:274] - INFO: epoch 001:   2523 / 42934 loss=0.946, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.4, ups=0.87, wpb=102.7, bsz=40, num_updates=2520, lr=7.3371e-06, gnorm=2.83, clip=100, loss_scale=256, train_wall=11, gb_free=7.9, ema_decay=0.9999, wall=2919
2022-09-27 12:29:07 - progress_bar.py[line:274] - INFO: epoch 001:   2533 / 42934 loss=0.979, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=87.4, ups=0.87, wpb=100.6, bsz=40, num_updates=2530, lr=7.36621e-06, gnorm=2.652, clip=100, loss_scale=256, train_wall=11, gb_free=8.6, ema_decay=0.9999, wall=2931
2022-09-27 12:29:18 - progress_bar.py[line:274] - INFO: epoch 001:   2543 / 42934 loss=0.952, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=92.3, ups=0.88, wpb=104.3, bsz=40, num_updates=2540, lr=7.39533e-06, gnorm=2.515, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=2942
2022-09-27 12:29:29 - progress_bar.py[line:274] - INFO: epoch 001:   2553 / 42934 loss=0.951, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=91.5, ups=0.88, wpb=103.7, bsz=40, num_updates=2550, lr=7.42445e-06, gnorm=2.62, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2953
2022-09-27 12:29:40 - progress_bar.py[line:274] - INFO: epoch 001:   2563 / 42934 loss=0.912, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92.7, ups=0.9, wpb=103.2, bsz=40, num_updates=2560, lr=7.45356e-06, gnorm=2.743, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=2964
2022-09-27 12:29:52 - progress_bar.py[line:274] - INFO: epoch 001:   2573 / 42934 loss=1.038, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=89.9, ups=0.88, wpb=102.7, bsz=40, num_updates=2570, lr=7.48268e-06, gnorm=3.035, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=2976
2022-09-27 12:30:03 - progress_bar.py[line:274] - INFO: epoch 001:   2583 / 42934 loss=0.962, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=92, ups=0.89, wpb=103, bsz=40, num_updates=2580, lr=7.51179e-06, gnorm=2.716, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=2987
2022-09-27 12:30:14 - progress_bar.py[line:274] - INFO: epoch 001:   2593 / 42934 loss=0.997, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=91.2, ups=0.89, wpb=102.5, bsz=40, num_updates=2590, lr=7.54091e-06, gnorm=2.504, clip=100, loss_scale=256, train_wall=11, gb_free=9, ema_decay=0.9999, wall=2998
2022-09-27 12:30:25 - progress_bar.py[line:274] - INFO: epoch 001:   2603 / 42934 loss=0.95, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=94.5, ups=0.92, wpb=102.4, bsz=40, num_updates=2600, lr=7.57002e-06, gnorm=2.403, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=3009
2022-09-27 12:30:37 - progress_bar.py[line:274] - INFO: epoch 001:   2613 / 42934 loss=0.936, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.8, ups=0.87, wpb=101.8, bsz=40, num_updates=2610, lr=7.59914e-06, gnorm=2.391, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=3021
2022-09-27 12:30:48 - progress_bar.py[line:274] - INFO: epoch 001:   2623 / 42934 loss=1.02, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=87.2, ups=0.86, wpb=101.1, bsz=40, num_updates=2620, lr=7.62825e-06, gnorm=2.729, clip=100, loss_scale=256, train_wall=12, gb_free=9.2, ema_decay=0.9999, wall=3032
2022-09-27 12:30:59 - progress_bar.py[line:274] - INFO: epoch 001:   2633 / 42934 loss=0.967, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=94.7, ups=0.92, wpb=102.7, bsz=40, num_updates=2630, lr=7.65737e-06, gnorm=2.835, clip=100, loss_scale=512, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=3043
2022-09-27 12:31:10 - progress_bar.py[line:274] - INFO: epoch 001:   2643 / 42934 loss=0.967, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=91.9, ups=0.88, wpb=104.1, bsz=40, num_updates=2640, lr=7.68648e-06, gnorm=2.753, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=3054
2022-09-27 12:31:22 - progress_bar.py[line:274] - INFO: epoch 001:   2653 / 42934 loss=0.93, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=87.8, ups=0.85, wpb=102.8, bsz=40, num_updates=2650, lr=7.7156e-06, gnorm=2.654, clip=100, loss_scale=512, train_wall=12, gb_free=9.2, ema_decay=0.9999, wall=3066
2022-09-27 12:31:37 - progress_bar.py[line:274] - INFO: epoch 001:   2663 / 42934 loss=0.971, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=85.6, ups=0.84, wpb=101.4, bsz=40, num_updates=2660, lr=7.74472e-06, gnorm=2.661, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=3078
2022-09-27 12:31:49 - progress_bar.py[line:274] - INFO: epoch 001:   2673 / 42934 loss=0.896, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=105.5, nsentences=40, sample_size=105.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.7, ups=0.86, wpb=105.5, bsz=40, num_updates=2670, lr=7.77383e-06, gnorm=2.622, clip=100, loss_scale=512, train_wall=12, gb_free=5.1, ema_decay=0.9999, wall=3093
2022-09-27 12:32:00 - progress_bar.py[line:274] - INFO: epoch 001:   2683 / 42934 loss=0.952, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=92.7, ups=0.89, wpb=103.7, bsz=40, num_updates=2680, lr=7.80295e-06, gnorm=2.55, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=3104
2022-09-27 12:32:11 - progress_bar.py[line:274] - INFO: epoch 001:   2693 / 42934 loss=0.895, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=91.5, ups=0.88, wpb=103.9, bsz=40, num_updates=2690, lr=7.83206e-06, gnorm=2.471, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=3115
2022-09-27 12:32:23 - progress_bar.py[line:274] - INFO: epoch 001:   2703 / 42934 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.4, ups=0.87, wpb=102.1, bsz=40, num_updates=2700, lr=7.86118e-06, gnorm=2.905, clip=100, loss_scale=512, train_wall=12, gb_free=6.8, ema_decay=0.9999, wall=3127
2022-09-27 12:32:34 - progress_bar.py[line:274] - INFO: epoch 001:   2713 / 42934 loss=0.956, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=92.2, ups=0.88, wpb=104.7, bsz=40, num_updates=2710, lr=7.89029e-06, gnorm=2.514, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=3138
2022-09-27 12:32:46 - progress_bar.py[line:274] - INFO: epoch 001:   2723 / 42934 loss=0.873, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.7, ups=0.88, wpb=104.4, bsz=40, num_updates=2720, lr=7.91941e-06, gnorm=2.444, clip=100, loss_scale=512, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=3150
2022-09-27 12:32:57 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 42934 loss=0.94, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=88.4, ups=0.86, wpb=103.4, bsz=40, num_updates=2730, lr=7.94852e-06, gnorm=2.526, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=3162
2022-09-27 12:33:09 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 42934 loss=0.99, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=90.4, ups=0.88, wpb=102.2, bsz=40, num_updates=2740, lr=7.97764e-06, gnorm=2.626, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=3173
2022-09-27 12:33:20 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 42934 loss=0.937, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=92.5, ups=0.89, wpb=104, bsz=40, num_updates=2750, lr=8.00675e-06, gnorm=2.667, clip=100, loss_scale=512, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=3184
2022-09-27 12:33:31 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 42934 loss=0.955, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=91.6, ups=0.88, wpb=104.1, bsz=40, num_updates=2760, lr=8.03587e-06, gnorm=2.836, clip=100, loss_scale=512, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=3195
2022-09-27 12:33:43 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 42934 loss=0.954, loss_v1=0, loss_v2=0, nll_loss=0.58, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=88.7, ups=0.87, wpb=102.3, bsz=40, num_updates=2770, lr=8.06499e-06, gnorm=2.495, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=3207
2022-09-27 12:33:55 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 42934 loss=0.941, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=87.3, ups=0.85, wpb=102.9, bsz=40, num_updates=2780, lr=8.0941e-06, gnorm=2.732, clip=100, loss_scale=512, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=3219
2022-09-27 12:34:06 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 42934 loss=0.93, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=91.9, ups=0.89, wpb=103.5, bsz=40, num_updates=2790, lr=8.12322e-06, gnorm=2.585, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=3230
2022-09-27 12:34:17 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 42934 loss=0.959, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89.5, ups=0.87, wpb=102.8, bsz=40, num_updates=2800, lr=8.15233e-06, gnorm=2.423, clip=100, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=3242
2022-09-27 12:34:29 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 42934 loss=0.934, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.8, ups=0.87, wpb=102.2, bsz=40, num_updates=2810, lr=8.18145e-06, gnorm=2.566, clip=100, loss_scale=512, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=3253
2022-09-27 12:34:39 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-27 12:34:41 - progress_bar.py[line:274] - INFO: epoch 001:   2824 / 42934 loss=0.926, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=85.4, ups=0.82, wpb=104, bsz=40, num_updates=2820, lr=8.21056e-06, gnorm=2.614, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=3265
2022-09-27 12:34:53 - progress_bar.py[line:274] - INFO: epoch 001:   2834 / 42934 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90, ups=0.87, wpb=103.9, bsz=40, num_updates=2830, lr=8.23968e-06, gnorm=2.764, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=3277
2022-09-27 12:35:04 - progress_bar.py[line:274] - INFO: epoch 001:   2844 / 42934 loss=0.909, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.4, ups=0.87, wpb=103.3, bsz=40, num_updates=2840, lr=8.26879e-06, gnorm=2.646, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=3288
2022-09-27 12:35:15 - progress_bar.py[line:274] - INFO: epoch 001:   2854 / 42934 loss=0.902, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.4, ups=0.91, wpb=101.8, bsz=40, num_updates=2850, lr=8.29791e-06, gnorm=2.469, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=3299
2022-09-27 12:35:26 - progress_bar.py[line:274] - INFO: epoch 001:   2864 / 42934 loss=0.94, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=93.6, ups=0.9, wpb=103.5, bsz=40, num_updates=2860, lr=8.32702e-06, gnorm=2.471, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=3310
2022-09-27 12:35:38 - progress_bar.py[line:274] - INFO: epoch 001:   2874 / 42934 loss=0.996, loss_v1=0, loss_v2=0, nll_loss=0.613, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=89.7, ups=0.89, wpb=101.1, bsz=40, num_updates=2870, lr=8.35614e-06, gnorm=2.824, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=3322
2022-09-27 12:35:49 - progress_bar.py[line:274] - INFO: epoch 001:   2884 / 42934 loss=0.936, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=91.9, ups=0.89, wpb=103.3, bsz=40, num_updates=2880, lr=8.38526e-06, gnorm=2.462, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=3333
2022-09-27 12:36:00 - progress_bar.py[line:274] - INFO: epoch 001:   2894 / 42934 loss=1.016, loss_v1=0, loss_v2=0, nll_loss=0.654, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=91.5, ups=0.89, wpb=102.2, bsz=40, num_updates=2890, lr=8.41437e-06, gnorm=3.053, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=3344
2022-09-27 12:36:11 - progress_bar.py[line:274] - INFO: epoch 001:   2904 / 42934 loss=0.935, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=91.5, ups=0.9, wpb=102, bsz=40, num_updates=2900, lr=8.44349e-06, gnorm=2.772, clip=100, loss_scale=256, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=3355
2022-09-27 12:36:22 - progress_bar.py[line:274] - INFO: epoch 001:   2914 / 42934 loss=0.977, loss_v1=0, loss_v2=0, nll_loss=0.608, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=94.7, ups=0.92, wpb=102.8, bsz=40, num_updates=2910, lr=8.4726e-06, gnorm=2.811, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=3366
2022-09-27 12:36:33 - progress_bar.py[line:274] - INFO: epoch 001:   2924 / 42934 loss=0.976, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=91.9, ups=0.89, wpb=102.9, bsz=40, num_updates=2920, lr=8.50172e-06, gnorm=2.561, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=3377
2022-09-27 12:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   2934 / 42934 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=90.8, ups=0.88, wpb=103.2, bsz=40, num_updates=2930, lr=8.53083e-06, gnorm=2.58, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=3389
2022-09-27 12:36:57 - progress_bar.py[line:274] - INFO: epoch 001:   2944 / 42934 loss=0.936, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=87, ups=0.85, wpb=102.6, bsz=40, num_updates=2940, lr=8.55995e-06, gnorm=2.574, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=3401
2022-09-27 12:37:08 - progress_bar.py[line:274] - INFO: epoch 001:   2954 / 42934 loss=0.911, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.5, ups=0.88, wpb=103.3, bsz=40, num_updates=2950, lr=8.58906e-06, gnorm=2.526, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=3412
2022-09-27 12:37:20 - progress_bar.py[line:274] - INFO: epoch 001:   2964 / 42934 loss=0.933, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=89.4, ups=0.87, wpb=102.8, bsz=40, num_updates=2960, lr=8.61818e-06, gnorm=2.773, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=3424
2022-09-27 12:37:31 - progress_bar.py[line:274] - INFO: epoch 001:   2974 / 42934 loss=0.907, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=91.9, ups=0.88, wpb=104.2, bsz=40, num_updates=2970, lr=8.6473e-06, gnorm=2.724, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=3435
2022-09-27 12:37:42 - progress_bar.py[line:274] - INFO: epoch 001:   2984 / 42934 loss=0.96, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=92, ups=0.9, wpb=102.7, bsz=40, num_updates=2980, lr=8.67641e-06, gnorm=2.885, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=3446
2022-09-27 12:37:53 - progress_bar.py[line:274] - INFO: epoch 001:   2994 / 42934 loss=1.047, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=91, ups=0.9, wpb=101.3, bsz=40, num_updates=2990, lr=8.70553e-06, gnorm=2.79, clip=100, loss_scale=256, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=3457
2022-09-27 12:38:05 - progress_bar.py[line:274] - INFO: epoch 001:   3004 / 42934 loss=0.922, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=90.2, ups=0.87, wpb=103.4, bsz=40, num_updates=3000, lr=8.73464e-06, gnorm=2.671, clip=100, loss_scale=256, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=3469
2022-09-27 12:38:16 - progress_bar.py[line:274] - INFO: epoch 001:   3014 / 42934 loss=1, loss_v1=0, loss_v2=0, nll_loss=0.633, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=3010, lr=8.76376e-06, gnorm=2.732, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=3480
2022-09-27 12:38:28 - progress_bar.py[line:274] - INFO: epoch 001:   3024 / 42934 loss=0.932, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.5, ups=0.87, wpb=103, bsz=40, num_updates=3020, lr=8.79287e-06, gnorm=2.683, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=3492
2022-09-27 12:38:39 - progress_bar.py[line:274] - INFO: epoch 001:   3034 / 42934 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90.3, ups=0.87, wpb=103.4, bsz=40, num_updates=3030, lr=8.82199e-06, gnorm=2.549, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3503
2022-09-27 12:38:50 - progress_bar.py[line:274] - INFO: epoch 001:   3044 / 42934 loss=0.948, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=91, ups=0.89, wpb=102.2, bsz=40, num_updates=3040, lr=8.8511e-06, gnorm=2.607, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=3514
2022-09-27 12:39:02 - progress_bar.py[line:274] - INFO: epoch 001:   3054 / 42934 loss=0.981, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=89.1, ups=0.88, wpb=101.4, bsz=40, num_updates=3050, lr=8.88022e-06, gnorm=2.663, clip=100, loss_scale=256, train_wall=11, gb_free=8.4, ema_decay=0.9999, wall=3526
2022-09-27 12:39:13 - progress_bar.py[line:274] - INFO: epoch 001:   3064 / 42934 loss=0.914, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=91.6, ups=0.88, wpb=103.9, bsz=40, num_updates=3060, lr=8.90933e-06, gnorm=2.595, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=3537
2022-09-27 12:39:25 - progress_bar.py[line:274] - INFO: epoch 001:   3074 / 42934 loss=0.897, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=87.3, ups=0.84, wpb=104.3, bsz=40, num_updates=3070, lr=8.93845e-06, gnorm=2.498, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=3549
2022-09-27 12:39:36 - progress_bar.py[line:274] - INFO: epoch 001:   3084 / 42934 loss=0.963, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=92.4, ups=0.9, wpb=102.5, bsz=40, num_updates=3080, lr=8.96757e-06, gnorm=2.7, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=3560
2022-09-27 12:39:48 - progress_bar.py[line:274] - INFO: epoch 001:   3094 / 42934 loss=0.919, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.3, ups=0.85, wpb=103.3, bsz=40, num_updates=3090, lr=8.99668e-06, gnorm=2.528, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=3572
2022-09-27 12:39:59 - progress_bar.py[line:274] - INFO: epoch 001:   3104 / 42934 loss=1, loss_v1=0, loss_v2=0, nll_loss=0.626, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=88.4, ups=0.87, wpb=101.2, bsz=40, num_updates=3100, lr=9.0258e-06, gnorm=2.861, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=3583
2022-09-27 12:40:11 - progress_bar.py[line:274] - INFO: epoch 001:   3114 / 42934 loss=0.952, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=88.5, ups=0.87, wpb=101.5, bsz=40, num_updates=3110, lr=9.05491e-06, gnorm=2.447, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=3595
2022-09-27 12:40:22 - progress_bar.py[line:274] - INFO: epoch 001:   3124 / 42934 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=95, ups=0.92, wpb=103.7, bsz=40, num_updates=3120, lr=9.08403e-06, gnorm=2.45, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=3606
2022-09-27 12:40:33 - progress_bar.py[line:274] - INFO: epoch 001:   3134 / 42934 loss=0.882, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=87.8, ups=0.85, wpb=103.6, bsz=40, num_updates=3130, lr=9.11314e-06, gnorm=2.457, clip=100, loss_scale=256, train_wall=12, gb_free=8.2, ema_decay=0.9999, wall=3618
2022-09-27 12:40:45 - progress_bar.py[line:274] - INFO: epoch 001:   3144 / 42934 loss=0.952, loss_v1=0, loss_v2=0, nll_loss=0.576, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=92.6, ups=0.9, wpb=102.7, bsz=40, num_updates=3140, lr=9.14226e-06, gnorm=2.538, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=3629
2022-09-27 12:40:56 - progress_bar.py[line:274] - INFO: epoch 001:   3154 / 42934 loss=0.869, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=104.6, nsentences=40, sample_size=104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90.9, ups=0.87, wpb=104.6, bsz=40, num_updates=3150, lr=9.17137e-06, gnorm=2.306, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=3640
2022-09-27 12:41:08 - progress_bar.py[line:274] - INFO: epoch 001:   3164 / 42934 loss=0.977, loss_v1=0, loss_v2=0, nll_loss=0.609, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=89.5, ups=0.87, wpb=103.2, bsz=40, num_updates=3160, lr=9.20049e-06, gnorm=2.848, clip=100, loss_scale=256, train_wall=11, gb_free=8.1, ema_decay=0.9999, wall=3652
2022-09-27 12:41:19 - progress_bar.py[line:274] - INFO: epoch 001:   3174 / 42934 loss=0.957, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=89.1, ups=0.88, wpb=101.2, bsz=40, num_updates=3170, lr=9.2296e-06, gnorm=2.613, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=3663
2022-09-27 12:41:31 - progress_bar.py[line:274] - INFO: epoch 001:   3184 / 42934 loss=0.919, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90.7, ups=0.88, wpb=103.4, bsz=40, num_updates=3180, lr=9.25872e-06, gnorm=2.741, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=3674
2022-09-27 12:41:43 - progress_bar.py[line:274] - INFO: epoch 001:   3194 / 42934 loss=0.905, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.5, ups=0.87, wpb=104, bsz=40, num_updates=3190, lr=9.28784e-06, gnorm=2.636, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=3687
2022-09-27 12:41:55 - progress_bar.py[line:274] - INFO: epoch 001:   3204 / 42934 loss=0.922, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=87.3, ups=0.85, wpb=103.2, bsz=40, num_updates=3200, lr=9.31695e-06, gnorm=2.657, clip=100, loss_scale=256, train_wall=12, gb_free=8.7, ema_decay=0.9999, wall=3699
2022-09-27 12:42:06 - progress_bar.py[line:274] - INFO: epoch 001:   3214 / 42934 loss=0.919, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=94.5, ups=0.92, wpb=103.3, bsz=40, num_updates=3210, lr=9.34607e-06, gnorm=2.38, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=3710
2022-09-27 12:42:17 - progress_bar.py[line:274] - INFO: epoch 001:   3224 / 42934 loss=0.943, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=91.9, ups=0.9, wpb=101.6, bsz=40, num_updates=3220, lr=9.37518e-06, gnorm=2.439, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=3721
2022-09-27 12:42:28 - progress_bar.py[line:274] - INFO: epoch 001:   3234 / 42934 loss=0.939, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.8, ups=0.88, wpb=102, bsz=40, num_updates=3230, lr=9.4043e-06, gnorm=2.553, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=3732
2022-09-27 12:42:39 - progress_bar.py[line:274] - INFO: epoch 001:   3244 / 42934 loss=0.901, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=94.4, ups=0.91, wpb=103.6, bsz=40, num_updates=3240, lr=9.43341e-06, gnorm=2.383, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=3743
2022-09-27 12:42:51 - progress_bar.py[line:274] - INFO: epoch 001:   3254 / 42934 loss=0.912, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=88.1, ups=0.86, wpb=102.5, bsz=40, num_updates=3250, lr=9.46253e-06, gnorm=2.46, clip=100, loss_scale=256, train_wall=12, gb_free=7.6, ema_decay=0.9999, wall=3755
2022-09-27 12:43:02 - progress_bar.py[line:274] - INFO: epoch 001:   3264 / 42934 loss=0.94, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=90.1, ups=0.88, wpb=102.5, bsz=40, num_updates=3260, lr=9.49164e-06, gnorm=2.659, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=3766
2022-09-27 12:43:14 - progress_bar.py[line:274] - INFO: epoch 001:   3274 / 42934 loss=0.907, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=86, ups=0.83, wpb=103.9, bsz=40, num_updates=3270, lr=9.52076e-06, gnorm=2.356, clip=100, loss_scale=256, train_wall=12, gb_free=4.9, ema_decay=0.9999, wall=3778
2022-09-27 12:43:26 - progress_bar.py[line:274] - INFO: epoch 001:   3284 / 42934 loss=0.912, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.1, ups=0.88, wpb=103.3, bsz=40, num_updates=3280, lr=9.54987e-06, gnorm=2.455, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=3790
2022-09-27 12:43:37 - progress_bar.py[line:274] - INFO: epoch 001:   3294 / 42934 loss=0.919, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90.7, ups=0.89, wpb=102.2, bsz=40, num_updates=3290, lr=9.57899e-06, gnorm=2.369, clip=100, loss_scale=256, train_wall=11, gb_free=9, ema_decay=0.9999, wall=3801
2022-09-27 12:43:48 - progress_bar.py[line:274] - INFO: epoch 001:   3304 / 42934 loss=0.937, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=91.7, ups=0.89, wpb=103.1, bsz=40, num_updates=3300, lr=9.60811e-06, gnorm=2.38, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=3812
2022-09-27 12:44:00 - progress_bar.py[line:274] - INFO: epoch 001:   3314 / 42934 loss=0.933, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=90.8, ups=0.88, wpb=103, bsz=40, num_updates=3310, lr=9.63722e-06, gnorm=2.536, clip=100, loss_scale=256, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=3824
2022-09-27 12:44:11 - progress_bar.py[line:274] - INFO: epoch 001:   3324 / 42934 loss=1.01, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=90.2, ups=0.88, wpb=102.2, bsz=40, num_updates=3320, lr=9.66634e-06, gnorm=2.774, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=3835
2022-09-27 12:44:23 - progress_bar.py[line:274] - INFO: epoch 001:   3334 / 42934 loss=0.935, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=88.5, ups=0.87, wpb=102, bsz=40, num_updates=3330, lr=9.69545e-06, gnorm=2.52, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=3847
2022-09-27 12:44:34 - progress_bar.py[line:274] - INFO: epoch 001:   3344 / 42934 loss=0.947, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=90, ups=0.87, wpb=103, bsz=40, num_updates=3340, lr=9.72457e-06, gnorm=2.448, clip=100, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=3858
2022-09-27 12:44:46 - progress_bar.py[line:274] - INFO: epoch 001:   3354 / 42934 loss=0.921, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=87.1, ups=0.85, wpb=102, bsz=40, num_updates=3350, lr=9.75368e-06, gnorm=2.41, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=3870
2022-09-27 12:44:57 - progress_bar.py[line:274] - INFO: epoch 001:   3364 / 42934 loss=0.962, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=91.5, ups=0.88, wpb=103.9, bsz=40, num_updates=3360, lr=9.7828e-06, gnorm=2.524, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=3881
2022-09-27 12:45:09 - progress_bar.py[line:274] - INFO: epoch 001:   3374 / 42934 loss=0.904, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.6, ups=0.87, wpb=102.9, bsz=40, num_updates=3370, lr=9.81191e-06, gnorm=2.438, clip=100, loss_scale=512, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=3893
2022-09-27 12:45:20 - progress_bar.py[line:274] - INFO: epoch 001:   3384 / 42934 loss=0.911, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=87.6, ups=0.86, wpb=101.5, bsz=40, num_updates=3380, lr=9.84103e-06, gnorm=2.444, clip=100, loss_scale=512, train_wall=12, gb_free=9, ema_decay=0.9999, wall=3904
2022-09-27 12:45:32 - progress_bar.py[line:274] - INFO: epoch 001:   3394 / 42934 loss=0.92, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=92, ups=0.88, wpb=104.5, bsz=40, num_updates=3390, lr=9.87014e-06, gnorm=2.529, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=3916
2022-09-27 12:45:43 - progress_bar.py[line:274] - INFO: epoch 001:   3404 / 42934 loss=0.889, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.7, ups=0.87, wpb=103.7, bsz=40, num_updates=3400, lr=9.89926e-06, gnorm=2.862, clip=100, loss_scale=512, train_wall=11, gb_free=7.4, ema_decay=0.9999, wall=3927
2022-09-27 12:45:54 - progress_bar.py[line:274] - INFO: epoch 001:   3414 / 42934 loss=0.906, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.4, ups=0.88, wpb=101.5, bsz=40, num_updates=3410, lr=9.92838e-06, gnorm=2.475, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=3938
2022-09-27 12:46:06 - progress_bar.py[line:274] - INFO: epoch 001:   3424 / 42934 loss=0.933, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.9, ups=0.87, wpb=102.5, bsz=40, num_updates=3420, lr=9.95749e-06, gnorm=2.734, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=3950
2022-09-27 12:46:17 - progress_bar.py[line:274] - INFO: epoch 001:   3434 / 42934 loss=0.858, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.8, ups=0.86, wpb=104.4, bsz=40, num_updates=3430, lr=9.98661e-06, gnorm=2.172, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=3962
2022-09-27 12:46:29 - progress_bar.py[line:274] - INFO: epoch 001:   3444 / 42934 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=93.6, ups=0.9, wpb=104, bsz=40, num_updates=3440, lr=1.00157e-05, gnorm=2.55, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=3973
2022-09-27 12:46:40 - progress_bar.py[line:274] - INFO: epoch 001:   3454 / 42934 loss=0.865, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89.7, ups=0.87, wpb=103, bsz=40, num_updates=3450, lr=1.00448e-05, gnorm=2.235, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=3984
2022-09-27 12:46:51 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-27 12:46:53 - progress_bar.py[line:274] - INFO: epoch 001:   3465 / 42934 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=81.6, ups=0.8, wpb=102.2, bsz=40, num_updates=3460, lr=1.0074e-05, gnorm=2.33, clip=100, loss_scale=256, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=3997
2022-09-27 12:47:04 - progress_bar.py[line:274] - INFO: epoch 001:   3475 / 42934 loss=0.898, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=104.9, nsentences=40, sample_size=104.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=93.2, ups=0.89, wpb=104.9, bsz=40, num_updates=3470, lr=1.01031e-05, gnorm=2.25, clip=100, loss_scale=256, train_wall=11, gb_free=7.2, ema_decay=0.9999, wall=4008
2022-09-27 12:47:15 - progress_bar.py[line:274] - INFO: epoch 001:   3485 / 42934 loss=0.958, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=88.4, ups=0.86, wpb=102.5, bsz=40, num_updates=3480, lr=1.01322e-05, gnorm=2.461, clip=100, loss_scale=256, train_wall=12, gb_free=7.6, ema_decay=0.9999, wall=4020
2022-09-27 12:47:27 - progress_bar.py[line:274] - INFO: epoch 001:   3495 / 42934 loss=0.944, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=89.2, ups=0.87, wpb=102.5, bsz=40, num_updates=3490, lr=1.01613e-05, gnorm=2.343, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=4031
2022-09-27 12:47:38 - progress_bar.py[line:274] - INFO: epoch 001:   3505 / 42934 loss=0.901, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.2, ups=0.87, wpb=103.1, bsz=40, num_updates=3500, lr=1.01904e-05, gnorm=2.387, clip=100, loss_scale=256, train_wall=11, gb_free=8.5, ema_decay=0.9999, wall=4043
2022-09-27 12:47:50 - progress_bar.py[line:274] - INFO: epoch 001:   3515 / 42934 loss=0.964, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=92.2, ups=0.9, wpb=103, bsz=40, num_updates=3510, lr=1.02195e-05, gnorm=2.551, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=4054
2022-09-27 12:48:01 - progress_bar.py[line:274] - INFO: epoch 001:   3525 / 42934 loss=0.912, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=88.5, ups=0.86, wpb=102.6, bsz=40, num_updates=3520, lr=1.02486e-05, gnorm=2.449, clip=100, loss_scale=256, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=4065
2022-09-27 12:48:12 - progress_bar.py[line:274] - INFO: epoch 001:   3535 / 42934 loss=0.961, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=92.3, ups=0.9, wpb=102.2, bsz=40, num_updates=3530, lr=1.02778e-05, gnorm=2.685, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=4076
2022-09-27 12:48:23 - progress_bar.py[line:274] - INFO: epoch 001:   3545 / 42934 loss=0.939, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=93.2, ups=0.9, wpb=103.2, bsz=40, num_updates=3540, lr=1.03069e-05, gnorm=2.59, clip=100, loss_scale=256, train_wall=11, gb_free=7, ema_decay=0.9999, wall=4087
2022-09-27 12:48:35 - progress_bar.py[line:274] - INFO: epoch 001:   3555 / 42934 loss=0.995, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=87.7, ups=0.85, wpb=103, bsz=40, num_updates=3550, lr=1.0336e-05, gnorm=2.629, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=4099
2022-09-27 12:48:46 - progress_bar.py[line:274] - INFO: epoch 001:   3565 / 42934 loss=0.996, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=90.7, ups=0.88, wpb=103.2, bsz=40, num_updates=3560, lr=1.03651e-05, gnorm=2.457, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=4111
2022-09-27 12:48:58 - progress_bar.py[line:274] - INFO: epoch 001:   3575 / 42934 loss=0.913, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.2, ups=0.89, wpb=102.2, bsz=40, num_updates=3570, lr=1.03942e-05, gnorm=2.248, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=4122
2022-09-27 12:49:09 - progress_bar.py[line:274] - INFO: epoch 001:   3585 / 42934 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=3580, lr=1.04233e-05, gnorm=2.34, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=4133
2022-09-27 12:49:20 - progress_bar.py[line:274] - INFO: epoch 001:   3595 / 42934 loss=0.851, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.6, ups=0.9, wpb=102.4, bsz=40, num_updates=3590, lr=1.04525e-05, gnorm=2.292, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=4144
2022-09-27 12:49:32 - progress_bar.py[line:274] - INFO: epoch 001:   3605 / 42934 loss=0.934, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.9, ups=0.87, wpb=102.1, bsz=40, num_updates=3600, lr=1.04816e-05, gnorm=2.47, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=4156
2022-09-27 12:49:47 - progress_bar.py[line:274] - INFO: epoch 001:   3615 / 42934 loss=0.949, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=88.2, ups=0.87, wpb=101.6, bsz=40, num_updates=3610, lr=1.05107e-05, gnorm=2.594, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=4167
2022-09-27 12:49:59 - progress_bar.py[line:274] - INFO: epoch 001:   3625 / 42934 loss=0.921, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.3, ups=0.86, wpb=102.6, bsz=40, num_updates=3620, lr=1.05398e-05, gnorm=2.37, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=4183
2022-09-27 12:50:11 - progress_bar.py[line:274] - INFO: epoch 001:   3635 / 42934 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=87.8, ups=0.85, wpb=102.8, bsz=40, num_updates=3630, lr=1.05689e-05, gnorm=2.304, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=4195
2022-09-27 12:50:22 - progress_bar.py[line:274] - INFO: epoch 001:   3645 / 42934 loss=0.937, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=91, ups=0.88, wpb=103.7, bsz=40, num_updates=3640, lr=1.0598e-05, gnorm=2.366, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=4206
2022-09-27 12:50:34 - progress_bar.py[line:274] - INFO: epoch 001:   3655 / 42934 loss=0.913, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90.5, ups=0.89, wpb=102, bsz=40, num_updates=3650, lr=1.06271e-05, gnorm=2.344, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=4218
2022-09-27 12:50:45 - progress_bar.py[line:274] - INFO: epoch 001:   3665 / 42934 loss=0.973, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=88.8, ups=0.87, wpb=102.1, bsz=40, num_updates=3660, lr=1.06563e-05, gnorm=2.283, clip=100, loss_scale=256, train_wall=11, gb_free=8.6, ema_decay=0.9999, wall=4229
2022-09-27 12:50:56 - progress_bar.py[line:274] - INFO: epoch 001:   3675 / 42934 loss=0.94, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=90.1, ups=0.89, wpb=101.2, bsz=40, num_updates=3670, lr=1.06854e-05, gnorm=2.355, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=4240
2022-09-27 12:51:08 - progress_bar.py[line:274] - INFO: epoch 001:   3685 / 42934 loss=0.943, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.8, ups=0.88, wpb=101, bsz=40, num_updates=3680, lr=1.07145e-05, gnorm=2.512, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=4252
2022-09-27 12:51:19 - progress_bar.py[line:274] - INFO: epoch 001:   3695 / 42934 loss=0.874, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=88.2, ups=0.86, wpb=102.9, bsz=40, num_updates=3690, lr=1.07436e-05, gnorm=2.286, clip=100, loss_scale=256, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=4263
2022-09-27 12:51:31 - progress_bar.py[line:274] - INFO: epoch 001:   3705 / 42934 loss=0.935, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=90.7, ups=0.88, wpb=103.1, bsz=40, num_updates=3700, lr=1.07727e-05, gnorm=2.643, clip=100, loss_scale=256, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=4275
2022-09-27 12:51:42 - progress_bar.py[line:274] - INFO: epoch 001:   3715 / 42934 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=92.5, ups=0.89, wpb=103.7, bsz=40, num_updates=3710, lr=1.08018e-05, gnorm=2.338, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4286
2022-09-27 12:51:53 - progress_bar.py[line:274] - INFO: epoch 001:   3725 / 42934 loss=0.877, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.4, ups=0.88, wpb=104.4, bsz=40, num_updates=3720, lr=1.0831e-05, gnorm=2.406, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=4297
2022-09-27 12:52:05 - progress_bar.py[line:274] - INFO: epoch 001:   3735 / 42934 loss=0.894, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.2, ups=0.87, wpb=102.9, bsz=40, num_updates=3730, lr=1.08601e-05, gnorm=2.402, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=4309
2022-09-27 12:52:16 - progress_bar.py[line:274] - INFO: epoch 001:   3745 / 42934 loss=0.999, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=89.1, ups=0.88, wpb=101.4, bsz=40, num_updates=3740, lr=1.08892e-05, gnorm=2.712, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=4320
2022-09-27 12:52:28 - progress_bar.py[line:274] - INFO: epoch 001:   3755 / 42934 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.58, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=87.7, ups=0.86, wpb=102.2, bsz=40, num_updates=3750, lr=1.09183e-05, gnorm=2.522, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=4332
2022-09-27 12:52:40 - progress_bar.py[line:274] - INFO: epoch 001:   3765 / 42934 loss=0.903, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=85.9, ups=0.84, wpb=101.7, bsz=40, num_updates=3760, lr=1.09474e-05, gnorm=2.24, clip=100, loss_scale=256, train_wall=12, gb_free=7.4, ema_decay=0.9999, wall=4344
2022-09-27 12:52:51 - progress_bar.py[line:274] - INFO: epoch 001:   3775 / 42934 loss=0.917, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=87.8, ups=0.85, wpb=102.8, bsz=40, num_updates=3770, lr=1.09765e-05, gnorm=2.438, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=4355
2022-09-27 12:53:03 - progress_bar.py[line:274] - INFO: epoch 001:   3785 / 42934 loss=0.984, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=90.5, ups=0.88, wpb=103, bsz=40, num_updates=3780, lr=1.10056e-05, gnorm=2.446, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=4367
2022-09-27 12:53:14 - progress_bar.py[line:274] - INFO: epoch 001:   3795 / 42934 loss=0.91, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=88.3, ups=0.86, wpb=102.7, bsz=40, num_updates=3790, lr=1.10348e-05, gnorm=2.438, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=4378
2022-09-27 12:53:26 - progress_bar.py[line:274] - INFO: epoch 001:   3805 / 42934 loss=0.913, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=88.7, ups=0.88, wpb=100.9, bsz=40, num_updates=3800, lr=1.10639e-05, gnorm=2.334, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=4390
2022-09-27 12:53:37 - progress_bar.py[line:274] - INFO: epoch 001:   3815 / 42934 loss=0.901, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.4, ups=0.89, wpb=102.2, bsz=40, num_updates=3810, lr=1.1093e-05, gnorm=2.699, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=4401
2022-09-27 12:53:49 - progress_bar.py[line:274] - INFO: epoch 001:   3825 / 42934 loss=0.889, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.3, ups=0.87, wpb=104.3, bsz=40, num_updates=3820, lr=1.11221e-05, gnorm=2.574, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=4413
2022-09-27 12:54:00 - progress_bar.py[line:274] - INFO: epoch 001:   3835 / 42934 loss=0.979, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=86.5, ups=0.85, wpb=101.5, bsz=40, num_updates=3830, lr=1.11512e-05, gnorm=3.226, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=4424
2022-09-27 12:54:12 - progress_bar.py[line:274] - INFO: epoch 001:   3845 / 42934 loss=0.984, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=91, ups=0.89, wpb=101.9, bsz=40, num_updates=3840, lr=1.11803e-05, gnorm=2.49, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=4436
2022-09-27 12:54:23 - progress_bar.py[line:274] - INFO: epoch 001:   3855 / 42934 loss=0.983, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=90.1, ups=0.89, wpb=100.9, bsz=40, num_updates=3850, lr=1.12095e-05, gnorm=2.312, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=4447
2022-09-27 12:54:34 - progress_bar.py[line:274] - INFO: epoch 001:   3865 / 42934 loss=0.939, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.9, ups=0.88, wpb=101.4, bsz=40, num_updates=3860, lr=1.12386e-05, gnorm=2.591, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=4458
2022-09-27 12:54:45 - progress_bar.py[line:274] - INFO: epoch 001:   3875 / 42934 loss=0.934, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=93.7, ups=0.91, wpb=103, bsz=40, num_updates=3870, lr=1.12677e-05, gnorm=2.629, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=4469
2022-09-27 12:54:57 - progress_bar.py[line:274] - INFO: epoch 001:   3885 / 42934 loss=0.907, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.5, ups=0.89, wpb=100.9, bsz=40, num_updates=3880, lr=1.12968e-05, gnorm=2.519, clip=100, loss_scale=256, train_wall=11, gb_free=8.6, ema_decay=0.9999, wall=4481
2022-09-27 12:55:08 - progress_bar.py[line:274] - INFO: epoch 001:   3895 / 42934 loss=0.946, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=89, ups=0.87, wpb=102.7, bsz=40, num_updates=3890, lr=1.13259e-05, gnorm=2.679, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=4492
2022-09-27 12:55:20 - progress_bar.py[line:274] - INFO: epoch 001:   3905 / 42934 loss=0.882, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=88.3, ups=0.86, wpb=102.4, bsz=40, num_updates=3900, lr=1.1355e-05, gnorm=2.508, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=4504
2022-09-27 12:55:31 - progress_bar.py[line:274] - INFO: epoch 001:   3915 / 42934 loss=0.951, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=86.2, ups=0.85, wpb=101.1, bsz=40, num_updates=3910, lr=1.13841e-05, gnorm=2.784, clip=100, loss_scale=256, train_wall=12, gb_free=8.1, ema_decay=0.9999, wall=4515
2022-09-27 12:55:43 - progress_bar.py[line:274] - INFO: epoch 001:   3925 / 42934 loss=0.914, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=90.6, ups=0.88, wpb=102.7, bsz=40, num_updates=3920, lr=1.14133e-05, gnorm=2.506, clip=100, loss_scale=256, train_wall=11, gb_free=8, ema_decay=0.9999, wall=4527
2022-09-27 12:55:55 - progress_bar.py[line:274] - INFO: epoch 001:   3935 / 42934 loss=0.941, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=87.2, ups=0.84, wpb=103.6, bsz=40, num_updates=3930, lr=1.14424e-05, gnorm=2.651, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=4539
2022-09-27 12:56:06 - progress_bar.py[line:274] - INFO: epoch 001:   3945 / 42934 loss=0.864, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.7, ups=0.86, wpb=101.6, bsz=40, num_updates=3940, lr=1.14715e-05, gnorm=2.244, clip=100, loss_scale=256, train_wall=12, gb_free=7.9, ema_decay=0.9999, wall=4550
2022-09-27 12:56:21 - progress_bar.py[line:274] - INFO: epoch 001:   3955 / 42934 loss=0.929, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=90.1, ups=0.88, wpb=102.6, bsz=40, num_updates=3950, lr=1.15006e-05, gnorm=2.417, clip=100, loss_scale=256, train_wall=11, gb_free=8.4, ema_decay=0.9999, wall=4562
2022-09-27 12:56:33 - progress_bar.py[line:274] - INFO: epoch 001:   3965 / 42934 loss=0.97, loss_v1=0, loss_v2=0, nll_loss=0.6, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=86.5, ups=0.85, wpb=101.8, bsz=40, num_updates=3960, lr=1.15297e-05, gnorm=2.572, clip=100, loss_scale=256, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=4577
2022-09-27 12:56:44 - progress_bar.py[line:274] - INFO: epoch 001:   3975 / 42934 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92.2, ups=0.9, wpb=102.9, bsz=40, num_updates=3970, lr=1.15588e-05, gnorm=2.362, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=4588
2022-09-27 12:56:55 - progress_bar.py[line:274] - INFO: epoch 001:   3985 / 42934 loss=0.937, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=87, ups=0.86, wpb=100.7, bsz=40, num_updates=3980, lr=1.1588e-05, gnorm=2.817, clip=100, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=4600
2022-09-27 12:57:07 - progress_bar.py[line:274] - INFO: epoch 001:   3995 / 42934 loss=0.878, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89, ups=0.86, wpb=103.8, bsz=40, num_updates=3990, lr=1.16171e-05, gnorm=2.201, clip=100, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=4611
2022-09-27 12:57:19 - progress_bar.py[line:274] - INFO: epoch 001:   4005 / 42934 loss=0.878, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90.5, ups=0.88, wpb=103, bsz=40, num_updates=4000, lr=1.16462e-05, gnorm=2.456, clip=100, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=4623
2022-09-27 12:57:30 - progress_bar.py[line:274] - INFO: epoch 001:   4015 / 42934 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.8, ups=0.87, wpb=102.9, bsz=40, num_updates=4010, lr=1.16753e-05, gnorm=2.496, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=4634
2022-09-27 12:57:38 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-27 12:57:42 - progress_bar.py[line:274] - INFO: epoch 001:   4026 / 42934 loss=0.932, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=81.7, ups=0.81, wpb=100.6, bsz=40, num_updates=4020, lr=1.17044e-05, gnorm=2.413, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=4646
2022-09-27 12:57:54 - progress_bar.py[line:274] - INFO: epoch 001:   4036 / 42934 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.3, ups=0.89, wpb=101.2, bsz=40, num_updates=4030, lr=1.17335e-05, gnorm=2.426, clip=100, loss_scale=256, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=4658
2022-09-27 12:58:05 - progress_bar.py[line:274] - INFO: epoch 001:   4046 / 42934 loss=0.971, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=93, ups=0.89, wpb=103.9, bsz=40, num_updates=4040, lr=1.17627e-05, gnorm=2.451, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=4669
2022-09-27 12:58:16 - progress_bar.py[line:274] - INFO: epoch 001:   4056 / 42934 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=87.7, ups=0.86, wpb=102.2, bsz=40, num_updates=4050, lr=1.17918e-05, gnorm=2.585, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=4680
2022-09-27 12:58:27 - progress_bar.py[line:274] - INFO: epoch 001:   4066 / 42934 loss=0.977, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=93.1, ups=0.91, wpb=102.7, bsz=40, num_updates=4060, lr=1.18209e-05, gnorm=2.821, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=4691
2022-09-27 12:58:39 - progress_bar.py[line:274] - INFO: epoch 001:   4076 / 42934 loss=0.899, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.9, ups=0.86, wpb=104.1, bsz=40, num_updates=4070, lr=1.185e-05, gnorm=2.595, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=4703
2022-09-27 12:58:50 - progress_bar.py[line:274] - INFO: epoch 001:   4086 / 42934 loss=0.912, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92.5, ups=0.89, wpb=103.9, bsz=40, num_updates=4080, lr=1.18791e-05, gnorm=2.279, clip=100, loss_scale=256, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=4714
2022-09-27 12:59:02 - progress_bar.py[line:274] - INFO: epoch 001:   4096 / 42934 loss=0.873, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.9, ups=0.86, wpb=104.1, bsz=40, num_updates=4090, lr=1.19082e-05, gnorm=2.106, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=4726
2022-09-27 12:59:13 - progress_bar.py[line:274] - INFO: epoch 001:   4106 / 42934 loss=0.887, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.4, ups=0.89, wpb=103, bsz=40, num_updates=4100, lr=1.19373e-05, gnorm=2.352, clip=100, loss_scale=256, train_wall=11, gb_free=8, ema_decay=0.9999, wall=4737
2022-09-27 12:59:24 - progress_bar.py[line:274] - INFO: epoch 001:   4116 / 42934 loss=0.915, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92.5, ups=0.9, wpb=102.9, bsz=40, num_updates=4110, lr=1.19665e-05, gnorm=2.438, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=4748
2022-09-27 12:59:36 - progress_bar.py[line:274] - INFO: epoch 001:   4126 / 42934 loss=0.88, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88.7, ups=0.85, wpb=104.2, bsz=40, num_updates=4120, lr=1.19956e-05, gnorm=2.447, clip=100, loss_scale=256, train_wall=12, gb_free=8, ema_decay=0.9999, wall=4760
2022-09-27 12:59:48 - progress_bar.py[line:274] - INFO: epoch 001:   4136 / 42934 loss=0.932, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=88, ups=0.86, wpb=102.6, bsz=40, num_updates=4130, lr=1.20247e-05, gnorm=2.519, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=4772
2022-09-27 12:59:59 - progress_bar.py[line:274] - INFO: epoch 001:   4146 / 42934 loss=0.889, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=86.8, ups=0.85, wpb=101.6, bsz=40, num_updates=4140, lr=1.20538e-05, gnorm=2.414, clip=100, loss_scale=256, train_wall=12, gb_free=8, ema_decay=0.9999, wall=4783
2022-09-27 13:00:11 - progress_bar.py[line:274] - INFO: epoch 001:   4156 / 42934 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.3, ups=0.87, wpb=102.4, bsz=40, num_updates=4150, lr=1.20829e-05, gnorm=2.436, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=4795
2022-09-27 13:00:23 - progress_bar.py[line:274] - INFO: epoch 001:   4166 / 42934 loss=0.908, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89, ups=0.85, wpb=104.4, bsz=40, num_updates=4160, lr=1.2112e-05, gnorm=2.286, clip=100, loss_scale=256, train_wall=12, gb_free=8.9, ema_decay=0.9999, wall=4807
2022-09-27 13:00:35 - progress_bar.py[line:274] - INFO: epoch 001:   4176 / 42934 loss=0.891, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.8, ups=0.86, wpb=101.9, bsz=40, num_updates=4170, lr=1.21412e-05, gnorm=2.421, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=4818
2022-09-27 13:00:47 - progress_bar.py[line:274] - INFO: epoch 001:   4186 / 42934 loss=0.921, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=87.6, ups=0.86, wpb=102, bsz=40, num_updates=4180, lr=1.21703e-05, gnorm=2.477, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=4831
2022-09-27 13:00:58 - progress_bar.py[line:274] - INFO: epoch 001:   4196 / 42934 loss=0.864, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=105.3, nsentences=40, sample_size=105.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.2, ups=0.87, wpb=105.3, bsz=40, num_updates=4190, lr=1.21994e-05, gnorm=2.195, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=4842
2022-09-27 13:01:10 - progress_bar.py[line:274] - INFO: epoch 001:   4206 / 42934 loss=0.901, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=88.5, ups=0.87, wpb=102, bsz=40, num_updates=4200, lr=1.22285e-05, gnorm=2.487, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=4854
2022-09-27 13:01:22 - progress_bar.py[line:274] - INFO: epoch 001:   4216 / 42934 loss=0.942, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=89.1, ups=0.87, wpb=101.9, bsz=40, num_updates=4210, lr=1.22576e-05, gnorm=2.334, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=4866
2022-09-27 13:01:33 - progress_bar.py[line:274] - INFO: epoch 001:   4226 / 42934 loss=0.877, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.7, ups=0.87, wpb=104.1, bsz=40, num_updates=4220, lr=1.22867e-05, gnorm=2.253, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=4877
2022-09-27 13:01:44 - progress_bar.py[line:274] - INFO: epoch 001:   4236 / 42934 loss=0.889, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91, ups=0.89, wpb=102.8, bsz=40, num_updates=4230, lr=1.23158e-05, gnorm=2.552, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=4888
2022-09-27 13:01:56 - progress_bar.py[line:274] - INFO: epoch 001:   4246 / 42934 loss=0.917, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=89.2, ups=0.87, wpb=102.5, bsz=40, num_updates=4240, lr=1.2345e-05, gnorm=2.486, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=4900
2022-09-27 13:02:07 - progress_bar.py[line:274] - INFO: epoch 001:   4256 / 42934 loss=0.98, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=89.5, ups=0.87, wpb=103, bsz=40, num_updates=4250, lr=1.23741e-05, gnorm=2.241, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=4912
2022-09-27 13:02:19 - progress_bar.py[line:274] - INFO: epoch 001:   4266 / 42934 loss=0.844, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=105.1, nsentences=40, sample_size=105.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.2, ups=0.9, wpb=105.1, bsz=40, num_updates=4260, lr=1.24032e-05, gnorm=2.246, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=4923
2022-09-27 13:02:30 - progress_bar.py[line:274] - INFO: epoch 001:   4276 / 42934 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=93.5, ups=0.9, wpb=104.1, bsz=40, num_updates=4270, lr=1.24323e-05, gnorm=2.31, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=4934
2022-09-27 13:02:41 - progress_bar.py[line:274] - INFO: epoch 001:   4286 / 42934 loss=0.926, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=93.5, ups=0.9, wpb=104.2, bsz=40, num_updates=4280, lr=1.24614e-05, gnorm=2.356, clip=100, loss_scale=256, train_wall=11, gb_free=9, ema_decay=0.9999, wall=4945
2022-09-27 13:02:52 - progress_bar.py[line:274] - INFO: epoch 001:   4296 / 42934 loss=0.882, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.3, ups=0.88, wpb=104.1, bsz=40, num_updates=4290, lr=1.24905e-05, gnorm=2.44, clip=100, loss_scale=256, train_wall=11, gb_free=8.9, ema_decay=0.9999, wall=4956
2022-09-27 13:03:04 - progress_bar.py[line:274] - INFO: epoch 001:   4306 / 42934 loss=0.941, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=86.3, ups=0.85, wpb=101.4, bsz=40, num_updates=4300, lr=1.25197e-05, gnorm=2.669, clip=100, loss_scale=256, train_wall=12, gb_free=9.2, ema_decay=0.9999, wall=4968
2022-09-27 13:03:16 - progress_bar.py[line:274] - INFO: epoch 001:   4316 / 42934 loss=0.944, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=88.2, ups=0.86, wpb=102.4, bsz=40, num_updates=4310, lr=1.25488e-05, gnorm=2.876, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=4980
2022-09-27 13:03:27 - progress_bar.py[line:274] - INFO: epoch 001:   4326 / 42934 loss=0.907, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=88.5, ups=0.86, wpb=103.1, bsz=40, num_updates=4320, lr=1.25779e-05, gnorm=2.374, clip=100, loss_scale=256, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=4991
2022-09-27 13:03:39 - progress_bar.py[line:274] - INFO: epoch 001:   4336 / 42934 loss=0.889, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88.6, ups=0.87, wpb=102.2, bsz=40, num_updates=4330, lr=1.2607e-05, gnorm=2.623, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=5003
2022-09-27 13:03:50 - progress_bar.py[line:274] - INFO: epoch 001:   4346 / 42934 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88.5, ups=0.86, wpb=102.4, bsz=40, num_updates=4340, lr=1.26361e-05, gnorm=2.386, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=5015
2022-09-27 13:04:02 - progress_bar.py[line:274] - INFO: epoch 001:   4356 / 42934 loss=0.883, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=88.2, ups=0.86, wpb=103, bsz=40, num_updates=4350, lr=1.26652e-05, gnorm=2.438, clip=100, loss_scale=256, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=5026
2022-09-27 13:04:14 - progress_bar.py[line:274] - INFO: epoch 001:   4366 / 42934 loss=0.937, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.2, ups=0.87, wpb=101.6, bsz=40, num_updates=4360, lr=1.26943e-05, gnorm=2.623, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=5038
2022-09-27 13:04:25 - progress_bar.py[line:274] - INFO: epoch 001:   4376 / 42934 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.3, ups=0.86, wpb=104, bsz=40, num_updates=4370, lr=1.27235e-05, gnorm=2.414, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=5049
2022-09-27 13:04:37 - progress_bar.py[line:274] - INFO: epoch 001:   4386 / 42934 loss=0.941, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=91, ups=0.89, wpb=102.6, bsz=40, num_updates=4380, lr=1.27526e-05, gnorm=2.479, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=5061
2022-09-27 13:04:49 - progress_bar.py[line:274] - INFO: epoch 001:   4396 / 42934 loss=0.932, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.8, ups=0.87, wpb=101.9, bsz=40, num_updates=4390, lr=1.27817e-05, gnorm=2.423, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=5073
2022-09-27 13:05:00 - progress_bar.py[line:274] - INFO: epoch 001:   4406 / 42934 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.9, ups=0.87, wpb=102.7, bsz=40, num_updates=4400, lr=1.28108e-05, gnorm=2.585, clip=100, loss_scale=256, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=5084
2022-09-27 13:05:11 - progress_bar.py[line:274] - INFO: epoch 001:   4416 / 42934 loss=0.928, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=91.3, ups=0.89, wpb=102.8, bsz=40, num_updates=4410, lr=1.28399e-05, gnorm=2.637, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=5096
2022-09-27 13:05:23 - progress_bar.py[line:274] - INFO: epoch 001:   4426 / 42934 loss=0.872, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.7, ups=0.88, wpb=102.9, bsz=40, num_updates=4420, lr=1.2869e-05, gnorm=2.51, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=5107
2022-09-27 13:05:34 - progress_bar.py[line:274] - INFO: epoch 001:   4436 / 42934 loss=0.897, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=105, nsentences=40, sample_size=105, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.4, ups=0.86, wpb=105, bsz=40, num_updates=4430, lr=1.28982e-05, gnorm=2.347, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=5118
2022-09-27 13:05:46 - progress_bar.py[line:274] - INFO: epoch 001:   4446 / 42934 loss=0.911, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=90.4, ups=0.86, wpb=104.7, bsz=40, num_updates=4440, lr=1.29273e-05, gnorm=2.406, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=5130
2022-09-27 13:05:57 - progress_bar.py[line:274] - INFO: epoch 001:   4456 / 42934 loss=0.854, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.6, ups=0.87, wpb=102.9, bsz=40, num_updates=4450, lr=1.29564e-05, gnorm=2.227, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=5142
2022-09-27 13:06:09 - progress_bar.py[line:274] - INFO: epoch 001:   4466 / 42934 loss=0.881, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.9, ups=0.87, wpb=103.4, bsz=40, num_updates=4460, lr=1.29855e-05, gnorm=2.425, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=5153
2022-09-27 13:06:20 - progress_bar.py[line:274] - INFO: epoch 001:   4476 / 42934 loss=0.869, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94.6, ups=0.93, wpb=101.5, bsz=40, num_updates=4470, lr=1.30146e-05, gnorm=2.25, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=5164
2022-09-27 13:06:31 - progress_bar.py[line:274] - INFO: epoch 001:   4486 / 42934 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93.8, ups=0.91, wpb=103, bsz=40, num_updates=4480, lr=1.30437e-05, gnorm=2.569, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=5175
2022-09-27 13:06:42 - progress_bar.py[line:274] - INFO: epoch 001:   4496 / 42934 loss=0.881, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91, ups=0.87, wpb=104, bsz=40, num_updates=4490, lr=1.30728e-05, gnorm=2.273, clip=100, loss_scale=256, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=5186
2022-09-27 13:06:54 - progress_bar.py[line:274] - INFO: epoch 001:   4506 / 42934 loss=0.928, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.3, ups=0.86, wpb=103.3, bsz=40, num_updates=4500, lr=1.3102e-05, gnorm=2.621, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=5198
2022-09-27 13:07:05 - progress_bar.py[line:274] - INFO: epoch 001:   4516 / 42934 loss=0.897, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.7, ups=0.89, wpb=103.1, bsz=40, num_updates=4510, lr=1.31311e-05, gnorm=2.296, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=5209
2022-09-27 13:07:16 - progress_bar.py[line:274] - INFO: epoch 001:   4526 / 42934 loss=0.917, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90.7, ups=0.89, wpb=102.5, bsz=40, num_updates=4520, lr=1.31602e-05, gnorm=2.359, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=5220
2022-09-27 13:07:28 - progress_bar.py[line:274] - INFO: epoch 001:   4536 / 42934 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90.2, ups=0.89, wpb=101.8, bsz=40, num_updates=4530, lr=1.31893e-05, gnorm=2.49, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=5232
2022-09-27 13:07:39 - progress_bar.py[line:274] - INFO: epoch 001:   4546 / 42934 loss=0.863, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.2, ups=0.88, wpb=102.5, bsz=40, num_updates=4540, lr=1.32184e-05, gnorm=2.153, clip=100, loss_scale=512, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=5243
2022-09-27 13:07:50 - progress_bar.py[line:274] - INFO: epoch 001:   4556 / 42934 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=92.5, ups=0.89, wpb=104.3, bsz=40, num_updates=4550, lr=1.32475e-05, gnorm=2.258, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=5254
2022-09-27 13:08:02 - progress_bar.py[line:274] - INFO: epoch 001:   4566 / 42934 loss=0.939, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=87.3, ups=0.85, wpb=102.6, bsz=40, num_updates=4560, lr=1.32767e-05, gnorm=2.426, clip=100, loss_scale=512, train_wall=12, gb_free=7.5, ema_decay=0.9999, wall=5266
2022-09-27 13:08:14 - progress_bar.py[line:274] - INFO: epoch 001:   4576 / 42934 loss=0.996, loss_v1=0, loss_v2=0, nll_loss=0.628, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=87.1, ups=0.85, wpb=102.1, bsz=40, num_updates=4570, lr=1.33058e-05, gnorm=2.514, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=5278
2022-09-27 13:08:25 - progress_bar.py[line:274] - INFO: epoch 001:   4586 / 42934 loss=0.928, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=87.2, ups=0.85, wpb=102.2, bsz=40, num_updates=4580, lr=1.33349e-05, gnorm=2.28, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=5289
2022-09-27 13:08:37 - progress_bar.py[line:274] - INFO: epoch 001:   4596 / 42934 loss=0.931, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.2, ups=0.86, wpb=102.3, bsz=40, num_updates=4590, lr=1.3364e-05, gnorm=2.383, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=5301
2022-09-27 13:08:48 - progress_bar.py[line:274] - INFO: epoch 001:   4606 / 42934 loss=0.903, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92.2, ups=0.89, wpb=104.1, bsz=40, num_updates=4600, lr=1.33931e-05, gnorm=2.2, clip=100, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=5312
2022-09-27 13:09:00 - progress_bar.py[line:274] - INFO: epoch 001:   4616 / 42934 loss=0.942, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=88.1, ups=0.86, wpb=102.7, bsz=40, num_updates=4610, lr=1.34222e-05, gnorm=2.309, clip=100, loss_scale=512, train_wall=12, gb_free=9.1, ema_decay=0.9999, wall=5324
2022-09-27 13:09:12 - progress_bar.py[line:274] - INFO: epoch 001:   4626 / 42934 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.1, ups=0.86, wpb=103.6, bsz=40, num_updates=4620, lr=1.34513e-05, gnorm=2.098, clip=100, loss_scale=512, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=5336
2022-09-27 13:09:23 - progress_bar.py[line:274] - INFO: epoch 001:   4636 / 42934 loss=0.982, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=86.2, ups=0.84, wpb=102.2, bsz=40, num_updates=4630, lr=1.34805e-05, gnorm=2.416, clip=100, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=5348
2022-09-27 13:09:35 - progress_bar.py[line:274] - INFO: epoch 001:   4646 / 42934 loss=0.935, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.7, ups=0.88, wpb=101.3, bsz=40, num_updates=4640, lr=1.35096e-05, gnorm=2.258, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=5359
2022-09-27 13:09:47 - progress_bar.py[line:274] - INFO: epoch 001:   4656 / 42934 loss=0.832, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=104.8, nsentences=40, sample_size=104.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.3, ups=0.85, wpb=104.8, bsz=40, num_updates=4650, lr=1.35387e-05, gnorm=2.152, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=5371
2022-09-27 13:09:58 - progress_bar.py[line:274] - INFO: epoch 001:   4666 / 42934 loss=0.935, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=87.8, ups=0.86, wpb=101.9, bsz=40, num_updates=4660, lr=1.35678e-05, gnorm=2.493, clip=100, loss_scale=512, train_wall=12, gb_free=8.8, ema_decay=0.9999, wall=5382
2022-09-27 13:10:10 - progress_bar.py[line:274] - INFO: epoch 001:   4676 / 42934 loss=0.877, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.6, ups=0.88, wpb=103.9, bsz=40, num_updates=4670, lr=1.35969e-05, gnorm=2.425, clip=100, loss_scale=512, train_wall=11, gb_free=9, ema_decay=0.9999, wall=5394
2022-09-27 13:10:21 - progress_bar.py[line:274] - INFO: epoch 001:   4686 / 42934 loss=0.896, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=105.8, nsentences=40, sample_size=105.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=94.3, ups=0.89, wpb=105.8, bsz=40, num_updates=4680, lr=1.3626e-05, gnorm=2.127, clip=100, loss_scale=512, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=5405
2022-09-27 13:10:32 - progress_bar.py[line:274] - INFO: epoch 001:   4696 / 42934 loss=0.902, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.3, ups=0.9, wpb=101.9, bsz=40, num_updates=4690, lr=1.36552e-05, gnorm=2.413, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=5416
2022-09-27 13:10:44 - progress_bar.py[line:274] - INFO: epoch 001:   4706 / 42934 loss=0.908, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=87, ups=0.85, wpb=102.3, bsz=40, num_updates=4700, lr=1.36843e-05, gnorm=2.362, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=5428
2022-09-27 13:10:52 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-27 13:10:56 - progress_bar.py[line:274] - INFO: epoch 001:   4717 / 42934 loss=0.854, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=82.6, ups=0.81, wpb=101.8, bsz=40, num_updates=4710, lr=1.37134e-05, gnorm=2.138, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=5440
2022-09-27 13:11:08 - progress_bar.py[line:274] - INFO: epoch 001:   4727 / 42934 loss=0.997, loss_v1=0, loss_v2=0, nll_loss=0.615, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=88.7, ups=0.87, wpb=102.1, bsz=40, num_updates=4720, lr=1.37425e-05, gnorm=2.518, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=5452
2022-09-27 13:11:19 - progress_bar.py[line:274] - INFO: epoch 001:   4737 / 42934 loss=0.907, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=92.5, ups=0.9, wpb=102.4, bsz=40, num_updates=4730, lr=1.37716e-05, gnorm=2.44, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=5463
2022-09-27 13:11:30 - progress_bar.py[line:274] - INFO: epoch 001:   4747 / 42934 loss=0.898, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90.2, ups=0.86, wpb=104.5, bsz=40, num_updates=4740, lr=1.38007e-05, gnorm=2.485, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=5474
2022-09-27 13:11:42 - progress_bar.py[line:274] - INFO: epoch 001:   4757 / 42934 loss=0.952, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=90.9, ups=0.88, wpb=103, bsz=40, num_updates=4750, lr=1.38298e-05, gnorm=2.286, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=5486
2022-09-27 13:11:53 - progress_bar.py[line:274] - INFO: epoch 001:   4767 / 42934 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.7, ups=0.87, wpb=103, bsz=40, num_updates=4760, lr=1.3859e-05, gnorm=2.299, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=5497
2022-09-27 13:12:05 - progress_bar.py[line:274] - INFO: epoch 001:   4777 / 42934 loss=0.915, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=87.5, ups=0.85, wpb=102.7, bsz=40, num_updates=4770, lr=1.38881e-05, gnorm=2.152, clip=100, loss_scale=256, train_wall=12, gb_free=8.9, ema_decay=0.9999, wall=5509
2022-09-27 13:12:16 - progress_bar.py[line:274] - INFO: epoch 001:   4787 / 42934 loss=0.898, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=91.9, ups=0.89, wpb=102.9, bsz=40, num_updates=4780, lr=1.39172e-05, gnorm=2.223, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=5521
2022-09-27 13:12:28 - progress_bar.py[line:274] - INFO: epoch 001:   4797 / 42934 loss=0.878, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=105, nsentences=40, sample_size=105, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.5, ups=0.87, wpb=105, bsz=40, num_updates=4790, lr=1.39463e-05, gnorm=2.159, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=5532
2022-09-27 13:12:39 - progress_bar.py[line:274] - INFO: epoch 001:   4807 / 42934 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=93.2, ups=0.92, wpb=101.4, bsz=40, num_updates=4800, lr=1.39754e-05, gnorm=2.237, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=5543
2022-09-27 13:12:50 - progress_bar.py[line:274] - INFO: epoch 001:   4817 / 42934 loss=0.946, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=90, ups=0.88, wpb=102.2, bsz=40, num_updates=4810, lr=1.40045e-05, gnorm=2.348, clip=100, loss_scale=256, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=5554
2022-09-27 13:13:02 - progress_bar.py[line:274] - INFO: epoch 001:   4827 / 42934 loss=0.997, loss_v1=0, loss_v2=0, nll_loss=0.612, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=83.5, ups=0.84, wpb=99.4, bsz=40, num_updates=4820, lr=1.40337e-05, gnorm=2.297, clip=100, loss_scale=256, train_wall=12, gb_free=6.3, ema_decay=0.9999, wall=5566
2022-09-27 13:13:14 - progress_bar.py[line:274] - INFO: epoch 001:   4837 / 42934 loss=0.873, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.7, ups=0.86, wpb=103, bsz=40, num_updates=4830, lr=1.40628e-05, gnorm=2.148, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=5578
2022-09-27 13:13:25 - progress_bar.py[line:274] - INFO: epoch 001:   4847 / 42934 loss=0.848, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90, ups=0.87, wpb=103.1, bsz=40, num_updates=4840, lr=1.40919e-05, gnorm=2.277, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=5589
2022-09-27 13:13:36 - progress_bar.py[line:274] - INFO: epoch 001:   4857 / 42934 loss=0.871, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=92.5, ups=0.9, wpb=102.9, bsz=40, num_updates=4850, lr=1.4121e-05, gnorm=2.201, clip=100, loss_scale=256, train_wall=11, gb_free=8.9, ema_decay=0.9999, wall=5600
2022-09-27 13:13:47 - progress_bar.py[line:274] - INFO: epoch 001:   4867 / 42934 loss=0.914, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=93.4, ups=0.89, wpb=104.5, bsz=40, num_updates=4860, lr=1.41501e-05, gnorm=2.334, clip=100, loss_scale=256, train_wall=11, gb_free=8, ema_decay=0.9999, wall=5612
2022-09-27 13:13:59 - progress_bar.py[line:274] - INFO: epoch 001:   4877 / 42934 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.8, ups=0.89, wpb=103.3, bsz=40, num_updates=4870, lr=1.41792e-05, gnorm=2.424, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=5623
2022-09-27 13:14:10 - progress_bar.py[line:274] - INFO: epoch 001:   4887 / 42934 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.1, ups=0.85, wpb=103.4, bsz=40, num_updates=4880, lr=1.42084e-05, gnorm=2.393, clip=100, loss_scale=256, train_wall=12, gb_free=7.7, ema_decay=0.9999, wall=5635
2022-09-27 13:14:22 - progress_bar.py[line:274] - INFO: epoch 001:   4897 / 42934 loss=0.92, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.9, ups=0.86, wpb=104.3, bsz=40, num_updates=4890, lr=1.42375e-05, gnorm=2.445, clip=100, loss_scale=256, train_wall=12, gb_free=9.1, ema_decay=0.9999, wall=5646
2022-09-27 13:14:34 - progress_bar.py[line:274] - INFO: epoch 001:   4907 / 42934 loss=0.904, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=87.6, ups=0.85, wpb=103.5, bsz=40, num_updates=4900, lr=1.42666e-05, gnorm=2.318, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=5658
2022-09-27 13:14:45 - progress_bar.py[line:274] - INFO: epoch 001:   4917 / 42934 loss=0.907, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90.4, ups=0.86, wpb=104.5, bsz=40, num_updates=4910, lr=1.42957e-05, gnorm=2.195, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=5670
2022-09-27 13:14:57 - progress_bar.py[line:274] - INFO: epoch 001:   4927 / 42934 loss=0.896, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=92.1, ups=0.89, wpb=104.1, bsz=40, num_updates=4920, lr=1.43248e-05, gnorm=2.06, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=5681
2022-09-27 13:15:08 - progress_bar.py[line:274] - INFO: epoch 001:   4937 / 42934 loss=0.932, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=90.7, ups=0.88, wpb=103.6, bsz=40, num_updates=4930, lr=1.43539e-05, gnorm=2.285, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=5692
2022-09-27 13:15:20 - progress_bar.py[line:274] - INFO: epoch 001:   4947 / 42934 loss=0.895, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=90.3, ups=0.88, wpb=103.2, bsz=40, num_updates=4940, lr=1.4383e-05, gnorm=2.17, clip=100, loss_scale=256, train_wall=11, gb_free=8.2, ema_decay=0.9999, wall=5704
2022-09-27 13:15:31 - progress_bar.py[line:274] - INFO: epoch 001:   4957 / 42934 loss=0.913, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=105, nsentences=40, sample_size=105, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=92.2, ups=0.88, wpb=105, bsz=40, num_updates=4950, lr=1.44122e-05, gnorm=2.293, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=5715
2022-09-27 13:15:43 - progress_bar.py[line:274] - INFO: epoch 001:   4967 / 42934 loss=0.912, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=87.8, ups=0.85, wpb=103.2, bsz=40, num_updates=4960, lr=1.44413e-05, gnorm=2.408, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=5727
2022-09-27 13:15:54 - progress_bar.py[line:274] - INFO: epoch 001:   4977 / 42934 loss=0.926, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=4970, lr=1.44704e-05, gnorm=2.266, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=5738
2022-09-27 13:16:06 - progress_bar.py[line:274] - INFO: epoch 001:   4987 / 42934 loss=0.901, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=91.1, ups=0.89, wpb=102.7, bsz=40, num_updates=4980, lr=1.44995e-05, gnorm=2.288, clip=100, loss_scale=256, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=5750
2022-09-27 13:16:18 - progress_bar.py[line:274] - INFO: epoch 001:   4997 / 42934 loss=0.895, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=86.8, ups=0.85, wpb=102.2, bsz=40, num_updates=4990, lr=1.45286e-05, gnorm=2.122, clip=100, loss_scale=256, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=5762
2022-09-27 13:16:28 - progress_bar.py[line:274] - INFO: epoch 001:   5007 / 42934 loss=0.913, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.3, ups=0.93, wpb=103.2, bsz=40, num_updates=5000, lr=1.45577e-05, gnorm=2.129, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=5772
2022-09-27 13:16:40 - progress_bar.py[line:274] - INFO: epoch 001:   5017 / 42934 loss=0.924, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90.5, ups=0.88, wpb=102.3, bsz=40, num_updates=5010, lr=1.45869e-05, gnorm=2.176, clip=100, loss_scale=256, train_wall=11, gb_free=8.9, ema_decay=0.9999, wall=5784
2022-09-27 13:16:51 - progress_bar.py[line:274] - INFO: epoch 001:   5027 / 42934 loss=0.909, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.6, ups=0.86, wpb=103.4, bsz=40, num_updates=5020, lr=1.4616e-05, gnorm=2.39, clip=100, loss_scale=256, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=5795
2022-09-27 13:17:03 - progress_bar.py[line:274] - INFO: epoch 001:   5037 / 42934 loss=0.957, loss_v1=0, loss_v2=0, nll_loss=0.586, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=92.1, ups=0.9, wpb=102.6, bsz=40, num_updates=5030, lr=1.46451e-05, gnorm=2.366, clip=100, loss_scale=256, train_wall=11, gb_free=8.6, ema_decay=0.9999, wall=5807
2022-09-27 13:17:14 - progress_bar.py[line:274] - INFO: epoch 001:   5047 / 42934 loss=0.889, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.7, ups=0.89, wpb=103.2, bsz=40, num_updates=5040, lr=1.46742e-05, gnorm=2.101, clip=100, loss_scale=256, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=5818
2022-09-27 13:17:25 - progress_bar.py[line:274] - INFO: epoch 001:   5057 / 42934 loss=0.828, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=105.2, nsentences=40, sample_size=105.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.9, ups=0.89, wpb=105.2, bsz=40, num_updates=5050, lr=1.47033e-05, gnorm=1.892, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=5829
2022-09-27 13:17:36 - progress_bar.py[line:274] - INFO: epoch 001:   5067 / 42934 loss=0.846, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.7, ups=0.9, wpb=104.5, bsz=40, num_updates=5060, lr=1.47324e-05, gnorm=2.202, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=5840
2022-09-27 13:17:48 - progress_bar.py[line:274] - INFO: epoch 001:   5077 / 42934 loss=0.851, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.9, ups=0.86, wpb=102.9, bsz=40, num_updates=5070, lr=1.47615e-05, gnorm=2.405, clip=100, loss_scale=256, train_wall=12, gb_free=8.2, ema_decay=0.9999, wall=5852
2022-09-27 13:17:59 - progress_bar.py[line:274] - INFO: epoch 001:   5087 / 42934 loss=0.887, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.5, ups=0.88, wpb=102.4, bsz=40, num_updates=5080, lr=1.47907e-05, gnorm=2.542, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=5863
2022-09-27 13:18:11 - progress_bar.py[line:274] - INFO: epoch 001:   5097 / 42934 loss=0.912, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.9, ups=0.87, wpb=102.6, bsz=40, num_updates=5090, lr=1.48198e-05, gnorm=2.21, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=5875
2022-09-27 13:18:22 - progress_bar.py[line:274] - INFO: epoch 001:   5107 / 42934 loss=0.966, loss_v1=0, loss_v2=0, nll_loss=0.611, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=88.7, ups=0.85, wpb=104, bsz=40, num_updates=5100, lr=1.48489e-05, gnorm=2.331, clip=100, loss_scale=256, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=5886
2022-09-27 13:18:34 - progress_bar.py[line:274] - INFO: epoch 001:   5117 / 42934 loss=0.897, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=88.6, ups=0.85, wpb=103.9, bsz=40, num_updates=5110, lr=1.4878e-05, gnorm=2.188, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=5898
2022-09-27 13:18:46 - progress_bar.py[line:274] - INFO: epoch 001:   5127 / 42934 loss=0.925, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=90.9, ups=0.88, wpb=103.3, bsz=40, num_updates=5120, lr=1.49071e-05, gnorm=2.543, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=5910
2022-09-27 13:18:57 - progress_bar.py[line:274] - INFO: epoch 001:   5137 / 42934 loss=0.867, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.6, ups=0.88, wpb=102.1, bsz=40, num_updates=5130, lr=1.49362e-05, gnorm=2.163, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=5921
2022-09-27 13:19:08 - progress_bar.py[line:274] - INFO: epoch 001:   5147 / 42934 loss=0.879, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.4, ups=0.89, wpb=103.1, bsz=40, num_updates=5140, lr=1.49654e-05, gnorm=1.988, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=5932
2022-09-27 13:19:20 - progress_bar.py[line:274] - INFO: epoch 001:   5157 / 42934 loss=0.847, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.5, ups=0.88, wpb=104, bsz=40, num_updates=5150, lr=1.49945e-05, gnorm=2.023, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=5944
2022-09-27 13:19:31 - progress_bar.py[line:274] - INFO: epoch 001:   5167 / 42934 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.6, ups=0.88, wpb=103.7, bsz=40, num_updates=5160, lr=1.50236e-05, gnorm=2.357, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=5955
2022-09-27 13:19:43 - progress_bar.py[line:274] - INFO: epoch 001:   5177 / 42934 loss=0.921, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=89.9, ups=0.87, wpb=103.6, bsz=40, num_updates=5170, lr=1.50527e-05, gnorm=2.254, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=5967
2022-09-27 13:19:54 - progress_bar.py[line:274] - INFO: epoch 001:   5187 / 42934 loss=0.932, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=104.6, nsentences=40, sample_size=104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=95.8, ups=0.92, wpb=104.6, bsz=40, num_updates=5180, lr=1.50818e-05, gnorm=2.324, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=5978
2022-09-27 13:20:05 - progress_bar.py[line:274] - INFO: epoch 001:   5197 / 42934 loss=0.867, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90, ups=0.87, wpb=103.8, bsz=40, num_updates=5190, lr=1.51109e-05, gnorm=2.258, clip=100, loss_scale=256, train_wall=11, gb_free=8.9, ema_decay=0.9999, wall=5989
2022-09-27 13:20:16 - progress_bar.py[line:274] - INFO: epoch 001:   5207 / 42934 loss=0.873, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90, ups=0.89, wpb=101.7, bsz=40, num_updates=5200, lr=1.514e-05, gnorm=2.199, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=6000
2022-09-27 13:20:28 - progress_bar.py[line:274] - INFO: epoch 001:   5217 / 42934 loss=0.904, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.1, ups=0.87, wpb=102.3, bsz=40, num_updates=5210, lr=1.51692e-05, gnorm=2.223, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6012
2022-09-27 13:20:39 - progress_bar.py[line:274] - INFO: epoch 001:   5227 / 42934 loss=0.914, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=89.7, ups=0.87, wpb=102.6, bsz=40, num_updates=5220, lr=1.51983e-05, gnorm=2.116, clip=100, loss_scale=512, train_wall=11, gb_free=8.3, ema_decay=0.9999, wall=6023
2022-09-27 13:20:51 - progress_bar.py[line:274] - INFO: epoch 001:   5237 / 42934 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=86.5, ups=0.84, wpb=102.8, bsz=40, num_updates=5230, lr=1.52274e-05, gnorm=2.155, clip=100, loss_scale=512, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=6035
2022-09-27 13:21:02 - progress_bar.py[line:274] - INFO: epoch 001:   5247 / 42934 loss=0.877, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.9, ups=0.9, wpb=103.3, bsz=40, num_updates=5240, lr=1.52565e-05, gnorm=2.284, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=6046
2022-09-27 13:21:06 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-27 13:21:15 - progress_bar.py[line:274] - INFO: epoch 001:   5258 / 42934 loss=0.897, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=80.4, ups=0.78, wpb=102.5, bsz=40, num_updates=5250, lr=1.52856e-05, gnorm=2.429, clip=100, loss_scale=256, train_wall=13, gb_free=9.5, ema_decay=0.9999, wall=6059
2022-09-27 13:21:27 - progress_bar.py[line:274] - INFO: epoch 001:   5268 / 42934 loss=0.854, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.8, ups=0.88, wpb=103.4, bsz=40, num_updates=5260, lr=1.53147e-05, gnorm=2.082, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=6071
2022-09-27 13:21:38 - progress_bar.py[line:274] - INFO: epoch 001:   5278 / 42934 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.2, ups=0.88, wpb=103.4, bsz=40, num_updates=5270, lr=1.53439e-05, gnorm=2.554, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=6082
2022-09-27 13:21:49 - progress_bar.py[line:274] - INFO: epoch 001:   5288 / 42934 loss=0.894, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.9, ups=0.92, wpb=101.4, bsz=40, num_updates=5280, lr=1.5373e-05, gnorm=2.458, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=6093
2022-09-27 13:22:00 - progress_bar.py[line:274] - INFO: epoch 001:   5298 / 42934 loss=0.953, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89.1, ups=0.86, wpb=103, bsz=40, num_updates=5290, lr=1.54021e-05, gnorm=2.481, clip=100, loss_scale=256, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=6104
2022-09-27 13:22:12 - progress_bar.py[line:274] - INFO: epoch 001:   5308 / 42934 loss=0.943, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=84.6, ups=0.84, wpb=101.2, bsz=40, num_updates=5300, lr=1.54312e-05, gnorm=2.375, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=6116
2022-09-27 13:22:26 - progress_bar.py[line:274] - INFO: epoch 001:   5318 / 42934 loss=0.921, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=87.5, ups=0.87, wpb=101.1, bsz=40, num_updates=5310, lr=1.54603e-05, gnorm=2.388, clip=100, loss_scale=256, train_wall=11, gb_free=7.9, ema_decay=0.9999, wall=6128
2022-09-27 13:22:38 - progress_bar.py[line:274] - INFO: epoch 001:   5328 / 42934 loss=0.908, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.6, ups=0.88, wpb=102.1, bsz=40, num_updates=5320, lr=1.54894e-05, gnorm=2.127, clip=100, loss_scale=256, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=6142
2022-09-27 13:22:49 - progress_bar.py[line:274] - INFO: epoch 001:   5338 / 42934 loss=0.933, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=87.8, ups=0.88, wpb=99.8, bsz=40, num_updates=5330, lr=1.55185e-05, gnorm=2.428, clip=100, loss_scale=256, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=6153
2022-09-27 13:23:01 - progress_bar.py[line:274] - INFO: epoch 001:   5348 / 42934 loss=0.846, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.8, ups=0.85, wpb=103.2, bsz=40, num_updates=5340, lr=1.55477e-05, gnorm=2.267, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=6165
2022-09-27 13:23:12 - progress_bar.py[line:274] - INFO: epoch 001:   5358 / 42934 loss=0.873, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89.2, ups=0.88, wpb=101.9, bsz=40, num_updates=5350, lr=1.55768e-05, gnorm=2.399, clip=100, loss_scale=256, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=6176
2022-09-27 13:23:24 - progress_bar.py[line:274] - INFO: epoch 001:   5368 / 42934 loss=0.848, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.5, ups=0.88, wpb=104.4, bsz=40, num_updates=5360, lr=1.56059e-05, gnorm=2.116, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=6188
2022-09-27 13:23:35 - progress_bar.py[line:274] - INFO: epoch 001:   5378 / 42934 loss=0.868, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=104.6, nsentences=40, sample_size=104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.6, ups=0.88, wpb=104.6, bsz=40, num_updates=5370, lr=1.5635e-05, gnorm=2.306, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=6199
2022-09-27 13:23:46 - progress_bar.py[line:274] - INFO: epoch 001:   5388 / 42934 loss=0.913, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.7, ups=0.88, wpb=102, bsz=40, num_updates=5380, lr=1.56641e-05, gnorm=2.117, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=6210
2022-09-27 13:23:58 - progress_bar.py[line:274] - INFO: epoch 001:   5398 / 42934 loss=0.92, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=90.6, ups=0.88, wpb=103.5, bsz=40, num_updates=5390, lr=1.56932e-05, gnorm=2.32, clip=100, loss_scale=256, train_wall=11, gb_free=8.2, ema_decay=0.9999, wall=6222
2022-09-27 13:24:09 - progress_bar.py[line:274] - INFO: epoch 001:   5408 / 42934 loss=0.999, loss_v1=0, loss_v2=0, nll_loss=0.615, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=85.2, ups=0.85, wpb=100, bsz=40, num_updates=5400, lr=1.57224e-05, gnorm=2.315, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=6234
2022-09-27 13:24:21 - progress_bar.py[line:274] - INFO: epoch 001:   5418 / 42934 loss=0.899, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=87.8, ups=0.86, wpb=102.3, bsz=40, num_updates=5410, lr=1.57515e-05, gnorm=2.041, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=6245
2022-09-27 13:24:33 - progress_bar.py[line:274] - INFO: epoch 001:   5428 / 42934 loss=0.898, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89, ups=0.85, wpb=104.7, bsz=40, num_updates=5420, lr=1.57806e-05, gnorm=2.488, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=6257
2022-09-27 13:24:44 - progress_bar.py[line:274] - INFO: epoch 001:   5438 / 42934 loss=0.93, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=87.5, ups=0.87, wpb=100.7, bsz=40, num_updates=5430, lr=1.58097e-05, gnorm=2.649, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=6269
2022-09-27 13:24:56 - progress_bar.py[line:274] - INFO: epoch 001:   5448 / 42934 loss=0.877, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=104.6, nsentences=40, sample_size=104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.5, ups=0.86, wpb=104.6, bsz=40, num_updates=5440, lr=1.58388e-05, gnorm=2.126, clip=100, loss_scale=256, train_wall=12, gb_free=9, ema_decay=0.9999, wall=6280
2022-09-27 13:25:08 - progress_bar.py[line:274] - INFO: epoch 001:   5458 / 42934 loss=0.999, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=90.3, ups=0.88, wpb=102.8, bsz=40, num_updates=5450, lr=1.58679e-05, gnorm=2.526, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6292
2022-09-27 13:25:19 - progress_bar.py[line:274] - INFO: epoch 001:   5468 / 42934 loss=0.9, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.8, ups=0.87, wpb=103.2, bsz=40, num_updates=5460, lr=1.5897e-05, gnorm=2.156, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=6303
2022-09-27 13:25:31 - progress_bar.py[line:274] - INFO: epoch 001:   5478 / 42934 loss=0.859, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.3, ups=0.87, wpb=102.5, bsz=40, num_updates=5470, lr=1.59262e-05, gnorm=1.972, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=6315
2022-09-27 13:25:42 - progress_bar.py[line:274] - INFO: epoch 001:   5488 / 42934 loss=0.908, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=88.9, ups=0.87, wpb=102, bsz=40, num_updates=5480, lr=1.59553e-05, gnorm=1.994, clip=100, loss_scale=256, train_wall=11, gb_free=8.9, ema_decay=0.9999, wall=6326
2022-09-27 13:25:54 - progress_bar.py[line:274] - INFO: epoch 001:   5498 / 42934 loss=0.978, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=87.9, ups=0.87, wpb=100.9, bsz=40, num_updates=5490, lr=1.59844e-05, gnorm=2.387, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=6338
2022-09-27 13:26:05 - progress_bar.py[line:274] - INFO: epoch 001:   5508 / 42934 loss=0.899, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=88.4, ups=0.87, wpb=101.7, bsz=40, num_updates=5500, lr=1.60135e-05, gnorm=2.343, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=6349
2022-09-27 13:26:16 - progress_bar.py[line:274] - INFO: epoch 001:   5518 / 42934 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=90.3, ups=0.89, wpb=101.1, bsz=40, num_updates=5510, lr=1.60426e-05, gnorm=2.674, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=6360
2022-09-27 13:26:28 - progress_bar.py[line:274] - INFO: epoch 001:   5528 / 42934 loss=0.929, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=90.3, ups=0.88, wpb=102.8, bsz=40, num_updates=5520, lr=1.60717e-05, gnorm=2.427, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=6372
2022-09-27 13:26:39 - progress_bar.py[line:274] - INFO: epoch 001:   5538 / 42934 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.2, ups=0.88, wpb=104, bsz=40, num_updates=5530, lr=1.61009e-05, gnorm=2.019, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=6383
2022-09-27 13:26:51 - progress_bar.py[line:274] - INFO: epoch 001:   5548 / 42934 loss=0.94, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=105.1, nsentences=40, sample_size=105.1, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89.6, ups=0.85, wpb=105.1, bsz=40, num_updates=5540, lr=1.613e-05, gnorm=2.374, clip=100, loss_scale=256, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=6395
2022-09-27 13:27:02 - progress_bar.py[line:274] - INFO: epoch 001:   5558 / 42934 loss=0.883, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93.1, ups=0.9, wpb=103.3, bsz=40, num_updates=5550, lr=1.61591e-05, gnorm=2.307, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=6406
2022-09-27 13:27:13 - progress_bar.py[line:274] - INFO: epoch 001:   5568 / 42934 loss=0.924, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=90.5, ups=0.88, wpb=103, bsz=40, num_updates=5560, lr=1.61882e-05, gnorm=2.201, clip=100, loss_scale=256, train_wall=11, gb_free=9, ema_decay=0.9999, wall=6417
2022-09-27 13:27:25 - progress_bar.py[line:274] - INFO: epoch 001:   5578 / 42934 loss=0.913, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.8, ups=0.86, wpb=103.4, bsz=40, num_updates=5570, lr=1.62173e-05, gnorm=2.266, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=6429
2022-09-27 13:27:37 - progress_bar.py[line:274] - INFO: epoch 001:   5588 / 42934 loss=0.885, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.5, ups=0.85, wpb=103.1, bsz=40, num_updates=5580, lr=1.62464e-05, gnorm=2.172, clip=100, loss_scale=256, train_wall=12, gb_free=6.3, ema_decay=0.9999, wall=6441
2022-09-27 13:27:49 - progress_bar.py[line:274] - INFO: epoch 001:   5598 / 42934 loss=0.912, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.7, ups=0.85, wpb=104.1, bsz=40, num_updates=5590, lr=1.62755e-05, gnorm=2.141, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=6453
2022-09-27 13:28:01 - progress_bar.py[line:274] - INFO: epoch 001:   5608 / 42934 loss=0.928, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.6, ups=0.86, wpb=103, bsz=40, num_updates=5600, lr=1.63047e-05, gnorm=2.214, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=6465
2022-09-27 13:28:12 - progress_bar.py[line:274] - INFO: epoch 001:   5618 / 42934 loss=0.855, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90, ups=0.87, wpb=104, bsz=40, num_updates=5610, lr=1.63338e-05, gnorm=2.196, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=6476
2022-09-27 13:28:24 - progress_bar.py[line:274] - INFO: epoch 001:   5628 / 42934 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.9, ups=0.87, wpb=101.9, bsz=40, num_updates=5620, lr=1.63629e-05, gnorm=2.056, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=6488
2022-09-27 13:28:35 - progress_bar.py[line:274] - INFO: epoch 001:   5638 / 42934 loss=0.926, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92.2, ups=0.91, wpb=101.7, bsz=40, num_updates=5630, lr=1.6392e-05, gnorm=2.121, clip=100, loss_scale=256, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=6499
2022-09-27 13:28:46 - progress_bar.py[line:274] - INFO: epoch 001:   5648 / 42934 loss=0.944, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=91.7, ups=0.89, wpb=102.8, bsz=40, num_updates=5640, lr=1.64211e-05, gnorm=2.071, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=6510
2022-09-27 13:28:58 - progress_bar.py[line:274] - INFO: epoch 001:   5658 / 42934 loss=0.896, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.2, ups=0.86, wpb=103.8, bsz=40, num_updates=5650, lr=1.64502e-05, gnorm=1.99, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=6522
2022-09-27 13:29:09 - progress_bar.py[line:274] - INFO: epoch 001:   5668 / 42934 loss=0.882, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.4, ups=0.88, wpb=104.4, bsz=40, num_updates=5660, lr=1.64794e-05, gnorm=2.11, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=6533
2022-09-27 13:29:20 - progress_bar.py[line:274] - INFO: epoch 001:   5678 / 42934 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=91.7, ups=0.9, wpb=102.1, bsz=40, num_updates=5670, lr=1.65085e-05, gnorm=2.471, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=6544
2022-09-27 13:29:32 - progress_bar.py[line:274] - INFO: epoch 001:   5688 / 42934 loss=0.855, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.2, ups=0.87, wpb=103.7, bsz=40, num_updates=5680, lr=1.65376e-05, gnorm=2.168, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=6556
2022-09-27 13:29:43 - progress_bar.py[line:274] - INFO: epoch 001:   5698 / 42934 loss=0.943, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=90.9, ups=0.89, wpb=101.7, bsz=40, num_updates=5690, lr=1.65667e-05, gnorm=2.321, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=6567
2022-09-27 13:29:55 - progress_bar.py[line:274] - INFO: epoch 001:   5708 / 42934 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.8, ups=0.87, wpb=102.9, bsz=40, num_updates=5700, lr=1.65958e-05, gnorm=2.116, clip=100, loss_scale=256, train_wall=11, gb_free=8.6, ema_decay=0.9999, wall=6579
2022-09-27 13:30:06 - progress_bar.py[line:274] - INFO: epoch 001:   5718 / 42934 loss=0.909, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=86.6, ups=0.84, wpb=102.8, bsz=40, num_updates=5710, lr=1.66249e-05, gnorm=2.171, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=6591
2022-09-27 13:30:18 - progress_bar.py[line:274] - INFO: epoch 001:   5728 / 42934 loss=0.816, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=104.6, nsentences=40, sample_size=104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.8, ups=0.86, wpb=104.6, bsz=40, num_updates=5720, lr=1.6654e-05, gnorm=1.997, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=6602
2022-09-27 13:30:30 - progress_bar.py[line:274] - INFO: epoch 001:   5738 / 42934 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=87, ups=0.86, wpb=101.4, bsz=40, num_updates=5730, lr=1.66832e-05, gnorm=2.16, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=6614
2022-09-27 13:30:41 - progress_bar.py[line:274] - INFO: epoch 001:   5748 / 42934 loss=0.859, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89.2, ups=0.87, wpb=102.6, bsz=40, num_updates=5740, lr=1.67123e-05, gnorm=2.238, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=6625
2022-09-27 13:30:53 - progress_bar.py[line:274] - INFO: epoch 001:   5758 / 42934 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=87.6, ups=0.85, wpb=102.7, bsz=40, num_updates=5750, lr=1.67414e-05, gnorm=2.159, clip=100, loss_scale=256, train_wall=12, gb_free=9, ema_decay=0.9999, wall=6637
2022-09-27 13:31:04 - progress_bar.py[line:274] - INFO: epoch 001:   5768 / 42934 loss=0.837, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.1, ups=0.89, wpb=103.7, bsz=40, num_updates=5760, lr=1.67705e-05, gnorm=2.243, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=6648
2022-09-27 13:31:16 - progress_bar.py[line:274] - INFO: epoch 001:   5778 / 42934 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.8, ups=0.89, wpb=101.9, bsz=40, num_updates=5770, lr=1.67996e-05, gnorm=2.167, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=6660
2022-09-27 13:31:27 - progress_bar.py[line:274] - INFO: epoch 001:   5788 / 42934 loss=0.915, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=90.7, ups=0.87, wpb=103.8, bsz=40, num_updates=5780, lr=1.68287e-05, gnorm=2.119, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=6671
2022-09-27 13:31:38 - progress_bar.py[line:274] - INFO: epoch 001:   5798 / 42934 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=91.7, ups=0.88, wpb=104.4, bsz=40, num_updates=5790, lr=1.68579e-05, gnorm=2.146, clip=100, loss_scale=512, train_wall=11, gb_free=8.5, ema_decay=0.9999, wall=6682
2022-09-27 13:31:41 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-27 13:31:51 - progress_bar.py[line:274] - INFO: epoch 001:   5809 / 42934 loss=0.879, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=82.8, ups=0.8, wpb=103.9, bsz=40, num_updates=5800, lr=1.6887e-05, gnorm=2.343, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=6695
2022-09-27 13:32:02 - progress_bar.py[line:274] - INFO: epoch 001:   5819 / 42934 loss=0.955, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=92.3, ups=0.9, wpb=102.3, bsz=40, num_updates=5810, lr=1.69161e-05, gnorm=2.038, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=6706
2022-09-27 13:32:13 - progress_bar.py[line:274] - INFO: epoch 001:   5829 / 42934 loss=0.899, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=92, ups=0.9, wpb=102.8, bsz=40, num_updates=5820, lr=1.69452e-05, gnorm=2.324, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=6717
2022-09-27 13:32:25 - progress_bar.py[line:274] - INFO: epoch 001:   5839 / 42934 loss=0.828, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.3, ups=0.89, wpb=104.3, bsz=40, num_updates=5830, lr=1.69743e-05, gnorm=1.902, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=6729
2022-09-27 13:32:36 - progress_bar.py[line:274] - INFO: epoch 001:   5849 / 42934 loss=0.862, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.6, ups=0.88, wpb=103.7, bsz=40, num_updates=5840, lr=1.70034e-05, gnorm=2.068, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=6740
2022-09-27 13:32:47 - progress_bar.py[line:274] - INFO: epoch 001:   5859 / 42934 loss=0.896, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=92.1, ups=0.89, wpb=103.5, bsz=40, num_updates=5850, lr=1.70326e-05, gnorm=2.081, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=6751
2022-09-27 13:32:59 - progress_bar.py[line:274] - INFO: epoch 001:   5869 / 42934 loss=0.937, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=91.6, ups=0.88, wpb=103.6, bsz=40, num_updates=5860, lr=1.70617e-05, gnorm=2.309, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=6763
2022-09-27 13:33:10 - progress_bar.py[line:274] - INFO: epoch 001:   5879 / 42934 loss=0.866, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.3, ups=0.87, wpb=101.7, bsz=40, num_updates=5870, lr=1.70908e-05, gnorm=2.161, clip=100, loss_scale=256, train_wall=11, gb_free=8.3, ema_decay=0.9999, wall=6774
2022-09-27 13:33:21 - progress_bar.py[line:274] - INFO: epoch 001:   5889 / 42934 loss=0.88, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.2, ups=0.88, wpb=103.2, bsz=40, num_updates=5880, lr=1.71199e-05, gnorm=1.974, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=6785
2022-09-27 13:33:33 - progress_bar.py[line:274] - INFO: epoch 001:   5899 / 42934 loss=0.925, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=91.5, ups=0.88, wpb=103.6, bsz=40, num_updates=5890, lr=1.7149e-05, gnorm=2.018, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=6797
2022-09-27 13:33:44 - progress_bar.py[line:274] - INFO: epoch 001:   5909 / 42934 loss=0.867, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=104.6, nsentences=40, sample_size=104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.3, ups=0.86, wpb=104.6, bsz=40, num_updates=5900, lr=1.71781e-05, gnorm=1.947, clip=100, loss_scale=256, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=6808
2022-09-27 13:33:56 - progress_bar.py[line:274] - INFO: epoch 001:   5919 / 42934 loss=0.969, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=89.4, ups=0.88, wpb=101.6, bsz=40, num_updates=5910, lr=1.72072e-05, gnorm=2.153, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=6820
2022-09-27 13:34:07 - progress_bar.py[line:274] - INFO: epoch 001:   5929 / 42934 loss=0.908, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.4, ups=0.89, wpb=103, bsz=40, num_updates=5920, lr=1.72364e-05, gnorm=2.231, clip=100, loss_scale=256, train_wall=11, gb_free=7.2, ema_decay=0.9999, wall=6831
2022-09-27 13:34:19 - progress_bar.py[line:274] - INFO: epoch 001:   5939 / 42934 loss=0.861, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89.8, ups=0.87, wpb=103.7, bsz=40, num_updates=5930, lr=1.72655e-05, gnorm=2.039, clip=100, loss_scale=256, train_wall=12, gb_free=8.5, ema_decay=0.9999, wall=6843
2022-09-27 13:34:30 - progress_bar.py[line:274] - INFO: epoch 001:   5949 / 42934 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.7, ups=0.87, wpb=104.5, bsz=40, num_updates=5940, lr=1.72946e-05, gnorm=2.058, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=6854
2022-09-27 13:34:41 - progress_bar.py[line:274] - INFO: epoch 001:   5959 / 42934 loss=0.814, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=105.2, nsentences=40, sample_size=105.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.8, ups=0.88, wpb=105.2, bsz=40, num_updates=5950, lr=1.73237e-05, gnorm=1.91, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=6865
2022-09-27 13:34:52 - progress_bar.py[line:274] - INFO: epoch 001:   5969 / 42934 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93, ups=0.91, wpb=102.3, bsz=40, num_updates=5960, lr=1.73528e-05, gnorm=2.276, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=6876
2022-09-27 13:35:04 - progress_bar.py[line:274] - INFO: epoch 001:   5979 / 42934 loss=0.865, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.9, ups=0.86, wpb=102.4, bsz=40, num_updates=5970, lr=1.73819e-05, gnorm=2.248, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=6888
2022-09-27 13:35:16 - progress_bar.py[line:274] - INFO: epoch 001:   5989 / 42934 loss=0.916, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=88.9, ups=0.87, wpb=102.3, bsz=40, num_updates=5980, lr=1.74111e-05, gnorm=2.133, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=6900
2022-09-27 13:35:27 - progress_bar.py[line:274] - INFO: epoch 001:   5999 / 42934 loss=0.908, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=86.9, ups=0.84, wpb=103.5, bsz=40, num_updates=5990, lr=1.74402e-05, gnorm=2.429, clip=100, loss_scale=256, train_wall=12, gb_free=8.6, ema_decay=0.9999, wall=6912
2022-09-27 13:35:39 - progress_bar.py[line:274] - INFO: epoch 001:   6009 / 42934 loss=0.825, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.4, ups=0.87, wpb=104.7, bsz=40, num_updates=6000, lr=1.74693e-05, gnorm=1.993, clip=100, loss_scale=256, train_wall=11, gb_free=8.3, ema_decay=0.9999, wall=6923
2022-09-27 13:35:51 - progress_bar.py[line:274] - INFO: epoch 001:   6019 / 42934 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=87.6, ups=0.85, wpb=103.5, bsz=40, num_updates=6010, lr=1.74984e-05, gnorm=2.047, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=6935
2022-09-27 13:36:03 - progress_bar.py[line:274] - INFO: epoch 001:   6029 / 42934 loss=0.85, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.1, ups=0.88, wpb=102.5, bsz=40, num_updates=6020, lr=1.75275e-05, gnorm=2.121, clip=100, loss_scale=256, train_wall=11, gb_free=6.6, ema_decay=0.9999, wall=6947
2022-09-27 13:36:14 - progress_bar.py[line:274] - INFO: epoch 001:   6039 / 42934 loss=0.865, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.8, ups=0.86, wpb=103.7, bsz=40, num_updates=6030, lr=1.75566e-05, gnorm=2.158, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=6958
2022-09-27 13:36:25 - progress_bar.py[line:274] - INFO: epoch 001:   6049 / 42934 loss=0.92, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.8, ups=0.9, wpb=101.7, bsz=40, num_updates=6040, lr=1.75857e-05, gnorm=2.425, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6969
2022-09-27 13:36:37 - progress_bar.py[line:274] - INFO: epoch 001:   6059 / 42934 loss=0.88, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.6, ups=0.87, wpb=104.2, bsz=40, num_updates=6050, lr=1.76149e-05, gnorm=2.202, clip=100, loss_scale=256, train_wall=11, gb_free=7.4, ema_decay=0.9999, wall=6981
2022-09-27 13:36:48 - progress_bar.py[line:274] - INFO: epoch 001:   6069 / 42934 loss=0.855, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.7, ups=0.87, wpb=102.8, bsz=40, num_updates=6060, lr=1.7644e-05, gnorm=2.009, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=6992
2022-09-27 13:36:59 - progress_bar.py[line:274] - INFO: epoch 001:   6079 / 42934 loss=0.929, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=92, ups=0.9, wpb=102.3, bsz=40, num_updates=6070, lr=1.76731e-05, gnorm=2.243, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=7004
2022-09-27 13:37:11 - progress_bar.py[line:274] - INFO: epoch 001:   6089 / 42934 loss=0.887, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=90.2, ups=0.87, wpb=103.9, bsz=40, num_updates=6080, lr=1.77022e-05, gnorm=1.883, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=7015
2022-09-27 13:37:23 - progress_bar.py[line:274] - INFO: epoch 001:   6099 / 42934 loss=0.903, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=86.8, ups=0.86, wpb=101, bsz=40, num_updates=6090, lr=1.77313e-05, gnorm=2.289, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=7027
2022-09-27 13:37:34 - progress_bar.py[line:274] - INFO: epoch 001:   6109 / 42934 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=92.4, ups=0.88, wpb=104.4, bsz=40, num_updates=6100, lr=1.77604e-05, gnorm=1.952, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=7038
2022-09-27 13:37:45 - progress_bar.py[line:274] - INFO: epoch 001:   6119 / 42934 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.7, ups=0.88, wpb=101.3, bsz=40, num_updates=6110, lr=1.77896e-05, gnorm=2.465, clip=100, loss_scale=256, train_wall=11, gb_free=8.6, ema_decay=0.9999, wall=7049
2022-09-27 13:37:57 - progress_bar.py[line:274] - INFO: epoch 001:   6129 / 42934 loss=0.941, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=88.9, ups=0.86, wpb=103.4, bsz=40, num_updates=6120, lr=1.78187e-05, gnorm=2.426, clip=100, loss_scale=256, train_wall=12, gb_free=6.9, ema_decay=0.9999, wall=7061
2022-09-27 13:38:09 - progress_bar.py[line:274] - INFO: epoch 001:   6139 / 42934 loss=0.943, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=87, ups=0.85, wpb=102.6, bsz=40, num_updates=6130, lr=1.78478e-05, gnorm=2.056, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=7073
2022-09-27 13:38:20 - progress_bar.py[line:274] - INFO: epoch 001:   6149 / 42934 loss=0.914, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=86.8, ups=0.86, wpb=101.1, bsz=40, num_updates=6140, lr=1.78769e-05, gnorm=2.024, clip=100, loss_scale=256, train_wall=12, gb_free=10, ema_decay=0.9999, wall=7085
2022-09-27 13:38:32 - progress_bar.py[line:274] - INFO: epoch 001:   6159 / 42934 loss=0.911, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=89.4, ups=0.87, wpb=103.4, bsz=40, num_updates=6150, lr=1.7906e-05, gnorm=2.432, clip=100, loss_scale=256, train_wall=12, gb_free=8.9, ema_decay=0.9999, wall=7096
2022-09-27 13:38:44 - progress_bar.py[line:274] - INFO: epoch 001:   6169 / 42934 loss=0.895, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.2, ups=0.86, wpb=103.5, bsz=40, num_updates=6160, lr=1.79351e-05, gnorm=2.142, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=7108
2022-09-27 13:38:55 - progress_bar.py[line:274] - INFO: epoch 001:   6179 / 42934 loss=0.869, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.9, ups=0.87, wpb=101.7, bsz=40, num_updates=6170, lr=1.79642e-05, gnorm=2.279, clip=100, loss_scale=256, train_wall=11, gb_free=8.9, ema_decay=0.9999, wall=7119
2022-09-27 13:39:06 - progress_bar.py[line:274] - INFO: epoch 001:   6189 / 42934 loss=0.915, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=92.5, ups=0.9, wpb=102.4, bsz=40, num_updates=6180, lr=1.79934e-05, gnorm=2.125, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=7130
2022-09-27 13:39:18 - progress_bar.py[line:274] - INFO: epoch 001:   6199 / 42934 loss=0.856, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.7, ups=0.88, wpb=104.4, bsz=40, num_updates=6190, lr=1.80225e-05, gnorm=1.969, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=7142
2022-09-27 13:39:29 - progress_bar.py[line:274] - INFO: epoch 001:   6209 / 42934 loss=0.891, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=86.5, ups=0.85, wpb=102.3, bsz=40, num_updates=6200, lr=1.80516e-05, gnorm=2.006, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=7153
2022-09-27 13:39:41 - progress_bar.py[line:274] - INFO: epoch 001:   6219 / 42934 loss=0.86, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89.2, ups=0.86, wpb=103.6, bsz=40, num_updates=6210, lr=1.80807e-05, gnorm=1.895, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=7165
2022-09-27 13:39:52 - progress_bar.py[line:274] - INFO: epoch 001:   6229 / 42934 loss=0.951, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=90.7, ups=0.88, wpb=102.6, bsz=40, num_updates=6220, lr=1.81098e-05, gnorm=2.468, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=7176
2022-09-27 13:40:04 - progress_bar.py[line:274] - INFO: epoch 001:   6239 / 42934 loss=0.872, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89, ups=0.86, wpb=103.5, bsz=40, num_updates=6230, lr=1.81389e-05, gnorm=2.274, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=7188
2022-09-27 13:40:16 - progress_bar.py[line:274] - INFO: epoch 001:   6249 / 42934 loss=0.846, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.4, ups=0.86, wpb=103.3, bsz=40, num_updates=6240, lr=1.81681e-05, gnorm=2.015, clip=100, loss_scale=256, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=7200
2022-09-27 13:40:27 - progress_bar.py[line:274] - INFO: epoch 001:   6259 / 42934 loss=0.813, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.6, ups=0.87, wpb=103.9, bsz=40, num_updates=6250, lr=1.81972e-05, gnorm=1.954, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=7211
2022-09-27 13:40:39 - progress_bar.py[line:274] - INFO: epoch 001:   6269 / 42934 loss=0.863, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90.3, ups=0.86, wpb=104.5, bsz=40, num_updates=6260, lr=1.82263e-05, gnorm=1.989, clip=100, loss_scale=256, train_wall=12, gb_free=8.7, ema_decay=0.9999, wall=7223
2022-09-27 13:40:51 - progress_bar.py[line:274] - INFO: epoch 001:   6279 / 42934 loss=0.885, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=88.4, ups=0.85, wpb=104.3, bsz=40, num_updates=6270, lr=1.82554e-05, gnorm=2.159, clip=100, loss_scale=256, train_wall=12, gb_free=9, ema_decay=0.9999, wall=7235
2022-09-27 13:41:02 - progress_bar.py[line:274] - INFO: epoch 001:   6289 / 42934 loss=0.858, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=105.4, nsentences=40, sample_size=105.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=94.7, ups=0.9, wpb=105.4, bsz=40, num_updates=6280, lr=1.82845e-05, gnorm=2.154, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=7246
2022-09-27 13:41:13 - progress_bar.py[line:274] - INFO: epoch 001:   6299 / 42934 loss=0.895, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=87.3, ups=0.86, wpb=101.6, bsz=40, num_updates=6290, lr=1.83136e-05, gnorm=2.076, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=7257
2022-09-27 13:41:25 - progress_bar.py[line:274] - INFO: epoch 001:   6309 / 42934 loss=0.91, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=90.7, ups=0.87, wpb=103.7, bsz=40, num_updates=6300, lr=1.83427e-05, gnorm=2.25, clip=100, loss_scale=256, train_wall=11, gb_free=9, ema_decay=0.9999, wall=7269
2022-09-27 13:41:36 - progress_bar.py[line:274] - INFO: epoch 001:   6319 / 42934 loss=0.917, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90.3, ups=0.88, wpb=102.7, bsz=40, num_updates=6310, lr=1.83719e-05, gnorm=2.221, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=7280
2022-09-27 13:41:47 - progress_bar.py[line:274] - INFO: epoch 001:   6329 / 42934 loss=0.915, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=92.6, ups=0.91, wpb=101.7, bsz=40, num_updates=6320, lr=1.8401e-05, gnorm=2.246, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=7291
2022-09-27 13:41:58 - progress_bar.py[line:274] - INFO: epoch 001:   6339 / 42934 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.1, ups=0.9, wpb=101.6, bsz=40, num_updates=6330, lr=1.84301e-05, gnorm=2.027, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=7302
2022-09-27 13:42:10 - progress_bar.py[line:274] - INFO: epoch 001:   6349 / 42934 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=90.9, ups=0.89, wpb=102.7, bsz=40, num_updates=6340, lr=1.84592e-05, gnorm=1.879, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=7314
2022-09-27 13:42:21 - progress_bar.py[line:274] - INFO: epoch 001:   6359 / 42934 loss=0.961, loss_v1=0, loss_v2=0, nll_loss=0.604, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=90.8, ups=0.88, wpb=102.9, bsz=40, num_updates=6350, lr=1.84883e-05, gnorm=2.062, clip=100, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=7325
2022-09-27 13:42:34 - progress_bar.py[line:274] - INFO: epoch 001:   6369 / 42934 loss=0.894, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=90, ups=0.88, wpb=102, bsz=40, num_updates=6360, lr=1.85174e-05, gnorm=2.15, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=7336
2022-09-27 13:42:45 - progress_bar.py[line:274] - INFO: epoch 001:   6379 / 42934 loss=0.929, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=90.3, ups=0.87, wpb=104, bsz=40, num_updates=6370, lr=1.85466e-05, gnorm=2.241, clip=100, loss_scale=512, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=7349
2022-09-27 13:42:57 - progress_bar.py[line:274] - INFO: epoch 001:   6389 / 42934 loss=0.881, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=87.4, ups=0.86, wpb=102, bsz=40, num_updates=6380, lr=1.85757e-05, gnorm=2.167, clip=100, loss_scale=512, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=7361
2022-09-27 13:43:08 - progress_bar.py[line:274] - INFO: epoch 001:   6399 / 42934 loss=0.901, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=93.6, ups=0.91, wpb=102.6, bsz=40, num_updates=6390, lr=1.86048e-05, gnorm=2.504, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=7372
2022-09-27 13:43:20 - progress_bar.py[line:274] - INFO: epoch 001:   6409 / 42934 loss=0.926, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=88.4, ups=0.86, wpb=102.9, bsz=40, num_updates=6400, lr=1.86339e-05, gnorm=2.521, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=7384
2022-09-27 13:43:31 - progress_bar.py[line:274] - INFO: epoch 001:   6419 / 42934 loss=0.914, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=86.9, ups=0.86, wpb=101.1, bsz=40, num_updates=6410, lr=1.8663e-05, gnorm=2.304, clip=100, loss_scale=512, train_wall=12, gb_free=8.9, ema_decay=0.9999, wall=7395
2022-09-27 13:43:42 - progress_bar.py[line:274] - INFO: epoch 001:   6429 / 42934 loss=0.901, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=93.5, ups=0.9, wpb=104.2, bsz=40, num_updates=6420, lr=1.86921e-05, gnorm=2.133, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=7406
2022-09-27 13:43:53 - progress_bar.py[line:274] - INFO: epoch 001:   6439 / 42934 loss=0.978, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=92.7, ups=0.91, wpb=102.4, bsz=40, num_updates=6430, lr=1.87212e-05, gnorm=2.223, clip=100, loss_scale=512, train_wall=11, gb_free=8.4, ema_decay=0.9999, wall=7417
2022-09-27 13:44:05 - progress_bar.py[line:274] - INFO: epoch 001:   6449 / 42934 loss=0.921, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.4, ups=0.85, wpb=103.4, bsz=40, num_updates=6440, lr=1.87504e-05, gnorm=2.17, clip=100, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=7429
2022-09-27 13:44:16 - progress_bar.py[line:274] - INFO: epoch 001:   6459 / 42934 loss=0.943, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=90.5, ups=0.89, wpb=101.5, bsz=40, num_updates=6450, lr=1.87795e-05, gnorm=2.177, clip=100, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=7440
2022-09-27 13:44:28 - progress_bar.py[line:274] - INFO: epoch 001:   6469 / 42934 loss=0.835, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.6, ups=0.9, wpb=103.4, bsz=40, num_updates=6460, lr=1.88086e-05, gnorm=2.079, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=7452
2022-09-27 13:44:38 - progress_bar.py[line:274] - INFO: epoch 001:   6479 / 42934 loss=0.897, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=94.3, ups=0.92, wpb=102.2, bsz=40, num_updates=6470, lr=1.88377e-05, gnorm=2.178, clip=100, loss_scale=512, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=7462
2022-09-27 13:44:41 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-27 13:44:51 - progress_bar.py[line:274] - INFO: epoch 001:   6490 / 42934 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=82.3, ups=0.79, wpb=103.6, bsz=40, num_updates=6480, lr=1.88668e-05, gnorm=2.296, clip=100, loss_scale=256, train_wall=13, gb_free=9.3, ema_decay=0.9999, wall=7475
2022-09-27 13:45:03 - progress_bar.py[line:274] - INFO: epoch 001:   6500 / 42934 loss=0.911, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.4, ups=0.86, wpb=102.6, bsz=40, num_updates=6490, lr=1.88959e-05, gnorm=2.337, clip=100, loss_scale=256, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=7487
2022-09-27 13:45:14 - progress_bar.py[line:274] - INFO: epoch 001:   6510 / 42934 loss=0.912, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.1, ups=0.89, wpb=101.6, bsz=40, num_updates=6500, lr=1.89251e-05, gnorm=2.093, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=7498
2022-09-27 13:45:25 - progress_bar.py[line:274] - INFO: epoch 001:   6520 / 42934 loss=0.922, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=93.3, ups=0.89, wpb=104.4, bsz=40, num_updates=6510, lr=1.89542e-05, gnorm=2.181, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=7509
2022-09-27 13:45:37 - progress_bar.py[line:274] - INFO: epoch 001:   6530 / 42934 loss=0.895, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=86.2, ups=0.86, wpb=100, bsz=40, num_updates=6520, lr=1.89833e-05, gnorm=2.054, clip=100, loss_scale=256, train_wall=12, gb_free=9.2, ema_decay=0.9999, wall=7521
2022-09-27 13:45:48 - progress_bar.py[line:274] - INFO: epoch 001:   6540 / 42934 loss=0.879, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.9, ups=0.87, wpb=104.4, bsz=40, num_updates=6530, lr=1.90124e-05, gnorm=1.985, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=7532
2022-09-27 13:46:00 - progress_bar.py[line:274] - INFO: epoch 001:   6550 / 42934 loss=0.883, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.1, ups=0.85, wpb=103, bsz=40, num_updates=6540, lr=1.90415e-05, gnorm=2.335, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=7544
2022-09-27 13:46:12 - progress_bar.py[line:274] - INFO: epoch 001:   6560 / 42934 loss=0.882, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.1, ups=0.86, wpb=103.2, bsz=40, num_updates=6550, lr=1.90706e-05, gnorm=2.084, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=7556
2022-09-27 13:46:23 - progress_bar.py[line:274] - INFO: epoch 001:   6570 / 42934 loss=0.869, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.7, ups=0.85, wpb=103.2, bsz=40, num_updates=6560, lr=1.90997e-05, gnorm=2.292, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=7567
2022-09-27 13:46:35 - progress_bar.py[line:274] - INFO: epoch 001:   6580 / 42934 loss=0.936, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=91.4, ups=0.88, wpb=103.6, bsz=40, num_updates=6570, lr=1.91289e-05, gnorm=2.211, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=7579
2022-09-27 13:46:46 - progress_bar.py[line:274] - INFO: epoch 001:   6590 / 42934 loss=0.925, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=87.6, ups=0.86, wpb=101.7, bsz=40, num_updates=6580, lr=1.9158e-05, gnorm=2.279, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=7590
2022-09-27 13:46:58 - progress_bar.py[line:274] - INFO: epoch 001:   6600 / 42934 loss=0.854, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.2, ups=0.87, wpb=103.4, bsz=40, num_updates=6590, lr=1.91871e-05, gnorm=2.218, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=7602
2022-09-27 13:47:09 - progress_bar.py[line:274] - INFO: epoch 001:   6610 / 42934 loss=0.863, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.7, ups=0.87, wpb=103.1, bsz=40, num_updates=6600, lr=1.92162e-05, gnorm=2.043, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=7613
2022-09-27 13:47:21 - progress_bar.py[line:274] - INFO: epoch 001:   6620 / 42934 loss=0.814, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=106, nsentences=40, sample_size=106, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.9, ups=0.88, wpb=106, bsz=40, num_updates=6610, lr=1.92453e-05, gnorm=1.97, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=7625
2022-09-27 13:47:32 - progress_bar.py[line:274] - INFO: epoch 001:   6630 / 42934 loss=0.863, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=93.4, ups=0.9, wpb=104.1, bsz=40, num_updates=6620, lr=1.92744e-05, gnorm=2.002, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=7636
2022-09-27 13:47:43 - progress_bar.py[line:274] - INFO: epoch 001:   6640 / 42934 loss=0.917, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=89.4, ups=0.86, wpb=103.6, bsz=40, num_updates=6630, lr=1.93036e-05, gnorm=2.082, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=7648
2022-09-27 13:47:55 - progress_bar.py[line:274] - INFO: epoch 001:   6650 / 42934 loss=0.877, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.2, ups=0.87, wpb=103.3, bsz=40, num_updates=6640, lr=1.93327e-05, gnorm=1.975, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=7659
2022-09-27 13:48:07 - progress_bar.py[line:274] - INFO: epoch 001:   6660 / 42934 loss=0.91, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.5, ups=0.87, wpb=102.5, bsz=40, num_updates=6650, lr=1.93618e-05, gnorm=2.208, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=7671
2022-09-27 13:48:18 - progress_bar.py[line:274] - INFO: epoch 001:   6670 / 42934 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=90.2, ups=0.88, wpb=102.9, bsz=40, num_updates=6660, lr=1.93909e-05, gnorm=2.145, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=7682
2022-09-27 13:48:29 - progress_bar.py[line:274] - INFO: epoch 001:   6680 / 42934 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.5, ups=0.89, wpb=103.4, bsz=40, num_updates=6670, lr=1.942e-05, gnorm=2.089, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=7693
2022-09-27 13:48:41 - progress_bar.py[line:274] - INFO: epoch 001:   6690 / 42934 loss=0.874, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.3, ups=0.87, wpb=104.3, bsz=40, num_updates=6680, lr=1.94491e-05, gnorm=2.225, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=7705
2022-09-27 13:48:53 - progress_bar.py[line:274] - INFO: epoch 001:   6700 / 42934 loss=0.839, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=85.3, ups=0.83, wpb=102.4, bsz=40, num_updates=6690, lr=1.94783e-05, gnorm=2.067, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=7717
2022-09-27 13:49:04 - progress_bar.py[line:274] - INFO: epoch 001:   6710 / 42934 loss=0.87, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.6, ups=0.88, wpb=103.6, bsz=40, num_updates=6700, lr=1.95074e-05, gnorm=2.105, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=7728
2022-09-27 13:49:15 - progress_bar.py[line:274] - INFO: epoch 001:   6720 / 42934 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.3, ups=0.9, wpb=101.9, bsz=40, num_updates=6710, lr=1.95365e-05, gnorm=2.449, clip=100, loss_scale=256, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=7739
2022-09-27 13:49:27 - progress_bar.py[line:274] - INFO: epoch 001:   6730 / 42934 loss=0.937, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=90.8, ups=0.88, wpb=102.8, bsz=40, num_updates=6720, lr=1.95656e-05, gnorm=2.304, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=7751
2022-09-27 13:49:38 - progress_bar.py[line:274] - INFO: epoch 001:   6740 / 42934 loss=0.848, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.8, ups=0.86, wpb=103.2, bsz=40, num_updates=6730, lr=1.95947e-05, gnorm=2.192, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=7762
2022-09-27 13:49:50 - progress_bar.py[line:274] - INFO: epoch 001:   6750 / 42934 loss=0.85, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.4, ups=0.86, wpb=102.3, bsz=40, num_updates=6740, lr=1.96238e-05, gnorm=2.185, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=7774
2022-09-27 13:50:02 - progress_bar.py[line:274] - INFO: epoch 001:   6760 / 42934 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=87.6, ups=0.86, wpb=102.2, bsz=40, num_updates=6750, lr=1.96529e-05, gnorm=2.471, clip=100, loss_scale=256, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=7786
2022-09-27 13:50:13 - progress_bar.py[line:274] - INFO: epoch 001:   6770 / 42934 loss=0.873, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.5, ups=0.89, wpb=102.3, bsz=40, num_updates=6760, lr=1.96821e-05, gnorm=2.004, clip=100, loss_scale=256, train_wall=11, gb_free=9, ema_decay=0.9999, wall=7797
2022-09-27 13:50:24 - progress_bar.py[line:274] - INFO: epoch 001:   6780 / 42934 loss=0.907, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92, ups=0.89, wpb=104, bsz=40, num_updates=6770, lr=1.97112e-05, gnorm=2.189, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=7808
2022-09-27 13:50:36 - progress_bar.py[line:274] - INFO: epoch 001:   6790 / 42934 loss=0.858, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.9, ups=0.85, wpb=104.1, bsz=40, num_updates=6780, lr=1.97403e-05, gnorm=2.019, clip=100, loss_scale=256, train_wall=12, gb_free=8.9, ema_decay=0.9999, wall=7820
2022-09-27 13:50:47 - progress_bar.py[line:274] - INFO: epoch 001:   6800 / 42934 loss=0.873, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.5, ups=0.88, wpb=104.7, bsz=40, num_updates=6790, lr=1.97694e-05, gnorm=2.092, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=7831
2022-09-27 13:50:58 - progress_bar.py[line:274] - INFO: epoch 001:   6810 / 42934 loss=0.94, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.4, ups=0.88, wpb=101.4, bsz=40, num_updates=6800, lr=1.97985e-05, gnorm=2.056, clip=100, loss_scale=256, train_wall=11, gb_free=9, ema_decay=0.9999, wall=7843
2022-09-27 13:51:09 - progress_bar.py[line:274] - INFO: epoch 001:   6820 / 42934 loss=0.914, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92.8, ups=0.91, wpb=101.9, bsz=40, num_updates=6810, lr=1.98276e-05, gnorm=2.083, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=7854
2022-09-27 13:51:21 - progress_bar.py[line:274] - INFO: epoch 001:   6830 / 42934 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88.9, ups=0.86, wpb=102.9, bsz=40, num_updates=6820, lr=1.98568e-05, gnorm=2.18, clip=100, loss_scale=256, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=7865
2022-09-27 13:51:33 - progress_bar.py[line:274] - INFO: epoch 001:   6840 / 42934 loss=0.932, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=88.5, ups=0.86, wpb=102.4, bsz=40, num_updates=6830, lr=1.98859e-05, gnorm=2.328, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=7877
2022-09-27 13:51:44 - progress_bar.py[line:274] - INFO: epoch 001:   6850 / 42934 loss=0.864, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89, ups=0.87, wpb=102.7, bsz=40, num_updates=6840, lr=1.9915e-05, gnorm=1.886, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=7888
2022-09-27 13:51:56 - progress_bar.py[line:274] - INFO: epoch 001:   6860 / 42934 loss=0.902, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=87.2, ups=0.86, wpb=101.9, bsz=40, num_updates=6850, lr=1.99441e-05, gnorm=2.398, clip=100, loss_scale=256, train_wall=12, gb_free=8.9, ema_decay=0.9999, wall=7900
2022-09-27 13:52:08 - progress_bar.py[line:274] - INFO: epoch 001:   6870 / 42934 loss=0.857, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.2, ups=0.85, wpb=103, bsz=40, num_updates=6860, lr=1.99732e-05, gnorm=2.061, clip=100, loss_scale=256, train_wall=12, gb_free=8.5, ema_decay=0.9999, wall=7912
2022-09-27 13:52:19 - progress_bar.py[line:274] - INFO: epoch 001:   6880 / 42934 loss=0.9, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=93, ups=0.9, wpb=103.8, bsz=40, num_updates=6870, lr=2.00023e-05, gnorm=2.169, clip=100, loss_scale=256, train_wall=11, gb_free=8.7, ema_decay=0.9999, wall=7923
2022-09-27 13:52:30 - progress_bar.py[line:274] - INFO: epoch 001:   6890 / 42934 loss=0.881, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92, ups=0.89, wpb=103.1, bsz=40, num_updates=6880, lr=2.00314e-05, gnorm=2.051, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=7934
2022-09-27 13:52:42 - progress_bar.py[line:274] - INFO: epoch 001:   6900 / 42934 loss=0.931, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.7, ups=0.87, wpb=101.6, bsz=40, num_updates=6890, lr=2.00606e-05, gnorm=2.355, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=7946
2022-09-27 13:52:53 - progress_bar.py[line:274] - INFO: epoch 001:   6910 / 42934 loss=0.875, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=104.6, nsentences=40, sample_size=104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.4, ups=0.87, wpb=104.6, bsz=40, num_updates=6900, lr=2.00897e-05, gnorm=2.022, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=7957
2022-09-27 13:53:04 - progress_bar.py[line:274] - INFO: epoch 001:   6920 / 42934 loss=0.895, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.2, ups=0.89, wpb=102.3, bsz=40, num_updates=6910, lr=2.01188e-05, gnorm=2.178, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=7968
2022-09-27 13:53:15 - progress_bar.py[line:274] - INFO: epoch 001:   6930 / 42934 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96.8, ups=0.94, wpb=103.2, bsz=40, num_updates=6920, lr=2.01479e-05, gnorm=2.21, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=7979
2022-09-27 13:53:27 - progress_bar.py[line:274] - INFO: epoch 001:   6940 / 42934 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=89.3, ups=0.87, wpb=102.7, bsz=40, num_updates=6930, lr=2.0177e-05, gnorm=2.449, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=7991
2022-09-27 13:53:38 - progress_bar.py[line:274] - INFO: epoch 001:   6950 / 42934 loss=0.887, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.6, ups=0.87, wpb=102.9, bsz=40, num_updates=6940, lr=2.02061e-05, gnorm=2.045, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8002
2022-09-27 13:53:50 - progress_bar.py[line:274] - INFO: epoch 001:   6960 / 42934 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=87.2, ups=0.85, wpb=102.7, bsz=40, num_updates=6950, lr=2.02353e-05, gnorm=2.408, clip=100, loss_scale=256, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=8014
2022-09-27 13:54:01 - progress_bar.py[line:274] - INFO: epoch 001:   6970 / 42934 loss=0.856, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=6960, lr=2.02644e-05, gnorm=2.187, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8025
2022-09-27 13:54:13 - progress_bar.py[line:274] - INFO: epoch 001:   6980 / 42934 loss=0.887, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88.2, ups=0.86, wpb=103, bsz=40, num_updates=6970, lr=2.02935e-05, gnorm=2.527, clip=100, loss_scale=256, train_wall=12, gb_free=7.7, ema_decay=0.9999, wall=8037
2022-09-27 13:54:24 - progress_bar.py[line:274] - INFO: epoch 001:   6990 / 42934 loss=0.882, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.7, ups=0.89, wpb=102.6, bsz=40, num_updates=6980, lr=2.03226e-05, gnorm=2.178, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8048
2022-09-27 13:54:36 - progress_bar.py[line:274] - INFO: epoch 001:   7000 / 42934 loss=0.844, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.4, ups=0.86, wpb=103.6, bsz=40, num_updates=6990, lr=2.03517e-05, gnorm=1.854, clip=100, loss_scale=512, train_wall=12, gb_free=8.2, ema_decay=0.9999, wall=8060
2022-09-27 13:54:40 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-27 13:54:48 - progress_bar.py[line:274] - INFO: epoch 001:   7011 / 42934 loss=0.913, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=84.9, ups=0.82, wpb=103.4, bsz=40, num_updates=7000, lr=2.03808e-05, gnorm=2.231, clip=100, loss_scale=256, train_wall=12, gb_free=9.2, ema_decay=0.9999, wall=8072
2022-09-27 13:55:00 - progress_bar.py[line:274] - INFO: epoch 001:   7021 / 42934 loss=0.882, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92, ups=0.88, wpb=104, bsz=40, num_updates=7010, lr=2.04099e-05, gnorm=2.367, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=8084
2022-09-27 13:55:10 - progress_bar.py[line:274] - INFO: epoch 001:   7031 / 42934 loss=0.895, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.7, ups=0.91, wpb=101.6, bsz=40, num_updates=7020, lr=2.04391e-05, gnorm=1.981, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8095
2022-09-27 13:55:22 - progress_bar.py[line:274] - INFO: epoch 001:   7041 / 42934 loss=0.915, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.1, ups=0.88, wpb=102.2, bsz=40, num_updates=7030, lr=2.04682e-05, gnorm=1.95, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=8106
2022-09-27 13:55:33 - progress_bar.py[line:274] - INFO: epoch 001:   7051 / 42934 loss=0.87, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90.6, ups=0.89, wpb=102.1, bsz=40, num_updates=7040, lr=2.04973e-05, gnorm=2.003, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8117
2022-09-27 13:55:44 - progress_bar.py[line:274] - INFO: epoch 001:   7061 / 42934 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=95.5, ups=0.92, wpb=104.2, bsz=40, num_updates=7050, lr=2.05264e-05, gnorm=2.08, clip=100, loss_scale=256, train_wall=11, gb_free=7.6, ema_decay=0.9999, wall=8128
2022-09-27 13:55:55 - progress_bar.py[line:274] - INFO: epoch 001:   7071 / 42934 loss=0.883, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.6, ups=0.88, wpb=104, bsz=40, num_updates=7060, lr=2.05555e-05, gnorm=2.12, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8139
2022-09-27 13:56:07 - progress_bar.py[line:274] - INFO: epoch 001:   7081 / 42934 loss=0.916, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90.7, ups=0.89, wpb=102.2, bsz=40, num_updates=7070, lr=2.05846e-05, gnorm=2.136, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=8151
2022-09-27 13:56:18 - progress_bar.py[line:274] - INFO: epoch 001:   7091 / 42934 loss=0.926, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.2, ups=0.87, wpb=102.1, bsz=40, num_updates=7080, lr=2.06138e-05, gnorm=2.218, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=8162
2022-09-27 13:56:30 - progress_bar.py[line:274] - INFO: epoch 001:   7101 / 42934 loss=0.872, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=88, ups=0.86, wpb=102.8, bsz=40, num_updates=7090, lr=2.06429e-05, gnorm=2.101, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=8174
2022-09-27 13:56:41 - progress_bar.py[line:274] - INFO: epoch 001:   7111 / 42934 loss=0.896, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=91.7, ups=0.88, wpb=103.7, bsz=40, num_updates=7100, lr=2.0672e-05, gnorm=1.876, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8185
2022-09-27 13:56:53 - progress_bar.py[line:274] - INFO: epoch 001:   7121 / 42934 loss=0.82, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=104.8, nsentences=40, sample_size=104.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.4, ups=0.85, wpb=104.8, bsz=40, num_updates=7110, lr=2.07011e-05, gnorm=1.729, clip=100, loss_scale=256, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=8197
2022-09-27 13:57:04 - progress_bar.py[line:274] - INFO: epoch 001:   7131 / 42934 loss=0.904, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=87.2, ups=0.86, wpb=101.7, bsz=40, num_updates=7120, lr=2.07302e-05, gnorm=1.907, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=8209
2022-09-27 13:57:16 - progress_bar.py[line:274] - INFO: epoch 001:   7141 / 42934 loss=0.854, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=105.7, nsentences=40, sample_size=105.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=92.4, ups=0.87, wpb=105.7, bsz=40, num_updates=7130, lr=2.07593e-05, gnorm=1.702, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=8220
2022-09-27 13:57:28 - progress_bar.py[line:274] - INFO: epoch 001:   7151 / 42934 loss=0.846, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.6, ups=0.85, wpb=103, bsz=40, num_updates=7140, lr=2.07884e-05, gnorm=1.799, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=8232
2022-09-27 13:57:39 - progress_bar.py[line:274] - INFO: epoch 001:   7161 / 42934 loss=0.981, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=86.6, ups=0.85, wpb=101.9, bsz=40, num_updates=7150, lr=2.08176e-05, gnorm=2.662, clip=100, loss_scale=256, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=8244
2022-09-27 13:57:51 - progress_bar.py[line:274] - INFO: epoch 001:   7171 / 42934 loss=0.852, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.8, ups=0.88, wpb=104.1, bsz=40, num_updates=7160, lr=2.08467e-05, gnorm=1.784, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=8255
2022-09-27 13:58:02 - progress_bar.py[line:274] - INFO: epoch 001:   7181 / 42934 loss=0.9, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.8, ups=0.88, wpb=102.4, bsz=40, num_updates=7170, lr=2.08758e-05, gnorm=1.961, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8266
2022-09-27 13:58:14 - progress_bar.py[line:274] - INFO: epoch 001:   7191 / 42934 loss=0.839, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.5, ups=0.87, wpb=103.4, bsz=40, num_updates=7180, lr=2.09049e-05, gnorm=1.816, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=8278
2022-09-27 13:58:25 - progress_bar.py[line:274] - INFO: epoch 001:   7201 / 42934 loss=0.95, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=90.4, ups=0.9, wpb=100.3, bsz=40, num_updates=7190, lr=2.0934e-05, gnorm=1.867, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=8289
2022-09-27 13:58:36 - progress_bar.py[line:274] - INFO: epoch 001:   7211 / 42934 loss=0.802, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.88, wpb=103.8, bsz=40, num_updates=7200, lr=2.09631e-05, gnorm=1.755, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=8300
2022-09-27 13:58:48 - progress_bar.py[line:274] - INFO: epoch 001:   7221 / 42934 loss=0.849, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.1, ups=0.86, wpb=104.3, bsz=40, num_updates=7210, lr=2.09923e-05, gnorm=2.04, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=8312
2022-09-27 13:59:00 - progress_bar.py[line:274] - INFO: epoch 001:   7231 / 42934 loss=0.88, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=86.2, ups=0.85, wpb=101.6, bsz=40, num_updates=7220, lr=2.10214e-05, gnorm=2.198, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=8324
2022-09-27 13:59:11 - progress_bar.py[line:274] - INFO: epoch 001:   7241 / 42934 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.5, ups=0.87, wpb=104.1, bsz=40, num_updates=7230, lr=2.10505e-05, gnorm=1.847, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=8335
2022-09-27 13:59:23 - progress_bar.py[line:274] - INFO: epoch 001:   7251 / 42934 loss=0.909, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=88.3, ups=0.86, wpb=102.2, bsz=40, num_updates=7240, lr=2.10796e-05, gnorm=2.224, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=8347
2022-09-27 13:59:35 - progress_bar.py[line:274] - INFO: epoch 001:   7261 / 42934 loss=0.856, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=86.7, ups=0.85, wpb=101.9, bsz=40, num_updates=7250, lr=2.11087e-05, gnorm=1.907, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=8359
2022-09-27 13:59:47 - progress_bar.py[line:274] - INFO: epoch 001:   7271 / 42934 loss=0.906, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=87.5, ups=0.85, wpb=102.5, bsz=40, num_updates=7260, lr=2.11378e-05, gnorm=1.919, clip=100, loss_scale=256, train_wall=12, gb_free=7, ema_decay=0.9999, wall=8371
2022-09-27 13:59:58 - progress_bar.py[line:274] - INFO: epoch 001:   7281 / 42934 loss=0.91, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=88.8, ups=0.87, wpb=101.9, bsz=40, num_updates=7270, lr=2.11669e-05, gnorm=1.811, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=8382
2022-09-27 14:00:09 - progress_bar.py[line:274] - INFO: epoch 001:   7291 / 42934 loss=0.902, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.6, ups=0.87, wpb=103, bsz=40, num_updates=7280, lr=2.11961e-05, gnorm=1.98, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=8394
2022-09-27 14:00:21 - progress_bar.py[line:274] - INFO: epoch 001:   7301 / 42934 loss=0.866, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=87.4, ups=0.84, wpb=103.8, bsz=40, num_updates=7290, lr=2.12252e-05, gnorm=1.97, clip=100, loss_scale=256, train_wall=12, gb_free=8, ema_decay=0.9999, wall=8405
2022-09-27 14:00:33 - progress_bar.py[line:274] - INFO: epoch 001:   7311 / 42934 loss=0.849, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.8, ups=0.89, wpb=102.5, bsz=40, num_updates=7300, lr=2.12543e-05, gnorm=1.768, clip=100, loss_scale=256, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=8417
2022-09-27 14:00:44 - progress_bar.py[line:274] - INFO: epoch 001:   7321 / 42934 loss=0.914, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.7, ups=0.86, wpb=103.2, bsz=40, num_updates=7310, lr=2.12834e-05, gnorm=1.981, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=8428
2022-09-27 14:00:55 - progress_bar.py[line:274] - INFO: epoch 001:   7331 / 42934 loss=0.932, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=92.7, ups=0.9, wpb=103.1, bsz=40, num_updates=7320, lr=2.13125e-05, gnorm=2.073, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=8440
2022-09-27 14:01:07 - progress_bar.py[line:274] - INFO: epoch 001:   7341 / 42934 loss=0.905, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.5, ups=0.88, wpb=103.9, bsz=40, num_updates=7330, lr=2.13416e-05, gnorm=1.987, clip=100, loss_scale=256, train_wall=11, gb_free=8, ema_decay=0.9999, wall=8451
2022-09-27 14:01:18 - progress_bar.py[line:274] - INFO: epoch 001:   7351 / 42934 loss=0.92, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.2, ups=0.86, wpb=102.3, bsz=40, num_updates=7340, lr=2.13708e-05, gnorm=1.912, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=8462
2022-09-27 14:01:30 - progress_bar.py[line:274] - INFO: epoch 001:   7361 / 42934 loss=0.824, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=105.1, nsentences=40, sample_size=105.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.4, ups=0.86, wpb=105.1, bsz=40, num_updates=7350, lr=2.13999e-05, gnorm=2.087, clip=100, loss_scale=256, train_wall=12, gb_free=7.8, ema_decay=0.9999, wall=8474
2022-09-27 14:01:41 - progress_bar.py[line:274] - INFO: epoch 001:   7371 / 42934 loss=0.947, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=90.3, ups=0.88, wpb=103.1, bsz=40, num_updates=7360, lr=2.1429e-05, gnorm=2.242, clip=100, loss_scale=256, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=8486
2022-09-27 14:01:53 - progress_bar.py[line:274] - INFO: epoch 001:   7381 / 42934 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.5, ups=0.86, wpb=102.8, bsz=40, num_updates=7370, lr=2.14581e-05, gnorm=2.16, clip=100, loss_scale=256, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=8497
2022-09-27 14:02:04 - progress_bar.py[line:274] - INFO: epoch 001:   7391 / 42934 loss=0.946, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=90.7, ups=0.88, wpb=103, bsz=40, num_updates=7380, lr=2.14872e-05, gnorm=2.217, clip=100, loss_scale=256, train_wall=11, gb_free=9, ema_decay=0.9999, wall=8509
2022-09-27 14:02:16 - progress_bar.py[line:274] - INFO: epoch 001:   7401 / 42934 loss=0.828, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.7, ups=0.88, wpb=103.6, bsz=40, num_updates=7390, lr=2.15163e-05, gnorm=1.824, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=8520
2022-09-27 14:02:27 - progress_bar.py[line:274] - INFO: epoch 001:   7411 / 42934 loss=0.921, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.3, ups=0.86, wpb=102.2, bsz=40, num_updates=7400, lr=2.15454e-05, gnorm=2.15, clip=100, loss_scale=256, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=8532
2022-09-27 14:02:39 - progress_bar.py[line:274] - INFO: epoch 001:   7421 / 42934 loss=0.924, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88, ups=0.87, wpb=101.5, bsz=40, num_updates=7410, lr=2.15746e-05, gnorm=2.033, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=8543
2022-09-27 14:02:50 - progress_bar.py[line:274] - INFO: epoch 001:   7431 / 42934 loss=0.935, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=92.2, ups=0.88, wpb=104.4, bsz=40, num_updates=7420, lr=2.16037e-05, gnorm=2.171, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8554
2022-09-27 14:03:02 - progress_bar.py[line:274] - INFO: epoch 001:   7441 / 42934 loss=0.921, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.3, ups=0.85, wpb=103.3, bsz=40, num_updates=7430, lr=2.16328e-05, gnorm=2.115, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=8566
2022-09-27 14:03:13 - progress_bar.py[line:274] - INFO: epoch 001:   7451 / 42934 loss=0.855, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.4, ups=0.91, wpb=103.8, bsz=40, num_updates=7440, lr=2.16619e-05, gnorm=1.674, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=8577
2022-09-27 14:03:24 - progress_bar.py[line:274] - INFO: epoch 001:   7461 / 42934 loss=0.866, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=92.1, ups=0.89, wpb=103, bsz=40, num_updates=7450, lr=2.1691e-05, gnorm=1.899, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=8588
2022-09-27 14:03:36 - progress_bar.py[line:274] - INFO: epoch 001:   7471 / 42934 loss=0.919, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90.3, ups=0.87, wpb=103.5, bsz=40, num_updates=7460, lr=2.17201e-05, gnorm=1.832, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=8600
2022-09-27 14:03:48 - progress_bar.py[line:274] - INFO: epoch 001:   7481 / 42934 loss=0.903, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=88.6, ups=0.87, wpb=102.1, bsz=40, num_updates=7470, lr=2.17493e-05, gnorm=2.073, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=8612
2022-09-27 14:03:59 - progress_bar.py[line:274] - INFO: epoch 001:   7491 / 42934 loss=0.952, loss_v1=0, loss_v2=0, nll_loss=0.587, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=91.3, ups=0.89, wpb=102.3, bsz=40, num_updates=7480, lr=2.17784e-05, gnorm=2.085, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=8623
2022-09-27 14:04:10 - progress_bar.py[line:274] - INFO: epoch 001:   7501 / 42934 loss=0.97, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=90.9, ups=0.89, wpb=101.9, bsz=40, num_updates=7490, lr=2.18075e-05, gnorm=2.077, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=8634
2022-09-27 14:04:21 - progress_bar.py[line:274] - INFO: epoch 001:   7511 / 42934 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.3, ups=0.89, wpb=102.3, bsz=40, num_updates=7500, lr=2.18366e-05, gnorm=1.942, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=8645
2022-09-27 14:04:33 - progress_bar.py[line:274] - INFO: epoch 001:   7521 / 42934 loss=0.895, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.5, ups=0.87, wpb=102.6, bsz=40, num_updates=7510, lr=2.18657e-05, gnorm=1.839, clip=100, loss_scale=512, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=8657
2022-09-27 14:04:45 - progress_bar.py[line:274] - INFO: epoch 001:   7531 / 42934 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=84.6, ups=0.84, wpb=100.9, bsz=40, num_updates=7520, lr=2.18948e-05, gnorm=2.119, clip=100, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=8669
2022-09-27 14:04:56 - progress_bar.py[line:274] - INFO: epoch 001:   7541 / 42934 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.1, ups=0.86, wpb=101.9, bsz=40, num_updates=7530, lr=2.1924e-05, gnorm=1.923, clip=100, loss_scale=512, train_wall=12, gb_free=10, ema_decay=0.9999, wall=8680
2022-09-27 14:05:08 - progress_bar.py[line:274] - INFO: epoch 001:   7551 / 42934 loss=0.945, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=89.1, ups=0.87, wpb=102, bsz=40, num_updates=7540, lr=2.19531e-05, gnorm=2.118, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=8692
2022-09-27 14:05:19 - progress_bar.py[line:274] - INFO: epoch 001:   7561 / 42934 loss=0.814, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.3, ups=0.88, wpb=102.5, bsz=40, num_updates=7550, lr=2.19822e-05, gnorm=1.867, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=8703
2022-09-27 14:05:30 - progress_bar.py[line:274] - INFO: epoch 001:   7571 / 42934 loss=0.885, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.3, ups=0.88, wpb=103.7, bsz=40, num_updates=7560, lr=2.20113e-05, gnorm=2.12, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=8714
2022-09-27 14:05:42 - progress_bar.py[line:274] - INFO: epoch 001:   7581 / 42934 loss=0.897, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.2, ups=0.87, wpb=102.5, bsz=40, num_updates=7570, lr=2.20404e-05, gnorm=2.22, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=8726
2022-09-27 14:05:54 - progress_bar.py[line:274] - INFO: epoch 001:   7591 / 42934 loss=0.92, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=89.9, ups=0.88, wpb=102.1, bsz=40, num_updates=7580, lr=2.20695e-05, gnorm=2.089, clip=100, loss_scale=512, train_wall=11, gb_free=7.7, ema_decay=0.9999, wall=8737
2022-09-27 14:06:06 - progress_bar.py[line:274] - INFO: epoch 001:   7601 / 42934 loss=0.867, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.1, ups=0.87, wpb=102.7, bsz=40, num_updates=7590, lr=2.20986e-05, gnorm=1.868, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=8750
2022-09-27 14:06:17 - progress_bar.py[line:274] - INFO: epoch 001:   7611 / 42934 loss=0.863, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90.8, ups=0.88, wpb=103.7, bsz=40, num_updates=7600, lr=2.21278e-05, gnorm=1.968, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8761
2022-09-27 14:06:28 - progress_bar.py[line:274] - INFO: epoch 001:   7621 / 42934 loss=0.905, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.8, ups=0.9, wpb=102.4, bsz=40, num_updates=7610, lr=2.21569e-05, gnorm=1.957, clip=100, loss_scale=512, train_wall=11, gb_free=8.9, ema_decay=0.9999, wall=8772
2022-09-27 14:06:40 - progress_bar.py[line:274] - INFO: epoch 001:   7631 / 42934 loss=0.905, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.7, ups=0.87, wpb=103.2, bsz=40, num_updates=7620, lr=2.2186e-05, gnorm=1.896, clip=100, loss_scale=512, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=8784
2022-09-27 14:06:51 - progress_bar.py[line:274] - INFO: epoch 001:   7641 / 42934 loss=0.881, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.7, ups=0.89, wpb=102.8, bsz=40, num_updates=7630, lr=2.22151e-05, gnorm=2.045, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8795
2022-09-27 14:07:02 - progress_bar.py[line:274] - INFO: epoch 001:   7651 / 42934 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.5, ups=0.87, wpb=102.8, bsz=40, num_updates=7640, lr=2.22442e-05, gnorm=1.985, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=8806
2022-09-27 14:07:14 - progress_bar.py[line:274] - INFO: epoch 001:   7661 / 42934 loss=0.841, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.7, ups=0.89, wpb=104.3, bsz=40, num_updates=7650, lr=2.22733e-05, gnorm=1.913, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8818
2022-09-27 14:07:25 - progress_bar.py[line:274] - INFO: epoch 001:   7671 / 42934 loss=0.885, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.6, ups=0.87, wpb=103.1, bsz=40, num_updates=7660, lr=2.23025e-05, gnorm=1.972, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=8829
2022-09-27 14:07:37 - progress_bar.py[line:274] - INFO: epoch 001:   7681 / 42934 loss=0.935, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=85.4, ups=0.85, wpb=100.6, bsz=40, num_updates=7670, lr=2.23316e-05, gnorm=1.985, clip=100, loss_scale=512, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=8841
2022-09-27 14:07:49 - progress_bar.py[line:274] - INFO: epoch 001:   7691 / 42934 loss=0.858, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.5, ups=0.87, wpb=102.9, bsz=40, num_updates=7680, lr=2.23607e-05, gnorm=2.048, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8853
2022-09-27 14:08:00 - progress_bar.py[line:274] - INFO: epoch 001:   7701 / 42934 loss=0.909, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.9, ups=0.88, wpb=102.4, bsz=40, num_updates=7690, lr=2.23898e-05, gnorm=1.893, clip=100, loss_scale=512, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=8864
2022-09-27 14:08:12 - progress_bar.py[line:274] - INFO: epoch 001:   7711 / 42934 loss=0.814, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.3, ups=0.87, wpb=104.2, bsz=40, num_updates=7700, lr=2.24189e-05, gnorm=1.761, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=8876
2022-09-27 14:08:23 - progress_bar.py[line:274] - INFO: epoch 001:   7721 / 42934 loss=0.87, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.1, ups=0.87, wpb=103.6, bsz=40, num_updates=7710, lr=2.2448e-05, gnorm=2.182, clip=100, loss_scale=512, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=8887
2022-09-27 14:08:34 - progress_bar.py[line:274] - INFO: epoch 001:   7731 / 42934 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.9, ups=0.89, wpb=102.4, bsz=40, num_updates=7720, lr=2.24771e-05, gnorm=1.776, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=8899
2022-09-27 14:08:37 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-27 14:08:47 - progress_bar.py[line:274] - INFO: epoch 001:   7742 / 42934 loss=0.874, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=81, ups=0.79, wpb=103.2, bsz=40, num_updates=7730, lr=2.25063e-05, gnorm=2.006, clip=100, loss_scale=256, train_wall=13, gb_free=9.7, ema_decay=0.9999, wall=8911
2022-09-27 14:08:59 - progress_bar.py[line:274] - INFO: epoch 001:   7752 / 42934 loss=0.871, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.5, ups=0.89, wpb=102.8, bsz=40, num_updates=7740, lr=2.25354e-05, gnorm=1.745, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8923
2022-09-27 14:09:10 - progress_bar.py[line:274] - INFO: epoch 001:   7762 / 42934 loss=0.951, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.8, ups=0.89, wpb=101.2, bsz=40, num_updates=7750, lr=2.25645e-05, gnorm=1.946, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=8934
2022-09-27 14:09:21 - progress_bar.py[line:274] - INFO: epoch 001:   7772 / 42934 loss=0.889, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=93.5, ups=0.91, wpb=102.9, bsz=40, num_updates=7760, lr=2.25936e-05, gnorm=1.87, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=8945
2022-09-27 14:09:34 - progress_bar.py[line:274] - INFO: epoch 001:   7782 / 42934 loss=0.91, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=88.7, ups=0.86, wpb=102.9, bsz=40, num_updates=7770, lr=2.26227e-05, gnorm=1.921, clip=100, loss_scale=256, train_wall=12, gb_free=8, ema_decay=0.9999, wall=8957
2022-09-27 14:09:45 - progress_bar.py[line:274] - INFO: epoch 001:   7792 / 42934 loss=0.903, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=88.4, ups=0.87, wpb=102.1, bsz=40, num_updates=7780, lr=2.26518e-05, gnorm=2.048, clip=100, loss_scale=256, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=8969
2022-09-27 14:09:57 - progress_bar.py[line:274] - INFO: epoch 001:   7802 / 42934 loss=0.832, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.1, ups=0.87, wpb=104.1, bsz=40, num_updates=7790, lr=2.2681e-05, gnorm=1.666, clip=100, loss_scale=256, train_wall=12, gb_free=9.1, ema_decay=0.9999, wall=8981
2022-09-27 14:10:08 - progress_bar.py[line:274] - INFO: epoch 001:   7812 / 42934 loss=0.828, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.8, ups=0.9, wpb=104.7, bsz=40, num_updates=7800, lr=2.27101e-05, gnorm=1.728, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=8992
2022-09-27 14:10:19 - progress_bar.py[line:274] - INFO: epoch 001:   7822 / 42934 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93.4, ups=0.91, wpb=102.8, bsz=40, num_updates=7810, lr=2.27392e-05, gnorm=1.846, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=9003
2022-09-27 14:10:31 - progress_bar.py[line:274] - INFO: epoch 001:   7832 / 42934 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.2, ups=0.86, wpb=103.6, bsz=40, num_updates=7820, lr=2.27683e-05, gnorm=1.789, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=9015
2022-09-27 14:10:42 - progress_bar.py[line:274] - INFO: epoch 001:   7842 / 42934 loss=0.922, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88, ups=0.86, wpb=102.6, bsz=40, num_updates=7830, lr=2.27974e-05, gnorm=2.134, clip=100, loss_scale=256, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=9026
2022-09-27 14:10:53 - progress_bar.py[line:274] - INFO: epoch 001:   7852 / 42934 loss=0.896, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.4, ups=0.9, wpb=101, bsz=40, num_updates=7840, lr=2.28265e-05, gnorm=2.039, clip=100, loss_scale=256, train_wall=11, gb_free=9, ema_decay=0.9999, wall=9038
2022-09-27 14:11:05 - progress_bar.py[line:274] - INFO: epoch 001:   7862 / 42934 loss=0.896, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.4, ups=0.87, wpb=101, bsz=40, num_updates=7850, lr=2.28556e-05, gnorm=2.022, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=9049
2022-09-27 14:11:17 - progress_bar.py[line:274] - INFO: epoch 001:   7872 / 42934 loss=0.875, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=88.9, ups=0.87, wpb=102.5, bsz=40, num_updates=7860, lr=2.28848e-05, gnorm=2.143, clip=100, loss_scale=256, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=9061
2022-09-27 14:11:28 - progress_bar.py[line:274] - INFO: epoch 001:   7882 / 42934 loss=0.863, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=105, nsentences=40, sample_size=105, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.8, ups=0.88, wpb=105, bsz=40, num_updates=7870, lr=2.29139e-05, gnorm=1.819, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=9072
2022-09-27 14:11:40 - progress_bar.py[line:274] - INFO: epoch 001:   7892 / 42934 loss=0.901, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.9, ups=0.85, wpb=104.7, bsz=40, num_updates=7880, lr=2.2943e-05, gnorm=1.919, clip=100, loss_scale=256, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=9084
2022-09-27 14:11:51 - progress_bar.py[line:274] - INFO: epoch 001:   7902 / 42934 loss=0.882, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93.7, ups=0.92, wpb=102.4, bsz=40, num_updates=7890, lr=2.29721e-05, gnorm=1.885, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=9095
2022-09-27 14:12:01 - progress_bar.py[line:274] - INFO: epoch 001:   7912 / 42934 loss=0.903, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96, ups=0.93, wpb=103.5, bsz=40, num_updates=7900, lr=2.30012e-05, gnorm=1.949, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=9106
2022-09-27 14:12:13 - progress_bar.py[line:274] - INFO: epoch 001:   7922 / 42934 loss=0.894, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=86.9, ups=0.85, wpb=101.8, bsz=40, num_updates=7910, lr=2.30303e-05, gnorm=1.966, clip=100, loss_scale=256, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=9117
2022-09-27 14:12:25 - progress_bar.py[line:274] - INFO: epoch 001:   7932 / 42934 loss=0.85, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=105.1, nsentences=40, sample_size=105.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=92, ups=0.87, wpb=105.1, bsz=40, num_updates=7920, lr=2.30595e-05, gnorm=1.939, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=9129
2022-09-27 14:12:36 - progress_bar.py[line:274] - INFO: epoch 001:   7942 / 42934 loss=0.831, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.2, ups=0.87, wpb=102.9, bsz=40, num_updates=7930, lr=2.30886e-05, gnorm=1.958, clip=100, loss_scale=256, train_wall=11, gb_free=7.4, ema_decay=0.9999, wall=9140
2022-09-27 14:12:48 - progress_bar.py[line:274] - INFO: epoch 001:   7952 / 42934 loss=0.931, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=87.3, ups=0.86, wpb=101.8, bsz=40, num_updates=7940, lr=2.31177e-05, gnorm=2.087, clip=100, loss_scale=256, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=9152
2022-09-27 14:12:59 - progress_bar.py[line:274] - INFO: epoch 001:   7962 / 42934 loss=0.932, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=92.7, ups=0.9, wpb=103.2, bsz=40, num_updates=7950, lr=2.31468e-05, gnorm=2.158, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=9163
2022-09-27 14:13:10 - progress_bar.py[line:274] - INFO: epoch 001:   7972 / 42934 loss=0.869, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90.7, ups=0.88, wpb=103.1, bsz=40, num_updates=7960, lr=2.31759e-05, gnorm=2.248, clip=100, loss_scale=256, train_wall=11, gb_free=8, ema_decay=0.9999, wall=9174
2022-09-27 14:13:22 - progress_bar.py[line:274] - INFO: epoch 001:   7982 / 42934 loss=0.914, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=90.3, ups=0.87, wpb=103.6, bsz=40, num_updates=7970, lr=2.3205e-05, gnorm=2.083, clip=100, loss_scale=256, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=9186
2022-09-27 14:13:33 - progress_bar.py[line:274] - INFO: epoch 001:   7992 / 42934 loss=0.885, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=90.7, ups=0.88, wpb=102.5, bsz=40, num_updates=7980, lr=2.32341e-05, gnorm=2.015, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=9197
2022-09-27 14:13:45 - progress_bar.py[line:274] - INFO: epoch 001:   8002 / 42934 loss=0.827, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.6, ups=0.87, wpb=103.4, bsz=40, num_updates=7990, lr=2.32633e-05, gnorm=1.858, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=9209
2022-09-27 14:13:56 - progress_bar.py[line:274] - INFO: epoch 001:   8012 / 42934 loss=0.887, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88.8, ups=0.85, wpb=103.9, bsz=40, num_updates=8000, lr=2.32924e-05, gnorm=1.839, clip=100, loss_scale=256, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=9220
2022-09-27 14:14:08 - progress_bar.py[line:274] - INFO: epoch 001:   8022 / 42934 loss=0.976, loss_v1=0, loss_v2=0, nll_loss=0.609, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=88.2, ups=0.85, wpb=103.5, bsz=40, num_updates=8010, lr=2.33215e-05, gnorm=2.067, clip=100, loss_scale=256, train_wall=12, gb_free=8.4, ema_decay=0.9999, wall=9232
2022-09-27 14:14:19 - progress_bar.py[line:274] - INFO: epoch 001:   8032 / 42934 loss=0.836, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.7, ups=0.9, wpb=103.5, bsz=40, num_updates=8020, lr=2.33506e-05, gnorm=1.693, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=9243
2022-09-27 14:14:31 - progress_bar.py[line:274] - INFO: epoch 001:   8042 / 42934 loss=0.946, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=88.2, ups=0.87, wpb=101.5, bsz=40, num_updates=8030, lr=2.33797e-05, gnorm=2.313, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=9255
2022-09-27 14:14:42 - progress_bar.py[line:274] - INFO: epoch 001:   8052 / 42934 loss=0.917, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=89.5, ups=0.87, wpb=103, bsz=40, num_updates=8040, lr=2.34088e-05, gnorm=2.05, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=9266
2022-09-27 14:14:54 - progress_bar.py[line:274] - INFO: epoch 001:   8062 / 42934 loss=0.886, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.6, ups=0.88, wpb=101.5, bsz=40, num_updates=8050, lr=2.3438e-05, gnorm=1.904, clip=100, loss_scale=256, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=9278
2022-09-27 14:15:05 - progress_bar.py[line:274] - INFO: epoch 001:   8072 / 42934 loss=0.941, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=91.8, ups=0.9, wpb=102.2, bsz=40, num_updates=8060, lr=2.34671e-05, gnorm=1.931, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=9289
2022-09-27 14:15:16 - progress_bar.py[line:274] - INFO: epoch 001:   8082 / 42934 loss=0.929, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=87.8, ups=0.86, wpb=101.5, bsz=40, num_updates=8070, lr=2.34962e-05, gnorm=1.842, clip=100, loss_scale=256, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=9301
2022-09-27 14:15:28 - progress_bar.py[line:274] - INFO: epoch 001:   8092 / 42934 loss=0.877, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=84.7, ups=0.83, wpb=101.6, bsz=40, num_updates=8080, lr=2.35253e-05, gnorm=1.811, clip=100, loss_scale=256, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=9313
2022-09-27 14:15:40 - progress_bar.py[line:274] - INFO: epoch 001:   8102 / 42934 loss=0.94, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=86.9, ups=0.85, wpb=102.5, bsz=40, num_updates=8090, lr=2.35544e-05, gnorm=2.089, clip=100, loss_scale=256, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=9324
2022-09-27 14:15:52 - progress_bar.py[line:274] - INFO: epoch 001:   8112 / 42934 loss=0.822, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.1, ups=0.85, wpb=103.7, bsz=40, num_updates=8100, lr=2.35835e-05, gnorm=1.767, clip=100, loss_scale=256, train_wall=12, gb_free=8.4, ema_decay=0.9999, wall=9336
2022-09-27 14:16:03 - progress_bar.py[line:274] - INFO: epoch 001:   8122 / 42934 loss=0.885, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.9, ups=0.89, wpb=101.5, bsz=40, num_updates=8110, lr=2.36126e-05, gnorm=2.149, clip=100, loss_scale=256, train_wall=11, gb_free=8.3, ema_decay=0.9999, wall=9347
2022-09-27 14:16:15 - progress_bar.py[line:274] - INFO: epoch 001:   8132 / 42934 loss=0.877, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.5, ups=0.86, wpb=101.2, bsz=40, num_updates=8120, lr=2.36418e-05, gnorm=2.024, clip=100, loss_scale=256, train_wall=12, gb_free=8.4, ema_decay=0.9999, wall=9359
2022-09-27 14:16:26 - progress_bar.py[line:274] - INFO: epoch 001:   8142 / 42934 loss=0.881, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.5, ups=0.88, wpb=102.9, bsz=40, num_updates=8130, lr=2.36709e-05, gnorm=1.926, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=9370
2022-09-27 14:16:38 - progress_bar.py[line:274] - INFO: epoch 001:   8152 / 42934 loss=0.914, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=91.9, ups=0.89, wpb=103.3, bsz=40, num_updates=8140, lr=2.37e-05, gnorm=2.093, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=9382
2022-09-27 14:16:49 - progress_bar.py[line:274] - INFO: epoch 001:   8162 / 42934 loss=0.862, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.9, ups=0.87, wpb=102.8, bsz=40, num_updates=8150, lr=2.37291e-05, gnorm=2.253, clip=100, loss_scale=256, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=9393
2022-09-27 14:17:00 - progress_bar.py[line:274] - INFO: epoch 001:   8172 / 42934 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=93.5, ups=0.9, wpb=104.4, bsz=40, num_updates=8160, lr=2.37582e-05, gnorm=1.934, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=9404
2022-09-27 14:17:12 - progress_bar.py[line:274] - INFO: epoch 001:   8182 / 42934 loss=0.839, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=104.8, nsentences=40, sample_size=104.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87.1, ups=0.83, wpb=104.8, bsz=40, num_updates=8170, lr=2.37873e-05, gnorm=1.969, clip=100, loss_scale=256, train_wall=12, gb_free=8.9, ema_decay=0.9999, wall=9416
2022-09-27 14:17:24 - progress_bar.py[line:274] - INFO: epoch 001:   8192 / 42934 loss=0.891, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.2, ups=0.88, wpb=102.9, bsz=40, num_updates=8180, lr=2.38165e-05, gnorm=2.02, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=9428
2022-09-27 14:17:35 - progress_bar.py[line:274] - INFO: epoch 001:   8202 / 42934 loss=0.863, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.1, ups=0.87, wpb=102.3, bsz=40, num_updates=8190, lr=2.38456e-05, gnorm=1.801, clip=100, loss_scale=256, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=9439
2022-09-27 14:17:47 - progress_bar.py[line:274] - INFO: epoch 001:   8212 / 42934 loss=0.852, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.4, ups=0.88, wpb=103.2, bsz=40, num_updates=8200, lr=2.38747e-05, gnorm=1.935, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=9451
2022-09-27 14:17:58 - progress_bar.py[line:274] - INFO: epoch 001:   8222 / 42934 loss=0.866, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.1, ups=0.85, wpb=103.3, bsz=40, num_updates=8210, lr=2.39038e-05, gnorm=2.077, clip=100, loss_scale=256, train_wall=12, gb_free=9.2, ema_decay=0.9999, wall=9462
2022-09-27 14:18:10 - progress_bar.py[line:274] - INFO: epoch 001:   8232 / 42934 loss=0.913, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.3, ups=0.86, wpb=102.4, bsz=40, num_updates=8220, lr=2.39329e-05, gnorm=2.029, clip=100, loss_scale=256, train_wall=12, gb_free=8.9, ema_decay=0.9999, wall=9474
2022-09-27 14:18:22 - progress_bar.py[line:274] - INFO: epoch 001:   8242 / 42934 loss=0.855, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=84.7, ups=0.83, wpb=102, bsz=40, num_updates=8230, lr=2.3962e-05, gnorm=2.008, clip=100, loss_scale=256, train_wall=12, gb_free=7.9, ema_decay=0.9999, wall=9486
2022-09-27 14:18:34 - progress_bar.py[line:274] - INFO: epoch 001:   8252 / 42934 loss=0.908, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.3, ups=0.86, wpb=103.1, bsz=40, num_updates=8240, lr=2.39911e-05, gnorm=1.922, clip=100, loss_scale=512, train_wall=12, gb_free=10, ema_decay=0.9999, wall=9498
2022-09-27 14:18:45 - progress_bar.py[line:274] - INFO: epoch 001:   8262 / 42934 loss=0.852, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.6, ups=0.86, wpb=102.3, bsz=40, num_updates=8250, lr=2.40203e-05, gnorm=1.794, clip=100, loss_scale=512, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=9509
2022-09-27 14:18:57 - progress_bar.py[line:274] - INFO: epoch 001:   8272 / 42934 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.2, ups=0.85, wpb=103.3, bsz=40, num_updates=8260, lr=2.40494e-05, gnorm=1.773, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=9521
2022-09-27 14:19:08 - progress_bar.py[line:274] - INFO: epoch 001:   8282 / 42934 loss=0.877, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.3, ups=0.9, wpb=102.8, bsz=40, num_updates=8270, lr=2.40785e-05, gnorm=1.896, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=9532
2022-09-27 14:19:20 - progress_bar.py[line:274] - INFO: epoch 001:   8292 / 42934 loss=0.901, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90, ups=0.86, wpb=104.2, bsz=40, num_updates=8280, lr=2.41076e-05, gnorm=1.898, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=9544
2022-09-27 14:19:32 - progress_bar.py[line:274] - INFO: epoch 001:   8302 / 42934 loss=0.943, loss_v1=0, loss_v2=0, nll_loss=0.585, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=87.6, ups=0.85, wpb=102.7, bsz=40, num_updates=8290, lr=2.41367e-05, gnorm=2.155, clip=100, loss_scale=512, train_wall=12, gb_free=8.2, ema_decay=0.9999, wall=9556
2022-09-27 14:19:43 - progress_bar.py[line:274] - INFO: epoch 001:   8312 / 42934 loss=0.935, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=86, ups=0.85, wpb=100.9, bsz=40, num_updates=8300, lr=2.41658e-05, gnorm=2.119, clip=100, loss_scale=512, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=9567
2022-09-27 14:19:55 - progress_bar.py[line:274] - INFO: epoch 001:   8322 / 42934 loss=0.832, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88, ups=0.86, wpb=102.5, bsz=40, num_updates=8310, lr=2.4195e-05, gnorm=2.041, clip=100, loss_scale=512, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=9579
2022-09-27 14:20:06 - progress_bar.py[line:274] - INFO: epoch 001:   8332 / 42934 loss=0.862, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=93.4, ups=0.9, wpb=104.2, bsz=40, num_updates=8320, lr=2.42241e-05, gnorm=1.899, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=9590
2022-09-27 14:20:17 - progress_bar.py[line:274] - INFO: epoch 001:   8342 / 42934 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=90.6, ups=0.88, wpb=102.6, bsz=40, num_updates=8330, lr=2.42532e-05, gnorm=2.178, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=9602
2022-09-27 14:20:29 - progress_bar.py[line:274] - INFO: epoch 001:   8352 / 42934 loss=0.861, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90.5, ups=0.88, wpb=103.3, bsz=40, num_updates=8340, lr=2.42823e-05, gnorm=1.949, clip=100, loss_scale=512, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=9613
2022-09-27 14:20:41 - progress_bar.py[line:274] - INFO: epoch 001:   8362 / 42934 loss=0.868, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=84, ups=0.82, wpb=102.3, bsz=40, num_updates=8350, lr=2.43114e-05, gnorm=1.914, clip=100, loss_scale=512, train_wall=12, gb_free=8.4, ema_decay=0.9999, wall=9625
2022-09-27 14:20:52 - progress_bar.py[line:274] - INFO: epoch 001:   8372 / 42934 loss=0.896, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89, ups=0.88, wpb=101.6, bsz=40, num_updates=8360, lr=2.43405e-05, gnorm=1.981, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=9637
2022-09-27 14:21:04 - progress_bar.py[line:274] - INFO: epoch 001:   8382 / 42934 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=87.4, ups=0.84, wpb=104.1, bsz=40, num_updates=8370, lr=2.43697e-05, gnorm=1.965, clip=100, loss_scale=512, train_wall=12, gb_free=9.2, ema_decay=0.9999, wall=9648
2022-09-27 14:21:16 - progress_bar.py[line:274] - INFO: epoch 001:   8392 / 42934 loss=0.867, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.6, ups=0.85, wpb=103.3, bsz=40, num_updates=8380, lr=2.43988e-05, gnorm=2.142, clip=100, loss_scale=512, train_wall=12, gb_free=6.6, ema_decay=0.9999, wall=9660
2022-09-27 14:21:28 - progress_bar.py[line:274] - INFO: epoch 001:   8402 / 42934 loss=0.869, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=84.9, ups=0.83, wpb=102.5, bsz=40, num_updates=8390, lr=2.44279e-05, gnorm=1.965, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=9672
2022-09-27 14:21:39 - progress_bar.py[line:274] - INFO: epoch 001:   8412 / 42934 loss=0.844, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=105.8, nsentences=40, sample_size=105.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.8, ups=0.9, wpb=105.8, bsz=40, num_updates=8400, lr=2.4457e-05, gnorm=1.945, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=9684
2022-09-27 14:21:51 - progress_bar.py[line:274] - INFO: epoch 001:   8422 / 42934 loss=0.856, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90.7, ups=0.88, wpb=103.5, bsz=40, num_updates=8410, lr=2.44861e-05, gnorm=2.005, clip=100, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=9695
2022-09-27 14:22:03 - progress_bar.py[line:274] - INFO: epoch 001:   8432 / 42934 loss=0.88, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.2, ups=0.85, wpb=102.8, bsz=40, num_updates=8420, lr=2.45152e-05, gnorm=2.464, clip=100, loss_scale=512, train_wall=12, gb_free=9, ema_decay=0.9999, wall=9707
2022-09-27 14:22:14 - progress_bar.py[line:274] - INFO: epoch 001:   8442 / 42934 loss=0.819, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.8, ups=0.85, wpb=104.1, bsz=40, num_updates=8430, lr=2.45443e-05, gnorm=1.879, clip=100, loss_scale=512, train_wall=12, gb_free=8.4, ema_decay=0.9999, wall=9718
2022-09-27 14:22:27 - progress_bar.py[line:274] - INFO: epoch 001:   8452 / 42934 loss=0.919, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=80.6, ups=0.79, wpb=101.7, bsz=40, num_updates=8440, lr=2.45735e-05, gnorm=2.323, clip=100, loss_scale=512, train_wall=13, gb_free=9.4, ema_decay=0.9999, wall=9731
2022-09-27 14:22:38 - progress_bar.py[line:274] - INFO: epoch 001:   8462 / 42934 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.5, ups=0.88, wpb=103.1, bsz=40, num_updates=8450, lr=2.46026e-05, gnorm=1.764, clip=100, loss_scale=512, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=9743
2022-09-27 14:22:50 - progress_bar.py[line:274] - INFO: epoch 001:   8472 / 42934 loss=0.913, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=91.1, ups=0.88, wpb=103, bsz=40, num_updates=8460, lr=2.46317e-05, gnorm=1.827, clip=100, loss_scale=512, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=9754
2022-09-27 14:23:01 - progress_bar.py[line:274] - INFO: epoch 001:   8482 / 42934 loss=0.934, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=88.7, ups=0.85, wpb=104, bsz=40, num_updates=8470, lr=2.46608e-05, gnorm=2.156, clip=100, loss_scale=512, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=9766
2022-09-27 14:23:13 - progress_bar.py[line:274] - INFO: epoch 001:   8492 / 42934 loss=0.865, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=88.4, ups=0.87, wpb=102.2, bsz=40, num_updates=8480, lr=2.46899e-05, gnorm=1.675, clip=100, loss_scale=512, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=9777
2022-09-27 14:23:25 - progress_bar.py[line:274] - INFO: epoch 001:   8502 / 42934 loss=0.908, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=84.5, ups=0.83, wpb=101.4, bsz=40, num_updates=8490, lr=2.4719e-05, gnorm=2.067, clip=100, loss_scale=512, train_wall=12, gb_free=10, ema_decay=0.9999, wall=9789
2022-09-27 14:23:37 - progress_bar.py[line:274] - INFO: epoch 001:   8512 / 42934 loss=0.87, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.6, ups=0.86, wpb=103.3, bsz=40, num_updates=8500, lr=2.47482e-05, gnorm=1.773, clip=100, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=9801
2022-09-27 14:23:48 - progress_bar.py[line:274] - INFO: epoch 001:   8522 / 42934 loss=0.899, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=92.5, ups=0.9, wpb=103.3, bsz=40, num_updates=8510, lr=2.47773e-05, gnorm=1.888, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=9812
2022-09-27 14:24:00 - progress_bar.py[line:274] - INFO: epoch 001:   8532 / 42934 loss=0.908, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=87.4, ups=0.86, wpb=101.4, bsz=40, num_updates=8520, lr=2.48064e-05, gnorm=1.929, clip=100, loss_scale=512, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=9824
2022-09-27 14:24:11 - progress_bar.py[line:274] - INFO: epoch 001:   8542 / 42934 loss=0.872, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.7, ups=0.89, wpb=103.4, bsz=40, num_updates=8530, lr=2.48355e-05, gnorm=1.806, clip=100, loss_scale=512, train_wall=11, gb_free=7.5, ema_decay=0.9999, wall=9835
2022-09-27 14:24:22 - progress_bar.py[line:274] - INFO: epoch 001:   8552 / 42934 loss=0.921, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=87.9, ups=0.86, wpb=102.1, bsz=40, num_updates=8540, lr=2.48646e-05, gnorm=1.928, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=9846
2022-09-27 14:24:34 - progress_bar.py[line:274] - INFO: epoch 001:   8562 / 42934 loss=0.877, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.7, ups=0.86, wpb=104.2, bsz=40, num_updates=8550, lr=2.48937e-05, gnorm=1.979, clip=100, loss_scale=512, train_wall=12, gb_free=8.1, ema_decay=0.9999, wall=9858
2022-09-27 14:24:46 - progress_bar.py[line:274] - INFO: epoch 001:   8572 / 42934 loss=0.925, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=87.2, ups=0.86, wpb=101.8, bsz=40, num_updates=8560, lr=2.49228e-05, gnorm=2.031, clip=100, loss_scale=512, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=9870
2022-09-27 14:24:57 - progress_bar.py[line:274] - INFO: epoch 001:   8582 / 42934 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=90.9, ups=0.88, wpb=103.6, bsz=40, num_updates=8570, lr=2.4952e-05, gnorm=2.122, clip=100, loss_scale=512, train_wall=11, gb_free=8.3, ema_decay=0.9999, wall=9881
2022-09-27 14:25:09 - progress_bar.py[line:274] - INFO: epoch 001:   8592 / 42934 loss=0.855, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89, ups=0.85, wpb=104.1, bsz=40, num_updates=8580, lr=2.49811e-05, gnorm=1.809, clip=100, loss_scale=512, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=9893
2022-09-27 14:25:20 - progress_bar.py[line:274] - INFO: epoch 001:   8602 / 42934 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.5, ups=0.88, wpb=102.3, bsz=40, num_updates=8590, lr=2.50102e-05, gnorm=2.067, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=9904
2022-09-27 14:25:32 - progress_bar.py[line:274] - INFO: epoch 001:   8612 / 42934 loss=0.836, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.5, ups=0.89, wpb=102.9, bsz=40, num_updates=8600, lr=2.50393e-05, gnorm=2.097, clip=100, loss_scale=512, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=9916
2022-09-27 14:25:43 - progress_bar.py[line:274] - INFO: epoch 001:   8622 / 42934 loss=0.917, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=92.1, ups=0.88, wpb=104.5, bsz=40, num_updates=8610, lr=2.50684e-05, gnorm=2.269, clip=100, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=9927
2022-09-27 14:25:54 - progress_bar.py[line:274] - INFO: epoch 001:   8632 / 42934 loss=0.871, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.4, ups=0.89, wpb=102.4, bsz=40, num_updates=8620, lr=2.50975e-05, gnorm=1.779, clip=100, loss_scale=512, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=9938
2022-09-27 14:26:06 - progress_bar.py[line:274] - INFO: epoch 001:   8642 / 42934 loss=0.891, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=105.1, nsentences=40, sample_size=105.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.7, ups=0.85, wpb=105.1, bsz=40, num_updates=8630, lr=2.51267e-05, gnorm=1.877, clip=100, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=9950
2022-09-27 14:26:17 - progress_bar.py[line:274] - INFO: epoch 001:   8652 / 42934 loss=0.887, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=90.6, ups=0.87, wpb=103.9, bsz=40, num_updates=8640, lr=2.51558e-05, gnorm=2.16, clip=100, loss_scale=512, train_wall=11, gb_free=8.6, ema_decay=0.9999, wall=9961
2022-09-27 14:26:29 - progress_bar.py[line:274] - INFO: epoch 001:   8662 / 42934 loss=0.878, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91, ups=0.87, wpb=104.1, bsz=40, num_updates=8650, lr=2.51849e-05, gnorm=1.788, clip=100, loss_scale=512, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=9973
2022-09-27 14:26:40 - progress_bar.py[line:274] - INFO: epoch 001:   8672 / 42934 loss=0.854, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.9, ups=0.91, wpb=103.8, bsz=40, num_updates=8660, lr=2.5214e-05, gnorm=1.766, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=9984
2022-09-27 14:26:51 - progress_bar.py[line:274] - INFO: epoch 001:   8682 / 42934 loss=0.931, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=91.1, ups=0.89, wpb=101.9, bsz=40, num_updates=8670, lr=2.52431e-05, gnorm=1.931, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=9995
2022-09-27 14:27:02 - progress_bar.py[line:274] - INFO: epoch 001:   8692 / 42934 loss=0.838, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.7, ups=0.88, wpb=104.2, bsz=40, num_updates=8680, lr=2.52722e-05, gnorm=1.723, clip=100, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=10006
2022-09-27 14:27:14 - progress_bar.py[line:274] - INFO: epoch 001:   8702 / 42934 loss=0.883, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.3, ups=0.86, wpb=104, bsz=40, num_updates=8690, lr=2.53013e-05, gnorm=1.861, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=10018
2022-09-27 14:27:25 - progress_bar.py[line:274] - INFO: epoch 001:   8712 / 42934 loss=0.879, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.2, ups=0.87, wpb=103.1, bsz=40, num_updates=8700, lr=2.53305e-05, gnorm=1.843, clip=100, loss_scale=512, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=10030
2022-09-27 14:27:37 - progress_bar.py[line:274] - INFO: epoch 001:   8722 / 42934 loss=0.886, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.1, ups=0.87, wpb=102.3, bsz=40, num_updates=8710, lr=2.53596e-05, gnorm=1.805, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=10041
2022-09-27 14:27:49 - progress_bar.py[line:274] - INFO: epoch 001:   8732 / 42934 loss=0.878, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=86.4, ups=0.85, wpb=101.3, bsz=40, num_updates=8720, lr=2.53887e-05, gnorm=1.844, clip=100, loss_scale=512, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=10053
2022-09-27 14:28:00 - progress_bar.py[line:274] - INFO: epoch 001:   8742 / 42934 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.2, ups=0.86, wpb=102, bsz=40, num_updates=8730, lr=2.54178e-05, gnorm=1.925, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=10064
2022-09-27 14:28:12 - progress_bar.py[line:274] - INFO: epoch 001:   8752 / 42934 loss=0.936, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=89.4, ups=0.87, wpb=103.3, bsz=40, num_updates=8740, lr=2.54469e-05, gnorm=1.946, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=10076
2022-09-27 14:28:21 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-27 14:28:24 - progress_bar.py[line:274] - INFO: epoch 001:   8763 / 42934 loss=0.897, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=83.4, ups=0.81, wpb=103.6, bsz=40, num_updates=8750, lr=2.5476e-05, gnorm=1.975, clip=100, loss_scale=512, train_wall=12, gb_free=9, ema_decay=0.9999, wall=10088
2022-09-27 14:28:36 - progress_bar.py[line:274] - INFO: epoch 001:   8773 / 42934 loss=0.831, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89, ups=0.85, wpb=104.5, bsz=40, num_updates=8760, lr=2.55052e-05, gnorm=1.709, clip=100, loss_scale=512, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=10100
2022-09-27 14:28:48 - progress_bar.py[line:274] - INFO: epoch 001:   8783 / 42934 loss=0.866, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.7, ups=0.85, wpb=103.2, bsz=40, num_updates=8770, lr=2.55343e-05, gnorm=1.867, clip=100, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=10112
2022-09-27 14:28:59 - progress_bar.py[line:274] - INFO: epoch 001:   8793 / 42934 loss=0.859, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89.8, ups=0.87, wpb=103.1, bsz=40, num_updates=8780, lr=2.55634e-05, gnorm=1.9, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=10123
2022-09-27 14:29:11 - progress_bar.py[line:274] - INFO: epoch 001:   8803 / 42934 loss=0.838, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.6, ups=0.86, wpb=103.5, bsz=40, num_updates=8790, lr=2.55925e-05, gnorm=1.652, clip=100, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=10135
2022-09-27 14:29:23 - progress_bar.py[line:274] - INFO: epoch 001:   8813 / 42934 loss=0.868, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.2, ups=0.85, wpb=104.4, bsz=40, num_updates=8800, lr=2.56216e-05, gnorm=1.731, clip=100, loss_scale=512, train_wall=12, gb_free=8.1, ema_decay=0.9999, wall=10147
2022-09-27 14:29:34 - progress_bar.py[line:274] - INFO: epoch 001:   8823 / 42934 loss=0.839, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.7, ups=0.9, wpb=102.7, bsz=40, num_updates=8810, lr=2.56507e-05, gnorm=1.584, clip=100, loss_scale=512, train_wall=11, gb_free=9.1, ema_decay=0.9999, wall=10158
2022-09-27 14:29:45 - progress_bar.py[line:274] - INFO: epoch 001:   8833 / 42934 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=87.7, ups=0.87, wpb=100.8, bsz=40, num_updates=8820, lr=2.56798e-05, gnorm=1.935, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=10169
2022-09-27 14:29:56 - progress_bar.py[line:274] - INFO: epoch 001:   8843 / 42934 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=91.9, ups=0.89, wpb=103, bsz=40, num_updates=8830, lr=2.5709e-05, gnorm=2, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=10181
2022-09-27 14:30:08 - progress_bar.py[line:274] - INFO: epoch 001:   8853 / 42934 loss=0.911, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=88.9, ups=0.88, wpb=101.3, bsz=40, num_updates=8840, lr=2.57381e-05, gnorm=1.899, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=10192
2022-09-27 14:30:19 - progress_bar.py[line:274] - INFO: epoch 001:   8863 / 42934 loss=0.874, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.7, ups=0.87, wpb=102.4, bsz=40, num_updates=8850, lr=2.57672e-05, gnorm=1.938, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=10203
2022-09-27 14:30:31 - progress_bar.py[line:274] - INFO: epoch 001:   8873 / 42934 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.5, ups=0.88, wpb=102, bsz=40, num_updates=8860, lr=2.57963e-05, gnorm=2.163, clip=100, loss_scale=512, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=10215
2022-09-27 14:30:42 - progress_bar.py[line:274] - INFO: epoch 001:   8883 / 42934 loss=0.862, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.8, ups=0.89, wpb=102.6, bsz=40, num_updates=8870, lr=2.58254e-05, gnorm=1.827, clip=100, loss_scale=512, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=10226
2022-09-27 14:30:54 - progress_bar.py[line:274] - INFO: epoch 001:   8893 / 42934 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=88.3, ups=0.86, wpb=103.1, bsz=40, num_updates=8880, lr=2.58545e-05, gnorm=1.9, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=10238
2022-09-27 14:31:05 - progress_bar.py[line:274] - INFO: epoch 001:   8903 / 42934 loss=0.894, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=93.3, ups=0.91, wpb=103, bsz=40, num_updates=8890, lr=2.58837e-05, gnorm=1.817, clip=100, loss_scale=512, train_wall=11, gb_free=7.6, ema_decay=0.9999, wall=10249
2022-09-27 14:31:16 - progress_bar.py[line:274] - INFO: epoch 001:   8913 / 42934 loss=0.875, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.8, ups=0.89, wpb=103.8, bsz=40, num_updates=8900, lr=2.59128e-05, gnorm=1.958, clip=100, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=10260
2022-09-27 14:31:27 - progress_bar.py[line:274] - INFO: epoch 001:   8923 / 42934 loss=0.954, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89.3, ups=0.88, wpb=102, bsz=40, num_updates=8910, lr=2.59419e-05, gnorm=1.95, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=10271
2022-09-27 14:31:39 - progress_bar.py[line:274] - INFO: epoch 001:   8933 / 42934 loss=0.909, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.1, ups=0.88, wpb=102.8, bsz=40, num_updates=8920, lr=2.5971e-05, gnorm=1.817, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=10283
2022-09-27 14:31:50 - progress_bar.py[line:274] - INFO: epoch 001:   8943 / 42934 loss=0.919, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92.4, ups=0.9, wpb=103.1, bsz=40, num_updates=8930, lr=2.60001e-05, gnorm=1.936, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=10294
2022-09-27 14:32:01 - progress_bar.py[line:274] - INFO: epoch 001:   8953 / 42934 loss=0.862, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=93.4, ups=0.9, wpb=103.8, bsz=40, num_updates=8940, lr=2.60292e-05, gnorm=1.898, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=10305
2022-09-27 14:32:13 - progress_bar.py[line:274] - INFO: epoch 001:   8963 / 42934 loss=0.941, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.6, ups=0.87, wpb=101.8, bsz=40, num_updates=8950, lr=2.60583e-05, gnorm=1.947, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=10317
2022-09-27 14:32:24 - progress_bar.py[line:274] - INFO: epoch 001:   8973 / 42934 loss=0.873, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.7, ups=0.88, wpb=103.1, bsz=40, num_updates=8960, lr=2.60875e-05, gnorm=2.047, clip=100, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=10328
2022-09-27 14:32:36 - progress_bar.py[line:274] - INFO: epoch 001:   8983 / 42934 loss=0.904, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=88.7, ups=0.86, wpb=103.4, bsz=40, num_updates=8970, lr=2.61166e-05, gnorm=2.109, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=10340
2022-09-27 14:32:47 - progress_bar.py[line:274] - INFO: epoch 001:   8993 / 42934 loss=0.921, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=93, ups=0.9, wpb=103.2, bsz=40, num_updates=8980, lr=2.61457e-05, gnorm=2.13, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=10351
2022-09-27 14:32:58 - progress_bar.py[line:274] - INFO: epoch 001:   9003 / 42934 loss=0.822, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.1, ups=0.89, wpb=103.6, bsz=40, num_updates=8990, lr=2.61748e-05, gnorm=1.688, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=10362
2022-09-27 14:33:09 - progress_bar.py[line:274] - INFO: epoch 001:   9013 / 42934 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.9, ups=0.87, wpb=103.2, bsz=40, num_updates=9000, lr=2.62039e-05, gnorm=2.236, clip=100, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=10373
2022-09-27 14:33:21 - progress_bar.py[line:274] - INFO: epoch 001:   9023 / 42934 loss=0.914, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=91.5, ups=0.88, wpb=103.5, bsz=40, num_updates=9010, lr=2.6233e-05, gnorm=1.956, clip=100, loss_scale=512, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=10385
2022-09-27 14:33:32 - progress_bar.py[line:274] - INFO: epoch 001:   9033 / 42934 loss=0.925, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=90.5, ups=0.88, wpb=102.6, bsz=40, num_updates=9020, lr=2.62622e-05, gnorm=1.887, clip=100, loss_scale=512, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=10396
2022-09-27 14:33:44 - progress_bar.py[line:274] - INFO: epoch 001:   9043 / 42934 loss=0.912, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=89.9, ups=0.87, wpb=102.9, bsz=40, num_updates=9030, lr=2.62913e-05, gnorm=1.89, clip=100, loss_scale=512, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=10408
2022-09-27 14:33:55 - progress_bar.py[line:274] - INFO: epoch 001:   9053 / 42934 loss=0.825, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=105, nsentences=40, sample_size=105, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.6, ups=0.85, wpb=105, bsz=40, num_updates=9040, lr=2.63204e-05, gnorm=1.769, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=10419
2022-09-27 14:34:07 - progress_bar.py[line:274] - INFO: epoch 001:   9063 / 42934 loss=0.846, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.5, ups=0.86, wpb=103.4, bsz=40, num_updates=9050, lr=2.63495e-05, gnorm=1.889, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=10431
2022-09-27 14:34:18 - progress_bar.py[line:274] - INFO: epoch 001:   9073 / 42934 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.8, ups=0.87, wpb=104.2, bsz=40, num_updates=9060, lr=2.63786e-05, gnorm=2.086, clip=100, loss_scale=512, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=10442
2022-09-27 14:34:30 - progress_bar.py[line:274] - INFO: epoch 001:   9083 / 42934 loss=0.822, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.1, ups=0.86, wpb=102.8, bsz=40, num_updates=9070, lr=2.64077e-05, gnorm=1.787, clip=100, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=10454
2022-09-27 14:34:41 - progress_bar.py[line:274] - INFO: epoch 001:   9093 / 42934 loss=0.842, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.1, ups=0.88, wpb=103.7, bsz=40, num_updates=9080, lr=2.64368e-05, gnorm=1.832, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=10466
2022-09-27 14:34:53 - progress_bar.py[line:274] - INFO: epoch 001:   9103 / 42934 loss=0.891, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.1, ups=0.89, wpb=102.3, bsz=40, num_updates=9090, lr=2.6466e-05, gnorm=1.908, clip=100, loss_scale=512, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=10477
2022-09-27 14:35:04 - progress_bar.py[line:274] - INFO: epoch 001:   9113 / 42934 loss=0.848, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.3, ups=0.86, wpb=101.8, bsz=40, num_updates=9100, lr=2.64951e-05, gnorm=1.76, clip=100, loss_scale=512, train_wall=12, gb_free=9.3, ema_decay=0.9999, wall=10488
2022-09-27 14:35:16 - progress_bar.py[line:274] - INFO: epoch 001:   9123 / 42934 loss=0.869, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.5, ups=0.89, wpb=103.5, bsz=40, num_updates=9110, lr=2.65242e-05, gnorm=1.946, clip=100, loss_scale=512, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=10500
2022-09-27 14:35:27 - progress_bar.py[line:274] - INFO: epoch 001:   9133 / 42934 loss=0.866, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.8, ups=0.88, wpb=103.4, bsz=40, num_updates=9120, lr=2.65533e-05, gnorm=1.837, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=10511
2022-09-27 14:35:39 - progress_bar.py[line:274] - INFO: epoch 001:   9143 / 42934 loss=0.953, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=86.8, ups=0.85, wpb=102.2, bsz=40, num_updates=9130, lr=2.65824e-05, gnorm=1.843, clip=100, loss_scale=512, train_wall=12, gb_free=9.2, ema_decay=0.9999, wall=10523
2022-09-27 14:35:50 - progress_bar.py[line:274] - INFO: epoch 001:   9153 / 42934 loss=0.957, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=91.1, ups=0.89, wpb=101.9, bsz=40, num_updates=9140, lr=2.66115e-05, gnorm=1.92, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=10534
2022-09-27 14:36:02 - progress_bar.py[line:274] - INFO: epoch 001:   9163 / 42934 loss=0.898, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=88, ups=0.85, wpb=103, bsz=40, num_updates=9150, lr=2.66407e-05, gnorm=1.927, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=10546
2022-09-27 14:36:13 - progress_bar.py[line:274] - INFO: epoch 001:   9173 / 42934 loss=0.868, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.5, ups=0.86, wpb=102.3, bsz=40, num_updates=9160, lr=2.66698e-05, gnorm=1.74, clip=100, loss_scale=512, train_wall=12, gb_free=9.1, ema_decay=0.9999, wall=10557
2022-09-27 14:36:24 - progress_bar.py[line:274] - INFO: epoch 001:   9183 / 42934 loss=0.897, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.2, ups=0.94, wpb=102.4, bsz=40, num_updates=9170, lr=2.66989e-05, gnorm=1.748, clip=100, loss_scale=512, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=10568
2022-09-27 14:36:35 - progress_bar.py[line:274] - INFO: epoch 001:   9193 / 42934 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.3, ups=0.89, wpb=102.9, bsz=40, num_updates=9180, lr=2.6728e-05, gnorm=1.896, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=10579
2022-09-27 14:36:47 - progress_bar.py[line:274] - INFO: epoch 001:   9203 / 42934 loss=0.843, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.9, ups=0.84, wpb=104.5, bsz=40, num_updates=9190, lr=2.67571e-05, gnorm=1.739, clip=100, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=10591
2022-09-27 14:36:59 - progress_bar.py[line:274] - INFO: epoch 001:   9213 / 42934 loss=0.906, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=87.9, ups=0.86, wpb=102.4, bsz=40, num_updates=9200, lr=2.67862e-05, gnorm=1.722, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=10603
2022-09-27 14:37:10 - progress_bar.py[line:274] - INFO: epoch 001:   9223 / 42934 loss=0.897, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.2, ups=0.87, wpb=100.1, bsz=40, num_updates=9210, lr=2.68153e-05, gnorm=1.884, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=10614
2022-09-27 14:37:22 - progress_bar.py[line:274] - INFO: epoch 001:   9233 / 42934 loss=0.86, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90, ups=0.88, wpb=102.8, bsz=40, num_updates=9220, lr=2.68445e-05, gnorm=2.013, clip=100, loss_scale=512, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=10626
2022-09-27 14:37:33 - progress_bar.py[line:274] - INFO: epoch 001:   9243 / 42934 loss=0.844, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.7, ups=0.86, wpb=103.2, bsz=40, num_updates=9230, lr=2.68736e-05, gnorm=1.911, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=10637
2022-09-27 14:37:45 - progress_bar.py[line:274] - INFO: epoch 001:   9253 / 42934 loss=0.838, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.6, ups=0.88, wpb=102.7, bsz=40, num_updates=9240, lr=2.69027e-05, gnorm=1.791, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=10649
2022-09-27 14:37:56 - progress_bar.py[line:274] - INFO: epoch 001:   9263 / 42934 loss=0.876, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.1, ups=0.86, wpb=103.4, bsz=40, num_updates=9250, lr=2.69318e-05, gnorm=1.79, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=10660
2022-09-27 14:38:08 - progress_bar.py[line:274] - INFO: epoch 001:   9273 / 42934 loss=0.832, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87.7, ups=0.84, wpb=103.8, bsz=40, num_updates=9260, lr=2.69609e-05, gnorm=1.728, clip=100, loss_scale=1024, train_wall=12, gb_free=9.1, ema_decay=0.9999, wall=10672
2022-09-27 14:38:20 - progress_bar.py[line:274] - INFO: epoch 001:   9283 / 42934 loss=0.866, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=85.8, ups=0.85, wpb=101, bsz=40, num_updates=9270, lr=2.699e-05, gnorm=1.854, clip=100, loss_scale=1024, train_wall=12, gb_free=9.4, ema_decay=0.9999, wall=10684
2022-09-27 14:38:30 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-27 14:38:33 - progress_bar.py[line:274] - INFO: epoch 001:   9294 / 42934 loss=0.841, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=80.9, ups=0.79, wpb=102.6, bsz=40, num_updates=9280, lr=2.70192e-05, gnorm=1.801, clip=100, loss_scale=512, train_wall=13, gb_free=9.7, ema_decay=0.9999, wall=10697
2022-09-27 14:38:44 - progress_bar.py[line:274] - INFO: epoch 001:   9304 / 42934 loss=0.878, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=93.1, ups=0.9, wpb=103.3, bsz=40, num_updates=9290, lr=2.70483e-05, gnorm=1.989, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=10708
2022-09-27 14:38:55 - progress_bar.py[line:274] - INFO: epoch 001:   9314 / 42934 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.1, ups=0.9, wpb=102, bsz=40, num_updates=9300, lr=2.70774e-05, gnorm=1.595, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=10719
2022-09-27 14:39:07 - progress_bar.py[line:274] - INFO: epoch 001:   9324 / 42934 loss=0.874, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88, ups=0.85, wpb=103.1, bsz=40, num_updates=9310, lr=2.71065e-05, gnorm=1.768, clip=100, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=10731
2022-09-27 14:39:18 - progress_bar.py[line:274] - INFO: epoch 001:   9334 / 42934 loss=0.847, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.1, ups=0.87, wpb=104.1, bsz=40, num_updates=9320, lr=2.71356e-05, gnorm=1.773, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=10742
2022-09-27 14:39:30 - progress_bar.py[line:274] - INFO: epoch 001:   9344 / 42934 loss=0.826, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.7, ups=0.86, wpb=104.2, bsz=40, num_updates=9330, lr=2.71647e-05, gnorm=1.838, clip=100, loss_scale=512, train_wall=12, gb_free=6.7, ema_decay=0.9999, wall=10754
2022-09-27 14:39:41 - progress_bar.py[line:274] - INFO: epoch 001:   9354 / 42934 loss=0.899, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=90.3, ups=0.88, wpb=102.3, bsz=40, num_updates=9340, lr=2.71939e-05, gnorm=1.995, clip=100, loss_scale=512, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=10765
2022-09-27 14:39:53 - progress_bar.py[line:274] - INFO: epoch 001:   9364 / 42934 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.8, ups=0.86, wpb=104.4, bsz=40, num_updates=9350, lr=2.7223e-05, gnorm=1.627, clip=100, loss_scale=512, train_wall=12, gb_free=9.2, ema_decay=0.9999, wall=10777
2022-09-27 14:40:04 - progress_bar.py[line:274] - INFO: epoch 001:   9374 / 42934 loss=0.881, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.1, ups=0.86, wpb=104.2, bsz=40, num_updates=9360, lr=2.72521e-05, gnorm=1.754, clip=100, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=10788
2022-09-27 14:40:16 - progress_bar.py[line:274] - INFO: epoch 001:   9384 / 42934 loss=0.876, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89, ups=0.88, wpb=101.5, bsz=40, num_updates=9370, lr=2.72812e-05, gnorm=1.826, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=10800
2022-09-27 14:40:28 - progress_bar.py[line:274] - INFO: epoch 001:   9394 / 42934 loss=0.871, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=105.4, nsentences=40, sample_size=105.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.3, ups=0.88, wpb=105.4, bsz=40, num_updates=9380, lr=2.73103e-05, gnorm=1.958, clip=100, loss_scale=512, train_wall=11, gb_free=8.6, ema_decay=0.9999, wall=10811
2022-09-27 14:40:39 - progress_bar.py[line:274] - INFO: epoch 001:   9404 / 42934 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.4, ups=0.87, wpb=103.3, bsz=40, num_updates=9390, lr=2.73394e-05, gnorm=1.662, clip=100, loss_scale=512, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=10823
2022-09-27 14:40:51 - progress_bar.py[line:274] - INFO: epoch 001:   9414 / 42934 loss=0.9, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.2, ups=0.87, wpb=100.7, bsz=40, num_updates=9400, lr=2.73685e-05, gnorm=1.695, clip=100, loss_scale=512, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=10835
2022-09-27 14:41:02 - progress_bar.py[line:274] - INFO: epoch 001:   9424 / 42934 loss=0.861, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87, ups=0.85, wpb=101.9, bsz=40, num_updates=9410, lr=2.73977e-05, gnorm=1.646, clip=100, loss_scale=512, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=10847
2022-09-27 14:41:14 - progress_bar.py[line:274] - INFO: epoch 001:   9434 / 42934 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=92.3, ups=0.9, wpb=102.4, bsz=40, num_updates=9420, lr=2.74268e-05, gnorm=1.844, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=10858
2022-09-27 14:41:25 - progress_bar.py[line:274] - INFO: epoch 001:   9444 / 42934 loss=0.866, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89.3, ups=0.87, wpb=102.4, bsz=40, num_updates=9430, lr=2.74559e-05, gnorm=1.664, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=10869
2022-09-27 14:41:37 - progress_bar.py[line:274] - INFO: epoch 001:   9454 / 42934 loss=0.873, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90, ups=0.87, wpb=103, bsz=40, num_updates=9440, lr=2.7485e-05, gnorm=1.915, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=10881
2022-09-27 14:41:48 - progress_bar.py[line:274] - INFO: epoch 001:   9464 / 42934 loss=0.886, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.5, ups=0.87, wpb=102.7, bsz=40, num_updates=9450, lr=2.75141e-05, gnorm=1.891, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=10893
2022-09-27 14:42:00 - progress_bar.py[line:274] - INFO: epoch 001:   9474 / 42934 loss=0.839, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=86, ups=0.83, wpb=103, bsz=40, num_updates=9460, lr=2.75432e-05, gnorm=1.725, clip=100, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=10905
2022-09-27 14:42:12 - progress_bar.py[line:274] - INFO: epoch 001:   9484 / 42934 loss=0.859, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.2, ups=0.89, wpb=102, bsz=40, num_updates=9470, lr=2.75724e-05, gnorm=1.786, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=10916
2022-09-27 14:42:23 - progress_bar.py[line:274] - INFO: epoch 001:   9494 / 42934 loss=0.862, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=104.6, nsentences=40, sample_size=104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.7, ups=0.85, wpb=104.6, bsz=40, num_updates=9480, lr=2.76015e-05, gnorm=1.692, clip=100, loss_scale=512, train_wall=12, gb_free=8.4, ema_decay=0.9999, wall=10928
2022-09-27 14:42:35 - progress_bar.py[line:274] - INFO: epoch 001:   9504 / 42934 loss=0.822, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.7, ups=0.89, wpb=103.5, bsz=40, num_updates=9490, lr=2.76306e-05, gnorm=1.785, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=10939
2022-09-27 14:42:46 - progress_bar.py[line:274] - INFO: epoch 001:   9514 / 42934 loss=0.838, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.6, ups=0.87, wpb=103.1, bsz=40, num_updates=9500, lr=2.76597e-05, gnorm=1.91, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=10950
2022-09-27 14:42:58 - progress_bar.py[line:274] - INFO: epoch 001:   9524 / 42934 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.8, ups=0.86, wpb=102.4, bsz=40, num_updates=9510, lr=2.76888e-05, gnorm=2.078, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=10962
2022-09-27 14:43:09 - progress_bar.py[line:274] - INFO: epoch 001:   9534 / 42934 loss=0.883, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=88.5, ups=0.87, wpb=101.9, bsz=40, num_updates=9520, lr=2.77179e-05, gnorm=1.776, clip=100, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=10974
2022-09-27 14:43:21 - progress_bar.py[line:274] - INFO: epoch 001:   9544 / 42934 loss=0.874, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88, ups=0.86, wpb=101.7, bsz=40, num_updates=9530, lr=2.7747e-05, gnorm=1.864, clip=100, loss_scale=512, train_wall=12, gb_free=8.1, ema_decay=0.9999, wall=10985
2022-09-27 14:43:32 - progress_bar.py[line:274] - INFO: epoch 001:   9554 / 42934 loss=0.911, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=92.5, ups=0.89, wpb=103.7, bsz=40, num_updates=9540, lr=2.77762e-05, gnorm=1.67, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=10996
2022-09-27 14:43:43 - progress_bar.py[line:274] - INFO: epoch 001:   9564 / 42934 loss=0.879, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.6, ups=0.9, wpb=103.2, bsz=40, num_updates=9550, lr=2.78053e-05, gnorm=1.853, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=11007
2022-09-27 14:43:55 - progress_bar.py[line:274] - INFO: epoch 001:   9574 / 42934 loss=0.813, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.6, ups=0.88, wpb=104, bsz=40, num_updates=9560, lr=2.78344e-05, gnorm=1.646, clip=100, loss_scale=512, train_wall=11, gb_free=8.4, ema_decay=0.9999, wall=11019
2022-09-27 14:44:07 - progress_bar.py[line:274] - INFO: epoch 001:   9584 / 42934 loss=0.834, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=86.6, ups=0.84, wpb=103, bsz=40, num_updates=9570, lr=2.78635e-05, gnorm=1.63, clip=100, loss_scale=512, train_wall=12, gb_free=8.5, ema_decay=0.9999, wall=11031
2022-09-27 14:44:18 - progress_bar.py[line:274] - INFO: epoch 001:   9594 / 42934 loss=0.849, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.5, ups=0.86, wpb=103.8, bsz=40, num_updates=9580, lr=2.78926e-05, gnorm=1.802, clip=100, loss_scale=512, train_wall=12, gb_free=9.1, ema_decay=0.9999, wall=11042
2022-09-27 14:44:30 - progress_bar.py[line:274] - INFO: epoch 001:   9604 / 42934 loss=0.886, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88.1, ups=0.87, wpb=101.4, bsz=40, num_updates=9590, lr=2.79217e-05, gnorm=1.798, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=11054
2022-09-27 14:44:41 - progress_bar.py[line:274] - INFO: epoch 001:   9614 / 42934 loss=0.877, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=88.9, ups=0.87, wpb=102.6, bsz=40, num_updates=9600, lr=2.79509e-05, gnorm=1.964, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=11065
2022-09-27 14:44:53 - progress_bar.py[line:274] - INFO: epoch 001:   9624 / 42934 loss=0.899, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=86.9, ups=0.85, wpb=101.7, bsz=40, num_updates=9610, lr=2.798e-05, gnorm=1.797, clip=100, loss_scale=512, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=11077
2022-09-27 14:45:05 - progress_bar.py[line:274] - INFO: epoch 001:   9634 / 42934 loss=0.858, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.7, ups=0.85, wpb=103.3, bsz=40, num_updates=9620, lr=2.80091e-05, gnorm=2.109, clip=100, loss_scale=512, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=11089
2022-09-27 14:45:16 - progress_bar.py[line:274] - INFO: epoch 001:   9644 / 42934 loss=0.972, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=89.5, ups=0.88, wpb=102.1, bsz=40, num_updates=9630, lr=2.80382e-05, gnorm=1.962, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=11100
2022-09-27 14:45:28 - progress_bar.py[line:274] - INFO: epoch 001:   9654 / 42934 loss=0.847, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.1, ups=0.87, wpb=104.1, bsz=40, num_updates=9640, lr=2.80673e-05, gnorm=1.823, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=11112
2022-09-27 14:45:39 - progress_bar.py[line:274] - INFO: epoch 001:   9664 / 42934 loss=0.939, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=86.9, ups=0.87, wpb=100.3, bsz=40, num_updates=9650, lr=2.80964e-05, gnorm=2.025, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=11123
2022-09-27 14:45:51 - progress_bar.py[line:274] - INFO: epoch 001:   9674 / 42934 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88.8, ups=0.86, wpb=102.7, bsz=40, num_updates=9660, lr=2.81255e-05, gnorm=1.837, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=11135
2022-09-27 14:46:02 - progress_bar.py[line:274] - INFO: epoch 001:   9684 / 42934 loss=0.87, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.5, ups=0.87, wpb=102.1, bsz=40, num_updates=9670, lr=2.81547e-05, gnorm=1.652, clip=100, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=11146
2022-09-27 14:46:14 - progress_bar.py[line:274] - INFO: epoch 001:   9694 / 42934 loss=0.876, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.4, ups=0.88, wpb=102.6, bsz=40, num_updates=9680, lr=2.81838e-05, gnorm=1.674, clip=100, loss_scale=512, train_wall=11, gb_free=8.9, ema_decay=0.9999, wall=11158
2022-09-27 14:46:25 - progress_bar.py[line:274] - INFO: epoch 001:   9704 / 42934 loss=0.873, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.1, ups=0.88, wpb=103, bsz=40, num_updates=9690, lr=2.82129e-05, gnorm=1.781, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=11169
2022-09-27 14:46:36 - progress_bar.py[line:274] - INFO: epoch 001:   9714 / 42934 loss=0.905, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=91.1, ups=0.89, wpb=102.5, bsz=40, num_updates=9700, lr=2.8242e-05, gnorm=1.786, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=11180
2022-09-27 14:46:48 - progress_bar.py[line:274] - INFO: epoch 001:   9724 / 42934 loss=0.919, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=90.2, ups=0.86, wpb=104.4, bsz=40, num_updates=9710, lr=2.82711e-05, gnorm=1.769, clip=100, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=11192
2022-09-27 14:46:59 - progress_bar.py[line:274] - INFO: epoch 001:   9734 / 42934 loss=0.899, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.3, ups=0.87, wpb=103.1, bsz=40, num_updates=9720, lr=2.83002e-05, gnorm=1.884, clip=100, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=11204
2022-09-27 14:47:11 - progress_bar.py[line:274] - INFO: epoch 001:   9744 / 42934 loss=0.811, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.6, ups=0.85, wpb=103.5, bsz=40, num_updates=9730, lr=2.83294e-05, gnorm=1.595, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=11215
2022-09-27 14:47:23 - progress_bar.py[line:274] - INFO: epoch 001:   9754 / 42934 loss=0.909, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=85.6, ups=0.84, wpb=102.2, bsz=40, num_updates=9740, lr=2.83585e-05, gnorm=1.881, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=11227
2022-09-27 14:47:35 - progress_bar.py[line:274] - INFO: epoch 001:   9764 / 42934 loss=0.924, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=86, ups=0.84, wpb=102.1, bsz=40, num_updates=9750, lr=2.83876e-05, gnorm=2.049, clip=100, loss_scale=512, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=11239
2022-09-27 14:47:47 - progress_bar.py[line:274] - INFO: epoch 001:   9774 / 42934 loss=0.838, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.4, ups=0.85, wpb=104.2, bsz=40, num_updates=9760, lr=2.84167e-05, gnorm=1.882, clip=100, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=11251
2022-09-27 14:47:59 - progress_bar.py[line:274] - INFO: epoch 001:   9784 / 42934 loss=0.891, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.6, ups=0.86, wpb=102.2, bsz=40, num_updates=9770, lr=2.84458e-05, gnorm=1.727, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=11263
2022-09-27 14:48:10 - progress_bar.py[line:274] - INFO: epoch 001:   9794 / 42934 loss=0.776, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.1, ups=0.86, wpb=104.1, bsz=40, num_updates=9780, lr=2.84749e-05, gnorm=1.609, clip=100, loss_scale=512, train_wall=12, gb_free=9.1, ema_decay=0.9999, wall=11274
2022-09-27 14:48:22 - progress_bar.py[line:274] - INFO: epoch 001:   9804 / 42934 loss=0.91, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=88.8, ups=0.88, wpb=100.7, bsz=40, num_updates=9790, lr=2.8504e-05, gnorm=1.604, clip=100, loss_scale=1024, train_wall=11, gb_free=8.4, ema_decay=0.9999, wall=11286
2022-09-27 14:48:33 - progress_bar.py[line:274] - INFO: epoch 001:   9814 / 42934 loss=0.869, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89.7, ups=0.87, wpb=102.8, bsz=40, num_updates=9800, lr=2.85332e-05, gnorm=1.946, clip=100, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=11297
2022-09-27 14:48:41 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-27 14:48:46 - progress_bar.py[line:274] - INFO: epoch 001:   9825 / 42934 loss=0.848, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=81.9, ups=0.79, wpb=103.9, bsz=40, num_updates=9810, lr=2.85623e-05, gnorm=1.824, clip=100, loss_scale=512, train_wall=13, gb_free=9.8, ema_decay=0.9999, wall=11310
2022-09-27 14:48:57 - progress_bar.py[line:274] - INFO: epoch 001:   9835 / 42934 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.7, ups=0.87, wpb=102.9, bsz=40, num_updates=9820, lr=2.85914e-05, gnorm=1.745, clip=100, loss_scale=512, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=11321
2022-09-27 14:49:09 - progress_bar.py[line:274] - INFO: epoch 001:   9845 / 42934 loss=0.872, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.5, ups=0.88, wpb=103.9, bsz=40, num_updates=9830, lr=2.86205e-05, gnorm=1.779, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=11333
2022-09-27 14:49:20 - progress_bar.py[line:274] - INFO: epoch 001:   9855 / 42934 loss=0.836, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.5, ups=0.89, wpb=102.1, bsz=40, num_updates=9840, lr=2.86496e-05, gnorm=1.566, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=11344
2022-09-27 14:49:31 - progress_bar.py[line:274] - INFO: epoch 001:   9865 / 42934 loss=0.906, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.6, ups=0.89, wpb=101.3, bsz=40, num_updates=9850, lr=2.86787e-05, gnorm=1.741, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=11355
2022-09-27 14:49:43 - progress_bar.py[line:274] - INFO: epoch 001:   9875 / 42934 loss=0.88, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88.8, ups=0.85, wpb=104, bsz=40, num_updates=9860, lr=2.87079e-05, gnorm=1.787, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=11367
2022-09-27 14:49:54 - progress_bar.py[line:274] - INFO: epoch 001:   9885 / 42934 loss=0.825, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.1, ups=0.89, wpb=103.2, bsz=40, num_updates=9870, lr=2.8737e-05, gnorm=1.831, clip=100, loss_scale=512, train_wall=11, gb_free=8.8, ema_decay=0.9999, wall=11378
2022-09-27 14:50:06 - progress_bar.py[line:274] - INFO: epoch 001:   9895 / 42934 loss=0.824, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=85.3, ups=0.83, wpb=103.2, bsz=40, num_updates=9880, lr=2.87661e-05, gnorm=1.814, clip=100, loss_scale=512, train_wall=12, gb_free=9.6, ema_decay=0.9999, wall=11390
2022-09-27 14:50:17 - progress_bar.py[line:274] - INFO: epoch 001:   9905 / 42934 loss=0.796, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.9, ups=0.91, wpb=102.6, bsz=40, num_updates=9890, lr=2.87952e-05, gnorm=1.844, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=11401
2022-09-27 14:50:29 - progress_bar.py[line:274] - INFO: epoch 001:   9915 / 42934 loss=0.874, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89, ups=0.86, wpb=103.5, bsz=40, num_updates=9900, lr=2.88243e-05, gnorm=1.792, clip=100, loss_scale=512, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=11413
2022-09-27 14:50:40 - progress_bar.py[line:274] - INFO: epoch 001:   9925 / 42934 loss=0.932, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=88.8, ups=0.87, wpb=102.1, bsz=40, num_updates=9910, lr=2.88534e-05, gnorm=1.818, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=11425
2022-09-27 14:50:52 - progress_bar.py[line:274] - INFO: epoch 001:   9935 / 42934 loss=0.9, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.4, ups=0.88, wpb=102.5, bsz=40, num_updates=9920, lr=2.88825e-05, gnorm=1.842, clip=100, loss_scale=512, train_wall=11, gb_free=8.9, ema_decay=0.9999, wall=11436
2022-09-27 14:51:03 - progress_bar.py[line:274] - INFO: epoch 001:   9945 / 42934 loss=0.88, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90, ups=0.88, wpb=101.7, bsz=40, num_updates=9930, lr=2.89117e-05, gnorm=1.758, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=11447
2022-09-27 14:51:14 - progress_bar.py[line:274] - INFO: epoch 001:   9955 / 42934 loss=0.886, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92, ups=0.89, wpb=103.2, bsz=40, num_updates=9940, lr=2.89408e-05, gnorm=1.702, clip=100, loss_scale=512, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=11458
2022-09-27 14:51:26 - progress_bar.py[line:274] - INFO: epoch 001:   9965 / 42934 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87.9, ups=0.85, wpb=103.8, bsz=40, num_updates=9950, lr=2.89699e-05, gnorm=1.626, clip=100, loss_scale=512, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=11470
2022-09-27 14:51:38 - progress_bar.py[line:274] - INFO: epoch 001:   9975 / 42934 loss=0.902, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89, ups=0.87, wpb=102.3, bsz=40, num_updates=9960, lr=2.8999e-05, gnorm=1.897, clip=100, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=11482
2022-09-27 14:51:49 - progress_bar.py[line:274] - INFO: epoch 001:   9985 / 42934 loss=0.885, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.6, ups=0.9, wpb=102.8, bsz=40, num_updates=9970, lr=2.90281e-05, gnorm=1.548, clip=100, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=11493
2022-09-27 14:52:00 - progress_bar.py[line:274] - INFO: epoch 001:   9995 / 42934 loss=0.86, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89, ups=0.86, wpb=103.8, bsz=40, num_updates=9980, lr=2.90572e-05, gnorm=1.606, clip=100, loss_scale=512, train_wall=12, gb_free=10, ema_decay=0.9999, wall=11505
2022-09-27 14:52:12 - progress_bar.py[line:274] - INFO: epoch 001:  10005 / 42934 loss=0.916, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=89.2, ups=0.88, wpb=101.9, bsz=40, num_updates=9990, lr=2.90864e-05, gnorm=1.824, clip=100, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=11516
2022-09-27 14:52:23 - progress_bar.py[line:274] - INFO: epoch 001:  10015 / 42934 loss=0.833, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.6, ups=0.88, wpb=103.8, bsz=40, num_updates=10000, lr=2.91155e-05, gnorm=1.782, clip=100, loss_scale=512, train_wall=11, gb_free=8.5, ema_decay=0.9999, wall=11527
2022-09-27 14:52:23 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-27 14:52:23 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-09-27 14:52:34 - train.py[line:549] - INFO: 0 / 2354
2022-09-27 14:52:34 - train.py[line:551] - INFO: load:6.97 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-27 14:56:26 - train.py[line:549] - INFO: 20 / 2354
2022-09-27 14:56:26 - train.py[line:551] - INFO: load:6.98 valid_run:232.28 task_valid:219.10 collect_output:13.04
2022-09-27 15:00:06 - train.py[line:549] - INFO: 40 / 2354
2022-09-27 15:00:06 - train.py[line:551] - INFO: load:6.99 valid_run:452.37 task_valid:438.21 collect_output:13.90
2022-09-27 15:03:39 - train.py[line:549] - INFO: 60 / 2354
2022-09-27 15:03:39 - train.py[line:551] - INFO: load:6.99 valid_run:665.79 task_valid:647.03 collect_output:18.37
2022-09-27 15:07:10 - train.py[line:549] - INFO: 80 / 2354
2022-09-27 15:07:10 - train.py[line:551] - INFO: load:7.00 valid_run:876.62 task_valid:856.47 collect_output:19.65
2022-09-27 15:11:16 - train.py[line:549] - INFO: 100 / 2354
2022-09-27 15:11:16 - train.py[line:551] - INFO: load:7.01 valid_run:1122.41 task_valid:1097.53 collect_output:24.25
2022-09-27 15:14:51 - train.py[line:549] - INFO: 120 / 2354
2022-09-27 15:14:51 - train.py[line:551] - INFO: load:7.01 valid_run:1337.75 task_valid:1312.53 collect_output:24.49
2022-09-27 15:18:21 - train.py[line:549] - INFO: 140 / 2354
2022-09-27 15:18:21 - train.py[line:551] - INFO: load:7.02 valid_run:1546.95 task_valid:1519.73 collect_output:26.37
2022-09-27 15:21:51 - train.py[line:549] - INFO: 160 / 2354
2022-09-27 15:21:51 - train.py[line:551] - INFO: load:7.03 valid_run:1757.03 task_valid:1722.38 collect_output:33.68
2022-09-27 15:25:26 - train.py[line:549] - INFO: 180 / 2354
2022-09-27 15:25:26 - train.py[line:551] - INFO: load:7.03 valid_run:1972.70 task_valid:1928.35 collect_output:43.25
2022-09-27 15:29:09 - train.py[line:549] - INFO: 200 / 2354
2022-09-27 15:29:09 - train.py[line:551] - INFO: load:7.04 valid_run:2195.48 task_valid:2133.48 collect_output:60.77
2022-09-27 15:32:32 - train.py[line:549] - INFO: 220 / 2354
2022-09-27 15:32:32 - train.py[line:551] - INFO: load:7.05 valid_run:2398.02 task_valid:2325.53 collect_output:71.13
2022-09-27 15:36:00 - train.py[line:549] - INFO: 240 / 2354
2022-09-27 15:36:00 - train.py[line:551] - INFO: load:7.05 valid_run:2606.49 task_valid:2517.39 collect_output:87.61
2022-09-27 15:39:35 - train.py[line:549] - INFO: 260 / 2354
2022-09-27 15:39:35 - train.py[line:551] - INFO: load:7.06 valid_run:2820.92 task_valid:2729.53 collect_output:89.74
2022-09-27 15:43:15 - train.py[line:549] - INFO: 280 / 2354
2022-09-27 15:43:15 - train.py[line:551] - INFO: load:7.07 valid_run:3041.61 task_valid:2945.24 collect_output:94.57
2022-09-27 15:46:49 - train.py[line:549] - INFO: 300 / 2354
2022-09-27 15:46:49 - train.py[line:551] - INFO: load:7.08 valid_run:3255.27 task_valid:3154.55 collect_output:98.78
2022-09-27 15:50:29 - train.py[line:549] - INFO: 320 / 2354
2022-09-27 15:50:29 - train.py[line:551] - INFO: load:7.08 valid_run:3475.42 task_valid:3364.82 collect_output:108.52
2022-09-27 15:54:15 - train.py[line:549] - INFO: 340 / 2354
2022-09-27 15:54:15 - train.py[line:551] - INFO: load:7.09 valid_run:3701.58 task_valid:3586.23 collect_output:113.14
2022-09-27 15:57:58 - train.py[line:549] - INFO: 360 / 2354
2022-09-27 15:57:58 - train.py[line:551] - INFO: load:7.10 valid_run:3923.82 task_valid:3800.33 collect_output:121.14
2022-09-27 16:01:36 - train.py[line:549] - INFO: 380 / 2354
2022-09-27 16:01:36 - train.py[line:551] - INFO: load:7.11 valid_run:4142.70 task_valid:4007.26 collect_output:132.98
2022-09-27 16:05:11 - train.py[line:549] - INFO: 400 / 2354
2022-09-27 16:05:11 - train.py[line:551] - INFO: load:7.11 valid_run:4357.31 task_valid:4217.65 collect_output:137.09
2022-09-27 16:08:48 - train.py[line:549] - INFO: 420 / 2354
2022-09-27 16:08:48 - train.py[line:551] - INFO: load:7.12 valid_run:4573.87 task_valid:4412.51 collect_output:158.67
2022-09-27 16:12:25 - train.py[line:549] - INFO: 440 / 2354
2022-09-27 16:12:25 - train.py[line:551] - INFO: load:7.13 valid_run:4791.33 task_valid:4625.94 collect_output:162.58
2022-09-27 16:16:08 - train.py[line:549] - INFO: 460 / 2354
2022-09-27 16:16:08 - train.py[line:551] - INFO: load:7.14 valid_run:5014.14 task_valid:4843.86 collect_output:167.37
2022-09-27 16:19:58 - train.py[line:549] - INFO: 480 / 2354
2022-09-27 16:19:58 - train.py[line:551] - INFO: load:7.14 valid_run:5244.66 task_valid:5068.49 collect_output:173.14
2022-09-27 16:23:55 - train.py[line:549] - INFO: 500 / 2354
2022-09-27 16:23:55 - train.py[line:551] - INFO: load:7.15 valid_run:5481.34 task_valid:5289.15 collect_output:189.03
2022-09-27 16:27:24 - train.py[line:549] - INFO: 520 / 2354
2022-09-27 16:27:24 - train.py[line:551] - INFO: load:7.16 valid_run:5689.78 task_valid:5490.11 collect_output:196.40
2022-09-27 16:30:55 - train.py[line:549] - INFO: 540 / 2354
2022-09-27 16:30:55 - train.py[line:551] - INFO: load:7.17 valid_run:5901.09 task_valid:5673.59 collect_output:224.12
2022-09-27 16:34:20 - train.py[line:549] - INFO: 560 / 2354
2022-09-27 16:34:20 - train.py[line:551] - INFO: load:7.18 valid_run:6106.44 task_valid:5871.10 collect_output:231.83
2022-09-27 16:37:44 - train.py[line:549] - INFO: 580 / 2354
2022-09-27 16:37:44 - train.py[line:551] - INFO: load:7.18 valid_run:6310.35 task_valid:6071.95 collect_output:234.78
2022-09-27 16:41:17 - train.py[line:549] - INFO: 600 / 2354
2022-09-27 16:41:17 - train.py[line:551] - INFO: load:7.19 valid_run:6522.83 task_valid:6264.62 collect_output:254.45
2022-09-27 16:45:21 - train.py[line:549] - INFO: 620 / 2354
2022-09-27 16:45:21 - train.py[line:551] - INFO: load:7.21 valid_run:6767.16 task_valid:6506.17 collect_output:257.08
2022-09-27 16:48:55 - train.py[line:549] - INFO: 640 / 2354
2022-09-27 16:48:55 - train.py[line:551] - INFO: load:7.22 valid_run:6980.62 task_valid:6715.24 collect_output:261.35
2022-09-27 16:52:28 - train.py[line:549] - INFO: 660 / 2354
2022-09-27 16:52:28 - train.py[line:551] - INFO: load:7.23 valid_run:7194.13 task_valid:6908.34 collect_output:281.65
2022-09-27 16:55:47 - train.py[line:549] - INFO: 680 / 2354
2022-09-27 16:55:47 - train.py[line:551] - INFO: load:7.23 valid_run:7392.80 task_valid:7095.44 collect_output:293.09
2022-09-27 16:59:21 - train.py[line:549] - INFO: 700 / 2354
2022-09-27 16:59:21 - train.py[line:551] - INFO: load:7.24 valid_run:7607.00 task_valid:7306.84 collect_output:295.77
2022-09-27 17:02:50 - train.py[line:549] - INFO: 720 / 2354
2022-09-27 17:02:50 - train.py[line:551] - INFO: load:7.25 valid_run:7815.69 task_valid:7509.73 collect_output:301.46
2022-09-27 17:06:26 - train.py[line:549] - INFO: 740 / 2354
2022-09-27 17:06:26 - train.py[line:551] - INFO: load:7.26 valid_run:8032.07 task_valid:7714.22 collect_output:313.23
2022-09-27 17:10:24 - train.py[line:549] - INFO: 760 / 2354
2022-09-27 17:10:24 - train.py[line:551] - INFO: load:7.27 valid_run:8269.70 task_valid:7950.91 collect_output:314.06
2022-09-27 17:14:14 - train.py[line:549] - INFO: 780 / 2354
2022-09-27 17:14:14 - train.py[line:551] - INFO: load:7.28 valid_run:8500.44 task_valid:8170.50 collect_output:325.10
2022-09-27 17:18:20 - train.py[line:549] - INFO: 800 / 2354
2022-09-27 17:18:20 - train.py[line:551] - INFO: load:7.29 valid_run:8745.84 task_valid:8370.62 collect_output:370.25
2022-09-27 17:22:25 - train.py[line:549] - INFO: 820 / 2354
2022-09-27 17:22:25 - train.py[line:551] - INFO: load:7.30 valid_run:8990.60 task_valid:8578.25 collect_output:407.24
2022-09-27 17:26:01 - train.py[line:549] - INFO: 840 / 2354
2022-09-27 17:26:01 - train.py[line:551] - INFO: load:7.30 valid_run:9206.55 task_valid:8781.40 collect_output:419.93
2022-09-27 17:29:42 - train.py[line:549] - INFO: 860 / 2354
2022-09-27 17:29:42 - train.py[line:551] - INFO: load:7.31 valid_run:9427.55 task_valid:8994.33 collect_output:427.87
2022-09-27 17:33:47 - train.py[line:549] - INFO: 880 / 2354
2022-09-27 17:33:47 - train.py[line:551] - INFO: load:7.32 valid_run:9672.94 task_valid:9202.23 collect_output:465.22
2022-09-27 17:37:56 - train.py[line:549] - INFO: 900 / 2354
2022-09-27 17:37:56 - train.py[line:551] - INFO: load:7.33 valid_run:9921.53 task_valid:9413.05 collect_output:502.86
2022-09-27 17:42:24 - train.py[line:549] - INFO: 920 / 2354
2022-09-27 17:42:24 - train.py[line:551] - INFO: load:7.34 valid_run:10189.79 task_valid:9681.13 collect_output:502.92
2022-09-27 17:45:56 - train.py[line:549] - INFO: 940 / 2354
2022-09-27 17:45:56 - train.py[line:551] - INFO: load:7.35 valid_run:10402.31 task_valid:9887.25 collect_output:509.21
2022-09-27 17:49:41 - train.py[line:549] - INFO: 960 / 2354
2022-09-27 17:49:41 - train.py[line:551] - INFO: load:7.36 valid_run:10627.22 task_valid:10095.66 collect_output:525.58
2022-09-27 17:53:47 - train.py[line:549] - INFO: 980 / 2354
2022-09-27 17:53:47 - train.py[line:551] - INFO: load:7.37 valid_run:10872.69 task_valid:10323.27 collect_output:543.31
2022-09-27 17:57:28 - train.py[line:549] - INFO: 1000 / 2354
2022-09-27 17:57:28 - train.py[line:551] - INFO: load:7.38 valid_run:11093.32 task_valid:10533.74 collect_output:553.34
2022-09-27 18:01:05 - train.py[line:549] - INFO: 1020 / 2354
2022-09-27 18:01:05 - train.py[line:551] - INFO: load:7.39 valid_run:11311.20 task_valid:10738.64 collect_output:566.18
2022-09-27 18:04:53 - train.py[line:549] - INFO: 1040 / 2354
2022-09-27 18:04:53 - train.py[line:551] - INFO: load:7.40 valid_run:11539.06 task_valid:10936.64 collect_output:595.93
2022-09-27 18:08:33 - train.py[line:549] - INFO: 1060 / 2354
2022-09-27 18:08:33 - train.py[line:551] - INFO: load:7.41 valid_run:11758.63 task_valid:11133.36 collect_output:618.64
2022-09-27 18:12:26 - train.py[line:549] - INFO: 1080 / 2354
2022-09-27 18:12:26 - train.py[line:551] - INFO: load:7.42 valid_run:11991.85 task_valid:11349.14 collect_output:635.95
2022-09-27 18:16:12 - train.py[line:549] - INFO: 1100 / 2354
2022-09-27 18:16:12 - train.py[line:551] - INFO: load:7.43 valid_run:12218.18 task_valid:11574.08 collect_output:637.23
2022-09-27 18:19:49 - train.py[line:549] - INFO: 1120 / 2354
2022-09-27 18:19:49 - train.py[line:551] - INFO: load:7.44 valid_run:12434.46 task_valid:11785.39 collect_output:642.07
2022-09-27 18:23:24 - train.py[line:549] - INFO: 1140 / 2354
2022-09-27 18:23:24 - train.py[line:551] - INFO: load:7.45 valid_run:12649.43 task_valid:11977.90 collect_output:664.40
2022-09-27 18:27:00 - train.py[line:549] - INFO: 1160 / 2354
2022-09-27 18:27:00 - train.py[line:551] - INFO: load:7.46 valid_run:12865.85 task_valid:12192.17 collect_output:666.44
2022-09-27 18:30:37 - train.py[line:549] - INFO: 1180 / 2354
2022-09-27 18:30:37 - train.py[line:551] - INFO: load:7.47 valid_run:13082.21 task_valid:12406.27 collect_output:668.59
2022-09-27 18:33:52 - train.py[line:549] - INFO: 1200 / 2354
2022-09-27 18:33:52 - train.py[line:551] - INFO: load:7.47 valid_run:13278.17 task_valid:12596.56 collect_output:674.15
2022-09-27 18:37:35 - train.py[line:549] - INFO: 1220 / 2354
2022-09-27 18:37:35 - train.py[line:551] - INFO: load:7.48 valid_run:13501.07 task_valid:12814.58 collect_output:678.90
2022-09-27 18:41:05 - train.py[line:549] - INFO: 1240 / 2354
2022-09-27 18:41:05 - train.py[line:551] - INFO: load:7.49 valid_run:13710.81 task_valid:13020.06 collect_output:683.06
2022-09-27 18:44:51 - train.py[line:549] - INFO: 1260 / 2354
2022-09-27 18:44:51 - train.py[line:551] - INFO: load:7.50 valid_run:13937.03 task_valid:13221.69 collect_output:707.53
2022-09-27 18:48:23 - train.py[line:549] - INFO: 1280 / 2354
2022-09-27 18:48:23 - train.py[line:551] - INFO: load:7.51 valid_run:14148.50 task_valid:13426.71 collect_output:713.86
2022-09-27 18:51:55 - train.py[line:549] - INFO: 1300 / 2354
2022-09-27 18:51:55 - train.py[line:551] - INFO: load:7.52 valid_run:14360.39 task_valid:13633.94 collect_output:718.40
2022-09-27 18:55:26 - train.py[line:549] - INFO: 1320 / 2354
2022-09-27 18:55:26 - train.py[line:551] - INFO: load:7.53 valid_run:14571.99 task_valid:13840.50 collect_output:723.30
2022-09-27 18:58:55 - train.py[line:549] - INFO: 1340 / 2354
2022-09-27 18:58:55 - train.py[line:551] - INFO: load:7.54 valid_run:14780.62 task_valid:14038.06 collect_output:734.23
2022-09-27 19:02:47 - train.py[line:549] - INFO: 1360 / 2354
2022-09-27 19:02:47 - train.py[line:551] - INFO: load:7.55 valid_run:15012.13 task_valid:14269.33 collect_output:734.30
2022-09-27 19:06:30 - train.py[line:549] - INFO: 1380 / 2354
2022-09-27 19:06:30 - train.py[line:551] - INFO: load:7.56 valid_run:15235.57 task_valid:14480.85 collect_output:746.09
2022-09-27 19:09:54 - train.py[line:549] - INFO: 1400 / 2354
2022-09-27 19:09:54 - train.py[line:551] - INFO: load:7.57 valid_run:15439.58 task_valid:14684.61 collect_output:746.22
2022-09-27 19:13:26 - train.py[line:549] - INFO: 1420 / 2354
2022-09-27 19:13:26 - train.py[line:551] - INFO: load:7.58 valid_run:15651.15 task_valid:14894.87 collect_output:747.40
2022-09-27 19:16:58 - train.py[line:549] - INFO: 1440 / 2354
2022-09-27 19:16:58 - train.py[line:551] - INFO: load:7.59 valid_run:15863.67 task_valid:15093.59 collect_output:761.08
2022-09-27 19:20:29 - train.py[line:549] - INFO: 1460 / 2354
2022-09-27 19:20:29 - train.py[line:551] - INFO: load:7.60 valid_run:16074.52 task_valid:15292.89 collect_output:772.52
2022-09-27 19:23:55 - train.py[line:549] - INFO: 1480 / 2354
2022-09-27 19:23:55 - train.py[line:551] - INFO: load:7.61 valid_run:16280.43 task_valid:15491.93 collect_output:779.27
2022-09-27 19:27:33 - train.py[line:549] - INFO: 1500 / 2354
2022-09-27 19:27:33 - train.py[line:551] - INFO: load:7.62 valid_run:16498.78 task_valid:15705.23 collect_output:784.20
2022-09-27 19:30:57 - train.py[line:549] - INFO: 1520 / 2354
2022-09-27 19:30:57 - train.py[line:551] - INFO: load:7.63 valid_run:16702.26 task_valid:15900.73 collect_output:792.07
2022-09-27 19:35:14 - train.py[line:549] - INFO: 1540 / 2354
2022-09-27 19:35:14 - train.py[line:551] - INFO: load:7.64 valid_run:16959.46 task_valid:16096.91 collect_output:852.96
2022-09-27 19:39:15 - train.py[line:549] - INFO: 1560 / 2354
2022-09-27 19:39:15 - train.py[line:551] - INFO: load:7.65 valid_run:17200.25 task_valid:16295.07 collect_output:895.47
2022-09-27 19:42:45 - train.py[line:549] - INFO: 1580 / 2354
2022-09-27 19:42:45 - train.py[line:551] - INFO: load:7.66 valid_run:17410.13 task_valid:16490.50 collect_output:909.80
2022-09-27 19:46:39 - train.py[line:549] - INFO: 1600 / 2354
2022-09-27 19:46:39 - train.py[line:551] - INFO: load:7.67 valid_run:17644.74 task_valid:16702.68 collect_output:932.11
2022-09-27 19:50:15 - train.py[line:549] - INFO: 1620 / 2354
2022-09-27 19:50:15 - train.py[line:551] - INFO: load:7.68 valid_run:17860.00 task_valid:16901.69 collect_output:948.24
2022-09-27 19:53:42 - train.py[line:549] - INFO: 1640 / 2354
2022-09-27 19:53:42 - train.py[line:551] - INFO: load:7.69 valid_run:18067.27 task_valid:17105.39 collect_output:951.70
2022-09-27 19:57:17 - train.py[line:549] - INFO: 1660 / 2354
2022-09-27 19:57:17 - train.py[line:551] - INFO: load:7.69 valid_run:18282.17 task_valid:17320.12 collect_output:951.75
2022-09-27 20:00:59 - train.py[line:549] - INFO: 1680 / 2354
2022-09-27 20:00:59 - train.py[line:551] - INFO: load:7.70 valid_run:18504.56 task_valid:17530.72 collect_output:963.43
2022-09-27 20:04:25 - train.py[line:549] - INFO: 1700 / 2354
2022-09-27 20:04:25 - train.py[line:551] - INFO: load:7.71 valid_run:18710.55 task_valid:17731.58 collect_output:968.43
2022-09-27 20:08:02 - train.py[line:549] - INFO: 1720 / 2354
2022-09-27 20:08:02 - train.py[line:551] - INFO: load:7.72 valid_run:18927.08 task_valid:17945.45 collect_output:970.94
2022-09-27 20:11:34 - train.py[line:549] - INFO: 1740 / 2354
2022-09-27 20:11:34 - train.py[line:551] - INFO: load:7.73 valid_run:19139.28 task_valid:18156.55 collect_output:971.91
2022-09-27 20:15:08 - train.py[line:549] - INFO: 1760 / 2354
2022-09-27 20:15:08 - train.py[line:551] - INFO: load:7.74 valid_run:19352.87 task_valid:18364.50 collect_output:977.40
2022-09-27 20:18:46 - train.py[line:549] - INFO: 1780 / 2354
2022-09-27 20:18:46 - train.py[line:551] - INFO: load:7.75 valid_run:19571.31 task_valid:18570.82 collect_output:989.40
2022-09-27 20:22:21 - train.py[line:549] - INFO: 1800 / 2354
2022-09-27 20:22:21 - train.py[line:551] - INFO: load:7.76 valid_run:19786.42 task_valid:18782.20 collect_output:993.01
2022-09-27 20:25:56 - train.py[line:549] - INFO: 1820 / 2354
2022-09-27 20:25:56 - train.py[line:551] - INFO: load:7.77 valid_run:20001.62 task_valid:18996.54 collect_output:993.75
2022-09-27 20:30:17 - train.py[line:549] - INFO: 1840 / 2354
2022-09-27 20:30:17 - train.py[line:551] - INFO: load:7.78 valid_run:20262.71 task_valid:19256.57 collect_output:994.67
2022-09-27 20:35:12 - train.py[line:549] - INFO: 1860 / 2354
2022-09-27 20:35:12 - train.py[line:551] - INFO: load:7.79 valid_run:20556.84 task_valid:19548.00 collect_output:997.25
2022-09-27 20:39:47 - train.py[line:549] - INFO: 1880 / 2354
2022-09-27 20:39:47 - train.py[line:551] - INFO: load:7.80 valid_run:20831.70 task_valid:19819.66 collect_output:1000.33
2022-09-27 20:43:40 - train.py[line:549] - INFO: 1900 / 2354
2022-09-27 20:43:40 - train.py[line:551] - INFO: load:7.81 valid_run:21065.15 task_valid:20049.99 collect_output:1003.34
2022-09-27 20:47:29 - train.py[line:549] - INFO: 1920 / 2354
2022-09-27 20:47:29 - train.py[line:551] - INFO: load:7.82 valid_run:21294.44 task_valid:20263.50 collect_output:1018.99
2022-09-27 20:51:07 - train.py[line:549] - INFO: 1940 / 2354
2022-09-27 20:51:07 - train.py[line:551] - INFO: load:7.83 valid_run:21511.82 task_valid:20474.17 collect_output:1025.59
2022-09-27 20:56:38 - train.py[line:549] - INFO: 1960 / 2354
2022-09-27 20:56:38 - train.py[line:551] - INFO: load:7.84 valid_run:21843.22 task_valid:20697.10 collect_output:1133.92
2022-09-27 21:00:41 - train.py[line:549] - INFO: 1980 / 2354
2022-09-27 21:00:41 - train.py[line:551] - INFO: load:7.85 valid_run:22085.93 task_valid:20928.84 collect_output:1144.77
2022-09-27 21:04:18 - train.py[line:549] - INFO: 2000 / 2354
2022-09-27 21:04:18 - train.py[line:551] - INFO: load:7.86 valid_run:22302.84 task_valid:21143.15 collect_output:1147.26
2022-09-27 21:08:06 - train.py[line:549] - INFO: 2020 / 2354
2022-09-27 21:08:06 - train.py[line:551] - INFO: load:7.87 valid_run:22531.17 task_valid:21336.81 collect_output:1181.80
2022-09-27 21:11:43 - train.py[line:549] - INFO: 2040 / 2354
2022-09-27 21:11:43 - train.py[line:551] - INFO: load:7.88 valid_run:22748.52 task_valid:21544.43 collect_output:1191.41
2022-09-27 21:15:23 - train.py[line:549] - INFO: 2060 / 2354
2022-09-27 21:15:23 - train.py[line:551] - INFO: load:7.89 valid_run:22968.20 task_valid:21759.30 collect_output:1196.09
2022-09-27 21:19:01 - train.py[line:549] - INFO: 2080 / 2354
2022-09-27 21:19:01 - train.py[line:551] - INFO: load:7.90 valid_run:23186.21 task_valid:21974.12 collect_output:1199.17
2022-09-27 21:22:41 - train.py[line:549] - INFO: 2100 / 2354
2022-09-27 21:22:41 - train.py[line:551] - INFO: load:7.91 valid_run:23406.25 task_valid:22191.86 collect_output:1201.34
2022-09-27 21:26:18 - train.py[line:549] - INFO: 2120 / 2354
2022-09-27 21:26:18 - train.py[line:551] - INFO: load:7.92 valid_run:23622.53 task_valid:22391.67 collect_output:1217.69
2022-09-27 21:29:44 - train.py[line:549] - INFO: 2140 / 2354
2022-09-27 21:29:44 - train.py[line:551] - INFO: load:7.93 valid_run:23828.86 task_valid:22594.96 collect_output:1220.61
2022-09-27 21:33:26 - train.py[line:549] - INFO: 2160 / 2354
2022-09-27 21:33:26 - train.py[line:551] - INFO: load:7.94 valid_run:24050.76 task_valid:22810.87 collect_output:1226.49
2022-09-27 21:37:57 - train.py[line:549] - INFO: 2180 / 2354
2022-09-27 21:37:57 - train.py[line:551] - INFO: load:7.95 valid_run:24322.06 task_valid:23081.94 collect_output:1226.58
2022-09-27 21:41:34 - train.py[line:549] - INFO: 2200 / 2354
2022-09-27 21:41:34 - train.py[line:551] - INFO: load:7.96 valid_run:24538.51 task_valid:23283.74 collect_output:1241.11
2022-09-27 21:45:09 - train.py[line:549] - INFO: 2220 / 2354
2022-09-27 21:45:09 - train.py[line:551] - INFO: load:7.97 valid_run:24753.91 task_valid:23496.52 collect_output:1243.60
