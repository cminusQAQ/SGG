2023-02-20 13:12:47 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2023-02-20 13:12:47 - utils.py[line:261] - INFO: Start init
2023-02-20 13:12:47 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-02-20 13:12:47 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2023-02-20 13:12:47 - utils.py[line:261] - INFO: Start init
Retry: 1, with value error <class 'RuntimeError'>
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--distill', 'default', '--distill-alpha=1.0', '--batch-size=20', '--batch-size-valid=12', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=5e-5', '--max-epoch=2', '--warmup-ratio=0.027', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=2000', '--validate-interval-updates=2000', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', '--valid-batch-size=51', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=allcand', '--num-workers=8']' returned non-zero exit status 255.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 3567968
Killing subprocess 3567969
2023-02-20 13:15:23 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2023-02-20 13:15:23 - utils.py[line:261] - INFO: Start init
2023-02-20 13:15:23 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2023-02-20 13:15:23 - utils.py[line:261] - INFO: Start init
2023-02-20 13:15:24 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-02-20 13:15:24 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-02-20 13:15:24 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2023-02-20 13:15:24 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2023-02-20 13:15:28 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 2000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 12, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 2, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 2000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='12', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=2, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480', save_interval=10, save_interval_updates=2000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=2000, wandb_project=None, warmup_ratio=0.027, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.027, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-02-20 13:15:28 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-02-20 13:15:28 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2023-02-20 13:15:33 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-02-20 13:15:33 - train.py[line:118] - INFO: task: VqaGenTask
2023-02-20 13:15:33 - train.py[line:119] - INFO: model: OFAModel
2023-02-20 13:15:33 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-02-20 13:15:33 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-02-20 13:15:33 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2023-02-20 13:15:33 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-02-20 13:15:33 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-02-20 13:15:34 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-02-20 13:15:34 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-02-20 13:15:34 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-02-20 13:15:34 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
Done 0.95 cuda cpu, cpu
2023-02-20 13:15:35 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2023-02-20 13:15:35 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2023-02-20 13:15:35 - trainer.py[line:499] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
Done 0.95 cuda cpu, cpu
2023-02-20 13:15:43 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-02-20 13:15:44 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-02-20 13:15:44 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-02-20 13:15:44 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-02-20 13:15:44 - trainer.py[line:314] - INFO: Exponential Moving Average Shadow Model is initialized.
2023-02-20 13:15:44 - trainer.py[line:674] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2023-02-20 13:15:45 - trainer.py[line:694] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E0.tsv slice_id 1 row count 1420222 total row count 2840444
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_train_NA1_E0.tsv slice_id 0 row count 1420222 total row count 2840444
2023-02-20 13:15:50 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 142024, warmup steps 3834, warmup_factor 0.0002608242044861763
Total steps 142024, warmup steps 3834, warmup_factor 0.0002608242044861763
2023-02-20 13:15:50 - trainer.py[line:758] - INFO: begin training epoch 1
2023-02-20 13:15:50 - train.py[line:312] - INFO: Start iterating over samples
2023-02-20 13:16:06 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 71012 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.4, ups=0.88, wpb=112.4, bsz=40, num_updates=10, lr=1.30412e-07, gnorm=7.135, clip=100, loss_scale=128, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=32
2023-02-20 13:16:18 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 71012 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.9, ups=0.87, wpb=112.1, bsz=40, num_updates=20, lr=2.60824e-07, gnorm=6.947, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44
2023-02-20 13:16:29 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 71012 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98, ups=0.89, wpb=110.5, bsz=40, num_updates=30, lr=3.91236e-07, gnorm=5.666, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=55
2023-02-20 13:16:40 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 71012 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.6, ups=0.89, wpb=110.8, bsz=40, num_updates=40, lr=5.21648e-07, gnorm=6.245, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67
2023-02-20 13:16:52 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 71012 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.3, ups=0.88, wpb=111.2, bsz=40, num_updates=50, lr=6.52061e-07, gnorm=4.997, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78
2023-02-20 13:17:03 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 71012 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=113.7, nsentences=40, sample_size=113.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=101.5, ups=0.89, wpb=113.7, bsz=40, num_updates=60, lr=7.82473e-07, gnorm=3.611, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89
2023-02-20 13:17:14 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 71012 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101, ups=0.91, wpb=111.4, bsz=40, num_updates=70, lr=9.12885e-07, gnorm=2.346, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=100
2023-02-20 13:17:25 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 71012 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.093, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=99, ups=0.89, wpb=111.6, bsz=40, num_updates=80, lr=1.0433e-06, gnorm=2.622, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=112
2023-02-20 13:17:36 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 71012 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.092, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=103.1, ups=0.92, wpb=111.8, bsz=40, num_updates=90, lr=1.17371e-06, gnorm=2.216, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122
2023-02-20 13:17:47 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 71012 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.088, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=102.2, ups=0.92, wpb=111.2, bsz=40, num_updates=100, lr=1.30412e-06, gnorm=2.21, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=133
2023-02-20 13:17:58 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 71012 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=100.1, ups=0.89, wpb=112.1, bsz=40, num_updates=110, lr=1.43453e-06, gnorm=2.37, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=145
2023-02-20 13:18:09 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 71012 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=120, lr=1.56495e-06, gnorm=1.408, clip=70, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=156
2023-02-20 13:18:20 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 71012 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.086, ntokens=113.4, nsentences=40, sample_size=113.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=101.4, ups=0.89, wpb=113.4, bsz=40, num_updates=130, lr=1.69536e-06, gnorm=1.536, clip=90, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167
2023-02-20 13:18:31 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 71012 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=102.5, ups=0.92, wpb=111.7, bsz=40, num_updates=140, lr=1.82577e-06, gnorm=1.376, clip=90, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=178
2023-02-20 13:18:43 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 71012 loss=0.209, loss_v1=0, loss_v2=0, nll_loss=0.09, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=150, lr=1.95618e-06, gnorm=1.193, clip=80, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=189
2023-02-20 13:18:54 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 71012 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.089, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=98.7, ups=0.9, wpb=110.1, bsz=40, num_updates=160, lr=2.08659e-06, gnorm=1.008, clip=50, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=200
2023-02-20 13:19:05 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 71012 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=99.1, ups=0.9, wpb=110.5, bsz=40, num_updates=170, lr=2.21701e-06, gnorm=0.954, clip=40, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=211
2023-02-20 13:19:16 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 71012 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=100.5, ups=0.91, wpb=110.2, bsz=40, num_updates=180, lr=2.34742e-06, gnorm=0.968, clip=30, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=222
2023-02-20 13:19:27 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 71012 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=97.9, ups=0.88, wpb=111.5, bsz=40, num_updates=190, lr=2.47783e-06, gnorm=0.808, clip=20, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=234
2023-02-20 13:19:38 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 71012 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.094, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=106.2, ups=0.95, wpb=112.2, bsz=40, num_updates=200, lr=2.60824e-06, gnorm=0.951, clip=40, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=244
2023-02-20 13:19:49 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 71012 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.088, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=100.8, ups=0.91, wpb=111, bsz=40, num_updates=210, lr=2.73865e-06, gnorm=0.798, clip=20, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=255
2023-02-20 13:20:00 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 71012 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.085, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=101.4, ups=0.91, wpb=111.8, bsz=40, num_updates=220, lr=2.86907e-06, gnorm=0.77, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=266
2023-02-20 13:20:11 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 71012 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=230, lr=2.99948e-06, gnorm=0.644, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=278
2023-02-20 13:20:22 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 71012 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=103.9, ups=0.92, wpb=113.1, bsz=40, num_updates=240, lr=3.12989e-06, gnorm=0.709, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=288
2023-02-20 13:20:34 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 71012 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.3, ups=0.87, wpb=112.7, bsz=40, num_updates=250, lr=3.2603e-06, gnorm=0.599, clip=10, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=300
2023-02-20 13:20:45 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 71012 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=100.5, ups=0.9, wpb=112.2, bsz=40, num_updates=260, lr=3.39071e-06, gnorm=0.622, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=311
2023-02-20 13:20:56 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 71012 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.084, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=100.6, ups=0.9, wpb=111.2, bsz=40, num_updates=270, lr=3.52113e-06, gnorm=0.605, clip=10, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=322
2023-02-20 13:21:07 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 71012 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=280, lr=3.65154e-06, gnorm=0.555, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=333
2023-02-20 13:21:18 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 71012 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.9, wpb=112.7, bsz=40, num_updates=290, lr=3.78195e-06, gnorm=0.452, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=345
2023-02-20 13:21:29 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 71012 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=100.7, ups=0.9, wpb=112, bsz=40, num_updates=300, lr=3.91236e-06, gnorm=0.597, clip=10, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=356
2023-02-20 13:21:40 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 71012 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=310, lr=4.04278e-06, gnorm=0.561, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=367
2023-02-20 13:21:52 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 71012 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.9, ups=0.89, wpb=112.1, bsz=40, num_updates=320, lr=4.17319e-06, gnorm=0.444, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=378
2023-02-20 13:22:03 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 71012 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=101.8, ups=0.92, wpb=110.8, bsz=40, num_updates=330, lr=4.3036e-06, gnorm=0.627, clip=10, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=389
2023-02-20 13:22:14 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 71012 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.1, ups=0.87, wpb=111.2, bsz=40, num_updates=340, lr=4.43401e-06, gnorm=0.442, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=400
2023-02-20 13:22:25 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 71012 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=350, lr=4.56442e-06, gnorm=0.455, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=411
2023-02-20 13:22:36 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 71012 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.9, ups=0.9, wpb=110.9, bsz=40, num_updates=360, lr=4.69484e-06, gnorm=0.447, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=423
2023-02-20 13:22:47 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 71012 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.09, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=99.1, ups=0.9, wpb=110.7, bsz=40, num_updates=370, lr=4.82525e-06, gnorm=0.576, clip=10, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=434
2023-02-20 13:22:59 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 71012 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.4, ups=0.89, wpb=112.2, bsz=40, num_updates=380, lr=4.95566e-06, gnorm=0.534, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=445
2023-02-20 13:23:10 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 71012 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=390, lr=5.08607e-06, gnorm=0.514, clip=10, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=456
2023-02-20 13:23:21 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 71012 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=100.2, ups=0.89, wpb=112.1, bsz=40, num_updates=400, lr=5.21648e-06, gnorm=0.582, clip=10, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=467
2023-02-20 13:23:32 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 71012 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.1, ups=0.87, wpb=111, bsz=40, num_updates=410, lr=5.3469e-06, gnorm=0.509, clip=10, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=479
2023-02-20 13:23:44 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 71012 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=420, lr=5.47731e-06, gnorm=0.57, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=490
2023-02-20 13:23:55 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 71012 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.7, ups=0.89, wpb=112.6, bsz=40, num_updates=430, lr=5.60772e-06, gnorm=0.499, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=501
2023-02-20 13:24:06 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 71012 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.7, ups=0.9, wpb=111.1, bsz=40, num_updates=440, lr=5.73813e-06, gnorm=0.52, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=512
2023-02-20 13:24:17 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 71012 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=98.2, ups=0.88, wpb=111, bsz=40, num_updates=450, lr=5.86854e-06, gnorm=0.549, clip=10, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=524
2023-02-20 13:24:29 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 71012 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97, ups=0.87, wpb=111.2, bsz=40, num_updates=460, lr=5.99896e-06, gnorm=0.462, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=535
2023-02-20 13:24:40 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 71012 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.1, ups=0.89, wpb=111.9, bsz=40, num_updates=470, lr=6.12937e-06, gnorm=0.509, clip=10, loss_scale=128, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=546
2023-02-20 13:24:51 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 71012 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=103, ups=0.92, wpb=112.5, bsz=40, num_updates=480, lr=6.25978e-06, gnorm=0.552, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=557
2023-02-20 13:25:02 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 71012 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.4, ups=0.88, wpb=110.6, bsz=40, num_updates=490, lr=6.39019e-06, gnorm=0.661, clip=10, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=569
2023-02-20 13:25:14 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 71012 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.4, ups=0.88, wpb=112.4, bsz=40, num_updates=500, lr=6.52061e-06, gnorm=0.514, clip=10, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=580
2023-02-20 13:25:25 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 71012 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.88, wpb=112.2, bsz=40, num_updates=510, lr=6.65102e-06, gnorm=0.47, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=591
2023-02-20 13:25:36 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 71012 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.4, ups=0.88, wpb=111.3, bsz=40, num_updates=520, lr=6.78143e-06, gnorm=0.515, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=603
2023-02-20 13:25:48 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 71012 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.7, ups=0.88, wpb=111.6, bsz=40, num_updates=530, lr=6.91184e-06, gnorm=0.438, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=614
2023-02-20 13:25:58 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 71012 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=104.9, ups=0.93, wpb=112.7, bsz=40, num_updates=540, lr=7.04225e-06, gnorm=0.481, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=625
2023-02-20 13:26:10 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 71012 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101.3, ups=0.9, wpb=112.1, bsz=40, num_updates=550, lr=7.17267e-06, gnorm=0.521, clip=10, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=636
2023-02-20 13:26:22 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 71012 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.2, ups=0.89, wpb=112.4, bsz=40, num_updates=560, lr=7.30308e-06, gnorm=0.534, clip=0, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=648
2023-02-20 13:26:33 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.6, ups=0.91, wpb=110.8, bsz=40, num_updates=570, lr=7.43349e-06, gnorm=0.538, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=659
2023-02-20 13:26:44 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=580, lr=7.5639e-06, gnorm=0.477, clip=10, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=670
2023-02-20 13:26:55 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 71012 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101.4, ups=0.91, wpb=111.7, bsz=40, num_updates=590, lr=7.69431e-06, gnorm=0.591, clip=10, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=681
2023-02-20 13:27:06 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.9, ups=0.92, wpb=111.8, bsz=40, num_updates=600, lr=7.82473e-06, gnorm=0.494, clip=10, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=692
2023-02-20 13:27:17 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=96.2, ups=0.87, wpb=110.3, bsz=40, num_updates=610, lr=7.95514e-06, gnorm=0.481, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=704
2023-02-20 13:27:28 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 71012 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=620, lr=8.08555e-06, gnorm=0.533, clip=10, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=715
2023-02-20 13:27:39 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 71012 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=630, lr=8.21596e-06, gnorm=0.566, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=726
2023-02-20 13:27:50 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.3, ups=0.93, wpb=110.7, bsz=40, num_updates=640, lr=8.34637e-06, gnorm=0.469, clip=0, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=737
2023-02-20 13:28:01 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 71012 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.88, wpb=112.5, bsz=40, num_updates=650, lr=8.47679e-06, gnorm=0.469, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=748
2023-02-20 13:28:13 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.91, wpb=111.2, bsz=40, num_updates=660, lr=8.6072e-06, gnorm=0.507, clip=0, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=759
2023-02-20 13:28:24 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.6, ups=0.91, wpb=111.8, bsz=40, num_updates=670, lr=8.73761e-06, gnorm=0.54, clip=20, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=770
2023-02-20 13:28:35 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.89, wpb=111.3, bsz=40, num_updates=680, lr=8.86802e-06, gnorm=0.494, clip=10, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=781
2023-02-20 13:28:46 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 71012 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.6, ups=0.88, wpb=112.7, bsz=40, num_updates=690, lr=8.99844e-06, gnorm=0.555, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=793
2023-02-20 13:28:58 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 71012 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.87, wpb=112.4, bsz=40, num_updates=700, lr=9.12885e-06, gnorm=0.513, clip=0, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=804
2023-02-20 13:29:09 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=710, lr=9.25926e-06, gnorm=0.526, clip=10, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=815
2023-02-20 13:29:20 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 71012 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=113.8, nsentences=40, sample_size=113.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.5, ups=0.91, wpb=113.8, bsz=40, num_updates=720, lr=9.38967e-06, gnorm=0.575, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=826
2023-02-20 13:29:31 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.87, wpb=112.2, bsz=40, num_updates=730, lr=9.52008e-06, gnorm=0.423, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=838
2023-02-20 13:29:42 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.2, ups=0.92, wpb=112.1, bsz=40, num_updates=740, lr=9.6505e-06, gnorm=0.64, clip=20, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=849
2023-02-20 13:29:53 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.7, ups=0.9, wpb=109.9, bsz=40, num_updates=750, lr=9.78091e-06, gnorm=0.471, clip=10, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=860
2023-02-20 13:30:05 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 71012 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.4, ups=0.88, wpb=111.3, bsz=40, num_updates=760, lr=9.91132e-06, gnorm=0.709, clip=10, loss_scale=256, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=871
2023-02-20 13:30:16 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 71012 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.89, wpb=111.3, bsz=40, num_updates=770, lr=1.00417e-05, gnorm=0.621, clip=20, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=883
2023-02-20 13:30:27 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.8, ups=0.93, wpb=111.2, bsz=40, num_updates=780, lr=1.01721e-05, gnorm=0.652, clip=10, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=893
2023-02-20 13:30:38 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.9, ups=0.93, wpb=112.4, bsz=40, num_updates=790, lr=1.03026e-05, gnorm=0.48, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=904
2023-02-20 13:30:49 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.8, ups=0.88, wpb=110.5, bsz=40, num_updates=800, lr=1.0433e-05, gnorm=0.516, clip=10, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=915
2023-02-20 13:31:00 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.4, bsz=40, num_updates=810, lr=1.05634e-05, gnorm=0.548, clip=10, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=926
2023-02-20 13:31:11 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 71012 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=820, lr=1.06938e-05, gnorm=0.413, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=938
2023-02-20 13:31:22 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.9, wpb=110.2, bsz=40, num_updates=830, lr=1.08242e-05, gnorm=0.548, clip=10, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=949
2023-02-20 13:31:34 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.2, bsz=40, num_updates=840, lr=1.09546e-05, gnorm=0.446, clip=0, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=960
2023-02-20 13:31:45 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=850, lr=1.1085e-05, gnorm=0.541, clip=20, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=971
2023-02-20 13:31:55 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.6, ups=0.93, wpb=110.4, bsz=40, num_updates=860, lr=1.12154e-05, gnorm=0.431, clip=0, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=982
2023-02-20 13:32:06 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 71012 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.9, ups=0.93, wpb=111.5, bsz=40, num_updates=870, lr=1.13459e-05, gnorm=0.641, clip=30, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=993
2023-02-20 13:32:17 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.3, bsz=40, num_updates=880, lr=1.14763e-05, gnorm=0.499, clip=10, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1004
2023-02-20 13:32:29 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.6, ups=0.9, wpb=110, bsz=40, num_updates=890, lr=1.16067e-05, gnorm=0.482, clip=0, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1015
2023-02-20 13:32:39 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=105.4, ups=0.94, wpb=111.9, bsz=40, num_updates=900, lr=1.17371e-05, gnorm=0.591, clip=10, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1026
2023-02-20 13:32:51 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.88, wpb=112.3, bsz=40, num_updates=910, lr=1.18675e-05, gnorm=0.402, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1037
2023-02-20 13:33:01 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.3, ups=0.92, wpb=111.5, bsz=40, num_updates=920, lr=1.19979e-05, gnorm=0.539, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1048
2023-02-20 13:33:12 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.2, ups=0.92, wpb=112.2, bsz=40, num_updates=930, lr=1.21283e-05, gnorm=0.446, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1059
2023-02-20 13:33:23 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 71012 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=102.4, ups=0.92, wpb=111.3, bsz=40, num_updates=940, lr=1.22587e-05, gnorm=0.499, clip=0, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=1070
2023-02-20 13:33:34 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.9, wpb=113.2, bsz=40, num_updates=950, lr=1.23891e-05, gnorm=0.419, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1081
2023-02-20 13:33:45 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.1, bsz=40, num_updates=960, lr=1.25196e-05, gnorm=0.391, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1092
2023-02-20 13:33:57 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.9, wpb=110.4, bsz=40, num_updates=970, lr=1.265e-05, gnorm=0.574, clip=10, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1103
2023-02-20 13:34:08 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.91, wpb=110.6, bsz=40, num_updates=980, lr=1.27804e-05, gnorm=0.591, clip=20, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1114
2023-02-20 13:34:19 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.9, wpb=111.4, bsz=40, num_updates=990, lr=1.29108e-05, gnorm=0.55, clip=10, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1125
2023-02-20 13:34:30 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.4, ups=0.91, wpb=110.6, bsz=40, num_updates=1000, lr=1.30412e-05, gnorm=0.688, clip=20, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1136
2023-02-20 13:34:41 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=1010, lr=1.31716e-05, gnorm=0.43, clip=10, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1147
2023-02-20 13:34:52 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.3, ups=0.91, wpb=112.6, bsz=40, num_updates=1020, lr=1.3302e-05, gnorm=0.516, clip=20, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1158
2023-02-20 13:35:03 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=1030, lr=1.34324e-05, gnorm=0.544, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1170
2023-02-20 13:35:14 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 71012 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.88, wpb=112.9, bsz=40, num_updates=1040, lr=1.35629e-05, gnorm=0.689, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1181
2023-02-20 13:35:26 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.3, bsz=40, num_updates=1050, lr=1.36933e-05, gnorm=0.414, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1192
2023-02-20 13:35:36 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.1, ups=0.93, wpb=111.4, bsz=40, num_updates=1060, lr=1.38237e-05, gnorm=0.526, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1203
2023-02-20 13:35:47 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=1070, lr=1.39541e-05, gnorm=0.506, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1214
2023-02-20 13:35:59 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.9, bsz=40, num_updates=1080, lr=1.40845e-05, gnorm=0.42, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1225
2023-02-20 13:36:10 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=111.2, bsz=40, num_updates=1090, lr=1.42149e-05, gnorm=0.353, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1236
2023-02-20 13:36:21 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.9, wpb=109.9, bsz=40, num_updates=1100, lr=1.43453e-05, gnorm=0.457, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1247
2023-02-20 13:36:32 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.3, bsz=40, num_updates=1110, lr=1.44757e-05, gnorm=0.437, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1258
2023-02-20 13:36:44 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.3, ups=0.86, wpb=111.6, bsz=40, num_updates=1120, lr=1.46062e-05, gnorm=0.444, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1270
2023-02-20 13:36:55 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.6, ups=0.91, wpb=111.7, bsz=40, num_updates=1130, lr=1.47366e-05, gnorm=0.368, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1281
2023-02-20 13:37:06 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=1140, lr=1.4867e-05, gnorm=0.465, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1292
2023-02-20 13:37:17 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=112.2, bsz=40, num_updates=1150, lr=1.49974e-05, gnorm=0.514, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1304
2023-02-20 13:37:28 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.9, wpb=111.2, bsz=40, num_updates=1160, lr=1.51278e-05, gnorm=0.353, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1315
2023-02-20 13:37:40 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.89, wpb=111.4, bsz=40, num_updates=1170, lr=1.52582e-05, gnorm=0.527, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1326
2023-02-20 13:37:51 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112.3, bsz=40, num_updates=1180, lr=1.53886e-05, gnorm=0.461, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1337
2023-02-20 13:38:02 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.7, ups=0.92, wpb=111.6, bsz=40, num_updates=1190, lr=1.5519e-05, gnorm=0.361, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=1348
2023-02-20 13:38:13 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 71012 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101.7, ups=0.91, wpb=112.1, bsz=40, num_updates=1200, lr=1.56495e-05, gnorm=0.537, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1359
2023-02-20 13:38:24 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.4, bsz=40, num_updates=1210, lr=1.57799e-05, gnorm=0.365, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1370
2023-02-20 13:38:35 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.9, wpb=110.8, bsz=40, num_updates=1220, lr=1.59103e-05, gnorm=0.485, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1381
2023-02-20 13:38:46 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.9, ups=0.92, wpb=112.1, bsz=40, num_updates=1230, lr=1.60407e-05, gnorm=0.38, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1392
2023-02-20 13:38:57 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=1240, lr=1.61711e-05, gnorm=0.354, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1403
2023-02-20 13:39:08 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.7, bsz=40, num_updates=1250, lr=1.63015e-05, gnorm=0.327, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1415
2023-02-20 13:39:19 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.8, bsz=40, num_updates=1260, lr=1.64319e-05, gnorm=0.206, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1426
2023-02-20 13:39:31 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.7, ups=0.88, wpb=109.3, bsz=40, num_updates=1270, lr=1.65623e-05, gnorm=0.357, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1437
2023-02-20 13:39:42 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.2, ups=0.91, wpb=112.1, bsz=40, num_updates=1280, lr=1.66927e-05, gnorm=0.364, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1448
2023-02-20 13:39:53 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.88, wpb=113.1, bsz=40, num_updates=1290, lr=1.68232e-05, gnorm=0.268, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=1459
2023-02-20 13:40:04 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.88, wpb=111.1, bsz=40, num_updates=1300, lr=1.69536e-05, gnorm=0.413, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1471
2023-02-20 13:40:16 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.88, wpb=111.2, bsz=40, num_updates=1310, lr=1.7084e-05, gnorm=0.602, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1482
2023-02-20 13:40:26 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.92, wpb=111.7, bsz=40, num_updates=1320, lr=1.72144e-05, gnorm=0.263, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1493
2023-02-20 13:40:38 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.88, wpb=111.4, bsz=40, num_updates=1330, lr=1.73448e-05, gnorm=0.439, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1504
2023-02-20 13:40:49 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=1340, lr=1.74752e-05, gnorm=0.362, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1515
2023-02-20 13:41:00 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=110.7, bsz=40, num_updates=1350, lr=1.76056e-05, gnorm=0.546, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1526
2023-02-20 13:41:11 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 71012 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=102.4, ups=0.91, wpb=112.6, bsz=40, num_updates=1360, lr=1.7736e-05, gnorm=0.466, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1537
2023-02-20 13:41:22 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.9, wpb=110.7, bsz=40, num_updates=1370, lr=1.78665e-05, gnorm=0.346, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=1548
2023-02-20 13:41:34 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.1, ups=0.87, wpb=111.3, bsz=40, num_updates=1380, lr=1.79969e-05, gnorm=0.306, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1560
2023-02-20 13:41:45 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=111.3, bsz=40, num_updates=1390, lr=1.81273e-05, gnorm=0.238, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=1571
2023-02-20 13:41:56 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.9, wpb=111.9, bsz=40, num_updates=1400, lr=1.82577e-05, gnorm=0.433, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1583
2023-02-20 13:42:07 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=1410, lr=1.83881e-05, gnorm=0.345, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1594
2023-02-20 13:42:19 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=1420, lr=1.85185e-05, gnorm=0.509, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1605
2023-02-20 13:42:30 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.89, wpb=109.9, bsz=40, num_updates=1430, lr=1.86489e-05, gnorm=0.307, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1616
2023-02-20 13:42:41 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.93, wpb=110, bsz=40, num_updates=1440, lr=1.87793e-05, gnorm=0.352, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1627
2023-02-20 13:42:51 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=105.6, ups=0.95, wpb=111.7, bsz=40, num_updates=1450, lr=1.89098e-05, gnorm=0.246, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1638
2023-02-20 13:43:02 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=106.6, ups=0.95, wpb=112.2, bsz=40, num_updates=1460, lr=1.90402e-05, gnorm=0.286, clip=0, loss_scale=512, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=1648
2023-02-20 13:43:13 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.9, bsz=40, num_updates=1470, lr=1.91706e-05, gnorm=0.371, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1659
2023-02-20 13:43:25 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.9, ups=0.87, wpb=111, bsz=40, num_updates=1480, lr=1.9301e-05, gnorm=0.306, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1671
2023-02-20 13:43:36 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.87, wpb=112.1, bsz=40, num_updates=1490, lr=1.94314e-05, gnorm=0.336, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1682
2023-02-20 13:43:49 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=112, bsz=40, num_updates=1500, lr=1.95618e-05, gnorm=0.373, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1693
2023-02-20 13:44:01 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.87, wpb=112.3, bsz=40, num_updates=1510, lr=1.96922e-05, gnorm=0.346, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1707
2023-02-20 13:44:12 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 71012 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=1520, lr=1.98226e-05, gnorm=0.432, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1719
2023-02-20 13:44:23 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=110.5, bsz=40, num_updates=1530, lr=1.99531e-05, gnorm=0.343, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1730
2023-02-20 13:44:34 - progress_bar.py[line:274] - INFO: epoch 001:   1540 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102, ups=0.91, wpb=112.4, bsz=40, num_updates=1540, lr=2.00835e-05, gnorm=0.383, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1741
2023-02-20 13:44:45 - progress_bar.py[line:274] - INFO: epoch 001:   1550 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.9, ups=0.94, wpb=112, bsz=40, num_updates=1550, lr=2.02139e-05, gnorm=0.351, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1752
2023-02-20 13:44:56 - progress_bar.py[line:274] - INFO: epoch 001:   1560 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.9, wpb=110.3, bsz=40, num_updates=1560, lr=2.03443e-05, gnorm=0.433, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1763
2023-02-20 13:45:07 - progress_bar.py[line:274] - INFO: epoch 001:   1570 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.6, bsz=40, num_updates=1570, lr=2.04747e-05, gnorm=0.285, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1774
2023-02-20 13:45:19 - progress_bar.py[line:274] - INFO: epoch 001:   1580 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.87, wpb=112.3, bsz=40, num_updates=1580, lr=2.06051e-05, gnorm=0.44, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1785
2023-02-20 13:45:30 - progress_bar.py[line:274] - INFO: epoch 001:   1590 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.2, bsz=40, num_updates=1590, lr=2.07355e-05, gnorm=0.395, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1796
2023-02-20 13:45:41 - progress_bar.py[line:274] - INFO: epoch 001:   1600 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.3, ups=0.91, wpb=112.6, bsz=40, num_updates=1600, lr=2.08659e-05, gnorm=0.378, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1807
2023-02-20 13:45:52 - progress_bar.py[line:274] - INFO: epoch 001:   1610 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.5, ups=0.92, wpb=112.6, bsz=40, num_updates=1610, lr=2.09963e-05, gnorm=0.368, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1818
2023-02-20 13:46:03 - progress_bar.py[line:274] - INFO: epoch 001:   1620 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.9, bsz=40, num_updates=1620, lr=2.11268e-05, gnorm=0.334, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1829
2023-02-20 13:46:14 - progress_bar.py[line:274] - INFO: epoch 001:   1630 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=1630, lr=2.12572e-05, gnorm=0.327, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1840
2023-02-20 13:46:25 - progress_bar.py[line:274] - INFO: epoch 001:   1640 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.88, wpb=110.7, bsz=40, num_updates=1640, lr=2.13876e-05, gnorm=0.311, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1851
2023-02-20 13:46:36 - progress_bar.py[line:274] - INFO: epoch 001:   1650 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.91, wpb=111.8, bsz=40, num_updates=1650, lr=2.1518e-05, gnorm=0.323, clip=0, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=1862
2023-02-20 13:46:48 - progress_bar.py[line:274] - INFO: epoch 001:   1660 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.6, bsz=40, num_updates=1660, lr=2.16484e-05, gnorm=0.313, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1874
2023-02-20 13:46:58 - progress_bar.py[line:274] - INFO: epoch 001:   1670 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.1, ups=0.92, wpb=110.1, bsz=40, num_updates=1670, lr=2.17788e-05, gnorm=0.416, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=1885
2023-02-20 13:47:10 - progress_bar.py[line:274] - INFO: epoch 001:   1680 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.9, wpb=111.5, bsz=40, num_updates=1680, lr=2.19092e-05, gnorm=0.513, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=1896
2023-02-20 13:47:21 - progress_bar.py[line:274] - INFO: epoch 001:   1690 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=1690, lr=2.20396e-05, gnorm=0.359, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1907
2023-02-20 13:47:32 - progress_bar.py[line:274] - INFO: epoch 001:   1700 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.92, wpb=109.8, bsz=40, num_updates=1700, lr=2.21701e-05, gnorm=0.338, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1918
2023-02-20 13:47:43 - progress_bar.py[line:274] - INFO: epoch 001:   1710 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=1710, lr=2.23005e-05, gnorm=0.243, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1929
2023-02-20 13:47:54 - progress_bar.py[line:274] - INFO: epoch 001:   1720 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.9, wpb=112, bsz=40, num_updates=1720, lr=2.24309e-05, gnorm=0.319, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1940
2023-02-20 13:48:05 - progress_bar.py[line:274] - INFO: epoch 001:   1730 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.89, wpb=112, bsz=40, num_updates=1730, lr=2.25613e-05, gnorm=0.398, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1952
2023-02-20 13:48:16 - progress_bar.py[line:274] - INFO: epoch 001:   1740 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111, bsz=40, num_updates=1740, lr=2.26917e-05, gnorm=0.276, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1963
2023-02-20 13:48:28 - progress_bar.py[line:274] - INFO: epoch 001:   1750 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.88, wpb=110.7, bsz=40, num_updates=1750, lr=2.28221e-05, gnorm=0.404, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1974
2023-02-20 13:48:39 - progress_bar.py[line:274] - INFO: epoch 001:   1760 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=1760, lr=2.29525e-05, gnorm=0.371, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1985
2023-02-20 13:48:50 - progress_bar.py[line:274] - INFO: epoch 001:   1770 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.7, ups=0.89, wpb=111.3, bsz=40, num_updates=1770, lr=2.30829e-05, gnorm=0.52, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1996
2023-02-20 13:49:02 - progress_bar.py[line:274] - INFO: epoch 001:   1780 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.1, ups=0.88, wpb=111, bsz=40, num_updates=1780, lr=2.32134e-05, gnorm=0.343, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2008
2023-02-20 13:49:13 - progress_bar.py[line:274] - INFO: epoch 001:   1790 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=1790, lr=2.33438e-05, gnorm=0.244, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2019
2023-02-20 13:49:24 - progress_bar.py[line:274] - INFO: epoch 001:   1800 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.9, ups=0.87, wpb=111.1, bsz=40, num_updates=1800, lr=2.34742e-05, gnorm=0.266, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2031
2023-02-20 13:49:35 - progress_bar.py[line:274] - INFO: epoch 001:   1810 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.9, wpb=111.2, bsz=40, num_updates=1810, lr=2.36046e-05, gnorm=0.342, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2042
2023-02-20 13:49:46 - progress_bar.py[line:274] - INFO: epoch 001:   1820 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.9, ups=0.93, wpb=111.3, bsz=40, num_updates=1820, lr=2.3735e-05, gnorm=0.303, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2052
2023-02-20 13:49:57 - progress_bar.py[line:274] - INFO: epoch 001:   1830 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111, bsz=40, num_updates=1830, lr=2.38654e-05, gnorm=0.345, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2063
2023-02-20 13:50:08 - progress_bar.py[line:274] - INFO: epoch 001:   1840 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.93, wpb=111, bsz=40, num_updates=1840, lr=2.39958e-05, gnorm=0.353, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=2074
2023-02-20 13:50:19 - progress_bar.py[line:274] - INFO: epoch 001:   1850 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=110.9, bsz=40, num_updates=1850, lr=2.41262e-05, gnorm=0.247, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2085
2023-02-20 13:50:30 - progress_bar.py[line:274] - INFO: epoch 001:   1860 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.4, bsz=40, num_updates=1860, lr=2.42567e-05, gnorm=0.367, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2097
2023-02-20 13:50:42 - progress_bar.py[line:274] - INFO: epoch 001:   1870 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.89, wpb=111.4, bsz=40, num_updates=1870, lr=2.43871e-05, gnorm=0.37, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2108
2023-02-20 13:50:53 - progress_bar.py[line:274] - INFO: epoch 001:   1880 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=112, bsz=40, num_updates=1880, lr=2.45175e-05, gnorm=0.479, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2119
2023-02-20 13:51:04 - progress_bar.py[line:274] - INFO: epoch 001:   1890 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=1890, lr=2.46479e-05, gnorm=0.291, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2131
2023-02-20 13:51:15 - progress_bar.py[line:274] - INFO: epoch 001:   1900 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.9, wpb=110.6, bsz=40, num_updates=1900, lr=2.47783e-05, gnorm=0.358, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2142
2023-02-20 13:51:27 - progress_bar.py[line:274] - INFO: epoch 001:   1910 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=111.8, bsz=40, num_updates=1910, lr=2.49087e-05, gnorm=0.255, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2153
2023-02-20 13:51:38 - progress_bar.py[line:274] - INFO: epoch 001:   1920 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.89, wpb=111.4, bsz=40, num_updates=1920, lr=2.50391e-05, gnorm=0.313, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2164
2023-02-20 13:51:49 - progress_bar.py[line:274] - INFO: epoch 001:   1930 / 71012 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=105.5, ups=0.93, wpb=113.1, bsz=40, num_updates=1930, lr=2.51695e-05, gnorm=0.384, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2175
2023-02-20 13:52:00 - progress_bar.py[line:274] - INFO: epoch 001:   1940 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.3, bsz=40, num_updates=1940, lr=2.52999e-05, gnorm=0.351, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2186
2023-02-20 13:52:11 - progress_bar.py[line:274] - INFO: epoch 001:   1950 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.1, ups=0.87, wpb=111.8, bsz=40, num_updates=1950, lr=2.54304e-05, gnorm=0.309, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2198
2023-02-20 13:52:23 - progress_bar.py[line:274] - INFO: epoch 001:   1960 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=112.1, bsz=40, num_updates=1960, lr=2.55608e-05, gnorm=0.244, clip=0, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2209
2023-02-20 13:52:34 - progress_bar.py[line:274] - INFO: epoch 001:   1970 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.5, bsz=40, num_updates=1970, lr=2.56912e-05, gnorm=0.235, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2220
2023-02-20 13:52:45 - progress_bar.py[line:274] - INFO: epoch 001:   1980 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.2, bsz=40, num_updates=1980, lr=2.58216e-05, gnorm=0.407, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2231
2023-02-20 13:52:56 - progress_bar.py[line:274] - INFO: epoch 001:   1990 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=1990, lr=2.5952e-05, gnorm=0.28, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2242
2023-02-20 13:53:07 - progress_bar.py[line:274] - INFO: epoch 001:   2000 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.89, wpb=112.5, bsz=40, num_updates=2000, lr=2.60824e-05, gnorm=0.366, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2254
2023-02-20 13:53:07 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-20 13:53:07 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-02-20 13:53:08 - train.py[line:549] - INFO: 0 / 6234
2023-02-20 13:53:08 - train.py[line:551] - INFO: load:0.77 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-20 13:55:12 - train.py[line:549] - INFO: 200 / 6234
2023-02-20 13:55:12 - train.py[line:551] - INFO: load:0.80 valid_run:123.91 task_valid:120.67 collect_output:2.08
2023-02-20 13:57:12 - train.py[line:549] - INFO: 400 / 6234
2023-02-20 13:57:12 - train.py[line:551] - INFO: load:0.82 valid_run:243.31 task_valid:236.10 collect_output:4.99
2023-02-20 13:59:14 - train.py[line:549] - INFO: 600 / 6234
2023-02-20 13:59:14 - train.py[line:551] - INFO: load:0.85 valid_run:365.57 task_valid:352.29 collect_output:10.04
2023-02-20 14:01:15 - train.py[line:549] - INFO: 800 / 6234
2023-02-20 14:01:15 - train.py[line:551] - INFO: load:0.87 valid_run:486.85 task_valid:465.41 collect_output:17.18
2023-02-20 14:03:15 - train.py[line:549] - INFO: 1000 / 6234
2023-02-20 14:03:15 - train.py[line:551] - INFO: load:0.89 valid_run:606.76 task_valid:582.20 collect_output:19.27
2023-02-20 14:05:18 - train.py[line:549] - INFO: 1200 / 6234
2023-02-20 14:05:18 - train.py[line:551] - INFO: load:0.92 valid_run:729.07 task_valid:700.41 collect_output:22.36
2023-02-20 14:07:20 - train.py[line:549] - INFO: 1400 / 6234
2023-02-20 14:07:20 - train.py[line:551] - INFO: load:0.94 valid_run:851.35 task_valid:817.95 collect_output:26.08
2023-02-20 14:09:21 - train.py[line:549] - INFO: 1600 / 6234
2023-02-20 14:09:21 - train.py[line:551] - INFO: load:0.97 valid_run:972.48 task_valid:933.91 collect_output:30.21
2023-02-20 14:11:24 - train.py[line:549] - INFO: 1800 / 6234
2023-02-20 14:11:24 - train.py[line:551] - INFO: load:0.99 valid_run:1095.52 task_valid:1050.56 collect_output:35.58
2023-02-20 14:13:25 - train.py[line:549] - INFO: 2000 / 6234
2023-02-20 14:13:25 - train.py[line:551] - INFO: load:1.02 valid_run:1216.50 task_valid:1162.71 collect_output:43.37
2023-02-20 14:15:25 - train.py[line:549] - INFO: 2200 / 6234
2023-02-20 14:15:25 - train.py[line:551] - INFO: load:1.04 valid_run:1336.14 task_valid:1277.92 collect_output:46.77
2023-02-20 14:17:26 - train.py[line:549] - INFO: 2400 / 6234
2023-02-20 14:17:26 - train.py[line:551] - INFO: load:1.07 valid_run:1457.41 task_valid:1394.58 collect_output:50.30
2023-02-20 14:19:25 - train.py[line:549] - INFO: 2600 / 6234
2023-02-20 14:19:25 - train.py[line:551] - INFO: load:1.09 valid_run:1575.74 task_valid:1507.96 collect_output:54.18
2023-02-20 14:21:25 - train.py[line:549] - INFO: 2800 / 6234
2023-02-20 14:21:25 - train.py[line:551] - INFO: load:1.12 valid_run:1696.23 task_valid:1625.32 collect_output:56.28
2023-02-20 14:23:26 - train.py[line:549] - INFO: 3000 / 6234
2023-02-20 14:23:26 - train.py[line:551] - INFO: load:1.14 valid_run:1816.68 task_valid:1741.05 collect_output:59.98
2023-02-20 14:25:27 - train.py[line:549] - INFO: 3200 / 6234
2023-02-20 14:25:27 - train.py[line:551] - INFO: load:1.16 valid_run:1937.67 task_valid:1854.71 collect_output:66.25
2023-02-20 14:27:28 - train.py[line:549] - INFO: 3400 / 6234
2023-02-20 14:27:28 - train.py[line:551] - INFO: load:1.19 valid_run:2058.85 task_valid:1970.62 collect_output:70.46
2023-02-20 14:29:29 - train.py[line:549] - INFO: 3600 / 6234
2023-02-20 14:29:29 - train.py[line:551] - INFO: load:1.21 valid_run:2179.23 task_valid:2088.29 collect_output:72.10
2023-02-20 14:31:30 - train.py[line:549] - INFO: 3800 / 6234
2023-02-20 14:31:30 - train.py[line:551] - INFO: load:1.24 valid_run:2300.15 task_valid:2204.92 collect_output:75.35
2023-02-20 14:33:30 - train.py[line:549] - INFO: 4000 / 6234
2023-02-20 14:33:30 - train.py[line:551] - INFO: load:1.26 valid_run:2420.03 task_valid:2321.05 collect_output:78.08
2023-02-20 14:35:31 - train.py[line:549] - INFO: 4200 / 6234
2023-02-20 14:35:31 - train.py[line:551] - INFO: load:1.29 valid_run:2541.23 task_valid:2437.25 collect_output:82.03
2023-02-20 14:37:32 - train.py[line:549] - INFO: 4400 / 6234
2023-02-20 14:37:32 - train.py[line:551] - INFO: load:1.31 valid_run:2662.74 task_valid:2555.70 collect_output:84.04
2023-02-20 14:39:32 - train.py[line:549] - INFO: 4600 / 6234
2023-02-20 14:39:32 - train.py[line:551] - INFO: load:1.34 valid_run:2782.74 task_valid:2669.75 collect_output:88.94
2023-02-20 14:41:32 - train.py[line:549] - INFO: 4800 / 6234
2023-02-20 14:41:32 - train.py[line:551] - INFO: load:1.36 valid_run:2902.01 task_valid:2785.55 collect_output:91.36
2023-02-20 14:43:33 - train.py[line:549] - INFO: 5000 / 6234
2023-02-20 14:43:33 - train.py[line:551] - INFO: load:1.38 valid_run:3023.28 task_valid:2901.56 collect_output:95.59
2023-02-20 14:45:36 - train.py[line:549] - INFO: 5200 / 6234
2023-02-20 14:45:36 - train.py[line:551] - INFO: load:1.41 valid_run:3146.00 task_valid:3017.44 collect_output:101.32
2023-02-20 14:47:36 - train.py[line:549] - INFO: 5400 / 6234
2023-02-20 14:47:36 - train.py[line:551] - INFO: load:1.44 valid_run:3265.61 task_valid:3131.55 collect_output:105.76
2023-02-20 14:49:37 - train.py[line:549] - INFO: 5600 / 6234
2023-02-20 14:49:37 - train.py[line:551] - INFO: load:1.46 valid_run:3387.37 task_valid:3250.80 collect_output:107.20
2023-02-20 14:51:39 - train.py[line:549] - INFO: 5800 / 6234
2023-02-20 14:51:39 - train.py[line:551] - INFO: load:1.49 valid_run:3508.74 task_valid:3366.13 collect_output:112.17
2023-02-20 14:53:40 - train.py[line:549] - INFO: 6000 / 6234
2023-02-20 14:53:40 - train.py[line:551] - INFO: load:1.51 valid_run:3630.31 task_valid:3484.32 collect_output:114.52
2023-02-20 14:55:42 - train.py[line:549] - INFO: 6200 / 6234
2023-02-20 14:55:42 - train.py[line:551] - INFO: load:1.54 valid_run:3751.42 task_valid:3602.69 collect_output:116.17

====================================================================================================
SGG eval:     R @ 50: 0.3165;     R @ 100: 0.3776;     R @ 500: 0.4474;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1298;    mR @ 100: 0.1949;    mR @ 500: 0.2360;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0732) (covered in:0.0000) (covering:0.1429) (eating:0.4412) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5484) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.2500) (playing:0.0000) (riding:0.5029) (says:0.0000) (sitting on:0.4522) (standing on:0.4958) (using:0.1500) (walking in:0.0000) (walking on:0.2162) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3165;     R @ 100: 0.3776;     R @ 500: 0.4474;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1298;    mR @ 100: 0.1949;    mR @ 500: 0.2360;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0732) (covered in:0.0000) (covering:0.1429) (eating:0.4412) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5484) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.2500) (playing:0.0000) (riding:0.5029) (says:0.0000) (sitting on:0.4522) (standing on:0.4958) (using:0.1500) (walking in:0.0000) (walking on:0.2162) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-02-20 14:56:12 - train.py[line:487] - INFO: 0.3776333333333333
2023-02-20 14:56:13 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-20 14:56:13 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.244 | loss_v1 0 | loss_v2 0 | nll_loss 0.064 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.377633 | ppl 1.05 | vqa_score 0.1216 | wps 118.6 | wpb 72 | bsz 24 | num_updates 2000
2023-02-20 14:56:13 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2023-02-20 14:56:13 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_2000.pt
2023-02-20 14:56:19 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_2000.pt
2023-02-20 14:56:24 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.3776333333333333) (writing took 11.756130872294307 seconds)
2023-02-20 14:56:36 - progress_bar.py[line:274] - INFO: epoch 001:   2010 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=112.5, bsz=40, num_updates=2010, lr=2.62128e-05, gnorm=0.261, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6062
2023-02-20 14:56:47 - progress_bar.py[line:274] - INFO: epoch 001:   2020 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.87, wpb=111.5, bsz=40, num_updates=2020, lr=2.63432e-05, gnorm=0.412, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6074
2023-02-20 14:56:59 - progress_bar.py[line:274] - INFO: epoch 001:   2030 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.88, wpb=112.1, bsz=40, num_updates=2030, lr=2.64737e-05, gnorm=0.345, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6085
2023-02-20 14:57:10 - progress_bar.py[line:274] - INFO: epoch 001:   2040 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=2040, lr=2.66041e-05, gnorm=0.364, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6096
2023-02-20 14:57:21 - progress_bar.py[line:274] - INFO: epoch 001:   2050 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=112.1, bsz=40, num_updates=2050, lr=2.67345e-05, gnorm=0.255, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6108
2023-02-20 14:57:33 - progress_bar.py[line:274] - INFO: epoch 001:   2060 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.8, bsz=40, num_updates=2060, lr=2.68649e-05, gnorm=0.288, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6119
2023-02-20 14:57:44 - progress_bar.py[line:274] - INFO: epoch 001:   2070 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=2070, lr=2.69953e-05, gnorm=0.335, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6130
2023-02-20 14:57:55 - progress_bar.py[line:274] - INFO: epoch 001:   2080 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.7, ups=0.91, wpb=112.1, bsz=40, num_updates=2080, lr=2.71257e-05, gnorm=0.38, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6141
2023-02-20 14:58:06 - progress_bar.py[line:274] - INFO: epoch 001:   2090 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=112, bsz=40, num_updates=2090, lr=2.72561e-05, gnorm=0.255, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6152
2023-02-20 14:58:17 - progress_bar.py[line:274] - INFO: epoch 001:   2100 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=2100, lr=2.73865e-05, gnorm=0.283, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6163
2023-02-20 14:58:28 - progress_bar.py[line:274] - INFO: epoch 001:   2110 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.3, bsz=40, num_updates=2110, lr=2.7517e-05, gnorm=0.24, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6175
2023-02-20 14:58:39 - progress_bar.py[line:274] - INFO: epoch 001:   2120 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.92, wpb=111.7, bsz=40, num_updates=2120, lr=2.76474e-05, gnorm=0.242, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6185
2023-02-20 14:58:50 - progress_bar.py[line:274] - INFO: epoch 001:   2130 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.3, ups=0.88, wpb=110, bsz=40, num_updates=2130, lr=2.77778e-05, gnorm=0.465, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6197
2023-02-20 14:59:02 - progress_bar.py[line:274] - INFO: epoch 001:   2140 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.3, bsz=40, num_updates=2140, lr=2.79082e-05, gnorm=0.275, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6208
2023-02-20 14:59:13 - progress_bar.py[line:274] - INFO: epoch 001:   2150 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.4, ups=0.9, wpb=111.3, bsz=40, num_updates=2150, lr=2.80386e-05, gnorm=0.34, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6219
2023-02-20 14:59:23 - progress_bar.py[line:274] - INFO: epoch 001:   2160 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.93, wpb=112, bsz=40, num_updates=2160, lr=2.8169e-05, gnorm=0.274, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6230
2023-02-20 14:59:35 - progress_bar.py[line:274] - INFO: epoch 001:   2170 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=2170, lr=2.82994e-05, gnorm=0.287, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6241
2023-02-20 14:59:45 - progress_bar.py[line:274] - INFO: epoch 001:   2180 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.92, wpb=110.2, bsz=40, num_updates=2180, lr=2.84298e-05, gnorm=0.326, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6252
2023-02-20 14:59:57 - progress_bar.py[line:274] - INFO: epoch 001:   2190 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=111.1, bsz=40, num_updates=2190, lr=2.85603e-05, gnorm=0.31, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6263
2023-02-20 15:00:07 - progress_bar.py[line:274] - INFO: epoch 001:   2200 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.3, ups=0.93, wpb=112.2, bsz=40, num_updates=2200, lr=2.86907e-05, gnorm=0.351, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6274
2023-02-20 15:00:19 - progress_bar.py[line:274] - INFO: epoch 001:   2210 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=2210, lr=2.88211e-05, gnorm=0.341, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6285
2023-02-20 15:00:29 - progress_bar.py[line:274] - INFO: epoch 001:   2220 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.3, ups=0.92, wpb=112.3, bsz=40, num_updates=2220, lr=2.89515e-05, gnorm=0.326, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6296
2023-02-20 15:00:40 - progress_bar.py[line:274] - INFO: epoch 001:   2230 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.3, ups=0.93, wpb=111.1, bsz=40, num_updates=2230, lr=2.90819e-05, gnorm=0.302, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6307
2023-02-20 15:00:51 - progress_bar.py[line:274] - INFO: epoch 001:   2240 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.7, bsz=40, num_updates=2240, lr=2.92123e-05, gnorm=0.301, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6317
2023-02-20 15:01:02 - progress_bar.py[line:274] - INFO: epoch 001:   2250 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=2250, lr=2.93427e-05, gnorm=0.213, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6328
2023-02-20 15:01:13 - progress_bar.py[line:274] - INFO: epoch 001:   2260 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.89, wpb=111.4, bsz=40, num_updates=2260, lr=2.94731e-05, gnorm=0.312, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6340
2023-02-20 15:01:24 - progress_bar.py[line:274] - INFO: epoch 001:   2270 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=2270, lr=2.96035e-05, gnorm=0.297, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6351
2023-02-20 15:01:35 - progress_bar.py[line:274] - INFO: epoch 001:   2280 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.91, wpb=112.8, bsz=40, num_updates=2280, lr=2.9734e-05, gnorm=0.286, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=6362
2023-02-20 15:01:46 - progress_bar.py[line:274] - INFO: epoch 001:   2290 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.92, wpb=112.4, bsz=40, num_updates=2290, lr=2.98644e-05, gnorm=0.363, clip=10, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=6373
2023-02-20 15:01:57 - progress_bar.py[line:274] - INFO: epoch 001:   2300 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.6, bsz=40, num_updates=2300, lr=2.99948e-05, gnorm=0.203, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6384
2023-02-20 15:02:08 - progress_bar.py[line:274] - INFO: epoch 001:   2310 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=2310, lr=3.01252e-05, gnorm=0.27, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6395
2023-02-20 15:02:19 - progress_bar.py[line:274] - INFO: epoch 001:   2320 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.5, bsz=40, num_updates=2320, lr=3.02556e-05, gnorm=0.264, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6406
2023-02-20 15:02:31 - progress_bar.py[line:274] - INFO: epoch 001:   2330 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112.3, bsz=40, num_updates=2330, lr=3.0386e-05, gnorm=0.255, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6417
2023-02-20 15:02:42 - progress_bar.py[line:274] - INFO: epoch 001:   2340 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.4, bsz=40, num_updates=2340, lr=3.05164e-05, gnorm=0.318, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6428
2023-02-20 15:02:53 - progress_bar.py[line:274] - INFO: epoch 001:   2350 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.92, wpb=110.7, bsz=40, num_updates=2350, lr=3.06468e-05, gnorm=0.325, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6439
2023-02-20 15:03:04 - progress_bar.py[line:274] - INFO: epoch 001:   2360 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=2360, lr=3.07773e-05, gnorm=0.316, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6450
2023-02-20 15:03:15 - progress_bar.py[line:274] - INFO: epoch 001:   2370 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=95.5, ups=0.87, wpb=109.7, bsz=40, num_updates=2370, lr=3.09077e-05, gnorm=0.312, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6462
2023-02-20 15:03:27 - progress_bar.py[line:274] - INFO: epoch 001:   2380 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.2, bsz=40, num_updates=2380, lr=3.10381e-05, gnorm=0.329, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6473
2023-02-20 15:03:37 - progress_bar.py[line:274] - INFO: epoch 001:   2390 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=105.2, ups=0.93, wpb=112.8, bsz=40, num_updates=2390, lr=3.11685e-05, gnorm=0.289, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6484
2023-02-20 15:03:49 - progress_bar.py[line:274] - INFO: epoch 001:   2400 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.87, wpb=112.5, bsz=40, num_updates=2400, lr=3.12989e-05, gnorm=0.355, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6495
2023-02-20 15:04:00 - progress_bar.py[line:274] - INFO: epoch 001:   2410 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=2410, lr=3.14293e-05, gnorm=0.315, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6506
2023-02-20 15:04:11 - progress_bar.py[line:274] - INFO: epoch 001:   2420 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=2420, lr=3.15597e-05, gnorm=0.276, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6518
2023-02-20 15:04:22 - progress_bar.py[line:274] - INFO: epoch 001:   2430 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.92, wpb=112.7, bsz=40, num_updates=2430, lr=3.16901e-05, gnorm=0.226, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6529
2023-02-20 15:04:33 - progress_bar.py[line:274] - INFO: epoch 001:   2440 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.7, ups=0.93, wpb=112.6, bsz=40, num_updates=2440, lr=3.18206e-05, gnorm=0.269, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6539
2023-02-20 15:04:44 - progress_bar.py[line:274] - INFO: epoch 001:   2450 / 71012 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99, ups=0.88, wpb=111.9, bsz=40, num_updates=2450, lr=3.1951e-05, gnorm=0.342, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6551
2023-02-20 15:04:55 - progress_bar.py[line:274] - INFO: epoch 001:   2460 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=2460, lr=3.20814e-05, gnorm=0.326, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6562
2023-02-20 15:05:07 - progress_bar.py[line:274] - INFO: epoch 001:   2470 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.6, bsz=40, num_updates=2470, lr=3.22118e-05, gnorm=0.257, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6573
2023-02-20 15:05:18 - progress_bar.py[line:274] - INFO: epoch 001:   2480 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.91, wpb=111.3, bsz=40, num_updates=2480, lr=3.23422e-05, gnorm=0.274, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6584
2023-02-20 15:05:29 - progress_bar.py[line:274] - INFO: epoch 001:   2490 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.4, ups=0.92, wpb=112.5, bsz=40, num_updates=2490, lr=3.24726e-05, gnorm=0.329, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6595
2023-02-20 15:05:40 - progress_bar.py[line:274] - INFO: epoch 001:   2500 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=112.1, bsz=40, num_updates=2500, lr=3.2603e-05, gnorm=0.345, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6606
2023-02-20 15:05:51 - progress_bar.py[line:274] - INFO: epoch 001:   2510 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=2510, lr=3.27334e-05, gnorm=0.233, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6618
2023-02-20 15:06:02 - progress_bar.py[line:274] - INFO: epoch 001:   2520 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.7, bsz=40, num_updates=2520, lr=3.28638e-05, gnorm=0.221, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6629
2023-02-20 15:06:13 - progress_bar.py[line:274] - INFO: epoch 001:   2530 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.9, wpb=112.5, bsz=40, num_updates=2530, lr=3.29943e-05, gnorm=0.205, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6640
2023-02-20 15:06:24 - progress_bar.py[line:274] - INFO: epoch 001:   2540 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.2, bsz=40, num_updates=2540, lr=3.31247e-05, gnorm=0.25, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6651
2023-02-20 15:06:35 - progress_bar.py[line:274] - INFO: epoch 001:   2550 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.93, wpb=111.8, bsz=40, num_updates=2550, lr=3.32551e-05, gnorm=0.282, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6662
2023-02-20 15:06:46 - progress_bar.py[line:274] - INFO: epoch 001:   2560 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=2560, lr=3.33855e-05, gnorm=0.336, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6673
2023-02-20 15:06:57 - progress_bar.py[line:274] - INFO: epoch 001:   2570 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.94, wpb=108.6, bsz=40, num_updates=2570, lr=3.35159e-05, gnorm=0.243, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6683
2023-02-20 15:07:08 - progress_bar.py[line:274] - INFO: epoch 001:   2580 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=2580, lr=3.36463e-05, gnorm=0.177, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6694
2023-02-20 15:07:15 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 15:07:20 - progress_bar.py[line:274] - INFO: epoch 001:   2591 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.4, ups=0.84, wpb=110.8, bsz=40, num_updates=2590, lr=3.37767e-05, gnorm=0.272, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6706
2023-02-20 15:07:31 - progress_bar.py[line:274] - INFO: epoch 001:   2601 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=2600, lr=3.39071e-05, gnorm=0.234, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6717
2023-02-20 15:07:42 - progress_bar.py[line:274] - INFO: epoch 001:   2611 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.3, ups=0.92, wpb=111.2, bsz=40, num_updates=2610, lr=3.40376e-05, gnorm=0.254, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6728
2023-02-20 15:07:53 - progress_bar.py[line:274] - INFO: epoch 001:   2621 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.91, wpb=110.5, bsz=40, num_updates=2620, lr=3.4168e-05, gnorm=0.314, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6739
2023-02-20 15:08:04 - progress_bar.py[line:274] - INFO: epoch 001:   2631 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.9, wpb=110.8, bsz=40, num_updates=2630, lr=3.42984e-05, gnorm=0.318, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6750
2023-02-20 15:08:16 - progress_bar.py[line:274] - INFO: epoch 001:   2641 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.7, bsz=40, num_updates=2640, lr=3.44288e-05, gnorm=0.224, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6762
2023-02-20 15:08:27 - progress_bar.py[line:274] - INFO: epoch 001:   2651 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.8, bsz=40, num_updates=2650, lr=3.45592e-05, gnorm=0.335, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6773
2023-02-20 15:08:38 - progress_bar.py[line:274] - INFO: epoch 001:   2661 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111, bsz=40, num_updates=2660, lr=3.46896e-05, gnorm=0.196, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6785
2023-02-20 15:08:49 - progress_bar.py[line:274] - INFO: epoch 001:   2671 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=2670, lr=3.482e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=6796
2023-02-20 15:09:00 - progress_bar.py[line:274] - INFO: epoch 001:   2681 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.92, wpb=111.7, bsz=40, num_updates=2680, lr=3.49504e-05, gnorm=0.358, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6807
2023-02-20 15:09:11 - progress_bar.py[line:274] - INFO: epoch 001:   2691 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.9, wpb=111.8, bsz=40, num_updates=2690, lr=3.50809e-05, gnorm=0.278, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6818
2023-02-20 15:09:23 - progress_bar.py[line:274] - INFO: epoch 001:   2701 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=2700, lr=3.52113e-05, gnorm=0.291, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6829
2023-02-20 15:09:34 - progress_bar.py[line:274] - INFO: epoch 001:   2711 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=2710, lr=3.53417e-05, gnorm=0.278, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6840
2023-02-20 15:09:45 - progress_bar.py[line:274] - INFO: epoch 001:   2721 / 71012 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.5, bsz=40, num_updates=2720, lr=3.54721e-05, gnorm=0.299, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6851
2023-02-20 15:09:56 - progress_bar.py[line:274] - INFO: epoch 001:   2731 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=2730, lr=3.56025e-05, gnorm=0.284, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6863
2023-02-20 15:10:08 - progress_bar.py[line:274] - INFO: epoch 001:   2741 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.87, wpb=112.8, bsz=40, num_updates=2740, lr=3.57329e-05, gnorm=0.285, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6874
2023-02-20 15:10:19 - progress_bar.py[line:274] - INFO: epoch 001:   2751 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=2750, lr=3.58633e-05, gnorm=0.188, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6885
2023-02-20 15:10:30 - progress_bar.py[line:274] - INFO: epoch 001:   2761 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.8, ups=0.91, wpb=112.3, bsz=40, num_updates=2760, lr=3.59937e-05, gnorm=0.261, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6896
2023-02-20 15:10:41 - progress_bar.py[line:274] - INFO: epoch 001:   2771 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.3, bsz=40, num_updates=2770, lr=3.61242e-05, gnorm=0.185, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6908
2023-02-20 15:10:52 - progress_bar.py[line:274] - INFO: epoch 001:   2781 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.89, wpb=111.5, bsz=40, num_updates=2780, lr=3.62546e-05, gnorm=0.269, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6919
2023-02-20 15:11:04 - progress_bar.py[line:274] - INFO: epoch 001:   2791 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=112.2, bsz=40, num_updates=2790, lr=3.6385e-05, gnorm=0.275, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6930
2023-02-20 15:11:15 - progress_bar.py[line:274] - INFO: epoch 001:   2801 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=112, bsz=40, num_updates=2800, lr=3.65154e-05, gnorm=0.242, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6941
2023-02-20 15:11:26 - progress_bar.py[line:274] - INFO: epoch 001:   2811 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=2810, lr=3.66458e-05, gnorm=0.264, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6953
2023-02-20 15:11:31 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-02-20 15:11:39 - progress_bar.py[line:274] - INFO: epoch 001:   2822 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.3, ups=0.81, wpb=111.1, bsz=40, num_updates=2820, lr=3.67762e-05, gnorm=0.189, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=6965
2023-02-20 15:11:50 - progress_bar.py[line:274] - INFO: epoch 001:   2832 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.3, bsz=40, num_updates=2830, lr=3.69066e-05, gnorm=0.326, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6976
2023-02-20 15:12:00 - progress_bar.py[line:274] - INFO: epoch 001:   2842 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.5, ups=0.93, wpb=112.1, bsz=40, num_updates=2840, lr=3.7037e-05, gnorm=0.305, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6987
2023-02-20 15:12:12 - progress_bar.py[line:274] - INFO: epoch 001:   2852 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.9, ups=0.87, wpb=111.3, bsz=40, num_updates=2850, lr=3.71674e-05, gnorm=0.219, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6998
2023-02-20 15:12:23 - progress_bar.py[line:274] - INFO: epoch 001:   2862 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=112, bsz=40, num_updates=2860, lr=3.72979e-05, gnorm=0.233, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7010
2023-02-20 15:12:35 - progress_bar.py[line:274] - INFO: epoch 001:   2872 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=2870, lr=3.74283e-05, gnorm=0.238, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7021
2023-02-20 15:12:46 - progress_bar.py[line:274] - INFO: epoch 001:   2882 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.3, bsz=40, num_updates=2880, lr=3.75587e-05, gnorm=0.196, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7032
2023-02-20 15:12:56 - progress_bar.py[line:274] - INFO: epoch 001:   2892 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.8, ups=0.93, wpb=112.2, bsz=40, num_updates=2890, lr=3.76891e-05, gnorm=0.28, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7043
2023-02-20 15:13:07 - progress_bar.py[line:274] - INFO: epoch 001:   2902 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.7, bsz=40, num_updates=2900, lr=3.78195e-05, gnorm=0.325, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=7054
2023-02-20 15:13:18 - progress_bar.py[line:274] - INFO: epoch 001:   2912 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.91, wpb=109.7, bsz=40, num_updates=2910, lr=3.79499e-05, gnorm=0.238, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=7065
2023-02-20 15:13:30 - progress_bar.py[line:274] - INFO: epoch 001:   2922 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.88, wpb=111.3, bsz=40, num_updates=2920, lr=3.80803e-05, gnorm=0.259, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7076
2023-02-20 15:13:41 - progress_bar.py[line:274] - INFO: epoch 001:   2932 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.9, bsz=40, num_updates=2930, lr=3.82107e-05, gnorm=0.247, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7087
2023-02-20 15:13:52 - progress_bar.py[line:274] - INFO: epoch 001:   2942 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.4, bsz=40, num_updates=2940, lr=3.83412e-05, gnorm=0.284, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7098
2023-02-20 15:14:03 - progress_bar.py[line:274] - INFO: epoch 001:   2952 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.5, ups=0.93, wpb=111, bsz=40, num_updates=2950, lr=3.84716e-05, gnorm=0.32, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=7109
2023-02-20 15:14:14 - progress_bar.py[line:274] - INFO: epoch 001:   2962 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.2, bsz=40, num_updates=2960, lr=3.8602e-05, gnorm=0.289, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7120
2023-02-20 15:14:25 - progress_bar.py[line:274] - INFO: epoch 001:   2972 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.2, bsz=40, num_updates=2970, lr=3.87324e-05, gnorm=0.18, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7131
2023-02-20 15:14:36 - progress_bar.py[line:274] - INFO: epoch 001:   2982 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.8, ups=0.94, wpb=111.3, bsz=40, num_updates=2980, lr=3.88628e-05, gnorm=0.191, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7142
2023-02-20 15:14:47 - progress_bar.py[line:274] - INFO: epoch 001:   2992 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.8, bsz=40, num_updates=2990, lr=3.89932e-05, gnorm=0.227, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7153
2023-02-20 15:14:58 - progress_bar.py[line:274] - INFO: epoch 001:   3002 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.6, bsz=40, num_updates=3000, lr=3.91236e-05, gnorm=0.248, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=7165
2023-02-20 15:15:09 - progress_bar.py[line:274] - INFO: epoch 001:   3012 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.6, ups=0.91, wpb=112.1, bsz=40, num_updates=3010, lr=3.9254e-05, gnorm=0.335, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7176
2023-02-20 15:15:21 - progress_bar.py[line:274] - INFO: epoch 001:   3022 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=3020, lr=3.93845e-05, gnorm=0.228, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7187
2023-02-20 15:15:32 - progress_bar.py[line:274] - INFO: epoch 001:   3032 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.89, wpb=111.9, bsz=40, num_updates=3030, lr=3.95149e-05, gnorm=0.286, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7198
2023-02-20 15:15:43 - progress_bar.py[line:274] - INFO: epoch 001:   3042 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.5, bsz=40, num_updates=3040, lr=3.96453e-05, gnorm=0.211, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=7209
2023-02-20 15:15:55 - progress_bar.py[line:274] - INFO: epoch 001:   3052 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.5, bsz=40, num_updates=3050, lr=3.97757e-05, gnorm=0.213, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7221
2023-02-20 15:16:06 - progress_bar.py[line:274] - INFO: epoch 001:   3062 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=112.1, bsz=40, num_updates=3060, lr=3.99061e-05, gnorm=0.232, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7232
2023-02-20 15:16:17 - progress_bar.py[line:274] - INFO: epoch 001:   3072 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.4, ups=0.9, wpb=109.9, bsz=40, num_updates=3070, lr=4.00365e-05, gnorm=0.272, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7243
2023-02-20 15:16:28 - progress_bar.py[line:274] - INFO: epoch 001:   3082 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.91, wpb=111.5, bsz=40, num_updates=3080, lr=4.01669e-05, gnorm=0.225, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7254
2023-02-20 15:16:39 - progress_bar.py[line:274] - INFO: epoch 001:   3092 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=3090, lr=4.02973e-05, gnorm=0.225, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7266
2023-02-20 15:16:50 - progress_bar.py[line:274] - INFO: epoch 001:   3102 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=3100, lr=4.04278e-05, gnorm=0.324, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7277
2023-02-20 15:17:01 - progress_bar.py[line:274] - INFO: epoch 001:   3112 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.5, ups=0.94, wpb=110.7, bsz=40, num_updates=3110, lr=4.05582e-05, gnorm=0.399, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=7287
2023-02-20 15:17:12 - progress_bar.py[line:274] - INFO: epoch 001:   3122 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.8, ups=0.91, wpb=111.1, bsz=40, num_updates=3120, lr=4.06886e-05, gnorm=0.35, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7299
2023-02-20 15:17:23 - progress_bar.py[line:274] - INFO: epoch 001:   3132 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=3130, lr=4.0819e-05, gnorm=0.273, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7310
2023-02-20 15:17:34 - progress_bar.py[line:274] - INFO: epoch 001:   3142 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.8, bsz=40, num_updates=3140, lr=4.09494e-05, gnorm=0.208, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7321
2023-02-20 15:17:45 - progress_bar.py[line:274] - INFO: epoch 001:   3152 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.92, wpb=113.1, bsz=40, num_updates=3150, lr=4.10798e-05, gnorm=0.249, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7331
2023-02-20 15:17:56 - progress_bar.py[line:274] - INFO: epoch 001:   3162 / 71012 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.7, ups=0.93, wpb=112.3, bsz=40, num_updates=3160, lr=4.12102e-05, gnorm=0.371, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7342
2023-02-20 15:18:07 - progress_bar.py[line:274] - INFO: epoch 001:   3172 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=110.9, bsz=40, num_updates=3170, lr=4.13406e-05, gnorm=0.198, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7353
2023-02-20 15:18:19 - progress_bar.py[line:274] - INFO: epoch 001:   3182 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=111.9, bsz=40, num_updates=3180, lr=4.1471e-05, gnorm=0.284, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7365
2023-02-20 15:18:29 - progress_bar.py[line:274] - INFO: epoch 001:   3192 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.3, bsz=40, num_updates=3190, lr=4.16015e-05, gnorm=0.276, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7376
2023-02-20 15:18:41 - progress_bar.py[line:274] - INFO: epoch 001:   3202 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=3200, lr=4.17319e-05, gnorm=0.228, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=7387
2023-02-20 15:18:52 - progress_bar.py[line:274] - INFO: epoch 001:   3212 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.7, bsz=40, num_updates=3210, lr=4.18623e-05, gnorm=0.249, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7398
2023-02-20 15:19:03 - progress_bar.py[line:274] - INFO: epoch 001:   3222 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.5, ups=0.92, wpb=111.6, bsz=40, num_updates=3220, lr=4.19927e-05, gnorm=0.319, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7409
2023-02-20 15:19:14 - progress_bar.py[line:274] - INFO: epoch 001:   3232 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.7, bsz=40, num_updates=3230, lr=4.21231e-05, gnorm=0.32, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7420
2023-02-20 15:19:25 - progress_bar.py[line:274] - INFO: epoch 001:   3242 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.1, ups=0.93, wpb=110.7, bsz=40, num_updates=3240, lr=4.22535e-05, gnorm=0.263, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=7431
2023-02-20 15:19:36 - progress_bar.py[line:274] - INFO: epoch 001:   3252 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.92, wpb=110.1, bsz=40, num_updates=3250, lr=4.23839e-05, gnorm=0.186, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7442
2023-02-20 15:19:47 - progress_bar.py[line:274] - INFO: epoch 001:   3262 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.3, bsz=40, num_updates=3260, lr=4.25143e-05, gnorm=0.268, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7453
2023-02-20 15:19:58 - progress_bar.py[line:274] - INFO: epoch 001:   3272 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112.9, bsz=40, num_updates=3270, lr=4.26448e-05, gnorm=0.205, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7464
2023-02-20 15:20:09 - progress_bar.py[line:274] - INFO: epoch 001:   3282 / 71012 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=105, ups=0.93, wpb=112.7, bsz=40, num_updates=3280, lr=4.27752e-05, gnorm=0.378, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7475
2023-02-20 15:20:20 - progress_bar.py[line:274] - INFO: epoch 001:   3292 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=3290, lr=4.29056e-05, gnorm=0.163, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7486
2023-02-20 15:20:31 - progress_bar.py[line:274] - INFO: epoch 001:   3302 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.8, bsz=40, num_updates=3300, lr=4.3036e-05, gnorm=0.176, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7497
2023-02-20 15:20:42 - progress_bar.py[line:274] - INFO: epoch 001:   3312 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.8, ups=0.88, wpb=110.6, bsz=40, num_updates=3310, lr=4.31664e-05, gnorm=0.246, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7509
2023-02-20 15:20:53 - progress_bar.py[line:274] - INFO: epoch 001:   3322 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.91, wpb=113.3, bsz=40, num_updates=3320, lr=4.32968e-05, gnorm=0.266, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7520
2023-02-20 15:21:04 - progress_bar.py[line:274] - INFO: epoch 001:   3332 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=109.8, bsz=40, num_updates=3330, lr=4.34272e-05, gnorm=0.219, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7531
2023-02-20 15:21:16 - progress_bar.py[line:274] - INFO: epoch 001:   3342 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111.1, bsz=40, num_updates=3340, lr=4.35576e-05, gnorm=0.277, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7542
2023-02-20 15:21:27 - progress_bar.py[line:274] - INFO: epoch 001:   3352 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=3350, lr=4.36881e-05, gnorm=0.216, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7553
2023-02-20 15:21:38 - progress_bar.py[line:274] - INFO: epoch 001:   3362 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.88, wpb=112.6, bsz=40, num_updates=3360, lr=4.38185e-05, gnorm=0.181, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=7564
2023-02-20 15:21:49 - progress_bar.py[line:274] - INFO: epoch 001:   3372 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.1, ups=0.92, wpb=112, bsz=40, num_updates=3370, lr=4.39489e-05, gnorm=0.226, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7575
2023-02-20 15:22:00 - progress_bar.py[line:274] - INFO: epoch 001:   3382 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.2, ups=0.91, wpb=112.2, bsz=40, num_updates=3380, lr=4.40793e-05, gnorm=0.322, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7586
2023-02-20 15:22:11 - progress_bar.py[line:274] - INFO: epoch 001:   3392 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.93, wpb=111, bsz=40, num_updates=3390, lr=4.42097e-05, gnorm=0.244, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7597
2023-02-20 15:22:22 - progress_bar.py[line:274] - INFO: epoch 001:   3402 / 71012 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.7, ups=0.9, wpb=111.4, bsz=40, num_updates=3400, lr=4.43401e-05, gnorm=0.342, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7608
2023-02-20 15:22:33 - progress_bar.py[line:274] - INFO: epoch 001:   3412 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.2, bsz=40, num_updates=3410, lr=4.44705e-05, gnorm=0.208, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7620
2023-02-20 15:22:44 - progress_bar.py[line:274] - INFO: epoch 001:   3422 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.2, bsz=40, num_updates=3420, lr=4.46009e-05, gnorm=0.185, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7631
2023-02-20 15:22:55 - progress_bar.py[line:274] - INFO: epoch 001:   3432 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.1, ups=0.9, wpb=109.6, bsz=40, num_updates=3430, lr=4.47314e-05, gnorm=0.483, clip=20, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7642
2023-02-20 15:23:07 - progress_bar.py[line:274] - INFO: epoch 001:   3442 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.4, ups=0.87, wpb=110.8, bsz=40, num_updates=3440, lr=4.48618e-05, gnorm=0.226, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7653
2023-02-20 15:23:18 - progress_bar.py[line:274] - INFO: epoch 001:   3452 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=3450, lr=4.49922e-05, gnorm=0.366, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7664
2023-02-20 15:23:29 - progress_bar.py[line:274] - INFO: epoch 001:   3462 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.9, wpb=111.4, bsz=40, num_updates=3460, lr=4.51226e-05, gnorm=0.238, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7676
2023-02-20 15:23:41 - progress_bar.py[line:274] - INFO: epoch 001:   3472 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=3470, lr=4.5253e-05, gnorm=0.165, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7687
2023-02-20 15:23:52 - progress_bar.py[line:274] - INFO: epoch 001:   3482 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.9, wpb=110.2, bsz=40, num_updates=3480, lr=4.53834e-05, gnorm=0.25, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7698
2023-02-20 15:24:02 - progress_bar.py[line:274] - INFO: epoch 001:   3492 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=105.2, ups=0.93, wpb=113, bsz=40, num_updates=3490, lr=4.55138e-05, gnorm=0.259, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7709
2023-02-20 15:24:14 - progress_bar.py[line:274] - INFO: epoch 001:   3502 / 71012 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.88, wpb=111.3, bsz=40, num_updates=3500, lr=4.56442e-05, gnorm=0.335, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=7720
2023-02-20 15:24:25 - progress_bar.py[line:274] - INFO: epoch 001:   3512 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.2, bsz=40, num_updates=3510, lr=4.57746e-05, gnorm=0.18, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=7731
2023-02-20 15:24:36 - progress_bar.py[line:274] - INFO: epoch 001:   3522 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=111.9, bsz=40, num_updates=3520, lr=4.59051e-05, gnorm=0.171, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=7742
2023-02-20 15:24:47 - progress_bar.py[line:274] - INFO: epoch 001:   3532 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.5, ups=0.93, wpb=112, bsz=40, num_updates=3530, lr=4.60355e-05, gnorm=0.184, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7753
2023-02-20 15:24:57 - progress_bar.py[line:274] - INFO: epoch 001:   3542 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=105.8, ups=0.94, wpb=112, bsz=40, num_updates=3540, lr=4.61659e-05, gnorm=0.174, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7764
2023-02-20 15:25:09 - progress_bar.py[line:274] - INFO: epoch 001:   3552 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=3550, lr=4.62963e-05, gnorm=0.199, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7775
2023-02-20 15:25:20 - progress_bar.py[line:274] - INFO: epoch 001:   3562 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.89, wpb=112.3, bsz=40, num_updates=3560, lr=4.64267e-05, gnorm=0.208, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7786
2023-02-20 15:25:31 - progress_bar.py[line:274] - INFO: epoch 001:   3572 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.89, wpb=113.1, bsz=40, num_updates=3570, lr=4.65571e-05, gnorm=0.16, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7797
2023-02-20 15:25:42 - progress_bar.py[line:274] - INFO: epoch 001:   3582 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=3580, lr=4.66875e-05, gnorm=0.241, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7808
2023-02-20 15:25:54 - progress_bar.py[line:274] - INFO: epoch 001:   3592 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.7, ups=0.88, wpb=111.6, bsz=40, num_updates=3590, lr=4.68179e-05, gnorm=0.289, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7820
2023-02-20 15:26:05 - progress_bar.py[line:274] - INFO: epoch 001:   3602 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.89, wpb=112.9, bsz=40, num_updates=3600, lr=4.69484e-05, gnorm=0.182, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7831
2023-02-20 15:26:16 - progress_bar.py[line:274] - INFO: epoch 001:   3612 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.7, ups=0.87, wpb=111.9, bsz=40, num_updates=3610, lr=4.70788e-05, gnorm=0.3, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7843
2023-02-20 15:26:27 - progress_bar.py[line:274] - INFO: epoch 001:   3622 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.2, bsz=40, num_updates=3620, lr=4.72092e-05, gnorm=0.234, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7854
2023-02-20 15:26:39 - progress_bar.py[line:274] - INFO: epoch 001:   3632 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.4, bsz=40, num_updates=3630, lr=4.73396e-05, gnorm=0.227, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7865
2023-02-20 15:26:50 - progress_bar.py[line:274] - INFO: epoch 001:   3642 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.8, bsz=40, num_updates=3640, lr=4.747e-05, gnorm=0.231, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7876
2023-02-20 15:27:01 - progress_bar.py[line:274] - INFO: epoch 001:   3652 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=3650, lr=4.76004e-05, gnorm=0.215, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7887
2023-02-20 15:27:12 - progress_bar.py[line:274] - INFO: epoch 001:   3662 / 71012 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.88, wpb=111.3, bsz=40, num_updates=3660, lr=4.77308e-05, gnorm=0.245, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=7898
2023-02-20 15:27:23 - progress_bar.py[line:274] - INFO: epoch 001:   3672 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.89, wpb=112, bsz=40, num_updates=3670, lr=4.78612e-05, gnorm=0.19, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7910
2023-02-20 15:27:34 - progress_bar.py[line:274] - INFO: epoch 001:   3682 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.8, ups=0.93, wpb=111.6, bsz=40, num_updates=3680, lr=4.79917e-05, gnorm=0.216, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7920
2023-02-20 15:27:45 - progress_bar.py[line:274] - INFO: epoch 001:   3692 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.93, wpb=110.7, bsz=40, num_updates=3690, lr=4.81221e-05, gnorm=0.191, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=7931
2023-02-20 15:27:56 - progress_bar.py[line:274] - INFO: epoch 001:   3702 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=3700, lr=4.82525e-05, gnorm=0.167, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7942
2023-02-20 15:28:07 - progress_bar.py[line:274] - INFO: epoch 001:   3712 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.88, wpb=111.7, bsz=40, num_updates=3710, lr=4.83829e-05, gnorm=0.189, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7954
2023-02-20 15:28:18 - progress_bar.py[line:274] - INFO: epoch 001:   3722 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=3720, lr=4.85133e-05, gnorm=0.205, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7965
2023-02-20 15:28:30 - progress_bar.py[line:274] - INFO: epoch 001:   3732 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=3730, lr=4.86437e-05, gnorm=0.345, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7976
2023-02-20 15:28:41 - progress_bar.py[line:274] - INFO: epoch 001:   3742 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=3740, lr=4.87741e-05, gnorm=0.161, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7987
2023-02-20 15:28:52 - progress_bar.py[line:274] - INFO: epoch 001:   3752 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.9, wpb=110.9, bsz=40, num_updates=3750, lr=4.89045e-05, gnorm=0.22, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7998
2023-02-20 15:29:03 - progress_bar.py[line:274] - INFO: epoch 001:   3762 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.5, bsz=40, num_updates=3760, lr=4.9035e-05, gnorm=0.217, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8009
2023-02-20 15:29:14 - progress_bar.py[line:274] - INFO: epoch 001:   3772 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.3, bsz=40, num_updates=3770, lr=4.91654e-05, gnorm=0.209, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=8021
2023-02-20 15:29:25 - progress_bar.py[line:274] - INFO: epoch 001:   3782 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=112.1, bsz=40, num_updates=3780, lr=4.92958e-05, gnorm=0.256, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8032
2023-02-20 15:29:36 - progress_bar.py[line:274] - INFO: epoch 001:   3792 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.89, wpb=112.5, bsz=40, num_updates=3790, lr=4.94262e-05, gnorm=0.178, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8043
2023-02-20 15:29:48 - progress_bar.py[line:274] - INFO: epoch 001:   3802 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.7, bsz=40, num_updates=3800, lr=4.95566e-05, gnorm=0.165, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=8054
2023-02-20 15:29:59 - progress_bar.py[line:274] - INFO: epoch 001:   3812 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110, bsz=40, num_updates=3810, lr=4.9687e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8065
2023-02-20 15:30:10 - progress_bar.py[line:274] - INFO: epoch 001:   3822 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.6, bsz=40, num_updates=3820, lr=4.98174e-05, gnorm=0.185, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=8076
2023-02-20 15:30:21 - progress_bar.py[line:274] - INFO: epoch 001:   3832 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.5, bsz=40, num_updates=3830, lr=4.99478e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=8088
2023-02-20 15:30:32 - progress_bar.py[line:274] - INFO: epoch 001:   3842 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112.1, bsz=40, num_updates=3840, lr=4.99978e-05, gnorm=0.366, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=8099
2023-02-20 15:30:44 - progress_bar.py[line:274] - INFO: epoch 001:   3852 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=3850, lr=4.99942e-05, gnorm=0.265, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=8110
2023-02-20 15:30:55 - progress_bar.py[line:274] - INFO: epoch 001:   3862 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=3860, lr=4.99906e-05, gnorm=0.177, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=8121
2023-02-20 15:31:06 - progress_bar.py[line:274] - INFO: epoch 001:   3872 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=113.8, nsentences=40, sample_size=113.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.91, wpb=113.8, bsz=40, num_updates=3870, lr=4.9987e-05, gnorm=0.191, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8132
2023-02-20 15:31:17 - progress_bar.py[line:274] - INFO: epoch 001:   3882 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.4, bsz=40, num_updates=3880, lr=4.99834e-05, gnorm=0.129, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=8143
2023-02-20 15:31:28 - progress_bar.py[line:274] - INFO: epoch 001:   3892 / 71012 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.9, wpb=112.7, bsz=40, num_updates=3890, lr=4.99797e-05, gnorm=0.331, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=8154
2023-02-20 15:31:39 - progress_bar.py[line:274] - INFO: epoch 001:   3902 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.8, ups=0.92, wpb=112.8, bsz=40, num_updates=3900, lr=4.99761e-05, gnorm=0.167, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=8165
2023-02-20 15:31:44 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 15:31:51 - progress_bar.py[line:274] - INFO: epoch 001:   3913 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.6, ups=0.83, wpb=110.3, bsz=40, num_updates=3910, lr=4.99725e-05, gnorm=0.238, clip=0, loss_scale=2048, train_wall=12, gb_free=11, ema_decay=0.9999, wall=8177
2023-02-20 15:32:02 - progress_bar.py[line:274] - INFO: epoch 001:   3923 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.9, ups=0.91, wpb=111.9, bsz=40, num_updates=3920, lr=4.99689e-05, gnorm=0.253, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=8188
2023-02-20 15:32:13 - progress_bar.py[line:274] - INFO: epoch 001:   3933 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=3930, lr=4.99653e-05, gnorm=0.208, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8200
2023-02-20 15:32:24 - progress_bar.py[line:274] - INFO: epoch 001:   3943 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.91, wpb=109.8, bsz=40, num_updates=3940, lr=4.99616e-05, gnorm=0.238, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=8211
2023-02-20 15:32:35 - progress_bar.py[line:274] - INFO: epoch 001:   3953 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.92, wpb=111.9, bsz=40, num_updates=3950, lr=4.9958e-05, gnorm=0.169, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=8221
2023-02-20 15:32:46 - progress_bar.py[line:274] - INFO: epoch 001:   3963 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.8, ups=0.92, wpb=110.8, bsz=40, num_updates=3960, lr=4.99544e-05, gnorm=0.319, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=8232
2023-02-20 15:32:57 - progress_bar.py[line:274] - INFO: epoch 001:   3973 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=111, bsz=40, num_updates=3970, lr=4.99508e-05, gnorm=0.263, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8244
2023-02-20 15:33:08 - progress_bar.py[line:274] - INFO: epoch 001:   3983 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.2, ups=0.92, wpb=112.4, bsz=40, num_updates=3980, lr=4.99472e-05, gnorm=0.166, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8255
2023-02-20 15:33:20 - progress_bar.py[line:274] - INFO: epoch 001:   3993 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.7, ups=0.87, wpb=112.3, bsz=40, num_updates=3990, lr=4.99436e-05, gnorm=0.201, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=8266
2023-02-20 15:33:31 - progress_bar.py[line:274] - INFO: epoch 001:   4003 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=4000, lr=4.99399e-05, gnorm=0.188, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=8277
2023-02-20 15:33:31 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-20 15:33:32 - train.py[line:549] - INFO: 0 / 6234
2023-02-20 15:33:32 - train.py[line:551] - INFO: load:1.02 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-20 15:35:34 - train.py[line:549] - INFO: 200 / 6234
2023-02-20 15:35:34 - train.py[line:551] - INFO: load:1.05 valid_run:121.91 task_valid:118.81 collect_output:2.03
2023-02-20 15:37:34 - train.py[line:549] - INFO: 400 / 6234
2023-02-20 15:37:34 - train.py[line:551] - INFO: load:1.07 valid_run:241.41 task_valid:234.29 collect_output:5.03
2023-02-20 15:39:36 - train.py[line:549] - INFO: 600 / 6234
2023-02-20 15:39:36 - train.py[line:551] - INFO: load:1.09 valid_run:363.50 task_valid:350.41 collect_output:9.96
2023-02-20 15:41:37 - train.py[line:549] - INFO: 800 / 6234
2023-02-20 15:41:37 - train.py[line:551] - INFO: load:1.12 valid_run:485.00 task_valid:463.84 collect_output:16.99
2023-02-20 15:43:38 - train.py[line:549] - INFO: 1000 / 6234
2023-02-20 15:43:38 - train.py[line:551] - INFO: load:1.14 valid_run:605.30 task_valid:580.89 collect_output:19.21
2023-02-20 15:45:40 - train.py[line:549] - INFO: 1200 / 6234
2023-02-20 15:45:40 - train.py[line:551] - INFO: load:1.17 valid_run:727.82 task_valid:699.25 collect_output:22.32
2023-02-20 15:47:43 - train.py[line:549] - INFO: 1400 / 6234
2023-02-20 15:47:43 - train.py[line:551] - INFO: load:1.19 valid_run:850.37 task_valid:816.83 collect_output:26.26
2023-02-20 15:49:45 - train.py[line:549] - INFO: 1600 / 6234
2023-02-20 15:49:45 - train.py[line:551] - INFO: load:1.22 valid_run:971.97 task_valid:933.25 collect_output:30.40
2023-02-20 15:51:48 - train.py[line:549] - INFO: 1800 / 6234
2023-02-20 15:51:48 - train.py[line:551] - INFO: load:1.24 valid_run:1095.25 task_valid:1050.02 collect_output:35.91
2023-02-20 15:53:49 - train.py[line:549] - INFO: 2000 / 6234
2023-02-20 15:53:49 - train.py[line:551] - INFO: load:1.26 valid_run:1216.43 task_valid:1162.30 collect_output:43.81
2023-02-20 15:55:49 - train.py[line:549] - INFO: 2200 / 6234
2023-02-20 15:55:49 - train.py[line:551] - INFO: load:1.29 valid_run:1336.17 task_valid:1277.66 collect_output:47.15
2023-02-20 15:57:50 - train.py[line:549] - INFO: 2400 / 6234
2023-02-20 15:57:50 - train.py[line:551] - INFO: load:1.31 valid_run:1457.37 task_valid:1394.41 collect_output:50.56
2023-02-20 15:59:49 - train.py[line:549] - INFO: 2600 / 6234
2023-02-20 15:59:49 - train.py[line:551] - INFO: load:1.34 valid_run:1575.97 task_valid:1508.01 collect_output:54.47
2023-02-20 16:01:50 - train.py[line:549] - INFO: 2800 / 6234
2023-02-20 16:01:50 - train.py[line:551] - INFO: load:1.36 valid_run:1696.74 task_valid:1625.55 collect_output:56.66
2023-02-20 16:03:51 - train.py[line:549] - INFO: 3000 / 6234
2023-02-20 16:03:51 - train.py[line:551] - INFO: load:1.39 valid_run:1817.55 task_valid:1741.57 collect_output:60.40
2023-02-20 16:05:51 - train.py[line:549] - INFO: 3200 / 6234
2023-02-20 16:05:51 - train.py[line:551] - INFO: load:1.41 valid_run:1938.19 task_valid:1855.36 collect_output:66.18
2023-02-20 16:07:52 - train.py[line:549] - INFO: 3400 / 6234
2023-02-20 16:07:52 - train.py[line:551] - INFO: load:1.44 valid_run:2059.25 task_valid:1971.22 collect_output:70.33
2023-02-20 16:09:53 - train.py[line:549] - INFO: 3600 / 6234
2023-02-20 16:09:53 - train.py[line:551] - INFO: load:1.46 valid_run:2179.74 task_valid:2088.96 collect_output:72.00
2023-02-20 16:11:54 - train.py[line:549] - INFO: 3800 / 6234
2023-02-20 16:11:54 - train.py[line:551] - INFO: load:1.49 valid_run:2300.74 task_valid:2205.78 collect_output:75.13
2023-02-20 16:13:54 - train.py[line:549] - INFO: 4000 / 6234
2023-02-20 16:13:54 - train.py[line:551] - INFO: load:1.51 valid_run:2420.74 task_valid:2322.14 collect_output:77.72
2023-02-20 16:15:56 - train.py[line:549] - INFO: 4200 / 6234
2023-02-20 16:15:56 - train.py[line:551] - INFO: load:1.53 valid_run:2542.09 task_valid:2438.59 collect_output:81.57
2023-02-20 16:17:57 - train.py[line:549] - INFO: 4400 / 6234
2023-02-20 16:17:57 - train.py[line:551] - INFO: load:1.56 valid_run:2663.86 task_valid:2557.45 collect_output:83.38
2023-02-20 16:19:57 - train.py[line:549] - INFO: 4600 / 6234
2023-02-20 16:19:57 - train.py[line:551] - INFO: load:1.58 valid_run:2783.79 task_valid:2671.62 collect_output:88.08
2023-02-20 16:21:57 - train.py[line:549] - INFO: 4800 / 6234
2023-02-20 16:21:57 - train.py[line:551] - INFO: load:1.62 valid_run:2903.17 task_valid:2787.52 collect_output:90.45
2023-02-20 16:23:58 - train.py[line:549] - INFO: 5000 / 6234
2023-02-20 16:23:58 - train.py[line:551] - INFO: load:1.64 valid_run:3024.39 task_valid:2903.47 collect_output:94.63
2023-02-20 16:26:01 - train.py[line:549] - INFO: 5200 / 6234
2023-02-20 16:26:01 - train.py[line:551] - INFO: load:1.67 valid_run:3146.88 task_valid:3019.21 collect_output:100.31
2023-02-20 16:28:00 - train.py[line:549] - INFO: 5400 / 6234
2023-02-20 16:28:00 - train.py[line:551] - INFO: load:1.69 valid_run:3266.36 task_valid:3133.33 collect_output:104.56
2023-02-20 16:30:02 - train.py[line:549] - INFO: 5600 / 6234
2023-02-20 16:30:02 - train.py[line:551] - INFO: load:1.72 valid_run:3388.12 task_valid:3252.66 collect_output:105.91
2023-02-20 16:32:03 - train.py[line:549] - INFO: 5800 / 6234
2023-02-20 16:32:03 - train.py[line:551] - INFO: load:1.74 valid_run:3509.40 task_valid:3368.11 collect_output:110.63
2023-02-20 16:34:05 - train.py[line:549] - INFO: 6000 / 6234
2023-02-20 16:34:05 - train.py[line:551] - INFO: load:1.77 valid_run:3630.78 task_valid:3486.19 collect_output:112.89
2023-02-20 16:36:06 - train.py[line:549] - INFO: 6200 / 6234
2023-02-20 16:36:06 - train.py[line:551] - INFO: load:1.80 valid_run:3751.84 task_valid:3604.61 collect_output:114.47

====================================================================================================
SGG eval:     R @ 50: 0.5671;     R @ 100: 0.6033;     R @ 500: 0.6481;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3435;    mR @ 100: 0.3939;    mR @ 500: 0.4382;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5732) (covered in:0.1250) (covering:0.3714) (eating:0.7059) (flying in:0.8182) (growing on:0.2500) (hanging from:0.5323) (lying on:0.2000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9167) (playing:0.0000) (riding:0.9379) (says:0.0000) (sitting on:0.5967) (standing on:0.4693) (using:0.3000) (walking in:0.0000) (walking on:0.5541) (watching:0.3611) 
--------------------------------------------------------
====================================================================================================

2023-02-20 16:36:36 - train.py[line:487] - INFO: 0.603268525592055

====================================================================================================
SGG eval:     R @ 50: 0.5671;     R @ 100: 0.6033;     R @ 500: 0.6481;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3435;    mR @ 100: 0.3939;    mR @ 500: 0.4382;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5732) (covered in:0.1250) (covering:0.3714) (eating:0.7059) (flying in:0.8182) (growing on:0.2500) (hanging from:0.5323) (lying on:0.2000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9167) (playing:0.0000) (riding:0.9379) (says:0.0000) (sitting on:0.5967) (standing on:0.4693) (using:0.3000) (walking in:0.0000) (walking on:0.5541) (watching:0.3611) 
--------------------------------------------------------
====================================================================================================

2023-02-20 16:36:36 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-20 16:36:37 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.247 | loss_v1 0 | loss_v2 0 | nll_loss 0.08 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.603269 | ppl 1.06 | vqa_score 0.1926 | wps 118.5 | wpb 72 | bsz 24 | num_updates 4000 | best_R@100 0.603269
2023-02-20 16:36:37 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2023-02-20 16:36:37 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_4000.pt
2023-02-20 16:36:42 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_4000.pt
2023-02-20 16:36:47 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.603268525592055) (writing took 10.918948791921139 seconds)
2023-02-20 16:36:58 - progress_bar.py[line:274] - INFO: epoch 001:   4013 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=0.3, ups=0, wpb=111.3, bsz=40, num_updates=4010, lr=4.99363e-05, gnorm=0.25, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12085
2023-02-20 16:37:09 - progress_bar.py[line:274] - INFO: epoch 001:   4023 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.9, bsz=40, num_updates=4020, lr=4.99327e-05, gnorm=0.205, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12096
2023-02-20 16:37:20 - progress_bar.py[line:274] - INFO: epoch 001:   4033 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.6, ups=0.92, wpb=111.3, bsz=40, num_updates=4030, lr=4.99291e-05, gnorm=0.181, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=12107
2023-02-20 16:37:31 - progress_bar.py[line:274] - INFO: epoch 001:   4043 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.4, bsz=40, num_updates=4040, lr=4.99255e-05, gnorm=0.21, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12118
2023-02-20 16:37:42 - progress_bar.py[line:274] - INFO: epoch 001:   4053 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.4, bsz=40, num_updates=4050, lr=4.99218e-05, gnorm=0.238, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12128
2023-02-20 16:37:53 - progress_bar.py[line:274] - INFO: epoch 001:   4063 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=4060, lr=4.99182e-05, gnorm=0.224, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12140
2023-02-20 16:38:05 - progress_bar.py[line:274] - INFO: epoch 001:   4073 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.87, wpb=112.7, bsz=40, num_updates=4070, lr=4.99146e-05, gnorm=0.176, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12151
2023-02-20 16:38:16 - progress_bar.py[line:274] - INFO: epoch 001:   4083 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=4080, lr=4.9911e-05, gnorm=0.161, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12162
2023-02-20 16:38:27 - progress_bar.py[line:274] - INFO: epoch 001:   4093 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.3, bsz=40, num_updates=4090, lr=4.99074e-05, gnorm=0.192, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=12174
2023-02-20 16:38:38 - progress_bar.py[line:274] - INFO: epoch 001:   4103 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=4100, lr=4.99038e-05, gnorm=0.155, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12185
2023-02-20 16:38:49 - progress_bar.py[line:274] - INFO: epoch 001:   4113 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.9, wpb=110, bsz=40, num_updates=4110, lr=4.99001e-05, gnorm=0.177, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=12196
2023-02-20 16:39:01 - progress_bar.py[line:274] - INFO: epoch 001:   4123 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.91, wpb=111.9, bsz=40, num_updates=4120, lr=4.98965e-05, gnorm=0.193, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12207
2023-02-20 16:39:12 - progress_bar.py[line:274] - INFO: epoch 001:   4133 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.9, wpb=111.5, bsz=40, num_updates=4130, lr=4.98929e-05, gnorm=0.181, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12218
2023-02-20 16:39:23 - progress_bar.py[line:274] - INFO: epoch 001:   4143 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.6, bsz=40, num_updates=4140, lr=4.98893e-05, gnorm=0.194, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12229
2023-02-20 16:39:34 - progress_bar.py[line:274] - INFO: epoch 001:   4153 / 71012 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.9, wpb=112.7, bsz=40, num_updates=4150, lr=4.98857e-05, gnorm=0.22, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12240
2023-02-20 16:39:45 - progress_bar.py[line:274] - INFO: epoch 001:   4163 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.3, bsz=40, num_updates=4160, lr=4.9882e-05, gnorm=0.227, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=12252
2023-02-20 16:39:57 - progress_bar.py[line:274] - INFO: epoch 001:   4173 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.6, bsz=40, num_updates=4170, lr=4.98784e-05, gnorm=0.177, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12263
2023-02-20 16:40:08 - progress_bar.py[line:274] - INFO: epoch 001:   4183 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.89, wpb=112.4, bsz=40, num_updates=4180, lr=4.98748e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12274
2023-02-20 16:40:19 - progress_bar.py[line:274] - INFO: epoch 001:   4193 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=4190, lr=4.98712e-05, gnorm=0.178, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12285
2023-02-20 16:40:30 - progress_bar.py[line:274] - INFO: epoch 001:   4203 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.91, wpb=109.8, bsz=40, num_updates=4200, lr=4.98676e-05, gnorm=0.289, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=12296
2023-02-20 16:40:41 - progress_bar.py[line:274] - INFO: epoch 001:   4213 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.2, bsz=40, num_updates=4210, lr=4.9864e-05, gnorm=0.175, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12307
2023-02-20 16:40:52 - progress_bar.py[line:274] - INFO: epoch 001:   4223 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111, bsz=40, num_updates=4220, lr=4.98603e-05, gnorm=0.132, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12318
2023-02-20 16:41:03 - progress_bar.py[line:274] - INFO: epoch 001:   4233 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.9, wpb=111.3, bsz=40, num_updates=4230, lr=4.98567e-05, gnorm=0.225, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12329
2023-02-20 16:41:14 - progress_bar.py[line:274] - INFO: epoch 001:   4243 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.6, bsz=40, num_updates=4240, lr=4.98531e-05, gnorm=0.158, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=12341
2023-02-20 16:41:25 - progress_bar.py[line:274] - INFO: epoch 001:   4253 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=4250, lr=4.98495e-05, gnorm=0.223, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12352
2023-02-20 16:41:37 - progress_bar.py[line:274] - INFO: epoch 001:   4263 / 71012 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.4, ups=0.9, wpb=113.2, bsz=40, num_updates=4260, lr=4.98459e-05, gnorm=0.188, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12363
2023-02-20 16:41:47 - progress_bar.py[line:274] - INFO: epoch 001:   4273 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.7, bsz=40, num_updates=4270, lr=4.98422e-05, gnorm=0.147, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12374
2023-02-20 16:41:58 - progress_bar.py[line:274] - INFO: epoch 001:   4283 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.91, wpb=109.2, bsz=40, num_updates=4280, lr=4.98386e-05, gnorm=0.178, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12385
2023-02-20 16:42:10 - progress_bar.py[line:274] - INFO: epoch 001:   4293 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.9, wpb=111.5, bsz=40, num_updates=4290, lr=4.9835e-05, gnorm=0.169, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12396
2023-02-20 16:42:21 - progress_bar.py[line:274] - INFO: epoch 001:   4303 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.2, bsz=40, num_updates=4300, lr=4.98314e-05, gnorm=0.147, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12407
2023-02-20 16:42:31 - progress_bar.py[line:274] - INFO: epoch 001:   4313 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=105.9, ups=0.94, wpb=112.1, bsz=40, num_updates=4310, lr=4.98278e-05, gnorm=0.186, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12418
2023-02-20 16:42:43 - progress_bar.py[line:274] - INFO: epoch 001:   4323 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=4320, lr=4.98242e-05, gnorm=0.181, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12429
2023-02-20 16:42:54 - progress_bar.py[line:274] - INFO: epoch 001:   4333 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.9, wpb=110.9, bsz=40, num_updates=4330, lr=4.98205e-05, gnorm=0.249, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12440
2023-02-20 16:43:05 - progress_bar.py[line:274] - INFO: epoch 001:   4343 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.5, bsz=40, num_updates=4340, lr=4.98169e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=12451
2023-02-20 16:43:16 - progress_bar.py[line:274] - INFO: epoch 001:   4353 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.9, wpb=110.2, bsz=40, num_updates=4350, lr=4.98133e-05, gnorm=0.186, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12462
2023-02-20 16:43:27 - progress_bar.py[line:274] - INFO: epoch 001:   4363 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=4360, lr=4.98097e-05, gnorm=0.213, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12474
2023-02-20 16:43:38 - progress_bar.py[line:274] - INFO: epoch 001:   4373 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=4370, lr=4.98061e-05, gnorm=0.204, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12485
2023-02-20 16:43:49 - progress_bar.py[line:274] - INFO: epoch 001:   4383 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.92, wpb=113, bsz=40, num_updates=4380, lr=4.98024e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12496
2023-02-20 16:44:00 - progress_bar.py[line:274] - INFO: epoch 001:   4393 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.7, bsz=40, num_updates=4390, lr=4.97988e-05, gnorm=0.145, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12507
2023-02-20 16:44:11 - progress_bar.py[line:274] - INFO: epoch 001:   4403 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.8, bsz=40, num_updates=4400, lr=4.97952e-05, gnorm=0.15, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12518
2023-02-20 16:44:22 - progress_bar.py[line:274] - INFO: epoch 001:   4413 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.8, bsz=40, num_updates=4410, lr=4.97916e-05, gnorm=0.199, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12529
2023-02-20 16:44:34 - progress_bar.py[line:274] - INFO: epoch 001:   4423 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.3, bsz=40, num_updates=4420, lr=4.9788e-05, gnorm=0.163, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12540
2023-02-20 16:44:45 - progress_bar.py[line:274] - INFO: epoch 001:   4433 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111, bsz=40, num_updates=4430, lr=4.97844e-05, gnorm=0.166, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12551
2023-02-20 16:44:56 - progress_bar.py[line:274] - INFO: epoch 001:   4443 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.3, bsz=40, num_updates=4440, lr=4.97807e-05, gnorm=0.165, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12562
2023-02-20 16:45:07 - progress_bar.py[line:274] - INFO: epoch 001:   4453 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.2, bsz=40, num_updates=4450, lr=4.97771e-05, gnorm=0.128, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12574
2023-02-20 16:45:19 - progress_bar.py[line:274] - INFO: epoch 001:   4463 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.9, bsz=40, num_updates=4460, lr=4.97735e-05, gnorm=0.101, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12585
2023-02-20 16:45:30 - progress_bar.py[line:274] - INFO: epoch 001:   4473 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.4, bsz=40, num_updates=4470, lr=4.97699e-05, gnorm=0.144, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12596
2023-02-20 16:45:41 - progress_bar.py[line:274] - INFO: epoch 001:   4483 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111.2, bsz=40, num_updates=4480, lr=4.97663e-05, gnorm=0.173, clip=0, loss_scale=4096, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=12607
2023-02-20 16:45:50 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 16:45:53 - progress_bar.py[line:274] - INFO: epoch 001:   4494 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=95.6, ups=0.85, wpb=112.3, bsz=40, num_updates=4490, lr=4.97626e-05, gnorm=0.27, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12619
2023-02-20 16:46:03 - progress_bar.py[line:274] - INFO: epoch 001:   4504 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.6, ups=0.93, wpb=112.2, bsz=40, num_updates=4500, lr=4.9759e-05, gnorm=0.169, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12630
2023-02-20 16:46:14 - progress_bar.py[line:274] - INFO: epoch 001:   4514 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.6, ups=0.92, wpb=111.6, bsz=40, num_updates=4510, lr=4.97554e-05, gnorm=0.197, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=12641
2023-02-20 16:46:26 - progress_bar.py[line:274] - INFO: epoch 001:   4524 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.5, bsz=40, num_updates=4520, lr=4.97518e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12652
2023-02-20 16:46:37 - progress_bar.py[line:274] - INFO: epoch 001:   4534 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.87, wpb=112.3, bsz=40, num_updates=4530, lr=4.97482e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12664
2023-02-20 16:46:48 - progress_bar.py[line:274] - INFO: epoch 001:   4544 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.92, wpb=112.7, bsz=40, num_updates=4540, lr=4.97446e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12674
2023-02-20 16:46:59 - progress_bar.py[line:274] - INFO: epoch 001:   4554 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.9, wpb=111.5, bsz=40, num_updates=4550, lr=4.97409e-05, gnorm=0.236, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12686
2023-02-20 16:47:10 - progress_bar.py[line:274] - INFO: epoch 001:   4564 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.5, ups=0.92, wpb=111.5, bsz=40, num_updates=4560, lr=4.97373e-05, gnorm=0.19, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=12696
2023-02-20 16:47:21 - progress_bar.py[line:274] - INFO: epoch 001:   4574 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.9, wpb=111.7, bsz=40, num_updates=4570, lr=4.97337e-05, gnorm=0.168, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12708
2023-02-20 16:47:32 - progress_bar.py[line:274] - INFO: epoch 001:   4584 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.92, wpb=112.4, bsz=40, num_updates=4580, lr=4.97301e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12718
2023-02-20 16:47:43 - progress_bar.py[line:274] - INFO: epoch 001:   4594 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.7, bsz=40, num_updates=4590, lr=4.97265e-05, gnorm=0.16, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12730
2023-02-20 16:47:55 - progress_bar.py[line:274] - INFO: epoch 001:   4604 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.8, bsz=40, num_updates=4600, lr=4.97228e-05, gnorm=0.185, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=12741
2023-02-20 16:48:06 - progress_bar.py[line:274] - INFO: epoch 001:   4614 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112.6, bsz=40, num_updates=4610, lr=4.97192e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12752
2023-02-20 16:48:17 - progress_bar.py[line:274] - INFO: epoch 001:   4624 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.91, wpb=110.7, bsz=40, num_updates=4620, lr=4.97156e-05, gnorm=0.203, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12763
2023-02-20 16:48:28 - progress_bar.py[line:274] - INFO: epoch 001:   4634 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.89, wpb=112.4, bsz=40, num_updates=4630, lr=4.9712e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12774
2023-02-20 16:48:42 - progress_bar.py[line:274] - INFO: epoch 001:   4644 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.3, bsz=40, num_updates=4640, lr=4.97084e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12786
2023-02-20 16:48:55 - progress_bar.py[line:274] - INFO: epoch 001:   4654 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=112.4, bsz=40, num_updates=4650, lr=4.97048e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12802
2023-02-20 16:49:06 - progress_bar.py[line:274] - INFO: epoch 001:   4664 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.9, bsz=40, num_updates=4660, lr=4.97011e-05, gnorm=0.16, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=12812
2023-02-20 16:49:17 - progress_bar.py[line:274] - INFO: epoch 001:   4674 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.94, wpb=111.3, bsz=40, num_updates=4670, lr=4.96975e-05, gnorm=0.223, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12823
2023-02-20 16:49:28 - progress_bar.py[line:274] - INFO: epoch 001:   4684 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.9, wpb=112.6, bsz=40, num_updates=4680, lr=4.96939e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12834
2023-02-20 16:49:38 - progress_bar.py[line:274] - INFO: epoch 001:   4694 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.6, ups=0.94, wpb=111.9, bsz=40, num_updates=4690, lr=4.96903e-05, gnorm=0.204, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12845
2023-02-20 16:49:50 - progress_bar.py[line:274] - INFO: epoch 001:   4704 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.7, bsz=40, num_updates=4700, lr=4.96867e-05, gnorm=0.17, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12856
2023-02-20 16:50:01 - progress_bar.py[line:274] - INFO: epoch 001:   4714 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.2, bsz=40, num_updates=4710, lr=4.9683e-05, gnorm=0.246, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12867
2023-02-20 16:50:12 - progress_bar.py[line:274] - INFO: epoch 001:   4724 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.3, ups=0.93, wpb=112.1, bsz=40, num_updates=4720, lr=4.96794e-05, gnorm=0.169, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12878
2023-02-20 16:50:23 - progress_bar.py[line:274] - INFO: epoch 001:   4734 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=4730, lr=4.96758e-05, gnorm=0.197, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12889
2023-02-20 16:50:34 - progress_bar.py[line:274] - INFO: epoch 001:   4744 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=4740, lr=4.96722e-05, gnorm=0.17, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12901
2023-02-20 16:50:45 - progress_bar.py[line:274] - INFO: epoch 001:   4754 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.91, wpb=111.2, bsz=40, num_updates=4750, lr=4.96686e-05, gnorm=0.173, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12912
2023-02-20 16:50:47 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-02-20 16:50:57 - progress_bar.py[line:274] - INFO: epoch 001:   4765 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91.3, ups=0.82, wpb=111.3, bsz=40, num_updates=4760, lr=4.9665e-05, gnorm=0.209, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12924
2023-02-20 16:51:08 - progress_bar.py[line:274] - INFO: epoch 001:   4775 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.92, wpb=112.7, bsz=40, num_updates=4770, lr=4.96613e-05, gnorm=0.12, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12935
2023-02-20 16:51:19 - progress_bar.py[line:274] - INFO: epoch 001:   4785 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=111.9, bsz=40, num_updates=4780, lr=4.96577e-05, gnorm=0.098, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12946
2023-02-20 16:51:30 - progress_bar.py[line:274] - INFO: epoch 001:   4795 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.92, wpb=110.9, bsz=40, num_updates=4790, lr=4.96541e-05, gnorm=0.175, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12957
2023-02-20 16:51:42 - progress_bar.py[line:274] - INFO: epoch 001:   4805 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.87, wpb=112.2, bsz=40, num_updates=4800, lr=4.96505e-05, gnorm=0.163, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12968
2023-02-20 16:51:53 - progress_bar.py[line:274] - INFO: epoch 001:   4815 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.1, bsz=40, num_updates=4810, lr=4.96469e-05, gnorm=0.124, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=12979
2023-02-20 16:52:04 - progress_bar.py[line:274] - INFO: epoch 001:   4825 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.4, ups=0.9, wpb=113.3, bsz=40, num_updates=4820, lr=4.96432e-05, gnorm=0.208, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=12990
2023-02-20 16:52:15 - progress_bar.py[line:274] - INFO: epoch 001:   4835 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.89, wpb=112.4, bsz=40, num_updates=4830, lr=4.96396e-05, gnorm=0.167, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13002
2023-02-20 16:52:26 - progress_bar.py[line:274] - INFO: epoch 001:   4845 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.89, wpb=112.2, bsz=40, num_updates=4840, lr=4.9636e-05, gnorm=0.197, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=13013
2023-02-20 16:52:37 - progress_bar.py[line:274] - INFO: epoch 001:   4855 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=113, bsz=40, num_updates=4850, lr=4.96324e-05, gnorm=0.198, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13024
2023-02-20 16:52:49 - progress_bar.py[line:274] - INFO: epoch 001:   4865 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=4860, lr=4.96288e-05, gnorm=0.128, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13035
2023-02-20 16:53:00 - progress_bar.py[line:274] - INFO: epoch 001:   4875 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.4, ups=0.87, wpb=110.4, bsz=40, num_updates=4870, lr=4.96252e-05, gnorm=0.182, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13046
2023-02-20 16:53:11 - progress_bar.py[line:274] - INFO: epoch 001:   4885 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=4880, lr=4.96215e-05, gnorm=0.122, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=13058
2023-02-20 16:53:22 - progress_bar.py[line:274] - INFO: epoch 001:   4895 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.1, ups=0.93, wpb=112.7, bsz=40, num_updates=4890, lr=4.96179e-05, gnorm=0.157, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13068
2023-02-20 16:53:33 - progress_bar.py[line:274] - INFO: epoch 001:   4905 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.92, wpb=112.3, bsz=40, num_updates=4900, lr=4.96143e-05, gnorm=0.123, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=13079
2023-02-20 16:53:44 - progress_bar.py[line:274] - INFO: epoch 001:   4915 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=111.9, bsz=40, num_updates=4910, lr=4.96107e-05, gnorm=0.154, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13090
2023-02-20 16:53:55 - progress_bar.py[line:274] - INFO: epoch 001:   4925 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.9, wpb=112.3, bsz=40, num_updates=4920, lr=4.96071e-05, gnorm=0.183, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13102
2023-02-20 16:54:06 - progress_bar.py[line:274] - INFO: epoch 001:   4935 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.1, ups=0.9, wpb=112.8, bsz=40, num_updates=4930, lr=4.96034e-05, gnorm=0.175, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13113
2023-02-20 16:54:17 - progress_bar.py[line:274] - INFO: epoch 001:   4945 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.9, wpb=112.8, bsz=40, num_updates=4940, lr=4.95998e-05, gnorm=0.166, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13124
2023-02-20 16:54:28 - progress_bar.py[line:274] - INFO: epoch 001:   4955 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.2, ups=0.95, wpb=111.2, bsz=40, num_updates=4950, lr=4.95962e-05, gnorm=0.261, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13134
2023-02-20 16:54:39 - progress_bar.py[line:274] - INFO: epoch 001:   4965 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.9, bsz=40, num_updates=4960, lr=4.95926e-05, gnorm=0.256, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13146
2023-02-20 16:54:50 - progress_bar.py[line:274] - INFO: epoch 001:   4975 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=4970, lr=4.9589e-05, gnorm=0.174, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13157
2023-02-20 16:55:01 - progress_bar.py[line:274] - INFO: epoch 001:   4985 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=4980, lr=4.95854e-05, gnorm=0.211, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13168
2023-02-20 16:55:13 - progress_bar.py[line:274] - INFO: epoch 001:   4995 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.7, bsz=40, num_updates=4990, lr=4.95817e-05, gnorm=0.129, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13179
2023-02-20 16:55:24 - progress_bar.py[line:274] - INFO: epoch 001:   5005 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=5000, lr=4.95781e-05, gnorm=0.184, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=13190
2023-02-20 16:55:35 - progress_bar.py[line:274] - INFO: epoch 001:   5015 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.9, wpb=111.1, bsz=40, num_updates=5010, lr=4.95745e-05, gnorm=0.204, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13201
2023-02-20 16:55:46 - progress_bar.py[line:274] - INFO: epoch 001:   5025 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.8, bsz=40, num_updates=5020, lr=4.95709e-05, gnorm=0.178, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13212
2023-02-20 16:55:57 - progress_bar.py[line:274] - INFO: epoch 001:   5035 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=5030, lr=4.95673e-05, gnorm=0.152, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13224
2023-02-20 16:56:08 - progress_bar.py[line:274] - INFO: epoch 001:   5045 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=5040, lr=4.95636e-05, gnorm=0.143, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13235
2023-02-20 16:56:20 - progress_bar.py[line:274] - INFO: epoch 001:   5055 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.8, bsz=40, num_updates=5050, lr=4.956e-05, gnorm=0.196, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=13246
2023-02-20 16:56:31 - progress_bar.py[line:274] - INFO: epoch 001:   5065 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112.9, bsz=40, num_updates=5060, lr=4.95564e-05, gnorm=0.252, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=13257
2023-02-20 16:56:42 - progress_bar.py[line:274] - INFO: epoch 001:   5075 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=5070, lr=4.95528e-05, gnorm=0.186, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13269
2023-02-20 16:56:53 - progress_bar.py[line:274] - INFO: epoch 001:   5085 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.4, bsz=40, num_updates=5080, lr=4.95492e-05, gnorm=0.168, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13280
2023-02-20 16:57:05 - progress_bar.py[line:274] - INFO: epoch 001:   5095 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111, bsz=40, num_updates=5090, lr=4.95456e-05, gnorm=0.163, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13291
2023-02-20 16:57:16 - progress_bar.py[line:274] - INFO: epoch 001:   5105 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.92, wpb=112, bsz=40, num_updates=5100, lr=4.95419e-05, gnorm=0.144, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13302
2023-02-20 16:57:27 - progress_bar.py[line:274] - INFO: epoch 001:   5115 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=5110, lr=4.95383e-05, gnorm=0.129, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13313
2023-02-20 16:57:38 - progress_bar.py[line:274] - INFO: epoch 001:   5125 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.87, wpb=111.1, bsz=40, num_updates=5120, lr=4.95347e-05, gnorm=0.239, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13325
2023-02-20 16:57:50 - progress_bar.py[line:274] - INFO: epoch 001:   5135 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.7, bsz=40, num_updates=5130, lr=4.95311e-05, gnorm=0.21, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13336
2023-02-20 16:58:01 - progress_bar.py[line:274] - INFO: epoch 001:   5145 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.89, wpb=112, bsz=40, num_updates=5140, lr=4.95275e-05, gnorm=0.208, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=13347
2023-02-20 16:58:12 - progress_bar.py[line:274] - INFO: epoch 001:   5155 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.5, bsz=40, num_updates=5150, lr=4.95238e-05, gnorm=0.129, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=13358
2023-02-20 16:58:23 - progress_bar.py[line:274] - INFO: epoch 001:   5165 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=5160, lr=4.95202e-05, gnorm=0.18, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13369
2023-02-20 16:58:34 - progress_bar.py[line:274] - INFO: epoch 001:   5175 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.9, wpb=111.9, bsz=40, num_updates=5170, lr=4.95166e-05, gnorm=0.171, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13380
2023-02-20 16:58:45 - progress_bar.py[line:274] - INFO: epoch 001:   5185 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.3, bsz=40, num_updates=5180, lr=4.9513e-05, gnorm=0.164, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13392
2023-02-20 16:58:56 - progress_bar.py[line:274] - INFO: epoch 001:   5195 / 71012 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=5190, lr=4.95094e-05, gnorm=0.198, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13403
2023-02-20 16:59:08 - progress_bar.py[line:274] - INFO: epoch 001:   5205 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=112, bsz=40, num_updates=5200, lr=4.95058e-05, gnorm=0.153, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13414
2023-02-20 16:59:19 - progress_bar.py[line:274] - INFO: epoch 001:   5215 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.2, bsz=40, num_updates=5210, lr=4.95021e-05, gnorm=0.143, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13426
2023-02-20 16:59:30 - progress_bar.py[line:274] - INFO: epoch 001:   5225 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=5220, lr=4.94985e-05, gnorm=0.181, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=13437
2023-02-20 16:59:41 - progress_bar.py[line:274] - INFO: epoch 001:   5235 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.7, ups=0.91, wpb=112.2, bsz=40, num_updates=5230, lr=4.94949e-05, gnorm=0.165, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13448
2023-02-20 16:59:53 - progress_bar.py[line:274] - INFO: epoch 001:   5245 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.89, wpb=112.7, bsz=40, num_updates=5240, lr=4.94913e-05, gnorm=0.171, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13459
2023-02-20 17:00:04 - progress_bar.py[line:274] - INFO: epoch 001:   5255 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112.7, bsz=40, num_updates=5250, lr=4.94877e-05, gnorm=0.142, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13470
2023-02-20 17:00:15 - progress_bar.py[line:274] - INFO: epoch 001:   5265 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.4, bsz=40, num_updates=5260, lr=4.9484e-05, gnorm=0.132, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13481
2023-02-20 17:00:26 - progress_bar.py[line:274] - INFO: epoch 001:   5275 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.89, wpb=110.7, bsz=40, num_updates=5270, lr=4.94804e-05, gnorm=0.19, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13493
2023-02-20 17:00:37 - progress_bar.py[line:274] - INFO: epoch 001:   5285 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.8, ups=0.93, wpb=111.4, bsz=40, num_updates=5280, lr=4.94768e-05, gnorm=0.131, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13503
2023-02-20 17:00:48 - progress_bar.py[line:274] - INFO: epoch 001:   5295 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=5290, lr=4.94732e-05, gnorm=0.205, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13514
2023-02-20 17:00:59 - progress_bar.py[line:274] - INFO: epoch 001:   5305 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.6, ups=0.91, wpb=112.2, bsz=40, num_updates=5300, lr=4.94696e-05, gnorm=0.181, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13525
2023-02-20 17:01:10 - progress_bar.py[line:274] - INFO: epoch 001:   5315 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.6, bsz=40, num_updates=5310, lr=4.9466e-05, gnorm=0.249, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13536
2023-02-20 17:01:21 - progress_bar.py[line:274] - INFO: epoch 001:   5325 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.9, wpb=111.4, bsz=40, num_updates=5320, lr=4.94623e-05, gnorm=0.131, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13548
2023-02-20 17:01:32 - progress_bar.py[line:274] - INFO: epoch 001:   5335 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112.8, bsz=40, num_updates=5330, lr=4.94587e-05, gnorm=0.163, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=13559
2023-02-20 17:01:43 - progress_bar.py[line:274] - INFO: epoch 001:   5345 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.7, ups=0.92, wpb=112.1, bsz=40, num_updates=5340, lr=4.94551e-05, gnorm=0.209, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13570
2023-02-20 17:01:55 - progress_bar.py[line:274] - INFO: epoch 001:   5355 / 71012 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=5350, lr=4.94515e-05, gnorm=0.235, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13581
2023-02-20 17:02:06 - progress_bar.py[line:274] - INFO: epoch 001:   5365 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.89, wpb=111.7, bsz=40, num_updates=5360, lr=4.94479e-05, gnorm=0.203, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13592
2023-02-20 17:02:17 - progress_bar.py[line:274] - INFO: epoch 001:   5375 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112.1, bsz=40, num_updates=5370, lr=4.94442e-05, gnorm=0.148, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13603
2023-02-20 17:02:28 - progress_bar.py[line:274] - INFO: epoch 001:   5385 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.9, wpb=112.8, bsz=40, num_updates=5380, lr=4.94406e-05, gnorm=0.16, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=13615
2023-02-20 17:02:40 - progress_bar.py[line:274] - INFO: epoch 001:   5395 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.1, ups=0.87, wpb=109.5, bsz=40, num_updates=5390, lr=4.9437e-05, gnorm=0.197, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13626
2023-02-20 17:02:51 - progress_bar.py[line:274] - INFO: epoch 001:   5405 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.86, wpb=113.1, bsz=40, num_updates=5400, lr=4.94334e-05, gnorm=0.153, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=13638
2023-02-20 17:03:02 - progress_bar.py[line:274] - INFO: epoch 001:   5415 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.8, bsz=40, num_updates=5410, lr=4.94298e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13649
2023-02-20 17:03:14 - progress_bar.py[line:274] - INFO: epoch 001:   5425 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.3, bsz=40, num_updates=5420, lr=4.94262e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13660
2023-02-20 17:03:25 - progress_bar.py[line:274] - INFO: epoch 001:   5435 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.9, wpb=111.5, bsz=40, num_updates=5430, lr=4.94225e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13671
2023-02-20 17:03:36 - progress_bar.py[line:274] - INFO: epoch 001:   5445 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=113, bsz=40, num_updates=5440, lr=4.94189e-05, gnorm=0.15, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13682
2023-02-20 17:03:47 - progress_bar.py[line:274] - INFO: epoch 001:   5455 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.6, bsz=40, num_updates=5450, lr=4.94153e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=13693
2023-02-20 17:03:58 - progress_bar.py[line:274] - INFO: epoch 001:   5465 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.6, bsz=40, num_updates=5460, lr=4.94117e-05, gnorm=0.144, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13705
2023-02-20 17:04:10 - progress_bar.py[line:274] - INFO: epoch 001:   5475 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=5470, lr=4.94081e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=13716
2023-02-20 17:04:20 - progress_bar.py[line:274] - INFO: epoch 001:   5485 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.5, bsz=40, num_updates=5480, lr=4.94044e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13727
2023-02-20 17:04:32 - progress_bar.py[line:274] - INFO: epoch 001:   5495 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.4, bsz=40, num_updates=5490, lr=4.94008e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13738
2023-02-20 17:04:43 - progress_bar.py[line:274] - INFO: epoch 001:   5505 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.91, wpb=111.1, bsz=40, num_updates=5500, lr=4.93972e-05, gnorm=0.236, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13749
2023-02-20 17:04:54 - progress_bar.py[line:274] - INFO: epoch 001:   5515 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.3, bsz=40, num_updates=5510, lr=4.93936e-05, gnorm=0.17, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13760
2023-02-20 17:05:05 - progress_bar.py[line:274] - INFO: epoch 001:   5525 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.9, bsz=40, num_updates=5520, lr=4.939e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13771
2023-02-20 17:05:16 - progress_bar.py[line:274] - INFO: epoch 001:   5535 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=5530, lr=4.93864e-05, gnorm=0.16, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13782
2023-02-20 17:05:27 - progress_bar.py[line:274] - INFO: epoch 001:   5545 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113.4, nsentences=40, sample_size=113.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.91, wpb=113.4, bsz=40, num_updates=5540, lr=4.93827e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13793
2023-02-20 17:05:38 - progress_bar.py[line:274] - INFO: epoch 001:   5555 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.91, wpb=111.2, bsz=40, num_updates=5550, lr=4.93791e-05, gnorm=0.199, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13804
2023-02-20 17:05:49 - progress_bar.py[line:274] - INFO: epoch 001:   5565 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=111.1, bsz=40, num_updates=5560, lr=4.93755e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13815
2023-02-20 17:06:00 - progress_bar.py[line:274] - INFO: epoch 001:   5575 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.3, bsz=40, num_updates=5570, lr=4.93719e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13827
2023-02-20 17:06:12 - progress_bar.py[line:274] - INFO: epoch 001:   5585 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=109.7, bsz=40, num_updates=5580, lr=4.93683e-05, gnorm=0.164, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13838
2023-02-20 17:06:23 - progress_bar.py[line:274] - INFO: epoch 001:   5595 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=5590, lr=4.93646e-05, gnorm=0.173, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13849
2023-02-20 17:06:33 - progress_bar.py[line:274] - INFO: epoch 001:   5605 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=108.3, ups=0.96, wpb=112.6, bsz=40, num_updates=5600, lr=4.9361e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=13860
2023-02-20 17:06:45 - progress_bar.py[line:274] - INFO: epoch 001:   5615 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.8, bsz=40, num_updates=5610, lr=4.93574e-05, gnorm=0.194, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13871
2023-02-20 17:06:56 - progress_bar.py[line:274] - INFO: epoch 001:   5625 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=112, bsz=40, num_updates=5620, lr=4.93538e-05, gnorm=0.18, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13882
2023-02-20 17:07:07 - progress_bar.py[line:274] - INFO: epoch 001:   5635 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.9, wpb=110.2, bsz=40, num_updates=5630, lr=4.93502e-05, gnorm=0.167, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13893
2023-02-20 17:07:18 - progress_bar.py[line:274] - INFO: epoch 001:   5645 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.1, bsz=40, num_updates=5640, lr=4.93466e-05, gnorm=0.167, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13905
2023-02-20 17:07:29 - progress_bar.py[line:274] - INFO: epoch 001:   5655 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.4, bsz=40, num_updates=5650, lr=4.93429e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13916
2023-02-20 17:07:41 - progress_bar.py[line:274] - INFO: epoch 001:   5665 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=110.6, bsz=40, num_updates=5660, lr=4.93393e-05, gnorm=0.16, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13927
2023-02-20 17:07:52 - progress_bar.py[line:274] - INFO: epoch 001:   5675 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.6, bsz=40, num_updates=5670, lr=4.93357e-05, gnorm=0.167, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=13938
2023-02-20 17:08:03 - progress_bar.py[line:274] - INFO: epoch 001:   5685 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=5680, lr=4.93321e-05, gnorm=0.189, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13949
2023-02-20 17:08:14 - progress_bar.py[line:274] - INFO: epoch 001:   5695 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.2, bsz=40, num_updates=5690, lr=4.93285e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13960
2023-02-20 17:08:25 - progress_bar.py[line:274] - INFO: epoch 001:   5705 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.9, wpb=111.2, bsz=40, num_updates=5700, lr=4.93248e-05, gnorm=0.164, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13972
2023-02-20 17:08:36 - progress_bar.py[line:274] - INFO: epoch 001:   5715 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.7, bsz=40, num_updates=5710, lr=4.93212e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=13983
2023-02-20 17:08:47 - progress_bar.py[line:274] - INFO: epoch 001:   5725 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.5, ups=0.92, wpb=111.3, bsz=40, num_updates=5720, lr=4.93176e-05, gnorm=0.209, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13994
2023-02-20 17:08:58 - progress_bar.py[line:274] - INFO: epoch 001:   5735 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.7, ups=0.91, wpb=112, bsz=40, num_updates=5730, lr=4.9314e-05, gnorm=0.154, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=14005
2023-02-20 17:09:09 - progress_bar.py[line:274] - INFO: epoch 001:   5745 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=113.4, nsentences=40, sample_size=113.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.92, wpb=113.4, bsz=40, num_updates=5740, lr=4.93104e-05, gnorm=0.18, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14016
2023-02-20 17:09:21 - progress_bar.py[line:274] - INFO: epoch 001:   5755 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.88, wpb=112.2, bsz=40, num_updates=5750, lr=4.93068e-05, gnorm=0.171, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14027
2023-02-20 17:09:32 - progress_bar.py[line:274] - INFO: epoch 001:   5765 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.6, bsz=40, num_updates=5760, lr=4.93031e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=14038
2023-02-20 17:09:43 - progress_bar.py[line:274] - INFO: epoch 001:   5775 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.9, wpb=113.3, bsz=40, num_updates=5770, lr=4.92995e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14050
2023-02-20 17:09:54 - progress_bar.py[line:274] - INFO: epoch 001:   5785 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.91, wpb=112.8, bsz=40, num_updates=5780, lr=4.92959e-05, gnorm=0.17, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=14061
2023-02-20 17:10:05 - progress_bar.py[line:274] - INFO: epoch 001:   5795 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.2, bsz=40, num_updates=5790, lr=4.92923e-05, gnorm=0.158, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14071
2023-02-20 17:10:16 - progress_bar.py[line:274] - INFO: epoch 001:   5805 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=5800, lr=4.92887e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14083
2023-02-20 17:10:28 - progress_bar.py[line:274] - INFO: epoch 001:   5815 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.8, bsz=40, num_updates=5810, lr=4.9285e-05, gnorm=0.155, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14094
2023-02-20 17:10:39 - progress_bar.py[line:274] - INFO: epoch 001:   5825 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.9, bsz=40, num_updates=5820, lr=4.92814e-05, gnorm=0.13, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14105
2023-02-20 17:10:50 - progress_bar.py[line:274] - INFO: epoch 001:   5835 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.89, wpb=113, bsz=40, num_updates=5830, lr=4.92778e-05, gnorm=0.144, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14116
2023-02-20 17:11:01 - progress_bar.py[line:274] - INFO: epoch 001:   5845 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.92, wpb=112.7, bsz=40, num_updates=5840, lr=4.92742e-05, gnorm=0.166, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14127
2023-02-20 17:11:12 - progress_bar.py[line:274] - INFO: epoch 001:   5855 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.3, bsz=40, num_updates=5850, lr=4.92706e-05, gnorm=0.179, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=14138
2023-02-20 17:11:23 - progress_bar.py[line:274] - INFO: epoch 001:   5865 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.8, bsz=40, num_updates=5860, lr=4.9267e-05, gnorm=0.164, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=14149
2023-02-20 17:11:34 - progress_bar.py[line:274] - INFO: epoch 001:   5875 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=112, bsz=40, num_updates=5870, lr=4.92633e-05, gnorm=0.156, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=14160
2023-02-20 17:11:45 - progress_bar.py[line:274] - INFO: epoch 001:   5885 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=5880, lr=4.92597e-05, gnorm=0.119, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14171
2023-02-20 17:11:48 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 17:11:58 - progress_bar.py[line:274] - INFO: epoch 001:   5896 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.7, ups=0.81, wpb=110.6, bsz=40, num_updates=5890, lr=4.92561e-05, gnorm=0.189, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=14184
2023-02-20 17:12:09 - progress_bar.py[line:274] - INFO: epoch 001:   5906 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112.2, bsz=40, num_updates=5900, lr=4.92525e-05, gnorm=0.182, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=14195
2023-02-20 17:12:20 - progress_bar.py[line:274] - INFO: epoch 001:   5916 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=5910, lr=4.92489e-05, gnorm=0.176, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14206
2023-02-20 17:12:32 - progress_bar.py[line:274] - INFO: epoch 001:   5926 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.89, wpb=111.3, bsz=40, num_updates=5920, lr=4.92452e-05, gnorm=0.218, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=14218
2023-02-20 17:12:43 - progress_bar.py[line:274] - INFO: epoch 001:   5936 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.89, wpb=112.3, bsz=40, num_updates=5930, lr=4.92416e-05, gnorm=0.169, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=14229
2023-02-20 17:12:54 - progress_bar.py[line:274] - INFO: epoch 001:   5946 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=111.1, bsz=40, num_updates=5940, lr=4.9238e-05, gnorm=0.136, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14241
2023-02-20 17:13:05 - progress_bar.py[line:274] - INFO: epoch 001:   5956 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.1, ups=0.93, wpb=111.7, bsz=40, num_updates=5950, lr=4.92344e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14251
2023-02-20 17:13:16 - progress_bar.py[line:274] - INFO: epoch 001:   5966 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.7, bsz=40, num_updates=5960, lr=4.92308e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=14263
2023-02-20 17:13:27 - progress_bar.py[line:274] - INFO: epoch 001:   5976 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.1, ups=0.92, wpb=111.1, bsz=40, num_updates=5970, lr=4.92272e-05, gnorm=0.225, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14274
2023-02-20 17:13:38 - progress_bar.py[line:274] - INFO: epoch 001:   5986 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.92, wpb=112.2, bsz=40, num_updates=5980, lr=4.92235e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14285
2023-02-20 17:13:49 - progress_bar.py[line:274] - INFO: epoch 001:   5996 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.7, bsz=40, num_updates=5990, lr=4.92199e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=14295
2023-02-20 17:14:00 - progress_bar.py[line:274] - INFO: epoch 001:   6006 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.7, bsz=40, num_updates=6000, lr=4.92163e-05, gnorm=0.154, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=14307
2023-02-20 17:14:00 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-20 17:14:02 - train.py[line:549] - INFO: 0 / 6234
2023-02-20 17:14:02 - train.py[line:551] - INFO: load:0.98 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-20 17:16:03 - train.py[line:549] - INFO: 200 / 6234
2023-02-20 17:16:03 - train.py[line:551] - INFO: load:1.00 valid_run:121.59 task_valid:118.54 collect_output:1.97
2023-02-20 17:18:03 - train.py[line:549] - INFO: 400 / 6234
2023-02-20 17:18:03 - train.py[line:551] - INFO: load:1.03 valid_run:240.95 task_valid:233.90 collect_output:4.91
2023-02-20 17:20:05 - train.py[line:549] - INFO: 600 / 6234
2023-02-20 17:20:05 - train.py[line:551] - INFO: load:1.05 valid_run:363.06 task_valid:349.87 collect_output:10.00
2023-02-20 17:22:06 - train.py[line:549] - INFO: 800 / 6234
2023-02-20 17:22:06 - train.py[line:551] - INFO: load:1.07 valid_run:484.44 task_valid:463.14 collect_output:17.08
2023-02-20 17:24:07 - train.py[line:549] - INFO: 1000 / 6234
2023-02-20 17:24:07 - train.py[line:551] - INFO: load:1.10 valid_run:604.44 task_valid:580.05 collect_output:19.12
2023-02-20 17:26:09 - train.py[line:549] - INFO: 1200 / 6234
2023-02-20 17:26:09 - train.py[line:551] - INFO: load:1.12 valid_run:726.77 task_valid:698.19 collect_output:22.28
2023-02-20 17:28:11 - train.py[line:549] - INFO: 1400 / 6234
2023-02-20 17:28:11 - train.py[line:551] - INFO: load:1.15 valid_run:849.21 task_valid:815.91 collect_output:25.95
2023-02-20 17:30:13 - train.py[line:549] - INFO: 1600 / 6234
2023-02-20 17:30:13 - train.py[line:551] - INFO: load:1.17 valid_run:970.38 task_valid:931.95 collect_output:30.05
2023-02-20 17:32:16 - train.py[line:549] - INFO: 1800 / 6234
2023-02-20 17:32:16 - train.py[line:551] - INFO: load:1.20 valid_run:1093.30 task_valid:1048.58 collect_output:35.28
2023-02-20 17:34:16 - train.py[line:549] - INFO: 2000 / 6234
2023-02-20 17:34:16 - train.py[line:551] - INFO: load:1.22 valid_run:1214.05 task_valid:1160.64 collect_output:42.94
2023-02-20 17:36:16 - train.py[line:549] - INFO: 2200 / 6234
2023-02-20 17:36:16 - train.py[line:551] - INFO: load:1.24 valid_run:1333.54 task_valid:1275.67 collect_output:46.37
2023-02-20 17:38:17 - train.py[line:549] - INFO: 2400 / 6234
2023-02-20 17:38:17 - train.py[line:551] - INFO: load:1.27 valid_run:1454.39 task_valid:1392.11 collect_output:49.74
2023-02-20 17:40:15 - train.py[line:549] - INFO: 2600 / 6234
2023-02-20 17:40:15 - train.py[line:551] - INFO: load:1.30 valid_run:1572.63 task_valid:1505.41 collect_output:53.65
2023-02-20 17:42:16 - train.py[line:549] - INFO: 2800 / 6234
2023-02-20 17:42:16 - train.py[line:551] - INFO: load:1.32 valid_run:1692.85 task_valid:1622.59 collect_output:55.67
2023-02-20 17:44:16 - train.py[line:549] - INFO: 3000 / 6234
2023-02-20 17:44:16 - train.py[line:551] - INFO: load:1.35 valid_run:1813.13 task_valid:1738.22 collect_output:59.32
2023-02-20 17:46:16 - train.py[line:549] - INFO: 3200 / 6234
2023-02-20 17:46:16 - train.py[line:551] - INFO: load:1.37 valid_run:1933.46 task_valid:1851.62 collect_output:65.19
2023-02-20 17:48:17 - train.py[line:549] - INFO: 3400 / 6234
2023-02-20 17:48:17 - train.py[line:551] - INFO: load:1.40 valid_run:2054.00 task_valid:1967.13 collect_output:69.19
2023-02-20 17:50:17 - train.py[line:549] - INFO: 3600 / 6234
2023-02-20 17:50:17 - train.py[line:551] - INFO: load:1.42 valid_run:2174.18 task_valid:2084.58 collect_output:70.89
2023-02-20 17:52:18 - train.py[line:549] - INFO: 3800 / 6234
2023-02-20 17:52:18 - train.py[line:551] - INFO: load:1.45 valid_run:2294.70 task_valid:2201.00 collect_output:73.94
2023-02-20 17:54:17 - train.py[line:549] - INFO: 4000 / 6234
2023-02-20 17:54:17 - train.py[line:551] - INFO: load:1.47 valid_run:2414.30 task_valid:2317.02 collect_output:76.51
2023-02-20 17:56:18 - train.py[line:549] - INFO: 4200 / 6234
2023-02-20 17:56:18 - train.py[line:551] - INFO: load:1.50 valid_run:2535.21 task_valid:2432.95 collect_output:80.45
2023-02-20 17:58:20 - train.py[line:549] - INFO: 4400 / 6234
2023-02-20 17:58:20 - train.py[line:551] - INFO: load:1.52 valid_run:2656.62 task_valid:2551.44 collect_output:82.32
2023-02-20 18:00:20 - train.py[line:549] - INFO: 4600 / 6234
2023-02-20 18:00:20 - train.py[line:551] - INFO: load:1.55 valid_run:2776.31 task_valid:2665.45 collect_output:86.93
2023-02-20 18:02:19 - train.py[line:549] - INFO: 4800 / 6234
2023-02-20 18:02:19 - train.py[line:551] - INFO: load:1.57 valid_run:2895.58 task_valid:2781.26 collect_output:89.36
2023-02-20 18:04:20 - train.py[line:549] - INFO: 5000 / 6234
2023-02-20 18:04:20 - train.py[line:551] - INFO: load:1.60 valid_run:3016.88 task_valid:2897.35 collect_output:93.51
2023-02-20 18:06:23 - train.py[line:549] - INFO: 5200 / 6234
2023-02-20 18:06:23 - train.py[line:551] - INFO: load:1.62 valid_run:3139.15 task_valid:3013.10 collect_output:98.95
2023-02-20 18:08:22 - train.py[line:549] - INFO: 5400 / 6234
2023-02-20 18:08:22 - train.py[line:551] - INFO: load:1.65 valid_run:3258.58 task_valid:3127.11 collect_output:103.31
2023-02-20 18:10:24 - train.py[line:549] - INFO: 5600 / 6234
2023-02-20 18:10:24 - train.py[line:551] - INFO: load:1.68 valid_run:3380.43 task_valid:3246.49 collect_output:104.67
2023-02-20 18:12:25 - train.py[line:549] - INFO: 5800 / 6234
2023-02-20 18:12:25 - train.py[line:551] - INFO: load:1.70 valid_run:3501.76 task_valid:3361.84 collect_output:109.59
2023-02-20 18:14:27 - train.py[line:549] - INFO: 6000 / 6234
2023-02-20 18:14:27 - train.py[line:551] - INFO: load:1.73 valid_run:3623.48 task_valid:3480.05 collect_output:112.03
2023-02-20 18:16:28 - train.py[line:549] - INFO: 6200 / 6234
2023-02-20 18:16:28 - train.py[line:551] - INFO: load:1.76 valid_run:3744.36 task_valid:3598.34 collect_output:113.56

====================================================================================================
SGG eval:     R @ 50: 0.6327;     R @ 100: 0.6648;     R @ 500: 0.6899;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4259;    mR @ 100: 0.4579;    mR @ 500: 0.4983;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.3714) (eating:0.7059) (flying in:0.8636) (growing on:0.3750) (hanging from:0.5161) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0833) (parked on:1.0000) (playing:0.0000) (riding:0.9624) (says:0.0000) (sitting on:0.7200) (standing on:0.3493) (using:0.5000) (walking in:0.0000) (walking on:0.7568) (watching:0.4306) 
--------------------------------------------------------
====================================================================================================

2023-02-20 18:16:59 - train.py[line:487] - INFO: 0.6647503437738732

====================================================================================================
SGG eval:     R @ 50: 0.6327;     R @ 100: 0.6648;     R @ 500: 0.6899;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4259;    mR @ 100: 0.4579;    mR @ 500: 0.4983;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.3714) (eating:0.7059) (flying in:0.8636) (growing on:0.3750) (hanging from:0.5161) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0833) (parked on:1.0000) (playing:0.0000) (riding:0.9624) (says:0.0000) (sitting on:0.7200) (standing on:0.3493) (using:0.5000) (walking in:0.0000) (walking on:0.7568) (watching:0.4306) 
--------------------------------------------------------
====================================================================================================

2023-02-20 18:16:59 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-20 18:16:59 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.235 | loss_v1 0 | loss_v2 0 | nll_loss 0.063 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.66475 | ppl 1.04 | vqa_score 0.3784 | wps 118.8 | wpb 72 | bsz 24 | num_updates 6000 | best_R@100 0.66475
2023-02-20 18:16:59 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2023-02-20 18:16:59 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_6000.pt
2023-02-20 18:17:05 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_6000.pt
2023-02-20 18:17:10 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.6647503437738732) (writing took 10.873799685388803 seconds)
2023-02-20 18:17:23 - progress_bar.py[line:274] - INFO: epoch 001:   6016 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=113, bsz=40, num_updates=6010, lr=4.92127e-05, gnorm=0.158, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18108
2023-02-20 18:17:34 - progress_bar.py[line:274] - INFO: epoch 001:   6026 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.88, wpb=111.9, bsz=40, num_updates=6020, lr=4.92091e-05, gnorm=0.238, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18121
2023-02-20 18:17:45 - progress_bar.py[line:274] - INFO: epoch 001:   6036 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=111, bsz=40, num_updates=6030, lr=4.92054e-05, gnorm=0.176, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18132
2023-02-20 18:17:57 - progress_bar.py[line:274] - INFO: epoch 001:   6046 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.2, bsz=40, num_updates=6040, lr=4.92018e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18143
2023-02-20 18:18:08 - progress_bar.py[line:274] - INFO: epoch 001:   6056 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=6050, lr=4.91982e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18154
2023-02-20 18:18:19 - progress_bar.py[line:274] - INFO: epoch 001:   6066 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.2, bsz=40, num_updates=6060, lr=4.91946e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=18165
2023-02-20 18:18:30 - progress_bar.py[line:274] - INFO: epoch 001:   6076 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.7, ups=0.88, wpb=111.8, bsz=40, num_updates=6070, lr=4.9191e-05, gnorm=0.159, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18177
2023-02-20 18:18:41 - progress_bar.py[line:274] - INFO: epoch 001:   6086 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.89, wpb=112.2, bsz=40, num_updates=6080, lr=4.91874e-05, gnorm=0.184, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18188
2023-02-20 18:18:53 - progress_bar.py[line:274] - INFO: epoch 001:   6096 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.8, bsz=40, num_updates=6090, lr=4.91837e-05, gnorm=0.146, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18199
2023-02-20 18:19:04 - progress_bar.py[line:274] - INFO: epoch 001:   6106 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.88, wpb=112.8, bsz=40, num_updates=6100, lr=4.91801e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=18210
2023-02-20 18:19:15 - progress_bar.py[line:274] - INFO: epoch 001:   6116 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=6110, lr=4.91765e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18222
2023-02-20 18:19:27 - progress_bar.py[line:274] - INFO: epoch 001:   6126 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.7, bsz=40, num_updates=6120, lr=4.91729e-05, gnorm=0.178, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18233
2023-02-20 18:19:38 - progress_bar.py[line:274] - INFO: epoch 001:   6136 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=6130, lr=4.91693e-05, gnorm=0.201, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=18244
2023-02-20 18:19:49 - progress_bar.py[line:274] - INFO: epoch 001:   6146 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=113.4, nsentences=40, sample_size=113.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.88, wpb=113.4, bsz=40, num_updates=6140, lr=4.91656e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18256
2023-02-20 18:20:00 - progress_bar.py[line:274] - INFO: epoch 001:   6156 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.3, ups=0.92, wpb=112.4, bsz=40, num_updates=6150, lr=4.9162e-05, gnorm=0.176, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18267
2023-02-20 18:20:11 - progress_bar.py[line:274] - INFO: epoch 001:   6166 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103, ups=0.92, wpb=111.8, bsz=40, num_updates=6160, lr=4.91584e-05, gnorm=0.192, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18277
2023-02-20 18:20:22 - progress_bar.py[line:274] - INFO: epoch 001:   6176 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.89, wpb=112.4, bsz=40, num_updates=6170, lr=4.91548e-05, gnorm=0.234, clip=0, loss_scale=2048, train_wall=11, gb_free=11.4, ema_decay=0.9999, wall=18289
2023-02-20 18:20:34 - progress_bar.py[line:274] - INFO: epoch 001:   6186 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112.6, bsz=40, num_updates=6180, lr=4.91512e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18300
2023-02-20 18:20:45 - progress_bar.py[line:274] - INFO: epoch 001:   6196 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.4, bsz=40, num_updates=6190, lr=4.91476e-05, gnorm=0.149, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18311
2023-02-20 18:20:56 - progress_bar.py[line:274] - INFO: epoch 001:   6206 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=6200, lr=4.91439e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18323
2023-02-20 18:21:07 - progress_bar.py[line:274] - INFO: epoch 001:   6216 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=6210, lr=4.91403e-05, gnorm=0.184, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=18334
2023-02-20 18:21:18 - progress_bar.py[line:274] - INFO: epoch 001:   6226 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.9, bsz=40, num_updates=6220, lr=4.91367e-05, gnorm=0.176, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=18345
2023-02-20 18:21:29 - progress_bar.py[line:274] - INFO: epoch 001:   6236 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.7, ups=0.91, wpb=112.1, bsz=40, num_updates=6230, lr=4.91331e-05, gnorm=0.169, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=18356
2023-02-20 18:21:40 - progress_bar.py[line:274] - INFO: epoch 001:   6246 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.9, bsz=40, num_updates=6240, lr=4.91295e-05, gnorm=0.149, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18367
2023-02-20 18:21:52 - progress_bar.py[line:274] - INFO: epoch 001:   6256 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.9, wpb=111.8, bsz=40, num_updates=6250, lr=4.91258e-05, gnorm=0.158, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18378
2023-02-20 18:22:03 - progress_bar.py[line:274] - INFO: epoch 001:   6266 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.5, bsz=40, num_updates=6260, lr=4.91222e-05, gnorm=0.17, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18389
2023-02-20 18:22:14 - progress_bar.py[line:274] - INFO: epoch 001:   6276 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=6270, lr=4.91186e-05, gnorm=0.209, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18400
2023-02-20 18:22:25 - progress_bar.py[line:274] - INFO: epoch 001:   6286 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.2, bsz=40, num_updates=6280, lr=4.9115e-05, gnorm=0.155, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18411
2023-02-20 18:22:36 - progress_bar.py[line:274] - INFO: epoch 001:   6296 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=6290, lr=4.91114e-05, gnorm=0.276, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=18423
2023-02-20 18:22:47 - progress_bar.py[line:274] - INFO: epoch 001:   6306 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=6300, lr=4.91078e-05, gnorm=0.203, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18434
2023-02-20 18:22:58 - progress_bar.py[line:274] - INFO: epoch 001:   6316 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.9, bsz=40, num_updates=6310, lr=4.91041e-05, gnorm=0.16, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18445
2023-02-20 18:23:10 - progress_bar.py[line:274] - INFO: epoch 001:   6326 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.1, bsz=40, num_updates=6320, lr=4.91005e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18456
2023-02-20 18:23:21 - progress_bar.py[line:274] - INFO: epoch 001:   6336 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.6, bsz=40, num_updates=6330, lr=4.90969e-05, gnorm=0.146, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18467
2023-02-20 18:23:32 - progress_bar.py[line:274] - INFO: epoch 001:   6346 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=110.6, bsz=40, num_updates=6340, lr=4.90933e-05, gnorm=0.185, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18478
2023-02-20 18:23:43 - progress_bar.py[line:274] - INFO: epoch 001:   6356 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.3, bsz=40, num_updates=6350, lr=4.90897e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18489
2023-02-20 18:23:54 - progress_bar.py[line:274] - INFO: epoch 001:   6366 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=6360, lr=4.9086e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18500
2023-02-20 18:24:05 - progress_bar.py[line:274] - INFO: epoch 001:   6376 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.93, wpb=110.9, bsz=40, num_updates=6370, lr=4.90824e-05, gnorm=0.215, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18511
2023-02-20 18:24:16 - progress_bar.py[line:274] - INFO: epoch 001:   6386 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.1, bsz=40, num_updates=6380, lr=4.90788e-05, gnorm=0.236, clip=0, loss_scale=2048, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=18522
2023-02-20 18:24:27 - progress_bar.py[line:274] - INFO: epoch 001:   6396 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=6390, lr=4.90752e-05, gnorm=0.202, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18534
2023-02-20 18:24:39 - progress_bar.py[line:274] - INFO: epoch 001:   6406 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.88, wpb=113, bsz=40, num_updates=6400, lr=4.90716e-05, gnorm=0.155, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18545
2023-02-20 18:24:49 - progress_bar.py[line:274] - INFO: epoch 001:   6416 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.6, ups=0.93, wpb=112.1, bsz=40, num_updates=6410, lr=4.90679e-05, gnorm=0.129, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18556
2023-02-20 18:25:01 - progress_bar.py[line:274] - INFO: epoch 001:   6426 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=6420, lr=4.90643e-05, gnorm=0.174, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18567
2023-02-20 18:25:12 - progress_bar.py[line:274] - INFO: epoch 001:   6436 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.8, bsz=40, num_updates=6430, lr=4.90607e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18578
2023-02-20 18:25:23 - progress_bar.py[line:274] - INFO: epoch 001:   6446 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.88, wpb=111.4, bsz=40, num_updates=6440, lr=4.90571e-05, gnorm=0.157, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18590
2023-02-20 18:25:34 - progress_bar.py[line:274] - INFO: epoch 001:   6456 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.92, wpb=112.8, bsz=40, num_updates=6450, lr=4.90535e-05, gnorm=0.144, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18601
2023-02-20 18:25:46 - progress_bar.py[line:274] - INFO: epoch 001:   6466 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.88, wpb=112.9, bsz=40, num_updates=6460, lr=4.90499e-05, gnorm=0.154, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18612
2023-02-20 18:25:57 - progress_bar.py[line:274] - INFO: epoch 001:   6476 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.87, wpb=112.9, bsz=40, num_updates=6470, lr=4.90462e-05, gnorm=0.129, clip=0, loss_scale=4096, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=18623
2023-02-20 18:26:08 - progress_bar.py[line:274] - INFO: epoch 001:   6486 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.91, wpb=113.1, bsz=40, num_updates=6480, lr=4.90426e-05, gnorm=0.152, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18635
2023-02-20 18:26:19 - progress_bar.py[line:274] - INFO: epoch 001:   6496 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.8, bsz=40, num_updates=6490, lr=4.9039e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18646
2023-02-20 18:26:30 - progress_bar.py[line:274] - INFO: epoch 001:   6506 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.4, bsz=40, num_updates=6500, lr=4.90354e-05, gnorm=0.131, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18657
2023-02-20 18:26:42 - progress_bar.py[line:274] - INFO: epoch 001:   6516 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=6510, lr=4.90318e-05, gnorm=0.159, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=18668
2023-02-20 18:26:53 - progress_bar.py[line:274] - INFO: epoch 001:   6526 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.3, bsz=40, num_updates=6520, lr=4.90281e-05, gnorm=0.17, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18679
2023-02-20 18:27:04 - progress_bar.py[line:274] - INFO: epoch 001:   6536 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.1, bsz=40, num_updates=6530, lr=4.90245e-05, gnorm=0.156, clip=0, loss_scale=4096, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=18690
2023-02-20 18:27:15 - progress_bar.py[line:274] - INFO: epoch 001:   6546 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.9, bsz=40, num_updates=6540, lr=4.90209e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=18701
2023-02-20 18:27:23 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 18:27:27 - progress_bar.py[line:274] - INFO: epoch 001:   6557 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.9, ups=0.81, wpb=110.7, bsz=40, num_updates=6550, lr=4.90173e-05, gnorm=0.144, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=18714
2023-02-20 18:27:38 - progress_bar.py[line:274] - INFO: epoch 001:   6567 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=6560, lr=4.90137e-05, gnorm=0.166, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18725
2023-02-20 18:27:50 - progress_bar.py[line:274] - INFO: epoch 001:   6577 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.4, bsz=40, num_updates=6570, lr=4.90101e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=18736
2023-02-20 18:28:01 - progress_bar.py[line:274] - INFO: epoch 001:   6587 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.91, wpb=110.3, bsz=40, num_updates=6580, lr=4.90064e-05, gnorm=0.23, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18747
2023-02-20 18:28:12 - progress_bar.py[line:274] - INFO: epoch 001:   6597 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112, bsz=40, num_updates=6590, lr=4.90028e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18758
2023-02-20 18:28:23 - progress_bar.py[line:274] - INFO: epoch 001:   6607 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=113.4, nsentences=40, sample_size=113.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.88, wpb=113.4, bsz=40, num_updates=6600, lr=4.89992e-05, gnorm=0.187, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=18770
2023-02-20 18:28:34 - progress_bar.py[line:274] - INFO: epoch 001:   6617 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.3, ups=0.94, wpb=112.5, bsz=40, num_updates=6610, lr=4.89956e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18780
2023-02-20 18:28:45 - progress_bar.py[line:274] - INFO: epoch 001:   6627 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.88, wpb=113.1, bsz=40, num_updates=6620, lr=4.8992e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18792
2023-02-20 18:28:56 - progress_bar.py[line:274] - INFO: epoch 001:   6637 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=6630, lr=4.89883e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18803
2023-02-20 18:29:07 - progress_bar.py[line:274] - INFO: epoch 001:   6647 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113.9, nsentences=40, sample_size=113.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.91, wpb=113.9, bsz=40, num_updates=6640, lr=4.89847e-05, gnorm=0.197, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=18814
2023-02-20 18:29:18 - progress_bar.py[line:274] - INFO: epoch 001:   6657 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.9, ups=0.91, wpb=112, bsz=40, num_updates=6650, lr=4.89811e-05, gnorm=0.171, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=18825
2023-02-20 18:29:30 - progress_bar.py[line:274] - INFO: epoch 001:   6667 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.5, bsz=40, num_updates=6660, lr=4.89775e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=18836
2023-02-20 18:29:41 - progress_bar.py[line:274] - INFO: epoch 001:   6677 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.5, bsz=40, num_updates=6670, lr=4.89739e-05, gnorm=0.161, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18847
2023-02-20 18:29:52 - progress_bar.py[line:274] - INFO: epoch 001:   6687 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.5, bsz=40, num_updates=6680, lr=4.89703e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18858
2023-02-20 18:30:03 - progress_bar.py[line:274] - INFO: epoch 001:   6697 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.8, bsz=40, num_updates=6690, lr=4.89666e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18870
2023-02-20 18:30:14 - progress_bar.py[line:274] - INFO: epoch 001:   6707 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112.1, bsz=40, num_updates=6700, lr=4.8963e-05, gnorm=0.155, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18881
2023-02-20 18:30:26 - progress_bar.py[line:274] - INFO: epoch 001:   6717 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.2, ups=0.86, wpb=112.8, bsz=40, num_updates=6710, lr=4.89594e-05, gnorm=0.219, clip=0, loss_scale=2048, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=18892
2023-02-20 18:30:37 - progress_bar.py[line:274] - INFO: epoch 001:   6727 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.8, bsz=40, num_updates=6720, lr=4.89558e-05, gnorm=0.146, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18903
2023-02-20 18:30:48 - progress_bar.py[line:274] - INFO: epoch 001:   6737 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.3, bsz=40, num_updates=6730, lr=4.89522e-05, gnorm=0.175, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18914
2023-02-20 18:30:59 - progress_bar.py[line:274] - INFO: epoch 001:   6747 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.6, bsz=40, num_updates=6740, lr=4.89485e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18925
2023-02-20 18:31:10 - progress_bar.py[line:274] - INFO: epoch 001:   6757 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=112.2, bsz=40, num_updates=6750, lr=4.89449e-05, gnorm=0.144, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=18936
2023-02-20 18:31:21 - progress_bar.py[line:274] - INFO: epoch 001:   6767 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.5, bsz=40, num_updates=6760, lr=4.89413e-05, gnorm=0.176, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=18947
2023-02-20 18:31:32 - progress_bar.py[line:274] - INFO: epoch 001:   6777 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112.3, bsz=40, num_updates=6770, lr=4.89377e-05, gnorm=0.153, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18958
2023-02-20 18:31:43 - progress_bar.py[line:274] - INFO: epoch 001:   6787 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.91, wpb=112.6, bsz=40, num_updates=6780, lr=4.89341e-05, gnorm=0.168, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18969
2023-02-20 18:31:55 - progress_bar.py[line:274] - INFO: epoch 001:   6797 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=111, bsz=40, num_updates=6790, lr=4.89305e-05, gnorm=0.21, clip=0, loss_scale=2048, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=18981
2023-02-20 18:32:05 - progress_bar.py[line:274] - INFO: epoch 001:   6807 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.92, wpb=112.6, bsz=40, num_updates=6800, lr=4.89268e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18992
2023-02-20 18:32:17 - progress_bar.py[line:274] - INFO: epoch 001:   6817 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.4, bsz=40, num_updates=6810, lr=4.89232e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19003
2023-02-20 18:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   6827 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.89, wpb=111.5, bsz=40, num_updates=6820, lr=4.89196e-05, gnorm=0.191, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=19014
2023-02-20 18:32:39 - progress_bar.py[line:274] - INFO: epoch 001:   6837 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.2, bsz=40, num_updates=6830, lr=4.8916e-05, gnorm=0.15, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19026
2023-02-20 18:32:51 - progress_bar.py[line:274] - INFO: epoch 001:   6847 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=6840, lr=4.89124e-05, gnorm=0.156, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19037
2023-02-20 18:33:02 - progress_bar.py[line:274] - INFO: epoch 001:   6857 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.6, bsz=40, num_updates=6850, lr=4.89087e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19048
2023-02-20 18:33:13 - progress_bar.py[line:274] - INFO: epoch 001:   6867 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.9, wpb=109.7, bsz=40, num_updates=6860, lr=4.89051e-05, gnorm=0.187, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19059
2023-02-20 18:33:24 - progress_bar.py[line:274] - INFO: epoch 001:   6877 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.9, bsz=40, num_updates=6870, lr=4.89015e-05, gnorm=0.15, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=19071
2023-02-20 18:33:35 - progress_bar.py[line:274] - INFO: epoch 001:   6887 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=110.6, bsz=40, num_updates=6880, lr=4.88979e-05, gnorm=0.144, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19082
2023-02-20 18:33:46 - progress_bar.py[line:274] - INFO: epoch 001:   6897 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.91, wpb=111.1, bsz=40, num_updates=6890, lr=4.88943e-05, gnorm=0.168, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19093
2023-02-20 18:33:58 - progress_bar.py[line:274] - INFO: epoch 001:   6907 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.8, bsz=40, num_updates=6900, lr=4.88907e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19104
2023-02-20 18:34:09 - progress_bar.py[line:274] - INFO: epoch 001:   6917 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.89, wpb=111.7, bsz=40, num_updates=6910, lr=4.8887e-05, gnorm=0.184, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19115
2023-02-20 18:34:21 - progress_bar.py[line:274] - INFO: epoch 001:   6927 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=112, bsz=40, num_updates=6920, lr=4.88834e-05, gnorm=0.136, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19127
2023-02-20 18:34:32 - progress_bar.py[line:274] - INFO: epoch 001:   6937 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.1, bsz=40, num_updates=6930, lr=4.88798e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=19138
2023-02-20 18:34:43 - progress_bar.py[line:274] - INFO: epoch 001:   6947 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=6940, lr=4.88762e-05, gnorm=0.154, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19149
2023-02-20 18:34:54 - progress_bar.py[line:274] - INFO: epoch 001:   6957 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.6, bsz=40, num_updates=6950, lr=4.88726e-05, gnorm=0.185, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19160
2023-02-20 18:35:05 - progress_bar.py[line:274] - INFO: epoch 001:   6967 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.9, wpb=112.7, bsz=40, num_updates=6960, lr=4.88689e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19171
2023-02-20 18:35:16 - progress_bar.py[line:274] - INFO: epoch 001:   6977 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.9, wpb=111.4, bsz=40, num_updates=6970, lr=4.88653e-05, gnorm=0.164, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19183
2023-02-20 18:35:27 - progress_bar.py[line:274] - INFO: epoch 001:   6987 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=6980, lr=4.88617e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19194
2023-02-20 18:35:39 - progress_bar.py[line:274] - INFO: epoch 001:   6997 / 71012 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.88, wpb=112.6, bsz=40, num_updates=6990, lr=4.88581e-05, gnorm=0.164, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19205
2023-02-20 18:35:50 - progress_bar.py[line:274] - INFO: epoch 001:   7007 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=7000, lr=4.88545e-05, gnorm=0.222, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19216
2023-02-20 18:36:01 - progress_bar.py[line:274] - INFO: epoch 001:   7017 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.5, bsz=40, num_updates=7010, lr=4.88509e-05, gnorm=0.15, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19228
2023-02-20 18:36:12 - progress_bar.py[line:274] - INFO: epoch 001:   7027 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.3, bsz=40, num_updates=7020, lr=4.88472e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19239
2023-02-20 18:36:23 - progress_bar.py[line:274] - INFO: epoch 001:   7037 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.91, wpb=112.5, bsz=40, num_updates=7030, lr=4.88436e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19250
2023-02-20 18:36:34 - progress_bar.py[line:274] - INFO: epoch 001:   7047 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.6, bsz=40, num_updates=7040, lr=4.884e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19260
2023-02-20 18:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   7057 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.93, wpb=110.7, bsz=40, num_updates=7050, lr=4.88364e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19271
2023-02-20 18:36:56 - progress_bar.py[line:274] - INFO: epoch 001:   7067 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=7060, lr=4.88328e-05, gnorm=0.184, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19282
2023-02-20 18:37:07 - progress_bar.py[line:274] - INFO: epoch 001:   7077 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.1, bsz=40, num_updates=7070, lr=4.88291e-05, gnorm=0.115, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19293
2023-02-20 18:37:18 - progress_bar.py[line:274] - INFO: epoch 001:   7087 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.3, ups=0.93, wpb=112.2, bsz=40, num_updates=7080, lr=4.88255e-05, gnorm=0.161, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19304
2023-02-20 18:37:29 - progress_bar.py[line:274] - INFO: epoch 001:   7097 / 71012 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=95.2, ups=0.86, wpb=110.5, bsz=40, num_updates=7090, lr=4.88219e-05, gnorm=0.194, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=19316
2023-02-20 18:37:40 - progress_bar.py[line:274] - INFO: epoch 001:   7107 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.8, ups=0.93, wpb=112.8, bsz=40, num_updates=7100, lr=4.88183e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19326
2023-02-20 18:37:51 - progress_bar.py[line:274] - INFO: epoch 001:   7117 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=111.8, bsz=40, num_updates=7110, lr=4.88147e-05, gnorm=0.138, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19337
2023-02-20 18:38:02 - progress_bar.py[line:274] - INFO: epoch 001:   7127 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=7120, lr=4.88111e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19349
2023-02-20 18:38:14 - progress_bar.py[line:274] - INFO: epoch 001:   7137 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=112.2, bsz=40, num_updates=7130, lr=4.88074e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19360
2023-02-20 18:38:25 - progress_bar.py[line:274] - INFO: epoch 001:   7147 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.5, bsz=40, num_updates=7140, lr=4.88038e-05, gnorm=0.159, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19372
2023-02-20 18:38:36 - progress_bar.py[line:274] - INFO: epoch 001:   7157 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.5, bsz=40, num_updates=7150, lr=4.88002e-05, gnorm=0.154, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19383
2023-02-20 18:38:47 - progress_bar.py[line:274] - INFO: epoch 001:   7167 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.2, ups=0.92, wpb=111.4, bsz=40, num_updates=7160, lr=4.87966e-05, gnorm=0.181, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19393
2023-02-20 18:38:58 - progress_bar.py[line:274] - INFO: epoch 001:   7177 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.8, bsz=40, num_updates=7170, lr=4.8793e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19405
2023-02-20 18:39:09 - progress_bar.py[line:274] - INFO: epoch 001:   7187 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.9, bsz=40, num_updates=7180, lr=4.87893e-05, gnorm=0.166, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19416
2023-02-20 18:39:20 - progress_bar.py[line:274] - INFO: epoch 001:   7197 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.8, ups=0.93, wpb=111.5, bsz=40, num_updates=7190, lr=4.87857e-05, gnorm=0.168, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19426
2023-02-20 18:39:31 - progress_bar.py[line:274] - INFO: epoch 001:   7207 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.4, bsz=40, num_updates=7200, lr=4.87821e-05, gnorm=0.172, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19438
2023-02-20 18:39:42 - progress_bar.py[line:274] - INFO: epoch 001:   7217 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.9, wpb=110.8, bsz=40, num_updates=7210, lr=4.87785e-05, gnorm=0.141, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19449
2023-02-20 18:39:54 - progress_bar.py[line:274] - INFO: epoch 001:   7227 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.3, bsz=40, num_updates=7220, lr=4.87749e-05, gnorm=0.16, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19460
2023-02-20 18:40:05 - progress_bar.py[line:274] - INFO: epoch 001:   7237 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.8, bsz=40, num_updates=7230, lr=4.87713e-05, gnorm=0.197, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19471
2023-02-20 18:40:16 - progress_bar.py[line:274] - INFO: epoch 001:   7247 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=7240, lr=4.87676e-05, gnorm=0.128, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19482
2023-02-20 18:40:27 - progress_bar.py[line:274] - INFO: epoch 001:   7257 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.9, bsz=40, num_updates=7250, lr=4.8764e-05, gnorm=0.153, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19493
2023-02-20 18:40:38 - progress_bar.py[line:274] - INFO: epoch 001:   7267 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.4, bsz=40, num_updates=7260, lr=4.87604e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=19505
2023-02-20 18:40:50 - progress_bar.py[line:274] - INFO: epoch 001:   7277 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=111.8, bsz=40, num_updates=7270, lr=4.87568e-05, gnorm=0.129, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19516
2023-02-20 18:41:01 - progress_bar.py[line:274] - INFO: epoch 001:   7287 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.91, wpb=111.2, bsz=40, num_updates=7280, lr=4.87532e-05, gnorm=0.137, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=19527
2023-02-20 18:41:12 - progress_bar.py[line:274] - INFO: epoch 001:   7297 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.88, wpb=110.4, bsz=40, num_updates=7290, lr=4.87495e-05, gnorm=0.145, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19538
2023-02-20 18:41:23 - progress_bar.py[line:274] - INFO: epoch 001:   7307 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112, bsz=40, num_updates=7300, lr=4.87459e-05, gnorm=0.129, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19550
2023-02-20 18:41:30 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 18:41:35 - progress_bar.py[line:274] - INFO: epoch 001:   7318 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91.7, ups=0.83, wpb=110.4, bsz=40, num_updates=7310, lr=4.87423e-05, gnorm=0.188, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=19562
2023-02-20 18:41:46 - progress_bar.py[line:274] - INFO: epoch 001:   7328 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.93, wpb=111.6, bsz=40, num_updates=7320, lr=4.87387e-05, gnorm=0.145, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19573
2023-02-20 18:41:57 - progress_bar.py[line:274] - INFO: epoch 001:   7338 / 71012 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.9, wpb=110.9, bsz=40, num_updates=7330, lr=4.87351e-05, gnorm=0.184, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19584
2023-02-20 18:42:09 - progress_bar.py[line:274] - INFO: epoch 001:   7348 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.9, wpb=109.7, bsz=40, num_updates=7340, lr=4.87315e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19595
2023-02-20 18:42:20 - progress_bar.py[line:274] - INFO: epoch 001:   7358 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.7, ups=0.86, wpb=111.2, bsz=40, num_updates=7350, lr=4.87278e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19607
2023-02-20 18:42:31 - progress_bar.py[line:274] - INFO: epoch 001:   7368 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.5, bsz=40, num_updates=7360, lr=4.87242e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19618
2023-02-20 18:42:42 - progress_bar.py[line:274] - INFO: epoch 001:   7378 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.9, wpb=110.5, bsz=40, num_updates=7370, lr=4.87206e-05, gnorm=0.181, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19629
2023-02-20 18:42:53 - progress_bar.py[line:274] - INFO: epoch 001:   7388 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.9, wpb=112.3, bsz=40, num_updates=7380, lr=4.8717e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=19640
2023-02-20 18:43:04 - progress_bar.py[line:274] - INFO: epoch 001:   7398 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.9, bsz=40, num_updates=7390, lr=4.87134e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19651
2023-02-20 18:43:15 - progress_bar.py[line:274] - INFO: epoch 001:   7408 / 71012 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.8, ups=0.93, wpb=112.6, bsz=40, num_updates=7400, lr=4.87097e-05, gnorm=0.182, clip=0, loss_scale=2048, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=19662
2023-02-20 18:43:26 - progress_bar.py[line:274] - INFO: epoch 001:   7418 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.8, bsz=40, num_updates=7410, lr=4.87061e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19672
2023-02-20 18:43:37 - progress_bar.py[line:274] - INFO: epoch 001:   7428 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.5, bsz=40, num_updates=7420, lr=4.87025e-05, gnorm=0.131, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19684
2023-02-20 18:43:48 - progress_bar.py[line:274] - INFO: epoch 001:   7438 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=7430, lr=4.86989e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19695
2023-02-20 18:44:00 - progress_bar.py[line:274] - INFO: epoch 001:   7448 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.9, wpb=110.1, bsz=40, num_updates=7440, lr=4.86953e-05, gnorm=0.172, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19706
2023-02-20 18:44:11 - progress_bar.py[line:274] - INFO: epoch 001:   7458 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.7, bsz=40, num_updates=7450, lr=4.86917e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19717
2023-02-20 18:44:22 - progress_bar.py[line:274] - INFO: epoch 001:   7468 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=7460, lr=4.8688e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19729
2023-02-20 18:44:33 - progress_bar.py[line:274] - INFO: epoch 001:   7478 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.5, bsz=40, num_updates=7470, lr=4.86844e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=19740
2023-02-20 18:44:45 - progress_bar.py[line:274] - INFO: epoch 001:   7488 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.4, ups=0.88, wpb=111.3, bsz=40, num_updates=7480, lr=4.86808e-05, gnorm=0.187, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19751
2023-02-20 18:44:56 - progress_bar.py[line:274] - INFO: epoch 001:   7498 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=7490, lr=4.86772e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19762
2023-02-20 18:45:07 - progress_bar.py[line:274] - INFO: epoch 001:   7508 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.3, bsz=40, num_updates=7500, lr=4.86736e-05, gnorm=0.132, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19773
2023-02-20 18:45:18 - progress_bar.py[line:274] - INFO: epoch 001:   7518 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=111.9, bsz=40, num_updates=7510, lr=4.86699e-05, gnorm=0.163, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19784
2023-02-20 18:45:29 - progress_bar.py[line:274] - INFO: epoch 001:   7528 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.8, bsz=40, num_updates=7520, lr=4.86663e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19795
2023-02-20 18:45:40 - progress_bar.py[line:274] - INFO: epoch 001:   7538 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112, bsz=40, num_updates=7530, lr=4.86627e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19806
2023-02-20 18:45:52 - progress_bar.py[line:274] - INFO: epoch 001:   7548 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.7, bsz=40, num_updates=7540, lr=4.86591e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19818
2023-02-20 18:46:03 - progress_bar.py[line:274] - INFO: epoch 001:   7558 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111, bsz=40, num_updates=7550, lr=4.86555e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19829
2023-02-20 18:46:14 - progress_bar.py[line:274] - INFO: epoch 001:   7568 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.7, bsz=40, num_updates=7560, lr=4.86519e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19840
2023-02-20 18:46:25 - progress_bar.py[line:274] - INFO: epoch 001:   7578 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.88, wpb=112.9, bsz=40, num_updates=7570, lr=4.86482e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19851
2023-02-20 18:46:36 - progress_bar.py[line:274] - INFO: epoch 001:   7588 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.87, wpb=112.7, bsz=40, num_updates=7580, lr=4.86446e-05, gnorm=0.227, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19863
2023-02-20 18:46:48 - progress_bar.py[line:274] - INFO: epoch 001:   7598 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=7590, lr=4.8641e-05, gnorm=0.202, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19874
2023-02-20 18:46:59 - progress_bar.py[line:274] - INFO: epoch 001:   7608 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=7600, lr=4.86374e-05, gnorm=0.156, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=19885
2023-02-20 18:47:13 - progress_bar.py[line:274] - INFO: epoch 001:   7618 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=111.8, bsz=40, num_updates=7610, lr=4.86338e-05, gnorm=0.189, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19896
2023-02-20 18:47:24 - progress_bar.py[line:274] - INFO: epoch 001:   7628 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.91, wpb=112.9, bsz=40, num_updates=7620, lr=4.86301e-05, gnorm=0.19, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19910
2023-02-20 18:47:35 - progress_bar.py[line:274] - INFO: epoch 001:   7638 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111.1, bsz=40, num_updates=7630, lr=4.86265e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19921
2023-02-20 18:47:46 - progress_bar.py[line:274] - INFO: epoch 001:   7648 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.2, ups=0.87, wpb=110.6, bsz=40, num_updates=7640, lr=4.86229e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19933
2023-02-20 18:47:57 - progress_bar.py[line:274] - INFO: epoch 001:   7658 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=7650, lr=4.86193e-05, gnorm=0.159, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19944
2023-02-20 18:48:09 - progress_bar.py[line:274] - INFO: epoch 001:   7668 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.88, wpb=112.9, bsz=40, num_updates=7660, lr=4.86157e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19955
2023-02-20 18:48:20 - progress_bar.py[line:274] - INFO: epoch 001:   7678 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.88, wpb=110.9, bsz=40, num_updates=7670, lr=4.86121e-05, gnorm=0.198, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19966
2023-02-20 18:48:31 - progress_bar.py[line:274] - INFO: epoch 001:   7688 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.4, bsz=40, num_updates=7680, lr=4.86084e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19977
2023-02-20 18:48:42 - progress_bar.py[line:274] - INFO: epoch 001:   7698 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.4, bsz=40, num_updates=7690, lr=4.86048e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19989
2023-02-20 18:48:53 - progress_bar.py[line:274] - INFO: epoch 001:   7708 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.8, ups=0.93, wpb=111.7, bsz=40, num_updates=7700, lr=4.86012e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19999
2023-02-20 18:49:04 - progress_bar.py[line:274] - INFO: epoch 001:   7718 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=7710, lr=4.85976e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=20010
2023-02-20 18:49:15 - progress_bar.py[line:274] - INFO: epoch 001:   7728 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112, bsz=40, num_updates=7720, lr=4.8594e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20022
2023-02-20 18:49:26 - progress_bar.py[line:274] - INFO: epoch 001:   7738 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.2, ups=0.92, wpb=111.3, bsz=40, num_updates=7730, lr=4.85903e-05, gnorm=0.145, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20032
2023-02-20 18:49:37 - progress_bar.py[line:274] - INFO: epoch 001:   7748 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.88, wpb=113.2, bsz=40, num_updates=7740, lr=4.85867e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=20044
2023-02-20 18:49:49 - progress_bar.py[line:274] - INFO: epoch 001:   7758 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=7750, lr=4.85831e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20055
2023-02-20 18:50:00 - progress_bar.py[line:274] - INFO: epoch 001:   7768 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=112.1, bsz=40, num_updates=7760, lr=4.85795e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=20066
2023-02-20 18:50:11 - progress_bar.py[line:274] - INFO: epoch 001:   7778 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.92, wpb=112.4, bsz=40, num_updates=7770, lr=4.85759e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20077
2023-02-20 18:50:22 - progress_bar.py[line:274] - INFO: epoch 001:   7788 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=7780, lr=4.85723e-05, gnorm=0.168, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20088
2023-02-20 18:50:33 - progress_bar.py[line:274] - INFO: epoch 001:   7798 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.88, wpb=110.2, bsz=40, num_updates=7790, lr=4.85686e-05, gnorm=0.148, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20099
2023-02-20 18:50:44 - progress_bar.py[line:274] - INFO: epoch 001:   7808 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.88, wpb=112.6, bsz=40, num_updates=7800, lr=4.8565e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20111
2023-02-20 18:50:55 - progress_bar.py[line:274] - INFO: epoch 001:   7818 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=7810, lr=4.85614e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20122
2023-02-20 18:51:07 - progress_bar.py[line:274] - INFO: epoch 001:   7828 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112, bsz=40, num_updates=7820, lr=4.85578e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20133
2023-02-20 18:51:18 - progress_bar.py[line:274] - INFO: epoch 001:   7838 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=7830, lr=4.85542e-05, gnorm=0.136, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20144
2023-02-20 18:51:29 - progress_bar.py[line:274] - INFO: epoch 001:   7848 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=7840, lr=4.85505e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20155
2023-02-20 18:51:40 - progress_bar.py[line:274] - INFO: epoch 001:   7858 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.87, wpb=110.1, bsz=40, num_updates=7850, lr=4.85469e-05, gnorm=0.124, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20167
2023-02-20 18:51:51 - progress_bar.py[line:274] - INFO: epoch 001:   7868 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=7860, lr=4.85433e-05, gnorm=0.145, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=20178
2023-02-20 18:52:02 - progress_bar.py[line:274] - INFO: epoch 001:   7878 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.7, ups=0.91, wpb=112.2, bsz=40, num_updates=7870, lr=4.85397e-05, gnorm=0.149, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20189
2023-02-20 18:52:14 - progress_bar.py[line:274] - INFO: epoch 001:   7888 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.8, ups=0.89, wpb=112.8, bsz=40, num_updates=7880, lr=4.85361e-05, gnorm=0.148, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20200
2023-02-20 18:52:25 - progress_bar.py[line:274] - INFO: epoch 001:   7898 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.3, bsz=40, num_updates=7890, lr=4.85325e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20211
2023-02-20 18:52:36 - progress_bar.py[line:274] - INFO: epoch 001:   7908 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=7900, lr=4.85288e-05, gnorm=0.12, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20222
2023-02-20 18:52:47 - progress_bar.py[line:274] - INFO: epoch 001:   7918 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.3, bsz=40, num_updates=7910, lr=4.85252e-05, gnorm=0.115, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20233
2023-02-20 18:52:59 - progress_bar.py[line:274] - INFO: epoch 001:   7928 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.87, wpb=112.4, bsz=40, num_updates=7920, lr=4.85216e-05, gnorm=0.148, clip=0, loss_scale=4096, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=20245
2023-02-20 18:53:09 - progress_bar.py[line:274] - INFO: epoch 001:   7938 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.3, bsz=40, num_updates=7930, lr=4.8518e-05, gnorm=0.142, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20256
2023-02-20 18:53:20 - progress_bar.py[line:274] - INFO: epoch 001:   7948 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.6, ups=0.92, wpb=112, bsz=40, num_updates=7940, lr=4.85144e-05, gnorm=0.176, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20267
2023-02-20 18:53:31 - progress_bar.py[line:274] - INFO: epoch 001:   7958 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=107.7, ups=0.96, wpb=112.3, bsz=40, num_updates=7950, lr=4.85107e-05, gnorm=0.151, clip=0, loss_scale=4096, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=20277
2023-02-20 18:53:42 - progress_bar.py[line:274] - INFO: epoch 001:   7968 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.2, bsz=40, num_updates=7960, lr=4.85071e-05, gnorm=0.128, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20288
2023-02-20 18:53:53 - progress_bar.py[line:274] - INFO: epoch 001:   7978 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.6, ups=0.92, wpb=111.5, bsz=40, num_updates=7970, lr=4.85035e-05, gnorm=0.154, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=20299
2023-02-20 18:54:04 - progress_bar.py[line:274] - INFO: epoch 001:   7988 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.4, bsz=40, num_updates=7980, lr=4.84999e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20311
2023-02-20 18:54:15 - progress_bar.py[line:274] - INFO: epoch 001:   7998 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.8, bsz=40, num_updates=7990, lr=4.84963e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20321
2023-02-20 18:54:26 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 18:54:27 - progress_bar.py[line:274] - INFO: epoch 001:   8009 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.7, ups=0.83, wpb=111.8, bsz=40, num_updates=8000, lr=4.84927e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=20333
2023-02-20 18:54:27 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-20 18:54:28 - train.py[line:549] - INFO: 0 / 6234
2023-02-20 18:54:28 - train.py[line:551] - INFO: load:0.92 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-20 18:56:30 - train.py[line:549] - INFO: 200 / 6234
2023-02-20 18:56:30 - train.py[line:551] - INFO: load:0.94 valid_run:122.12 task_valid:119.06 collect_output:1.98
2023-02-20 18:58:30 - train.py[line:549] - INFO: 400 / 6234
2023-02-20 18:58:30 - train.py[line:551] - INFO: load:0.97 valid_run:241.59 task_valid:234.75 collect_output:4.66
2023-02-20 19:00:32 - train.py[line:549] - INFO: 600 / 6234
2023-02-20 19:00:32 - train.py[line:551] - INFO: load:0.99 valid_run:363.06 task_valid:351.12 collect_output:8.70
2023-02-20 19:02:33 - train.py[line:549] - INFO: 800 / 6234
2023-02-20 19:02:33 - train.py[line:551] - INFO: load:1.02 valid_run:484.44 task_valid:464.63 collect_output:15.50
2023-02-20 19:04:33 - train.py[line:549] - INFO: 1000 / 6234
2023-02-20 19:04:33 - train.py[line:551] - INFO: load:1.04 valid_run:604.64 task_valid:581.84 collect_output:17.40
2023-02-20 19:06:36 - train.py[line:549] - INFO: 1200 / 6234
2023-02-20 19:06:36 - train.py[line:551] - INFO: load:1.07 valid_run:727.14 task_valid:700.31 collect_output:20.35
2023-02-20 19:08:38 - train.py[line:549] - INFO: 1400 / 6234
2023-02-20 19:08:38 - train.py[line:551] - INFO: load:1.09 valid_run:849.48 task_valid:818.14 collect_output:23.79
2023-02-20 19:10:40 - train.py[line:549] - INFO: 1600 / 6234
2023-02-20 19:10:40 - train.py[line:551] - INFO: load:1.12 valid_run:970.77 task_valid:934.41 collect_output:27.73
2023-02-20 19:12:43 - train.py[line:549] - INFO: 1800 / 6234
2023-02-20 19:12:43 - train.py[line:551] - INFO: load:1.14 valid_run:1093.77 task_valid:1051.29 collect_output:32.80
2023-02-20 19:14:44 - train.py[line:549] - INFO: 2000 / 6234
2023-02-20 19:14:44 - train.py[line:551] - INFO: load:1.17 valid_run:1214.86 task_valid:1163.72 collect_output:40.41
2023-02-20 19:16:43 - train.py[line:549] - INFO: 2200 / 6234
2023-02-20 19:16:43 - train.py[line:551] - INFO: load:1.19 valid_run:1334.44 task_valid:1279.05 collect_output:43.61
2023-02-20 19:18:44 - train.py[line:549] - INFO: 2400 / 6234
2023-02-20 19:18:44 - train.py[line:551] - INFO: load:1.22 valid_run:1455.44 task_valid:1395.81 collect_output:46.77
2023-02-20 19:20:43 - train.py[line:549] - INFO: 2600 / 6234
2023-02-20 19:20:43 - train.py[line:551] - INFO: load:1.24 valid_run:1573.84 task_valid:1509.21 collect_output:50.74
2023-02-20 19:22:43 - train.py[line:549] - INFO: 2800 / 6234
2023-02-20 19:22:43 - train.py[line:551] - INFO: load:1.27 valid_run:1694.27 task_valid:1626.64 collect_output:52.70
2023-02-20 19:24:44 - train.py[line:549] - INFO: 3000 / 6234
2023-02-20 19:24:44 - train.py[line:551] - INFO: load:1.29 valid_run:1814.73 task_valid:1742.58 collect_output:56.18
2023-02-20 19:26:45 - train.py[line:549] - INFO: 3200 / 6234
2023-02-20 19:26:45 - train.py[line:551] - INFO: load:1.32 valid_run:1935.25 task_valid:1856.18 collect_output:62.06
2023-02-20 19:28:45 - train.py[line:549] - INFO: 3400 / 6234
2023-02-20 19:28:45 - train.py[line:551] - INFO: load:1.34 valid_run:2056.04 task_valid:1971.90 collect_output:66.07
2023-02-20 19:30:46 - train.py[line:549] - INFO: 3600 / 6234
2023-02-20 19:30:46 - train.py[line:551] - INFO: load:1.37 valid_run:2176.23 task_valid:2089.48 collect_output:67.65
2023-02-20 19:32:46 - train.py[line:549] - INFO: 3800 / 6234
2023-02-20 19:32:46 - train.py[line:551] - INFO: load:1.39 valid_run:2297.03 task_valid:2206.18 collect_output:70.69
2023-02-20 19:34:47 - train.py[line:549] - INFO: 4000 / 6234
2023-02-20 19:34:47 - train.py[line:551] - INFO: load:1.42 valid_run:2417.07 task_valid:2322.62 collect_output:73.24
2023-02-20 19:36:48 - train.py[line:549] - INFO: 4200 / 6234
2023-02-20 19:36:48 - train.py[line:551] - INFO: load:1.44 valid_run:2538.15 task_valid:2438.81 collect_output:77.08
2023-02-20 19:38:49 - train.py[line:549] - INFO: 4400 / 6234
2023-02-20 19:38:49 - train.py[line:551] - INFO: load:1.47 valid_run:2659.62 task_valid:2557.44 collect_output:78.84
2023-02-20 19:40:49 - train.py[line:549] - INFO: 4600 / 6234
2023-02-20 19:40:49 - train.py[line:551] - INFO: load:1.49 valid_run:2779.27 task_valid:2671.44 collect_output:83.43
2023-02-20 19:42:48 - train.py[line:549] - INFO: 4800 / 6234
2023-02-20 19:42:48 - train.py[line:551] - INFO: load:1.52 valid_run:2898.46 task_valid:2787.23 collect_output:85.80
2023-02-20 19:44:49 - train.py[line:549] - INFO: 5000 / 6234
2023-02-20 19:44:49 - train.py[line:551] - INFO: load:1.55 valid_run:3019.36 task_valid:2903.10 collect_output:89.76
2023-02-20 19:46:52 - train.py[line:549] - INFO: 5200 / 6234
2023-02-20 19:46:52 - train.py[line:551] - INFO: load:1.57 valid_run:3141.72 task_valid:3018.82 collect_output:95.33
2023-02-20 19:48:51 - train.py[line:549] - INFO: 5400 / 6234
2023-02-20 19:48:51 - train.py[line:551] - INFO: load:1.60 valid_run:3260.58 task_valid:3132.53 collect_output:99.45
2023-02-20 19:50:52 - train.py[line:549] - INFO: 5600 / 6234
2023-02-20 19:50:52 - train.py[line:551] - INFO: load:1.62 valid_run:3381.78 task_valid:3251.47 collect_output:100.68
2023-02-20 19:52:53 - train.py[line:549] - INFO: 5800 / 6234
2023-02-20 19:52:53 - train.py[line:551] - INFO: load:1.65 valid_run:3502.54 task_valid:3366.50 collect_output:105.37
2023-02-20 19:54:54 - train.py[line:549] - INFO: 6000 / 6234
2023-02-20 19:54:54 - train.py[line:551] - INFO: load:1.68 valid_run:3623.66 task_valid:3484.38 collect_output:107.58
2023-02-20 19:56:54 - train.py[line:549] - INFO: 6200 / 6234
2023-02-20 19:56:54 - train.py[line:551] - INFO: load:1.70 valid_run:3744.24 task_valid:3602.45 collect_output:109.06

====================================================================================================
SGG eval:     R @ 50: 0.6678;     R @ 100: 0.6915;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4436;    mR @ 100: 0.4672;    mR @ 500: 0.5303;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.5625) (covering:0.3714) (eating:0.7647) (flying in:0.5000) (growing on:0.5000) (hanging from:0.5161) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0000) (parked on:1.0000) (playing:0.0000) (riding:0.9673) (says:0.0000) (sitting on:0.7415) (standing on:0.3793) (using:0.6000) (walking in:0.0000) (walking on:0.8108) (watching:0.5139) 
--------------------------------------------------------
====================================================================================================

2023-02-20 19:57:25 - train.py[line:487] - INFO: 0.6914624649859943

====================================================================================================
SGG eval:     R @ 50: 0.6678;     R @ 100: 0.6915;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4436;    mR @ 100: 0.4672;    mR @ 500: 0.5303;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.5625) (covering:0.3714) (eating:0.7647) (flying in:0.5000) (growing on:0.5000) (hanging from:0.5161) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0000) (parked on:1.0000) (playing:0.0000) (riding:0.9673) (says:0.0000) (sitting on:0.7415) (standing on:0.3793) (using:0.6000) (walking in:0.0000) (walking on:0.8108) (watching:0.5139) 
--------------------------------------------------------
====================================================================================================

2023-02-20 19:57:25 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-20 19:57:25 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.235 | loss_v1 0 | loss_v2 0 | nll_loss 0.069 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.691462 | ppl 1.05 | vqa_score 0.4493 | wps 118.8 | wpb 72 | bsz 24 | num_updates 8000 | best_R@100 0.691462
2023-02-20 19:57:25 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2023-02-20 19:57:25 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_8000.pt
2023-02-20 19:57:31 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_8000.pt
2023-02-20 19:57:36 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.6914624649859943) (writing took 10.701853588223457 seconds)
2023-02-20 19:57:47 - progress_bar.py[line:274] - INFO: epoch 001:   8019 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=110.7, bsz=40, num_updates=8010, lr=4.8489e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24134
2023-02-20 19:57:59 - progress_bar.py[line:274] - INFO: epoch 001:   8029 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.9, wpb=112.5, bsz=40, num_updates=8020, lr=4.84854e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24145
2023-02-20 19:58:06 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-02-20 19:58:11 - progress_bar.py[line:274] - INFO: epoch 001:   8040 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=93.7, ups=0.84, wpb=111.4, bsz=40, num_updates=8030, lr=4.84818e-05, gnorm=0.154, clip=0, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=24157
2023-02-20 19:58:22 - progress_bar.py[line:274] - INFO: epoch 001:   8050 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.89, wpb=112.1, bsz=40, num_updates=8040, lr=4.84782e-05, gnorm=0.147, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24169
2023-02-20 19:58:34 - progress_bar.py[line:274] - INFO: epoch 001:   8060 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113.6, nsentences=40, sample_size=113.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.88, wpb=113.6, bsz=40, num_updates=8050, lr=4.84746e-05, gnorm=0.092, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24180
2023-02-20 19:58:45 - progress_bar.py[line:274] - INFO: epoch 001:   8070 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.9, bsz=40, num_updates=8060, lr=4.84709e-05, gnorm=0.122, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24191
2023-02-20 19:58:56 - progress_bar.py[line:274] - INFO: epoch 001:   8080 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111, bsz=40, num_updates=8070, lr=4.84673e-05, gnorm=0.105, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24202
2023-02-20 19:59:08 - progress_bar.py[line:274] - INFO: epoch 001:   8090 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.87, wpb=112.5, bsz=40, num_updates=8080, lr=4.84637e-05, gnorm=0.096, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24214
2023-02-20 19:59:19 - progress_bar.py[line:274] - INFO: epoch 001:   8100 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.2, bsz=40, num_updates=8090, lr=4.84601e-05, gnorm=0.15, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24225
2023-02-20 19:59:30 - progress_bar.py[line:274] - INFO: epoch 001:   8110 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.1, bsz=40, num_updates=8100, lr=4.84565e-05, gnorm=0.164, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24236
2023-02-20 19:59:42 - progress_bar.py[line:274] - INFO: epoch 001:   8120 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=111.6, bsz=40, num_updates=8110, lr=4.84529e-05, gnorm=0.132, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24248
2023-02-20 19:59:53 - progress_bar.py[line:274] - INFO: epoch 001:   8130 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.7, bsz=40, num_updates=8120, lr=4.84492e-05, gnorm=0.104, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24259
2023-02-20 20:00:04 - progress_bar.py[line:274] - INFO: epoch 001:   8140 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.5, bsz=40, num_updates=8130, lr=4.84456e-05, gnorm=0.089, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24270
2023-02-20 20:00:15 - progress_bar.py[line:274] - INFO: epoch 001:   8150 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.9, ups=0.91, wpb=112.1, bsz=40, num_updates=8140, lr=4.8442e-05, gnorm=0.191, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24281
2023-02-20 20:00:26 - progress_bar.py[line:274] - INFO: epoch 001:   8160 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112.2, bsz=40, num_updates=8150, lr=4.84384e-05, gnorm=0.106, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24293
2023-02-20 20:00:37 - progress_bar.py[line:274] - INFO: epoch 001:   8170 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.5, bsz=40, num_updates=8160, lr=4.84348e-05, gnorm=0.102, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24304
2023-02-20 20:00:48 - progress_bar.py[line:274] - INFO: epoch 001:   8180 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.4, ups=0.92, wpb=111.3, bsz=40, num_updates=8170, lr=4.84311e-05, gnorm=0.175, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24315
2023-02-20 20:00:59 - progress_bar.py[line:274] - INFO: epoch 001:   8190 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=8180, lr=4.84275e-05, gnorm=0.166, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=24326
2023-02-20 20:01:10 - progress_bar.py[line:274] - INFO: epoch 001:   8200 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=112.2, bsz=40, num_updates=8190, lr=4.84239e-05, gnorm=0.109, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24337
2023-02-20 20:01:21 - progress_bar.py[line:274] - INFO: epoch 001:   8210 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=109.8, bsz=40, num_updates=8200, lr=4.84203e-05, gnorm=0.146, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24348
2023-02-20 20:01:33 - progress_bar.py[line:274] - INFO: epoch 001:   8220 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.3, bsz=40, num_updates=8210, lr=4.84167e-05, gnorm=0.135, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24359
2023-02-20 20:01:44 - progress_bar.py[line:274] - INFO: epoch 001:   8230 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=8220, lr=4.84131e-05, gnorm=0.098, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24370
2023-02-20 20:01:55 - progress_bar.py[line:274] - INFO: epoch 001:   8240 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.8, ups=0.93, wpb=112.5, bsz=40, num_updates=8230, lr=4.84094e-05, gnorm=0.125, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24381
2023-02-20 20:02:06 - progress_bar.py[line:274] - INFO: epoch 001:   8250 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.88, wpb=111.3, bsz=40, num_updates=8240, lr=4.84058e-05, gnorm=0.141, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24392
2023-02-20 20:02:17 - progress_bar.py[line:274] - INFO: epoch 001:   8260 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.4, bsz=40, num_updates=8250, lr=4.84022e-05, gnorm=0.106, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24404
2023-02-20 20:02:29 - progress_bar.py[line:274] - INFO: epoch 001:   8270 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.3, bsz=40, num_updates=8260, lr=4.83986e-05, gnorm=0.149, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24415
2023-02-20 20:02:40 - progress_bar.py[line:274] - INFO: epoch 001:   8280 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.4, bsz=40, num_updates=8270, lr=4.8395e-05, gnorm=0.084, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24426
2023-02-20 20:02:51 - progress_bar.py[line:274] - INFO: epoch 001:   8290 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.7, ups=0.89, wpb=111.5, bsz=40, num_updates=8280, lr=4.83913e-05, gnorm=0.174, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24438
2023-02-20 20:03:02 - progress_bar.py[line:274] - INFO: epoch 001:   8300 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.7, bsz=40, num_updates=8290, lr=4.83877e-05, gnorm=0.099, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24449
2023-02-20 20:03:14 - progress_bar.py[line:274] - INFO: epoch 001:   8310 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.8, bsz=40, num_updates=8300, lr=4.83841e-05, gnorm=0.142, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24460
2023-02-20 20:03:25 - progress_bar.py[line:274] - INFO: epoch 001:   8320 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.3, bsz=40, num_updates=8310, lr=4.83805e-05, gnorm=0.178, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24471
2023-02-20 20:03:36 - progress_bar.py[line:274] - INFO: epoch 001:   8330 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.6, bsz=40, num_updates=8320, lr=4.83769e-05, gnorm=0.11, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24482
2023-02-20 20:03:47 - progress_bar.py[line:274] - INFO: epoch 001:   8340 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.9, bsz=40, num_updates=8330, lr=4.83733e-05, gnorm=0.095, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24494
2023-02-20 20:03:58 - progress_bar.py[line:274] - INFO: epoch 001:   8350 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=8340, lr=4.83696e-05, gnorm=0.105, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24505
2023-02-20 20:04:10 - progress_bar.py[line:274] - INFO: epoch 001:   8360 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.8, bsz=40, num_updates=8350, lr=4.8366e-05, gnorm=0.093, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24516
2023-02-20 20:04:21 - progress_bar.py[line:274] - INFO: epoch 001:   8370 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.7, bsz=40, num_updates=8360, lr=4.83624e-05, gnorm=0.115, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24527
2023-02-20 20:04:32 - progress_bar.py[line:274] - INFO: epoch 001:   8380 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=111.9, bsz=40, num_updates=8370, lr=4.83588e-05, gnorm=0.116, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24539
2023-02-20 20:04:43 - progress_bar.py[line:274] - INFO: epoch 001:   8390 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.8, ups=0.92, wpb=112.8, bsz=40, num_updates=8380, lr=4.83552e-05, gnorm=0.111, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24550
2023-02-20 20:04:55 - progress_bar.py[line:274] - INFO: epoch 001:   8400 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=110.3, bsz=40, num_updates=8390, lr=4.83515e-05, gnorm=0.095, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24561
2023-02-20 20:05:06 - progress_bar.py[line:274] - INFO: epoch 001:   8410 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.3, bsz=40, num_updates=8400, lr=4.83479e-05, gnorm=0.164, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24572
2023-02-20 20:05:17 - progress_bar.py[line:274] - INFO: epoch 001:   8420 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.92, wpb=112.1, bsz=40, num_updates=8410, lr=4.83443e-05, gnorm=0.117, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24583
2023-02-20 20:05:28 - progress_bar.py[line:274] - INFO: epoch 001:   8430 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.8, bsz=40, num_updates=8420, lr=4.83407e-05, gnorm=0.102, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24594
2023-02-20 20:05:39 - progress_bar.py[line:274] - INFO: epoch 001:   8440 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=110.4, bsz=40, num_updates=8430, lr=4.83371e-05, gnorm=0.114, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24605
2023-02-20 20:05:50 - progress_bar.py[line:274] - INFO: epoch 001:   8450 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.89, wpb=112.3, bsz=40, num_updates=8440, lr=4.83335e-05, gnorm=0.136, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24616
2023-02-20 20:06:01 - progress_bar.py[line:274] - INFO: epoch 001:   8460 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.6, bsz=40, num_updates=8450, lr=4.83298e-05, gnorm=0.136, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24627
2023-02-20 20:06:12 - progress_bar.py[line:274] - INFO: epoch 001:   8470 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.3, bsz=40, num_updates=8460, lr=4.83262e-05, gnorm=0.108, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24638
2023-02-20 20:06:23 - progress_bar.py[line:274] - INFO: epoch 001:   8480 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=8470, lr=4.83226e-05, gnorm=0.137, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24650
2023-02-20 20:06:34 - progress_bar.py[line:274] - INFO: epoch 001:   8490 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112, bsz=40, num_updates=8480, lr=4.8319e-05, gnorm=0.116, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24661
2023-02-20 20:06:45 - progress_bar.py[line:274] - INFO: epoch 001:   8500 / 71012 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.9, bsz=40, num_updates=8490, lr=4.83154e-05, gnorm=0.106, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24672
2023-02-20 20:06:56 - progress_bar.py[line:274] - INFO: epoch 001:   8510 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.92, wpb=110.9, bsz=40, num_updates=8500, lr=4.83117e-05, gnorm=0.117, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24683
2023-02-20 20:07:08 - progress_bar.py[line:274] - INFO: epoch 001:   8520 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.89, wpb=110.1, bsz=40, num_updates=8510, lr=4.83081e-05, gnorm=0.128, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24694
2023-02-20 20:07:19 - progress_bar.py[line:274] - INFO: epoch 001:   8530 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=8520, lr=4.83045e-05, gnorm=0.165, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24705
2023-02-20 20:07:30 - progress_bar.py[line:274] - INFO: epoch 001:   8540 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=8530, lr=4.83009e-05, gnorm=0.195, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24717
2023-02-20 20:07:42 - progress_bar.py[line:274] - INFO: epoch 001:   8550 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.7, bsz=40, num_updates=8540, lr=4.82973e-05, gnorm=0.149, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24728
2023-02-20 20:07:52 - progress_bar.py[line:274] - INFO: epoch 001:   8560 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.1, ups=0.93, wpb=111.4, bsz=40, num_updates=8550, lr=4.82937e-05, gnorm=0.144, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=24739
2023-02-20 20:08:03 - progress_bar.py[line:274] - INFO: epoch 001:   8570 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=8560, lr=4.829e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24750
2023-02-20 20:08:14 - progress_bar.py[line:274] - INFO: epoch 001:   8580 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.91, wpb=111.5, bsz=40, num_updates=8570, lr=4.82864e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24761
2023-02-20 20:08:25 - progress_bar.py[line:274] - INFO: epoch 001:   8590 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.7, bsz=40, num_updates=8580, lr=4.82828e-05, gnorm=0.173, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24772
2023-02-20 20:08:36 - progress_bar.py[line:274] - INFO: epoch 001:   8600 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.5, bsz=40, num_updates=8590, lr=4.82792e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24783
2023-02-20 20:08:47 - progress_bar.py[line:274] - INFO: epoch 001:   8610 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.3, bsz=40, num_updates=8600, lr=4.82756e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24794
2023-02-20 20:08:58 - progress_bar.py[line:274] - INFO: epoch 001:   8620 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.9, wpb=111.4, bsz=40, num_updates=8610, lr=4.82719e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24805
2023-02-20 20:09:10 - progress_bar.py[line:274] - INFO: epoch 001:   8630 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=112.1, bsz=40, num_updates=8620, lr=4.82683e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24816
2023-02-20 20:09:21 - progress_bar.py[line:274] - INFO: epoch 001:   8640 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.6, bsz=40, num_updates=8630, lr=4.82647e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24827
2023-02-20 20:09:32 - progress_bar.py[line:274] - INFO: epoch 001:   8650 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=113, bsz=40, num_updates=8640, lr=4.82611e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24839
2023-02-20 20:09:43 - progress_bar.py[line:274] - INFO: epoch 001:   8660 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.91, wpb=109.5, bsz=40, num_updates=8650, lr=4.82575e-05, gnorm=0.188, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=24850
2023-02-20 20:09:54 - progress_bar.py[line:274] - INFO: epoch 001:   8670 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112, bsz=40, num_updates=8660, lr=4.82539e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24861
2023-02-20 20:10:06 - progress_bar.py[line:274] - INFO: epoch 001:   8680 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.87, wpb=111.6, bsz=40, num_updates=8670, lr=4.82502e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24872
2023-02-20 20:10:17 - progress_bar.py[line:274] - INFO: epoch 001:   8690 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.9, bsz=40, num_updates=8680, lr=4.82466e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24883
2023-02-20 20:10:28 - progress_bar.py[line:274] - INFO: epoch 001:   8700 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.9, wpb=112.8, bsz=40, num_updates=8690, lr=4.8243e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24894
2023-02-20 20:10:39 - progress_bar.py[line:274] - INFO: epoch 001:   8710 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.8, ups=0.87, wpb=112.1, bsz=40, num_updates=8700, lr=4.82394e-05, gnorm=0.142, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24906
2023-02-20 20:10:50 - progress_bar.py[line:274] - INFO: epoch 001:   8720 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=8710, lr=4.82358e-05, gnorm=0.132, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24917
2023-02-20 20:11:01 - progress_bar.py[line:274] - INFO: epoch 001:   8730 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=110.9, bsz=40, num_updates=8720, lr=4.82321e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24928
2023-02-20 20:11:12 - progress_bar.py[line:274] - INFO: epoch 001:   8740 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.4, bsz=40, num_updates=8730, lr=4.82285e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24939
2023-02-20 20:11:23 - progress_bar.py[line:274] - INFO: epoch 001:   8750 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.2, bsz=40, num_updates=8740, lr=4.82249e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24950
2023-02-20 20:11:35 - progress_bar.py[line:274] - INFO: epoch 001:   8760 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.89, wpb=110.6, bsz=40, num_updates=8750, lr=4.82213e-05, gnorm=0.16, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24961
2023-02-20 20:11:46 - progress_bar.py[line:274] - INFO: epoch 001:   8770 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.5, bsz=40, num_updates=8760, lr=4.82177e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24972
2023-02-20 20:11:57 - progress_bar.py[line:274] - INFO: epoch 001:   8780 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=8770, lr=4.82141e-05, gnorm=0.181, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24984
2023-02-20 20:12:08 - progress_bar.py[line:274] - INFO: epoch 001:   8790 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.9, bsz=40, num_updates=8780, lr=4.82104e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24994
2023-02-20 20:12:19 - progress_bar.py[line:274] - INFO: epoch 001:   8800 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111, bsz=40, num_updates=8790, lr=4.82068e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25006
2023-02-20 20:12:30 - progress_bar.py[line:274] - INFO: epoch 001:   8810 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.8, ups=0.91, wpb=112.3, bsz=40, num_updates=8800, lr=4.82032e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25017
2023-02-20 20:12:42 - progress_bar.py[line:274] - INFO: epoch 001:   8820 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.6, bsz=40, num_updates=8810, lr=4.81996e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25028
2023-02-20 20:12:53 - progress_bar.py[line:274] - INFO: epoch 001:   8830 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112.7, bsz=40, num_updates=8820, lr=4.8196e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25039
2023-02-20 20:13:04 - progress_bar.py[line:274] - INFO: epoch 001:   8840 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.8, bsz=40, num_updates=8830, lr=4.81923e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25050
2023-02-20 20:13:15 - progress_bar.py[line:274] - INFO: epoch 001:   8850 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.89, wpb=111, bsz=40, num_updates=8840, lr=4.81887e-05, gnorm=0.176, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25062
2023-02-20 20:13:26 - progress_bar.py[line:274] - INFO: epoch 001:   8860 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112, bsz=40, num_updates=8850, lr=4.81851e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25073
2023-02-20 20:13:38 - progress_bar.py[line:274] - INFO: epoch 001:   8870 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112.4, bsz=40, num_updates=8860, lr=4.81815e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25084
2023-02-20 20:13:49 - progress_bar.py[line:274] - INFO: epoch 001:   8880 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=110.7, bsz=40, num_updates=8870, lr=4.81779e-05, gnorm=0.132, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25095
2023-02-20 20:14:00 - progress_bar.py[line:274] - INFO: epoch 001:   8890 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.9, bsz=40, num_updates=8880, lr=4.81743e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25106
2023-02-20 20:14:12 - progress_bar.py[line:274] - INFO: epoch 001:   8900 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.86, wpb=111.4, bsz=40, num_updates=8890, lr=4.81706e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=25118
2023-02-20 20:14:22 - progress_bar.py[line:274] - INFO: epoch 001:   8910 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.6, ups=0.92, wpb=112.4, bsz=40, num_updates=8900, lr=4.8167e-05, gnorm=0.154, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25129
2023-02-20 20:14:33 - progress_bar.py[line:274] - INFO: epoch 001:   8920 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.1, bsz=40, num_updates=8910, lr=4.81634e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25140
2023-02-20 20:14:44 - progress_bar.py[line:274] - INFO: epoch 001:   8930 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.4, ups=0.92, wpb=111.3, bsz=40, num_updates=8920, lr=4.81598e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25151
2023-02-20 20:14:56 - progress_bar.py[line:274] - INFO: epoch 001:   8940 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.4, bsz=40, num_updates=8930, lr=4.81562e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25162
2023-02-20 20:15:07 - progress_bar.py[line:274] - INFO: epoch 001:   8950 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111, bsz=40, num_updates=8940, lr=4.81525e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25173
2023-02-20 20:15:18 - progress_bar.py[line:274] - INFO: epoch 001:   8960 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.92, wpb=109.7, bsz=40, num_updates=8950, lr=4.81489e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25184
2023-02-20 20:15:29 - progress_bar.py[line:274] - INFO: epoch 001:   8970 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.5, bsz=40, num_updates=8960, lr=4.81453e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=25195
2023-02-20 20:15:40 - progress_bar.py[line:274] - INFO: epoch 001:   8980 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=112.1, bsz=40, num_updates=8970, lr=4.81417e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25207
2023-02-20 20:15:52 - progress_bar.py[line:274] - INFO: epoch 001:   8990 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.6, bsz=40, num_updates=8980, lr=4.81381e-05, gnorm=0.178, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=25218
2023-02-20 20:16:03 - progress_bar.py[line:274] - INFO: epoch 001:   9000 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.3, bsz=40, num_updates=8990, lr=4.81345e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25229
2023-02-20 20:16:14 - progress_bar.py[line:274] - INFO: epoch 001:   9010 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.88, wpb=109.6, bsz=40, num_updates=9000, lr=4.81308e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25240
2023-02-20 20:16:25 - progress_bar.py[line:274] - INFO: epoch 001:   9020 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.6, bsz=40, num_updates=9010, lr=4.81272e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25251
2023-02-20 20:16:36 - progress_bar.py[line:274] - INFO: epoch 001:   9030 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.87, wpb=111.9, bsz=40, num_updates=9020, lr=4.81236e-05, gnorm=0.15, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25263
2023-02-20 20:16:48 - progress_bar.py[line:274] - INFO: epoch 001:   9040 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=111.6, bsz=40, num_updates=9030, lr=4.812e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25274
2023-02-20 20:16:59 - progress_bar.py[line:274] - INFO: epoch 001:   9050 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.89, wpb=111.4, bsz=40, num_updates=9040, lr=4.81164e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25286
2023-02-20 20:17:10 - progress_bar.py[line:274] - INFO: epoch 001:   9060 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=112, bsz=40, num_updates=9050, lr=4.81127e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25297
2023-02-20 20:17:22 - progress_bar.py[line:274] - INFO: epoch 001:   9070 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.2, bsz=40, num_updates=9060, lr=4.81091e-05, gnorm=0.123, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25308
2023-02-20 20:17:32 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 20:17:34 - progress_bar.py[line:274] - INFO: epoch 001:   9081 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.2, ups=0.81, wpb=111, bsz=40, num_updates=9070, lr=4.81055e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=25320
2023-02-20 20:17:45 - progress_bar.py[line:274] - INFO: epoch 001:   9091 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.8, bsz=40, num_updates=9080, lr=4.81019e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25332
2023-02-20 20:17:56 - progress_bar.py[line:274] - INFO: epoch 001:   9101 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111, bsz=40, num_updates=9090, lr=4.80983e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25343
2023-02-20 20:18:08 - progress_bar.py[line:274] - INFO: epoch 001:   9111 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=110.8, bsz=40, num_updates=9100, lr=4.80947e-05, gnorm=0.162, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25354
2023-02-20 20:18:19 - progress_bar.py[line:274] - INFO: epoch 001:   9121 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111, bsz=40, num_updates=9110, lr=4.8091e-05, gnorm=0.15, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25365
2023-02-20 20:18:30 - progress_bar.py[line:274] - INFO: epoch 001:   9131 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=9120, lr=4.80874e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=25376
2023-02-20 20:18:41 - progress_bar.py[line:274] - INFO: epoch 001:   9141 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.8, bsz=40, num_updates=9130, lr=4.80838e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25387
2023-02-20 20:18:52 - progress_bar.py[line:274] - INFO: epoch 001:   9151 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.3, bsz=40, num_updates=9140, lr=4.80802e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25398
2023-02-20 20:19:03 - progress_bar.py[line:274] - INFO: epoch 001:   9161 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.2, bsz=40, num_updates=9150, lr=4.80766e-05, gnorm=0.168, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25410
2023-02-20 20:19:15 - progress_bar.py[line:274] - INFO: epoch 001:   9171 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.86, wpb=111.1, bsz=40, num_updates=9160, lr=4.80729e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=25421
2023-02-20 20:19:26 - progress_bar.py[line:274] - INFO: epoch 001:   9181 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.7, ups=0.87, wpb=112, bsz=40, num_updates=9170, lr=4.80693e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25433
2023-02-20 20:19:38 - progress_bar.py[line:274] - INFO: epoch 001:   9191 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.4, bsz=40, num_updates=9180, lr=4.80657e-05, gnorm=0.196, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25444
2023-02-20 20:19:49 - progress_bar.py[line:274] - INFO: epoch 001:   9201 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.2, ups=0.91, wpb=111.3, bsz=40, num_updates=9190, lr=4.80621e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25455
2023-02-20 20:20:00 - progress_bar.py[line:274] - INFO: epoch 001:   9211 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.4, bsz=40, num_updates=9200, lr=4.80585e-05, gnorm=0.146, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25466
2023-02-20 20:20:11 - progress_bar.py[line:274] - INFO: epoch 001:   9221 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112, bsz=40, num_updates=9210, lr=4.80549e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=25477
2023-02-20 20:20:22 - progress_bar.py[line:274] - INFO: epoch 001:   9231 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.8, ups=0.91, wpb=111.9, bsz=40, num_updates=9220, lr=4.80512e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25488
2023-02-20 20:20:33 - progress_bar.py[line:274] - INFO: epoch 001:   9241 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.1, bsz=40, num_updates=9230, lr=4.80476e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25499
2023-02-20 20:20:44 - progress_bar.py[line:274] - INFO: epoch 001:   9251 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=111.9, bsz=40, num_updates=9240, lr=4.8044e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25511
2023-02-20 20:20:56 - progress_bar.py[line:274] - INFO: epoch 001:   9261 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.87, wpb=112, bsz=40, num_updates=9250, lr=4.80404e-05, gnorm=0.168, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25522
2023-02-20 20:21:07 - progress_bar.py[line:274] - INFO: epoch 001:   9271 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=110.8, bsz=40, num_updates=9260, lr=4.80368e-05, gnorm=0.154, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25533
2023-02-20 20:21:18 - progress_bar.py[line:274] - INFO: epoch 001:   9281 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.8, bsz=40, num_updates=9270, lr=4.80331e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25545
2023-02-20 20:21:30 - progress_bar.py[line:274] - INFO: epoch 001:   9291 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.87, wpb=112.8, bsz=40, num_updates=9280, lr=4.80295e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25556
2023-02-20 20:21:41 - progress_bar.py[line:274] - INFO: epoch 001:   9301 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.1, bsz=40, num_updates=9290, lr=4.80259e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25567
2023-02-20 20:21:52 - progress_bar.py[line:274] - INFO: epoch 001:   9311 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.3, bsz=40, num_updates=9300, lr=4.80223e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25579
2023-02-20 20:22:03 - progress_bar.py[line:274] - INFO: epoch 001:   9321 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.7, bsz=40, num_updates=9310, lr=4.80187e-05, gnorm=0.171, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25590
2023-02-20 20:22:15 - progress_bar.py[line:274] - INFO: epoch 001:   9331 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.2, bsz=40, num_updates=9320, lr=4.80151e-05, gnorm=0.161, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25601
2023-02-20 20:22:26 - progress_bar.py[line:274] - INFO: epoch 001:   9341 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.87, wpb=111.9, bsz=40, num_updates=9330, lr=4.80114e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25612
2023-02-20 20:22:37 - progress_bar.py[line:274] - INFO: epoch 001:   9351 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.2, bsz=40, num_updates=9340, lr=4.80078e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25623
2023-02-20 20:22:48 - progress_bar.py[line:274] - INFO: epoch 001:   9361 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.6, bsz=40, num_updates=9350, lr=4.80042e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25635
2023-02-20 20:22:59 - progress_bar.py[line:274] - INFO: epoch 001:   9371 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.93, wpb=110.8, bsz=40, num_updates=9360, lr=4.80006e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25645
2023-02-20 20:23:10 - progress_bar.py[line:274] - INFO: epoch 001:   9381 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=112.1, bsz=40, num_updates=9370, lr=4.7997e-05, gnorm=0.145, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25657
2023-02-20 20:23:21 - progress_bar.py[line:274] - INFO: epoch 001:   9391 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.93, wpb=110.8, bsz=40, num_updates=9380, lr=4.79933e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25667
2023-02-20 20:23:32 - progress_bar.py[line:274] - INFO: epoch 001:   9401 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.7, ups=0.88, wpb=110.6, bsz=40, num_updates=9390, lr=4.79897e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25679
2023-02-20 20:23:43 - progress_bar.py[line:274] - INFO: epoch 001:   9411 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.92, wpb=112.9, bsz=40, num_updates=9400, lr=4.79861e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25690
2023-02-20 20:23:54 - progress_bar.py[line:274] - INFO: epoch 001:   9421 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=9410, lr=4.79825e-05, gnorm=0.148, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25701
2023-02-20 20:24:06 - progress_bar.py[line:274] - INFO: epoch 001:   9431 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=9420, lr=4.79789e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25712
2023-02-20 20:24:17 - progress_bar.py[line:274] - INFO: epoch 001:   9441 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.89, wpb=112.4, bsz=40, num_updates=9430, lr=4.79753e-05, gnorm=0.17, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25723
2023-02-20 20:24:28 - progress_bar.py[line:274] - INFO: epoch 001:   9451 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.89, wpb=111.2, bsz=40, num_updates=9440, lr=4.79716e-05, gnorm=0.159, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25735
2023-02-20 20:24:40 - progress_bar.py[line:274] - INFO: epoch 001:   9461 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.1, bsz=40, num_updates=9450, lr=4.7968e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25746
2023-02-20 20:24:51 - progress_bar.py[line:274] - INFO: epoch 001:   9471 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112.8, bsz=40, num_updates=9460, lr=4.79644e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25757
2023-02-20 20:25:02 - progress_bar.py[line:274] - INFO: epoch 001:   9481 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.7, bsz=40, num_updates=9470, lr=4.79608e-05, gnorm=0.177, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25768
2023-02-20 20:25:13 - progress_bar.py[line:274] - INFO: epoch 001:   9491 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=9480, lr=4.79572e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25780
2023-02-20 20:25:24 - progress_bar.py[line:274] - INFO: epoch 001:   9501 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.92, wpb=111.8, bsz=40, num_updates=9490, lr=4.79535e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25791
2023-02-20 20:25:35 - progress_bar.py[line:274] - INFO: epoch 001:   9511 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.93, wpb=111.5, bsz=40, num_updates=9500, lr=4.79499e-05, gnorm=0.176, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25801
2023-02-20 20:25:46 - progress_bar.py[line:274] - INFO: epoch 001:   9521 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.8, bsz=40, num_updates=9510, lr=4.79463e-05, gnorm=0.159, clip=0, loss_scale=2048, train_wall=11, gb_free=10, ema_decay=0.9999, wall=25813
2023-02-20 20:25:57 - progress_bar.py[line:274] - INFO: epoch 001:   9531 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.6, bsz=40, num_updates=9520, lr=4.79427e-05, gnorm=0.185, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25824
2023-02-20 20:26:09 - progress_bar.py[line:274] - INFO: epoch 001:   9541 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=9530, lr=4.79391e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25835
2023-02-20 20:26:20 - progress_bar.py[line:274] - INFO: epoch 001:   9551 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.2, bsz=40, num_updates=9540, lr=4.79355e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25846
2023-02-20 20:26:31 - progress_bar.py[line:274] - INFO: epoch 001:   9561 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=111.2, bsz=40, num_updates=9550, lr=4.79318e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=25857
2023-02-20 20:26:42 - progress_bar.py[line:274] - INFO: epoch 001:   9571 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.7, bsz=40, num_updates=9560, lr=4.79282e-05, gnorm=0.149, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25868
2023-02-20 20:26:53 - progress_bar.py[line:274] - INFO: epoch 001:   9581 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.4, bsz=40, num_updates=9570, lr=4.79246e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25879
2023-02-20 20:27:04 - progress_bar.py[line:274] - INFO: epoch 001:   9591 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.1, bsz=40, num_updates=9580, lr=4.7921e-05, gnorm=0.111, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25891
2023-02-20 20:27:15 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 20:27:17 - progress_bar.py[line:274] - INFO: epoch 001:   9602 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.6, ups=0.8, wpb=111.7, bsz=40, num_updates=9590, lr=4.79174e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=25903
2023-02-20 20:27:28 - progress_bar.py[line:274] - INFO: epoch 001:   9612 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=113.1, bsz=40, num_updates=9600, lr=4.79137e-05, gnorm=0.183, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=25914
2023-02-20 20:27:39 - progress_bar.py[line:274] - INFO: epoch 001:   9622 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.9, wpb=110.3, bsz=40, num_updates=9610, lr=4.79101e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25925
2023-02-20 20:27:50 - progress_bar.py[line:274] - INFO: epoch 001:   9632 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.1, bsz=40, num_updates=9620, lr=4.79065e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25936
2023-02-20 20:28:01 - progress_bar.py[line:274] - INFO: epoch 001:   9642 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.2, bsz=40, num_updates=9630, lr=4.79029e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=25947
2023-02-20 20:28:12 - progress_bar.py[line:274] - INFO: epoch 001:   9652 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.88, wpb=112.5, bsz=40, num_updates=9640, lr=4.78993e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25959
2023-02-20 20:28:24 - progress_bar.py[line:274] - INFO: epoch 001:   9662 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=113.3, bsz=40, num_updates=9650, lr=4.78957e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25970
2023-02-20 20:28:35 - progress_bar.py[line:274] - INFO: epoch 001:   9672 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112, bsz=40, num_updates=9660, lr=4.7892e-05, gnorm=0.144, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25981
2023-02-20 20:28:46 - progress_bar.py[line:274] - INFO: epoch 001:   9682 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.4, bsz=40, num_updates=9670, lr=4.78884e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25992
2023-02-20 20:28:57 - progress_bar.py[line:274] - INFO: epoch 001:   9692 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.92, wpb=112.4, bsz=40, num_updates=9680, lr=4.78848e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26003
2023-02-20 20:29:08 - progress_bar.py[line:274] - INFO: epoch 001:   9702 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112.2, bsz=40, num_updates=9690, lr=4.78812e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26014
2023-02-20 20:29:19 - progress_bar.py[line:274] - INFO: epoch 001:   9712 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.3, bsz=40, num_updates=9700, lr=4.78776e-05, gnorm=0.17, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26025
2023-02-20 20:29:30 - progress_bar.py[line:274] - INFO: epoch 001:   9722 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.4, ups=0.94, wpb=112.3, bsz=40, num_updates=9710, lr=4.78739e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26036
2023-02-20 20:29:41 - progress_bar.py[line:274] - INFO: epoch 001:   9732 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.9, bsz=40, num_updates=9720, lr=4.78703e-05, gnorm=0.183, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26047
2023-02-20 20:29:52 - progress_bar.py[line:274] - INFO: epoch 001:   9742 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112.1, bsz=40, num_updates=9730, lr=4.78667e-05, gnorm=0.147, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26058
2023-02-20 20:30:03 - progress_bar.py[line:274] - INFO: epoch 001:   9752 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.4, bsz=40, num_updates=9740, lr=4.78631e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26069
2023-02-20 20:30:14 - progress_bar.py[line:274] - INFO: epoch 001:   9762 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=111, bsz=40, num_updates=9750, lr=4.78595e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26080
2023-02-20 20:30:25 - progress_bar.py[line:274] - INFO: epoch 001:   9772 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.1, bsz=40, num_updates=9760, lr=4.78559e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26092
2023-02-20 20:30:36 - progress_bar.py[line:274] - INFO: epoch 001:   9782 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.7, bsz=40, num_updates=9770, lr=4.78522e-05, gnorm=0.136, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26103
2023-02-20 20:30:47 - progress_bar.py[line:274] - INFO: epoch 001:   9792 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.88, wpb=112.7, bsz=40, num_updates=9780, lr=4.78486e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26114
2023-02-20 20:30:59 - progress_bar.py[line:274] - INFO: epoch 001:   9802 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.3, bsz=40, num_updates=9790, lr=4.7845e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26125
2023-02-20 20:31:10 - progress_bar.py[line:274] - INFO: epoch 001:   9812 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.3, bsz=40, num_updates=9800, lr=4.78414e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26136
2023-02-20 20:31:21 - progress_bar.py[line:274] - INFO: epoch 001:   9822 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=112, bsz=40, num_updates=9810, lr=4.78378e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=26147
2023-02-20 20:31:32 - progress_bar.py[line:274] - INFO: epoch 001:   9832 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.8, bsz=40, num_updates=9820, lr=4.78341e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26159
2023-02-20 20:31:43 - progress_bar.py[line:274] - INFO: epoch 001:   9842 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.9, bsz=40, num_updates=9830, lr=4.78305e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26170
2023-02-20 20:31:55 - progress_bar.py[line:274] - INFO: epoch 001:   9852 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.89, wpb=110.2, bsz=40, num_updates=9840, lr=4.78269e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26181
2023-02-20 20:32:06 - progress_bar.py[line:274] - INFO: epoch 001:   9862 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.4, bsz=40, num_updates=9850, lr=4.78233e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26192
2023-02-20 20:32:17 - progress_bar.py[line:274] - INFO: epoch 001:   9872 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.4, ups=0.9, wpb=112, bsz=40, num_updates=9860, lr=4.78197e-05, gnorm=0.176, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=26203
2023-02-20 20:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   9882 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.89, wpb=111.3, bsz=40, num_updates=9870, lr=4.78161e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26215
2023-02-20 20:32:39 - progress_bar.py[line:274] - INFO: epoch 001:   9892 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.4, ups=0.92, wpb=111.3, bsz=40, num_updates=9880, lr=4.78124e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26225
2023-02-20 20:32:50 - progress_bar.py[line:274] - INFO: epoch 001:   9902 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=111.9, bsz=40, num_updates=9890, lr=4.78088e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26237
2023-02-20 20:33:02 - progress_bar.py[line:274] - INFO: epoch 001:   9912 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.2, bsz=40, num_updates=9900, lr=4.78052e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26248
2023-02-20 20:33:13 - progress_bar.py[line:274] - INFO: epoch 001:   9922 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.1, bsz=40, num_updates=9910, lr=4.78016e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26259
2023-02-20 20:33:24 - progress_bar.py[line:274] - INFO: epoch 001:   9932 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.5, bsz=40, num_updates=9920, lr=4.7798e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26270
2023-02-20 20:33:35 - progress_bar.py[line:274] - INFO: epoch 001:   9942 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.89, wpb=109.9, bsz=40, num_updates=9930, lr=4.77943e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26282
2023-02-20 20:33:46 - progress_bar.py[line:274] - INFO: epoch 001:   9952 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.6, bsz=40, num_updates=9940, lr=4.77907e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26292
2023-02-20 20:33:57 - progress_bar.py[line:274] - INFO: epoch 001:   9962 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=112, bsz=40, num_updates=9950, lr=4.77871e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=26304
2023-02-20 20:34:08 - progress_bar.py[line:274] - INFO: epoch 001:   9972 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=9960, lr=4.77835e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26315
2023-02-20 20:34:20 - progress_bar.py[line:274] - INFO: epoch 001:   9982 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.4, bsz=40, num_updates=9970, lr=4.77799e-05, gnorm=0.153, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26326
2023-02-20 20:34:31 - progress_bar.py[line:274] - INFO: epoch 001:   9992 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=110.7, bsz=40, num_updates=9980, lr=4.77763e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26338
2023-02-20 20:34:42 - progress_bar.py[line:274] - INFO: epoch 001:  10002 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.9, wpb=111.3, bsz=40, num_updates=9990, lr=4.77726e-05, gnorm=0.16, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26349
2023-02-20 20:34:54 - progress_bar.py[line:274] - INFO: epoch 001:  10012 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.4, bsz=40, num_updates=10000, lr=4.7769e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26360
2023-02-20 20:34:54 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-20 20:34:55 - train.py[line:549] - INFO: 0 / 6234
2023-02-20 20:34:55 - train.py[line:551] - INFO: load:1.17 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-20 20:36:57 - train.py[line:549] - INFO: 200 / 6234
2023-02-20 20:36:57 - train.py[line:551] - INFO: load:1.19 valid_run:121.96 task_valid:119.10 collect_output:1.68
2023-02-20 20:38:56 - train.py[line:549] - INFO: 400 / 6234
2023-02-20 20:38:56 - train.py[line:551] - INFO: load:1.22 valid_run:241.25 task_valid:234.48 collect_output:4.52
2023-02-20 20:40:58 - train.py[line:549] - INFO: 600 / 6234
2023-02-20 20:40:58 - train.py[line:551] - INFO: load:1.24 valid_run:362.43 task_valid:350.50 collect_output:8.61
2023-02-20 20:42:59 - train.py[line:549] - INFO: 800 / 6234
2023-02-20 20:42:59 - train.py[line:551] - INFO: load:1.26 valid_run:483.71 task_valid:463.72 collect_output:15.61
2023-02-20 20:44:59 - train.py[line:549] - INFO: 1000 / 6234
2023-02-20 20:44:59 - train.py[line:551] - INFO: load:1.29 valid_run:603.73 task_valid:580.76 collect_output:17.54
2023-02-20 20:47:01 - train.py[line:549] - INFO: 1200 / 6234
2023-02-20 20:47:01 - train.py[line:551] - INFO: load:1.32 valid_run:725.98 task_valid:699.02 collect_output:20.50
2023-02-20 20:49:04 - train.py[line:549] - INFO: 1400 / 6234
2023-02-20 20:49:04 - train.py[line:551] - INFO: load:1.34 valid_run:848.40 task_valid:816.84 collect_output:24.05
2023-02-20 20:51:05 - train.py[line:549] - INFO: 1600 / 6234
2023-02-20 20:51:05 - train.py[line:551] - INFO: load:1.37 valid_run:969.36 task_valid:932.69 collect_output:28.11
2023-02-20 20:53:08 - train.py[line:549] - INFO: 1800 / 6234
2023-02-20 20:53:08 - train.py[line:551] - INFO: load:1.40 valid_run:1092.39 task_valid:1049.33 collect_output:33.47
2023-02-20 20:55:09 - train.py[line:549] - INFO: 2000 / 6234
2023-02-20 20:55:09 - train.py[line:551] - INFO: load:1.42 valid_run:1213.36 task_valid:1161.52 collect_output:41.18
2023-02-20 20:57:08 - train.py[line:549] - INFO: 2200 / 6234
2023-02-20 20:57:08 - train.py[line:551] - INFO: load:1.45 valid_run:1332.71 task_valid:1276.55 collect_output:44.47
2023-02-20 20:59:09 - train.py[line:549] - INFO: 2400 / 6234
2023-02-20 20:59:09 - train.py[line:551] - INFO: load:1.47 valid_run:1453.52 task_valid:1392.99 collect_output:47.80
2023-02-20 21:01:07 - train.py[line:549] - INFO: 2600 / 6234
2023-02-20 21:01:07 - train.py[line:551] - INFO: load:1.50 valid_run:1571.66 task_valid:1506.24 collect_output:51.65
2023-02-20 21:03:08 - train.py[line:549] - INFO: 2800 / 6234
2023-02-20 21:03:08 - train.py[line:551] - INFO: load:1.52 valid_run:1692.12 task_valid:1623.65 collect_output:53.65
2023-02-20 21:05:08 - train.py[line:549] - INFO: 3000 / 6234
2023-02-20 21:05:08 - train.py[line:551] - INFO: load:1.55 valid_run:1812.37 task_valid:1739.40 collect_output:57.11
2023-02-20 21:07:09 - train.py[line:549] - INFO: 3200 / 6234
2023-02-20 21:07:09 - train.py[line:551] - INFO: load:1.57 valid_run:1932.69 task_valid:1852.89 collect_output:62.92
2023-02-20 21:09:09 - train.py[line:549] - INFO: 3400 / 6234
2023-02-20 21:09:09 - train.py[line:551] - INFO: load:1.60 valid_run:2053.39 task_valid:1968.67 collect_output:66.79
2023-02-20 21:11:10 - train.py[line:549] - INFO: 3600 / 6234
2023-02-20 21:11:10 - train.py[line:551] - INFO: load:1.63 valid_run:2173.70 task_valid:2086.25 collect_output:68.47
2023-02-20 21:13:11 - train.py[line:549] - INFO: 3800 / 6234
2023-02-20 21:13:11 - train.py[line:551] - INFO: load:1.65 valid_run:2294.55 task_valid:2203.00 collect_output:71.51
2023-02-20 21:15:11 - train.py[line:549] - INFO: 4000 / 6234
2023-02-20 21:15:11 - train.py[line:551] - INFO: load:1.68 valid_run:2414.45 task_valid:2319.22 collect_output:74.16
2023-02-20 21:17:12 - train.py[line:549] - INFO: 4200 / 6234
2023-02-20 21:17:12 - train.py[line:551] - INFO: load:1.70 valid_run:2535.52 task_valid:2435.33 collect_output:78.09
2023-02-20 21:19:13 - train.py[line:549] - INFO: 4400 / 6234
2023-02-20 21:19:13 - train.py[line:551] - INFO: load:1.73 valid_run:2656.86 task_valid:2553.73 collect_output:80.00
2023-02-20 21:21:13 - train.py[line:549] - INFO: 4600 / 6234
2023-02-20 21:21:13 - train.py[line:551] - INFO: load:1.75 valid_run:2776.41 task_valid:2667.42 collect_output:84.83
2023-02-20 21:23:12 - train.py[line:549] - INFO: 4800 / 6234
2023-02-20 21:23:12 - train.py[line:551] - INFO: load:1.78 valid_run:2895.40 task_valid:2783.04 collect_output:87.18
2023-02-20 21:25:13 - train.py[line:549] - INFO: 5000 / 6234
2023-02-20 21:25:13 - train.py[line:551] - INFO: load:1.80 valid_run:3016.31 task_valid:2898.74 collect_output:91.34
2023-02-20 21:27:15 - train.py[line:549] - INFO: 5200 / 6234
2023-02-20 21:27:15 - train.py[line:551] - INFO: load:1.83 valid_run:3138.45 task_valid:3014.07 collect_output:97.13
2023-02-20 21:29:14 - train.py[line:549] - INFO: 5400 / 6234
2023-02-20 21:29:14 - train.py[line:551] - INFO: load:1.85 valid_run:3257.41 task_valid:3127.81 collect_output:101.30
2023-02-20 21:31:15 - train.py[line:549] - INFO: 5600 / 6234
2023-02-20 21:31:15 - train.py[line:551] - INFO: load:1.88 valid_run:3378.58 task_valid:3246.65 collect_output:102.60
2023-02-20 21:33:16 - train.py[line:549] - INFO: 5800 / 6234
2023-02-20 21:33:16 - train.py[line:551] - INFO: load:1.90 valid_run:3499.47 task_valid:3361.60 collect_output:107.52
2023-02-20 21:35:18 - train.py[line:549] - INFO: 6000 / 6234
2023-02-20 21:35:18 - train.py[line:551] - INFO: load:1.93 valid_run:3620.74 task_valid:3479.56 collect_output:109.78
2023-02-20 21:37:18 - train.py[line:549] - INFO: 6200 / 6234
2023-02-20 21:37:18 - train.py[line:551] - INFO: load:1.95 valid_run:3741.31 task_valid:3597.62 collect_output:111.27

====================================================================================================
SGG eval:     R @ 50: 0.6595;     R @ 100: 0.6891;     R @ 500: 0.7154;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4076;    mR @ 100: 0.4577;    mR @ 500: 0.5463;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.5625) (covering:0.3714) (eating:0.7647) (flying in:0.5000) (growing on:0.5000) (hanging from:0.5323) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9673) (says:0.0000) (sitting on:0.7483) (standing on:0.3793) (using:0.6000) (walking in:0.0000) (walking on:0.7568) (watching:0.4722) 
--------------------------------------------------------
====================================================================================================

2023-02-20 21:37:49 - train.py[line:487] - INFO: 0.6891291316526611

====================================================================================================
SGG eval:     R @ 50: 0.6595;     R @ 100: 0.6891;     R @ 500: 0.7154;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4076;    mR @ 100: 0.4577;    mR @ 500: 0.5463;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.5625) (covering:0.3714) (eating:0.7647) (flying in:0.5000) (growing on:0.5000) (hanging from:0.5323) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9673) (says:0.0000) (sitting on:0.7483) (standing on:0.3793) (using:0.6000) (walking in:0.0000) (walking on:0.7568) (watching:0.4722) 
--------------------------------------------------------
====================================================================================================

2023-02-20 21:37:49 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-20 21:37:49 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.231 | loss_v1 0 | loss_v2 0 | nll_loss 0.059 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.689129 | ppl 1.04 | vqa_score 0.464 | wps 118.9 | wpb 72 | bsz 24 | num_updates 10000 | best_R@100 0.691462
2023-02-20 21:37:49 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 10000 updates
2023-02-20 21:37:49 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_10000.pt
2023-02-20 21:37:56 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_10000.pt
2023-02-20 21:37:59 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 0.6891291316526611) (writing took 9.685644295066595 seconds)
2023-02-20 21:38:10 - progress_bar.py[line:274] - INFO: epoch 001:  10022 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=111.8, bsz=40, num_updates=10010, lr=4.77654e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30156
2023-02-20 21:38:21 - progress_bar.py[line:274] - INFO: epoch 001:  10032 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.92, wpb=111.2, bsz=40, num_updates=10020, lr=4.77618e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30167
2023-02-20 21:38:32 - progress_bar.py[line:274] - INFO: epoch 001:  10042 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112, bsz=40, num_updates=10030, lr=4.77582e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30178
2023-02-20 21:38:43 - progress_bar.py[line:274] - INFO: epoch 001:  10052 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=10040, lr=4.77545e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30189
2023-02-20 21:38:54 - progress_bar.py[line:274] - INFO: epoch 001:  10062 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.88, wpb=109.5, bsz=40, num_updates=10050, lr=4.77509e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30201
2023-02-20 21:39:05 - progress_bar.py[line:274] - INFO: epoch 001:  10072 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112.1, bsz=40, num_updates=10060, lr=4.77473e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30212
2023-02-20 21:39:16 - progress_bar.py[line:274] - INFO: epoch 001:  10082 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.91, wpb=109.6, bsz=40, num_updates=10070, lr=4.77437e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=30223
2023-02-20 21:39:27 - progress_bar.py[line:274] - INFO: epoch 001:  10092 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.2, bsz=40, num_updates=10080, lr=4.77401e-05, gnorm=0.158, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30234
2023-02-20 21:39:39 - progress_bar.py[line:274] - INFO: epoch 001:  10102 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.9, bsz=40, num_updates=10090, lr=4.77364e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30245
2023-02-20 21:39:50 - progress_bar.py[line:274] - INFO: epoch 001:  10112 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.3, bsz=40, num_updates=10100, lr=4.77328e-05, gnorm=0.147, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30256
2023-02-20 21:40:01 - progress_bar.py[line:274] - INFO: epoch 001:  10122 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.9, wpb=110.6, bsz=40, num_updates=10110, lr=4.77292e-05, gnorm=0.175, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30267
2023-02-20 21:40:12 - progress_bar.py[line:274] - INFO: epoch 001:  10132 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=112, bsz=40, num_updates=10120, lr=4.77256e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30278
2023-02-20 21:40:23 - progress_bar.py[line:274] - INFO: epoch 001:  10142 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.88, wpb=112.3, bsz=40, num_updates=10130, lr=4.7722e-05, gnorm=0.122, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30290
2023-02-20 21:40:35 - progress_bar.py[line:274] - INFO: epoch 001:  10152 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.6, bsz=40, num_updates=10140, lr=4.77184e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30301
2023-02-20 21:40:46 - progress_bar.py[line:274] - INFO: epoch 001:  10162 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.8, bsz=40, num_updates=10150, lr=4.77147e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30312
2023-02-20 21:40:57 - progress_bar.py[line:274] - INFO: epoch 001:  10172 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.1, bsz=40, num_updates=10160, lr=4.77111e-05, gnorm=0.131, clip=0, loss_scale=4096, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=30323
2023-02-20 21:41:01 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 21:41:08 - progress_bar.py[line:274] - INFO: epoch 001:  10183 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.1, ups=0.84, wpb=111.6, bsz=40, num_updates=10170, lr=4.77075e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=30335
2023-02-20 21:41:20 - progress_bar.py[line:274] - INFO: epoch 001:  10193 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=112, bsz=40, num_updates=10180, lr=4.77039e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30346
2023-02-20 21:41:31 - progress_bar.py[line:274] - INFO: epoch 001:  10203 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.7, bsz=40, num_updates=10190, lr=4.77003e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30357
2023-02-20 21:41:42 - progress_bar.py[line:274] - INFO: epoch 001:  10213 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.5, ups=0.92, wpb=112.4, bsz=40, num_updates=10200, lr=4.76966e-05, gnorm=0.155, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30368
2023-02-20 21:41:53 - progress_bar.py[line:274] - INFO: epoch 001:  10223 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.9, wpb=109.7, bsz=40, num_updates=10210, lr=4.7693e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=30379
2023-02-20 21:42:04 - progress_bar.py[line:274] - INFO: epoch 001:  10233 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112.5, bsz=40, num_updates=10220, lr=4.76894e-05, gnorm=0.173, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30390
2023-02-20 21:42:15 - progress_bar.py[line:274] - INFO: epoch 001:  10243 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=10230, lr=4.76858e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30401
2023-02-20 21:42:26 - progress_bar.py[line:274] - INFO: epoch 001:  10253 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.89, wpb=111.6, bsz=40, num_updates=10240, lr=4.76822e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30413
2023-02-20 21:42:37 - progress_bar.py[line:274] - INFO: epoch 001:  10263 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105, ups=0.93, wpb=112.6, bsz=40, num_updates=10250, lr=4.76786e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30424
2023-02-20 21:42:48 - progress_bar.py[line:274] - INFO: epoch 001:  10273 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.91, wpb=111.2, bsz=40, num_updates=10260, lr=4.76749e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30435
2023-02-20 21:42:59 - progress_bar.py[line:274] - INFO: epoch 001:  10283 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.88, wpb=112.8, bsz=40, num_updates=10270, lr=4.76713e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30446
2023-02-20 21:43:10 - progress_bar.py[line:274] - INFO: epoch 001:  10293 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.93, wpb=111.8, bsz=40, num_updates=10280, lr=4.76677e-05, gnorm=0.117, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30457
2023-02-20 21:43:21 - progress_bar.py[line:274] - INFO: epoch 001:  10303 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.7, bsz=40, num_updates=10290, lr=4.76641e-05, gnorm=0.072, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30468
2023-02-20 21:43:32 - progress_bar.py[line:274] - INFO: epoch 001:  10313 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111, bsz=40, num_updates=10300, lr=4.76605e-05, gnorm=0.131, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30479
2023-02-20 21:43:44 - progress_bar.py[line:274] - INFO: epoch 001:  10323 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113.5, nsentences=40, sample_size=113.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.88, wpb=113.5, bsz=40, num_updates=10310, lr=4.76568e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30490
2023-02-20 21:43:55 - progress_bar.py[line:274] - INFO: epoch 001:  10333 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.1, bsz=40, num_updates=10320, lr=4.76532e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30501
2023-02-20 21:44:06 - progress_bar.py[line:274] - INFO: epoch 001:  10343 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=112.3, bsz=40, num_updates=10330, lr=4.76496e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30513
2023-02-20 21:44:17 - progress_bar.py[line:274] - INFO: epoch 001:  10353 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.3, bsz=40, num_updates=10340, lr=4.7646e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30524
2023-02-20 21:44:28 - progress_bar.py[line:274] - INFO: epoch 001:  10363 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.6, bsz=40, num_updates=10350, lr=4.76424e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30535
2023-02-20 21:44:39 - progress_bar.py[line:274] - INFO: epoch 001:  10373 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=112.9, bsz=40, num_updates=10360, lr=4.76388e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30546
2023-02-20 21:44:51 - progress_bar.py[line:274] - INFO: epoch 001:  10383 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=10370, lr=4.76351e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30557
2023-02-20 21:45:01 - progress_bar.py[line:274] - INFO: epoch 001:  10393 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105, ups=0.93, wpb=112.5, bsz=40, num_updates=10380, lr=4.76315e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30568
2023-02-20 21:45:12 - progress_bar.py[line:274] - INFO: epoch 001:  10403 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.3, bsz=40, num_updates=10390, lr=4.76279e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30578
2023-02-20 21:45:23 - progress_bar.py[line:274] - INFO: epoch 001:  10413 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.9, wpb=110.2, bsz=40, num_updates=10400, lr=4.76243e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30590
2023-02-20 21:45:34 - progress_bar.py[line:274] - INFO: epoch 001:  10423 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.91, wpb=110.2, bsz=40, num_updates=10410, lr=4.76207e-05, gnorm=0.17, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30601
2023-02-20 21:45:45 - progress_bar.py[line:274] - INFO: epoch 001:  10433 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.9, wpb=112.8, bsz=40, num_updates=10420, lr=4.7617e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30612
2023-02-20 21:45:57 - progress_bar.py[line:274] - INFO: epoch 001:  10443 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.9, wpb=112.5, bsz=40, num_updates=10430, lr=4.76134e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30623
2023-02-20 21:46:08 - progress_bar.py[line:274] - INFO: epoch 001:  10453 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.89, wpb=111.7, bsz=40, num_updates=10440, lr=4.76098e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30634
2023-02-20 21:46:19 - progress_bar.py[line:274] - INFO: epoch 001:  10463 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.2, bsz=40, num_updates=10450, lr=4.76062e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30646
2023-02-20 21:46:30 - progress_bar.py[line:274] - INFO: epoch 001:  10473 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111, bsz=40, num_updates=10460, lr=4.76026e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30657
2023-02-20 21:46:41 - progress_bar.py[line:274] - INFO: epoch 001:  10483 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=111.9, bsz=40, num_updates=10470, lr=4.7599e-05, gnorm=0.147, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30668
2023-02-20 21:46:52 - progress_bar.py[line:274] - INFO: epoch 001:  10493 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.92, wpb=112.3, bsz=40, num_updates=10480, lr=4.75953e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30679
2023-02-20 21:47:04 - progress_bar.py[line:274] - INFO: epoch 001:  10503 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.8, bsz=40, num_updates=10490, lr=4.75917e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30690
2023-02-20 21:47:15 - progress_bar.py[line:274] - INFO: epoch 001:  10513 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.4, bsz=40, num_updates=10500, lr=4.75881e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30701
2023-02-20 21:47:26 - progress_bar.py[line:274] - INFO: epoch 001:  10523 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=10510, lr=4.75845e-05, gnorm=0.142, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30712
2023-02-20 21:47:37 - progress_bar.py[line:274] - INFO: epoch 001:  10533 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=111.8, bsz=40, num_updates=10520, lr=4.75809e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30724
2023-02-20 21:47:49 - progress_bar.py[line:274] - INFO: epoch 001:  10543 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=111.1, bsz=40, num_updates=10530, lr=4.75772e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30735
2023-02-20 21:48:00 - progress_bar.py[line:274] - INFO: epoch 001:  10553 / 71012 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.4, ups=0.91, wpb=110.5, bsz=40, num_updates=10540, lr=4.75736e-05, gnorm=0.169, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30746
2023-02-20 21:48:11 - progress_bar.py[line:274] - INFO: epoch 001:  10563 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=10550, lr=4.757e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30757
2023-02-20 21:48:22 - progress_bar.py[line:274] - INFO: epoch 001:  10573 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.5, bsz=40, num_updates=10560, lr=4.75664e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30769
2023-02-20 21:48:34 - progress_bar.py[line:274] - INFO: epoch 001:  10583 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.8, bsz=40, num_updates=10570, lr=4.75628e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30780
2023-02-20 21:48:45 - progress_bar.py[line:274] - INFO: epoch 001:  10593 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=112.1, bsz=40, num_updates=10580, lr=4.75592e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30792
2023-02-20 21:48:56 - progress_bar.py[line:274] - INFO: epoch 001:  10603 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.3, ups=0.9, wpb=112.8, bsz=40, num_updates=10590, lr=4.75555e-05, gnorm=0.154, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30803
2023-02-20 21:49:07 - progress_bar.py[line:274] - INFO: epoch 001:  10613 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112, bsz=40, num_updates=10600, lr=4.75519e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30814
2023-02-20 21:49:18 - progress_bar.py[line:274] - INFO: epoch 001:  10623 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.7, bsz=40, num_updates=10610, lr=4.75483e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30825
2023-02-20 21:49:30 - progress_bar.py[line:274] - INFO: epoch 001:  10633 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=110.8, bsz=40, num_updates=10620, lr=4.75447e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30836
2023-02-20 21:49:40 - progress_bar.py[line:274] - INFO: epoch 001:  10643 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.8, ups=0.94, wpb=112, bsz=40, num_updates=10630, lr=4.75411e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30846
2023-02-20 21:49:51 - progress_bar.py[line:274] - INFO: epoch 001:  10653 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.5, bsz=40, num_updates=10640, lr=4.75374e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30857
2023-02-20 21:50:02 - progress_bar.py[line:274] - INFO: epoch 001:  10663 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.7, bsz=40, num_updates=10650, lr=4.75338e-05, gnorm=0.181, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30869
2023-02-20 21:50:13 - progress_bar.py[line:274] - INFO: epoch 001:  10673 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112, bsz=40, num_updates=10660, lr=4.75302e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30880
2023-02-20 21:50:25 - progress_bar.py[line:274] - INFO: epoch 001:  10683 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.89, wpb=110.4, bsz=40, num_updates=10670, lr=4.75266e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30891
2023-02-20 21:50:36 - progress_bar.py[line:274] - INFO: epoch 001:  10693 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.6, bsz=40, num_updates=10680, lr=4.7523e-05, gnorm=0.194, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30902
2023-02-20 21:50:45 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 21:50:48 - progress_bar.py[line:274] - INFO: epoch 001:  10704 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91.1, ups=0.81, wpb=112.4, bsz=40, num_updates=10690, lr=4.75194e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=30915
2023-02-20 21:51:04 - progress_bar.py[line:274] - INFO: epoch 001:  10714 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.89, wpb=112.5, bsz=40, num_updates=10700, lr=4.75157e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30926
2023-02-20 21:51:15 - progress_bar.py[line:274] - INFO: epoch 001:  10724 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.91, wpb=110.4, bsz=40, num_updates=10710, lr=4.75121e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30942
2023-02-20 21:51:27 - progress_bar.py[line:274] - INFO: epoch 001:  10734 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.9, bsz=40, num_updates=10720, lr=4.75085e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30953
2023-02-20 21:51:38 - progress_bar.py[line:274] - INFO: epoch 001:  10744 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.9, wpb=113.2, bsz=40, num_updates=10730, lr=4.75049e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30964
2023-02-20 21:51:49 - progress_bar.py[line:274] - INFO: epoch 001:  10754 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.3, bsz=40, num_updates=10740, lr=4.75013e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30976
2023-02-20 21:52:00 - progress_bar.py[line:274] - INFO: epoch 001:  10764 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.1, ups=0.9, wpb=112.9, bsz=40, num_updates=10750, lr=4.74976e-05, gnorm=0.168, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30987
2023-02-20 21:52:11 - progress_bar.py[line:274] - INFO: epoch 001:  10774 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.5, bsz=40, num_updates=10760, lr=4.7494e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30998
2023-02-20 21:52:22 - progress_bar.py[line:274] - INFO: epoch 001:  10784 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.6, ups=0.92, wpb=111.5, bsz=40, num_updates=10770, lr=4.74904e-05, gnorm=0.163, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31009
2023-02-20 21:52:33 - progress_bar.py[line:274] - INFO: epoch 001:  10794 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.4, bsz=40, num_updates=10780, lr=4.74868e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31020
2023-02-20 21:52:45 - progress_bar.py[line:274] - INFO: epoch 001:  10804 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.6, bsz=40, num_updates=10790, lr=4.74832e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31031
2023-02-20 21:52:56 - progress_bar.py[line:274] - INFO: epoch 001:  10814 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.4, bsz=40, num_updates=10800, lr=4.74796e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31042
2023-02-20 21:53:07 - progress_bar.py[line:274] - INFO: epoch 001:  10824 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.5, bsz=40, num_updates=10810, lr=4.74759e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31054
2023-02-20 21:53:19 - progress_bar.py[line:274] - INFO: epoch 001:  10834 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.5, bsz=40, num_updates=10820, lr=4.74723e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31065
2023-02-20 21:53:30 - progress_bar.py[line:274] - INFO: epoch 001:  10844 / 71012 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.89, wpb=112.5, bsz=40, num_updates=10830, lr=4.74687e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31076
2023-02-20 21:53:41 - progress_bar.py[line:274] - INFO: epoch 001:  10854 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.1, ups=0.93, wpb=112.6, bsz=40, num_updates=10840, lr=4.74651e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31087
2023-02-20 21:53:52 - progress_bar.py[line:274] - INFO: epoch 001:  10864 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=112.2, bsz=40, num_updates=10850, lr=4.74615e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31098
2023-02-20 21:54:03 - progress_bar.py[line:274] - INFO: epoch 001:  10874 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=110.8, bsz=40, num_updates=10860, lr=4.74578e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31109
2023-02-20 21:54:14 - progress_bar.py[line:274] - INFO: epoch 001:  10884 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.6, ups=0.91, wpb=111.5, bsz=40, num_updates=10870, lr=4.74542e-05, gnorm=0.18, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31120
2023-02-20 21:54:25 - progress_bar.py[line:274] - INFO: epoch 001:  10894 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=110.9, bsz=40, num_updates=10880, lr=4.74506e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31131
2023-02-20 21:54:36 - progress_bar.py[line:274] - INFO: epoch 001:  10904 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=10890, lr=4.7447e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=31143
2023-02-20 21:54:47 - progress_bar.py[line:274] - INFO: epoch 001:  10914 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=10900, lr=4.74434e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31154
2023-02-20 21:54:59 - progress_bar.py[line:274] - INFO: epoch 001:  10924 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.5, bsz=40, num_updates=10910, lr=4.74398e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31165
2023-02-20 21:55:10 - progress_bar.py[line:274] - INFO: epoch 001:  10934 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=10920, lr=4.74361e-05, gnorm=0.136, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31176
2023-02-20 21:55:21 - progress_bar.py[line:274] - INFO: epoch 001:  10944 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=113.7, nsentences=40, sample_size=113.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.88, wpb=113.7, bsz=40, num_updates=10930, lr=4.74325e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31187
2023-02-20 21:55:32 - progress_bar.py[line:274] - INFO: epoch 001:  10954 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.7, bsz=40, num_updates=10940, lr=4.74289e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31198
2023-02-20 21:55:43 - progress_bar.py[line:274] - INFO: epoch 001:  10964 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=10950, lr=4.74253e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31209
2023-02-20 21:55:54 - progress_bar.py[line:274] - INFO: epoch 001:  10974 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.87, wpb=111.3, bsz=40, num_updates=10960, lr=4.74217e-05, gnorm=0.147, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31221
2023-02-20 21:56:05 - progress_bar.py[line:274] - INFO: epoch 001:  10984 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.5, ups=0.91, wpb=112.7, bsz=40, num_updates=10970, lr=4.7418e-05, gnorm=0.155, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31232
2023-02-20 21:56:17 - progress_bar.py[line:274] - INFO: epoch 001:  10994 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.9, bsz=40, num_updates=10980, lr=4.74144e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=31243
2023-02-20 21:56:27 - progress_bar.py[line:274] - INFO: epoch 001:  11004 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.5, ups=0.94, wpb=110.7, bsz=40, num_updates=10990, lr=4.74108e-05, gnorm=0.131, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31254
2023-02-20 21:56:39 - progress_bar.py[line:274] - INFO: epoch 001:  11014 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=11000, lr=4.74072e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=31265
2023-02-20 21:56:50 - progress_bar.py[line:274] - INFO: epoch 001:  11024 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.9, wpb=109.8, bsz=40, num_updates=11010, lr=4.74036e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31276
2023-02-20 21:57:01 - progress_bar.py[line:274] - INFO: epoch 001:  11034 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=11020, lr=4.74e-05, gnorm=0.159, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31287
2023-02-20 21:57:12 - progress_bar.py[line:274] - INFO: epoch 001:  11044 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=111.4, bsz=40, num_updates=11030, lr=4.73963e-05, gnorm=0.142, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=31299
2023-02-20 21:57:23 - progress_bar.py[line:274] - INFO: epoch 001:  11054 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.9, wpb=111.4, bsz=40, num_updates=11040, lr=4.73927e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31310
2023-02-20 21:57:34 - progress_bar.py[line:274] - INFO: epoch 001:  11064 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.3, bsz=40, num_updates=11050, lr=4.73891e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31321
2023-02-20 21:57:46 - progress_bar.py[line:274] - INFO: epoch 001:  11074 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.5, bsz=40, num_updates=11060, lr=4.73855e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31332
2023-02-20 21:57:57 - progress_bar.py[line:274] - INFO: epoch 001:  11084 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.2, bsz=40, num_updates=11070, lr=4.73819e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31343
2023-02-20 21:58:08 - progress_bar.py[line:274] - INFO: epoch 001:  11094 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.5, ups=0.92, wpb=111.4, bsz=40, num_updates=11080, lr=4.73782e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31354
2023-02-20 21:58:19 - progress_bar.py[line:274] - INFO: epoch 001:  11104 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.91, wpb=112.7, bsz=40, num_updates=11090, lr=4.73746e-05, gnorm=0.141, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31365
2023-02-20 21:58:30 - progress_bar.py[line:274] - INFO: epoch 001:  11114 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=110.5, bsz=40, num_updates=11100, lr=4.7371e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31377
2023-02-20 21:58:41 - progress_bar.py[line:274] - INFO: epoch 001:  11124 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112.8, bsz=40, num_updates=11110, lr=4.73674e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31388
2023-02-20 21:58:52 - progress_bar.py[line:274] - INFO: epoch 001:  11134 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.9, wpb=113, bsz=40, num_updates=11120, lr=4.73638e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31399
2023-02-20 21:59:03 - progress_bar.py[line:274] - INFO: epoch 001:  11144 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.2, ups=0.91, wpb=111.4, bsz=40, num_updates=11130, lr=4.73602e-05, gnorm=0.146, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31410
2023-02-20 21:59:14 - progress_bar.py[line:274] - INFO: epoch 001:  11154 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.93, wpb=110.6, bsz=40, num_updates=11140, lr=4.73565e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31421
2023-02-20 21:59:25 - progress_bar.py[line:274] - INFO: epoch 001:  11164 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.2, bsz=40, num_updates=11150, lr=4.73529e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=31431
2023-02-20 21:59:36 - progress_bar.py[line:274] - INFO: epoch 001:  11174 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=111.9, bsz=40, num_updates=11160, lr=4.73493e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31443
2023-02-20 21:59:48 - progress_bar.py[line:274] - INFO: epoch 001:  11184 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.7, bsz=40, num_updates=11170, lr=4.73457e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31454
2023-02-20 21:59:59 - progress_bar.py[line:274] - INFO: epoch 001:  11194 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.8, bsz=40, num_updates=11180, lr=4.73421e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31465
2023-02-20 22:00:10 - progress_bar.py[line:274] - INFO: epoch 001:  11204 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=11190, lr=4.73384e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31477
2023-02-20 22:00:21 - progress_bar.py[line:274] - INFO: epoch 001:  11214 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.8, bsz=40, num_updates=11200, lr=4.73348e-05, gnorm=0.127, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31488
2023-02-20 22:00:32 - progress_bar.py[line:274] - INFO: epoch 001:  11224 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.93, wpb=111.7, bsz=40, num_updates=11210, lr=4.73312e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=31499
2023-02-20 22:00:43 - progress_bar.py[line:274] - INFO: epoch 001:  11234 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.89, wpb=110.9, bsz=40, num_updates=11220, lr=4.73276e-05, gnorm=0.153, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31510
2023-02-20 22:00:54 - progress_bar.py[line:274] - INFO: epoch 001:  11244 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.4, bsz=40, num_updates=11230, lr=4.7324e-05, gnorm=0.105, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31521
2023-02-20 22:01:05 - progress_bar.py[line:274] - INFO: epoch 001:  11254 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.5, bsz=40, num_updates=11240, lr=4.73204e-05, gnorm=0.114, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31532
2023-02-20 22:01:17 - progress_bar.py[line:274] - INFO: epoch 001:  11264 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.9, bsz=40, num_updates=11250, lr=4.73167e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31543
2023-02-20 22:01:28 - progress_bar.py[line:274] - INFO: epoch 001:  11274 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.3, bsz=40, num_updates=11260, lr=4.73131e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31554
2023-02-20 22:01:39 - progress_bar.py[line:274] - INFO: epoch 001:  11284 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.6, bsz=40, num_updates=11270, lr=4.73095e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31565
2023-02-20 22:01:50 - progress_bar.py[line:274] - INFO: epoch 001:  11294 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=111.3, bsz=40, num_updates=11280, lr=4.73059e-05, gnorm=0.179, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31577
2023-02-20 22:02:01 - progress_bar.py[line:274] - INFO: epoch 001:  11304 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=11290, lr=4.73023e-05, gnorm=0.132, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=31588
2023-02-20 22:02:12 - progress_bar.py[line:274] - INFO: epoch 001:  11314 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.93, wpb=111.4, bsz=40, num_updates=11300, lr=4.72986e-05, gnorm=0.133, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31598
2023-02-20 22:02:23 - progress_bar.py[line:274] - INFO: epoch 001:  11324 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.5, bsz=40, num_updates=11310, lr=4.7295e-05, gnorm=0.122, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31610
2023-02-20 22:02:34 - progress_bar.py[line:274] - INFO: epoch 001:  11334 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=11320, lr=4.72914e-05, gnorm=0.114, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31621
2023-02-20 22:02:46 - progress_bar.py[line:274] - INFO: epoch 001:  11344 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.88, wpb=112.2, bsz=40, num_updates=11330, lr=4.72878e-05, gnorm=0.165, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31632
2023-02-20 22:02:57 - progress_bar.py[line:274] - INFO: epoch 001:  11354 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.92, wpb=110.9, bsz=40, num_updates=11340, lr=4.72842e-05, gnorm=0.13, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31643
2023-02-20 22:03:08 - progress_bar.py[line:274] - INFO: epoch 001:  11364 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=112, bsz=40, num_updates=11350, lr=4.72806e-05, gnorm=0.137, clip=0, loss_scale=4096, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=31654
2023-02-20 22:03:19 - progress_bar.py[line:274] - INFO: epoch 001:  11374 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=11360, lr=4.72769e-05, gnorm=0.206, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=31665
2023-02-20 22:03:30 - progress_bar.py[line:274] - INFO: epoch 001:  11384 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.1, bsz=40, num_updates=11370, lr=4.72733e-05, gnorm=0.123, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31676
2023-02-20 22:03:41 - progress_bar.py[line:274] - INFO: epoch 001:  11394 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.88, wpb=112.7, bsz=40, num_updates=11380, lr=4.72697e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31688
2023-02-20 22:03:52 - progress_bar.py[line:274] - INFO: epoch 001:  11404 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.5, bsz=40, num_updates=11390, lr=4.72661e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=31699
2023-02-20 22:04:04 - progress_bar.py[line:274] - INFO: epoch 001:  11414 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=110.8, bsz=40, num_updates=11400, lr=4.72625e-05, gnorm=0.131, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31710
2023-02-20 22:04:15 - progress_bar.py[line:274] - INFO: epoch 001:  11424 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=11410, lr=4.72588e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=31722
2023-02-20 22:04:26 - progress_bar.py[line:274] - INFO: epoch 001:  11434 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=110.7, bsz=40, num_updates=11420, lr=4.72552e-05, gnorm=0.14, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=31732
2023-02-20 22:04:37 - progress_bar.py[line:274] - INFO: epoch 001:  11444 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.93, wpb=110.7, bsz=40, num_updates=11430, lr=4.72516e-05, gnorm=0.168, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31743
2023-02-20 22:04:48 - progress_bar.py[line:274] - INFO: epoch 001:  11454 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=11440, lr=4.7248e-05, gnorm=0.122, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31754
2023-02-20 22:04:59 - progress_bar.py[line:274] - INFO: epoch 001:  11464 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.9, ups=0.91, wpb=112.3, bsz=40, num_updates=11450, lr=4.72444e-05, gnorm=0.121, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31765
2023-02-20 22:05:10 - progress_bar.py[line:274] - INFO: epoch 001:  11474 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.9, bsz=40, num_updates=11460, lr=4.72408e-05, gnorm=0.138, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=31777
2023-02-20 22:05:21 - progress_bar.py[line:274] - INFO: epoch 001:  11484 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.3, ups=0.91, wpb=112.4, bsz=40, num_updates=11470, lr=4.72371e-05, gnorm=0.125, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31788
2023-02-20 22:05:32 - progress_bar.py[line:274] - INFO: epoch 001:  11494 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.3, bsz=40, num_updates=11480, lr=4.72335e-05, gnorm=0.132, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31798
2023-02-20 22:05:43 - progress_bar.py[line:274] - INFO: epoch 001:  11504 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.9, wpb=110.7, bsz=40, num_updates=11490, lr=4.72299e-05, gnorm=0.119, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31810
2023-02-20 22:05:54 - progress_bar.py[line:274] - INFO: epoch 001:  11514 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.5, bsz=40, num_updates=11500, lr=4.72263e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31821
2023-02-20 22:06:05 - progress_bar.py[line:274] - INFO: epoch 001:  11524 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.1, ups=0.91, wpb=111.4, bsz=40, num_updates=11510, lr=4.72227e-05, gnorm=0.122, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31832
2023-02-20 22:06:17 - progress_bar.py[line:274] - INFO: epoch 001:  11534 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=111.5, bsz=40, num_updates=11520, lr=4.7219e-05, gnorm=0.121, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31843
2023-02-20 22:06:28 - progress_bar.py[line:274] - INFO: epoch 001:  11544 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.1, bsz=40, num_updates=11530, lr=4.72154e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31854
2023-02-20 22:06:39 - progress_bar.py[line:274] - INFO: epoch 001:  11554 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.5, bsz=40, num_updates=11540, lr=4.72118e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31865
2023-02-20 22:06:50 - progress_bar.py[line:274] - INFO: epoch 001:  11564 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.9, bsz=40, num_updates=11550, lr=4.72082e-05, gnorm=0.164, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31876
2023-02-20 22:07:01 - progress_bar.py[line:274] - INFO: epoch 001:  11574 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=112, bsz=40, num_updates=11560, lr=4.72046e-05, gnorm=0.173, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31887
2023-02-20 22:07:12 - progress_bar.py[line:274] - INFO: epoch 001:  11584 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=11570, lr=4.7201e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31898
2023-02-20 22:07:23 - progress_bar.py[line:274] - INFO: epoch 001:  11594 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.1, bsz=40, num_updates=11580, lr=4.71973e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31910
2023-02-20 22:07:35 - progress_bar.py[line:274] - INFO: epoch 001:  11604 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=111.1, bsz=40, num_updates=11590, lr=4.71937e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31921
2023-02-20 22:07:46 - progress_bar.py[line:274] - INFO: epoch 001:  11614 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112.1, bsz=40, num_updates=11600, lr=4.71901e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31932
2023-02-20 22:07:57 - progress_bar.py[line:274] - INFO: epoch 001:  11624 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.1, bsz=40, num_updates=11610, lr=4.71865e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31944
2023-02-20 22:08:08 - progress_bar.py[line:274] - INFO: epoch 001:  11634 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.1, bsz=40, num_updates=11620, lr=4.71829e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31955
2023-02-20 22:08:20 - progress_bar.py[line:274] - INFO: epoch 001:  11644 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.1, bsz=40, num_updates=11630, lr=4.71792e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=31966
2023-02-20 22:08:31 - progress_bar.py[line:274] - INFO: epoch 001:  11654 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=110.9, bsz=40, num_updates=11640, lr=4.71756e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31977
2023-02-20 22:08:42 - progress_bar.py[line:274] - INFO: epoch 001:  11664 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.8, bsz=40, num_updates=11650, lr=4.7172e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31988
2023-02-20 22:08:53 - progress_bar.py[line:274] - INFO: epoch 001:  11674 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.9, wpb=111.8, bsz=40, num_updates=11660, lr=4.71684e-05, gnorm=0.16, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31999
2023-02-20 22:09:04 - progress_bar.py[line:274] - INFO: epoch 001:  11684 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.89, wpb=112.1, bsz=40, num_updates=11670, lr=4.71648e-05, gnorm=0.145, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32010
2023-02-20 22:09:15 - progress_bar.py[line:274] - INFO: epoch 001:  11694 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.2, bsz=40, num_updates=11680, lr=4.71612e-05, gnorm=0.119, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32022
2023-02-20 22:09:26 - progress_bar.py[line:274] - INFO: epoch 001:  11704 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=110.5, bsz=40, num_updates=11690, lr=4.71575e-05, gnorm=0.141, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32033
2023-02-20 22:09:37 - progress_bar.py[line:274] - INFO: epoch 001:  11714 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=11700, lr=4.71539e-05, gnorm=0.123, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=32044
2023-02-20 22:09:48 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 22:09:49 - progress_bar.py[line:274] - INFO: epoch 001:  11725 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92.7, ups=0.83, wpb=111.4, bsz=40, num_updates=11710, lr=4.71503e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=32056
2023-02-20 22:10:00 - progress_bar.py[line:274] - INFO: epoch 001:  11735 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.7, bsz=40, num_updates=11720, lr=4.71467e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32067
2023-02-20 22:10:11 - progress_bar.py[line:274] - INFO: epoch 001:  11745 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.2, bsz=40, num_updates=11730, lr=4.71431e-05, gnorm=0.149, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32078
2023-02-20 22:10:23 - progress_bar.py[line:274] - INFO: epoch 001:  11755 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.2, ups=0.87, wpb=111.2, bsz=40, num_updates=11740, lr=4.71394e-05, gnorm=0.156, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32089
2023-02-20 22:10:34 - progress_bar.py[line:274] - INFO: epoch 001:  11765 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.3, bsz=40, num_updates=11750, lr=4.71358e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32100
2023-02-20 22:10:45 - progress_bar.py[line:274] - INFO: epoch 001:  11775 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.7, bsz=40, num_updates=11760, lr=4.71322e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32111
2023-02-20 22:10:56 - progress_bar.py[line:274] - INFO: epoch 001:  11785 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=111.2, bsz=40, num_updates=11770, lr=4.71286e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=32123
2023-02-20 22:11:08 - progress_bar.py[line:274] - INFO: epoch 001:  11795 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.5, bsz=40, num_updates=11780, lr=4.7125e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32134
2023-02-20 22:11:19 - progress_bar.py[line:274] - INFO: epoch 001:  11805 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=112.5, bsz=40, num_updates=11790, lr=4.71214e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32145
2023-02-20 22:11:30 - progress_bar.py[line:274] - INFO: epoch 001:  11815 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.6, bsz=40, num_updates=11800, lr=4.71177e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32156
2023-02-20 22:11:41 - progress_bar.py[line:274] - INFO: epoch 001:  11825 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.8, bsz=40, num_updates=11810, lr=4.71141e-05, gnorm=0.169, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32168
2023-02-20 22:11:52 - progress_bar.py[line:274] - INFO: epoch 001:  11835 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=111, bsz=40, num_updates=11820, lr=4.71105e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32179
2023-02-20 22:12:04 - progress_bar.py[line:274] - INFO: epoch 001:  11845 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.5, bsz=40, num_updates=11830, lr=4.71069e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32190
2023-02-20 22:12:15 - progress_bar.py[line:274] - INFO: epoch 001:  11855 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.3, bsz=40, num_updates=11840, lr=4.71033e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=32201
2023-02-20 22:12:26 - progress_bar.py[line:274] - INFO: epoch 001:  11865 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=112.1, bsz=40, num_updates=11850, lr=4.70996e-05, gnorm=0.131, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32212
2023-02-20 22:12:37 - progress_bar.py[line:274] - INFO: epoch 001:  11875 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112.2, bsz=40, num_updates=11860, lr=4.7096e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=32224
2023-02-20 22:12:48 - progress_bar.py[line:274] - INFO: epoch 001:  11885 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.4, bsz=40, num_updates=11870, lr=4.70924e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=32235
2023-02-20 22:12:59 - progress_bar.py[line:274] - INFO: epoch 001:  11895 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.91, wpb=111.8, bsz=40, num_updates=11880, lr=4.70888e-05, gnorm=0.176, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=32246
2023-02-20 22:13:10 - progress_bar.py[line:274] - INFO: epoch 001:  11905 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112, bsz=40, num_updates=11890, lr=4.70852e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32257
2023-02-20 22:13:22 - progress_bar.py[line:274] - INFO: epoch 001:  11915 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111.1, bsz=40, num_updates=11900, lr=4.70816e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32268
2023-02-20 22:13:33 - progress_bar.py[line:274] - INFO: epoch 001:  11925 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.4, ups=0.87, wpb=111.4, bsz=40, num_updates=11910, lr=4.70779e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32280
2023-02-20 22:13:44 - progress_bar.py[line:274] - INFO: epoch 001:  11935 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.7, bsz=40, num_updates=11920, lr=4.70743e-05, gnorm=0.148, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32291
2023-02-20 22:13:56 - progress_bar.py[line:274] - INFO: epoch 001:  11945 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.9, wpb=113.1, bsz=40, num_updates=11930, lr=4.70707e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=32302
2023-02-20 22:14:07 - progress_bar.py[line:274] - INFO: epoch 001:  11955 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=112.6, bsz=40, num_updates=11940, lr=4.70671e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32313
2023-02-20 22:14:18 - progress_bar.py[line:274] - INFO: epoch 001:  11965 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.8, bsz=40, num_updates=11950, lr=4.70635e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32325
2023-02-20 22:14:29 - progress_bar.py[line:274] - INFO: epoch 001:  11975 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=11960, lr=4.70598e-05, gnorm=0.149, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32336
2023-02-20 22:14:40 - progress_bar.py[line:274] - INFO: epoch 001:  11985 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.8, bsz=40, num_updates=11970, lr=4.70562e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32347
2023-02-20 22:14:52 - progress_bar.py[line:274] - INFO: epoch 001:  11995 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.7, bsz=40, num_updates=11980, lr=4.70526e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32358
2023-02-20 22:15:03 - progress_bar.py[line:274] - INFO: epoch 001:  12005 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113.5, nsentences=40, sample_size=113.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.91, wpb=113.5, bsz=40, num_updates=11990, lr=4.7049e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=32369
2023-02-20 22:15:14 - progress_bar.py[line:274] - INFO: epoch 001:  12015 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.87, wpb=110.1, bsz=40, num_updates=12000, lr=4.70454e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32380
2023-02-20 22:15:14 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-20 22:15:15 - train.py[line:549] - INFO: 0 / 6234
2023-02-20 22:15:15 - train.py[line:551] - INFO: load:1.10 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-20 22:17:17 - train.py[line:549] - INFO: 200 / 6234
2023-02-20 22:17:17 - train.py[line:551] - INFO: load:1.13 valid_run:121.76 task_valid:118.99 collect_output:1.62
2023-02-20 22:19:17 - train.py[line:549] - INFO: 400 / 6234
2023-02-20 22:19:17 - train.py[line:551] - INFO: load:1.15 valid_run:241.20 task_valid:234.72 collect_output:4.23
2023-02-20 22:21:18 - train.py[line:549] - INFO: 600 / 6234
2023-02-20 22:21:18 - train.py[line:551] - INFO: load:1.18 valid_run:362.51 task_valid:351.09 collect_output:8.04
2023-02-20 22:23:19 - train.py[line:549] - INFO: 800 / 6234
2023-02-20 22:23:19 - train.py[line:551] - INFO: load:1.21 valid_run:483.71 task_valid:464.57 collect_output:14.73
2023-02-20 22:25:19 - train.py[line:549] - INFO: 1000 / 6234
2023-02-20 22:25:19 - train.py[line:551] - INFO: load:1.24 valid_run:603.66 task_valid:581.63 collect_output:16.58
2023-02-20 22:27:22 - train.py[line:549] - INFO: 1200 / 6234
2023-02-20 22:27:22 - train.py[line:551] - INFO: load:1.27 valid_run:726.02 task_valid:700.03 collect_output:19.51
2023-02-20 22:29:24 - train.py[line:549] - INFO: 1400 / 6234
2023-02-20 22:29:24 - train.py[line:551] - INFO: load:1.29 valid_run:848.18 task_valid:817.61 collect_output:23.08
2023-02-20 22:31:25 - train.py[line:549] - INFO: 1600 / 6234
2023-02-20 22:31:25 - train.py[line:551] - INFO: load:1.32 valid_run:969.17 task_valid:933.64 collect_output:27.03
2023-02-20 22:33:28 - train.py[line:549] - INFO: 1800 / 6234
2023-02-20 22:33:28 - train.py[line:551] - INFO: load:1.34 valid_run:1092.09 task_valid:1050.51 collect_output:32.06
2023-02-20 22:35:29 - train.py[line:549] - INFO: 2000 / 6234
2023-02-20 22:35:29 - train.py[line:551] - INFO: load:1.37 valid_run:1212.82 task_valid:1162.74 collect_output:39.54
2023-02-20 22:37:28 - train.py[line:549] - INFO: 2200 / 6234
2023-02-20 22:37:28 - train.py[line:551] - INFO: load:1.39 valid_run:1332.23 task_valid:1277.91 collect_output:42.76
2023-02-20 22:39:29 - train.py[line:549] - INFO: 2400 / 6234
2023-02-20 22:39:29 - train.py[line:551] - INFO: load:1.42 valid_run:1453.13 task_valid:1394.42 collect_output:46.12
2023-02-20 22:41:28 - train.py[line:549] - INFO: 2600 / 6234
2023-02-20 22:41:28 - train.py[line:551] - INFO: load:1.44 valid_run:1571.42 task_valid:1507.80 collect_output:50.02
2023-02-20 22:43:28 - train.py[line:549] - INFO: 2800 / 6234
2023-02-20 22:43:28 - train.py[line:551] - INFO: load:1.47 valid_run:1692.20 task_valid:1625.48 collect_output:52.10
2023-02-20 22:45:29 - train.py[line:549] - INFO: 3000 / 6234
2023-02-20 22:45:29 - train.py[line:551] - INFO: load:1.50 valid_run:1812.50 task_valid:1741.16 collect_output:55.69
2023-02-20 22:47:29 - train.py[line:549] - INFO: 3200 / 6234
2023-02-20 22:47:29 - train.py[line:551] - INFO: load:1.52 valid_run:1932.89 task_valid:1854.65 collect_output:61.58
2023-02-20 22:49:30 - train.py[line:549] - INFO: 3400 / 6234
2023-02-20 22:49:30 - train.py[line:551] - INFO: load:1.55 valid_run:2053.54 task_valid:1970.32 collect_output:65.52
2023-02-20 22:51:30 - train.py[line:549] - INFO: 3600 / 6234
2023-02-20 22:51:30 - train.py[line:551] - INFO: load:1.57 valid_run:2173.48 task_valid:2087.69 collect_output:67.07
2023-02-20 22:53:31 - train.py[line:549] - INFO: 3800 / 6234
2023-02-20 22:53:31 - train.py[line:551] - INFO: load:1.60 valid_run:2294.01 task_valid:2204.16 collect_output:70.13
2023-02-20 22:55:30 - train.py[line:549] - INFO: 4000 / 6234
2023-02-20 22:55:30 - train.py[line:551] - INFO: load:1.62 valid_run:2413.73 task_valid:2320.32 collect_output:72.68
2023-02-20 22:57:31 - train.py[line:549] - INFO: 4200 / 6234
2023-02-20 22:57:31 - train.py[line:551] - INFO: load:1.65 valid_run:2534.57 task_valid:2436.39 collect_output:76.43
2023-02-20 22:59:33 - train.py[line:549] - INFO: 4400 / 6234
2023-02-20 22:59:33 - train.py[line:551] - INFO: load:1.67 valid_run:2655.83 task_valid:2554.84 collect_output:78.24
2023-02-20 23:01:32 - train.py[line:549] - INFO: 4600 / 6234
2023-02-20 23:01:32 - train.py[line:551] - INFO: load:1.70 valid_run:2775.46 task_valid:2668.85 collect_output:82.84
2023-02-20 23:03:32 - train.py[line:549] - INFO: 4800 / 6234
2023-02-20 23:03:32 - train.py[line:551] - INFO: load:1.72 valid_run:2894.64 task_valid:2784.71 collect_output:85.14
2023-02-20 23:05:33 - train.py[line:549] - INFO: 5000 / 6234
2023-02-20 23:05:33 - train.py[line:551] - INFO: load:1.75 valid_run:3015.67 task_valid:2900.71 collect_output:89.14
2023-02-20 23:07:35 - train.py[line:549] - INFO: 5200 / 6234
2023-02-20 23:07:35 - train.py[line:551] - INFO: load:1.77 valid_run:3137.84 task_valid:3016.45 collect_output:94.55
2023-02-20 23:09:34 - train.py[line:549] - INFO: 5400 / 6234
2023-02-20 23:09:34 - train.py[line:551] - INFO: load:1.80 valid_run:3256.77 task_valid:3130.24 collect_output:98.67
2023-02-20 23:11:35 - train.py[line:549] - INFO: 5600 / 6234
2023-02-20 23:11:35 - train.py[line:551] - INFO: load:1.83 valid_run:3378.20 task_valid:3249.39 collect_output:99.95
2023-02-20 23:13:37 - train.py[line:549] - INFO: 5800 / 6234
2023-02-20 23:13:37 - train.py[line:551] - INFO: load:1.85 valid_run:3499.35 task_valid:3364.66 collect_output:104.77
2023-02-20 23:15:38 - train.py[line:549] - INFO: 6000 / 6234
2023-02-20 23:15:38 - train.py[line:551] - INFO: load:1.88 valid_run:3620.74 task_valid:3482.78 collect_output:107.02
2023-02-20 23:17:39 - train.py[line:549] - INFO: 6200 / 6234
2023-02-20 23:17:39 - train.py[line:551] - INFO: load:1.90 valid_run:3741.35 task_valid:3600.92 collect_output:108.47

====================================================================================================
SGG eval:     R @ 50: 0.6475;     R @ 100: 0.6819;     R @ 500: 0.7034;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4006;    mR @ 100: 0.4652;    mR @ 500: 0.5444;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.6250) (covering:0.3000) (eating:0.7647) (flying in:0.5909) (growing on:0.5000) (hanging from:0.5000) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9771) (says:0.0000) (sitting on:0.7347) (standing on:0.3693) (using:0.6000) (walking in:0.0000) (walking on:0.7568) (watching:0.4028) 
--------------------------------------------------------
====================================================================================================

2023-02-20 23:18:09 - train.py[line:487] - INFO: 0.6819451489686784

====================================================================================================
SGG eval:     R @ 50: 0.6475;     R @ 100: 0.6819;     R @ 500: 0.7034;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4006;    mR @ 100: 0.4652;    mR @ 500: 0.5444;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.6250) (covering:0.3000) (eating:0.7647) (flying in:0.5909) (growing on:0.5000) (hanging from:0.5000) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9771) (says:0.0000) (sitting on:0.7347) (standing on:0.3693) (using:0.6000) (walking in:0.0000) (walking on:0.7568) (watching:0.4028) 
--------------------------------------------------------
====================================================================================================

2023-02-20 23:18:09 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-20 23:18:10 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.235 | loss_v1 0 | loss_v2 0 | nll_loss 0.063 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.681945 | ppl 1.04 | vqa_score 0.4809 | wps 118.9 | wpb 72 | bsz 24 | num_updates 12000 | best_R@100 0.691462
2023-02-20 23:18:10 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 12000 updates
2023-02-20 23:18:10 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_12000.pt
2023-02-20 23:18:15 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_12000.pt
2023-02-20 23:18:18 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 0.6819451489686784) (writing took 8.617570977658033 seconds)
2023-02-20 23:18:29 - progress_bar.py[line:274] - INFO: epoch 001:  12025 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=111.1, bsz=40, num_updates=12010, lr=4.70418e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36176
2023-02-20 23:18:40 - progress_bar.py[line:274] - INFO: epoch 001:  12035 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.7, bsz=40, num_updates=12020, lr=4.70381e-05, gnorm=0.145, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36187
2023-02-20 23:18:51 - progress_bar.py[line:274] - INFO: epoch 001:  12045 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.3, bsz=40, num_updates=12030, lr=4.70345e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36198
2023-02-20 23:19:03 - progress_bar.py[line:274] - INFO: epoch 001:  12055 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.3, bsz=40, num_updates=12040, lr=4.70309e-05, gnorm=0.167, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36209
2023-02-20 23:19:14 - progress_bar.py[line:274] - INFO: epoch 001:  12065 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.2, bsz=40, num_updates=12050, lr=4.70273e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=36220
2023-02-20 23:19:25 - progress_bar.py[line:274] - INFO: epoch 001:  12075 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.92, wpb=112.3, bsz=40, num_updates=12060, lr=4.70237e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36231
2023-02-20 23:19:36 - progress_bar.py[line:274] - INFO: epoch 001:  12085 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.92, wpb=112.3, bsz=40, num_updates=12070, lr=4.702e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36242
2023-02-20 23:19:47 - progress_bar.py[line:274] - INFO: epoch 001:  12095 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.89, wpb=111.7, bsz=40, num_updates=12080, lr=4.70164e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36254
2023-02-20 23:19:58 - progress_bar.py[line:274] - INFO: epoch 001:  12105 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.9, wpb=110.7, bsz=40, num_updates=12090, lr=4.70128e-05, gnorm=0.167, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=36265
2023-02-20 23:20:09 - progress_bar.py[line:274] - INFO: epoch 001:  12115 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.3, bsz=40, num_updates=12100, lr=4.70092e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36276
2023-02-20 23:20:21 - progress_bar.py[line:274] - INFO: epoch 001:  12125 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.6, bsz=40, num_updates=12110, lr=4.70056e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36287
2023-02-20 23:20:31 - progress_bar.py[line:274] - INFO: epoch 001:  12135 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.2, bsz=40, num_updates=12120, lr=4.7002e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36298
2023-02-20 23:20:42 - progress_bar.py[line:274] - INFO: epoch 001:  12145 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=110.6, bsz=40, num_updates=12130, lr=4.69983e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36309
2023-02-20 23:20:53 - progress_bar.py[line:274] - INFO: epoch 001:  12155 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.93, wpb=111.2, bsz=40, num_updates=12140, lr=4.69947e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36320
2023-02-20 23:21:04 - progress_bar.py[line:274] - INFO: epoch 001:  12165 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.1, bsz=40, num_updates=12150, lr=4.69911e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36331
2023-02-20 23:21:15 - progress_bar.py[line:274] - INFO: epoch 001:  12175 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=12160, lr=4.69875e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=36342
2023-02-20 23:21:27 - progress_bar.py[line:274] - INFO: epoch 001:  12185 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.9, bsz=40, num_updates=12170, lr=4.69839e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=36353
2023-02-20 23:21:38 - progress_bar.py[line:274] - INFO: epoch 001:  12195 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.5, bsz=40, num_updates=12180, lr=4.69802e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=36364
2023-02-20 23:21:49 - progress_bar.py[line:274] - INFO: epoch 001:  12205 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.8, bsz=40, num_updates=12190, lr=4.69766e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36375
2023-02-20 23:22:00 - progress_bar.py[line:274] - INFO: epoch 001:  12215 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113.7, nsentences=40, sample_size=113.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.91, wpb=113.7, bsz=40, num_updates=12200, lr=4.6973e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36386
2023-02-20 23:22:11 - progress_bar.py[line:274] - INFO: epoch 001:  12225 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.8, bsz=40, num_updates=12210, lr=4.69694e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36397
2023-02-20 23:22:23 - progress_bar.py[line:274] - INFO: epoch 001:  12235 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=112, bsz=40, num_updates=12220, lr=4.69658e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=36409
2023-02-20 23:22:34 - progress_bar.py[line:274] - INFO: epoch 001:  12245 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.6, bsz=40, num_updates=12230, lr=4.69622e-05, gnorm=0.135, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36420
2023-02-20 23:22:45 - progress_bar.py[line:274] - INFO: epoch 001:  12255 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.7, bsz=40, num_updates=12240, lr=4.69585e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36432
2023-02-20 23:22:56 - progress_bar.py[line:274] - INFO: epoch 001:  12265 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.5, ups=0.93, wpb=113.3, bsz=40, num_updates=12250, lr=4.69549e-05, gnorm=0.127, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36442
2023-02-20 23:23:07 - progress_bar.py[line:274] - INFO: epoch 001:  12275 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.2, bsz=40, num_updates=12260, lr=4.69513e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36453
2023-02-20 23:23:18 - progress_bar.py[line:274] - INFO: epoch 001:  12285 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.1, ups=0.92, wpb=112.1, bsz=40, num_updates=12270, lr=4.69477e-05, gnorm=0.132, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=36464
2023-02-20 23:23:29 - progress_bar.py[line:274] - INFO: epoch 001:  12295 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.4, bsz=40, num_updates=12280, lr=4.69441e-05, gnorm=0.105, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36475
2023-02-20 23:23:40 - progress_bar.py[line:274] - INFO: epoch 001:  12305 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.4, bsz=40, num_updates=12290, lr=4.69404e-05, gnorm=0.133, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36486
2023-02-20 23:23:51 - progress_bar.py[line:274] - INFO: epoch 001:  12315 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.9, bsz=40, num_updates=12300, lr=4.69368e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=36497
2023-02-20 23:24:02 - progress_bar.py[line:274] - INFO: epoch 001:  12325 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=112, bsz=40, num_updates=12310, lr=4.69332e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=36509
2023-02-20 23:24:13 - progress_bar.py[line:274] - INFO: epoch 001:  12335 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.93, wpb=109.3, bsz=40, num_updates=12320, lr=4.69296e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36519
2023-02-20 23:24:24 - progress_bar.py[line:274] - INFO: epoch 001:  12345 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.5, bsz=40, num_updates=12330, lr=4.6926e-05, gnorm=0.123, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36530
2023-02-20 23:24:35 - progress_bar.py[line:274] - INFO: epoch 001:  12355 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.8, bsz=40, num_updates=12340, lr=4.69224e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36541
2023-02-20 23:24:46 - progress_bar.py[line:274] - INFO: epoch 001:  12365 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=111.9, bsz=40, num_updates=12350, lr=4.69187e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36553
2023-02-20 23:24:58 - progress_bar.py[line:274] - INFO: epoch 001:  12375 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=12360, lr=4.69151e-05, gnorm=0.153, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36564
2023-02-20 23:25:08 - progress_bar.py[line:274] - INFO: epoch 001:  12385 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.2, ups=0.93, wpb=112.8, bsz=40, num_updates=12370, lr=4.69115e-05, gnorm=0.122, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36575
2023-02-20 23:25:20 - progress_bar.py[line:274] - INFO: epoch 001:  12395 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.4, bsz=40, num_updates=12380, lr=4.69079e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36586
2023-02-20 23:25:31 - progress_bar.py[line:274] - INFO: epoch 001:  12405 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.89, wpb=113.1, bsz=40, num_updates=12390, lr=4.69043e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36597
2023-02-20 23:25:42 - progress_bar.py[line:274] - INFO: epoch 001:  12415 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.9, wpb=112.4, bsz=40, num_updates=12400, lr=4.69006e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36608
2023-02-20 23:25:53 - progress_bar.py[line:274] - INFO: epoch 001:  12425 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.7, bsz=40, num_updates=12410, lr=4.6897e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36619
2023-02-20 23:26:04 - progress_bar.py[line:274] - INFO: epoch 001:  12435 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.2, bsz=40, num_updates=12420, lr=4.68934e-05, gnorm=0.138, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36630
2023-02-20 23:26:15 - progress_bar.py[line:274] - INFO: epoch 001:  12445 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.9, bsz=40, num_updates=12430, lr=4.68898e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36641
2023-02-20 23:26:26 - progress_bar.py[line:274] - INFO: epoch 001:  12455 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=110.9, bsz=40, num_updates=12440, lr=4.68862e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36652
2023-02-20 23:26:37 - progress_bar.py[line:274] - INFO: epoch 001:  12465 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112, bsz=40, num_updates=12450, lr=4.68826e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36664
2023-02-20 23:26:48 - progress_bar.py[line:274] - INFO: epoch 001:  12475 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=111, bsz=40, num_updates=12460, lr=4.68789e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36674
2023-02-20 23:26:59 - progress_bar.py[line:274] - INFO: epoch 001:  12485 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.9, ups=0.94, wpb=111.9, bsz=40, num_updates=12470, lr=4.68753e-05, gnorm=0.128, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36685
2023-02-20 23:27:10 - progress_bar.py[line:274] - INFO: epoch 001:  12495 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.8, bsz=40, num_updates=12480, lr=4.68717e-05, gnorm=0.148, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36696
2023-02-20 23:27:21 - progress_bar.py[line:274] - INFO: epoch 001:  12505 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.94, wpb=111.3, bsz=40, num_updates=12490, lr=4.68681e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36707
2023-02-20 23:27:32 - progress_bar.py[line:274] - INFO: epoch 001:  12515 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.86, wpb=112.7, bsz=40, num_updates=12500, lr=4.68645e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=36719
2023-02-20 23:27:43 - progress_bar.py[line:274] - INFO: epoch 001:  12525 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=111.8, bsz=40, num_updates=12510, lr=4.68608e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36730
2023-02-20 23:27:54 - progress_bar.py[line:274] - INFO: epoch 001:  12535 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.1, ups=0.93, wpb=111.6, bsz=40, num_updates=12520, lr=4.68572e-05, gnorm=0.175, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=36740
2023-02-20 23:28:05 - progress_bar.py[line:274] - INFO: epoch 001:  12545 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.4, bsz=40, num_updates=12530, lr=4.68536e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36752
2023-02-20 23:28:16 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 23:28:17 - progress_bar.py[line:274] - INFO: epoch 001:  12556 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.7, ups=0.83, wpb=112.5, bsz=40, num_updates=12540, lr=4.685e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=36764
2023-02-20 23:28:29 - progress_bar.py[line:274] - INFO: epoch 001:  12566 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.3, bsz=40, num_updates=12550, lr=4.68464e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36775
2023-02-20 23:28:40 - progress_bar.py[line:274] - INFO: epoch 001:  12576 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112, bsz=40, num_updates=12560, lr=4.68428e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36786
2023-02-20 23:28:51 - progress_bar.py[line:274] - INFO: epoch 001:  12586 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.9, ups=0.93, wpb=111.3, bsz=40, num_updates=12570, lr=4.68391e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36797
2023-02-20 23:29:02 - progress_bar.py[line:274] - INFO: epoch 001:  12596 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=111.2, bsz=40, num_updates=12580, lr=4.68355e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36808
2023-02-20 23:29:13 - progress_bar.py[line:274] - INFO: epoch 001:  12606 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111, bsz=40, num_updates=12590, lr=4.68319e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36820
2023-02-20 23:29:24 - progress_bar.py[line:274] - INFO: epoch 001:  12616 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=113, bsz=40, num_updates=12600, lr=4.68283e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=36831
2023-02-20 23:29:36 - progress_bar.py[line:274] - INFO: epoch 001:  12626 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112.3, bsz=40, num_updates=12610, lr=4.68247e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36842
2023-02-20 23:29:47 - progress_bar.py[line:274] - INFO: epoch 001:  12636 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.9, wpb=110.1, bsz=40, num_updates=12620, lr=4.6821e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=36853
2023-02-20 23:29:58 - progress_bar.py[line:274] - INFO: epoch 001:  12646 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.9, bsz=40, num_updates=12630, lr=4.68174e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36864
2023-02-20 23:30:09 - progress_bar.py[line:274] - INFO: epoch 001:  12656 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=110.5, bsz=40, num_updates=12640, lr=4.68138e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=36876
2023-02-20 23:30:21 - progress_bar.py[line:274] - INFO: epoch 001:  12666 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.8, bsz=40, num_updates=12650, lr=4.68102e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36887
2023-02-20 23:30:32 - progress_bar.py[line:274] - INFO: epoch 001:  12676 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.8, bsz=40, num_updates=12660, lr=4.68066e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=36898
2023-02-20 23:30:43 - progress_bar.py[line:274] - INFO: epoch 001:  12686 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.4, ups=0.93, wpb=112.8, bsz=40, num_updates=12670, lr=4.6803e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36909
2023-02-20 23:30:54 - progress_bar.py[line:274] - INFO: epoch 001:  12696 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112, bsz=40, num_updates=12680, lr=4.67993e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36920
2023-02-20 23:31:05 - progress_bar.py[line:274] - INFO: epoch 001:  12706 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.6, bsz=40, num_updates=12690, lr=4.67957e-05, gnorm=0.153, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=36931
2023-02-20 23:31:16 - progress_bar.py[line:274] - INFO: epoch 001:  12716 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=12700, lr=4.67921e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=36942
2023-02-20 23:31:27 - progress_bar.py[line:274] - INFO: epoch 001:  12726 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112, bsz=40, num_updates=12710, lr=4.67885e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36953
2023-02-20 23:31:38 - progress_bar.py[line:274] - INFO: epoch 001:  12736 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.2, bsz=40, num_updates=12720, lr=4.67849e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36964
2023-02-20 23:31:49 - progress_bar.py[line:274] - INFO: epoch 001:  12746 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.5, bsz=40, num_updates=12730, lr=4.67812e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36976
2023-02-20 23:32:00 - progress_bar.py[line:274] - INFO: epoch 001:  12756 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111, bsz=40, num_updates=12740, lr=4.67776e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36987
2023-02-20 23:32:11 - progress_bar.py[line:274] - INFO: epoch 001:  12766 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.7, bsz=40, num_updates=12750, lr=4.6774e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=36998
2023-02-20 23:32:22 - progress_bar.py[line:274] - INFO: epoch 001:  12776 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.7, bsz=40, num_updates=12760, lr=4.67704e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37009
2023-02-20 23:32:34 - progress_bar.py[line:274] - INFO: epoch 001:  12786 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.87, wpb=111, bsz=40, num_updates=12770, lr=4.67668e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37020
2023-02-20 23:32:44 - progress_bar.py[line:274] - INFO: epoch 001:  12796 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.93, wpb=111.1, bsz=40, num_updates=12780, lr=4.67632e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=37031
2023-02-20 23:32:56 - progress_bar.py[line:274] - INFO: epoch 001:  12806 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.7, bsz=40, num_updates=12790, lr=4.67595e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=37042
2023-02-20 23:33:07 - progress_bar.py[line:274] - INFO: epoch 001:  12816 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.9, bsz=40, num_updates=12800, lr=4.67559e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37054
2023-02-20 23:33:18 - progress_bar.py[line:274] - INFO: epoch 001:  12826 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=111.5, bsz=40, num_updates=12810, lr=4.67523e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=37065
2023-02-20 23:33:29 - progress_bar.py[line:274] - INFO: epoch 001:  12836 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=109.9, bsz=40, num_updates=12820, lr=4.67487e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37076
2023-02-20 23:33:40 - progress_bar.py[line:274] - INFO: epoch 001:  12846 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.5, bsz=40, num_updates=12830, lr=4.67451e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37087
2023-02-20 23:33:52 - progress_bar.py[line:274] - INFO: epoch 001:  12856 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.9, bsz=40, num_updates=12840, lr=4.67414e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=37098
2023-02-20 23:34:02 - progress_bar.py[line:274] - INFO: epoch 001:  12866 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.93, wpb=111.2, bsz=40, num_updates=12850, lr=4.67378e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37109
2023-02-20 23:34:14 - progress_bar.py[line:274] - INFO: epoch 001:  12876 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.2, bsz=40, num_updates=12860, lr=4.67342e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37120
2023-02-20 23:34:25 - progress_bar.py[line:274] - INFO: epoch 001:  12886 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.6, bsz=40, num_updates=12870, lr=4.67306e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37131
2023-02-20 23:34:36 - progress_bar.py[line:274] - INFO: epoch 001:  12896 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.4, bsz=40, num_updates=12880, lr=4.6727e-05, gnorm=0.17, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=37142
2023-02-20 23:34:47 - progress_bar.py[line:274] - INFO: epoch 001:  12906 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.7, bsz=40, num_updates=12890, lr=4.67234e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37153
2023-02-20 23:34:58 - progress_bar.py[line:274] - INFO: epoch 001:  12916 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.6, bsz=40, num_updates=12900, lr=4.67197e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37164
2023-02-20 23:35:09 - progress_bar.py[line:274] - INFO: epoch 001:  12926 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.6, bsz=40, num_updates=12910, lr=4.67161e-05, gnorm=0.16, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37175
2023-02-20 23:35:20 - progress_bar.py[line:274] - INFO: epoch 001:  12936 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.5, ups=0.92, wpb=111.3, bsz=40, num_updates=12920, lr=4.67125e-05, gnorm=0.165, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37186
2023-02-20 23:35:31 - progress_bar.py[line:274] - INFO: epoch 001:  12946 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.89, wpb=110.3, bsz=40, num_updates=12930, lr=4.67089e-05, gnorm=0.17, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37197
2023-02-20 23:35:42 - progress_bar.py[line:274] - INFO: epoch 001:  12956 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111, bsz=40, num_updates=12940, lr=4.67053e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37208
2023-02-20 23:35:53 - progress_bar.py[line:274] - INFO: epoch 001:  12966 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.89, wpb=109.5, bsz=40, num_updates=12950, lr=4.67016e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37220
2023-02-20 23:36:05 - progress_bar.py[line:274] - INFO: epoch 001:  12976 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=12960, lr=4.6698e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37231
2023-02-20 23:36:16 - progress_bar.py[line:274] - INFO: epoch 001:  12986 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.3, bsz=40, num_updates=12970, lr=4.66944e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37242
2023-02-20 23:36:27 - progress_bar.py[line:274] - INFO: epoch 001:  12996 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.4, bsz=40, num_updates=12980, lr=4.66908e-05, gnorm=0.144, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=37253
2023-02-20 23:36:38 - progress_bar.py[line:274] - INFO: epoch 001:  13006 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.3, bsz=40, num_updates=12990, lr=4.66872e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37264
2023-02-20 23:36:49 - progress_bar.py[line:274] - INFO: epoch 001:  13016 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.6, bsz=40, num_updates=13000, lr=4.66836e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=37275
2023-02-20 23:37:00 - progress_bar.py[line:274] - INFO: epoch 001:  13026 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=112.7, bsz=40, num_updates=13010, lr=4.66799e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37287
2023-02-20 23:37:11 - progress_bar.py[line:274] - INFO: epoch 001:  13036 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.3, bsz=40, num_updates=13020, lr=4.66763e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37298
2023-02-20 23:37:22 - progress_bar.py[line:274] - INFO: epoch 001:  13046 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=13030, lr=4.66727e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=37309
2023-02-20 23:37:33 - progress_bar.py[line:274] - INFO: epoch 001:  13056 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.91, wpb=112.7, bsz=40, num_updates=13040, lr=4.66691e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37320
2023-02-20 23:37:44 - progress_bar.py[line:274] - INFO: epoch 001:  13066 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.9, ups=0.95, wpb=111.9, bsz=40, num_updates=13050, lr=4.66655e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=37330
2023-02-20 23:37:56 - progress_bar.py[line:274] - INFO: epoch 001:  13076 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=110.7, bsz=40, num_updates=13060, lr=4.66618e-05, gnorm=0.122, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37342
2023-02-20 23:38:07 - progress_bar.py[line:274] - INFO: epoch 001:  13086 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.9, bsz=40, num_updates=13070, lr=4.66582e-05, gnorm=0.131, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37353
2023-02-20 23:38:18 - progress_bar.py[line:274] - INFO: epoch 001:  13096 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.2, bsz=40, num_updates=13080, lr=4.66546e-05, gnorm=0.127, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37364
2023-02-20 23:38:28 - progress_bar.py[line:274] - INFO: epoch 001:  13106 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=113.5, nsentences=40, sample_size=113.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.92, wpb=113.5, bsz=40, num_updates=13090, lr=4.6651e-05, gnorm=0.111, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37375
2023-02-20 23:38:39 - progress_bar.py[line:274] - INFO: epoch 001:  13116 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.2, bsz=40, num_updates=13100, lr=4.66474e-05, gnorm=0.138, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37386
2023-02-20 23:38:50 - progress_bar.py[line:274] - INFO: epoch 001:  13126 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.4, bsz=40, num_updates=13110, lr=4.66438e-05, gnorm=0.133, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37397
2023-02-20 23:39:01 - progress_bar.py[line:274] - INFO: epoch 001:  13136 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.1, bsz=40, num_updates=13120, lr=4.66401e-05, gnorm=0.101, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37408
2023-02-20 23:39:12 - progress_bar.py[line:274] - INFO: epoch 001:  13146 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.6, ups=0.93, wpb=112.3, bsz=40, num_updates=13130, lr=4.66365e-05, gnorm=0.133, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37418
2023-02-20 23:39:23 - progress_bar.py[line:274] - INFO: epoch 001:  13156 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.8, ups=0.93, wpb=112.2, bsz=40, num_updates=13140, lr=4.66329e-05, gnorm=0.114, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=37429
2023-02-20 23:39:34 - progress_bar.py[line:274] - INFO: epoch 001:  13166 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=13150, lr=4.66293e-05, gnorm=0.175, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37440
2023-02-20 23:39:45 - progress_bar.py[line:274] - INFO: epoch 001:  13176 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.5, bsz=40, num_updates=13160, lr=4.66257e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37451
2023-02-20 23:39:56 - progress_bar.py[line:274] - INFO: epoch 001:  13186 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.91, wpb=112.4, bsz=40, num_updates=13170, lr=4.6622e-05, gnorm=0.111, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37462
2023-02-20 23:40:07 - progress_bar.py[line:274] - INFO: epoch 001:  13196 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.87, wpb=111.8, bsz=40, num_updates=13180, lr=4.66184e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37474
2023-02-20 23:40:19 - progress_bar.py[line:274] - INFO: epoch 001:  13206 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.87, wpb=112.5, bsz=40, num_updates=13190, lr=4.66148e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37485
2023-02-20 23:40:30 - progress_bar.py[line:274] - INFO: epoch 001:  13216 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.1, bsz=40, num_updates=13200, lr=4.66112e-05, gnorm=0.164, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37496
2023-02-20 23:40:41 - progress_bar.py[line:274] - INFO: epoch 001:  13226 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=110.9, bsz=40, num_updates=13210, lr=4.66076e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37507
2023-02-20 23:40:52 - progress_bar.py[line:274] - INFO: epoch 001:  13236 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=111.9, bsz=40, num_updates=13220, lr=4.6604e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37519
2023-02-20 23:41:03 - progress_bar.py[line:274] - INFO: epoch 001:  13246 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.8, bsz=40, num_updates=13230, lr=4.66003e-05, gnorm=0.145, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37530
2023-02-20 23:41:14 - progress_bar.py[line:274] - INFO: epoch 001:  13256 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.4, bsz=40, num_updates=13240, lr=4.65967e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=37541
2023-02-20 23:41:25 - progress_bar.py[line:274] - INFO: epoch 001:  13266 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=13250, lr=4.65931e-05, gnorm=0.115, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37552
2023-02-20 23:41:37 - progress_bar.py[line:274] - INFO: epoch 001:  13276 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.7, bsz=40, num_updates=13260, lr=4.65895e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37563
2023-02-20 23:41:48 - progress_bar.py[line:274] - INFO: epoch 001:  13286 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.9, wpb=111.4, bsz=40, num_updates=13270, lr=4.65859e-05, gnorm=0.187, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=37574
2023-02-20 23:41:59 - progress_bar.py[line:274] - INFO: epoch 001:  13296 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.9, ups=0.93, wpb=112.3, bsz=40, num_updates=13280, lr=4.65822e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37585
2023-02-20 23:42:10 - progress_bar.py[line:274] - INFO: epoch 001:  13306 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=110.9, bsz=40, num_updates=13290, lr=4.65786e-05, gnorm=0.101, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37596
2023-02-20 23:42:16 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 23:42:22 - progress_bar.py[line:274] - INFO: epoch 001:  13317 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.7, ups=0.81, wpb=111.6, bsz=40, num_updates=13300, lr=4.6575e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=37608
2023-02-20 23:42:33 - progress_bar.py[line:274] - INFO: epoch 001:  13327 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=111.3, bsz=40, num_updates=13310, lr=4.65714e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37620
2023-02-20 23:42:45 - progress_bar.py[line:274] - INFO: epoch 001:  13337 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.1, bsz=40, num_updates=13320, lr=4.65678e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=37631
2023-02-20 23:42:56 - progress_bar.py[line:274] - INFO: epoch 001:  13347 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.3, bsz=40, num_updates=13330, lr=4.65642e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=37642
2023-02-20 23:43:07 - progress_bar.py[line:274] - INFO: epoch 001:  13357 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112.5, bsz=40, num_updates=13340, lr=4.65605e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37653
2023-02-20 23:43:18 - progress_bar.py[line:274] - INFO: epoch 001:  13367 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=111.4, bsz=40, num_updates=13350, lr=4.65569e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37665
2023-02-20 23:43:29 - progress_bar.py[line:274] - INFO: epoch 001:  13377 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.9, ups=0.94, wpb=112.2, bsz=40, num_updates=13360, lr=4.65533e-05, gnorm=0.161, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37675
2023-02-20 23:43:40 - progress_bar.py[line:274] - INFO: epoch 001:  13387 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.2, ups=0.93, wpb=112.4, bsz=40, num_updates=13370, lr=4.65497e-05, gnorm=0.142, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37686
2023-02-20 23:43:51 - progress_bar.py[line:274] - INFO: epoch 001:  13397 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=111.6, bsz=40, num_updates=13380, lr=4.65461e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37697
2023-02-20 23:44:02 - progress_bar.py[line:274] - INFO: epoch 001:  13407 / 71012 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.89, wpb=109.7, bsz=40, num_updates=13390, lr=4.65424e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=37709
2023-02-20 23:44:14 - progress_bar.py[line:274] - INFO: epoch 001:  13417 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=111.3, bsz=40, num_updates=13400, lr=4.65388e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37720
2023-02-20 23:44:25 - progress_bar.py[line:274] - INFO: epoch 001:  13427 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=13410, lr=4.65352e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37731
2023-02-20 23:44:36 - progress_bar.py[line:274] - INFO: epoch 001:  13437 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.89, wpb=109.6, bsz=40, num_updates=13420, lr=4.65316e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37742
2023-02-20 23:44:47 - progress_bar.py[line:274] - INFO: epoch 001:  13447 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112.9, bsz=40, num_updates=13430, lr=4.6528e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37754
2023-02-20 23:44:58 - progress_bar.py[line:274] - INFO: epoch 001:  13457 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.4, bsz=40, num_updates=13440, lr=4.65244e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37765
2023-02-20 23:45:10 - progress_bar.py[line:274] - INFO: epoch 001:  13467 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.1, bsz=40, num_updates=13450, lr=4.65207e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37776
2023-02-20 23:45:21 - progress_bar.py[line:274] - INFO: epoch 001:  13477 / 71012 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=98.9, ups=0.9, wpb=110.5, bsz=40, num_updates=13460, lr=4.65171e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=37787
2023-02-20 23:45:32 - progress_bar.py[line:274] - INFO: epoch 001:  13487 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=13470, lr=4.65135e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37798
2023-02-20 23:45:43 - progress_bar.py[line:274] - INFO: epoch 001:  13497 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.8, bsz=40, num_updates=13480, lr=4.65099e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37810
2023-02-20 23:45:54 - progress_bar.py[line:274] - INFO: epoch 001:  13507 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.9, bsz=40, num_updates=13490, lr=4.65063e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=37821
2023-02-20 23:46:05 - progress_bar.py[line:274] - INFO: epoch 001:  13517 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.6, bsz=40, num_updates=13500, lr=4.65026e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=37832
2023-02-20 23:46:16 - progress_bar.py[line:274] - INFO: epoch 001:  13527 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.9, wpb=112.7, bsz=40, num_updates=13510, lr=4.6499e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37843
2023-02-20 23:46:28 - progress_bar.py[line:274] - INFO: epoch 001:  13537 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.9, bsz=40, num_updates=13520, lr=4.64954e-05, gnorm=0.117, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37854
2023-02-20 23:46:39 - progress_bar.py[line:274] - INFO: epoch 001:  13547 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.6, bsz=40, num_updates=13530, lr=4.64918e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37865
2023-02-20 23:46:50 - progress_bar.py[line:274] - INFO: epoch 001:  13557 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.2, bsz=40, num_updates=13540, lr=4.64882e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37876
2023-02-20 23:47:01 - progress_bar.py[line:274] - INFO: epoch 001:  13567 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.5, bsz=40, num_updates=13550, lr=4.64846e-05, gnorm=0.17, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37887
2023-02-20 23:47:12 - progress_bar.py[line:274] - INFO: epoch 001:  13577 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.8, bsz=40, num_updates=13560, lr=4.64809e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37898
2023-02-20 23:47:23 - progress_bar.py[line:274] - INFO: epoch 001:  13587 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.9, wpb=110.6, bsz=40, num_updates=13570, lr=4.64773e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=37909
2023-02-20 23:47:34 - progress_bar.py[line:274] - INFO: epoch 001:  13597 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.5, bsz=40, num_updates=13580, lr=4.64737e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37920
2023-02-20 23:47:45 - progress_bar.py[line:274] - INFO: epoch 001:  13607 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.9, ups=0.93, wpb=112.6, bsz=40, num_updates=13590, lr=4.64701e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37931
2023-02-20 23:47:56 - progress_bar.py[line:274] - INFO: epoch 001:  13617 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.2, bsz=40, num_updates=13600, lr=4.64665e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37942
2023-02-20 23:48:07 - progress_bar.py[line:274] - INFO: epoch 001:  13627 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112.1, bsz=40, num_updates=13610, lr=4.64628e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37954
2023-02-20 23:48:18 - progress_bar.py[line:274] - INFO: epoch 001:  13637 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.7, bsz=40, num_updates=13620, lr=4.64592e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37965
2023-02-20 23:48:29 - progress_bar.py[line:274] - INFO: epoch 001:  13647 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.7, bsz=40, num_updates=13630, lr=4.64556e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=37976
2023-02-20 23:48:40 - progress_bar.py[line:274] - INFO: epoch 001:  13657 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.4, bsz=40, num_updates=13640, lr=4.6452e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37987
2023-02-20 23:48:51 - progress_bar.py[line:274] - INFO: epoch 001:  13667 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.9, wpb=110.1, bsz=40, num_updates=13650, lr=4.64484e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37998
2023-02-20 23:49:03 - progress_bar.py[line:274] - INFO: epoch 001:  13677 / 71012 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=13660, lr=4.64447e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=38009
2023-02-20 23:49:14 - progress_bar.py[line:274] - INFO: epoch 001:  13687 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.7, bsz=40, num_updates=13670, lr=4.64411e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38021
2023-02-20 23:49:25 - progress_bar.py[line:274] - INFO: epoch 001:  13697 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.1, bsz=40, num_updates=13680, lr=4.64375e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38032
2023-02-20 23:49:37 - progress_bar.py[line:274] - INFO: epoch 001:  13707 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.1, bsz=40, num_updates=13690, lr=4.64339e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38043
2023-02-20 23:49:48 - progress_bar.py[line:274] - INFO: epoch 001:  13717 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.7, bsz=40, num_updates=13700, lr=4.64303e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38054
2023-02-20 23:49:59 - progress_bar.py[line:274] - INFO: epoch 001:  13727 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.2, bsz=40, num_updates=13710, lr=4.64267e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10, ema_decay=0.9999, wall=38065
2023-02-20 23:50:10 - progress_bar.py[line:274] - INFO: epoch 001:  13737 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=110.9, bsz=40, num_updates=13720, lr=4.6423e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=38076
2023-02-20 23:50:21 - progress_bar.py[line:274] - INFO: epoch 001:  13747 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.8, bsz=40, num_updates=13730, lr=4.64194e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38087
2023-02-20 23:50:32 - progress_bar.py[line:274] - INFO: epoch 001:  13757 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.9, bsz=40, num_updates=13740, lr=4.64158e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38098
2023-02-20 23:50:43 - progress_bar.py[line:274] - INFO: epoch 001:  13767 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.87, wpb=112.3, bsz=40, num_updates=13750, lr=4.64122e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38110
2023-02-20 23:50:55 - progress_bar.py[line:274] - INFO: epoch 001:  13777 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.9, bsz=40, num_updates=13760, lr=4.64086e-05, gnorm=0.141, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38121
2023-02-20 23:51:06 - progress_bar.py[line:274] - INFO: epoch 001:  13787 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.4, bsz=40, num_updates=13770, lr=4.64049e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=38132
2023-02-20 23:51:17 - progress_bar.py[line:274] - INFO: epoch 001:  13797 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=113.1, bsz=40, num_updates=13780, lr=4.64013e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38143
2023-02-20 23:51:28 - progress_bar.py[line:274] - INFO: epoch 001:  13807 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=111.4, bsz=40, num_updates=13790, lr=4.63977e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38155
2023-02-20 23:51:39 - progress_bar.py[line:274] - INFO: epoch 001:  13817 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.92, wpb=111.8, bsz=40, num_updates=13800, lr=4.63941e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38165
2023-02-20 23:51:50 - progress_bar.py[line:274] - INFO: epoch 001:  13827 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=112.6, bsz=40, num_updates=13810, lr=4.63905e-05, gnorm=0.111, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38177
2023-02-20 23:52:01 - progress_bar.py[line:274] - INFO: epoch 001:  13837 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.92, wpb=112.5, bsz=40, num_updates=13820, lr=4.63869e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=38187
2023-02-20 23:52:12 - progress_bar.py[line:274] - INFO: epoch 001:  13847 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=112.1, bsz=40, num_updates=13830, lr=4.63832e-05, gnorm=0.101, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38198
2023-02-20 23:52:23 - progress_bar.py[line:274] - INFO: epoch 001:  13857 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.5, bsz=40, num_updates=13840, lr=4.63796e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38209
2023-02-20 23:52:34 - progress_bar.py[line:274] - INFO: epoch 001:  13867 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.6, bsz=40, num_updates=13850, lr=4.6376e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38220
2023-02-20 23:52:45 - progress_bar.py[line:274] - INFO: epoch 001:  13877 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.5, bsz=40, num_updates=13860, lr=4.63724e-05, gnorm=0.142, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38232
2023-02-20 23:52:57 - progress_bar.py[line:274] - INFO: epoch 001:  13887 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.5, bsz=40, num_updates=13870, lr=4.63688e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38243
2023-02-20 23:53:08 - progress_bar.py[line:274] - INFO: epoch 001:  13897 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111, bsz=40, num_updates=13880, lr=4.63651e-05, gnorm=0.111, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38254
2023-02-20 23:53:19 - progress_bar.py[line:274] - INFO: epoch 001:  13907 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.3, bsz=40, num_updates=13890, lr=4.63615e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=38265
2023-02-20 23:53:30 - progress_bar.py[line:274] - INFO: epoch 001:  13917 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.9, wpb=112.7, bsz=40, num_updates=13900, lr=4.63579e-05, gnorm=0.143, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38276
2023-02-20 23:53:41 - progress_bar.py[line:274] - INFO: epoch 001:  13927 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.3, bsz=40, num_updates=13910, lr=4.63543e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38288
2023-02-20 23:53:52 - progress_bar.py[line:274] - INFO: epoch 001:  13937 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.92, wpb=109.4, bsz=40, num_updates=13920, lr=4.63507e-05, gnorm=0.136, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38298
2023-02-20 23:54:03 - progress_bar.py[line:274] - INFO: epoch 001:  13947 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.5, bsz=40, num_updates=13930, lr=4.63471e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=38310
2023-02-20 23:54:14 - progress_bar.py[line:274] - INFO: epoch 001:  13957 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.3, bsz=40, num_updates=13940, lr=4.63434e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38321
2023-02-20 23:54:26 - progress_bar.py[line:274] - INFO: epoch 001:  13967 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.6, bsz=40, num_updates=13950, lr=4.63398e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=38332
2023-02-20 23:54:37 - progress_bar.py[line:274] - INFO: epoch 001:  13977 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.1, bsz=40, num_updates=13960, lr=4.63362e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38343
2023-02-20 23:54:48 - progress_bar.py[line:274] - INFO: epoch 001:  13987 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=113, bsz=40, num_updates=13970, lr=4.63326e-05, gnorm=0.101, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38354
2023-02-20 23:55:00 - progress_bar.py[line:274] - INFO: epoch 001:  13997 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.87, wpb=112.5, bsz=40, num_updates=13980, lr=4.6329e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38366
2023-02-20 23:55:11 - progress_bar.py[line:274] - INFO: epoch 001:  14007 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.5, bsz=40, num_updates=13990, lr=4.63253e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38377
2023-02-20 23:55:22 - progress_bar.py[line:274] - INFO: epoch 001:  14017 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.1, bsz=40, num_updates=14000, lr=4.63217e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38388
2023-02-20 23:55:22 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-20 23:55:23 - train.py[line:549] - INFO: 0 / 6234
2023-02-20 23:55:23 - train.py[line:551] - INFO: load:0.85 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-20 23:57:25 - train.py[line:549] - INFO: 200 / 6234
2023-02-20 23:57:25 - train.py[line:551] - INFO: load:0.87 valid_run:121.66 task_valid:118.85 collect_output:1.74
2023-02-20 23:59:24 - train.py[line:549] - INFO: 400 / 6234
2023-02-20 23:59:24 - train.py[line:551] - INFO: load:0.90 valid_run:240.93 task_valid:234.26 collect_output:4.56
2023-02-21 00:01:26 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 00:01:26 - train.py[line:551] - INFO: load:0.92 valid_run:362.30 task_valid:350.44 collect_output:8.71
2023-02-21 00:03:27 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 00:03:27 - train.py[line:551] - INFO: load:0.95 valid_run:483.60 task_valid:463.79 collect_output:15.62
2023-02-21 00:05:27 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 00:05:27 - train.py[line:551] - INFO: load:0.97 valid_run:603.57 task_valid:580.88 collect_output:17.48
2023-02-21 00:07:29 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 00:07:29 - train.py[line:551] - INFO: load:1.00 valid_run:725.76 task_valid:699.12 collect_output:20.40
2023-02-21 00:09:31 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 00:09:31 - train.py[line:551] - INFO: load:1.02 valid_run:848.00 task_valid:816.74 collect_output:23.99
2023-02-21 00:11:33 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 00:11:33 - train.py[line:551] - INFO: load:1.05 valid_run:969.28 task_valid:932.74 collect_output:28.25
2023-02-21 00:13:36 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 00:13:36 - train.py[line:551] - INFO: load:1.07 valid_run:1092.18 task_valid:1049.42 collect_output:33.44
2023-02-21 00:15:37 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 00:15:37 - train.py[line:551] - INFO: load:1.10 valid_run:1212.94 task_valid:1161.59 collect_output:40.99
2023-02-21 00:17:36 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 00:17:36 - train.py[line:551] - INFO: load:1.12 valid_run:1332.36 task_valid:1276.68 collect_output:44.30
2023-02-21 00:19:37 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 00:19:37 - train.py[line:551] - INFO: load:1.15 valid_run:1453.22 task_valid:1393.15 collect_output:47.66
2023-02-21 00:21:35 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 00:21:35 - train.py[line:551] - INFO: load:1.18 valid_run:1571.37 task_valid:1506.53 collect_output:51.41
2023-02-21 00:23:36 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 00:23:36 - train.py[line:551] - INFO: load:1.20 valid_run:1691.71 task_valid:1623.86 collect_output:53.39
2023-02-21 00:25:36 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 00:25:36 - train.py[line:551] - INFO: load:1.23 valid_run:1811.95 task_valid:1739.56 collect_output:56.90
2023-02-21 00:27:36 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 00:27:36 - train.py[line:551] - INFO: load:1.25 valid_run:1932.33 task_valid:1853.00 collect_output:62.82
2023-02-21 00:29:37 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 00:29:37 - train.py[line:551] - INFO: load:1.28 valid_run:2053.08 task_valid:1968.74 collect_output:66.82
2023-02-21 00:31:37 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 00:31:37 - train.py[line:551] - INFO: load:1.30 valid_run:2173.08 task_valid:2086.17 collect_output:68.37
2023-02-21 00:33:38 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 00:33:38 - train.py[line:551] - INFO: load:1.33 valid_run:2293.58 task_valid:2202.62 collect_output:71.41
2023-02-21 00:35:37 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 00:35:37 - train.py[line:551] - INFO: load:1.35 valid_run:2413.20 task_valid:2318.75 collect_output:73.88
2023-02-21 00:37:39 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 00:37:39 - train.py[line:551] - INFO: load:1.38 valid_run:2534.23 task_valid:2434.77 collect_output:77.87
2023-02-21 00:39:40 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 00:39:40 - train.py[line:551] - INFO: load:1.40 valid_run:2655.45 task_valid:2553.15 collect_output:79.70
2023-02-21 00:41:39 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 00:41:39 - train.py[line:551] - INFO: load:1.43 valid_run:2774.95 task_valid:2666.93 collect_output:84.41
2023-02-21 00:43:38 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 00:43:38 - train.py[line:551] - INFO: load:1.45 valid_run:2893.95 task_valid:2782.49 collect_output:86.83
2023-02-21 00:45:39 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 00:45:39 - train.py[line:551] - INFO: load:1.48 valid_run:3014.86 task_valid:2898.04 collect_output:91.17
2023-02-21 00:47:42 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 00:47:42 - train.py[line:551] - INFO: load:1.50 valid_run:3136.93 task_valid:3013.54 collect_output:96.72
2023-02-21 00:49:40 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 00:49:40 - train.py[line:551] - INFO: load:1.53 valid_run:3255.84 task_valid:3127.21 collect_output:100.93
2023-02-21 00:51:42 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 00:51:42 - train.py[line:551] - INFO: load:1.55 valid_run:3377.12 task_valid:3246.18 collect_output:102.22
2023-02-21 00:53:43 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 00:53:43 - train.py[line:551] - INFO: load:1.58 valid_run:3498.10 task_valid:3361.26 collect_output:107.10
2023-02-21 00:55:44 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 00:55:44 - train.py[line:551] - INFO: load:1.60 valid_run:3619.53 task_valid:3479.46 collect_output:109.31
2023-02-21 00:57:45 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 00:57:45 - train.py[line:551] - INFO: load:1.63 valid_run:3740.14 task_valid:3597.62 collect_output:110.74

====================================================================================================
SGG eval:     R @ 50: 0.6323;     R @ 100: 0.6676;     R @ 500: 0.6900;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3828;    mR @ 100: 0.4289;    mR @ 500: 0.5068;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8659) (covered in:0.6250) (covering:0.3000) (eating:0.7647) (flying in:0.1818) (growing on:0.3750) (hanging from:0.4516) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9771) (says:0.0000) (sitting on:0.7245) (standing on:0.3593) (using:0.6000) (walking in:0.0000) (walking on:0.7568) (watching:0.3542) 
--------------------------------------------------------
====================================================================================================

2023-02-21 00:58:16 - train.py[line:487] - INFO: 0.667642118665648

====================================================================================================
SGG eval:     R @ 50: 0.6323;     R @ 100: 0.6676;     R @ 500: 0.6900;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3828;    mR @ 100: 0.4289;    mR @ 500: 0.5068;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8659) (covered in:0.6250) (covering:0.3000) (eating:0.7647) (flying in:0.1818) (growing on:0.3750) (hanging from:0.4516) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9771) (says:0.0000) (sitting on:0.7245) (standing on:0.3593) (using:0.6000) (walking in:0.0000) (walking on:0.7568) (watching:0.3542) 
--------------------------------------------------------
====================================================================================================

2023-02-21 00:58:16 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 00:58:16 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.236 | loss_v1 0 | loss_v2 0 | nll_loss 0.068 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.667642 | ppl 1.05 | vqa_score 0.4775 | wps 118.9 | wpb 72 | bsz 24 | num_updates 14000 | best_R@100 0.691462
2023-02-21 00:58:16 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 14000 updates
2023-02-21 00:58:16 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_14000.pt
2023-02-21 00:58:22 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_14000.pt
2023-02-21 00:58:25 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_14000.pt (epoch 1 @ 14000 updates, score 0.667642118665648) (writing took 8.962652606889606 seconds)
2023-02-21 00:58:36 - progress_bar.py[line:274] - INFO: epoch 001:  14027 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=111.7, bsz=40, num_updates=14010, lr=4.63181e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42183
2023-02-21 00:58:47 - progress_bar.py[line:274] - INFO: epoch 001:  14037 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.91, wpb=113.1, bsz=40, num_updates=14020, lr=4.63145e-05, gnorm=0.105, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42194
2023-02-21 00:58:58 - progress_bar.py[line:274] - INFO: epoch 001:  14047 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=109.9, bsz=40, num_updates=14030, lr=4.63109e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42205
2023-02-21 00:59:02 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 00:59:10 - progress_bar.py[line:274] - INFO: epoch 001:  14058 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.8, ups=0.83, wpb=111.5, bsz=40, num_updates=14040, lr=4.63073e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=42217
2023-02-21 00:59:22 - progress_bar.py[line:274] - INFO: epoch 001:  14068 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111.8, bsz=40, num_updates=14050, lr=4.63036e-05, gnorm=0.165, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42228
2023-02-21 00:59:33 - progress_bar.py[line:274] - INFO: epoch 001:  14078 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.6, ups=0.93, wpb=112.3, bsz=40, num_updates=14060, lr=4.63e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42239
2023-02-21 00:59:44 - progress_bar.py[line:274] - INFO: epoch 001:  14088 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.87, wpb=112.7, bsz=40, num_updates=14070, lr=4.62964e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42250
2023-02-21 00:59:55 - progress_bar.py[line:274] - INFO: epoch 001:  14098 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.1, bsz=40, num_updates=14080, lr=4.62928e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42261
2023-02-21 01:00:06 - progress_bar.py[line:274] - INFO: epoch 001:  14108 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.6, bsz=40, num_updates=14090, lr=4.62892e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42273
2023-02-21 01:00:17 - progress_bar.py[line:274] - INFO: epoch 001:  14118 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=100.7, ups=0.9, wpb=112.2, bsz=40, num_updates=14100, lr=4.62855e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42284
2023-02-21 01:00:28 - progress_bar.py[line:274] - INFO: epoch 001:  14128 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.8, bsz=40, num_updates=14110, lr=4.62819e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42295
2023-02-21 01:00:39 - progress_bar.py[line:274] - INFO: epoch 001:  14138 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=112, bsz=40, num_updates=14120, lr=4.62783e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42306
2023-02-21 01:00:50 - progress_bar.py[line:274] - INFO: epoch 001:  14148 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.91, wpb=112.8, bsz=40, num_updates=14130, lr=4.62747e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=42317
2023-02-21 01:01:01 - progress_bar.py[line:274] - INFO: epoch 001:  14158 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=110.7, bsz=40, num_updates=14140, lr=4.62711e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42327
2023-02-21 01:01:12 - progress_bar.py[line:274] - INFO: epoch 001:  14168 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.93, wpb=111.6, bsz=40, num_updates=14150, lr=4.62675e-05, gnorm=0.061, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42338
2023-02-21 01:01:23 - progress_bar.py[line:274] - INFO: epoch 001:  14178 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.9, bsz=40, num_updates=14160, lr=4.62638e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42349
2023-02-21 01:01:34 - progress_bar.py[line:274] - INFO: epoch 001:  14188 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.91, wpb=111.7, bsz=40, num_updates=14170, lr=4.62602e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42360
2023-02-21 01:01:45 - progress_bar.py[line:274] - INFO: epoch 001:  14198 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.91, wpb=112.9, bsz=40, num_updates=14180, lr=4.62566e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42371
2023-02-21 01:01:56 - progress_bar.py[line:274] - INFO: epoch 001:  14208 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=112, bsz=40, num_updates=14190, lr=4.6253e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42383
2023-02-21 01:02:07 - progress_bar.py[line:274] - INFO: epoch 001:  14218 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.1, bsz=40, num_updates=14200, lr=4.62494e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42394
2023-02-21 01:02:19 - progress_bar.py[line:274] - INFO: epoch 001:  14228 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.86, wpb=112.7, bsz=40, num_updates=14210, lr=4.62457e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=42405
2023-02-21 01:02:30 - progress_bar.py[line:274] - INFO: epoch 001:  14238 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.89, wpb=111.9, bsz=40, num_updates=14220, lr=4.62421e-05, gnorm=0.159, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42416
2023-02-21 01:02:41 - progress_bar.py[line:274] - INFO: epoch 001:  14248 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.92, wpb=112, bsz=40, num_updates=14230, lr=4.62385e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42427
2023-02-21 01:02:52 - progress_bar.py[line:274] - INFO: epoch 001:  14258 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.9, ups=0.91, wpb=112, bsz=40, num_updates=14240, lr=4.62349e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42438
2023-02-21 01:03:03 - progress_bar.py[line:274] - INFO: epoch 001:  14268 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.4, bsz=40, num_updates=14250, lr=4.62313e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42449
2023-02-21 01:03:15 - progress_bar.py[line:274] - INFO: epoch 001:  14278 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.86, wpb=113, bsz=40, num_updates=14260, lr=4.62277e-05, gnorm=0.058, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=42461
2023-02-21 01:03:25 - progress_bar.py[line:274] - INFO: epoch 001:  14288 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.93, wpb=112.1, bsz=40, num_updates=14270, lr=4.6224e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42472
2023-02-21 01:03:37 - progress_bar.py[line:274] - INFO: epoch 001:  14298 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.3, bsz=40, num_updates=14280, lr=4.62204e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42483
2023-02-21 01:03:48 - progress_bar.py[line:274] - INFO: epoch 001:  14308 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113.5, nsentences=40, sample_size=113.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.91, wpb=113.5, bsz=40, num_updates=14290, lr=4.62168e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42494
2023-02-21 01:03:59 - progress_bar.py[line:274] - INFO: epoch 001:  14318 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.1, ups=0.89, wpb=109.7, bsz=40, num_updates=14300, lr=4.62132e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42505
2023-02-21 01:04:10 - progress_bar.py[line:274] - INFO: epoch 001:  14328 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.8, bsz=40, num_updates=14310, lr=4.62096e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42517
2023-02-21 01:04:21 - progress_bar.py[line:274] - INFO: epoch 001:  14338 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.6, bsz=40, num_updates=14320, lr=4.62059e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42527
2023-02-21 01:04:32 - progress_bar.py[line:274] - INFO: epoch 001:  14348 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.3, ups=0.93, wpb=111.8, bsz=40, num_updates=14330, lr=4.62023e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42538
2023-02-21 01:04:43 - progress_bar.py[line:274] - INFO: epoch 001:  14358 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=111.9, bsz=40, num_updates=14340, lr=4.61987e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42550
2023-02-21 01:04:55 - progress_bar.py[line:274] - INFO: epoch 001:  14368 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=111, bsz=40, num_updates=14350, lr=4.61951e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42561
2023-02-21 01:05:06 - progress_bar.py[line:274] - INFO: epoch 001:  14378 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=14360, lr=4.61915e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42572
2023-02-21 01:05:17 - progress_bar.py[line:274] - INFO: epoch 001:  14388 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.94, wpb=111.5, bsz=40, num_updates=14370, lr=4.61879e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42583
2023-02-21 01:05:28 - progress_bar.py[line:274] - INFO: epoch 001:  14398 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.4, bsz=40, num_updates=14380, lr=4.61842e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42594
2023-02-21 01:05:39 - progress_bar.py[line:274] - INFO: epoch 001:  14408 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=112.9, bsz=40, num_updates=14390, lr=4.61806e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42605
2023-02-21 01:05:50 - progress_bar.py[line:274] - INFO: epoch 001:  14418 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.4, bsz=40, num_updates=14400, lr=4.6177e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=42616
2023-02-21 01:06:01 - progress_bar.py[line:274] - INFO: epoch 001:  14428 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.1, bsz=40, num_updates=14410, lr=4.61734e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42627
2023-02-21 01:06:12 - progress_bar.py[line:274] - INFO: epoch 001:  14438 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.9, bsz=40, num_updates=14420, lr=4.61698e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42638
2023-02-21 01:06:23 - progress_bar.py[line:274] - INFO: epoch 001:  14448 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112, bsz=40, num_updates=14430, lr=4.61661e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42649
2023-02-21 01:06:34 - progress_bar.py[line:274] - INFO: epoch 001:  14458 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.5, bsz=40, num_updates=14440, lr=4.61625e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42661
2023-02-21 01:06:45 - progress_bar.py[line:274] - INFO: epoch 001:  14468 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.6, bsz=40, num_updates=14450, lr=4.61589e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42672
2023-02-21 01:06:56 - progress_bar.py[line:274] - INFO: epoch 001:  14478 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=14460, lr=4.61553e-05, gnorm=0.154, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42683
2023-02-21 01:07:08 - progress_bar.py[line:274] - INFO: epoch 001:  14488 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.88, wpb=110.5, bsz=40, num_updates=14470, lr=4.61517e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42694
2023-02-21 01:07:19 - progress_bar.py[line:274] - INFO: epoch 001:  14498 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.3, bsz=40, num_updates=14480, lr=4.61481e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42705
2023-02-21 01:07:30 - progress_bar.py[line:274] - INFO: epoch 001:  14508 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.4, ups=0.91, wpb=111.8, bsz=40, num_updates=14490, lr=4.61444e-05, gnorm=0.169, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42716
2023-02-21 01:07:41 - progress_bar.py[line:274] - INFO: epoch 001:  14518 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.9, wpb=110.1, bsz=40, num_updates=14500, lr=4.61408e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42728
2023-02-21 01:07:52 - progress_bar.py[line:274] - INFO: epoch 001:  14528 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111, bsz=40, num_updates=14510, lr=4.61372e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42739
2023-02-21 01:08:03 - progress_bar.py[line:274] - INFO: epoch 001:  14538 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.4, bsz=40, num_updates=14520, lr=4.61336e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42750
2023-02-21 01:08:14 - progress_bar.py[line:274] - INFO: epoch 001:  14548 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.2, bsz=40, num_updates=14530, lr=4.613e-05, gnorm=0.145, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42761
2023-02-21 01:08:26 - progress_bar.py[line:274] - INFO: epoch 001:  14558 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.2, bsz=40, num_updates=14540, lr=4.61263e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42772
2023-02-21 01:08:37 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 01:08:38 - progress_bar.py[line:274] - INFO: epoch 001:  14569 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91, ups=0.82, wpb=110.6, bsz=40, num_updates=14550, lr=4.61227e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=42784
2023-02-21 01:08:49 - progress_bar.py[line:274] - INFO: epoch 001:  14579 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.3, bsz=40, num_updates=14560, lr=4.61191e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42795
2023-02-21 01:09:00 - progress_bar.py[line:274] - INFO: epoch 001:  14589 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.5, bsz=40, num_updates=14570, lr=4.61155e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42806
2023-02-21 01:09:11 - progress_bar.py[line:274] - INFO: epoch 001:  14599 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.87, wpb=112.2, bsz=40, num_updates=14580, lr=4.61119e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42817
2023-02-21 01:09:22 - progress_bar.py[line:274] - INFO: epoch 001:  14609 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.91, wpb=112.8, bsz=40, num_updates=14590, lr=4.61083e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42828
2023-02-21 01:09:33 - progress_bar.py[line:274] - INFO: epoch 001:  14619 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=14600, lr=4.61046e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42840
2023-02-21 01:09:44 - progress_bar.py[line:274] - INFO: epoch 001:  14629 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.7, bsz=40, num_updates=14610, lr=4.6101e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42851
2023-02-21 01:09:55 - progress_bar.py[line:274] - INFO: epoch 001:  14639 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.4, bsz=40, num_updates=14620, lr=4.60974e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42862
2023-02-21 01:10:06 - progress_bar.py[line:274] - INFO: epoch 001:  14649 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.2, bsz=40, num_updates=14630, lr=4.60938e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42873
2023-02-21 01:10:17 - progress_bar.py[line:274] - INFO: epoch 001:  14659 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.4, bsz=40, num_updates=14640, lr=4.60902e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42884
2023-02-21 01:10:28 - progress_bar.py[line:274] - INFO: epoch 001:  14669 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.2, ups=0.92, wpb=113.2, bsz=40, num_updates=14650, lr=4.60865e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42895
2023-02-21 01:10:40 - progress_bar.py[line:274] - INFO: epoch 001:  14679 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.88, wpb=109.7, bsz=40, num_updates=14660, lr=4.60829e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42906
2023-02-21 01:10:50 - progress_bar.py[line:274] - INFO: epoch 001:  14689 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.7, ups=0.94, wpb=111.9, bsz=40, num_updates=14670, lr=4.60793e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42917
2023-02-21 01:11:01 - progress_bar.py[line:274] - INFO: epoch 001:  14699 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111, bsz=40, num_updates=14680, lr=4.60757e-05, gnorm=0.156, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42928
2023-02-21 01:11:12 - progress_bar.py[line:274] - INFO: epoch 001:  14709 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.8, ups=0.93, wpb=113.2, bsz=40, num_updates=14690, lr=4.60721e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42939
2023-02-21 01:11:23 - progress_bar.py[line:274] - INFO: epoch 001:  14719 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.9, wpb=112.6, bsz=40, num_updates=14700, lr=4.60685e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42950
2023-02-21 01:11:34 - progress_bar.py[line:274] - INFO: epoch 001:  14729 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111, bsz=40, num_updates=14710, lr=4.60648e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42961
2023-02-21 01:11:45 - progress_bar.py[line:274] - INFO: epoch 001:  14739 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.5, bsz=40, num_updates=14720, lr=4.60612e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42972
2023-02-21 01:11:56 - progress_bar.py[line:274] - INFO: epoch 001:  14749 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.1, bsz=40, num_updates=14730, lr=4.60576e-05, gnorm=0.072, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42983
2023-02-21 01:12:07 - progress_bar.py[line:274] - INFO: epoch 001:  14759 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111, bsz=40, num_updates=14740, lr=4.6054e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=42994
2023-02-21 01:12:18 - progress_bar.py[line:274] - INFO: epoch 001:  14769 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.9, wpb=113.3, bsz=40, num_updates=14750, lr=4.60504e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43005
2023-02-21 01:12:30 - progress_bar.py[line:274] - INFO: epoch 001:  14779 / 71012 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.6, bsz=40, num_updates=14760, lr=4.60467e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43016
2023-02-21 01:12:40 - progress_bar.py[line:274] - INFO: epoch 001:  14789 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.93, wpb=111.9, bsz=40, num_updates=14770, lr=4.60431e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43027
2023-02-21 01:12:51 - progress_bar.py[line:274] - INFO: epoch 001:  14799 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.6, bsz=40, num_updates=14780, lr=4.60395e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43038
2023-02-21 01:13:03 - progress_bar.py[line:274] - INFO: epoch 001:  14809 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=111.7, bsz=40, num_updates=14790, lr=4.60359e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=43049
2023-02-21 01:13:14 - progress_bar.py[line:274] - INFO: epoch 001:  14819 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.5, bsz=40, num_updates=14800, lr=4.60323e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43060
2023-02-21 01:13:25 - progress_bar.py[line:274] - INFO: epoch 001:  14829 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.6, bsz=40, num_updates=14810, lr=4.60287e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=43072
2023-02-21 01:13:36 - progress_bar.py[line:274] - INFO: epoch 001:  14839 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.1, bsz=40, num_updates=14820, lr=4.6025e-05, gnorm=0.07, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43083
2023-02-21 01:13:47 - progress_bar.py[line:274] - INFO: epoch 001:  14849 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.1, bsz=40, num_updates=14830, lr=4.60214e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43094
2023-02-21 01:13:58 - progress_bar.py[line:274] - INFO: epoch 001:  14859 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.9, wpb=110.2, bsz=40, num_updates=14840, lr=4.60178e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43105
2023-02-21 01:14:09 - progress_bar.py[line:274] - INFO: epoch 001:  14869 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.7, bsz=40, num_updates=14850, lr=4.60142e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43116
2023-02-21 01:14:20 - progress_bar.py[line:274] - INFO: epoch 001:  14879 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.9, wpb=109.8, bsz=40, num_updates=14860, lr=4.60106e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43127
2023-02-21 01:14:31 - progress_bar.py[line:274] - INFO: epoch 001:  14889 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.1, bsz=40, num_updates=14870, lr=4.60069e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43138
2023-02-21 01:14:43 - progress_bar.py[line:274] - INFO: epoch 001:  14899 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.9, wpb=109.3, bsz=40, num_updates=14880, lr=4.60033e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43149
2023-02-21 01:14:53 - progress_bar.py[line:274] - INFO: epoch 001:  14909 / 71012 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.92, wpb=109.9, bsz=40, num_updates=14890, lr=4.59997e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43160
2023-02-21 01:15:05 - progress_bar.py[line:274] - INFO: epoch 001:  14919 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.7, bsz=40, num_updates=14900, lr=4.59961e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43171
2023-02-21 01:15:15 - progress_bar.py[line:274] - INFO: epoch 001:  14929 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110.7, bsz=40, num_updates=14910, lr=4.59925e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43182
2023-02-21 01:15:27 - progress_bar.py[line:274] - INFO: epoch 001:  14939 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.5, bsz=40, num_updates=14920, lr=4.59889e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43193
2023-02-21 01:15:38 - progress_bar.py[line:274] - INFO: epoch 001:  14949 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.87, wpb=111.8, bsz=40, num_updates=14930, lr=4.59852e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43204
2023-02-21 01:15:49 - progress_bar.py[line:274] - INFO: epoch 001:  14959 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.7, ups=0.93, wpb=112.4, bsz=40, num_updates=14940, lr=4.59816e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43215
2023-02-21 01:16:00 - progress_bar.py[line:274] - INFO: epoch 001:  14969 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.4, bsz=40, num_updates=14950, lr=4.5978e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43226
2023-02-21 01:16:11 - progress_bar.py[line:274] - INFO: epoch 001:  14979 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112.5, bsz=40, num_updates=14960, lr=4.59744e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43237
2023-02-21 01:16:22 - progress_bar.py[line:274] - INFO: epoch 001:  14989 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.6, bsz=40, num_updates=14970, lr=4.59708e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43248
2023-02-21 01:16:33 - progress_bar.py[line:274] - INFO: epoch 001:  14999 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=113.1, bsz=40, num_updates=14980, lr=4.59671e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43260
2023-02-21 01:16:44 - progress_bar.py[line:274] - INFO: epoch 001:  15009 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.4, bsz=40, num_updates=14990, lr=4.59635e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43271
2023-02-21 01:16:55 - progress_bar.py[line:274] - INFO: epoch 001:  15019 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.9, wpb=113.1, bsz=40, num_updates=15000, lr=4.59599e-05, gnorm=0.052, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43282
2023-02-21 01:17:06 - progress_bar.py[line:274] - INFO: epoch 001:  15029 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112.3, bsz=40, num_updates=15010, lr=4.59563e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43293
2023-02-21 01:17:17 - progress_bar.py[line:274] - INFO: epoch 001:  15039 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.4, bsz=40, num_updates=15020, lr=4.59527e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43304
2023-02-21 01:17:28 - progress_bar.py[line:274] - INFO: epoch 001:  15049 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.9, ups=0.95, wpb=112.6, bsz=40, num_updates=15030, lr=4.59491e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=10, gb_free=10.5, ema_decay=0.9999, wall=43314
2023-02-21 01:17:39 - progress_bar.py[line:274] - INFO: epoch 001:  15059 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.9, wpb=113.3, bsz=40, num_updates=15040, lr=4.59454e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43325
2023-02-21 01:17:50 - progress_bar.py[line:274] - INFO: epoch 001:  15069 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.6, bsz=40, num_updates=15050, lr=4.59418e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43337
2023-02-21 01:18:01 - progress_bar.py[line:274] - INFO: epoch 001:  15079 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.2, bsz=40, num_updates=15060, lr=4.59382e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43348
2023-02-21 01:18:13 - progress_bar.py[line:274] - INFO: epoch 001:  15089 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.86, wpb=111.3, bsz=40, num_updates=15070, lr=4.59346e-05, gnorm=0.139, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=43359
2023-02-21 01:18:24 - progress_bar.py[line:274] - INFO: epoch 001:  15099 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.7, bsz=40, num_updates=15080, lr=4.5931e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43370
2023-02-21 01:18:35 - progress_bar.py[line:274] - INFO: epoch 001:  15109 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.8, ups=0.94, wpb=110.6, bsz=40, num_updates=15090, lr=4.59273e-05, gnorm=0.128, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43381
2023-02-21 01:18:46 - progress_bar.py[line:274] - INFO: epoch 001:  15119 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.5, bsz=40, num_updates=15100, lr=4.59237e-05, gnorm=0.12, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43392
2023-02-21 01:18:56 - progress_bar.py[line:274] - INFO: epoch 001:  15129 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.92, wpb=110.7, bsz=40, num_updates=15110, lr=4.59201e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43403
2023-02-21 01:19:07 - progress_bar.py[line:274] - INFO: epoch 001:  15139 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.9, bsz=40, num_updates=15120, lr=4.59165e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43414
2023-02-21 01:19:18 - progress_bar.py[line:274] - INFO: epoch 001:  15149 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110.5, bsz=40, num_updates=15130, lr=4.59129e-05, gnorm=0.114, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43425
2023-02-21 01:19:29 - progress_bar.py[line:274] - INFO: epoch 001:  15159 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=112.3, bsz=40, num_updates=15140, lr=4.59093e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43436
2023-02-21 01:19:40 - progress_bar.py[line:274] - INFO: epoch 001:  15169 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.8, bsz=40, num_updates=15150, lr=4.59056e-05, gnorm=0.139, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43447
2023-02-21 01:19:51 - progress_bar.py[line:274] - INFO: epoch 001:  15179 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.92, wpb=109.7, bsz=40, num_updates=15160, lr=4.5902e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43458
2023-02-21 01:20:02 - progress_bar.py[line:274] - INFO: epoch 001:  15189 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=112, bsz=40, num_updates=15170, lr=4.58984e-05, gnorm=0.129, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43469
2023-02-21 01:20:13 - progress_bar.py[line:274] - INFO: epoch 001:  15199 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=110.6, bsz=40, num_updates=15180, lr=4.58948e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43480
2023-02-21 01:20:24 - progress_bar.py[line:274] - INFO: epoch 001:  15209 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.4, ups=0.9, wpb=112.6, bsz=40, num_updates=15190, lr=4.58912e-05, gnorm=0.124, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43491
2023-02-21 01:20:35 - progress_bar.py[line:274] - INFO: epoch 001:  15219 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.1, ups=0.94, wpb=112, bsz=40, num_updates=15200, lr=4.58875e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43501
2023-02-21 01:20:46 - progress_bar.py[line:274] - INFO: epoch 001:  15229 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.4, bsz=40, num_updates=15210, lr=4.58839e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=43513
2023-02-21 01:20:57 - progress_bar.py[line:274] - INFO: epoch 001:  15239 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.91, wpb=112.6, bsz=40, num_updates=15220, lr=4.58803e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43524
2023-02-21 01:21:08 - progress_bar.py[line:274] - INFO: epoch 001:  15249 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.93, wpb=111.1, bsz=40, num_updates=15230, lr=4.58767e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43534
2023-02-21 01:21:19 - progress_bar.py[line:274] - INFO: epoch 001:  15259 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=112.2, bsz=40, num_updates=15240, lr=4.58731e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43546
2023-02-21 01:21:30 - progress_bar.py[line:274] - INFO: epoch 001:  15269 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.5, bsz=40, num_updates=15250, lr=4.58695e-05, gnorm=0.125, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43557
2023-02-21 01:21:42 - progress_bar.py[line:274] - INFO: epoch 001:  15279 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.2, bsz=40, num_updates=15260, lr=4.58658e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43568
2023-02-21 01:21:53 - progress_bar.py[line:274] - INFO: epoch 001:  15289 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111, bsz=40, num_updates=15270, lr=4.58622e-05, gnorm=0.155, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=43579
2023-02-21 01:22:04 - progress_bar.py[line:274] - INFO: epoch 001:  15299 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=15280, lr=4.58586e-05, gnorm=0.12, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43591
2023-02-21 01:22:15 - progress_bar.py[line:274] - INFO: epoch 001:  15309 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.1, ups=0.94, wpb=111.3, bsz=40, num_updates=15290, lr=4.5855e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=43601
2023-02-21 01:22:26 - progress_bar.py[line:274] - INFO: epoch 001:  15319 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.7, bsz=40, num_updates=15300, lr=4.58514e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43612
2023-02-21 01:22:37 - progress_bar.py[line:274] - INFO: epoch 001:  15329 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.87, wpb=112.3, bsz=40, num_updates=15310, lr=4.58477e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43623
2023-02-21 01:22:48 - progress_bar.py[line:274] - INFO: epoch 001:  15339 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.9, bsz=40, num_updates=15320, lr=4.58441e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43635
2023-02-21 01:22:59 - progress_bar.py[line:274] - INFO: epoch 001:  15349 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.3, bsz=40, num_updates=15330, lr=4.58405e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43645
2023-02-21 01:23:10 - progress_bar.py[line:274] - INFO: epoch 001:  15359 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=15340, lr=4.58369e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43657
2023-02-21 01:23:21 - progress_bar.py[line:274] - INFO: epoch 001:  15369 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.3, bsz=40, num_updates=15350, lr=4.58333e-05, gnorm=0.119, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43668
2023-02-21 01:23:32 - progress_bar.py[line:274] - INFO: epoch 001:  15379 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.4, bsz=40, num_updates=15360, lr=4.58297e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43679
2023-02-21 01:23:44 - progress_bar.py[line:274] - INFO: epoch 001:  15389 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.5, bsz=40, num_updates=15370, lr=4.5826e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=43690
2023-02-21 01:23:55 - progress_bar.py[line:274] - INFO: epoch 001:  15399 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.9, bsz=40, num_updates=15380, lr=4.58224e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43701
2023-02-21 01:24:06 - progress_bar.py[line:274] - INFO: epoch 001:  15409 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=15390, lr=4.58188e-05, gnorm=0.101, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43712
2023-02-21 01:24:17 - progress_bar.py[line:274] - INFO: epoch 001:  15419 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=15400, lr=4.58152e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43724
2023-02-21 01:24:28 - progress_bar.py[line:274] - INFO: epoch 001:  15429 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.9, ups=0.95, wpb=111.8, bsz=40, num_updates=15410, lr=4.58116e-05, gnorm=0.122, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43734
2023-02-21 01:24:39 - progress_bar.py[line:274] - INFO: epoch 001:  15439 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.5, bsz=40, num_updates=15420, lr=4.58079e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43745
2023-02-21 01:24:50 - progress_bar.py[line:274] - INFO: epoch 001:  15449 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.5, bsz=40, num_updates=15430, lr=4.58043e-05, gnorm=0.113, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43756
2023-02-21 01:25:01 - progress_bar.py[line:274] - INFO: epoch 001:  15459 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.9, bsz=40, num_updates=15440, lr=4.58007e-05, gnorm=0.132, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43768
2023-02-21 01:25:13 - progress_bar.py[line:274] - INFO: epoch 001:  15469 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112.3, bsz=40, num_updates=15450, lr=4.57971e-05, gnorm=0.111, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43779
2023-02-21 01:25:24 - progress_bar.py[line:274] - INFO: epoch 001:  15479 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=99.8, ups=0.9, wpb=111.5, bsz=40, num_updates=15460, lr=4.57935e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=43790
2023-02-21 01:25:35 - progress_bar.py[line:274] - INFO: epoch 001:  15489 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.91, wpb=113.2, bsz=40, num_updates=15470, lr=4.57899e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10, ema_decay=0.9999, wall=43801
2023-02-21 01:25:46 - progress_bar.py[line:274] - INFO: epoch 001:  15499 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.5, bsz=40, num_updates=15480, lr=4.57862e-05, gnorm=0.156, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43812
2023-02-21 01:25:57 - progress_bar.py[line:274] - INFO: epoch 001:  15509 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=111.5, bsz=40, num_updates=15490, lr=4.57826e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43823
2023-02-21 01:26:08 - progress_bar.py[line:274] - INFO: epoch 001:  15519 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.3, ups=0.91, wpb=111.2, bsz=40, num_updates=15500, lr=4.5779e-05, gnorm=0.136, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43834
2023-02-21 01:26:19 - progress_bar.py[line:274] - INFO: epoch 001:  15529 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.9, bsz=40, num_updates=15510, lr=4.57754e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43845
2023-02-21 01:26:30 - progress_bar.py[line:274] - INFO: epoch 001:  15539 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.88, wpb=112.6, bsz=40, num_updates=15520, lr=4.57718e-05, gnorm=0.169, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43856
2023-02-21 01:26:41 - progress_bar.py[line:274] - INFO: epoch 001:  15549 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.9, bsz=40, num_updates=15530, lr=4.57681e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43867
2023-02-21 01:26:48 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 01:26:53 - progress_bar.py[line:274] - INFO: epoch 001:  15560 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.7, ups=0.81, wpb=110.6, bsz=40, num_updates=15540, lr=4.57645e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=43880
2023-02-21 01:27:05 - progress_bar.py[line:274] - INFO: epoch 001:  15570 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.87, wpb=112.6, bsz=40, num_updates=15550, lr=4.57609e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43891
2023-02-21 01:27:16 - progress_bar.py[line:274] - INFO: epoch 001:  15580 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=97.9, ups=0.87, wpb=112.1, bsz=40, num_updates=15560, lr=4.57573e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43903
2023-02-21 01:27:27 - progress_bar.py[line:274] - INFO: epoch 001:  15590 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.9, wpb=109.9, bsz=40, num_updates=15570, lr=4.57537e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43914
2023-02-21 01:27:39 - progress_bar.py[line:274] - INFO: epoch 001:  15600 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.8, bsz=40, num_updates=15580, lr=4.57501e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43925
2023-02-21 01:27:50 - progress_bar.py[line:274] - INFO: epoch 001:  15610 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=110.7, bsz=40, num_updates=15590, lr=4.57464e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43936
2023-02-21 01:28:01 - progress_bar.py[line:274] - INFO: epoch 001:  15620 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=112.2, bsz=40, num_updates=15600, lr=4.57428e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43947
2023-02-21 01:28:12 - progress_bar.py[line:274] - INFO: epoch 001:  15630 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.92, wpb=110.6, bsz=40, num_updates=15610, lr=4.57392e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43958
2023-02-21 01:28:23 - progress_bar.py[line:274] - INFO: epoch 001:  15640 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.2, bsz=40, num_updates=15620, lr=4.57356e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43970
2023-02-21 01:28:34 - progress_bar.py[line:274] - INFO: epoch 001:  15650 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.9, wpb=113.1, bsz=40, num_updates=15630, lr=4.5732e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43981
2023-02-21 01:28:45 - progress_bar.py[line:274] - INFO: epoch 001:  15660 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.4, bsz=40, num_updates=15640, lr=4.57283e-05, gnorm=0.162, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43992
2023-02-21 01:28:56 - progress_bar.py[line:274] - INFO: epoch 001:  15670 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.95, wpb=110.4, bsz=40, num_updates=15650, lr=4.57247e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44002
2023-02-21 01:29:07 - progress_bar.py[line:274] - INFO: epoch 001:  15680 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.1, bsz=40, num_updates=15660, lr=4.57211e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=44014
2023-02-21 01:29:19 - progress_bar.py[line:274] - INFO: epoch 001:  15690 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=110.5, bsz=40, num_updates=15670, lr=4.57175e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=44025
2023-02-21 01:29:30 - progress_bar.py[line:274] - INFO: epoch 001:  15700 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.5, bsz=40, num_updates=15680, lr=4.57139e-05, gnorm=0.132, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44036
2023-02-21 01:29:41 - progress_bar.py[line:274] - INFO: epoch 001:  15710 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.4, bsz=40, num_updates=15690, lr=4.57103e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44048
2023-02-21 01:29:52 - progress_bar.py[line:274] - INFO: epoch 001:  15720 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.3, bsz=40, num_updates=15700, lr=4.57066e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44059
2023-02-21 01:30:04 - progress_bar.py[line:274] - INFO: epoch 001:  15730 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=111.6, bsz=40, num_updates=15710, lr=4.5703e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44070
2023-02-21 01:30:15 - progress_bar.py[line:274] - INFO: epoch 001:  15740 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112, bsz=40, num_updates=15720, lr=4.56994e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44082
2023-02-21 01:30:27 - progress_bar.py[line:274] - INFO: epoch 001:  15750 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=110.6, bsz=40, num_updates=15730, lr=4.56958e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44093
2023-02-21 01:30:38 - progress_bar.py[line:274] - INFO: epoch 001:  15760 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.2, bsz=40, num_updates=15740, lr=4.56922e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44104
2023-02-21 01:30:49 - progress_bar.py[line:274] - INFO: epoch 001:  15770 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.6, bsz=40, num_updates=15750, lr=4.56885e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44115
2023-02-21 01:30:59 - progress_bar.py[line:274] - INFO: epoch 001:  15780 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.7, ups=0.94, wpb=111.9, bsz=40, num_updates=15760, lr=4.56849e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44126
2023-02-21 01:31:11 - progress_bar.py[line:274] - INFO: epoch 001:  15790 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.89, wpb=109.9, bsz=40, num_updates=15770, lr=4.56813e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44137
2023-02-21 01:31:22 - progress_bar.py[line:274] - INFO: epoch 001:  15800 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110.6, bsz=40, num_updates=15780, lr=4.56777e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44148
2023-02-21 01:31:33 - progress_bar.py[line:274] - INFO: epoch 001:  15810 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.91, wpb=112.9, bsz=40, num_updates=15790, lr=4.56741e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44159
2023-02-21 01:31:44 - progress_bar.py[line:274] - INFO: epoch 001:  15820 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.8, bsz=40, num_updates=15800, lr=4.56705e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44171
2023-02-21 01:31:56 - progress_bar.py[line:274] - INFO: epoch 001:  15830 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.2, bsz=40, num_updates=15810, lr=4.56668e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44182
2023-02-21 01:32:07 - progress_bar.py[line:274] - INFO: epoch 001:  15840 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.92, wpb=112.5, bsz=40, num_updates=15820, lr=4.56632e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44193
2023-02-21 01:32:18 - progress_bar.py[line:274] - INFO: epoch 001:  15850 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.6, bsz=40, num_updates=15830, lr=4.56596e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44204
2023-02-21 01:32:28 - progress_bar.py[line:274] - INFO: epoch 001:  15860 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.4, ups=0.95, wpb=112.5, bsz=40, num_updates=15840, lr=4.5656e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44215
2023-02-21 01:32:39 - progress_bar.py[line:274] - INFO: epoch 001:  15870 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111, bsz=40, num_updates=15850, lr=4.56524e-05, gnorm=0.057, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44226
2023-02-21 01:32:50 - progress_bar.py[line:274] - INFO: epoch 001:  15880 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.6, bsz=40, num_updates=15860, lr=4.56487e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44237
2023-02-21 01:33:02 - progress_bar.py[line:274] - INFO: epoch 001:  15890 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=15870, lr=4.56451e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44248
2023-02-21 01:33:13 - progress_bar.py[line:274] - INFO: epoch 001:  15900 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111.9, bsz=40, num_updates=15880, lr=4.56415e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44260
2023-02-21 01:33:24 - progress_bar.py[line:274] - INFO: epoch 001:  15910 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.4, bsz=40, num_updates=15890, lr=4.56379e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44271
2023-02-21 01:33:35 - progress_bar.py[line:274] - INFO: epoch 001:  15920 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.4, bsz=40, num_updates=15900, lr=4.56343e-05, gnorm=0.153, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44282
2023-02-21 01:33:46 - progress_bar.py[line:274] - INFO: epoch 001:  15930 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111, bsz=40, num_updates=15910, lr=4.56307e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44293
2023-02-21 01:33:57 - progress_bar.py[line:274] - INFO: epoch 001:  15940 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.1, ups=0.92, wpb=112.9, bsz=40, num_updates=15920, lr=4.5627e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=44303
2023-02-21 01:34:08 - progress_bar.py[line:274] - INFO: epoch 001:  15950 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.2, bsz=40, num_updates=15930, lr=4.56234e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44314
2023-02-21 01:34:19 - progress_bar.py[line:274] - INFO: epoch 001:  15960 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.93, wpb=111, bsz=40, num_updates=15940, lr=4.56198e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44325
2023-02-21 01:34:30 - progress_bar.py[line:274] - INFO: epoch 001:  15970 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.9, wpb=112.4, bsz=40, num_updates=15950, lr=4.56162e-05, gnorm=0.063, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44336
2023-02-21 01:34:41 - progress_bar.py[line:274] - INFO: epoch 001:  15980 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.4, bsz=40, num_updates=15960, lr=4.56126e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44347
2023-02-21 01:34:52 - progress_bar.py[line:274] - INFO: epoch 001:  15990 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=112.7, bsz=40, num_updates=15970, lr=4.56089e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44358
2023-02-21 01:35:02 - progress_bar.py[line:274] - INFO: epoch 001:  16000 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.3, ups=0.95, wpb=112.3, bsz=40, num_updates=15980, lr=4.56053e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44369
2023-02-21 01:35:13 - progress_bar.py[line:274] - INFO: epoch 001:  16010 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112, bsz=40, num_updates=15990, lr=4.56017e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44380
2023-02-21 01:35:24 - progress_bar.py[line:274] - INFO: epoch 001:  16020 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.92, wpb=109.3, bsz=40, num_updates=16000, lr=4.55981e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44391
2023-02-21 01:35:24 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 01:35:26 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 01:35:26 - train.py[line:551] - INFO: load:1.14 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 01:37:27 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 01:37:27 - train.py[line:551] - INFO: load:1.17 valid_run:121.42 task_valid:118.71 collect_output:1.67
2023-02-21 01:39:27 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 01:39:27 - train.py[line:551] - INFO: load:1.19 valid_run:240.60 task_valid:234.13 collect_output:4.39
2023-02-21 01:41:28 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 01:41:28 - train.py[line:551] - INFO: load:1.22 valid_run:361.95 task_valid:350.23 collect_output:8.60
2023-02-21 01:43:29 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 01:43:29 - train.py[line:551] - INFO: load:1.24 valid_run:483.23 task_valid:463.58 collect_output:15.50
2023-02-21 01:45:29 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 01:45:29 - train.py[line:551] - INFO: load:1.27 valid_run:603.10 task_valid:580.51 collect_output:17.41
2023-02-21 01:47:32 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 01:47:32 - train.py[line:551] - INFO: load:1.30 valid_run:725.52 task_valid:698.81 collect_output:20.49
2023-02-21 01:49:34 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 01:49:34 - train.py[line:551] - INFO: load:1.32 valid_run:847.92 task_valid:816.59 collect_output:24.06
2023-02-21 01:51:35 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 01:51:35 - train.py[line:551] - INFO: load:1.35 valid_run:969.09 task_valid:932.66 collect_output:28.12
2023-02-21 01:53:39 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 01:53:39 - train.py[line:551] - INFO: load:1.38 valid_run:1092.14 task_valid:1049.41 collect_output:33.38
2023-02-21 01:55:40 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 01:55:40 - train.py[line:551] - INFO: load:1.40 valid_run:1213.12 task_valid:1161.67 collect_output:41.04
2023-02-21 01:57:39 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 01:57:39 - train.py[line:551] - INFO: load:1.43 valid_run:1332.75 task_valid:1277.04 collect_output:44.26
2023-02-21 01:59:40 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 01:59:40 - train.py[line:551] - INFO: load:1.46 valid_run:1453.73 task_valid:1393.59 collect_output:47.65
2023-02-21 02:01:39 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 02:01:39 - train.py[line:551] - INFO: load:1.48 valid_run:1572.16 task_valid:1507.12 collect_output:51.48
2023-02-21 02:03:39 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 02:03:39 - train.py[line:551] - INFO: load:1.51 valid_run:1692.61 task_valid:1624.48 collect_output:53.56
2023-02-21 02:05:40 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 02:05:40 - train.py[line:551] - INFO: load:1.54 valid_run:1813.04 task_valid:1740.27 collect_output:57.16
2023-02-21 02:07:40 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 02:07:40 - train.py[line:551] - INFO: load:1.56 valid_run:1933.34 task_valid:1853.79 collect_output:62.92
2023-02-21 02:09:41 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 02:09:41 - train.py[line:551] - INFO: load:1.59 valid_run:2054.02 task_valid:1969.44 collect_output:66.91
2023-02-21 02:11:41 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 02:11:41 - train.py[line:551] - INFO: load:1.62 valid_run:2174.27 task_valid:2087.02 collect_output:68.55
2023-02-21 02:13:42 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 02:13:42 - train.py[line:551] - INFO: load:1.65 valid_run:2295.12 task_valid:2203.60 collect_output:71.77
2023-02-21 02:15:42 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 02:15:42 - train.py[line:551] - INFO: load:1.67 valid_run:2415.01 task_valid:2319.85 collect_output:74.36
2023-02-21 02:17:43 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 02:17:43 - train.py[line:551] - INFO: load:1.70 valid_run:2535.95 task_valid:2435.80 collect_output:78.33
2023-02-21 02:19:45 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 02:19:45 - train.py[line:551] - INFO: load:1.73 valid_run:2657.41 task_valid:2554.29 collect_output:80.28
2023-02-21 02:21:44 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 02:21:44 - train.py[line:551] - INFO: load:1.75 valid_run:2777.22 task_valid:2668.23 collect_output:85.11
2023-02-21 02:23:44 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 02:23:44 - train.py[line:551] - INFO: load:1.78 valid_run:2896.44 task_valid:2784.08 collect_output:87.44
2023-02-21 02:25:45 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 02:25:45 - train.py[line:551] - INFO: load:1.81 valid_run:3017.44 task_valid:2899.96 collect_output:91.50
2023-02-21 02:27:47 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 02:27:47 - train.py[line:551] - INFO: load:1.83 valid_run:3139.76 task_valid:3015.68 collect_output:97.06
2023-02-21 02:29:46 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 02:29:46 - train.py[line:551] - INFO: load:1.86 valid_run:3258.82 task_valid:3129.60 collect_output:101.15
2023-02-21 02:31:48 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 02:31:48 - train.py[line:551] - INFO: load:1.89 valid_run:3380.31 task_valid:3248.72 collect_output:102.48
2023-02-21 02:33:49 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 02:33:49 - train.py[line:551] - INFO: load:1.92 valid_run:3501.40 task_valid:3364.00 collect_output:107.27
2023-02-21 02:35:51 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 02:35:51 - train.py[line:551] - INFO: load:1.94 valid_run:3622.85 task_valid:3482.23 collect_output:109.46
2023-02-21 02:37:51 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 02:37:51 - train.py[line:551] - INFO: load:1.97 valid_run:3743.64 task_valid:3600.43 collect_output:111.01

====================================================================================================
SGG eval:     R @ 50: 0.6297;     R @ 100: 0.6614;     R @ 500: 0.6845;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4030;    mR @ 100: 0.4442;    mR @ 500: 0.4947;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.6250) (covering:0.3000) (eating:0.7647) (flying in:0.5000) (growing on:0.3750) (hanging from:0.4516) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9771) (says:0.0000) (sitting on:0.7000) (standing on:0.3593) (using:0.6000) (walking in:0.0000) (walking on:0.7838) (watching:0.3889) 
--------------------------------------------------------
====================================================================================================

2023-02-21 02:38:22 - train.py[line:487] - INFO: 0.661381512605042

====================================================================================================
SGG eval:     R @ 50: 0.6297;     R @ 100: 0.6614;     R @ 500: 0.6845;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4030;    mR @ 100: 0.4442;    mR @ 500: 0.4947;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.6250) (covering:0.3000) (eating:0.7647) (flying in:0.5000) (growing on:0.3750) (hanging from:0.4516) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9771) (says:0.0000) (sitting on:0.7000) (standing on:0.3593) (using:0.6000) (walking in:0.0000) (walking on:0.7838) (watching:0.3889) 
--------------------------------------------------------
====================================================================================================

2023-02-21 02:38:22 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 02:38:22 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.235 | loss_v1 0 | loss_v2 0 | nll_loss 0.069 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.661382 | ppl 1.05 | vqa_score 0.4752 | wps 118.8 | wpb 72 | bsz 24 | num_updates 16000 | best_R@100 0.691462
2023-02-21 02:38:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 16000 updates
2023-02-21 02:38:22 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_16000.pt
2023-02-21 02:38:29 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_16000.pt
2023-02-21 02:38:31 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_16000.pt (epoch 1 @ 16000 updates, score 0.661381512605042) (writing took 9.069210059940815 seconds)
2023-02-21 02:38:42 - progress_bar.py[line:274] - INFO: epoch 001:  16030 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=112.4, bsz=40, num_updates=16010, lr=4.55945e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=48189
2023-02-21 02:38:53 - progress_bar.py[line:274] - INFO: epoch 001:  16040 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.8, ups=0.93, wpb=112, bsz=40, num_updates=16020, lr=4.55909e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48200
2023-02-21 02:39:05 - progress_bar.py[line:274] - INFO: epoch 001:  16050 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.1, bsz=40, num_updates=16030, lr=4.55872e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48211
2023-02-21 02:39:16 - progress_bar.py[line:274] - INFO: epoch 001:  16060 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.87, wpb=112.4, bsz=40, num_updates=16040, lr=4.55836e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48222
2023-02-21 02:39:27 - progress_bar.py[line:274] - INFO: epoch 001:  16070 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.91, wpb=112.6, bsz=40, num_updates=16050, lr=4.558e-05, gnorm=0.141, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48233
2023-02-21 02:39:38 - progress_bar.py[line:274] - INFO: epoch 001:  16080 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.91, wpb=113.3, bsz=40, num_updates=16060, lr=4.55764e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=48244
2023-02-21 02:39:49 - progress_bar.py[line:274] - INFO: epoch 001:  16090 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.9, nsentences=40, sample_size=113.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.9, wpb=113.9, bsz=40, num_updates=16070, lr=4.55728e-05, gnorm=0.139, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=48256
2023-02-21 02:40:00 - progress_bar.py[line:274] - INFO: epoch 001:  16100 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.6, ups=0.93, wpb=112, bsz=40, num_updates=16080, lr=4.55691e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48266
2023-02-21 02:40:11 - progress_bar.py[line:274] - INFO: epoch 001:  16110 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111, bsz=40, num_updates=16090, lr=4.55655e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48277
2023-02-21 02:40:22 - progress_bar.py[line:274] - INFO: epoch 001:  16120 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.89, wpb=110.3, bsz=40, num_updates=16100, lr=4.55619e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48289
2023-02-21 02:40:33 - progress_bar.py[line:274] - INFO: epoch 001:  16130 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.93, wpb=111.7, bsz=40, num_updates=16110, lr=4.55583e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48299
2023-02-21 02:40:44 - progress_bar.py[line:274] - INFO: epoch 001:  16140 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=16120, lr=4.55547e-05, gnorm=0.123, clip=0, loss_scale=4096, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=48311
2023-02-21 02:40:55 - progress_bar.py[line:274] - INFO: epoch 001:  16150 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111, bsz=40, num_updates=16130, lr=4.55511e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48322
2023-02-21 02:41:06 - progress_bar.py[line:274] - INFO: epoch 001:  16160 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.7, bsz=40, num_updates=16140, lr=4.55474e-05, gnorm=0.122, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48333
2023-02-21 02:41:13 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 02:41:18 - progress_bar.py[line:274] - INFO: epoch 001:  16171 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.1, ups=0.83, wpb=113.1, bsz=40, num_updates=16150, lr=4.55438e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=12, gb_free=11.3, ema_decay=0.9999, wall=48345
2023-02-21 02:41:29 - progress_bar.py[line:274] - INFO: epoch 001:  16181 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=110.8, bsz=40, num_updates=16160, lr=4.55402e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48356
2023-02-21 02:41:41 - progress_bar.py[line:274] - INFO: epoch 001:  16191 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112.7, bsz=40, num_updates=16170, lr=4.55366e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=48367
2023-02-21 02:41:52 - progress_bar.py[line:274] - INFO: epoch 001:  16201 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=110.7, bsz=40, num_updates=16180, lr=4.5533e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=48378
2023-02-21 02:42:03 - progress_bar.py[line:274] - INFO: epoch 001:  16211 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.2, bsz=40, num_updates=16190, lr=4.55293e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48389
2023-02-21 02:42:14 - progress_bar.py[line:274] - INFO: epoch 001:  16221 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.9, wpb=109.8, bsz=40, num_updates=16200, lr=4.55257e-05, gnorm=0.17, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48401
2023-02-21 02:42:25 - progress_bar.py[line:274] - INFO: epoch 001:  16231 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.9, wpb=110.2, bsz=40, num_updates=16210, lr=4.55221e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48412
2023-02-21 02:42:37 - progress_bar.py[line:274] - INFO: epoch 001:  16241 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=16220, lr=4.55185e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48423
2023-02-21 02:42:48 - progress_bar.py[line:274] - INFO: epoch 001:  16251 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112.1, bsz=40, num_updates=16230, lr=4.55149e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48434
2023-02-21 02:42:59 - progress_bar.py[line:274] - INFO: epoch 001:  16261 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.8, bsz=40, num_updates=16240, lr=4.55113e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48446
2023-02-21 02:43:10 - progress_bar.py[line:274] - INFO: epoch 001:  16271 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=110.7, bsz=40, num_updates=16250, lr=4.55076e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=48457
2023-02-21 02:43:22 - progress_bar.py[line:274] - INFO: epoch 001:  16281 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.9, bsz=40, num_updates=16260, lr=4.5504e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48468
2023-02-21 02:43:33 - progress_bar.py[line:274] - INFO: epoch 001:  16291 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.1, bsz=40, num_updates=16270, lr=4.55004e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48479
2023-02-21 02:43:44 - progress_bar.py[line:274] - INFO: epoch 001:  16301 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=111.1, bsz=40, num_updates=16280, lr=4.54968e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=48491
2023-02-21 02:43:56 - progress_bar.py[line:274] - INFO: epoch 001:  16311 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.9, bsz=40, num_updates=16290, lr=4.54932e-05, gnorm=0.131, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48502
2023-02-21 02:44:07 - progress_bar.py[line:274] - INFO: epoch 001:  16321 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.87, wpb=112, bsz=40, num_updates=16300, lr=4.54895e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48513
2023-02-21 02:44:18 - progress_bar.py[line:274] - INFO: epoch 001:  16331 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=113, bsz=40, num_updates=16310, lr=4.54859e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48525
2023-02-21 02:44:29 - progress_bar.py[line:274] - INFO: epoch 001:  16341 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=16320, lr=4.54823e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=48536
2023-02-21 02:44:41 - progress_bar.py[line:274] - INFO: epoch 001:  16351 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=112.1, bsz=40, num_updates=16330, lr=4.54787e-05, gnorm=0.174, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48547
2023-02-21 02:44:52 - progress_bar.py[line:274] - INFO: epoch 001:  16361 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.7, bsz=40, num_updates=16340, lr=4.54751e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=48558
2023-02-21 02:45:03 - progress_bar.py[line:274] - INFO: epoch 001:  16371 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.5, bsz=40, num_updates=16350, lr=4.54715e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=48569
2023-02-21 02:45:14 - progress_bar.py[line:274] - INFO: epoch 001:  16381 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.7, bsz=40, num_updates=16360, lr=4.54678e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48580
2023-02-21 02:45:24 - progress_bar.py[line:274] - INFO: epoch 001:  16391 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.9, ups=0.93, wpb=112.3, bsz=40, num_updates=16370, lr=4.54642e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48591
2023-02-21 02:45:36 - progress_bar.py[line:274] - INFO: epoch 001:  16401 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.89, wpb=110.4, bsz=40, num_updates=16380, lr=4.54606e-05, gnorm=0.159, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=48602
2023-02-21 02:45:47 - progress_bar.py[line:274] - INFO: epoch 001:  16411 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.9, bsz=40, num_updates=16390, lr=4.5457e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=48613
2023-02-21 02:45:58 - progress_bar.py[line:274] - INFO: epoch 001:  16421 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113.4, nsentences=40, sample_size=113.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.91, wpb=113.4, bsz=40, num_updates=16400, lr=4.54534e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48624
2023-02-21 02:46:09 - progress_bar.py[line:274] - INFO: epoch 001:  16431 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.93, wpb=111.1, bsz=40, num_updates=16410, lr=4.54497e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48635
2023-02-21 02:46:20 - progress_bar.py[line:274] - INFO: epoch 001:  16441 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.9, wpb=110.1, bsz=40, num_updates=16420, lr=4.54461e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48646
2023-02-21 02:46:32 - progress_bar.py[line:274] - INFO: epoch 001:  16451 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.86, wpb=112, bsz=40, num_updates=16430, lr=4.54425e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=48658
2023-02-21 02:46:43 - progress_bar.py[line:274] - INFO: epoch 001:  16461 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.4, bsz=40, num_updates=16440, lr=4.54389e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=48669
2023-02-21 02:46:54 - progress_bar.py[line:274] - INFO: epoch 001:  16471 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110.6, bsz=40, num_updates=16450, lr=4.54353e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48681
2023-02-21 02:47:05 - progress_bar.py[line:274] - INFO: epoch 001:  16481 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=112.6, bsz=40, num_updates=16460, lr=4.54317e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48692
2023-02-21 02:47:16 - progress_bar.py[line:274] - INFO: epoch 001:  16491 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.5, bsz=40, num_updates=16470, lr=4.5428e-05, gnorm=0.056, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=48703
2023-02-21 02:47:28 - progress_bar.py[line:274] - INFO: epoch 001:  16501 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.3, bsz=40, num_updates=16480, lr=4.54244e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48714
2023-02-21 02:47:39 - progress_bar.py[line:274] - INFO: epoch 001:  16511 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111, bsz=40, num_updates=16490, lr=4.54208e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48725
2023-02-21 02:47:49 - progress_bar.py[line:274] - INFO: epoch 001:  16521 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=107.2, ups=0.95, wpb=113.3, bsz=40, num_updates=16500, lr=4.54172e-05, gnorm=0.154, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=48736
2023-02-21 02:48:00 - progress_bar.py[line:274] - INFO: epoch 001:  16531 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110, bsz=40, num_updates=16510, lr=4.54136e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48747
2023-02-21 02:48:12 - progress_bar.py[line:274] - INFO: epoch 001:  16541 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.9, wpb=113, bsz=40, num_updates=16520, lr=4.54099e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=48758
2023-02-21 02:48:23 - progress_bar.py[line:274] - INFO: epoch 001:  16551 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=16530, lr=4.54063e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48769
2023-02-21 02:48:34 - progress_bar.py[line:274] - INFO: epoch 001:  16561 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.1, ups=0.93, wpb=111.5, bsz=40, num_updates=16540, lr=4.54027e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48780
2023-02-21 02:48:45 - progress_bar.py[line:274] - INFO: epoch 001:  16571 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.91, wpb=112.9, bsz=40, num_updates=16550, lr=4.53991e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48791
2023-02-21 02:48:56 - progress_bar.py[line:274] - INFO: epoch 001:  16581 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.7, bsz=40, num_updates=16560, lr=4.53955e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48802
2023-02-21 02:49:08 - progress_bar.py[line:274] - INFO: epoch 001:  16591 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.86, wpb=113, bsz=40, num_updates=16570, lr=4.53919e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=48814
2023-02-21 02:49:19 - progress_bar.py[line:274] - INFO: epoch 001:  16601 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.3, bsz=40, num_updates=16580, lr=4.53882e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48825
2023-02-21 02:49:30 - progress_bar.py[line:274] - INFO: epoch 001:  16611 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.3, bsz=40, num_updates=16590, lr=4.53846e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48837
2023-02-21 02:49:41 - progress_bar.py[line:274] - INFO: epoch 001:  16621 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.5, bsz=40, num_updates=16600, lr=4.5381e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48848
2023-02-21 02:49:52 - progress_bar.py[line:274] - INFO: epoch 001:  16631 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.1, bsz=40, num_updates=16610, lr=4.53774e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=48859
2023-02-21 02:50:03 - progress_bar.py[line:274] - INFO: epoch 001:  16641 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=16620, lr=4.53738e-05, gnorm=0.072, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48870
2023-02-21 02:50:14 - progress_bar.py[line:274] - INFO: epoch 001:  16651 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111, bsz=40, num_updates=16630, lr=4.53701e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48881
2023-02-21 02:50:26 - progress_bar.py[line:274] - INFO: epoch 001:  16661 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111, bsz=40, num_updates=16640, lr=4.53665e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=48892
2023-02-21 02:50:37 - progress_bar.py[line:274] - INFO: epoch 001:  16671 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.3, bsz=40, num_updates=16650, lr=4.53629e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48903
2023-02-21 02:50:48 - progress_bar.py[line:274] - INFO: epoch 001:  16681 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.2, bsz=40, num_updates=16660, lr=4.53593e-05, gnorm=0.112, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48914
2023-02-21 02:50:59 - progress_bar.py[line:274] - INFO: epoch 001:  16691 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=16670, lr=4.53557e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=48925
2023-02-21 02:51:10 - progress_bar.py[line:274] - INFO: epoch 001:  16701 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=110.9, bsz=40, num_updates=16680, lr=4.53521e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=48936
2023-02-21 02:51:21 - progress_bar.py[line:274] - INFO: epoch 001:  16711 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112, bsz=40, num_updates=16690, lr=4.53484e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48948
2023-02-21 02:51:24 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 02:51:34 - progress_bar.py[line:274] - INFO: epoch 001:  16722 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89, ups=0.8, wpb=110.8, bsz=40, num_updates=16700, lr=4.53448e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=48960
2023-02-21 02:51:45 - progress_bar.py[line:274] - INFO: epoch 001:  16732 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.1, bsz=40, num_updates=16710, lr=4.53412e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=48971
2023-02-21 02:51:56 - progress_bar.py[line:274] - INFO: epoch 001:  16742 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.93, wpb=111.8, bsz=40, num_updates=16720, lr=4.53376e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48982
2023-02-21 02:52:07 - progress_bar.py[line:274] - INFO: epoch 001:  16752 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=16730, lr=4.5334e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48993
2023-02-21 02:52:18 - progress_bar.py[line:274] - INFO: epoch 001:  16762 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.3, bsz=40, num_updates=16740, lr=4.53303e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49004
2023-02-21 02:52:30 - progress_bar.py[line:274] - INFO: epoch 001:  16772 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.91, wpb=111.3, bsz=40, num_updates=16750, lr=4.53267e-05, gnorm=0.145, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49015
2023-02-21 02:52:41 - progress_bar.py[line:274] - INFO: epoch 001:  16782 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112.9, bsz=40, num_updates=16760, lr=4.53231e-05, gnorm=0.156, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49028
2023-02-21 02:52:53 - progress_bar.py[line:274] - INFO: epoch 001:  16792 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.88, wpb=111.5, bsz=40, num_updates=16770, lr=4.53195e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49039
2023-02-21 02:53:03 - progress_bar.py[line:274] - INFO: epoch 001:  16802 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.93, wpb=110.9, bsz=40, num_updates=16780, lr=4.53159e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49050
2023-02-21 02:53:15 - progress_bar.py[line:274] - INFO: epoch 001:  16812 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.2, bsz=40, num_updates=16790, lr=4.53123e-05, gnorm=0.131, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=49061
2023-02-21 02:53:26 - progress_bar.py[line:274] - INFO: epoch 001:  16822 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=16800, lr=4.53086e-05, gnorm=0.154, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49073
2023-02-21 02:53:37 - progress_bar.py[line:274] - INFO: epoch 001:  16832 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.93, wpb=111.7, bsz=40, num_updates=16810, lr=4.5305e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49083
2023-02-21 02:53:48 - progress_bar.py[line:274] - INFO: epoch 001:  16842 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=113.1, bsz=40, num_updates=16820, lr=4.53014e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49095
2023-02-21 02:54:00 - progress_bar.py[line:274] - INFO: epoch 001:  16852 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.87, wpb=112.6, bsz=40, num_updates=16830, lr=4.52978e-05, gnorm=0.231, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49106
2023-02-21 02:54:11 - progress_bar.py[line:274] - INFO: epoch 001:  16862 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.4, bsz=40, num_updates=16840, lr=4.52942e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49117
2023-02-21 02:54:22 - progress_bar.py[line:274] - INFO: epoch 001:  16872 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.7, bsz=40, num_updates=16850, lr=4.52905e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49128
2023-02-21 02:54:33 - progress_bar.py[line:274] - INFO: epoch 001:  16882 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.8, bsz=40, num_updates=16860, lr=4.52869e-05, gnorm=0.161, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49139
2023-02-21 02:54:44 - progress_bar.py[line:274] - INFO: epoch 001:  16892 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112, bsz=40, num_updates=16870, lr=4.52833e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49150
2023-02-21 02:54:55 - progress_bar.py[line:274] - INFO: epoch 001:  16902 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.4, bsz=40, num_updates=16880, lr=4.52797e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=49161
2023-02-21 02:55:06 - progress_bar.py[line:274] - INFO: epoch 001:  16912 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=16890, lr=4.52761e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49172
2023-02-21 02:55:17 - progress_bar.py[line:274] - INFO: epoch 001:  16922 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.89, wpb=109.4, bsz=40, num_updates=16900, lr=4.52725e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49183
2023-02-21 02:55:28 - progress_bar.py[line:274] - INFO: epoch 001:  16932 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.6, bsz=40, num_updates=16910, lr=4.52688e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49195
2023-02-21 02:55:40 - progress_bar.py[line:274] - INFO: epoch 001:  16942 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=112.1, bsz=40, num_updates=16920, lr=4.52652e-05, gnorm=0.154, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49206
2023-02-21 02:55:51 - progress_bar.py[line:274] - INFO: epoch 001:  16952 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111, bsz=40, num_updates=16930, lr=4.52616e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49217
2023-02-21 02:56:02 - progress_bar.py[line:274] - INFO: epoch 001:  16962 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.7, bsz=40, num_updates=16940, lr=4.5258e-05, gnorm=0.182, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49229
2023-02-21 02:56:13 - progress_bar.py[line:274] - INFO: epoch 001:  16972 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=112.2, bsz=40, num_updates=16950, lr=4.52544e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49240
2023-02-21 02:56:24 - progress_bar.py[line:274] - INFO: epoch 001:  16982 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.2, ups=0.93, wpb=111.6, bsz=40, num_updates=16960, lr=4.52507e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49251
2023-02-21 02:56:35 - progress_bar.py[line:274] - INFO: epoch 001:  16992 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.93, wpb=112.1, bsz=40, num_updates=16970, lr=4.52471e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=49261
2023-02-21 02:56:46 - progress_bar.py[line:274] - INFO: epoch 001:  17002 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=111.9, bsz=40, num_updates=16980, lr=4.52435e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49273
2023-02-21 02:56:57 - progress_bar.py[line:274] - INFO: epoch 001:  17012 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.4, bsz=40, num_updates=16990, lr=4.52399e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49284
2023-02-21 02:57:08 - progress_bar.py[line:274] - INFO: epoch 001:  17022 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111, bsz=40, num_updates=17000, lr=4.52363e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49295
2023-02-21 02:57:19 - progress_bar.py[line:274] - INFO: epoch 001:  17032 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.1, bsz=40, num_updates=17010, lr=4.52327e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49306
2023-02-21 02:57:30 - progress_bar.py[line:274] - INFO: epoch 001:  17042 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=111.7, bsz=40, num_updates=17020, lr=4.5229e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49317
2023-02-21 02:57:42 - progress_bar.py[line:274] - INFO: epoch 001:  17052 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.2, bsz=40, num_updates=17030, lr=4.52254e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49328
2023-02-21 02:57:53 - progress_bar.py[line:274] - INFO: epoch 001:  17062 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=17040, lr=4.52218e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49339
2023-02-21 02:58:04 - progress_bar.py[line:274] - INFO: epoch 001:  17072 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.6, bsz=40, num_updates=17050, lr=4.52182e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49350
2023-02-21 02:58:15 - progress_bar.py[line:274] - INFO: epoch 001:  17082 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.7, bsz=40, num_updates=17060, lr=4.52146e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49361
2023-02-21 02:58:26 - progress_bar.py[line:274] - INFO: epoch 001:  17092 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.9, wpb=110.2, bsz=40, num_updates=17070, lr=4.52109e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49373
2023-02-21 02:58:37 - progress_bar.py[line:274] - INFO: epoch 001:  17102 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.3, bsz=40, num_updates=17080, lr=4.52073e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49384
2023-02-21 02:58:48 - progress_bar.py[line:274] - INFO: epoch 001:  17112 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111, bsz=40, num_updates=17090, lr=4.52037e-05, gnorm=0.136, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49395
2023-02-21 02:58:59 - progress_bar.py[line:274] - INFO: epoch 001:  17122 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.9, ups=0.93, wpb=113, bsz=40, num_updates=17100, lr=4.52001e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49406
2023-02-21 02:59:10 - progress_bar.py[line:274] - INFO: epoch 001:  17132 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.9, bsz=40, num_updates=17110, lr=4.51965e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49417
2023-02-21 02:59:21 - progress_bar.py[line:274] - INFO: epoch 001:  17142 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.6, ups=0.92, wpb=112.5, bsz=40, num_updates=17120, lr=4.51929e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49428
2023-02-21 02:59:32 - progress_bar.py[line:274] - INFO: epoch 001:  17152 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.4, ups=0.91, wpb=111.5, bsz=40, num_updates=17130, lr=4.51892e-05, gnorm=0.136, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49439
2023-02-21 02:59:43 - progress_bar.py[line:274] - INFO: epoch 001:  17162 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.1, bsz=40, num_updates=17140, lr=4.51856e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49450
2023-02-21 02:59:54 - progress_bar.py[line:274] - INFO: epoch 001:  17172 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.5, bsz=40, num_updates=17150, lr=4.5182e-05, gnorm=0.149, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49461
2023-02-21 03:00:05 - progress_bar.py[line:274] - INFO: epoch 001:  17182 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.8, bsz=40, num_updates=17160, lr=4.51784e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49472
2023-02-21 03:00:16 - progress_bar.py[line:274] - INFO: epoch 001:  17192 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.3, ups=0.95, wpb=111.9, bsz=40, num_updates=17170, lr=4.51748e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=10, gb_free=10.7, ema_decay=0.9999, wall=49482
2023-02-21 03:00:26 - progress_bar.py[line:274] - INFO: epoch 001:  17202 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=107.1, ups=0.96, wpb=111.6, bsz=40, num_updates=17180, lr=4.51711e-05, gnorm=0.132, clip=0, loss_scale=2048, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=49493
2023-02-21 03:00:37 - progress_bar.py[line:274] - INFO: epoch 001:  17212 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.1, bsz=40, num_updates=17190, lr=4.51675e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49504
2023-02-21 03:00:49 - progress_bar.py[line:274] - INFO: epoch 001:  17222 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.89, wpb=110, bsz=40, num_updates=17200, lr=4.51639e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49515
2023-02-21 03:01:00 - progress_bar.py[line:274] - INFO: epoch 001:  17232 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.1, bsz=40, num_updates=17210, lr=4.51603e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49526
2023-02-21 03:01:11 - progress_bar.py[line:274] - INFO: epoch 001:  17242 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.91, wpb=112.7, bsz=40, num_updates=17220, lr=4.51567e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49537
2023-02-21 03:01:22 - progress_bar.py[line:274] - INFO: epoch 001:  17252 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.4, bsz=40, num_updates=17230, lr=4.51531e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49548
2023-02-21 03:01:34 - progress_bar.py[line:274] - INFO: epoch 001:  17262 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.4, ups=0.86, wpb=111.1, bsz=40, num_updates=17240, lr=4.51494e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=49560
2023-02-21 03:01:45 - progress_bar.py[line:274] - INFO: epoch 001:  17272 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.6, bsz=40, num_updates=17250, lr=4.51458e-05, gnorm=0.122, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49571
2023-02-21 03:01:56 - progress_bar.py[line:274] - INFO: epoch 001:  17282 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.8, bsz=40, num_updates=17260, lr=4.51422e-05, gnorm=0.132, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49583
2023-02-21 03:02:07 - progress_bar.py[line:274] - INFO: epoch 001:  17292 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.9, wpb=110.8, bsz=40, num_updates=17270, lr=4.51386e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49594
2023-02-21 03:02:18 - progress_bar.py[line:274] - INFO: epoch 001:  17302 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=111.9, bsz=40, num_updates=17280, lr=4.5135e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49605
2023-02-21 03:02:30 - progress_bar.py[line:274] - INFO: epoch 001:  17312 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.7, bsz=40, num_updates=17290, lr=4.51313e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49616
2023-02-21 03:02:41 - progress_bar.py[line:274] - INFO: epoch 001:  17322 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.1, bsz=40, num_updates=17300, lr=4.51277e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49627
2023-02-21 03:02:43 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 03:02:53 - progress_bar.py[line:274] - INFO: epoch 001:  17333 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.1, ups=0.84, wpb=111.8, bsz=40, num_updates=17310, lr=4.51241e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=49639
2023-02-21 03:03:04 - progress_bar.py[line:274] - INFO: epoch 001:  17343 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.6, bsz=40, num_updates=17320, lr=4.51205e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49651
2023-02-21 03:03:15 - progress_bar.py[line:274] - INFO: epoch 001:  17353 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.4, bsz=40, num_updates=17330, lr=4.51169e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49661
2023-02-21 03:03:27 - progress_bar.py[line:274] - INFO: epoch 001:  17363 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.6, bsz=40, num_updates=17340, lr=4.51132e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49673
2023-02-21 03:03:38 - progress_bar.py[line:274] - INFO: epoch 001:  17373 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.6, bsz=40, num_updates=17350, lr=4.51096e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49684
2023-02-21 03:03:48 - progress_bar.py[line:274] - INFO: epoch 001:  17383 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=110.5, bsz=40, num_updates=17360, lr=4.5106e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49695
2023-02-21 03:04:00 - progress_bar.py[line:274] - INFO: epoch 001:  17393 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=17370, lr=4.51024e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49706
2023-02-21 03:04:11 - progress_bar.py[line:274] - INFO: epoch 001:  17403 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112, bsz=40, num_updates=17380, lr=4.50988e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49717
2023-02-21 03:04:22 - progress_bar.py[line:274] - INFO: epoch 001:  17413 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.2, bsz=40, num_updates=17390, lr=4.50952e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=49728
2023-02-21 03:04:33 - progress_bar.py[line:274] - INFO: epoch 001:  17423 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.3, bsz=40, num_updates=17400, lr=4.50915e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49739
2023-02-21 03:04:44 - progress_bar.py[line:274] - INFO: epoch 001:  17433 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.9, wpb=110.2, bsz=40, num_updates=17410, lr=4.50879e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49750
2023-02-21 03:04:55 - progress_bar.py[line:274] - INFO: epoch 001:  17443 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111, bsz=40, num_updates=17420, lr=4.50843e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=49762
2023-02-21 03:05:06 - progress_bar.py[line:274] - INFO: epoch 001:  17453 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.8, bsz=40, num_updates=17430, lr=4.50807e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49773
2023-02-21 03:05:17 - progress_bar.py[line:274] - INFO: epoch 001:  17463 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110, bsz=40, num_updates=17440, lr=4.50771e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49784
2023-02-21 03:05:29 - progress_bar.py[line:274] - INFO: epoch 001:  17473 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.7, bsz=40, num_updates=17450, lr=4.50734e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49795
2023-02-21 03:05:40 - progress_bar.py[line:274] - INFO: epoch 001:  17483 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.5, bsz=40, num_updates=17460, lr=4.50698e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49806
2023-02-21 03:05:51 - progress_bar.py[line:274] - INFO: epoch 001:  17493 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.88, wpb=113.1, bsz=40, num_updates=17470, lr=4.50662e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49817
2023-02-21 03:06:02 - progress_bar.py[line:274] - INFO: epoch 001:  17503 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.7, bsz=40, num_updates=17480, lr=4.50626e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49828
2023-02-21 03:06:13 - progress_bar.py[line:274] - INFO: epoch 001:  17513 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=112.3, bsz=40, num_updates=17490, lr=4.5059e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49840
2023-02-21 03:06:25 - progress_bar.py[line:274] - INFO: epoch 001:  17523 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.87, wpb=111.1, bsz=40, num_updates=17500, lr=4.50554e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49851
2023-02-21 03:06:36 - progress_bar.py[line:274] - INFO: epoch 001:  17533 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.9, wpb=112.8, bsz=40, num_updates=17510, lr=4.50517e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49862
2023-02-21 03:06:47 - progress_bar.py[line:274] - INFO: epoch 001:  17543 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=112.2, bsz=40, num_updates=17520, lr=4.50481e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49873
2023-02-21 03:06:58 - progress_bar.py[line:274] - INFO: epoch 001:  17553 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.6, bsz=40, num_updates=17530, lr=4.50445e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49885
2023-02-21 03:07:10 - progress_bar.py[line:274] - INFO: epoch 001:  17563 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112, bsz=40, num_updates=17540, lr=4.50409e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49896
2023-02-21 03:07:21 - progress_bar.py[line:274] - INFO: epoch 001:  17573 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=17550, lr=4.50373e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49907
2023-02-21 03:07:32 - progress_bar.py[line:274] - INFO: epoch 001:  17583 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.2, bsz=40, num_updates=17560, lr=4.50336e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49918
2023-02-21 03:07:43 - progress_bar.py[line:274] - INFO: epoch 001:  17593 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.6, bsz=40, num_updates=17570, lr=4.503e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49929
2023-02-21 03:07:54 - progress_bar.py[line:274] - INFO: epoch 001:  17603 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.1, bsz=40, num_updates=17580, lr=4.50264e-05, gnorm=0.141, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49940
2023-02-21 03:08:05 - progress_bar.py[line:274] - INFO: epoch 001:  17613 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.1, bsz=40, num_updates=17590, lr=4.50228e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49951
2023-02-21 03:08:16 - progress_bar.py[line:274] - INFO: epoch 001:  17623 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.92, wpb=109.7, bsz=40, num_updates=17600, lr=4.50192e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49962
2023-02-21 03:08:27 - progress_bar.py[line:274] - INFO: epoch 001:  17633 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.2, bsz=40, num_updates=17610, lr=4.50156e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49973
2023-02-21 03:08:38 - progress_bar.py[line:274] - INFO: epoch 001:  17643 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.3, bsz=40, num_updates=17620, lr=4.50119e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49984
2023-02-21 03:08:49 - progress_bar.py[line:274] - INFO: epoch 001:  17653 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.91, wpb=113.1, bsz=40, num_updates=17630, lr=4.50083e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49995
2023-02-21 03:09:00 - progress_bar.py[line:274] - INFO: epoch 001:  17663 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.7, bsz=40, num_updates=17640, lr=4.50047e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50006
2023-02-21 03:09:11 - progress_bar.py[line:274] - INFO: epoch 001:  17673 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.7, bsz=40, num_updates=17650, lr=4.50011e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=50017
2023-02-21 03:09:22 - progress_bar.py[line:274] - INFO: epoch 001:  17683 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=17660, lr=4.49975e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50028
2023-02-21 03:09:33 - progress_bar.py[line:274] - INFO: epoch 001:  17693 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.3, bsz=40, num_updates=17670, lr=4.49938e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50039
2023-02-21 03:09:44 - progress_bar.py[line:274] - INFO: epoch 001:  17703 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112.3, bsz=40, num_updates=17680, lr=4.49902e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50051
2023-02-21 03:09:55 - progress_bar.py[line:274] - INFO: epoch 001:  17713 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112, bsz=40, num_updates=17690, lr=4.49866e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50061
2023-02-21 03:10:06 - progress_bar.py[line:274] - INFO: epoch 001:  17723 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.6, ups=0.93, wpb=112, bsz=40, num_updates=17700, lr=4.4983e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50072
2023-02-21 03:10:17 - progress_bar.py[line:274] - INFO: epoch 001:  17733 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.5, bsz=40, num_updates=17710, lr=4.49794e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50083
2023-02-21 03:10:28 - progress_bar.py[line:274] - INFO: epoch 001:  17743 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.5, bsz=40, num_updates=17720, lr=4.49758e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50094
2023-02-21 03:10:39 - progress_bar.py[line:274] - INFO: epoch 001:  17753 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.2, bsz=40, num_updates=17730, lr=4.49721e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=50105
2023-02-21 03:10:50 - progress_bar.py[line:274] - INFO: epoch 001:  17763 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.8, bsz=40, num_updates=17740, lr=4.49685e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50116
2023-02-21 03:11:01 - progress_bar.py[line:274] - INFO: epoch 001:  17773 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=110.9, bsz=40, num_updates=17750, lr=4.49649e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50127
2023-02-21 03:11:12 - progress_bar.py[line:274] - INFO: epoch 001:  17783 / 71012 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.7, ups=0.87, wpb=111.8, bsz=40, num_updates=17760, lr=4.49613e-05, gnorm=0.167, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=50139
2023-02-21 03:11:23 - progress_bar.py[line:274] - INFO: epoch 001:  17793 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112.1, bsz=40, num_updates=17770, lr=4.49577e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50150
2023-02-21 03:11:35 - progress_bar.py[line:274] - INFO: epoch 001:  17803 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.7, bsz=40, num_updates=17780, lr=4.4954e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50161
2023-02-21 03:11:46 - progress_bar.py[line:274] - INFO: epoch 001:  17813 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.2, bsz=40, num_updates=17790, lr=4.49504e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=50172
2023-02-21 03:11:57 - progress_bar.py[line:274] - INFO: epoch 001:  17823 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.1, bsz=40, num_updates=17800, lr=4.49468e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50184
2023-02-21 03:12:09 - progress_bar.py[line:274] - INFO: epoch 001:  17833 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.87, wpb=112.3, bsz=40, num_updates=17810, lr=4.49432e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50195
2023-02-21 03:12:20 - progress_bar.py[line:274] - INFO: epoch 001:  17843 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.2, bsz=40, num_updates=17820, lr=4.49396e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=50206
2023-02-21 03:12:31 - progress_bar.py[line:274] - INFO: epoch 001:  17853 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.9, bsz=40, num_updates=17830, lr=4.4936e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50218
2023-02-21 03:12:42 - progress_bar.py[line:274] - INFO: epoch 001:  17863 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.93, wpb=111.3, bsz=40, num_updates=17840, lr=4.49323e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50228
2023-02-21 03:12:50 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 03:12:54 - progress_bar.py[line:274] - INFO: epoch 001:  17874 / 71012 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=92.1, ups=0.83, wpb=110.5, bsz=40, num_updates=17850, lr=4.49287e-05, gnorm=0.063, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=50240
2023-02-21 03:13:05 - progress_bar.py[line:274] - INFO: epoch 001:  17884 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.3, bsz=40, num_updates=17860, lr=4.49251e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50252
2023-02-21 03:13:17 - progress_bar.py[line:274] - INFO: epoch 001:  17894 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.7, bsz=40, num_updates=17870, lr=4.49215e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50263
2023-02-21 03:13:28 - progress_bar.py[line:274] - INFO: epoch 001:  17904 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.3, bsz=40, num_updates=17880, lr=4.49179e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50274
2023-02-21 03:13:39 - progress_bar.py[line:274] - INFO: epoch 001:  17914 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111.2, bsz=40, num_updates=17890, lr=4.49142e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50285
2023-02-21 03:13:51 - progress_bar.py[line:274] - INFO: epoch 001:  17924 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.6, ups=0.86, wpb=109.6, bsz=40, num_updates=17900, lr=4.49106e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=50297
2023-02-21 03:14:02 - progress_bar.py[line:274] - INFO: epoch 001:  17934 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.89, wpb=112.6, bsz=40, num_updates=17910, lr=4.4907e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50308
2023-02-21 03:14:13 - progress_bar.py[line:274] - INFO: epoch 001:  17944 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=100.4, ups=0.9, wpb=112.2, bsz=40, num_updates=17920, lr=4.49034e-05, gnorm=0.057, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50319
2023-02-21 03:14:24 - progress_bar.py[line:274] - INFO: epoch 001:  17954 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.3, bsz=40, num_updates=17930, lr=4.48998e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=50331
2023-02-21 03:14:35 - progress_bar.py[line:274] - INFO: epoch 001:  17964 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.93, wpb=110.9, bsz=40, num_updates=17940, lr=4.48962e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=50341
2023-02-21 03:14:46 - progress_bar.py[line:274] - INFO: epoch 001:  17974 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.3, bsz=40, num_updates=17950, lr=4.48925e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50352
2023-02-21 03:14:57 - progress_bar.py[line:274] - INFO: epoch 001:  17984 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.6, bsz=40, num_updates=17960, lr=4.48889e-05, gnorm=0.117, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50363
2023-02-21 03:15:08 - progress_bar.py[line:274] - INFO: epoch 001:  17994 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.3, bsz=40, num_updates=17970, lr=4.48853e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50375
2023-02-21 03:15:19 - progress_bar.py[line:274] - INFO: epoch 001:  18004 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=110.7, bsz=40, num_updates=17980, lr=4.48817e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50385
2023-02-21 03:15:30 - progress_bar.py[line:274] - INFO: epoch 001:  18014 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.5, bsz=40, num_updates=17990, lr=4.48781e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50397
2023-02-21 03:15:42 - progress_bar.py[line:274] - INFO: epoch 001:  18024 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.6, bsz=40, num_updates=18000, lr=4.48744e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50408
2023-02-21 03:15:42 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 03:15:43 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 03:15:43 - train.py[line:551] - INFO: load:0.95 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 03:17:45 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 03:17:45 - train.py[line:551] - INFO: load:0.98 valid_run:121.64 task_valid:119.02 collect_output:1.53
2023-02-21 03:19:44 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 03:19:44 - train.py[line:551] - INFO: load:1.00 valid_run:241.16 task_valid:234.52 collect_output:4.52
2023-02-21 03:21:46 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 03:21:46 - train.py[line:551] - INFO: load:1.03 valid_run:362.50 task_valid:350.54 collect_output:8.81
2023-02-21 03:23:47 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 03:23:47 - train.py[line:551] - INFO: load:1.05 valid_run:483.88 task_valid:463.93 collect_output:15.76
2023-02-21 03:25:47 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 03:25:47 - train.py[line:551] - INFO: load:1.08 valid_run:603.79 task_valid:580.84 collect_output:17.74
2023-02-21 03:27:49 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 03:27:49 - train.py[line:551] - INFO: load:1.11 valid_run:726.04 task_valid:699.02 collect_output:20.77
2023-02-21 03:29:52 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 03:29:52 - train.py[line:551] - INFO: load:1.13 valid_run:848.25 task_valid:816.66 collect_output:24.32
2023-02-21 03:31:53 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 03:31:53 - train.py[line:551] - INFO: load:1.16 valid_run:969.57 task_valid:932.74 collect_output:28.50
2023-02-21 03:33:56 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 03:33:56 - train.py[line:551] - INFO: load:1.18 valid_run:1092.81 task_valid:1049.48 collect_output:33.97
2023-02-21 03:35:57 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 03:35:57 - train.py[line:551] - INFO: load:1.21 valid_run:1213.74 task_valid:1161.63 collect_output:41.68
2023-02-21 03:37:57 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 03:37:57 - train.py[line:551] - INFO: load:1.23 valid_run:1333.35 task_valid:1276.81 collect_output:45.07
2023-02-21 03:39:58 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 03:39:58 - train.py[line:551] - INFO: load:1.26 valid_run:1454.43 task_valid:1393.31 collect_output:48.62
2023-02-21 03:41:56 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 03:41:56 - train.py[line:551] - INFO: load:1.29 valid_run:1572.66 task_valid:1506.59 collect_output:52.52
2023-02-21 03:43:57 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 03:43:57 - train.py[line:551] - INFO: load:1.31 valid_run:1693.11 task_valid:1624.02 collect_output:54.53
2023-02-21 03:45:57 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 03:45:57 - train.py[line:551] - INFO: load:1.34 valid_run:1813.51 task_valid:1739.81 collect_output:58.10
2023-02-21 03:47:58 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 03:47:58 - train.py[line:551] - INFO: load:1.37 valid_run:1933.88 task_valid:1853.26 collect_output:64.00
2023-02-21 03:49:59 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 03:49:59 - train.py[line:551] - INFO: load:1.39 valid_run:2054.64 task_valid:1968.93 collect_output:68.05
2023-02-21 03:51:59 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 03:51:59 - train.py[line:551] - INFO: load:1.42 valid_run:2174.96 task_valid:2086.55 collect_output:69.70
2023-02-21 03:54:00 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 03:54:00 - train.py[line:551] - INFO: load:1.44 valid_run:2295.67 task_valid:2203.15 collect_output:72.78
2023-02-21 03:56:00 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 03:56:00 - train.py[line:551] - INFO: load:1.47 valid_run:2415.64 task_valid:2319.40 collect_output:75.47
2023-02-21 03:58:01 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 03:58:01 - train.py[line:551] - INFO: load:1.50 valid_run:2536.70 task_valid:2435.50 collect_output:79.39
2023-02-21 04:00:02 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 04:00:02 - train.py[line:551] - INFO: load:1.52 valid_run:2658.14 task_valid:2553.99 collect_output:81.31
2023-02-21 04:02:02 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 04:02:02 - train.py[line:551] - INFO: load:1.55 valid_run:2777.80 task_valid:2667.83 collect_output:86.12
2023-02-21 04:04:01 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 04:04:01 - train.py[line:551] - INFO: load:1.58 valid_run:2896.94 task_valid:2783.55 collect_output:88.49
2023-02-21 04:06:02 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 04:06:02 - train.py[line:551] - INFO: load:1.60 valid_run:3017.83 task_valid:2899.32 collect_output:92.58
2023-02-21 04:08:05 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 04:08:05 - train.py[line:551] - INFO: load:1.63 valid_run:3140.09 task_valid:3014.91 collect_output:98.21
2023-02-21 04:10:04 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 04:10:04 - train.py[line:551] - INFO: load:1.65 valid_run:3259.21 task_valid:3128.61 collect_output:102.61
2023-02-21 04:12:05 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 04:12:05 - train.py[line:551] - INFO: load:1.68 valid_run:3380.60 task_valid:3247.67 collect_output:103.92
2023-02-21 04:14:06 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 04:14:06 - train.py[line:551] - INFO: load:1.70 valid_run:3501.63 task_valid:3362.91 collect_output:108.67
2023-02-21 04:16:08 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 04:16:08 - train.py[line:551] - INFO: load:1.73 valid_run:3623.05 task_valid:3481.02 collect_output:110.93
2023-02-21 04:18:09 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 04:18:09 - train.py[line:551] - INFO: load:1.76 valid_run:3743.74 task_valid:3599.20 collect_output:112.40

====================================================================================================
SGG eval:     R @ 50: 0.6051;     R @ 100: 0.6366;     R @ 500: 0.6581;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3894;    mR @ 100: 0.4297;    mR @ 500: 0.4729;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.6250) (covering:0.3000) (eating:0.7647) (flying in:0.4545) (growing on:0.3750) (hanging from:0.3871) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9510) (says:0.0000) (sitting on:0.6837) (standing on:0.3493) (using:0.5500) (walking in:0.0000) (walking on:0.7297) (watching:0.3889) 
--------------------------------------------------------
====================================================================================================

2023-02-21 04:18:39 - train.py[line:487] - INFO: 0.6365663610898905

====================================================================================================
SGG eval:     R @ 50: 0.6051;     R @ 100: 0.6366;     R @ 500: 0.6581;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3894;    mR @ 100: 0.4297;    mR @ 500: 0.4729;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.6250) (covering:0.3000) (eating:0.7647) (flying in:0.4545) (growing on:0.3750) (hanging from:0.3871) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9510) (says:0.0000) (sitting on:0.6837) (standing on:0.3493) (using:0.5500) (walking in:0.0000) (walking on:0.7297) (watching:0.3889) 
--------------------------------------------------------
====================================================================================================

2023-02-21 04:18:39 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 04:18:39 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.234 | loss_v1 0 | loss_v2 0 | nll_loss 0.063 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.636566 | ppl 1.04 | vqa_score 0.464 | wps 118.8 | wpb 72 | bsz 24 | num_updates 18000 | best_R@100 0.691462
2023-02-21 04:18:39 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 18000 updates
2023-02-21 04:18:39 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_18000.pt
2023-02-21 04:18:45 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_18000.pt
2023-02-21 04:18:48 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_18000.pt (epoch 1 @ 18000 updates, score 0.6365663610898905) (writing took 8.431971102952957 seconds)
2023-02-21 04:18:59 - progress_bar.py[line:274] - INFO: epoch 001:  18034 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=111.3, bsz=40, num_updates=18010, lr=4.48708e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54205
2023-02-21 04:19:10 - progress_bar.py[line:274] - INFO: epoch 001:  18044 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.88, wpb=112.6, bsz=40, num_updates=18020, lr=4.48672e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54217
2023-02-21 04:19:21 - progress_bar.py[line:274] - INFO: epoch 001:  18054 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=18030, lr=4.48636e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54228
2023-02-21 04:19:33 - progress_bar.py[line:274] - INFO: epoch 001:  18064 / 71012 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.89, wpb=112.7, bsz=40, num_updates=18040, lr=4.486e-05, gnorm=0.147, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54239
2023-02-21 04:19:44 - progress_bar.py[line:274] - INFO: epoch 001:  18074 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.5, bsz=40, num_updates=18050, lr=4.48564e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54250
2023-02-21 04:19:55 - progress_bar.py[line:274] - INFO: epoch 001:  18084 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.5, bsz=40, num_updates=18060, lr=4.48527e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54261
2023-02-21 04:20:06 - progress_bar.py[line:274] - INFO: epoch 001:  18094 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111, bsz=40, num_updates=18070, lr=4.48491e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54272
2023-02-21 04:20:17 - progress_bar.py[line:274] - INFO: epoch 001:  18104 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.4, bsz=40, num_updates=18080, lr=4.48455e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54284
2023-02-21 04:20:28 - progress_bar.py[line:274] - INFO: epoch 001:  18114 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.92, wpb=111.9, bsz=40, num_updates=18090, lr=4.48419e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54295
2023-02-21 04:20:39 - progress_bar.py[line:274] - INFO: epoch 001:  18124 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.8, bsz=40, num_updates=18100, lr=4.48383e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54306
2023-02-21 04:20:51 - progress_bar.py[line:274] - INFO: epoch 001:  18134 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.89, wpb=110.2, bsz=40, num_updates=18110, lr=4.48346e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54317
2023-02-21 04:21:02 - progress_bar.py[line:274] - INFO: epoch 001:  18144 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.5, bsz=40, num_updates=18120, lr=4.4831e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54328
2023-02-21 04:21:13 - progress_bar.py[line:274] - INFO: epoch 001:  18154 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=112.1, bsz=40, num_updates=18130, lr=4.48274e-05, gnorm=0.153, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54339
2023-02-21 04:21:24 - progress_bar.py[line:274] - INFO: epoch 001:  18164 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111, bsz=40, num_updates=18140, lr=4.48238e-05, gnorm=0.136, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54350
2023-02-21 04:21:35 - progress_bar.py[line:274] - INFO: epoch 001:  18174 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=18150, lr=4.48202e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54361
2023-02-21 04:21:46 - progress_bar.py[line:274] - INFO: epoch 001:  18184 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.4, bsz=40, num_updates=18160, lr=4.48166e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54372
2023-02-21 04:21:57 - progress_bar.py[line:274] - INFO: epoch 001:  18194 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.91, wpb=112.8, bsz=40, num_updates=18170, lr=4.48129e-05, gnorm=0.147, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54383
2023-02-21 04:22:08 - progress_bar.py[line:274] - INFO: epoch 001:  18204 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.8, ups=0.95, wpb=111.7, bsz=40, num_updates=18180, lr=4.48093e-05, gnorm=0.058, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54394
2023-02-21 04:22:19 - progress_bar.py[line:274] - INFO: epoch 001:  18214 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.91, wpb=113.1, bsz=40, num_updates=18190, lr=4.48057e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54405
2023-02-21 04:22:30 - progress_bar.py[line:274] - INFO: epoch 001:  18224 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=110.7, bsz=40, num_updates=18200, lr=4.48021e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54416
2023-02-21 04:22:41 - progress_bar.py[line:274] - INFO: epoch 001:  18234 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.91, wpb=112.9, bsz=40, num_updates=18210, lr=4.47985e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54427
2023-02-21 04:22:52 - progress_bar.py[line:274] - INFO: epoch 001:  18244 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.8, bsz=40, num_updates=18220, lr=4.47948e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54438
2023-02-21 04:23:03 - progress_bar.py[line:274] - INFO: epoch 001:  18254 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=112.3, bsz=40, num_updates=18230, lr=4.47912e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54449
2023-02-21 04:23:14 - progress_bar.py[line:274] - INFO: epoch 001:  18264 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.91, wpb=112.9, bsz=40, num_updates=18240, lr=4.47876e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54460
2023-02-21 04:23:25 - progress_bar.py[line:274] - INFO: epoch 001:  18274 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.7, bsz=40, num_updates=18250, lr=4.4784e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54472
2023-02-21 04:23:36 - progress_bar.py[line:274] - INFO: epoch 001:  18284 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.3, bsz=40, num_updates=18260, lr=4.47804e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=54483
2023-02-21 04:23:47 - progress_bar.py[line:274] - INFO: epoch 001:  18294 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.7, bsz=40, num_updates=18270, lr=4.47768e-05, gnorm=0.173, clip=0, loss_scale=2048, train_wall=11, gb_free=10, ema_decay=0.9999, wall=54494
2023-02-21 04:23:58 - progress_bar.py[line:274] - INFO: epoch 001:  18304 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.6, bsz=40, num_updates=18280, lr=4.47731e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54505
2023-02-21 04:24:10 - progress_bar.py[line:274] - INFO: epoch 001:  18314 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.6, bsz=40, num_updates=18290, lr=4.47695e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54516
2023-02-21 04:24:20 - progress_bar.py[line:274] - INFO: epoch 001:  18324 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112, bsz=40, num_updates=18300, lr=4.47659e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54527
2023-02-21 04:24:31 - progress_bar.py[line:274] - INFO: epoch 001:  18334 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.3, bsz=40, num_updates=18310, lr=4.47623e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54538
2023-02-21 04:24:43 - progress_bar.py[line:274] - INFO: epoch 001:  18344 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=112.6, bsz=40, num_updates=18320, lr=4.47587e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=54549
2023-02-21 04:24:54 - progress_bar.py[line:274] - INFO: epoch 001:  18354 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.3, bsz=40, num_updates=18330, lr=4.4755e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54560
2023-02-21 04:25:05 - progress_bar.py[line:274] - INFO: epoch 001:  18364 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.6, bsz=40, num_updates=18340, lr=4.47514e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54571
2023-02-21 04:25:16 - progress_bar.py[line:274] - INFO: epoch 001:  18374 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=110.9, bsz=40, num_updates=18350, lr=4.47478e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54582
2023-02-21 04:25:27 - progress_bar.py[line:274] - INFO: epoch 001:  18384 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.4, bsz=40, num_updates=18360, lr=4.47442e-05, gnorm=0.113, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54593
2023-02-21 04:25:38 - progress_bar.py[line:274] - INFO: epoch 001:  18394 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.4, bsz=40, num_updates=18370, lr=4.47406e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54604
2023-02-21 04:25:49 - progress_bar.py[line:274] - INFO: epoch 001:  18404 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.8, bsz=40, num_updates=18380, lr=4.4737e-05, gnorm=0.145, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54616
2023-02-21 04:26:00 - progress_bar.py[line:274] - INFO: epoch 001:  18414 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.9, ups=0.93, wpb=111.4, bsz=40, num_updates=18390, lr=4.47333e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54626
2023-02-21 04:26:03 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 04:26:11 - progress_bar.py[line:274] - INFO: epoch 001:  18425 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.86, wpb=111.2, bsz=40, num_updates=18400, lr=4.47297e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=54638
2023-02-21 04:26:23 - progress_bar.py[line:274] - INFO: epoch 001:  18435 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.5, bsz=40, num_updates=18410, lr=4.47261e-05, gnorm=0.063, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=54649
2023-02-21 04:26:34 - progress_bar.py[line:274] - INFO: epoch 001:  18445 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.2, bsz=40, num_updates=18420, lr=4.47225e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54660
2023-02-21 04:26:45 - progress_bar.py[line:274] - INFO: epoch 001:  18455 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.91, wpb=109.1, bsz=40, num_updates=18430, lr=4.47189e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54671
2023-02-21 04:26:56 - progress_bar.py[line:274] - INFO: epoch 001:  18465 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112.8, bsz=40, num_updates=18440, lr=4.47152e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54682
2023-02-21 04:27:07 - progress_bar.py[line:274] - INFO: epoch 001:  18475 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=110.7, bsz=40, num_updates=18450, lr=4.47116e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54693
2023-02-21 04:27:18 - progress_bar.py[line:274] - INFO: epoch 001:  18485 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.88, wpb=108.7, bsz=40, num_updates=18460, lr=4.4708e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54705
2023-02-21 04:27:29 - progress_bar.py[line:274] - INFO: epoch 001:  18495 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.8, bsz=40, num_updates=18470, lr=4.47044e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54716
2023-02-21 04:27:41 - progress_bar.py[line:274] - INFO: epoch 001:  18505 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=113.4, nsentences=40, sample_size=113.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.9, wpb=113.4, bsz=40, num_updates=18480, lr=4.47008e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=54727
2023-02-21 04:27:52 - progress_bar.py[line:274] - INFO: epoch 001:  18515 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.2, bsz=40, num_updates=18490, lr=4.46972e-05, gnorm=0.149, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54738
2023-02-21 04:28:03 - progress_bar.py[line:274] - INFO: epoch 001:  18525 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.2, bsz=40, num_updates=18500, lr=4.46935e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=54749
2023-02-21 04:28:14 - progress_bar.py[line:274] - INFO: epoch 001:  18535 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.2, bsz=40, num_updates=18510, lr=4.46899e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54760
2023-02-21 04:28:25 - progress_bar.py[line:274] - INFO: epoch 001:  18545 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=111.1, bsz=40, num_updates=18520, lr=4.46863e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54771
2023-02-21 04:28:36 - progress_bar.py[line:274] - INFO: epoch 001:  18555 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=112, bsz=40, num_updates=18530, lr=4.46827e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54783
2023-02-21 04:28:47 - progress_bar.py[line:274] - INFO: epoch 001:  18565 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.93, wpb=110.6, bsz=40, num_updates=18540, lr=4.46791e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54793
2023-02-21 04:28:58 - progress_bar.py[line:274] - INFO: epoch 001:  18575 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.4, bsz=40, num_updates=18550, lr=4.46754e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54805
2023-02-21 04:29:09 - progress_bar.py[line:274] - INFO: epoch 001:  18585 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.3, bsz=40, num_updates=18560, lr=4.46718e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=54815
2023-02-21 04:29:20 - progress_bar.py[line:274] - INFO: epoch 001:  18595 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.4, bsz=40, num_updates=18570, lr=4.46682e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54826
2023-02-21 04:29:31 - progress_bar.py[line:274] - INFO: epoch 001:  18605 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.92, wpb=111.9, bsz=40, num_updates=18580, lr=4.46646e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54837
2023-02-21 04:29:42 - progress_bar.py[line:274] - INFO: epoch 001:  18615 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.3, bsz=40, num_updates=18590, lr=4.4661e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54848
2023-02-21 04:29:53 - progress_bar.py[line:274] - INFO: epoch 001:  18625 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.8, bsz=40, num_updates=18600, lr=4.46574e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54859
2023-02-21 04:30:04 - progress_bar.py[line:274] - INFO: epoch 001:  18635 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.5, bsz=40, num_updates=18610, lr=4.46537e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54870
2023-02-21 04:30:15 - progress_bar.py[line:274] - INFO: epoch 001:  18645 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.4, ups=0.87, wpb=111.6, bsz=40, num_updates=18620, lr=4.46501e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54882
2023-02-21 04:30:27 - progress_bar.py[line:274] - INFO: epoch 001:  18655 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=113.1, bsz=40, num_updates=18630, lr=4.46465e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54893
2023-02-21 04:30:38 - progress_bar.py[line:274] - INFO: epoch 001:  18665 / 71012 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.8, bsz=40, num_updates=18640, lr=4.46429e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54904
2023-02-21 04:30:49 - progress_bar.py[line:274] - INFO: epoch 001:  18675 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.2, bsz=40, num_updates=18650, lr=4.46393e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54915
2023-02-21 04:31:00 - progress_bar.py[line:274] - INFO: epoch 001:  18685 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.5, bsz=40, num_updates=18660, lr=4.46356e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54926
2023-02-21 04:31:11 - progress_bar.py[line:274] - INFO: epoch 001:  18695 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.9, wpb=112.3, bsz=40, num_updates=18670, lr=4.4632e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54937
2023-02-21 04:31:22 - progress_bar.py[line:274] - INFO: epoch 001:  18705 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.6, bsz=40, num_updates=18680, lr=4.46284e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54949
2023-02-21 04:31:33 - progress_bar.py[line:274] - INFO: epoch 001:  18715 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.8, bsz=40, num_updates=18690, lr=4.46248e-05, gnorm=0.159, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54960
2023-02-21 04:31:44 - progress_bar.py[line:274] - INFO: epoch 001:  18725 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.3, bsz=40, num_updates=18700, lr=4.46212e-05, gnorm=0.132, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54971
2023-02-21 04:31:55 - progress_bar.py[line:274] - INFO: epoch 001:  18735 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=18710, lr=4.46176e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54982
2023-02-21 04:32:06 - progress_bar.py[line:274] - INFO: epoch 001:  18745 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=112.7, bsz=40, num_updates=18720, lr=4.46139e-05, gnorm=0.117, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54993
2023-02-21 04:32:18 - progress_bar.py[line:274] - INFO: epoch 001:  18755 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.2, bsz=40, num_updates=18730, lr=4.46103e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55004
2023-02-21 04:32:29 - progress_bar.py[line:274] - INFO: epoch 001:  18765 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.3, bsz=40, num_updates=18740, lr=4.46067e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55015
2023-02-21 04:32:39 - progress_bar.py[line:274] - INFO: epoch 001:  18775 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.92, wpb=112.3, bsz=40, num_updates=18750, lr=4.46031e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55026
2023-02-21 04:32:50 - progress_bar.py[line:274] - INFO: epoch 001:  18785 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.2, bsz=40, num_updates=18760, lr=4.45995e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55037
2023-02-21 04:33:02 - progress_bar.py[line:274] - INFO: epoch 001:  18795 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112.2, bsz=40, num_updates=18770, lr=4.45958e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55048
2023-02-21 04:33:13 - progress_bar.py[line:274] - INFO: epoch 001:  18805 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.5, bsz=40, num_updates=18780, lr=4.45922e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55059
2023-02-21 04:33:24 - progress_bar.py[line:274] - INFO: epoch 001:  18815 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=111, bsz=40, num_updates=18790, lr=4.45886e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55071
2023-02-21 04:33:35 - progress_bar.py[line:274] - INFO: epoch 001:  18825 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=18800, lr=4.4585e-05, gnorm=0.156, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=55082
2023-02-21 04:33:46 - progress_bar.py[line:274] - INFO: epoch 001:  18835 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112, bsz=40, num_updates=18810, lr=4.45814e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55093
2023-02-21 04:33:57 - progress_bar.py[line:274] - INFO: epoch 001:  18845 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112, bsz=40, num_updates=18820, lr=4.45778e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=55104
2023-02-21 04:34:08 - progress_bar.py[line:274] - INFO: epoch 001:  18855 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=109.8, bsz=40, num_updates=18830, lr=4.45741e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55115
2023-02-21 04:34:20 - progress_bar.py[line:274] - INFO: epoch 001:  18865 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.89, wpb=109.7, bsz=40, num_updates=18840, lr=4.45705e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=55126
2023-02-21 04:34:31 - progress_bar.py[line:274] - INFO: epoch 001:  18875 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.1, bsz=40, num_updates=18850, lr=4.45669e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55137
2023-02-21 04:34:42 - progress_bar.py[line:274] - INFO: epoch 001:  18885 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.9, wpb=113.1, bsz=40, num_updates=18860, lr=4.45633e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55148
2023-02-21 04:34:53 - progress_bar.py[line:274] - INFO: epoch 001:  18895 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.92, wpb=113, bsz=40, num_updates=18870, lr=4.45597e-05, gnorm=0.136, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55159
2023-02-21 04:35:03 - progress_bar.py[line:274] - INFO: epoch 001:  18905 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.1, bsz=40, num_updates=18880, lr=4.4556e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55170
2023-02-21 04:35:14 - progress_bar.py[line:274] - INFO: epoch 001:  18915 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.92, wpb=113, bsz=40, num_updates=18890, lr=4.45524e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55181
2023-02-21 04:35:25 - progress_bar.py[line:274] - INFO: epoch 001:  18925 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.92, wpb=111.6, bsz=40, num_updates=18900, lr=4.45488e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55191
2023-02-21 04:35:36 - progress_bar.py[line:274] - INFO: epoch 001:  18935 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.88, wpb=112.7, bsz=40, num_updates=18910, lr=4.45452e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55203
2023-02-21 04:35:48 - progress_bar.py[line:274] - INFO: epoch 001:  18945 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.6, bsz=40, num_updates=18920, lr=4.45416e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55214
2023-02-21 04:35:59 - progress_bar.py[line:274] - INFO: epoch 001:  18955 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.9, wpb=110.4, bsz=40, num_updates=18930, lr=4.4538e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55225
2023-02-21 04:36:10 - progress_bar.py[line:274] - INFO: epoch 001:  18965 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=18940, lr=4.45343e-05, gnorm=0.115, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55236
2023-02-21 04:36:21 - progress_bar.py[line:274] - INFO: epoch 001:  18975 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.4, bsz=40, num_updates=18950, lr=4.45307e-05, gnorm=0.131, clip=0, loss_scale=4096, train_wall=11, gb_free=10, ema_decay=0.9999, wall=55248
2023-02-21 04:36:33 - progress_bar.py[line:274] - INFO: epoch 001:  18985 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=18960, lr=4.45271e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55259
2023-02-21 04:36:44 - progress_bar.py[line:274] - INFO: epoch 001:  18995 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.3, bsz=40, num_updates=18970, lr=4.45235e-05, gnorm=0.113, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=55270
2023-02-21 04:36:55 - progress_bar.py[line:274] - INFO: epoch 001:  19005 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.4, bsz=40, num_updates=18980, lr=4.45199e-05, gnorm=0.171, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55282
2023-02-21 04:37:07 - progress_bar.py[line:274] - INFO: epoch 001:  19015 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.2, bsz=40, num_updates=18990, lr=4.45162e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55293
2023-02-21 04:37:18 - progress_bar.py[line:274] - INFO: epoch 001:  19025 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=111, bsz=40, num_updates=19000, lr=4.45126e-05, gnorm=0.14, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55304
2023-02-21 04:37:29 - progress_bar.py[line:274] - INFO: epoch 001:  19035 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.4, bsz=40, num_updates=19010, lr=4.4509e-05, gnorm=0.116, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55315
2023-02-21 04:37:40 - progress_bar.py[line:274] - INFO: epoch 001:  19045 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.6, nsentences=40, sample_size=113.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.91, wpb=113.6, bsz=40, num_updates=19020, lr=4.45054e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55326
2023-02-21 04:37:51 - progress_bar.py[line:274] - INFO: epoch 001:  19055 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.88, wpb=111.3, bsz=40, num_updates=19030, lr=4.45018e-05, gnorm=0.179, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=55338
2023-02-21 04:38:02 - progress_bar.py[line:274] - INFO: epoch 001:  19065 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=109.9, bsz=40, num_updates=19040, lr=4.44982e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=55349
2023-02-21 04:38:13 - progress_bar.py[line:274] - INFO: epoch 001:  19075 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.8, bsz=40, num_updates=19050, lr=4.44945e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55360
2023-02-21 04:38:25 - progress_bar.py[line:274] - INFO: epoch 001:  19085 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.8, ups=0.89, wpb=110.4, bsz=40, num_updates=19060, lr=4.44909e-05, gnorm=0.147, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=55371
2023-02-21 04:38:36 - progress_bar.py[line:274] - INFO: epoch 001:  19095 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.2, bsz=40, num_updates=19070, lr=4.44873e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55382
2023-02-21 04:38:47 - progress_bar.py[line:274] - INFO: epoch 001:  19105 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.5, bsz=40, num_updates=19080, lr=4.44837e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55393
2023-02-21 04:38:58 - progress_bar.py[line:274] - INFO: epoch 001:  19115 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.6, bsz=40, num_updates=19090, lr=4.44801e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55405
2023-02-21 04:39:09 - progress_bar.py[line:274] - INFO: epoch 001:  19125 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.5, ups=0.93, wpb=112.7, bsz=40, num_updates=19100, lr=4.44764e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55415
2023-02-21 04:39:20 - progress_bar.py[line:274] - INFO: epoch 001:  19135 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=105.2, ups=0.94, wpb=112.5, bsz=40, num_updates=19110, lr=4.44728e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55426
2023-02-21 04:39:31 - progress_bar.py[line:274] - INFO: epoch 001:  19145 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.8, bsz=40, num_updates=19120, lr=4.44692e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55437
2023-02-21 04:39:42 - progress_bar.py[line:274] - INFO: epoch 001:  19155 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.1, bsz=40, num_updates=19130, lr=4.44656e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55448
2023-02-21 04:39:53 - progress_bar.py[line:274] - INFO: epoch 001:  19165 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.7, bsz=40, num_updates=19140, lr=4.4462e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55459
2023-02-21 04:40:04 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 04:40:05 - progress_bar.py[line:274] - INFO: epoch 001:  19176 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.2, ups=0.82, wpb=112.2, bsz=40, num_updates=19150, lr=4.44584e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=55472
2023-02-21 04:40:16 - progress_bar.py[line:274] - INFO: epoch 001:  19186 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.5, bsz=40, num_updates=19160, lr=4.44547e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55483
2023-02-21 04:40:27 - progress_bar.py[line:274] - INFO: epoch 001:  19196 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.4, bsz=40, num_updates=19170, lr=4.44511e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55494
2023-02-21 04:40:39 - progress_bar.py[line:274] - INFO: epoch 001:  19206 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.7, bsz=40, num_updates=19180, lr=4.44475e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55505
2023-02-21 04:40:50 - progress_bar.py[line:274] - INFO: epoch 001:  19216 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.2, bsz=40, num_updates=19190, lr=4.44439e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55516
2023-02-21 04:41:01 - progress_bar.py[line:274] - INFO: epoch 001:  19226 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=113, bsz=40, num_updates=19200, lr=4.44403e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55527
2023-02-21 04:41:12 - progress_bar.py[line:274] - INFO: epoch 001:  19236 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.1, bsz=40, num_updates=19210, lr=4.44366e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55539
2023-02-21 04:41:23 - progress_bar.py[line:274] - INFO: epoch 001:  19246 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=104, ups=0.93, wpb=111.4, bsz=40, num_updates=19220, lr=4.4433e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55549
2023-02-21 04:41:34 - progress_bar.py[line:274] - INFO: epoch 001:  19256 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.3, bsz=40, num_updates=19230, lr=4.44294e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55561
2023-02-21 04:41:45 - progress_bar.py[line:274] - INFO: epoch 001:  19266 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=113, bsz=40, num_updates=19240, lr=4.44258e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55572
2023-02-21 04:41:57 - progress_bar.py[line:274] - INFO: epoch 001:  19276 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.9, wpb=109.5, bsz=40, num_updates=19250, lr=4.44222e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55583
2023-02-21 04:42:08 - progress_bar.py[line:274] - INFO: epoch 001:  19286 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.9, bsz=40, num_updates=19260, lr=4.44186e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55594
2023-02-21 04:42:19 - progress_bar.py[line:274] - INFO: epoch 001:  19296 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=19270, lr=4.44149e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55605
2023-02-21 04:42:30 - progress_bar.py[line:274] - INFO: epoch 001:  19306 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.6, bsz=40, num_updates=19280, lr=4.44113e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55616
2023-02-21 04:42:41 - progress_bar.py[line:274] - INFO: epoch 001:  19316 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.5, bsz=40, num_updates=19290, lr=4.44077e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55628
2023-02-21 04:42:53 - progress_bar.py[line:274] - INFO: epoch 001:  19326 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=111, bsz=40, num_updates=19300, lr=4.44041e-05, gnorm=0.132, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=55639
2023-02-21 04:43:04 - progress_bar.py[line:274] - INFO: epoch 001:  19336 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112, bsz=40, num_updates=19310, lr=4.44005e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55650
2023-02-21 04:43:15 - progress_bar.py[line:274] - INFO: epoch 001:  19346 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.9, bsz=40, num_updates=19320, lr=4.43968e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55661
2023-02-21 04:43:26 - progress_bar.py[line:274] - INFO: epoch 001:  19356 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=112.7, bsz=40, num_updates=19330, lr=4.43932e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55672
2023-02-21 04:43:37 - progress_bar.py[line:274] - INFO: epoch 001:  19366 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.3, bsz=40, num_updates=19340, lr=4.43896e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55684
2023-02-21 04:43:48 - progress_bar.py[line:274] - INFO: epoch 001:  19376 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=111.9, bsz=40, num_updates=19350, lr=4.4386e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55695
2023-02-21 04:44:00 - progress_bar.py[line:274] - INFO: epoch 001:  19386 / 71012 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.5, bsz=40, num_updates=19360, lr=4.43824e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55706
2023-02-21 04:44:11 - progress_bar.py[line:274] - INFO: epoch 001:  19396 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.4, bsz=40, num_updates=19370, lr=4.43788e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55717
2023-02-21 04:44:22 - progress_bar.py[line:274] - INFO: epoch 001:  19406 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.1, bsz=40, num_updates=19380, lr=4.43751e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55729
2023-02-21 04:44:33 - progress_bar.py[line:274] - INFO: epoch 001:  19416 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.4, bsz=40, num_updates=19390, lr=4.43715e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55740
2023-02-21 04:44:45 - progress_bar.py[line:274] - INFO: epoch 001:  19426 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.4, bsz=40, num_updates=19400, lr=4.43679e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55751
2023-02-21 04:44:56 - progress_bar.py[line:274] - INFO: epoch 001:  19436 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.9, bsz=40, num_updates=19410, lr=4.43643e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55762
2023-02-21 04:45:06 - progress_bar.py[line:274] - INFO: epoch 001:  19446 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.93, wpb=110, bsz=40, num_updates=19420, lr=4.43607e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55773
2023-02-21 04:45:18 - progress_bar.py[line:274] - INFO: epoch 001:  19456 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=98.7, ups=0.89, wpb=111.2, bsz=40, num_updates=19430, lr=4.4357e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55784
2023-02-21 04:45:29 - progress_bar.py[line:274] - INFO: epoch 001:  19466 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=110.9, bsz=40, num_updates=19440, lr=4.43534e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55795
2023-02-21 04:45:39 - progress_bar.py[line:274] - INFO: epoch 001:  19476 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.8, ups=0.95, wpb=110.2, bsz=40, num_updates=19450, lr=4.43498e-05, gnorm=0.141, clip=0, loss_scale=2048, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=55806
2023-02-21 04:45:50 - progress_bar.py[line:274] - INFO: epoch 001:  19486 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=112.2, bsz=40, num_updates=19460, lr=4.43462e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55817
2023-02-21 04:46:02 - progress_bar.py[line:274] - INFO: epoch 001:  19496 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.6, bsz=40, num_updates=19470, lr=4.43426e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55828
2023-02-21 04:46:13 - progress_bar.py[line:274] - INFO: epoch 001:  19506 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=111.9, bsz=40, num_updates=19480, lr=4.4339e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55839
2023-02-21 04:46:24 - progress_bar.py[line:274] - INFO: epoch 001:  19516 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.8, bsz=40, num_updates=19490, lr=4.43353e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55850
2023-02-21 04:46:35 - progress_bar.py[line:274] - INFO: epoch 001:  19526 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111, bsz=40, num_updates=19500, lr=4.43317e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55861
2023-02-21 04:46:46 - progress_bar.py[line:274] - INFO: epoch 001:  19536 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.93, wpb=111.3, bsz=40, num_updates=19510, lr=4.43281e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55872
2023-02-21 04:46:57 - progress_bar.py[line:274] - INFO: epoch 001:  19546 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.92, wpb=112.2, bsz=40, num_updates=19520, lr=4.43245e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55883
2023-02-21 04:47:07 - progress_bar.py[line:274] - INFO: epoch 001:  19556 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.94, wpb=110.5, bsz=40, num_updates=19530, lr=4.43209e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55894
2023-02-21 04:47:18 - progress_bar.py[line:274] - INFO: epoch 001:  19566 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.3, bsz=40, num_updates=19540, lr=4.43172e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55905
2023-02-21 04:47:29 - progress_bar.py[line:274] - INFO: epoch 001:  19576 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.3, bsz=40, num_updates=19550, lr=4.43136e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=55916
2023-02-21 04:47:41 - progress_bar.py[line:274] - INFO: epoch 001:  19586 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112, bsz=40, num_updates=19560, lr=4.431e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=55927
2023-02-21 04:47:51 - progress_bar.py[line:274] - INFO: epoch 001:  19596 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.3, bsz=40, num_updates=19570, lr=4.43064e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55938
2023-02-21 04:48:03 - progress_bar.py[line:274] - INFO: epoch 001:  19606 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.5, bsz=40, num_updates=19580, lr=4.43028e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55949
2023-02-21 04:48:14 - progress_bar.py[line:274] - INFO: epoch 001:  19616 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=112.1, bsz=40, num_updates=19590, lr=4.42992e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=55960
2023-02-21 04:48:25 - progress_bar.py[line:274] - INFO: epoch 001:  19626 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=112.1, bsz=40, num_updates=19600, lr=4.42955e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55972
2023-02-21 04:48:36 - progress_bar.py[line:274] - INFO: epoch 001:  19636 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.5, bsz=40, num_updates=19610, lr=4.42919e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55983
2023-02-21 04:48:48 - progress_bar.py[line:274] - INFO: epoch 001:  19646 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.8, bsz=40, num_updates=19620, lr=4.42883e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55994
2023-02-21 04:48:59 - progress_bar.py[line:274] - INFO: epoch 001:  19656 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.2, bsz=40, num_updates=19630, lr=4.42847e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=56005
2023-02-21 04:49:10 - progress_bar.py[line:274] - INFO: epoch 001:  19666 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112.8, bsz=40, num_updates=19640, lr=4.42811e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56016
2023-02-21 04:49:21 - progress_bar.py[line:274] - INFO: epoch 001:  19676 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.4, bsz=40, num_updates=19650, lr=4.42774e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56028
2023-02-21 04:49:32 - progress_bar.py[line:274] - INFO: epoch 001:  19686 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.6, bsz=40, num_updates=19660, lr=4.42738e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=56039
2023-02-21 04:49:44 - progress_bar.py[line:274] - INFO: epoch 001:  19696 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111, bsz=40, num_updates=19670, lr=4.42702e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56050
2023-02-21 04:49:55 - progress_bar.py[line:274] - INFO: epoch 001:  19706 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.5, bsz=40, num_updates=19680, lr=4.42666e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=56061
2023-02-21 04:50:06 - progress_bar.py[line:274] - INFO: epoch 001:  19716 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=110.6, bsz=40, num_updates=19690, lr=4.4263e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56072
2023-02-21 04:50:17 - progress_bar.py[line:274] - INFO: epoch 001:  19726 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111, bsz=40, num_updates=19700, lr=4.42594e-05, gnorm=0.121, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56084
2023-02-21 04:50:28 - progress_bar.py[line:274] - INFO: epoch 001:  19736 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=102.9, ups=0.91, wpb=113.1, bsz=40, num_updates=19710, lr=4.42557e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56095
2023-02-21 04:50:39 - progress_bar.py[line:274] - INFO: epoch 001:  19746 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=99.9, ups=0.9, wpb=111.4, bsz=40, num_updates=19720, lr=4.42521e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=56106
2023-02-21 04:50:51 - progress_bar.py[line:274] - INFO: epoch 001:  19756 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=19730, lr=4.42485e-05, gnorm=0.13, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56117
2023-02-21 04:51:01 - progress_bar.py[line:274] - INFO: epoch 001:  19766 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.94, wpb=110.5, bsz=40, num_updates=19740, lr=4.42449e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56128
2023-02-21 04:51:12 - progress_bar.py[line:274] - INFO: epoch 001:  19776 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.5, ups=0.94, wpb=111.6, bsz=40, num_updates=19750, lr=4.42413e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56138
2023-02-21 04:51:23 - progress_bar.py[line:274] - INFO: epoch 001:  19786 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=113.5, nsentences=40, sample_size=113.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.1, ups=0.93, wpb=113.5, bsz=40, num_updates=19760, lr=4.42376e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56149
2023-02-21 04:51:28 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 04:51:34 - progress_bar.py[line:274] - INFO: epoch 001:  19797 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.5, ups=0.84, wpb=112.1, bsz=40, num_updates=19770, lr=4.4234e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=56161
2023-02-21 04:51:45 - progress_bar.py[line:274] - INFO: epoch 001:  19807 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.92, wpb=112.6, bsz=40, num_updates=19780, lr=4.42304e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56172
2023-02-21 04:51:57 - progress_bar.py[line:274] - INFO: epoch 001:  19817 / 71012 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.8, bsz=40, num_updates=19790, lr=4.42268e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56183
2023-02-21 04:52:08 - progress_bar.py[line:274] - INFO: epoch 001:  19827 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.3, bsz=40, num_updates=19800, lr=4.42232e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56194
2023-02-21 04:52:18 - progress_bar.py[line:274] - INFO: epoch 001:  19837 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=107.2, ups=0.96, wpb=111.3, bsz=40, num_updates=19810, lr=4.42196e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=56204
2023-02-21 04:52:29 - progress_bar.py[line:274] - INFO: epoch 001:  19847 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.9, wpb=113.1, bsz=40, num_updates=19820, lr=4.42159e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56216
2023-02-21 04:52:41 - progress_bar.py[line:274] - INFO: epoch 001:  19857 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=110.9, bsz=40, num_updates=19830, lr=4.42123e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56227
2023-02-21 04:52:52 - progress_bar.py[line:274] - INFO: epoch 001:  19867 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.3, bsz=40, num_updates=19840, lr=4.42087e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56238
2023-02-21 04:53:03 - progress_bar.py[line:274] - INFO: epoch 001:  19877 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.3, bsz=40, num_updates=19850, lr=4.42051e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56249
2023-02-21 04:53:14 - progress_bar.py[line:274] - INFO: epoch 001:  19887 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111.6, bsz=40, num_updates=19860, lr=4.42015e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=56261
2023-02-21 04:53:25 - progress_bar.py[line:274] - INFO: epoch 001:  19897 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=110.9, bsz=40, num_updates=19870, lr=4.41978e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56272
2023-02-21 04:53:37 - progress_bar.py[line:274] - INFO: epoch 001:  19907 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=112, bsz=40, num_updates=19880, lr=4.41942e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56283
2023-02-21 04:53:47 - progress_bar.py[line:274] - INFO: epoch 001:  19917 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.5, ups=0.92, wpb=113.1, bsz=40, num_updates=19890, lr=4.41906e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56294
2023-02-21 04:53:59 - progress_bar.py[line:274] - INFO: epoch 001:  19927 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.2, bsz=40, num_updates=19900, lr=4.4187e-05, gnorm=0.148, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56305
2023-02-21 04:54:10 - progress_bar.py[line:274] - INFO: epoch 001:  19937 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.2, bsz=40, num_updates=19910, lr=4.41834e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56316
2023-02-21 04:54:21 - progress_bar.py[line:274] - INFO: epoch 001:  19947 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=111.8, bsz=40, num_updates=19920, lr=4.41798e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56327
2023-02-21 04:54:32 - progress_bar.py[line:274] - INFO: epoch 001:  19957 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.3, bsz=40, num_updates=19930, lr=4.41761e-05, gnorm=0.056, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56338
2023-02-21 04:54:42 - progress_bar.py[line:274] - INFO: epoch 001:  19967 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.5, ups=0.95, wpb=110.5, bsz=40, num_updates=19940, lr=4.41725e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=56349
2023-02-21 04:54:53 - progress_bar.py[line:274] - INFO: epoch 001:  19977 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.2, bsz=40, num_updates=19950, lr=4.41689e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56360
2023-02-21 04:55:05 - progress_bar.py[line:274] - INFO: epoch 001:  19987 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.5, bsz=40, num_updates=19960, lr=4.41653e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56371
2023-02-21 04:55:16 - progress_bar.py[line:274] - INFO: epoch 001:  19997 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=112, bsz=40, num_updates=19970, lr=4.41617e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=56382
2023-02-21 04:55:27 - progress_bar.py[line:274] - INFO: epoch 001:  20007 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=111.9, bsz=40, num_updates=19980, lr=4.4158e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=56393
2023-02-21 04:55:38 - progress_bar.py[line:274] - INFO: epoch 001:  20017 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.8, ups=0.93, wpb=111.1, bsz=40, num_updates=19990, lr=4.41544e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=56404
2023-02-21 04:55:49 - progress_bar.py[line:274] - INFO: epoch 001:  20027 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.9, ups=0.87, wpb=110.9, bsz=40, num_updates=20000, lr=4.41508e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=56415
2023-02-21 04:55:49 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 04:55:50 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 04:55:50 - train.py[line:551] - INFO: load:0.97 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 04:57:52 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 04:57:52 - train.py[line:551] - INFO: load:1.00 valid_run:121.61 task_valid:118.76 collect_output:1.76
2023-02-21 04:59:51 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 04:59:51 - train.py[line:551] - INFO: load:1.02 valid_run:240.78 task_valid:234.13 collect_output:4.55
2023-02-21 05:01:52 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 05:01:52 - train.py[line:551] - INFO: load:1.05 valid_run:362.05 task_valid:350.27 collect_output:8.62
2023-02-21 05:03:54 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 05:03:54 - train.py[line:551] - INFO: load:1.08 valid_run:483.18 task_valid:463.64 collect_output:15.35
2023-02-21 05:05:53 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 05:05:53 - train.py[line:551] - INFO: load:1.10 valid_run:602.89 task_valid:580.42 collect_output:17.27
2023-02-21 05:07:56 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 05:07:56 - train.py[line:551] - INFO: load:1.13 valid_run:725.20 task_valid:698.69 collect_output:20.27
2023-02-21 05:09:58 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 05:09:58 - train.py[line:551] - INFO: load:1.16 valid_run:847.49 task_valid:816.43 collect_output:23.78
2023-02-21 05:11:59 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 05:11:59 - train.py[line:551] - INFO: load:1.18 valid_run:968.54 task_valid:932.45 collect_output:27.78
2023-02-21 05:14:02 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 05:14:02 - train.py[line:551] - INFO: load:1.21 valid_run:1091.46 task_valid:1049.20 collect_output:32.94
2023-02-21 05:16:03 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 05:16:03 - train.py[line:551] - INFO: load:1.23 valid_run:1212.39 task_valid:1161.41 collect_output:40.61
2023-02-21 05:18:03 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 05:18:03 - train.py[line:551] - INFO: load:1.26 valid_run:1331.91 task_valid:1276.50 collect_output:44.03
2023-02-21 05:20:04 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 05:20:04 - train.py[line:551] - INFO: load:1.29 valid_run:1452.86 task_valid:1392.98 collect_output:47.47
2023-02-21 05:22:02 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 05:22:02 - train.py[line:551] - INFO: load:1.32 valid_run:1571.22 task_valid:1506.33 collect_output:51.45
2023-02-21 05:24:03 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 05:24:03 - train.py[line:551] - INFO: load:1.34 valid_run:1691.54 task_valid:1623.64 collect_output:53.44
2023-02-21 05:26:03 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 05:26:03 - train.py[line:551] - INFO: load:1.37 valid_run:1811.81 task_valid:1739.35 collect_output:56.98
2023-02-21 05:28:03 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 05:28:03 - train.py[line:551] - INFO: load:1.39 valid_run:1932.15 task_valid:1852.78 collect_output:62.83
2023-02-21 05:30:04 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 05:30:04 - train.py[line:551] - INFO: load:1.42 valid_run:2052.74 task_valid:1968.43 collect_output:66.75
2023-02-21 05:32:04 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 05:32:04 - train.py[line:551] - INFO: load:1.45 valid_run:2172.80 task_valid:2085.83 collect_output:68.38
2023-02-21 05:34:05 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 05:34:05 - train.py[line:551] - INFO: load:1.47 valid_run:2293.43 task_valid:2202.38 collect_output:71.45
2023-02-21 05:36:05 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 05:36:05 - train.py[line:551] - INFO: load:1.50 valid_run:2413.18 task_valid:2318.57 collect_output:73.98
2023-02-21 05:38:06 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 05:38:06 - train.py[line:551] - INFO: load:1.52 valid_run:2534.09 task_valid:2434.64 collect_output:77.79
2023-02-21 05:40:07 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 05:40:07 - train.py[line:551] - INFO: load:1.55 valid_run:2655.40 task_valid:2553.10 collect_output:79.62
2023-02-21 05:42:07 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 05:42:07 - train.py[line:551] - INFO: load:1.58 valid_run:2774.94 task_valid:2666.90 collect_output:84.35
2023-02-21 05:44:06 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 05:44:06 - train.py[line:551] - INFO: load:1.60 valid_run:2894.05 task_valid:2782.63 collect_output:86.72
2023-02-21 05:46:07 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 05:46:07 - train.py[line:551] - INFO: load:1.63 valid_run:3015.00 task_valid:2898.45 collect_output:90.80
2023-02-21 05:48:09 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 05:48:09 - train.py[line:551] - INFO: load:1.65 valid_run:3136.97 task_valid:3014.04 collect_output:96.16
2023-02-21 05:50:08 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 05:50:08 - train.py[line:551] - INFO: load:1.68 valid_run:3255.93 task_valid:3127.81 collect_output:100.34
2023-02-21 05:52:09 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 05:52:09 - train.py[line:551] - INFO: load:1.71 valid_run:3377.24 task_valid:3246.77 collect_output:101.67
2023-02-21 05:54:10 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 05:54:10 - train.py[line:551] - INFO: load:1.73 valid_run:3498.20 task_valid:3361.84 collect_output:106.54
2023-02-21 05:56:12 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 05:56:12 - train.py[line:551] - INFO: load:1.76 valid_run:3619.47 task_valid:3479.86 collect_output:108.78
2023-02-21 05:58:12 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 05:58:12 - train.py[line:551] - INFO: load:1.78 valid_run:3740.14 task_valid:3598.00 collect_output:110.27

====================================================================================================
SGG eval:     R @ 50: 0.5900;     R @ 100: 0.6237;     R @ 500: 0.6477;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3675;    mR @ 100: 0.4100;    mR @ 500: 0.4692;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.7500) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3387) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9314) (says:0.0000) (sitting on:0.6735) (standing on:0.3493) (using:0.5500) (walking in:0.0000) (walking on:0.6757) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-02-21 05:58:43 - train.py[line:487] - INFO: 0.6237481792717088

====================================================================================================
SGG eval:     R @ 50: 0.5900;     R @ 100: 0.6237;     R @ 500: 0.6477;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3675;    mR @ 100: 0.4100;    mR @ 500: 0.4692;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.7500) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3387) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9314) (says:0.0000) (sitting on:0.6735) (standing on:0.3493) (using:0.5500) (walking in:0.0000) (walking on:0.6757) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-02-21 05:58:43 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 05:58:43 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.231 | loss_v1 0 | loss_v2 0 | nll_loss 0.063 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.623748 | ppl 1.04 | vqa_score 0.4595 | wps 118.9 | wpb 72 | bsz 24 | num_updates 20000 | best_R@100 0.691462
2023-02-21 05:58:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 20000 updates
2023-02-21 05:58:43 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_20000.pt
2023-02-21 05:58:49 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_20000.pt
2023-02-21 05:58:51 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_20000.pt (epoch 1 @ 20000 updates, score 0.6237481792717088) (writing took 8.405211932957172 seconds)
2023-02-21 05:59:02 - progress_bar.py[line:274] - INFO: epoch 001:  20037 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=110.3, bsz=40, num_updates=20010, lr=4.41472e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60209
2023-02-21 05:59:14 - progress_bar.py[line:274] - INFO: epoch 001:  20047 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.7, bsz=40, num_updates=20020, lr=4.41436e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60220
2023-02-21 05:59:25 - progress_bar.py[line:274] - INFO: epoch 001:  20057 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.6, bsz=40, num_updates=20030, lr=4.414e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60231
2023-02-21 05:59:36 - progress_bar.py[line:274] - INFO: epoch 001:  20067 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.1, bsz=40, num_updates=20040, lr=4.41363e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60242
2023-02-21 05:59:46 - progress_bar.py[line:274] - INFO: epoch 001:  20077 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.5, bsz=40, num_updates=20050, lr=4.41327e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60253
2023-02-21 05:59:58 - progress_bar.py[line:274] - INFO: epoch 001:  20087 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=110.7, bsz=40, num_updates=20060, lr=4.41291e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60264
2023-02-21 06:00:09 - progress_bar.py[line:274] - INFO: epoch 001:  20097 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.9, ups=0.93, wpb=111.2, bsz=40, num_updates=20070, lr=4.41255e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60275
2023-02-21 06:00:20 - progress_bar.py[line:274] - INFO: epoch 001:  20107 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.2, bsz=40, num_updates=20080, lr=4.41219e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=60286
2023-02-21 06:00:31 - progress_bar.py[line:274] - INFO: epoch 001:  20117 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.2, bsz=40, num_updates=20090, lr=4.41182e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60297
2023-02-21 06:00:42 - progress_bar.py[line:274] - INFO: epoch 001:  20127 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.2, bsz=40, num_updates=20100, lr=4.41146e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60308
2023-02-21 06:00:53 - progress_bar.py[line:274] - INFO: epoch 001:  20137 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.4, bsz=40, num_updates=20110, lr=4.4111e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60319
2023-02-21 06:01:04 - progress_bar.py[line:274] - INFO: epoch 001:  20147 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.7, bsz=40, num_updates=20120, lr=4.41074e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60331
2023-02-21 06:01:16 - progress_bar.py[line:274] - INFO: epoch 001:  20157 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.1, bsz=40, num_updates=20130, lr=4.41038e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60342
2023-02-21 06:01:27 - progress_bar.py[line:274] - INFO: epoch 001:  20167 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=20140, lr=4.41002e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60353
2023-02-21 06:01:38 - progress_bar.py[line:274] - INFO: epoch 001:  20177 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.87, wpb=112.3, bsz=40, num_updates=20150, lr=4.40965e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60364
2023-02-21 06:01:49 - progress_bar.py[line:274] - INFO: epoch 001:  20187 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111, bsz=40, num_updates=20160, lr=4.40929e-05, gnorm=0.117, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60375
2023-02-21 06:02:00 - progress_bar.py[line:274] - INFO: epoch 001:  20197 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.7, bsz=40, num_updates=20170, lr=4.40893e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60387
2023-02-21 06:02:12 - progress_bar.py[line:274] - INFO: epoch 001:  20207 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=111.3, bsz=40, num_updates=20180, lr=4.40857e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60398
2023-02-21 06:02:23 - progress_bar.py[line:274] - INFO: epoch 001:  20217 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.1, bsz=40, num_updates=20190, lr=4.40821e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60409
2023-02-21 06:02:34 - progress_bar.py[line:274] - INFO: epoch 001:  20227 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.93, wpb=111.9, bsz=40, num_updates=20200, lr=4.40784e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60420
2023-02-21 06:02:44 - progress_bar.py[line:274] - INFO: epoch 001:  20237 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.94, wpb=110.4, bsz=40, num_updates=20210, lr=4.40748e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60431
2023-02-21 06:02:55 - progress_bar.py[line:274] - INFO: epoch 001:  20247 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.7, bsz=40, num_updates=20220, lr=4.40712e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60442
2023-02-21 06:03:07 - progress_bar.py[line:274] - INFO: epoch 001:  20257 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.87, wpb=112.5, bsz=40, num_updates=20230, lr=4.40676e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60453
2023-02-21 06:03:18 - progress_bar.py[line:274] - INFO: epoch 001:  20267 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111.1, bsz=40, num_updates=20240, lr=4.4064e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60465
2023-02-21 06:03:30 - progress_bar.py[line:274] - INFO: epoch 001:  20277 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=112.7, bsz=40, num_updates=20250, lr=4.40604e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60476
2023-02-21 06:03:41 - progress_bar.py[line:274] - INFO: epoch 001:  20287 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.6, bsz=40, num_updates=20260, lr=4.40567e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60487
2023-02-21 06:03:52 - progress_bar.py[line:274] - INFO: epoch 001:  20297 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=20270, lr=4.40531e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60498
2023-02-21 06:04:03 - progress_bar.py[line:274] - INFO: epoch 001:  20307 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.6, bsz=40, num_updates=20280, lr=4.40495e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60509
2023-02-21 06:04:14 - progress_bar.py[line:274] - INFO: epoch 001:  20317 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.6, bsz=40, num_updates=20290, lr=4.40459e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60520
2023-02-21 06:04:25 - progress_bar.py[line:274] - INFO: epoch 001:  20327 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.4, bsz=40, num_updates=20300, lr=4.40423e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=60532
2023-02-21 06:04:37 - progress_bar.py[line:274] - INFO: epoch 001:  20337 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.3, bsz=40, num_updates=20310, lr=4.40386e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60543
2023-02-21 06:04:48 - progress_bar.py[line:274] - INFO: epoch 001:  20347 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.1, bsz=40, num_updates=20320, lr=4.4035e-05, gnorm=0.112, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60554
2023-02-21 06:04:59 - progress_bar.py[line:274] - INFO: epoch 001:  20357 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=111.8, bsz=40, num_updates=20330, lr=4.40314e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60565
2023-02-21 06:05:10 - progress_bar.py[line:274] - INFO: epoch 001:  20367 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.6, bsz=40, num_updates=20340, lr=4.40278e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60576
2023-02-21 06:05:21 - progress_bar.py[line:274] - INFO: epoch 001:  20377 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.3, bsz=40, num_updates=20350, lr=4.40242e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60587
2023-02-21 06:05:32 - progress_bar.py[line:274] - INFO: epoch 001:  20387 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.4, bsz=40, num_updates=20360, lr=4.40206e-05, gnorm=0.13, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60598
2023-02-21 06:05:43 - progress_bar.py[line:274] - INFO: epoch 001:  20397 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=112, bsz=40, num_updates=20370, lr=4.40169e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=60609
2023-02-21 06:05:53 - progress_bar.py[line:274] - INFO: epoch 001:  20407 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.93, wpb=109, bsz=40, num_updates=20380, lr=4.40133e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=60620
2023-02-21 06:06:05 - progress_bar.py[line:274] - INFO: epoch 001:  20417 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.6, bsz=40, num_updates=20390, lr=4.40097e-05, gnorm=0.116, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=60631
2023-02-21 06:06:16 - progress_bar.py[line:274] - INFO: epoch 001:  20427 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.3, bsz=40, num_updates=20400, lr=4.40061e-05, gnorm=0.121, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60642
2023-02-21 06:06:24 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 06:06:28 - progress_bar.py[line:274] - INFO: epoch 001:  20438 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91.8, ups=0.82, wpb=111.9, bsz=40, num_updates=20410, lr=4.40025e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=60654
2023-02-21 06:06:39 - progress_bar.py[line:274] - INFO: epoch 001:  20448 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112.7, bsz=40, num_updates=20420, lr=4.39988e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=60666
2023-02-21 06:06:50 - progress_bar.py[line:274] - INFO: epoch 001:  20458 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.3, bsz=40, num_updates=20430, lr=4.39952e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=60677
2023-02-21 06:07:01 - progress_bar.py[line:274] - INFO: epoch 001:  20468 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=20440, lr=4.39916e-05, gnorm=0.153, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60688
2023-02-21 06:07:13 - progress_bar.py[line:274] - INFO: epoch 001:  20478 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.4, bsz=40, num_updates=20450, lr=4.3988e-05, gnorm=0.072, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=60699
2023-02-21 06:07:23 - progress_bar.py[line:274] - INFO: epoch 001:  20488 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.4, ups=0.95, wpb=111.3, bsz=40, num_updates=20460, lr=4.39844e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60710
2023-02-21 06:07:34 - progress_bar.py[line:274] - INFO: epoch 001:  20498 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.88, wpb=113.3, bsz=40, num_updates=20470, lr=4.39808e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60721
2023-02-21 06:07:45 - progress_bar.py[line:274] - INFO: epoch 001:  20508 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.3, bsz=40, num_updates=20480, lr=4.39771e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60732
2023-02-21 06:07:57 - progress_bar.py[line:274] - INFO: epoch 001:  20518 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.3, bsz=40, num_updates=20490, lr=4.39735e-05, gnorm=0.061, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=60743
2023-02-21 06:08:08 - progress_bar.py[line:274] - INFO: epoch 001:  20528 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.1, bsz=40, num_updates=20500, lr=4.39699e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60754
2023-02-21 06:08:19 - progress_bar.py[line:274] - INFO: epoch 001:  20538 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110.5, bsz=40, num_updates=20510, lr=4.39663e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=60765
2023-02-21 06:08:30 - progress_bar.py[line:274] - INFO: epoch 001:  20548 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.4, bsz=40, num_updates=20520, lr=4.39627e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=60776
2023-02-21 06:08:41 - progress_bar.py[line:274] - INFO: epoch 001:  20558 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.1, bsz=40, num_updates=20530, lr=4.3959e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60788
2023-02-21 06:08:52 - progress_bar.py[line:274] - INFO: epoch 001:  20568 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.7, bsz=40, num_updates=20540, lr=4.39554e-05, gnorm=0.159, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60798
2023-02-21 06:09:03 - progress_bar.py[line:274] - INFO: epoch 001:  20578 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.2, bsz=40, num_updates=20550, lr=4.39518e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60809
2023-02-21 06:09:14 - progress_bar.py[line:274] - INFO: epoch 001:  20588 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.7, bsz=40, num_updates=20560, lr=4.39482e-05, gnorm=0.144, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60821
2023-02-21 06:09:26 - progress_bar.py[line:274] - INFO: epoch 001:  20598 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.89, wpb=112.1, bsz=40, num_updates=20570, lr=4.39446e-05, gnorm=0.141, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=60832
2023-02-21 06:09:37 - progress_bar.py[line:274] - INFO: epoch 001:  20608 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.9, bsz=40, num_updates=20580, lr=4.3941e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60843
2023-02-21 06:09:48 - progress_bar.py[line:274] - INFO: epoch 001:  20618 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=111.9, bsz=40, num_updates=20590, lr=4.39373e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=60855
2023-02-21 06:09:59 - progress_bar.py[line:274] - INFO: epoch 001:  20628 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.1, bsz=40, num_updates=20600, lr=4.39337e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60866
2023-02-21 06:10:10 - progress_bar.py[line:274] - INFO: epoch 001:  20638 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.93, wpb=111.1, bsz=40, num_updates=20610, lr=4.39301e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60877
2023-02-21 06:10:21 - progress_bar.py[line:274] - INFO: epoch 001:  20648 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.9, bsz=40, num_updates=20620, lr=4.39265e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=60888
2023-02-21 06:10:32 - progress_bar.py[line:274] - INFO: epoch 001:  20658 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111.1, bsz=40, num_updates=20630, lr=4.39229e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=60899
2023-02-21 06:10:44 - progress_bar.py[line:274] - INFO: epoch 001:  20668 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.2, ups=0.87, wpb=111.1, bsz=40, num_updates=20640, lr=4.39192e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60910
2023-02-21 06:10:55 - progress_bar.py[line:274] - INFO: epoch 001:  20678 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.3, bsz=40, num_updates=20650, lr=4.39156e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60921
2023-02-21 06:11:06 - progress_bar.py[line:274] - INFO: epoch 001:  20688 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.7, bsz=40, num_updates=20660, lr=4.3912e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60932
2023-02-21 06:11:17 - progress_bar.py[line:274] - INFO: epoch 001:  20698 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.2, bsz=40, num_updates=20670, lr=4.39084e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60944
2023-02-21 06:11:29 - progress_bar.py[line:274] - INFO: epoch 001:  20708 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.7, bsz=40, num_updates=20680, lr=4.39048e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60955
2023-02-21 06:11:40 - progress_bar.py[line:274] - INFO: epoch 001:  20718 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.92, wpb=112.1, bsz=40, num_updates=20690, lr=4.39012e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60966
2023-02-21 06:11:51 - progress_bar.py[line:274] - INFO: epoch 001:  20728 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111, bsz=40, num_updates=20700, lr=4.38975e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60977
2023-02-21 06:12:02 - progress_bar.py[line:274] - INFO: epoch 001:  20738 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.5, bsz=40, num_updates=20710, lr=4.38939e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=60988
2023-02-21 06:12:13 - progress_bar.py[line:274] - INFO: epoch 001:  20748 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.1, bsz=40, num_updates=20720, lr=4.38903e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60999
2023-02-21 06:12:24 - progress_bar.py[line:274] - INFO: epoch 001:  20758 / 71012 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=101, ups=0.92, wpb=109.7, bsz=40, num_updates=20730, lr=4.38867e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61010
2023-02-21 06:12:35 - progress_bar.py[line:274] - INFO: epoch 001:  20768 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=111.4, bsz=40, num_updates=20740, lr=4.38831e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61022
2023-02-21 06:12:47 - progress_bar.py[line:274] - INFO: epoch 001:  20778 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=20750, lr=4.38794e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61033
2023-02-21 06:12:58 - progress_bar.py[line:274] - INFO: epoch 001:  20788 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.8, bsz=40, num_updates=20760, lr=4.38758e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61044
2023-02-21 06:13:09 - progress_bar.py[line:274] - INFO: epoch 001:  20798 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=112.7, bsz=40, num_updates=20770, lr=4.38722e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61056
2023-02-21 06:13:20 - progress_bar.py[line:274] - INFO: epoch 001:  20808 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.4, bsz=40, num_updates=20780, lr=4.38686e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61067
2023-02-21 06:13:32 - progress_bar.py[line:274] - INFO: epoch 001:  20818 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.7, bsz=40, num_updates=20790, lr=4.3865e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61078
2023-02-21 06:13:43 - progress_bar.py[line:274] - INFO: epoch 001:  20828 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.1, bsz=40, num_updates=20800, lr=4.38614e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=61089
2023-02-21 06:13:54 - progress_bar.py[line:274] - INFO: epoch 001:  20838 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111, bsz=40, num_updates=20810, lr=4.38577e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61100
2023-02-21 06:14:05 - progress_bar.py[line:274] - INFO: epoch 001:  20848 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=113.1, bsz=40, num_updates=20820, lr=4.38541e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61111
2023-02-21 06:14:16 - progress_bar.py[line:274] - INFO: epoch 001:  20858 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.5, bsz=40, num_updates=20830, lr=4.38505e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61122
2023-02-21 06:14:27 - progress_bar.py[line:274] - INFO: epoch 001:  20868 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=20840, lr=4.38469e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61134
2023-02-21 06:14:38 - progress_bar.py[line:274] - INFO: epoch 001:  20878 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.4, bsz=40, num_updates=20850, lr=4.38433e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61145
2023-02-21 06:14:49 - progress_bar.py[line:274] - INFO: epoch 001:  20888 / 71012 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.93, wpb=110.2, bsz=40, num_updates=20860, lr=4.38396e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61155
2023-02-21 06:15:00 - progress_bar.py[line:274] - INFO: epoch 001:  20898 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.9, bsz=40, num_updates=20870, lr=4.3836e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61166
2023-02-21 06:15:11 - progress_bar.py[line:274] - INFO: epoch 001:  20908 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=109.5, bsz=40, num_updates=20880, lr=4.38324e-05, gnorm=0.161, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61178
2023-02-21 06:15:22 - progress_bar.py[line:274] - INFO: epoch 001:  20918 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.9, bsz=40, num_updates=20890, lr=4.38288e-05, gnorm=0.214, clip=10, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61189
2023-02-21 06:15:33 - progress_bar.py[line:274] - INFO: epoch 001:  20928 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.9, wpb=112.5, bsz=40, num_updates=20900, lr=4.38252e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61200
2023-02-21 06:15:45 - progress_bar.py[line:274] - INFO: epoch 001:  20938 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.3, bsz=40, num_updates=20910, lr=4.38216e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61211
2023-02-21 06:15:55 - progress_bar.py[line:274] - INFO: epoch 001:  20948 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113.9, nsentences=40, sample_size=113.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.9, ups=0.92, wpb=113.9, bsz=40, num_updates=20920, lr=4.38179e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61222
2023-02-21 06:16:07 - progress_bar.py[line:274] - INFO: epoch 001:  20958 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111, bsz=40, num_updates=20930, lr=4.38143e-05, gnorm=0.128, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61233
2023-02-21 06:16:18 - progress_bar.py[line:274] - INFO: epoch 001:  20968 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112, bsz=40, num_updates=20940, lr=4.38107e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61244
2023-02-21 06:16:29 - progress_bar.py[line:274] - INFO: epoch 001:  20978 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=112, bsz=40, num_updates=20950, lr=4.38071e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61256
2023-02-21 06:16:40 - progress_bar.py[line:274] - INFO: epoch 001:  20988 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.9, ups=0.93, wpb=111.2, bsz=40, num_updates=20960, lr=4.38035e-05, gnorm=0.113, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61266
2023-02-21 06:16:51 - progress_bar.py[line:274] - INFO: epoch 001:  20998 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=20970, lr=4.37998e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61277
2023-02-21 06:17:02 - progress_bar.py[line:274] - INFO: epoch 001:  21008 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.5, bsz=40, num_updates=20980, lr=4.37962e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61289
2023-02-21 06:17:13 - progress_bar.py[line:274] - INFO: epoch 001:  21018 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.3, bsz=40, num_updates=20990, lr=4.37926e-05, gnorm=0.209, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61300
2023-02-21 06:17:25 - progress_bar.py[line:274] - INFO: epoch 001:  21028 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.3, bsz=40, num_updates=21000, lr=4.3789e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61311
2023-02-21 06:17:36 - progress_bar.py[line:274] - INFO: epoch 001:  21038 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.5, bsz=40, num_updates=21010, lr=4.37854e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61322
2023-02-21 06:17:47 - progress_bar.py[line:274] - INFO: epoch 001:  21048 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.4, ups=0.91, wpb=111.4, bsz=40, num_updates=21020, lr=4.37817e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61333
2023-02-21 06:17:58 - progress_bar.py[line:274] - INFO: epoch 001:  21058 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=112.5, bsz=40, num_updates=21030, lr=4.37781e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61345
2023-02-21 06:18:09 - progress_bar.py[line:274] - INFO: epoch 001:  21068 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.9, bsz=40, num_updates=21040, lr=4.37745e-05, gnorm=0.144, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61356
2023-02-21 06:18:20 - progress_bar.py[line:274] - INFO: epoch 001:  21078 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.9, bsz=40, num_updates=21050, lr=4.37709e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61367
2023-02-21 06:18:31 - progress_bar.py[line:274] - INFO: epoch 001:  21088 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.2, bsz=40, num_updates=21060, lr=4.37673e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61378
2023-02-21 06:18:42 - progress_bar.py[line:274] - INFO: epoch 001:  21098 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=103.8, ups=0.92, wpb=112.4, bsz=40, num_updates=21070, lr=4.37637e-05, gnorm=0.049, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61388
2023-02-21 06:18:53 - progress_bar.py[line:274] - INFO: epoch 001:  21108 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.3, bsz=40, num_updates=21080, lr=4.376e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=61400
2023-02-21 06:19:04 - progress_bar.py[line:274] - INFO: epoch 001:  21118 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.92, wpb=112.1, bsz=40, num_updates=21090, lr=4.37564e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=61410
2023-02-21 06:19:15 - progress_bar.py[line:274] - INFO: epoch 001:  21128 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.4, ups=0.9, wpb=111.8, bsz=40, num_updates=21100, lr=4.37528e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61422
2023-02-21 06:19:26 - progress_bar.py[line:274] - INFO: epoch 001:  21138 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.7, bsz=40, num_updates=21110, lr=4.37492e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61433
2023-02-21 06:19:38 - progress_bar.py[line:274] - INFO: epoch 001:  21148 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=110.9, bsz=40, num_updates=21120, lr=4.37456e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61444
2023-02-21 06:19:49 - progress_bar.py[line:274] - INFO: epoch 001:  21158 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.3, bsz=40, num_updates=21130, lr=4.37419e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61455
2023-02-21 06:20:00 - progress_bar.py[line:274] - INFO: epoch 001:  21168 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.8, bsz=40, num_updates=21140, lr=4.37383e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61466
2023-02-21 06:20:11 - progress_bar.py[line:274] - INFO: epoch 001:  21178 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.89, wpb=112.9, bsz=40, num_updates=21150, lr=4.37347e-05, gnorm=0.137, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61477
2023-02-21 06:20:22 - progress_bar.py[line:274] - INFO: epoch 001:  21188 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.1, bsz=40, num_updates=21160, lr=4.37311e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61488
2023-02-21 06:20:33 - progress_bar.py[line:274] - INFO: epoch 001:  21198 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.4, bsz=40, num_updates=21170, lr=4.37275e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61499
2023-02-21 06:20:44 - progress_bar.py[line:274] - INFO: epoch 001:  21208 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112.5, bsz=40, num_updates=21180, lr=4.37239e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61510
2023-02-21 06:20:55 - progress_bar.py[line:274] - INFO: epoch 001:  21218 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.89, wpb=113, bsz=40, num_updates=21190, lr=4.37202e-05, gnorm=0.145, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61522
2023-02-21 06:21:07 - progress_bar.py[line:274] - INFO: epoch 001:  21228 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=110.4, bsz=40, num_updates=21200, lr=4.37166e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61533
2023-02-21 06:21:18 - progress_bar.py[line:274] - INFO: epoch 001:  21238 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=112.1, bsz=40, num_updates=21210, lr=4.3713e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61544
2023-02-21 06:21:29 - progress_bar.py[line:274] - INFO: epoch 001:  21248 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.93, wpb=111, bsz=40, num_updates=21220, lr=4.37094e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61555
2023-02-21 06:21:40 - progress_bar.py[line:274] - INFO: epoch 001:  21258 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.2, bsz=40, num_updates=21230, lr=4.37058e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61566
2023-02-21 06:21:51 - progress_bar.py[line:274] - INFO: epoch 001:  21268 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.8, bsz=40, num_updates=21240, lr=4.37021e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=61577
2023-02-21 06:22:02 - progress_bar.py[line:274] - INFO: epoch 001:  21278 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.3, bsz=40, num_updates=21250, lr=4.36985e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=61589
2023-02-21 06:22:13 - progress_bar.py[line:274] - INFO: epoch 001:  21288 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.1, bsz=40, num_updates=21260, lr=4.36949e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61600
2023-02-21 06:22:24 - progress_bar.py[line:274] - INFO: epoch 001:  21298 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=111.9, bsz=40, num_updates=21270, lr=4.36913e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61611
2023-02-21 06:22:35 - progress_bar.py[line:274] - INFO: epoch 001:  21308 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=110.8, bsz=40, num_updates=21280, lr=4.36877e-05, gnorm=0.116, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61621
2023-02-21 06:22:46 - progress_bar.py[line:274] - INFO: epoch 001:  21318 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.3, bsz=40, num_updates=21290, lr=4.36841e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61633
2023-02-21 06:22:57 - progress_bar.py[line:274] - INFO: epoch 001:  21328 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=111.9, bsz=40, num_updates=21300, lr=4.36804e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=61644
2023-02-21 06:23:08 - progress_bar.py[line:274] - INFO: epoch 001:  21338 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=110.9, bsz=40, num_updates=21310, lr=4.36768e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61655
2023-02-21 06:23:20 - progress_bar.py[line:274] - INFO: epoch 001:  21348 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.4, bsz=40, num_updates=21320, lr=4.36732e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61666
2023-02-21 06:23:31 - progress_bar.py[line:274] - INFO: epoch 001:  21358 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.2, ups=0.91, wpb=111.4, bsz=40, num_updates=21330, lr=4.36696e-05, gnorm=0.135, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61677
2023-02-21 06:23:40 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 06:23:43 - progress_bar.py[line:274] - INFO: epoch 001:  21369 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91, ups=0.81, wpb=112.9, bsz=40, num_updates=21340, lr=4.3666e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=61690
2023-02-21 06:23:54 - progress_bar.py[line:274] - INFO: epoch 001:  21379 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.3, bsz=40, num_updates=21350, lr=4.36623e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61701
2023-02-21 06:24:05 - progress_bar.py[line:274] - INFO: epoch 001:  21389 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.7, bsz=40, num_updates=21360, lr=4.36587e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61712
2023-02-21 06:24:17 - progress_bar.py[line:274] - INFO: epoch 001:  21399 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=113.4, nsentences=40, sample_size=113.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.89, wpb=113.4, bsz=40, num_updates=21370, lr=4.36551e-05, gnorm=0.053, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61723
2023-02-21 06:24:28 - progress_bar.py[line:274] - INFO: epoch 001:  21409 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.8, bsz=40, num_updates=21380, lr=4.36515e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61734
2023-02-21 06:24:39 - progress_bar.py[line:274] - INFO: epoch 001:  21419 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.5, bsz=40, num_updates=21390, lr=4.36479e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61745
2023-02-21 06:24:50 - progress_bar.py[line:274] - INFO: epoch 001:  21429 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.4, bsz=40, num_updates=21400, lr=4.36443e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61756
2023-02-21 06:25:01 - progress_bar.py[line:274] - INFO: epoch 001:  21439 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.4, bsz=40, num_updates=21410, lr=4.36406e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61767
2023-02-21 06:25:12 - progress_bar.py[line:274] - INFO: epoch 001:  21449 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111, bsz=40, num_updates=21420, lr=4.3637e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61778
2023-02-21 06:25:23 - progress_bar.py[line:274] - INFO: epoch 001:  21459 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111.1, bsz=40, num_updates=21430, lr=4.36334e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61790
2023-02-21 06:25:34 - progress_bar.py[line:274] - INFO: epoch 001:  21469 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.3, bsz=40, num_updates=21440, lr=4.36298e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61801
2023-02-21 06:25:45 - progress_bar.py[line:274] - INFO: epoch 001:  21479 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.9, ups=0.93, wpb=112.3, bsz=40, num_updates=21450, lr=4.36262e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61811
2023-02-21 06:25:56 - progress_bar.py[line:274] - INFO: epoch 001:  21489 / 71012 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.6, bsz=40, num_updates=21460, lr=4.36225e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61822
2023-02-21 06:26:07 - progress_bar.py[line:274] - INFO: epoch 001:  21499 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=111.9, bsz=40, num_updates=21470, lr=4.36189e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61833
2023-02-21 06:26:18 - progress_bar.py[line:274] - INFO: epoch 001:  21509 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112, bsz=40, num_updates=21480, lr=4.36153e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61844
2023-02-21 06:26:29 - progress_bar.py[line:274] - INFO: epoch 001:  21519 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=113, bsz=40, num_updates=21490, lr=4.36117e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61856
2023-02-21 06:26:41 - progress_bar.py[line:274] - INFO: epoch 001:  21529 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.87, wpb=113.2, bsz=40, num_updates=21500, lr=4.36081e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61867
2023-02-21 06:26:52 - progress_bar.py[line:274] - INFO: epoch 001:  21539 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.5, bsz=40, num_updates=21510, lr=4.36045e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61878
2023-02-21 06:27:03 - progress_bar.py[line:274] - INFO: epoch 001:  21549 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.87, wpb=112.9, bsz=40, num_updates=21520, lr=4.36008e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61890
2023-02-21 06:27:14 - progress_bar.py[line:274] - INFO: epoch 001:  21559 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=112.5, bsz=40, num_updates=21530, lr=4.35972e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61901
2023-02-21 06:27:26 - progress_bar.py[line:274] - INFO: epoch 001:  21569 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.5, bsz=40, num_updates=21540, lr=4.35936e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61912
2023-02-21 06:27:37 - progress_bar.py[line:274] - INFO: epoch 001:  21579 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.1, bsz=40, num_updates=21550, lr=4.359e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61923
2023-02-21 06:27:48 - progress_bar.py[line:274] - INFO: epoch 001:  21589 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=21560, lr=4.35864e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61934
2023-02-21 06:28:00 - progress_bar.py[line:274] - INFO: epoch 001:  21599 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=110.7, bsz=40, num_updates=21570, lr=4.35827e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61946
2023-02-21 06:28:11 - progress_bar.py[line:274] - INFO: epoch 001:  21609 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.5, bsz=40, num_updates=21580, lr=4.35791e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61957
2023-02-21 06:28:22 - progress_bar.py[line:274] - INFO: epoch 001:  21619 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.2, bsz=40, num_updates=21590, lr=4.35755e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61968
2023-02-21 06:28:33 - progress_bar.py[line:274] - INFO: epoch 001:  21629 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=110.9, bsz=40, num_updates=21600, lr=4.35719e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61979
2023-02-21 06:28:44 - progress_bar.py[line:274] - INFO: epoch 001:  21639 / 71012 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.1, bsz=40, num_updates=21610, lr=4.35683e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=61990
2023-02-21 06:28:55 - progress_bar.py[line:274] - INFO: epoch 001:  21649 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.8, bsz=40, num_updates=21620, lr=4.35647e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62001
2023-02-21 06:29:06 - progress_bar.py[line:274] - INFO: epoch 001:  21659 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.1, bsz=40, num_updates=21630, lr=4.3561e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62013
2023-02-21 06:29:18 - progress_bar.py[line:274] - INFO: epoch 001:  21669 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=112.1, bsz=40, num_updates=21640, lr=4.35574e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62024
2023-02-21 06:29:29 - progress_bar.py[line:274] - INFO: epoch 001:  21679 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.2, bsz=40, num_updates=21650, lr=4.35538e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62035
2023-02-21 06:29:40 - progress_bar.py[line:274] - INFO: epoch 001:  21689 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=112.2, bsz=40, num_updates=21660, lr=4.35502e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62047
2023-02-21 06:29:51 - progress_bar.py[line:274] - INFO: epoch 001:  21699 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.2, bsz=40, num_updates=21670, lr=4.35466e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62058
2023-02-21 06:30:03 - progress_bar.py[line:274] - INFO: epoch 001:  21709 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112.5, bsz=40, num_updates=21680, lr=4.35429e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62069
2023-02-21 06:30:14 - progress_bar.py[line:274] - INFO: epoch 001:  21719 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=21690, lr=4.35393e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62080
2023-02-21 06:30:25 - progress_bar.py[line:274] - INFO: epoch 001:  21729 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.87, wpb=112.7, bsz=40, num_updates=21700, lr=4.35357e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62092
2023-02-21 06:30:36 - progress_bar.py[line:274] - INFO: epoch 001:  21739 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.9, wpb=111.1, bsz=40, num_updates=21710, lr=4.35321e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62103
2023-02-21 06:30:48 - progress_bar.py[line:274] - INFO: epoch 001:  21749 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.89, wpb=112.1, bsz=40, num_updates=21720, lr=4.35285e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62114
2023-02-21 06:30:59 - progress_bar.py[line:274] - INFO: epoch 001:  21759 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.92, wpb=112.1, bsz=40, num_updates=21730, lr=4.35249e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62125
2023-02-21 06:31:10 - progress_bar.py[line:274] - INFO: epoch 001:  21769 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.2, bsz=40, num_updates=21740, lr=4.35212e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62136
2023-02-21 06:31:21 - progress_bar.py[line:274] - INFO: epoch 001:  21779 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.9, wpb=110.2, bsz=40, num_updates=21750, lr=4.35176e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62147
2023-02-21 06:31:32 - progress_bar.py[line:274] - INFO: epoch 001:  21789 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.7, bsz=40, num_updates=21760, lr=4.3514e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62158
2023-02-21 06:31:43 - progress_bar.py[line:274] - INFO: epoch 001:  21799 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.8, bsz=40, num_updates=21770, lr=4.35104e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62170
2023-02-21 06:31:54 - progress_bar.py[line:274] - INFO: epoch 001:  21809 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.5, ups=0.91, wpb=113, bsz=40, num_updates=21780, lr=4.35068e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62181
2023-02-21 06:32:05 - progress_bar.py[line:274] - INFO: epoch 001:  21819 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.5, bsz=40, num_updates=21790, lr=4.35031e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62192
2023-02-21 06:32:17 - progress_bar.py[line:274] - INFO: epoch 001:  21829 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=21800, lr=4.34995e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62203
2023-02-21 06:32:28 - progress_bar.py[line:274] - INFO: epoch 001:  21839 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=21810, lr=4.34959e-05, gnorm=0.159, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62214
2023-02-21 06:32:39 - progress_bar.py[line:274] - INFO: epoch 001:  21849 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112.8, bsz=40, num_updates=21820, lr=4.34923e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62226
2023-02-21 06:32:51 - progress_bar.py[line:274] - INFO: epoch 001:  21859 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.4, bsz=40, num_updates=21830, lr=4.34887e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62237
2023-02-21 06:33:02 - progress_bar.py[line:274] - INFO: epoch 001:  21869 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99, ups=0.89, wpb=111.7, bsz=40, num_updates=21840, lr=4.34851e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62248
2023-02-21 06:33:13 - progress_bar.py[line:274] - INFO: epoch 001:  21879 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.7, bsz=40, num_updates=21850, lr=4.34814e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62260
2023-02-21 06:33:24 - progress_bar.py[line:274] - INFO: epoch 001:  21889 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.6, bsz=40, num_updates=21860, lr=4.34778e-05, gnorm=0.12, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62271
2023-02-21 06:33:36 - progress_bar.py[line:274] - INFO: epoch 001:  21899 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.87, wpb=112.7, bsz=40, num_updates=21870, lr=4.34742e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62282
2023-02-21 06:33:47 - progress_bar.py[line:274] - INFO: epoch 001:  21909 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110.7, bsz=40, num_updates=21880, lr=4.34706e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62294
2023-02-21 06:33:58 - progress_bar.py[line:274] - INFO: epoch 001:  21919 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=21890, lr=4.3467e-05, gnorm=0.13, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62305
2023-02-21 06:34:10 - progress_bar.py[line:274] - INFO: epoch 001:  21929 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=21900, lr=4.34633e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62316
2023-02-21 06:34:21 - progress_bar.py[line:274] - INFO: epoch 001:  21939 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=21910, lr=4.34597e-05, gnorm=0.137, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62327
2023-02-21 06:34:32 - progress_bar.py[line:274] - INFO: epoch 001:  21949 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.91, wpb=112.9, bsz=40, num_updates=21920, lr=4.34561e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62338
2023-02-21 06:34:43 - progress_bar.py[line:274] - INFO: epoch 001:  21959 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.1, bsz=40, num_updates=21930, lr=4.34525e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62350
2023-02-21 06:34:55 - progress_bar.py[line:274] - INFO: epoch 001:  21969 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.7, bsz=40, num_updates=21940, lr=4.34489e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62361
2023-02-21 06:35:06 - progress_bar.py[line:274] - INFO: epoch 001:  21979 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.1, bsz=40, num_updates=21950, lr=4.34453e-05, gnorm=0.119, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62372
2023-02-21 06:35:17 - progress_bar.py[line:274] - INFO: epoch 001:  21989 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.9, wpb=112.7, bsz=40, num_updates=21960, lr=4.34416e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62383
2023-02-21 06:35:28 - progress_bar.py[line:274] - INFO: epoch 001:  21999 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.5, bsz=40, num_updates=21970, lr=4.3438e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62394
2023-02-21 06:35:39 - progress_bar.py[line:274] - INFO: epoch 001:  22009 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112, bsz=40, num_updates=21980, lr=4.34344e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62405
2023-02-21 06:35:50 - progress_bar.py[line:274] - INFO: epoch 001:  22019 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.8, bsz=40, num_updates=21990, lr=4.34308e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62416
2023-02-21 06:36:01 - progress_bar.py[line:274] - INFO: epoch 001:  22029 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.3, bsz=40, num_updates=22000, lr=4.34272e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62427
2023-02-21 06:36:01 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 06:36:02 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 06:36:02 - train.py[line:551] - INFO: load:0.98 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 06:38:04 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 06:38:04 - train.py[line:551] - INFO: load:1.01 valid_run:121.65 task_valid:118.71 collect_output:1.89
2023-02-21 06:40:03 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 06:40:03 - train.py[line:551] - INFO: load:1.03 valid_run:240.91 task_valid:234.16 collect_output:4.64
2023-02-21 06:42:04 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 06:42:04 - train.py[line:551] - INFO: load:1.06 valid_run:362.26 task_valid:350.30 collect_output:8.80
2023-02-21 06:44:06 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 06:44:06 - train.py[line:551] - INFO: load:1.08 valid_run:483.42 task_valid:463.61 collect_output:15.62
2023-02-21 06:46:06 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 06:46:06 - train.py[line:551] - INFO: load:1.11 valid_run:603.30 task_valid:580.60 collect_output:17.46
2023-02-21 06:48:08 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 06:48:08 - train.py[line:551] - INFO: load:1.14 valid_run:725.57 task_valid:698.86 collect_output:20.43
2023-02-21 06:50:10 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 06:50:10 - train.py[line:551] - INFO: load:1.16 valid_run:847.82 task_valid:816.66 collect_output:23.85
2023-02-21 06:52:11 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 06:52:11 - train.py[line:551] - INFO: load:1.19 valid_run:968.98 task_valid:932.78 collect_output:27.86
2023-02-21 06:54:14 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 06:54:14 - train.py[line:551] - INFO: load:1.21 valid_run:1091.95 task_valid:1049.55 collect_output:33.03
2023-02-21 06:56:15 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 06:56:15 - train.py[line:551] - INFO: load:1.24 valid_run:1212.83 task_valid:1161.74 collect_output:40.68
2023-02-21 06:58:15 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 06:58:15 - train.py[line:551] - INFO: load:1.27 valid_run:1332.38 task_valid:1277.03 collect_output:43.90
2023-02-21 07:00:16 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 07:00:16 - train.py[line:551] - INFO: load:1.29 valid_run:1453.39 task_valid:1393.67 collect_output:47.23
2023-02-21 07:02:15 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 07:02:15 - train.py[line:551] - INFO: load:1.32 valid_run:1571.83 task_valid:1507.16 collect_output:51.16
2023-02-21 07:04:15 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 07:04:15 - train.py[line:551] - INFO: load:1.35 valid_run:1692.29 task_valid:1624.54 collect_output:53.20
2023-02-21 07:06:16 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 07:06:16 - train.py[line:551] - INFO: load:1.37 valid_run:1812.78 task_valid:1740.44 collect_output:56.77
2023-02-21 07:08:16 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 07:08:16 - train.py[line:551] - INFO: load:1.40 valid_run:1933.33 task_valid:1854.04 collect_output:62.68
2023-02-21 07:10:17 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 07:10:17 - train.py[line:551] - INFO: load:1.42 valid_run:2054.03 task_valid:1969.76 collect_output:66.65
2023-02-21 07:12:17 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 07:12:17 - train.py[line:551] - INFO: load:1.45 valid_run:2174.20 task_valid:2087.27 collect_output:68.29
2023-02-21 07:14:18 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 07:14:18 - train.py[line:551] - INFO: load:1.48 valid_run:2294.80 task_valid:2203.83 collect_output:71.32
2023-02-21 07:16:18 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 07:16:18 - train.py[line:551] - INFO: load:1.50 valid_run:2414.58 task_valid:2319.92 collect_output:74.00
2023-02-21 07:18:19 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 07:18:19 - train.py[line:551] - INFO: load:1.53 valid_run:2535.63 task_valid:2436.05 collect_output:77.89
2023-02-21 07:20:20 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 07:20:20 - train.py[line:551] - INFO: load:1.56 valid_run:2657.01 task_valid:2554.46 collect_output:79.84
2023-02-21 07:22:20 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 07:22:20 - train.py[line:551] - INFO: load:1.58 valid_run:2776.63 task_valid:2668.34 collect_output:84.55
2023-02-21 07:24:19 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 07:24:19 - train.py[line:551] - INFO: load:1.61 valid_run:2895.84 task_valid:2784.08 collect_output:87.00
2023-02-21 07:26:20 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 07:26:20 - train.py[line:551] - INFO: load:1.64 valid_run:3016.85 task_valid:2899.99 collect_output:91.07
2023-02-21 07:28:23 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 07:28:23 - train.py[line:551] - INFO: load:1.66 valid_run:3139.00 task_valid:3015.61 collect_output:96.56
2023-02-21 07:30:22 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 07:30:22 - train.py[line:551] - INFO: load:1.69 valid_run:3258.02 task_valid:3129.42 collect_output:100.72
2023-02-21 07:32:23 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 07:32:23 - train.py[line:551] - INFO: load:1.72 valid_run:3379.25 task_valid:3248.38 collect_output:101.97
2023-02-21 07:34:24 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 07:34:24 - train.py[line:551] - INFO: load:1.74 valid_run:3500.18 task_valid:3363.46 collect_output:106.78
2023-02-21 07:36:25 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 07:36:25 - train.py[line:551] - INFO: load:1.77 valid_run:3621.42 task_valid:3481.48 collect_output:108.99
2023-02-21 07:38:26 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 07:38:26 - train.py[line:551] - INFO: load:1.80 valid_run:3741.95 task_valid:3599.46 collect_output:110.49

====================================================================================================
SGG eval:     R @ 50: 0.5837;     R @ 100: 0.6179;     R @ 500: 0.6383;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3651;    mR @ 100: 0.4069;    mR @ 500: 0.4393;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.7500) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3710) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9314) (says:0.0000) (sitting on:0.6485) (standing on:0.3593) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-02-21 07:38:56 - train.py[line:487] - INFO: 0.6179148459383753

====================================================================================================
SGG eval:     R @ 50: 0.5837;     R @ 100: 0.6179;     R @ 500: 0.6383;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3651;    mR @ 100: 0.4069;    mR @ 500: 0.4393;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.7500) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3710) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9314) (says:0.0000) (sitting on:0.6485) (standing on:0.3593) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-02-21 07:38:56 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 07:38:56 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.233 | loss_v1 0 | loss_v2 0 | nll_loss 0.063 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.617915 | ppl 1.04 | vqa_score 0.4595 | wps 118.9 | wpb 72 | bsz 24 | num_updates 22000 | best_R@100 0.691462
2023-02-21 07:38:57 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 22000 updates
2023-02-21 07:38:57 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_22000.pt
2023-02-21 07:39:02 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_22000.pt
2023-02-21 07:39:05 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_22000.pt (epoch 1 @ 22000 updates, score 0.6179148459383753) (writing took 8.383459316566586 seconds)
2023-02-21 07:39:16 - progress_bar.py[line:274] - INFO: epoch 001:  22039 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=111.2, bsz=40, num_updates=22010, lr=4.34235e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66222
2023-02-21 07:39:27 - progress_bar.py[line:274] - INFO: epoch 001:  22049 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.1, bsz=40, num_updates=22020, lr=4.34199e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66233
2023-02-21 07:39:38 - progress_bar.py[line:274] - INFO: epoch 001:  22059 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=98.6, ups=0.89, wpb=111.4, bsz=40, num_updates=22030, lr=4.34163e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66244
2023-02-21 07:39:49 - progress_bar.py[line:274] - INFO: epoch 001:  22069 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=22040, lr=4.34127e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66256
2023-02-21 07:40:00 - progress_bar.py[line:274] - INFO: epoch 001:  22079 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.6, bsz=40, num_updates=22050, lr=4.34091e-05, gnorm=0.116, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66267
2023-02-21 07:40:11 - progress_bar.py[line:274] - INFO: epoch 001:  22089 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=22060, lr=4.34055e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66278
2023-02-21 07:40:22 - progress_bar.py[line:274] - INFO: epoch 001:  22099 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.9, wpb=112.9, bsz=40, num_updates=22070, lr=4.34018e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66289
2023-02-21 07:40:33 - progress_bar.py[line:274] - INFO: epoch 001:  22109 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105, ups=0.93, wpb=112.4, bsz=40, num_updates=22080, lr=4.33982e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66300
2023-02-21 07:40:44 - progress_bar.py[line:274] - INFO: epoch 001:  22119 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.91, wpb=112.9, bsz=40, num_updates=22090, lr=4.33946e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66311
2023-02-21 07:40:55 - progress_bar.py[line:274] - INFO: epoch 001:  22129 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112, bsz=40, num_updates=22100, lr=4.3391e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66322
2023-02-21 07:41:06 - progress_bar.py[line:274] - INFO: epoch 001:  22139 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112.1, bsz=40, num_updates=22110, lr=4.33874e-05, gnorm=0.123, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66333
2023-02-21 07:41:17 - progress_bar.py[line:274] - INFO: epoch 001:  22149 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.2, bsz=40, num_updates=22120, lr=4.33837e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66344
2023-02-21 07:41:28 - progress_bar.py[line:274] - INFO: epoch 001:  22159 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.2, ups=0.93, wpb=111.5, bsz=40, num_updates=22130, lr=4.33801e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66354
2023-02-21 07:41:39 - progress_bar.py[line:274] - INFO: epoch 001:  22169 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.8, bsz=40, num_updates=22140, lr=4.33765e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66365
2023-02-21 07:41:50 - progress_bar.py[line:274] - INFO: epoch 001:  22179 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.4, bsz=40, num_updates=22150, lr=4.33729e-05, gnorm=0.166, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66376
2023-02-21 07:42:01 - progress_bar.py[line:274] - INFO: epoch 001:  22189 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.3, bsz=40, num_updates=22160, lr=4.33693e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66387
2023-02-21 07:42:12 - progress_bar.py[line:274] - INFO: epoch 001:  22199 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.1, bsz=40, num_updates=22170, lr=4.33657e-05, gnorm=0.142, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66398
2023-02-21 07:42:23 - progress_bar.py[line:274] - INFO: epoch 001:  22209 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.1, bsz=40, num_updates=22180, lr=4.3362e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66409
2023-02-21 07:42:34 - progress_bar.py[line:274] - INFO: epoch 001:  22219 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.6, bsz=40, num_updates=22190, lr=4.33584e-05, gnorm=0.145, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66420
2023-02-21 07:42:45 - progress_bar.py[line:274] - INFO: epoch 001:  22229 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=111.3, bsz=40, num_updates=22200, lr=4.33548e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66432
2023-02-21 07:42:57 - progress_bar.py[line:274] - INFO: epoch 001:  22239 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113.5, nsentences=40, sample_size=113.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.89, wpb=113.5, bsz=40, num_updates=22210, lr=4.33512e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=66443
2023-02-21 07:43:08 - progress_bar.py[line:274] - INFO: epoch 001:  22249 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.2, bsz=40, num_updates=22220, lr=4.33476e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66454
2023-02-21 07:43:19 - progress_bar.py[line:274] - INFO: epoch 001:  22259 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=111.9, bsz=40, num_updates=22230, lr=4.33439e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66465
2023-02-21 07:43:30 - progress_bar.py[line:274] - INFO: epoch 001:  22269 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.6, bsz=40, num_updates=22240, lr=4.33403e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66477
2023-02-21 07:43:41 - progress_bar.py[line:274] - INFO: epoch 001:  22279 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=22250, lr=4.33367e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66488
2023-02-21 07:43:53 - progress_bar.py[line:274] - INFO: epoch 001:  22289 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=111, bsz=40, num_updates=22260, lr=4.33331e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66499
2023-02-21 07:44:04 - progress_bar.py[line:274] - INFO: epoch 001:  22299 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=110.4, bsz=40, num_updates=22270, lr=4.33295e-05, gnorm=0.152, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66510
2023-02-21 07:44:15 - progress_bar.py[line:274] - INFO: epoch 001:  22309 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.6, bsz=40, num_updates=22280, lr=4.33259e-05, gnorm=0.114, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66522
2023-02-21 07:44:26 - progress_bar.py[line:274] - INFO: epoch 001:  22319 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.4, bsz=40, num_updates=22290, lr=4.33222e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66533
2023-02-21 07:44:37 - progress_bar.py[line:274] - INFO: epoch 001:  22329 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.7, bsz=40, num_updates=22300, lr=4.33186e-05, gnorm=0.141, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66544
2023-02-21 07:44:48 - progress_bar.py[line:274] - INFO: epoch 001:  22339 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.8, bsz=40, num_updates=22310, lr=4.3315e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66555
2023-02-21 07:45:00 - progress_bar.py[line:274] - INFO: epoch 001:  22349 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.9, wpb=110.3, bsz=40, num_updates=22320, lr=4.33114e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66566
2023-02-21 07:45:11 - progress_bar.py[line:274] - INFO: epoch 001:  22359 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=111.6, bsz=40, num_updates=22330, lr=4.33078e-05, gnorm=0.115, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66577
2023-02-21 07:45:22 - progress_bar.py[line:274] - INFO: epoch 001:  22369 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.86, wpb=112.1, bsz=40, num_updates=22340, lr=4.33041e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=66589
2023-02-21 07:45:34 - progress_bar.py[line:274] - INFO: epoch 001:  22379 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=110.4, bsz=40, num_updates=22350, lr=4.33005e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66600
2023-02-21 07:45:44 - progress_bar.py[line:274] - INFO: epoch 001:  22389 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=105.5, ups=0.94, wpb=112.8, bsz=40, num_updates=22360, lr=4.32969e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66611
2023-02-21 07:45:55 - progress_bar.py[line:274] - INFO: epoch 001:  22399 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.1, ups=0.93, wpb=112.5, bsz=40, num_updates=22370, lr=4.32933e-05, gnorm=0.092, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66621
2023-02-21 07:46:05 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 07:46:07 - progress_bar.py[line:274] - INFO: epoch 001:  22410 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.2, ups=0.8, wpb=112.2, bsz=40, num_updates=22380, lr=4.32897e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=66634
2023-02-21 07:46:18 - progress_bar.py[line:274] - INFO: epoch 001:  22420 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.7, bsz=40, num_updates=22390, lr=4.32861e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=66645
2023-02-21 07:46:30 - progress_bar.py[line:274] - INFO: epoch 001:  22430 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.2, bsz=40, num_updates=22400, lr=4.32824e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=66656
2023-02-21 07:46:41 - progress_bar.py[line:274] - INFO: epoch 001:  22440 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=110.6, bsz=40, num_updates=22410, lr=4.32788e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66667
2023-02-21 07:46:52 - progress_bar.py[line:274] - INFO: epoch 001:  22450 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=112.7, bsz=40, num_updates=22420, lr=4.32752e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66678
2023-02-21 07:47:03 - progress_bar.py[line:274] - INFO: epoch 001:  22460 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.4, bsz=40, num_updates=22430, lr=4.32716e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66690
2023-02-21 07:47:14 - progress_bar.py[line:274] - INFO: epoch 001:  22470 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.93, wpb=111.1, bsz=40, num_updates=22440, lr=4.3268e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66700
2023-02-21 07:47:25 - progress_bar.py[line:274] - INFO: epoch 001:  22480 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.1, ups=0.92, wpb=112.9, bsz=40, num_updates=22450, lr=4.32643e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66711
2023-02-21 07:47:36 - progress_bar.py[line:274] - INFO: epoch 001:  22490 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.2, bsz=40, num_updates=22460, lr=4.32607e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=66723
2023-02-21 07:47:48 - progress_bar.py[line:274] - INFO: epoch 001:  22500 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.6, bsz=40, num_updates=22470, lr=4.32571e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66734
2023-02-21 07:47:59 - progress_bar.py[line:274] - INFO: epoch 001:  22510 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=110.2, bsz=40, num_updates=22480, lr=4.32535e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66745
2023-02-21 07:48:10 - progress_bar.py[line:274] - INFO: epoch 001:  22520 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.89, wpb=110.1, bsz=40, num_updates=22490, lr=4.32499e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66757
2023-02-21 07:48:21 - progress_bar.py[line:274] - INFO: epoch 001:  22530 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.9, bsz=40, num_updates=22500, lr=4.32463e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66768
2023-02-21 07:48:29 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 07:48:34 - progress_bar.py[line:274] - INFO: epoch 001:  22541 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91.9, ups=0.82, wpb=112, bsz=40, num_updates=22510, lr=4.32426e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=66780
2023-02-21 07:48:45 - progress_bar.py[line:274] - INFO: epoch 001:  22551 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.2, bsz=40, num_updates=22520, lr=4.3239e-05, gnorm=0.141, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66791
2023-02-21 07:48:56 - progress_bar.py[line:274] - INFO: epoch 001:  22561 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.5, bsz=40, num_updates=22530, lr=4.32354e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66802
2023-02-21 07:49:07 - progress_bar.py[line:274] - INFO: epoch 001:  22571 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.7, bsz=40, num_updates=22540, lr=4.32318e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66813
2023-02-21 07:49:18 - progress_bar.py[line:274] - INFO: epoch 001:  22581 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.5, bsz=40, num_updates=22550, lr=4.32282e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66824
2023-02-21 07:49:29 - progress_bar.py[line:274] - INFO: epoch 001:  22591 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.6, bsz=40, num_updates=22560, lr=4.32245e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66835
2023-02-21 07:49:40 - progress_bar.py[line:274] - INFO: epoch 001:  22601 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.5, bsz=40, num_updates=22570, lr=4.32209e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66846
2023-02-21 07:49:51 - progress_bar.py[line:274] - INFO: epoch 001:  22611 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.3, bsz=40, num_updates=22580, lr=4.32173e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66857
2023-02-21 07:50:03 - progress_bar.py[line:274] - INFO: epoch 001:  22621 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=22590, lr=4.32137e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=66869
2023-02-21 07:50:14 - progress_bar.py[line:274] - INFO: epoch 001:  22631 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112.3, bsz=40, num_updates=22600, lr=4.32101e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=66880
2023-02-21 07:50:25 - progress_bar.py[line:274] - INFO: epoch 001:  22641 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=111.5, bsz=40, num_updates=22610, lr=4.32065e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66891
2023-02-21 07:50:36 - progress_bar.py[line:274] - INFO: epoch 001:  22651 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.7, bsz=40, num_updates=22620, lr=4.32028e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66903
2023-02-21 07:50:47 - progress_bar.py[line:274] - INFO: epoch 001:  22661 / 71012 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=100, ups=0.9, wpb=111.4, bsz=40, num_updates=22630, lr=4.31992e-05, gnorm=0.058, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66914
2023-02-21 07:50:59 - progress_bar.py[line:274] - INFO: epoch 001:  22671 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.7, bsz=40, num_updates=22640, lr=4.31956e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66925
2023-02-21 07:51:09 - progress_bar.py[line:274] - INFO: epoch 001:  22681 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111, bsz=40, num_updates=22650, lr=4.3192e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66936
2023-02-21 07:51:20 - progress_bar.py[line:274] - INFO: epoch 001:  22691 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=110.8, bsz=40, num_updates=22660, lr=4.31884e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66947
2023-02-21 07:51:32 - progress_bar.py[line:274] - INFO: epoch 001:  22701 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.6, bsz=40, num_updates=22670, lr=4.31847e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66958
2023-02-21 07:51:43 - progress_bar.py[line:274] - INFO: epoch 001:  22711 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111, bsz=40, num_updates=22680, lr=4.31811e-05, gnorm=0.057, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66969
2023-02-21 07:51:54 - progress_bar.py[line:274] - INFO: epoch 001:  22721 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.9, wpb=110.3, bsz=40, num_updates=22690, lr=4.31775e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66980
2023-02-21 07:52:05 - progress_bar.py[line:274] - INFO: epoch 001:  22731 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=22700, lr=4.31739e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66991
2023-02-21 07:52:16 - progress_bar.py[line:274] - INFO: epoch 001:  22741 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.5, ups=0.94, wpb=112.6, bsz=40, num_updates=22710, lr=4.31703e-05, gnorm=0.06, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67002
2023-02-21 07:52:27 - progress_bar.py[line:274] - INFO: epoch 001:  22751 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=111.9, bsz=40, num_updates=22720, lr=4.31667e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67013
2023-02-21 07:52:38 - progress_bar.py[line:274] - INFO: epoch 001:  22761 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.5, nsentences=40, sample_size=113.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.92, wpb=113.5, bsz=40, num_updates=22730, lr=4.3163e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67024
2023-02-21 07:52:49 - progress_bar.py[line:274] - INFO: epoch 001:  22771 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.7, bsz=40, num_updates=22740, lr=4.31594e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67035
2023-02-21 07:53:00 - progress_bar.py[line:274] - INFO: epoch 001:  22781 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111, bsz=40, num_updates=22750, lr=4.31558e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67046
2023-02-21 07:53:11 - progress_bar.py[line:274] - INFO: epoch 001:  22791 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.89, wpb=112.7, bsz=40, num_updates=22760, lr=4.31522e-05, gnorm=0.158, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67058
2023-02-21 07:53:23 - progress_bar.py[line:274] - INFO: epoch 001:  22801 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.2, bsz=40, num_updates=22770, lr=4.31486e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67069
2023-02-21 07:53:34 - progress_bar.py[line:274] - INFO: epoch 001:  22811 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.4, bsz=40, num_updates=22780, lr=4.31449e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67080
2023-02-21 07:53:45 - progress_bar.py[line:274] - INFO: epoch 001:  22821 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.4, bsz=40, num_updates=22790, lr=4.31413e-05, gnorm=0.051, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67091
2023-02-21 07:53:56 - progress_bar.py[line:274] - INFO: epoch 001:  22831 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.2, bsz=40, num_updates=22800, lr=4.31377e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67103
2023-02-21 07:54:07 - progress_bar.py[line:274] - INFO: epoch 001:  22841 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.9, bsz=40, num_updates=22810, lr=4.31341e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67114
2023-02-21 07:54:18 - progress_bar.py[line:274] - INFO: epoch 001:  22851 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.92, wpb=112.4, bsz=40, num_updates=22820, lr=4.31305e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67125
2023-02-21 07:54:29 - progress_bar.py[line:274] - INFO: epoch 001:  22861 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=22830, lr=4.31269e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67136
2023-02-21 07:54:41 - progress_bar.py[line:274] - INFO: epoch 001:  22871 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.3, bsz=40, num_updates=22840, lr=4.31232e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67147
2023-02-21 07:54:51 - progress_bar.py[line:274] - INFO: epoch 001:  22881 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.3, ups=0.93, wpb=113.2, bsz=40, num_updates=22850, lr=4.31196e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67158
2023-02-21 07:55:03 - progress_bar.py[line:274] - INFO: epoch 001:  22891 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.1, bsz=40, num_updates=22860, lr=4.3116e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67169
2023-02-21 07:55:14 - progress_bar.py[line:274] - INFO: epoch 001:  22901 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.88, wpb=113, bsz=40, num_updates=22870, lr=4.31124e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67180
2023-02-21 07:55:25 - progress_bar.py[line:274] - INFO: epoch 001:  22911 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.1, bsz=40, num_updates=22880, lr=4.31088e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67191
2023-02-21 07:55:36 - progress_bar.py[line:274] - INFO: epoch 001:  22921 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.3, bsz=40, num_updates=22890, lr=4.31051e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67203
2023-02-21 07:55:47 - progress_bar.py[line:274] - INFO: epoch 001:  22931 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=112.9, bsz=40, num_updates=22900, lr=4.31015e-05, gnorm=0.147, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67214
2023-02-21 07:55:58 - progress_bar.py[line:274] - INFO: epoch 001:  22941 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.8, ups=0.91, wpb=111.8, bsz=40, num_updates=22910, lr=4.30979e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67225
2023-02-21 07:56:09 - progress_bar.py[line:274] - INFO: epoch 001:  22951 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.93, wpb=111.2, bsz=40, num_updates=22920, lr=4.30943e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67235
2023-02-21 07:56:20 - progress_bar.py[line:274] - INFO: epoch 001:  22961 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.2, bsz=40, num_updates=22930, lr=4.30907e-05, gnorm=0.07, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67246
2023-02-21 07:56:31 - progress_bar.py[line:274] - INFO: epoch 001:  22971 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=22940, lr=4.30871e-05, gnorm=0.051, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67257
2023-02-21 07:56:42 - progress_bar.py[line:274] - INFO: epoch 001:  22981 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.3, bsz=40, num_updates=22950, lr=4.30834e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67269
2023-02-21 07:56:53 - progress_bar.py[line:274] - INFO: epoch 001:  22991 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.8, bsz=40, num_updates=22960, lr=4.30798e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67280
2023-02-21 07:57:05 - progress_bar.py[line:274] - INFO: epoch 001:  23001 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.9, bsz=40, num_updates=22970, lr=4.30762e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67291
2023-02-21 07:57:16 - progress_bar.py[line:274] - INFO: epoch 001:  23011 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111, bsz=40, num_updates=22980, lr=4.30726e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67302
2023-02-21 07:57:27 - progress_bar.py[line:274] - INFO: epoch 001:  23021 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.88, wpb=112.8, bsz=40, num_updates=22990, lr=4.3069e-05, gnorm=0.059, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67313
2023-02-21 07:57:38 - progress_bar.py[line:274] - INFO: epoch 001:  23031 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=110.8, bsz=40, num_updates=23000, lr=4.30653e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67325
2023-02-21 07:57:50 - progress_bar.py[line:274] - INFO: epoch 001:  23041 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.86, wpb=111.6, bsz=40, num_updates=23010, lr=4.30617e-05, gnorm=0.056, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=67336
2023-02-21 07:58:01 - progress_bar.py[line:274] - INFO: epoch 001:  23051 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.87, wpb=110.9, bsz=40, num_updates=23020, lr=4.30581e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67348
2023-02-21 07:58:12 - progress_bar.py[line:274] - INFO: epoch 001:  23061 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.92, wpb=113.2, bsz=40, num_updates=23030, lr=4.30545e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67358
2023-02-21 07:58:23 - progress_bar.py[line:274] - INFO: epoch 001:  23071 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=23040, lr=4.30509e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67370
2023-02-21 07:58:34 - progress_bar.py[line:274] - INFO: epoch 001:  23081 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.8, ups=0.93, wpb=112.2, bsz=40, num_updates=23050, lr=4.30473e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67380
2023-02-21 07:58:45 - progress_bar.py[line:274] - INFO: epoch 001:  23091 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.5, bsz=40, num_updates=23060, lr=4.30436e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67391
2023-02-21 07:58:56 - progress_bar.py[line:274] - INFO: epoch 001:  23101 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.92, wpb=112.9, bsz=40, num_updates=23070, lr=4.304e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67402
2023-02-21 07:59:07 - progress_bar.py[line:274] - INFO: epoch 001:  23111 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.9, bsz=40, num_updates=23080, lr=4.30364e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67413
2023-02-21 07:59:18 - progress_bar.py[line:274] - INFO: epoch 001:  23121 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=110.9, bsz=40, num_updates=23090, lr=4.30328e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67424
2023-02-21 07:59:29 - progress_bar.py[line:274] - INFO: epoch 001:  23131 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111, bsz=40, num_updates=23100, lr=4.30292e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67436
2023-02-21 07:59:39 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 07:59:42 - progress_bar.py[line:274] - INFO: epoch 001:  23142 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91, ups=0.82, wpb=110.6, bsz=40, num_updates=23110, lr=4.30255e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=67448
2023-02-21 07:59:53 - progress_bar.py[line:274] - INFO: epoch 001:  23152 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111.1, bsz=40, num_updates=23120, lr=4.30219e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67459
2023-02-21 08:00:04 - progress_bar.py[line:274] - INFO: epoch 001:  23162 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.87, wpb=112.3, bsz=40, num_updates=23130, lr=4.30183e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67471
2023-02-21 08:00:16 - progress_bar.py[line:274] - INFO: epoch 001:  23172 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.9, bsz=40, num_updates=23140, lr=4.30147e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67482
2023-02-21 08:00:27 - progress_bar.py[line:274] - INFO: epoch 001:  23182 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.8, bsz=40, num_updates=23150, lr=4.30111e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67493
2023-02-21 08:00:38 - progress_bar.py[line:274] - INFO: epoch 001:  23192 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.92, wpb=112.2, bsz=40, num_updates=23160, lr=4.30075e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67504
2023-02-21 08:00:49 - progress_bar.py[line:274] - INFO: epoch 001:  23202 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112.1, bsz=40, num_updates=23170, lr=4.30038e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67516
2023-02-21 08:01:00 - progress_bar.py[line:274] - INFO: epoch 001:  23212 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.6, bsz=40, num_updates=23180, lr=4.30002e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67527
2023-02-21 08:01:12 - progress_bar.py[line:274] - INFO: epoch 001:  23222 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.91, wpb=109.7, bsz=40, num_updates=23190, lr=4.29966e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67538
2023-02-21 08:01:22 - progress_bar.py[line:274] - INFO: epoch 001:  23232 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.92, wpb=113.2, bsz=40, num_updates=23200, lr=4.2993e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67549
2023-02-21 08:01:34 - progress_bar.py[line:274] - INFO: epoch 001:  23242 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.4, bsz=40, num_updates=23210, lr=4.29894e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67560
2023-02-21 08:01:44 - progress_bar.py[line:274] - INFO: epoch 001:  23252 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.9, ups=0.93, wpb=112.4, bsz=40, num_updates=23220, lr=4.29857e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67571
2023-02-21 08:01:56 - progress_bar.py[line:274] - INFO: epoch 001:  23262 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110.7, bsz=40, num_updates=23230, lr=4.29821e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67582
2023-02-21 08:02:07 - progress_bar.py[line:274] - INFO: epoch 001:  23272 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=110.9, bsz=40, num_updates=23240, lr=4.29785e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67593
2023-02-21 08:02:18 - progress_bar.py[line:274] - INFO: epoch 001:  23282 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=112, bsz=40, num_updates=23250, lr=4.29749e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67604
2023-02-21 08:02:29 - progress_bar.py[line:274] - INFO: epoch 001:  23292 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112.1, bsz=40, num_updates=23260, lr=4.29713e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67616
2023-02-21 08:02:40 - progress_bar.py[line:274] - INFO: epoch 001:  23302 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=23270, lr=4.29677e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67627
2023-02-21 08:02:51 - progress_bar.py[line:274] - INFO: epoch 001:  23312 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=23280, lr=4.2964e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67638
2023-02-21 08:03:03 - progress_bar.py[line:274] - INFO: epoch 001:  23322 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111, bsz=40, num_updates=23290, lr=4.29604e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67649
2023-02-21 08:03:14 - progress_bar.py[line:274] - INFO: epoch 001:  23332 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=112.1, bsz=40, num_updates=23300, lr=4.29568e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67660
2023-02-21 08:03:25 - progress_bar.py[line:274] - INFO: epoch 001:  23342 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.4, bsz=40, num_updates=23310, lr=4.29532e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67672
2023-02-21 08:03:36 - progress_bar.py[line:274] - INFO: epoch 001:  23352 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.5, bsz=40, num_updates=23320, lr=4.29496e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67683
2023-02-21 08:03:48 - progress_bar.py[line:274] - INFO: epoch 001:  23362 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.89, wpb=110.3, bsz=40, num_updates=23330, lr=4.29459e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67694
2023-02-21 08:03:59 - progress_bar.py[line:274] - INFO: epoch 001:  23372 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.91, wpb=111.8, bsz=40, num_updates=23340, lr=4.29423e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67705
2023-02-21 08:04:10 - progress_bar.py[line:274] - INFO: epoch 001:  23382 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.032, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=100, ups=0.9, wpb=111.4, bsz=40, num_updates=23350, lr=4.29387e-05, gnorm=0.052, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67716
2023-02-21 08:04:21 - progress_bar.py[line:274] - INFO: epoch 001:  23392 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.4, bsz=40, num_updates=23360, lr=4.29351e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67727
2023-02-21 08:04:32 - progress_bar.py[line:274] - INFO: epoch 001:  23402 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.87, wpb=112.7, bsz=40, num_updates=23370, lr=4.29315e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67739
2023-02-21 08:04:43 - progress_bar.py[line:274] - INFO: epoch 001:  23412 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.6, bsz=40, num_updates=23380, lr=4.29279e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=67750
2023-02-21 08:04:55 - progress_bar.py[line:274] - INFO: epoch 001:  23422 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=112.9, bsz=40, num_updates=23390, lr=4.29242e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67761
2023-02-21 08:05:06 - progress_bar.py[line:274] - INFO: epoch 001:  23432 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=112, bsz=40, num_updates=23400, lr=4.29206e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67772
2023-02-21 08:05:17 - progress_bar.py[line:274] - INFO: epoch 001:  23442 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.2, bsz=40, num_updates=23410, lr=4.2917e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67783
2023-02-21 08:05:29 - progress_bar.py[line:274] - INFO: epoch 001:  23452 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.3, bsz=40, num_updates=23420, lr=4.29134e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67795
2023-02-21 08:05:40 - progress_bar.py[line:274] - INFO: epoch 001:  23462 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.5, bsz=40, num_updates=23430, lr=4.29098e-05, gnorm=0.117, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67806
2023-02-21 08:05:51 - progress_bar.py[line:274] - INFO: epoch 001:  23472 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.7, bsz=40, num_updates=23440, lr=4.29061e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67817
2023-02-21 08:06:02 - progress_bar.py[line:274] - INFO: epoch 001:  23482 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.1, bsz=40, num_updates=23450, lr=4.29025e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67828
2023-02-21 08:06:13 - progress_bar.py[line:274] - INFO: epoch 001:  23492 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=110.9, bsz=40, num_updates=23460, lr=4.28989e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67840
2023-02-21 08:06:24 - progress_bar.py[line:274] - INFO: epoch 001:  23502 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.1, ups=0.92, wpb=112.8, bsz=40, num_updates=23470, lr=4.28953e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67850
2023-02-21 08:06:35 - progress_bar.py[line:274] - INFO: epoch 001:  23512 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.3, bsz=40, num_updates=23480, lr=4.28917e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67861
2023-02-21 08:06:46 - progress_bar.py[line:274] - INFO: epoch 001:  23522 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.7, bsz=40, num_updates=23490, lr=4.28881e-05, gnorm=0.07, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67872
2023-02-21 08:06:57 - progress_bar.py[line:274] - INFO: epoch 001:  23532 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=110.3, bsz=40, num_updates=23500, lr=4.28844e-05, gnorm=0.063, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67884
2023-02-21 08:07:08 - progress_bar.py[line:274] - INFO: epoch 001:  23542 / 71012 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.1, bsz=40, num_updates=23510, lr=4.28808e-05, gnorm=0.07, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67895
2023-02-21 08:07:20 - progress_bar.py[line:274] - INFO: epoch 001:  23552 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.2, bsz=40, num_updates=23520, lr=4.28772e-05, gnorm=0.142, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67906
2023-02-21 08:07:31 - progress_bar.py[line:274] - INFO: epoch 001:  23562 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.5, bsz=40, num_updates=23530, lr=4.28736e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67917
2023-02-21 08:07:42 - progress_bar.py[line:274] - INFO: epoch 001:  23572 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.4, bsz=40, num_updates=23540, lr=4.287e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67929
2023-02-21 08:07:54 - progress_bar.py[line:274] - INFO: epoch 001:  23582 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.89, wpb=110.5, bsz=40, num_updates=23550, lr=4.28663e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67940
2023-02-21 08:08:04 - progress_bar.py[line:274] - INFO: epoch 001:  23592 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.6, ups=0.95, wpb=111.5, bsz=40, num_updates=23560, lr=4.28627e-05, gnorm=0.065, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67951
2023-02-21 08:08:15 - progress_bar.py[line:274] - INFO: epoch 001:  23602 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=110.6, bsz=40, num_updates=23570, lr=4.28591e-05, gnorm=0.161, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67962
2023-02-21 08:08:27 - progress_bar.py[line:274] - INFO: epoch 001:  23612 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.9, bsz=40, num_updates=23580, lr=4.28555e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67973
2023-02-21 08:08:38 - progress_bar.py[line:274] - INFO: epoch 001:  23622 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.6, bsz=40, num_updates=23590, lr=4.28519e-05, gnorm=0.059, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67984
2023-02-21 08:08:49 - progress_bar.py[line:274] - INFO: epoch 001:  23632 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.7, bsz=40, num_updates=23600, lr=4.28483e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67995
2023-02-21 08:09:00 - progress_bar.py[line:274] - INFO: epoch 001:  23642 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=112.5, bsz=40, num_updates=23610, lr=4.28446e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68006
2023-02-21 08:09:11 - progress_bar.py[line:274] - INFO: epoch 001:  23652 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=110.5, bsz=40, num_updates=23620, lr=4.2841e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68018
2023-02-21 08:09:22 - progress_bar.py[line:274] - INFO: epoch 001:  23662 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=111.5, bsz=40, num_updates=23630, lr=4.28374e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68029
2023-02-21 08:09:33 - progress_bar.py[line:274] - INFO: epoch 001:  23672 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112.1, bsz=40, num_updates=23640, lr=4.28338e-05, gnorm=0.111, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68040
2023-02-21 08:09:44 - progress_bar.py[line:274] - INFO: epoch 001:  23682 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=111.8, bsz=40, num_updates=23650, lr=4.28302e-05, gnorm=0.122, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68051
2023-02-21 08:09:55 - progress_bar.py[line:274] - INFO: epoch 001:  23692 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.2, bsz=40, num_updates=23660, lr=4.28265e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68061
2023-02-21 08:10:06 - progress_bar.py[line:274] - INFO: epoch 001:  23702 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.6, bsz=40, num_updates=23670, lr=4.28229e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68073
2023-02-21 08:10:18 - progress_bar.py[line:274] - INFO: epoch 001:  23712 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.6, bsz=40, num_updates=23680, lr=4.28193e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68084
2023-02-21 08:10:29 - progress_bar.py[line:274] - INFO: epoch 001:  23722 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.5, bsz=40, num_updates=23690, lr=4.28157e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68095
2023-02-21 08:10:40 - progress_bar.py[line:274] - INFO: epoch 001:  23732 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.8, bsz=40, num_updates=23700, lr=4.28121e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=68106
2023-02-21 08:10:51 - progress_bar.py[line:274] - INFO: epoch 001:  23742 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.9, wpb=112.7, bsz=40, num_updates=23710, lr=4.28085e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68117
2023-02-21 08:11:02 - progress_bar.py[line:274] - INFO: epoch 001:  23752 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.3, ups=0.91, wpb=112, bsz=40, num_updates=23720, lr=4.28048e-05, gnorm=0.123, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68128
2023-02-21 08:11:13 - progress_bar.py[line:274] - INFO: epoch 001:  23762 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111, bsz=40, num_updates=23730, lr=4.28012e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=68139
2023-02-21 08:11:24 - progress_bar.py[line:274] - INFO: epoch 001:  23772 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112.2, bsz=40, num_updates=23740, lr=4.27976e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68150
2023-02-21 08:11:35 - progress_bar.py[line:274] - INFO: epoch 001:  23782 / 71012 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.2, bsz=40, num_updates=23750, lr=4.2794e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68161
2023-02-21 08:11:46 - progress_bar.py[line:274] - INFO: epoch 001:  23792 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.5, bsz=40, num_updates=23760, lr=4.27904e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68172
2023-02-21 08:11:57 - progress_bar.py[line:274] - INFO: epoch 001:  23802 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=110.8, bsz=40, num_updates=23770, lr=4.27867e-05, gnorm=0.121, clip=0, loss_scale=4096, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=68183
2023-02-21 08:12:08 - progress_bar.py[line:274] - INFO: epoch 001:  23812 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=112, bsz=40, num_updates=23780, lr=4.27831e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68194
2023-02-21 08:12:18 - progress_bar.py[line:274] - INFO: epoch 001:  23822 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=107.2, ups=0.95, wpb=113, bsz=40, num_updates=23790, lr=4.27795e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=68205
2023-02-21 08:12:30 - progress_bar.py[line:274] - INFO: epoch 001:  23832 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112, bsz=40, num_updates=23800, lr=4.27759e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68216
2023-02-21 08:12:41 - progress_bar.py[line:274] - INFO: epoch 001:  23842 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.89, wpb=110.1, bsz=40, num_updates=23810, lr=4.27723e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68227
2023-02-21 08:12:52 - progress_bar.py[line:274] - INFO: epoch 001:  23852 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.4, bsz=40, num_updates=23820, lr=4.27687e-05, gnorm=0.123, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68238
2023-02-21 08:13:03 - progress_bar.py[line:274] - INFO: epoch 001:  23862 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.9, ups=0.92, wpb=112.5, bsz=40, num_updates=23830, lr=4.2765e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=68249
2023-02-21 08:13:07 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 08:13:15 - progress_bar.py[line:274] - INFO: epoch 001:  23873 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91.6, ups=0.81, wpb=112.5, bsz=40, num_updates=23840, lr=4.27614e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=68262
2023-02-21 08:13:26 - progress_bar.py[line:274] - INFO: epoch 001:  23883 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112, bsz=40, num_updates=23850, lr=4.27578e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=68272
2023-02-21 08:13:37 - progress_bar.py[line:274] - INFO: epoch 001:  23893 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.4, bsz=40, num_updates=23860, lr=4.27542e-05, gnorm=0.146, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68284
2023-02-21 08:13:48 - progress_bar.py[line:274] - INFO: epoch 001:  23903 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.3, bsz=40, num_updates=23870, lr=4.27506e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68295
2023-02-21 08:13:59 - progress_bar.py[line:274] - INFO: epoch 001:  23913 / 71012 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110, bsz=40, num_updates=23880, lr=4.27469e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68305
2023-02-21 08:14:10 - progress_bar.py[line:274] - INFO: epoch 001:  23923 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.9, bsz=40, num_updates=23890, lr=4.27433e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68317
2023-02-21 08:14:21 - progress_bar.py[line:274] - INFO: epoch 001:  23933 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.91, wpb=109.7, bsz=40, num_updates=23900, lr=4.27397e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68328
2023-02-21 08:14:32 - progress_bar.py[line:274] - INFO: epoch 001:  23943 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.6, bsz=40, num_updates=23910, lr=4.27361e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68339
2023-02-21 08:14:43 - progress_bar.py[line:274] - INFO: epoch 001:  23953 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=102.5, ups=0.92, wpb=111.2, bsz=40, num_updates=23920, lr=4.27325e-05, gnorm=0.048, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68349
2023-02-21 08:14:54 - progress_bar.py[line:274] - INFO: epoch 001:  23963 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.6, bsz=40, num_updates=23930, lr=4.27289e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=68361
2023-02-21 08:15:05 - progress_bar.py[line:274] - INFO: epoch 001:  23973 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.91, wpb=108.9, bsz=40, num_updates=23940, lr=4.27252e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68372
2023-02-21 08:15:16 - progress_bar.py[line:274] - INFO: epoch 001:  23983 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.8, bsz=40, num_updates=23950, lr=4.27216e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68383
2023-02-21 08:15:28 - progress_bar.py[line:274] - INFO: epoch 001:  23993 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.87, wpb=112.7, bsz=40, num_updates=23960, lr=4.2718e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=68394
2023-02-21 08:15:39 - progress_bar.py[line:274] - INFO: epoch 001:  24003 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.3, bsz=40, num_updates=23970, lr=4.27144e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68405
2023-02-21 08:15:50 - progress_bar.py[line:274] - INFO: epoch 001:  24013 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.8, bsz=40, num_updates=23980, lr=4.27108e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=68417
2023-02-21 08:16:01 - progress_bar.py[line:274] - INFO: epoch 001:  24023 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.93, wpb=112.1, bsz=40, num_updates=23990, lr=4.27071e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68427
2023-02-21 08:16:12 - progress_bar.py[line:274] - INFO: epoch 001:  24033 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.3, bsz=40, num_updates=24000, lr=4.27035e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68439
2023-02-21 08:16:12 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 08:16:13 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 08:16:13 - train.py[line:551] - INFO: load:0.85 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 08:18:15 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 08:18:15 - train.py[line:551] - INFO: load:0.87 valid_run:122.00 task_valid:119.04 collect_output:1.86
2023-02-21 08:20:15 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 08:20:15 - train.py[line:551] - INFO: load:0.90 valid_run:241.47 task_valid:234.53 collect_output:4.78
2023-02-21 08:22:16 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 08:22:16 - train.py[line:551] - INFO: load:0.92 valid_run:362.70 task_valid:350.70 collect_output:8.82
2023-02-21 08:24:18 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 08:24:18 - train.py[line:551] - INFO: load:0.95 valid_run:483.98 task_valid:464.02 collect_output:15.76
2023-02-21 08:26:18 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 08:26:18 - train.py[line:551] - INFO: load:0.97 valid_run:604.10 task_valid:581.15 collect_output:17.72
2023-02-21 08:28:22 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 08:28:22 - train.py[line:551] - INFO: load:1.00 valid_run:728.51 task_valid:700.80 collect_output:21.29
2023-02-21 08:30:28 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 08:30:28 - train.py[line:551] - INFO: load:1.03 valid_run:853.83 task_valid:820.75 collect_output:25.43
2023-02-21 08:32:32 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 08:32:32 - train.py[line:551] - INFO: load:1.06 valid_run:977.84 task_valid:938.87 collect_output:30.14
2023-02-21 08:34:37 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 08:34:37 - train.py[line:551] - INFO: load:1.08 valid_run:1103.24 task_valid:1057.47 collect_output:35.71
2023-02-21 08:36:41 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 08:36:41 - train.py[line:551] - INFO: load:1.11 valid_run:1226.50 task_valid:1171.40 collect_output:43.83
2023-02-21 08:38:43 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 08:38:43 - train.py[line:551] - INFO: load:1.14 valid_run:1348.43 task_valid:1288.11 collect_output:47.89
2023-02-21 08:40:46 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 08:40:46 - train.py[line:551] - INFO: load:1.17 valid_run:1471.68 task_valid:1406.34 collect_output:51.71
2023-02-21 08:42:47 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 08:42:47 - train.py[line:551] - INFO: load:1.19 valid_run:1592.29 task_valid:1521.41 collect_output:56.11
2023-02-21 08:44:49 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 08:44:49 - train.py[line:551] - INFO: load:1.22 valid_run:1715.00 task_valid:1640.21 collect_output:58.76
2023-02-21 08:46:52 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 08:46:52 - train.py[line:551] - INFO: load:1.26 valid_run:1837.55 task_valid:1757.37 collect_output:62.98
2023-02-21 08:48:55 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 08:48:55 - train.py[line:551] - INFO: load:1.29 valid_run:1960.20 task_valid:1872.51 collect_output:69.25
2023-02-21 08:50:58 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 08:50:58 - train.py[line:551] - INFO: load:1.32 valid_run:2083.11 task_valid:1989.54 collect_output:73.94
2023-02-21 08:53:00 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 08:53:00 - train.py[line:551] - INFO: load:1.35 valid_run:2205.62 task_valid:2108.62 collect_output:76.14
2023-02-21 08:55:04 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 08:55:04 - train.py[line:551] - INFO: load:1.38 valid_run:2329.11 task_valid:2227.08 collect_output:79.91
2023-02-21 08:57:06 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 08:57:06 - train.py[line:551] - INFO: load:1.41 valid_run:2451.00 task_valid:2344.87 collect_output:82.76
2023-02-21 08:59:09 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 08:59:09 - train.py[line:551] - INFO: load:1.44 valid_run:2574.10 task_valid:2462.71 collect_output:86.83
2023-02-21 09:01:13 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 09:01:13 - train.py[line:551] - INFO: load:1.47 valid_run:2697.94 task_valid:2582.56 collect_output:89.58
2023-02-21 09:03:15 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 09:03:15 - train.py[line:551] - INFO: load:1.49 valid_run:2819.96 task_valid:2697.95 collect_output:95.01
2023-02-21 09:05:17 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 09:05:17 - train.py[line:551] - INFO: load:1.52 valid_run:2941.61 task_valid:2815.17 collect_output:98.23
2023-02-21 09:07:20 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 09:07:20 - train.py[line:551] - INFO: load:1.55 valid_run:3065.32 task_valid:2932.60 collect_output:103.30
2023-02-21 09:09:25 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 09:09:25 - train.py[line:551] - INFO: load:1.57 valid_run:3189.94 task_valid:3049.72 collect_output:109.61
2023-02-21 09:11:26 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 09:11:26 - train.py[line:551] - INFO: load:1.60 valid_run:3311.09 task_valid:3165.26 collect_output:113.98
2023-02-21 09:13:30 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 09:13:30 - train.py[line:551] - INFO: load:1.63 valid_run:3434.98 task_valid:3286.13 collect_output:115.72
2023-02-21 09:15:34 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 09:15:34 - train.py[line:551] - INFO: load:1.66 valid_run:3558.37 task_valid:3402.67 collect_output:121.33
2023-02-21 09:17:38 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 09:17:38 - train.py[line:551] - INFO: load:1.69 valid_run:3682.20 task_valid:3522.40 collect_output:124.27
2023-02-21 09:19:40 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 09:19:40 - train.py[line:551] - INFO: load:1.72 valid_run:3805.02 task_valid:3642.04 collect_output:126.23

====================================================================================================
SGG eval:     R @ 50: 0.5834;     R @ 100: 0.6112;     R @ 500: 0.6329;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3629;    mR @ 100: 0.3996;    mR @ 500: 0.4314;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.7500) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3387) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9314) (says:0.0000) (sitting on:0.6531) (standing on:0.3593) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-02-21 09:20:12 - train.py[line:487] - INFO: 0.6112481792717086
2023-02-21 09:20:12 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 09:20:12 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.232 | loss_v1 0 | loss_v2 0 | nll_loss 0.063 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.611248 | ppl 1.04 | vqa_score 0.4572 | wps 116.9 | wpb 72 | bsz 24 | num_updates 24000 | best_R@100 0.691462
2023-02-21 09:20:12 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 24000 updates
2023-02-21 09:20:12 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_24000.pt

====================================================================================================
SGG eval:     R @ 50: 0.5834;     R @ 100: 0.6112;     R @ 500: 0.6329;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3629;    mR @ 100: 0.3996;    mR @ 500: 0.4314;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.7500) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3387) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9314) (says:0.0000) (sitting on:0.6531) (standing on:0.3593) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-02-21 09:20:19 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_24000.pt
2023-02-21 09:20:21 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_24000.pt (epoch 1 @ 24000 updates, score 0.6112481792717086) (writing took 8.97651787288487 seconds)
2023-02-21 09:20:32 - progress_bar.py[line:274] - INFO: epoch 001:  24043 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=111.1, bsz=40, num_updates=24010, lr=4.26999e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72299
2023-02-21 09:20:44 - progress_bar.py[line:274] - INFO: epoch 001:  24053 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.87, wpb=111, bsz=40, num_updates=24020, lr=4.26963e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=72310
2023-02-21 09:20:55 - progress_bar.py[line:274] - INFO: epoch 001:  24063 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.8, bsz=40, num_updates=24030, lr=4.26927e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72322
2023-02-21 09:21:06 - progress_bar.py[line:274] - INFO: epoch 001:  24073 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.8, bsz=40, num_updates=24040, lr=4.26891e-05, gnorm=0.065, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72333
2023-02-21 09:21:18 - progress_bar.py[line:274] - INFO: epoch 001:  24083 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=111.9, bsz=40, num_updates=24050, lr=4.26854e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72344
2023-02-21 09:21:29 - progress_bar.py[line:274] - INFO: epoch 001:  24093 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=24060, lr=4.26818e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72356
2023-02-21 09:21:40 - progress_bar.py[line:274] - INFO: epoch 001:  24103 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=24070, lr=4.26782e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72367
2023-02-21 09:21:52 - progress_bar.py[line:274] - INFO: epoch 001:  24113 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.7, bsz=40, num_updates=24080, lr=4.26746e-05, gnorm=0.057, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72378
2023-02-21 09:22:03 - progress_bar.py[line:274] - INFO: epoch 001:  24123 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=112.7, bsz=40, num_updates=24090, lr=4.2671e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72389
2023-02-21 09:22:14 - progress_bar.py[line:274] - INFO: epoch 001:  24133 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=24100, lr=4.26673e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72400
2023-02-21 09:22:25 - progress_bar.py[line:274] - INFO: epoch 001:  24143 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.9, wpb=111.5, bsz=40, num_updates=24110, lr=4.26637e-05, gnorm=0.175, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72411
2023-02-21 09:22:36 - progress_bar.py[line:274] - INFO: epoch 001:  24153 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.8, bsz=40, num_updates=24120, lr=4.26601e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=72422
2023-02-21 09:22:47 - progress_bar.py[line:274] - INFO: epoch 001:  24163 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=112, bsz=40, num_updates=24130, lr=4.26565e-05, gnorm=0.07, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72434
2023-02-21 09:22:58 - progress_bar.py[line:274] - INFO: epoch 001:  24173 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.1, bsz=40, num_updates=24140, lr=4.26529e-05, gnorm=0.07, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=72445
2023-02-21 09:23:09 - progress_bar.py[line:274] - INFO: epoch 001:  24183 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.93, wpb=111.2, bsz=40, num_updates=24150, lr=4.26493e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72455
2023-02-21 09:23:20 - progress_bar.py[line:274] - INFO: epoch 001:  24193 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.6, bsz=40, num_updates=24160, lr=4.26456e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=72466
2023-02-21 09:23:31 - progress_bar.py[line:274] - INFO: epoch 001:  24203 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.87, wpb=111.9, bsz=40, num_updates=24170, lr=4.2642e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72478
2023-02-21 09:23:43 - progress_bar.py[line:274] - INFO: epoch 001:  24213 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.6, bsz=40, num_updates=24180, lr=4.26384e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72489
2023-02-21 09:23:54 - progress_bar.py[line:274] - INFO: epoch 001:  24223 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.9, wpb=113.2, bsz=40, num_updates=24190, lr=4.26348e-05, gnorm=0.132, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72500
2023-02-21 09:24:05 - progress_bar.py[line:274] - INFO: epoch 001:  24233 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=96.1, ups=0.87, wpb=110.3, bsz=40, num_updates=24200, lr=4.26312e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72512
2023-02-21 09:24:16 - progress_bar.py[line:274] - INFO: epoch 001:  24243 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.92, wpb=113, bsz=40, num_updates=24210, lr=4.26275e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72523
2023-02-21 09:24:27 - progress_bar.py[line:274] - INFO: epoch 001:  24253 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=24220, lr=4.26239e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=72534
2023-02-21 09:24:38 - progress_bar.py[line:274] - INFO: epoch 001:  24263 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.6, bsz=40, num_updates=24230, lr=4.26203e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72545
2023-02-21 09:24:50 - progress_bar.py[line:274] - INFO: epoch 001:  24273 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111, bsz=40, num_updates=24240, lr=4.26167e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72556
2023-02-21 09:25:01 - progress_bar.py[line:274] - INFO: epoch 001:  24283 / 71012 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=111.1, bsz=40, num_updates=24250, lr=4.26131e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72567
2023-02-21 09:25:13 - progress_bar.py[line:274] - INFO: epoch 001:  24293 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=96.4, ups=0.86, wpb=111.9, bsz=40, num_updates=24260, lr=4.26095e-05, gnorm=0.05, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=72579
2023-02-21 09:25:24 - progress_bar.py[line:274] - INFO: epoch 001:  24303 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.3, bsz=40, num_updates=24270, lr=4.26058e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=72590
2023-02-21 09:25:35 - progress_bar.py[line:274] - INFO: epoch 001:  24313 / 71012 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=110.5, bsz=40, num_updates=24280, lr=4.26022e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72601
2023-02-21 09:25:46 - progress_bar.py[line:274] - INFO: epoch 001:  24323 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.88, wpb=110.4, bsz=40, num_updates=24290, lr=4.25986e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72613
2023-02-21 09:25:58 - progress_bar.py[line:274] - INFO: epoch 001:  24333 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.88, wpb=113.2, bsz=40, num_updates=24300, lr=4.2595e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72624
2023-02-21 09:26:09 - progress_bar.py[line:274] - INFO: epoch 001:  24343 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.1, bsz=40, num_updates=24310, lr=4.25914e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=72636
2023-02-21 09:26:21 - progress_bar.py[line:274] - INFO: epoch 001:  24353 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=112, bsz=40, num_updates=24320, lr=4.25877e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72647
2023-02-21 09:26:32 - progress_bar.py[line:274] - INFO: epoch 001:  24363 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.7, bsz=40, num_updates=24330, lr=4.25841e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72658
2023-02-21 09:26:43 - progress_bar.py[line:274] - INFO: epoch 001:  24373 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=24340, lr=4.25805e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72670
2023-02-21 09:26:55 - progress_bar.py[line:274] - INFO: epoch 001:  24383 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=111.9, bsz=40, num_updates=24350, lr=4.25769e-05, gnorm=0.159, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72681
2023-02-21 09:27:06 - progress_bar.py[line:274] - INFO: epoch 001:  24393 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.4, bsz=40, num_updates=24360, lr=4.25733e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72692
2023-02-21 09:27:17 - progress_bar.py[line:274] - INFO: epoch 001:  24403 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.6, bsz=40, num_updates=24370, lr=4.25697e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72704
2023-02-21 09:27:29 - progress_bar.py[line:274] - INFO: epoch 001:  24413 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.7, bsz=40, num_updates=24380, lr=4.2566e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72715
2023-02-21 09:27:40 - progress_bar.py[line:274] - INFO: epoch 001:  24423 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.5, bsz=40, num_updates=24390, lr=4.25624e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72726
2023-02-21 09:27:51 - progress_bar.py[line:274] - INFO: epoch 001:  24433 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=100.5, ups=0.89, wpb=112.3, bsz=40, num_updates=24400, lr=4.25588e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72738
2023-02-21 09:28:02 - progress_bar.py[line:274] - INFO: epoch 001:  24443 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.1, bsz=40, num_updates=24410, lr=4.25552e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72749
2023-02-21 09:28:14 - progress_bar.py[line:274] - INFO: epoch 001:  24453 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.2, ups=0.85, wpb=111.5, bsz=40, num_updates=24420, lr=4.25516e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=72761
2023-02-21 09:28:19 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 09:28:26 - progress_bar.py[line:274] - INFO: epoch 001:  24464 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.7, ups=0.83, wpb=111.8, bsz=40, num_updates=24430, lr=4.25479e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=72773
2023-02-21 09:28:38 - progress_bar.py[line:274] - INFO: epoch 001:  24474 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.8, bsz=40, num_updates=24440, lr=4.25443e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=72784
2023-02-21 09:28:49 - progress_bar.py[line:274] - INFO: epoch 001:  24484 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.4, bsz=40, num_updates=24450, lr=4.25407e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72795
2023-02-21 09:29:00 - progress_bar.py[line:274] - INFO: epoch 001:  24494 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.9, wpb=112.3, bsz=40, num_updates=24460, lr=4.25371e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72806
2023-02-21 09:29:11 - progress_bar.py[line:274] - INFO: epoch 001:  24504 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=24470, lr=4.25335e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72817
2023-02-21 09:29:23 - progress_bar.py[line:274] - INFO: epoch 001:  24514 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.7, ups=0.86, wpb=111.6, bsz=40, num_updates=24480, lr=4.25299e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=72829
2023-02-21 09:29:34 - progress_bar.py[line:274] - INFO: epoch 001:  24524 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=24490, lr=4.25262e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72840
2023-02-21 09:29:45 - progress_bar.py[line:274] - INFO: epoch 001:  24534 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.5, bsz=40, num_updates=24500, lr=4.25226e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72851
2023-02-21 09:29:56 - progress_bar.py[line:274] - INFO: epoch 001:  24544 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.6, bsz=40, num_updates=24510, lr=4.2519e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72863
2023-02-21 09:30:07 - progress_bar.py[line:274] - INFO: epoch 001:  24554 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=24520, lr=4.25154e-05, gnorm=0.171, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72874
2023-02-21 09:30:19 - progress_bar.py[line:274] - INFO: epoch 001:  24564 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.86, wpb=112.5, bsz=40, num_updates=24530, lr=4.25118e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=12, gb_free=11, ema_decay=0.9999, wall=72885
2023-02-21 09:30:30 - progress_bar.py[line:274] - INFO: epoch 001:  24574 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.5, bsz=40, num_updates=24540, lr=4.25081e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=72897
2023-02-21 09:30:41 - progress_bar.py[line:274] - INFO: epoch 001:  24584 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.4, bsz=40, num_updates=24550, lr=4.25045e-05, gnorm=0.142, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72908
2023-02-21 09:30:53 - progress_bar.py[line:274] - INFO: epoch 001:  24594 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.4, ups=0.87, wpb=111.3, bsz=40, num_updates=24560, lr=4.25009e-05, gnorm=0.142, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72919
2023-02-21 09:31:04 - progress_bar.py[line:274] - INFO: epoch 001:  24604 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.89, wpb=110.3, bsz=40, num_updates=24570, lr=4.24973e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72931
2023-02-21 09:31:16 - progress_bar.py[line:274] - INFO: epoch 001:  24614 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=112.2, bsz=40, num_updates=24580, lr=4.24937e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72942
2023-02-21 09:31:27 - progress_bar.py[line:274] - INFO: epoch 001:  24624 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.9, bsz=40, num_updates=24590, lr=4.249e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72953
2023-02-21 09:31:38 - progress_bar.py[line:274] - INFO: epoch 001:  24634 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.2, bsz=40, num_updates=24600, lr=4.24864e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72964
2023-02-21 09:31:49 - progress_bar.py[line:274] - INFO: epoch 001:  24644 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=111.9, bsz=40, num_updates=24610, lr=4.24828e-05, gnorm=0.158, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72975
2023-02-21 09:32:00 - progress_bar.py[line:274] - INFO: epoch 001:  24654 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.2, bsz=40, num_updates=24620, lr=4.24792e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72986
2023-02-21 09:32:11 - progress_bar.py[line:274] - INFO: epoch 001:  24664 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111, bsz=40, num_updates=24630, lr=4.24756e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72997
2023-02-21 09:32:22 - progress_bar.py[line:274] - INFO: epoch 001:  24674 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.8, bsz=40, num_updates=24640, lr=4.2472e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73009
2023-02-21 09:32:34 - progress_bar.py[line:274] - INFO: epoch 001:  24684 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=98.5, ups=0.88, wpb=111.8, bsz=40, num_updates=24650, lr=4.24683e-05, gnorm=0.051, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73020
2023-02-21 09:32:45 - progress_bar.py[line:274] - INFO: epoch 001:  24694 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.1, bsz=40, num_updates=24660, lr=4.24647e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73031
2023-02-21 09:32:56 - progress_bar.py[line:274] - INFO: epoch 001:  24704 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=24670, lr=4.24611e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73043
2023-02-21 09:33:07 - progress_bar.py[line:274] - INFO: epoch 001:  24714 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.4, bsz=40, num_updates=24680, lr=4.24575e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=73054
2023-02-21 09:33:19 - progress_bar.py[line:274] - INFO: epoch 001:  24724 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.8, ups=0.86, wpb=109.9, bsz=40, num_updates=24690, lr=4.24539e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=73065
2023-02-21 09:33:30 - progress_bar.py[line:274] - INFO: epoch 001:  24734 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.8, bsz=40, num_updates=24700, lr=4.24502e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73077
2023-02-21 09:33:42 - progress_bar.py[line:274] - INFO: epoch 001:  24744 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=24710, lr=4.24466e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73088
2023-02-21 09:33:53 - progress_bar.py[line:274] - INFO: epoch 001:  24754 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=24720, lr=4.2443e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73099
2023-02-21 09:34:04 - progress_bar.py[line:274] - INFO: epoch 001:  24764 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=112.1, bsz=40, num_updates=24730, lr=4.24394e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73111
2023-02-21 09:34:15 - progress_bar.py[line:274] - INFO: epoch 001:  24774 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.93, wpb=110.4, bsz=40, num_updates=24740, lr=4.24358e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73121
2023-02-21 09:34:26 - progress_bar.py[line:274] - INFO: epoch 001:  24784 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.91, wpb=109.7, bsz=40, num_updates=24750, lr=4.24322e-05, gnorm=0.117, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73132
2023-02-21 09:34:37 - progress_bar.py[line:274] - INFO: epoch 001:  24794 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=112.3, bsz=40, num_updates=24760, lr=4.24285e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73144
2023-02-21 09:34:49 - progress_bar.py[line:274] - INFO: epoch 001:  24804 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.87, wpb=113.1, bsz=40, num_updates=24770, lr=4.24249e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73155
2023-02-21 09:35:00 - progress_bar.py[line:274] - INFO: epoch 001:  24814 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=112, bsz=40, num_updates=24780, lr=4.24213e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73167
2023-02-21 09:35:11 - progress_bar.py[line:274] - INFO: epoch 001:  24824 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=24790, lr=4.24177e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73178
2023-02-21 09:35:23 - progress_bar.py[line:274] - INFO: epoch 001:  24834 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=112.2, bsz=40, num_updates=24800, lr=4.24141e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73189
2023-02-21 09:35:34 - progress_bar.py[line:274] - INFO: epoch 001:  24844 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.7, bsz=40, num_updates=24810, lr=4.24104e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73200
2023-02-21 09:35:45 - progress_bar.py[line:274] - INFO: epoch 001:  24854 / 71012 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.8, ups=0.9, wpb=112.1, bsz=40, num_updates=24820, lr=4.24068e-05, gnorm=0.166, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73211
2023-02-21 09:35:56 - progress_bar.py[line:274] - INFO: epoch 001:  24864 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=111.3, bsz=40, num_updates=24830, lr=4.24032e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73223
2023-02-21 09:36:08 - progress_bar.py[line:274] - INFO: epoch 001:  24874 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112.5, bsz=40, num_updates=24840, lr=4.23996e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73234
2023-02-21 09:36:19 - progress_bar.py[line:274] - INFO: epoch 001:  24884 / 71012 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=24850, lr=4.2396e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73245
2023-02-21 09:36:30 - progress_bar.py[line:274] - INFO: epoch 001:  24894 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112.2, bsz=40, num_updates=24860, lr=4.23924e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73256
2023-02-21 09:36:43 - progress_bar.py[line:274] - INFO: epoch 001:  24904 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=96.7, ups=0.87, wpb=110.6, bsz=40, num_updates=24870, lr=4.23887e-05, gnorm=0.07, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73268
2023-02-21 09:36:54 - progress_bar.py[line:274] - INFO: epoch 001:  24914 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112.3, bsz=40, num_updates=24880, lr=4.23851e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73280
2023-02-21 09:37:05 - progress_bar.py[line:274] - INFO: epoch 001:  24924 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.8, bsz=40, num_updates=24890, lr=4.23815e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73292
2023-02-21 09:37:17 - progress_bar.py[line:274] - INFO: epoch 001:  24934 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=112, bsz=40, num_updates=24900, lr=4.23779e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73303
2023-02-21 09:37:28 - progress_bar.py[line:274] - INFO: epoch 001:  24944 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=112.2, bsz=40, num_updates=24910, lr=4.23743e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73315
2023-02-21 09:37:39 - progress_bar.py[line:274] - INFO: epoch 001:  24954 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112.4, bsz=40, num_updates=24920, lr=4.23706e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73326
2023-02-21 09:37:51 - progress_bar.py[line:274] - INFO: epoch 001:  24964 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=111.6, bsz=40, num_updates=24930, lr=4.2367e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73337
2023-02-21 09:38:03 - progress_bar.py[line:274] - INFO: epoch 001:  24974 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.86, wpb=111.7, bsz=40, num_updates=24940, lr=4.23634e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73349
2023-02-21 09:38:14 - progress_bar.py[line:274] - INFO: epoch 001:  24984 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.9, bsz=40, num_updates=24950, lr=4.23598e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73360
2023-02-21 09:38:25 - progress_bar.py[line:274] - INFO: epoch 001:  24994 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=111.1, bsz=40, num_updates=24960, lr=4.23562e-05, gnorm=0.105, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73372
2023-02-21 09:38:37 - progress_bar.py[line:274] - INFO: epoch 001:  25004 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.89, wpb=110.1, bsz=40, num_updates=24970, lr=4.23526e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73383
2023-02-21 09:38:38 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 09:38:49 - progress_bar.py[line:274] - INFO: epoch 001:  25015 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.4, ups=0.84, wpb=111.6, bsz=40, num_updates=24980, lr=4.23489e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=73395
2023-02-21 09:39:00 - progress_bar.py[line:274] - INFO: epoch 001:  25025 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=24990, lr=4.23453e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73406
2023-02-21 09:39:11 - progress_bar.py[line:274] - INFO: epoch 001:  25035 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=25000, lr=4.23417e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73417
2023-02-21 09:39:22 - progress_bar.py[line:274] - INFO: epoch 001:  25045 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.6, bsz=40, num_updates=25010, lr=4.23381e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73429
2023-02-21 09:39:34 - progress_bar.py[line:274] - INFO: epoch 001:  25055 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.4, bsz=40, num_updates=25020, lr=4.23345e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73440
2023-02-21 09:39:45 - progress_bar.py[line:274] - INFO: epoch 001:  25065 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=111, bsz=40, num_updates=25030, lr=4.23308e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73451
2023-02-21 09:39:56 - progress_bar.py[line:274] - INFO: epoch 001:  25075 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=112.2, bsz=40, num_updates=25040, lr=4.23272e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73462
2023-02-21 09:40:07 - progress_bar.py[line:274] - INFO: epoch 001:  25085 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.4, bsz=40, num_updates=25050, lr=4.23236e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73474
2023-02-21 09:40:19 - progress_bar.py[line:274] - INFO: epoch 001:  25095 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.86, wpb=112.6, bsz=40, num_updates=25060, lr=4.232e-05, gnorm=0.065, clip=0, loss_scale=2048, train_wall=12, gb_free=11, ema_decay=0.9999, wall=73485
2023-02-21 09:40:30 - progress_bar.py[line:274] - INFO: epoch 001:  25105 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.3, bsz=40, num_updates=25070, lr=4.23164e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73496
2023-02-21 09:40:41 - progress_bar.py[line:274] - INFO: epoch 001:  25115 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113.7, nsentences=40, sample_size=113.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.89, wpb=113.7, bsz=40, num_updates=25080, lr=4.23128e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73507
2023-02-21 09:40:52 - progress_bar.py[line:274] - INFO: epoch 001:  25125 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.7, bsz=40, num_updates=25090, lr=4.23091e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73519
2023-02-21 09:41:04 - progress_bar.py[line:274] - INFO: epoch 001:  25135 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.86, wpb=113.2, bsz=40, num_updates=25100, lr=4.23055e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=73530
2023-02-21 09:41:15 - progress_bar.py[line:274] - INFO: epoch 001:  25145 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=25110, lr=4.23019e-05, gnorm=0.061, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73541
2023-02-21 09:41:27 - progress_bar.py[line:274] - INFO: epoch 001:  25155 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=111.4, bsz=40, num_updates=25120, lr=4.22983e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73553
2023-02-21 09:41:38 - progress_bar.py[line:274] - INFO: epoch 001:  25165 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=25130, lr=4.22947e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73564
2023-02-21 09:41:49 - progress_bar.py[line:274] - INFO: epoch 001:  25175 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111, bsz=40, num_updates=25140, lr=4.2291e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73575
2023-02-21 09:42:00 - progress_bar.py[line:274] - INFO: epoch 001:  25185 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=111.3, bsz=40, num_updates=25150, lr=4.22874e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73587
2023-02-21 09:42:12 - progress_bar.py[line:274] - INFO: epoch 001:  25195 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.9, wpb=110, bsz=40, num_updates=25160, lr=4.22838e-05, gnorm=0.072, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73598
2023-02-21 09:42:23 - progress_bar.py[line:274] - INFO: epoch 001:  25205 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=110.9, bsz=40, num_updates=25170, lr=4.22802e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=73609
2023-02-21 09:42:35 - progress_bar.py[line:274] - INFO: epoch 001:  25215 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.86, wpb=111.4, bsz=40, num_updates=25180, lr=4.22766e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=73621
2023-02-21 09:42:46 - progress_bar.py[line:274] - INFO: epoch 001:  25225 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=25190, lr=4.2273e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73632
2023-02-21 09:42:57 - progress_bar.py[line:274] - INFO: epoch 001:  25235 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.2, bsz=40, num_updates=25200, lr=4.22693e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73643
2023-02-21 09:43:08 - progress_bar.py[line:274] - INFO: epoch 001:  25245 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.1, bsz=40, num_updates=25210, lr=4.22657e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73654
2023-02-21 09:43:19 - progress_bar.py[line:274] - INFO: epoch 001:  25255 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.2, bsz=40, num_updates=25220, lr=4.22621e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=73665
2023-02-21 09:43:30 - progress_bar.py[line:274] - INFO: epoch 001:  25265 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.86, wpb=111.6, bsz=40, num_updates=25230, lr=4.22585e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=73677
2023-02-21 09:43:42 - progress_bar.py[line:274] - INFO: epoch 001:  25275 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.9, bsz=40, num_updates=25240, lr=4.22549e-05, gnorm=0.141, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73688
2023-02-21 09:43:53 - progress_bar.py[line:274] - INFO: epoch 001:  25285 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=112.6, bsz=40, num_updates=25250, lr=4.22512e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73699
2023-02-21 09:44:04 - progress_bar.py[line:274] - INFO: epoch 001:  25295 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112.1, bsz=40, num_updates=25260, lr=4.22476e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73711
2023-02-21 09:44:16 - progress_bar.py[line:274] - INFO: epoch 001:  25305 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.1, ups=0.86, wpb=110.4, bsz=40, num_updates=25270, lr=4.2244e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=73722
2023-02-21 09:44:27 - progress_bar.py[line:274] - INFO: epoch 001:  25315 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=111.9, bsz=40, num_updates=25280, lr=4.22404e-05, gnorm=0.053, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73734
2023-02-21 09:44:39 - progress_bar.py[line:274] - INFO: epoch 001:  25325 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.6, bsz=40, num_updates=25290, lr=4.22368e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=73745
2023-02-21 09:44:50 - progress_bar.py[line:274] - INFO: epoch 001:  25335 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.3, bsz=40, num_updates=25300, lr=4.22332e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=73756
2023-02-21 09:45:01 - progress_bar.py[line:274] - INFO: epoch 001:  25345 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=112.7, bsz=40, num_updates=25310, lr=4.22295e-05, gnorm=0.061, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73767
2023-02-21 09:45:12 - progress_bar.py[line:274] - INFO: epoch 001:  25355 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=112.1, bsz=40, num_updates=25320, lr=4.22259e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73779
2023-02-21 09:45:24 - progress_bar.py[line:274] - INFO: epoch 001:  25365 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=112.2, bsz=40, num_updates=25330, lr=4.22223e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=73790
2023-02-21 09:45:35 - progress_bar.py[line:274] - INFO: epoch 001:  25375 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112.6, bsz=40, num_updates=25340, lr=4.22187e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73802
2023-02-21 09:45:46 - progress_bar.py[line:274] - INFO: epoch 001:  25385 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=100.4, ups=0.9, wpb=111.7, bsz=40, num_updates=25350, lr=4.22151e-05, gnorm=0.07, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73813
2023-02-21 09:45:58 - progress_bar.py[line:274] - INFO: epoch 001:  25395 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.87, wpb=113.1, bsz=40, num_updates=25360, lr=4.22114e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73824
2023-02-21 09:46:09 - progress_bar.py[line:274] - INFO: epoch 001:  25405 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.9, bsz=40, num_updates=25370, lr=4.22078e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73836
2023-02-21 09:46:20 - progress_bar.py[line:274] - INFO: epoch 001:  25415 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.91, wpb=109.6, bsz=40, num_updates=25380, lr=4.22042e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73847
2023-02-21 09:46:32 - progress_bar.py[line:274] - INFO: epoch 001:  25425 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.8, bsz=40, num_updates=25390, lr=4.22006e-05, gnorm=0.142, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73858
2023-02-21 09:46:43 - progress_bar.py[line:274] - INFO: epoch 001:  25435 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.9, bsz=40, num_updates=25400, lr=4.2197e-05, gnorm=0.063, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73869
2023-02-21 09:46:54 - progress_bar.py[line:274] - INFO: epoch 001:  25445 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=25410, lr=4.21934e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73880
2023-02-21 09:47:05 - progress_bar.py[line:274] - INFO: epoch 001:  25455 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.3, bsz=40, num_updates=25420, lr=4.21897e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73891
2023-02-21 09:47:16 - progress_bar.py[line:274] - INFO: epoch 001:  25465 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=25430, lr=4.21861e-05, gnorm=0.062, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73903
2023-02-21 09:47:28 - progress_bar.py[line:274] - INFO: epoch 001:  25475 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.2, bsz=40, num_updates=25440, lr=4.21825e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73914
2023-02-21 09:47:39 - progress_bar.py[line:274] - INFO: epoch 001:  25485 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111, bsz=40, num_updates=25450, lr=4.21789e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10, ema_decay=0.9999, wall=73925
2023-02-21 09:47:50 - progress_bar.py[line:274] - INFO: epoch 001:  25495 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.9, bsz=40, num_updates=25460, lr=4.21753e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73937
2023-02-21 09:48:02 - progress_bar.py[line:274] - INFO: epoch 001:  25505 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=112.2, bsz=40, num_updates=25470, lr=4.21716e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73948
2023-02-21 09:48:13 - progress_bar.py[line:274] - INFO: epoch 001:  25515 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.7, bsz=40, num_updates=25480, lr=4.2168e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73959
2023-02-21 09:48:24 - progress_bar.py[line:274] - INFO: epoch 001:  25525 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=112.2, bsz=40, num_updates=25490, lr=4.21644e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73971
2023-02-21 09:48:36 - progress_bar.py[line:274] - INFO: epoch 001:  25535 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.5, bsz=40, num_updates=25500, lr=4.21608e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73982
2023-02-21 09:48:47 - progress_bar.py[line:274] - INFO: epoch 001:  25545 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=112, bsz=40, num_updates=25510, lr=4.21572e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73993
2023-02-21 09:48:58 - progress_bar.py[line:274] - INFO: epoch 001:  25555 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=112.5, bsz=40, num_updates=25520, lr=4.21536e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74004
2023-02-21 09:49:07 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 09:49:10 - progress_bar.py[line:274] - INFO: epoch 001:  25566 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94, ups=0.84, wpb=112.2, bsz=40, num_updates=25530, lr=4.21499e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=74016
2023-02-21 09:49:22 - progress_bar.py[line:274] - INFO: epoch 001:  25576 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.86, wpb=113, bsz=40, num_updates=25540, lr=4.21463e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=74028
2023-02-21 09:49:33 - progress_bar.py[line:274] - INFO: epoch 001:  25586 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.8, bsz=40, num_updates=25550, lr=4.21427e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74039
2023-02-21 09:49:44 - progress_bar.py[line:274] - INFO: epoch 001:  25596 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.9, wpb=111.2, bsz=40, num_updates=25560, lr=4.21391e-05, gnorm=0.195, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=74051
2023-02-21 09:49:56 - progress_bar.py[line:274] - INFO: epoch 001:  25606 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.1, ups=0.87, wpb=112, bsz=40, num_updates=25570, lr=4.21355e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74062
2023-02-21 09:50:07 - progress_bar.py[line:274] - INFO: epoch 001:  25616 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.91, wpb=112.7, bsz=40, num_updates=25580, lr=4.21318e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74073
2023-02-21 09:50:18 - progress_bar.py[line:274] - INFO: epoch 001:  25626 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.86, wpb=111.1, bsz=40, num_updates=25590, lr=4.21282e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=74085
2023-02-21 09:50:29 - progress_bar.py[line:274] - INFO: epoch 001:  25636 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=25600, lr=4.21246e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=74096
2023-02-21 09:50:40 - progress_bar.py[line:274] - INFO: epoch 001:  25646 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=112.7, bsz=40, num_updates=25610, lr=4.2121e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=74107
2023-02-21 09:50:52 - progress_bar.py[line:274] - INFO: epoch 001:  25656 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112, bsz=40, num_updates=25620, lr=4.21174e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74118
2023-02-21 09:51:03 - progress_bar.py[line:274] - INFO: epoch 001:  25666 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.3, bsz=40, num_updates=25630, lr=4.21138e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74129
2023-02-21 09:51:14 - progress_bar.py[line:274] - INFO: epoch 001:  25676 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.7, bsz=40, num_updates=25640, lr=4.21101e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74141
2023-02-21 09:51:26 - progress_bar.py[line:274] - INFO: epoch 001:  25686 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.86, wpb=111.9, bsz=40, num_updates=25650, lr=4.21065e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=74152
2023-02-21 09:51:37 - progress_bar.py[line:274] - INFO: epoch 001:  25696 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=112, bsz=40, num_updates=25660, lr=4.21029e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74164
2023-02-21 09:51:48 - progress_bar.py[line:274] - INFO: epoch 001:  25706 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.6, bsz=40, num_updates=25670, lr=4.20993e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74175
2023-02-21 09:52:00 - progress_bar.py[line:274] - INFO: epoch 001:  25716 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.4, bsz=40, num_updates=25680, lr=4.20957e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=74186
2023-02-21 09:52:11 - progress_bar.py[line:274] - INFO: epoch 001:  25726 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112.2, bsz=40, num_updates=25690, lr=4.2092e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74197
2023-02-21 09:52:22 - progress_bar.py[line:274] - INFO: epoch 001:  25736 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.4, bsz=40, num_updates=25700, lr=4.20884e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74209
2023-02-21 09:52:33 - progress_bar.py[line:274] - INFO: epoch 001:  25746 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.3, bsz=40, num_updates=25710, lr=4.20848e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74220
2023-02-21 09:52:45 - progress_bar.py[line:274] - INFO: epoch 001:  25756 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=111.8, bsz=40, num_updates=25720, lr=4.20812e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74231
2023-02-21 09:52:57 - progress_bar.py[line:274] - INFO: epoch 001:  25766 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.86, wpb=112.2, bsz=40, num_updates=25730, lr=4.20776e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=74243
2023-02-21 09:53:08 - progress_bar.py[line:274] - INFO: epoch 001:  25776 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.87, wpb=112.8, bsz=40, num_updates=25740, lr=4.2074e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=74254
2023-02-21 09:53:19 - progress_bar.py[line:274] - INFO: epoch 001:  25786 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.6, bsz=40, num_updates=25750, lr=4.20703e-05, gnorm=0.055, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74266
2023-02-21 09:53:30 - progress_bar.py[line:274] - INFO: epoch 001:  25796 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=25760, lr=4.20667e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74277
2023-02-21 09:53:42 - progress_bar.py[line:274] - INFO: epoch 001:  25806 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=25770, lr=4.20631e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74288
2023-02-21 09:53:53 - progress_bar.py[line:274] - INFO: epoch 001:  25816 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.3, bsz=40, num_updates=25780, lr=4.20595e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74299
2023-02-21 09:54:04 - progress_bar.py[line:274] - INFO: epoch 001:  25826 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.6, bsz=40, num_updates=25790, lr=4.20559e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=74311
2023-02-21 09:54:15 - progress_bar.py[line:274] - INFO: epoch 001:  25836 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.8, ups=0.96, wpb=110.6, bsz=40, num_updates=25800, lr=4.20522e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=74321
2023-02-21 09:54:25 - progress_bar.py[line:274] - INFO: epoch 001:  25846 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.1, ups=0.94, wpb=111.9, bsz=40, num_updates=25810, lr=4.20486e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74332
2023-02-21 09:54:37 - progress_bar.py[line:274] - INFO: epoch 001:  25856 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=112.1, bsz=40, num_updates=25820, lr=4.2045e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10, ema_decay=0.9999, wall=74343
2023-02-21 09:54:48 - progress_bar.py[line:274] - INFO: epoch 001:  25866 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.8, bsz=40, num_updates=25830, lr=4.20414e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74355
2023-02-21 09:55:00 - progress_bar.py[line:274] - INFO: epoch 001:  25876 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=99, ups=0.88, wpb=112.2, bsz=40, num_updates=25840, lr=4.20378e-05, gnorm=0.07, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74366
2023-02-21 09:55:11 - progress_bar.py[line:274] - INFO: epoch 001:  25886 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.3, bsz=40, num_updates=25850, lr=4.20342e-05, gnorm=0.135, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=74377
2023-02-21 09:55:22 - progress_bar.py[line:274] - INFO: epoch 001:  25896 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.8, ups=0.87, wpb=110.5, bsz=40, num_updates=25860, lr=4.20305e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=74389
2023-02-21 09:55:34 - progress_bar.py[line:274] - INFO: epoch 001:  25906 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.8, bsz=40, num_updates=25870, lr=4.20269e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74400
2023-02-21 09:55:45 - progress_bar.py[line:274] - INFO: epoch 001:  25916 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112, bsz=40, num_updates=25880, lr=4.20233e-05, gnorm=0.144, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74412
2023-02-21 09:55:57 - progress_bar.py[line:274] - INFO: epoch 001:  25926 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.8, bsz=40, num_updates=25890, lr=4.20197e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=74423
2023-02-21 09:56:08 - progress_bar.py[line:274] - INFO: epoch 001:  25936 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=111.6, bsz=40, num_updates=25900, lr=4.20161e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=74434
2023-02-21 09:56:19 - progress_bar.py[line:274] - INFO: epoch 001:  25946 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=25910, lr=4.20124e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74446
2023-02-21 09:56:31 - progress_bar.py[line:274] - INFO: epoch 001:  25956 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.87, wpb=110.1, bsz=40, num_updates=25920, lr=4.20088e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74457
2023-02-21 09:56:42 - progress_bar.py[line:274] - INFO: epoch 001:  25966 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.1, bsz=40, num_updates=25930, lr=4.20052e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=74468
2023-02-21 09:56:53 - progress_bar.py[line:274] - INFO: epoch 001:  25976 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.87, wpb=112.6, bsz=40, num_updates=25940, lr=4.20016e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74480
2023-02-21 09:57:04 - progress_bar.py[line:274] - INFO: epoch 001:  25986 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.9, wpb=111.2, bsz=40, num_updates=25950, lr=4.1998e-05, gnorm=0.144, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=74491
2023-02-21 09:57:16 - progress_bar.py[line:274] - INFO: epoch 001:  25996 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.88, wpb=109.9, bsz=40, num_updates=25960, lr=4.19944e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74502
2023-02-21 09:57:27 - progress_bar.py[line:274] - INFO: epoch 001:  26006 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.8, ups=0.86, wpb=110.6, bsz=40, num_updates=25970, lr=4.19907e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=74514
2023-02-21 09:57:39 - progress_bar.py[line:274] - INFO: epoch 001:  26016 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=25980, lr=4.19871e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74525
2023-02-21 09:57:50 - progress_bar.py[line:274] - INFO: epoch 001:  26026 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.6, bsz=40, num_updates=25990, lr=4.19835e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74536
2023-02-21 09:58:01 - progress_bar.py[line:274] - INFO: epoch 001:  26036 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.2, bsz=40, num_updates=26000, lr=4.19799e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74547
2023-02-21 09:58:01 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 09:58:02 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 09:58:02 - train.py[line:551] - INFO: load:0.92 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 10:00:06 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 10:00:06 - train.py[line:551] - INFO: load:0.94 valid_run:123.69 task_valid:120.06 collect_output:2.41
2023-02-21 10:02:08 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 10:02:08 - train.py[line:551] - INFO: load:0.97 valid_run:245.64 task_valid:237.09 collect_output:6.09
2023-02-21 10:04:12 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 10:04:12 - train.py[line:551] - INFO: load:1.00 valid_run:369.43 task_valid:354.94 collect_output:10.80
2023-02-21 10:06:16 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 10:06:16 - train.py[line:551] - INFO: load:1.03 valid_run:493.30 task_valid:469.86 collect_output:18.49
2023-02-21 10:08:18 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 10:08:18 - train.py[line:551] - INFO: load:1.06 valid_run:615.52 task_valid:588.34 collect_output:21.03
2023-02-21 10:10:23 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 10:10:23 - train.py[line:551] - INFO: load:1.08 valid_run:740.06 task_valid:708.27 collect_output:24.45
2023-02-21 10:12:27 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 10:12:27 - train.py[line:551] - INFO: load:1.11 valid_run:864.67 task_valid:827.72 collect_output:28.43
2023-02-21 10:14:31 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 10:14:31 - train.py[line:551] - INFO: load:1.14 valid_run:988.50 task_valid:945.34 collect_output:33.46
2023-02-21 10:16:37 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 10:16:37 - train.py[line:551] - INFO: load:1.17 valid_run:1114.29 task_valid:1063.87 collect_output:39.50
2023-02-21 10:18:40 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 10:18:40 - train.py[line:551] - INFO: load:1.19 valid_run:1237.62 task_valid:1177.63 collect_output:47.83
2023-02-21 10:20:42 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 10:20:42 - train.py[line:551] - INFO: load:1.22 valid_run:1359.57 task_valid:1294.50 collect_output:51.66
2023-02-21 10:22:46 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 10:22:46 - train.py[line:551] - INFO: load:1.25 valid_run:1482.80 task_valid:1412.70 collect_output:55.43
2023-02-21 10:24:47 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 10:24:47 - train.py[line:551] - INFO: load:1.27 valid_run:1603.62 task_valid:1527.98 collect_output:59.69
2023-02-21 10:26:49 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 10:26:49 - train.py[line:551] - INFO: load:1.30 valid_run:1726.21 task_valid:1646.87 collect_output:62.19
2023-02-21 10:28:52 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 10:28:52 - train.py[line:551] - INFO: load:1.33 valid_run:1848.92 task_valid:1764.25 collect_output:66.28
2023-02-21 10:30:55 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 10:30:55 - train.py[line:551] - INFO: load:1.35 valid_run:1971.95 task_valid:1879.74 collect_output:72.59
2023-02-21 10:32:59 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 10:32:59 - train.py[line:551] - INFO: load:1.40 valid_run:2095.21 task_valid:1997.55 collect_output:76.79
2023-02-21 10:35:01 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 10:35:01 - train.py[line:551] - INFO: load:1.42 valid_run:2217.56 task_valid:2116.50 collect_output:79.02
2023-02-21 10:37:04 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 10:37:04 - train.py[line:551] - INFO: load:1.45 valid_run:2340.18 task_valid:2234.49 collect_output:82.44
2023-02-21 10:39:06 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 10:39:06 - train.py[line:551] - INFO: load:1.48 valid_run:2462.45 task_valid:2352.15 collect_output:85.85
2023-02-21 10:41:09 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 10:41:09 - train.py[line:551] - INFO: load:1.51 valid_run:2585.53 task_valid:2469.25 collect_output:90.61
2023-02-21 10:43:13 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 10:43:13 - train.py[line:551] - INFO: load:1.54 valid_run:2708.96 task_valid:2589.16 collect_output:92.90
2023-02-21 10:45:15 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 10:45:15 - train.py[line:551] - INFO: load:1.57 valid_run:2831.31 task_valid:2704.88 collect_output:98.31
2023-02-21 10:47:17 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 10:47:17 - train.py[line:551] - INFO: load:1.60 valid_run:2953.00 task_valid:2822.50 collect_output:101.11
2023-02-21 10:49:20 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 10:49:20 - train.py[line:551] - INFO: load:1.62 valid_run:3076.30 task_valid:2939.67 collect_output:106.05
2023-02-21 10:51:25 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 10:51:25 - train.py[line:551] - INFO: load:1.65 valid_run:3200.79 task_valid:3057.15 collect_output:111.84
2023-02-21 10:53:26 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 10:53:26 - train.py[line:551] - INFO: load:1.68 valid_run:3321.93 task_valid:3172.39 collect_output:116.55
2023-02-21 10:55:29 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 10:55:29 - train.py[line:551] - INFO: load:1.71 valid_run:3445.40 task_valid:3292.99 collect_output:118.17
2023-02-21 10:57:33 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 10:57:33 - train.py[line:551] - INFO: load:1.74 valid_run:3568.80 task_valid:3409.89 collect_output:123.49
2023-02-21 10:59:37 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 10:59:37 - train.py[line:551] - INFO: load:1.76 valid_run:3692.72 task_valid:3529.97 collect_output:126.15
2023-02-21 11:01:40 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 11:01:40 - train.py[line:551] - INFO: load:1.79 valid_run:3815.64 task_valid:3649.89 collect_output:127.93

====================================================================================================
SGG eval:     R @ 50: 0.5821;     R @ 100: 0.6109;     R @ 500: 0.6319;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3560;    mR @ 100: 0.3927;    mR @ 500: 0.4183;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.8750) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.2500) (hanging from:0.3387) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9216) (says:0.0000) (sitting on:0.6616) (standing on:0.3652) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-02-21 11:02:11 - train.py[line:487] - INFO: 0.6109148459383753

====================================================================================================
SGG eval:     R @ 50: 0.5821;     R @ 100: 0.6109;     R @ 500: 0.6319;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3560;    mR @ 100: 0.3927;    mR @ 500: 0.4183;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.8750) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.2500) (hanging from:0.3387) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9216) (says:0.0000) (sitting on:0.6616) (standing on:0.3652) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-02-21 11:02:11 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 11:02:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.235 | loss_v1 0 | loss_v2 0 | nll_loss 0.068 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.610915 | ppl 1.05 | vqa_score 0.4617 | wps 116.5 | wpb 72 | bsz 24 | num_updates 26000 | best_R@100 0.691462
2023-02-21 11:02:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 26000 updates
2023-02-21 11:02:11 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_26000.pt
2023-02-21 11:02:17 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_26000.pt
2023-02-21 11:02:20 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_26000.pt (epoch 1 @ 26000 updates, score 0.6109148459383753) (writing took 8.703253887593746 seconds)
2023-02-21 11:02:32 - progress_bar.py[line:274] - INFO: epoch 001:  26046 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=112.4, bsz=40, num_updates=26010, lr=4.19763e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=78418
2023-02-21 11:02:43 - progress_bar.py[line:274] - INFO: epoch 001:  26056 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.5, bsz=40, num_updates=26020, lr=4.19726e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78429
2023-02-21 11:02:54 - progress_bar.py[line:274] - INFO: epoch 001:  26066 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=110.4, bsz=40, num_updates=26030, lr=4.1969e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=78440
2023-02-21 11:03:05 - progress_bar.py[line:274] - INFO: epoch 001:  26076 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.6, bsz=40, num_updates=26040, lr=4.19654e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78452
2023-02-21 11:03:17 - progress_bar.py[line:274] - INFO: epoch 001:  26086 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=111.4, bsz=40, num_updates=26050, lr=4.19618e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78463
2023-02-21 11:03:26 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 11:03:28 - progress_bar.py[line:274] - INFO: epoch 001:  26097 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.9, ups=0.85, wpb=112, bsz=40, num_updates=26060, lr=4.19582e-05, gnorm=0.053, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=78475
2023-02-21 11:03:40 - progress_bar.py[line:274] - INFO: epoch 001:  26107 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.6, bsz=40, num_updates=26070, lr=4.19546e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78486
2023-02-21 11:03:50 - progress_bar.py[line:274] - INFO: epoch 001:  26117 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.7, ups=0.94, wpb=112.9, bsz=40, num_updates=26080, lr=4.19509e-05, gnorm=0.072, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78497
2023-02-21 11:04:02 - progress_bar.py[line:274] - INFO: epoch 001:  26127 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.7, bsz=40, num_updates=26090, lr=4.19473e-05, gnorm=0.136, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78508
2023-02-21 11:04:13 - progress_bar.py[line:274] - INFO: epoch 001:  26137 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113.6, nsentences=40, sample_size=113.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.88, wpb=113.6, bsz=40, num_updates=26100, lr=4.19437e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=78519
2023-02-21 11:04:25 - progress_bar.py[line:274] - INFO: epoch 001:  26147 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=111.1, bsz=40, num_updates=26110, lr=4.19401e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=78531
2023-02-21 11:04:36 - progress_bar.py[line:274] - INFO: epoch 001:  26157 / 71012 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.88, wpb=112.2, bsz=40, num_updates=26120, lr=4.19365e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78542
2023-02-21 11:04:47 - progress_bar.py[line:274] - INFO: epoch 001:  26167 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=26130, lr=4.19328e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78554
2023-02-21 11:04:58 - progress_bar.py[line:274] - INFO: epoch 001:  26177 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.89, wpb=112.9, bsz=40, num_updates=26140, lr=4.19292e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78565
2023-02-21 11:05:09 - progress_bar.py[line:274] - INFO: epoch 001:  26187 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.2, bsz=40, num_updates=26150, lr=4.19256e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78576
2023-02-21 11:05:20 - progress_bar.py[line:274] - INFO: epoch 001:  26197 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.8, bsz=40, num_updates=26160, lr=4.1922e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78587
2023-02-21 11:05:32 - progress_bar.py[line:274] - INFO: epoch 001:  26207 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.4, bsz=40, num_updates=26170, lr=4.19184e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78598
2023-02-21 11:05:43 - progress_bar.py[line:274] - INFO: epoch 001:  26217 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.5, ups=0.86, wpb=110.5, bsz=40, num_updates=26180, lr=4.19148e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=78610
2023-02-21 11:05:55 - progress_bar.py[line:274] - INFO: epoch 001:  26227 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111, bsz=40, num_updates=26190, lr=4.19111e-05, gnorm=0.136, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78621
2023-02-21 11:06:06 - progress_bar.py[line:274] - INFO: epoch 001:  26237 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.4, bsz=40, num_updates=26200, lr=4.19075e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78632
2023-02-21 11:06:17 - progress_bar.py[line:274] - INFO: epoch 001:  26247 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.1, bsz=40, num_updates=26210, lr=4.19039e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78643
2023-02-21 11:06:29 - progress_bar.py[line:274] - INFO: epoch 001:  26257 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=112.3, bsz=40, num_updates=26220, lr=4.19003e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78655
2023-02-21 11:06:39 - progress_bar.py[line:274] - INFO: epoch 001:  26267 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.93, wpb=110.7, bsz=40, num_updates=26230, lr=4.18967e-05, gnorm=0.062, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78666
2023-02-21 11:06:51 - progress_bar.py[line:274] - INFO: epoch 001:  26277 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.9, wpb=112.3, bsz=40, num_updates=26240, lr=4.1893e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78677
2023-02-21 11:07:02 - progress_bar.py[line:274] - INFO: epoch 001:  26287 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.7, bsz=40, num_updates=26250, lr=4.18894e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=78688
2023-02-21 11:07:13 - progress_bar.py[line:274] - INFO: epoch 001:  26297 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.9, bsz=40, num_updates=26260, lr=4.18858e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78699
2023-02-21 11:07:24 - progress_bar.py[line:274] - INFO: epoch 001:  26307 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.3, bsz=40, num_updates=26270, lr=4.18822e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78711
2023-02-21 11:07:35 - progress_bar.py[line:274] - INFO: epoch 001:  26317 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.9, bsz=40, num_updates=26280, lr=4.18786e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=78722
2023-02-21 11:07:46 - progress_bar.py[line:274] - INFO: epoch 001:  26327 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.2, bsz=40, num_updates=26290, lr=4.1875e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78733
2023-02-21 11:07:58 - progress_bar.py[line:274] - INFO: epoch 001:  26337 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.8, bsz=40, num_updates=26300, lr=4.18713e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=78744
2023-02-21 11:08:09 - progress_bar.py[line:274] - INFO: epoch 001:  26347 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=26310, lr=4.18677e-05, gnorm=0.072, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=78756
2023-02-21 11:08:20 - progress_bar.py[line:274] - INFO: epoch 001:  26357 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112, bsz=40, num_updates=26320, lr=4.18641e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78767
2023-02-21 11:08:32 - progress_bar.py[line:274] - INFO: epoch 001:  26367 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.3, bsz=40, num_updates=26330, lr=4.18605e-05, gnorm=0.06, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78778
2023-02-21 11:08:43 - progress_bar.py[line:274] - INFO: epoch 001:  26377 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.5, bsz=40, num_updates=26340, lr=4.18569e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78789
2023-02-21 11:08:54 - progress_bar.py[line:274] - INFO: epoch 001:  26387 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=110.9, bsz=40, num_updates=26350, lr=4.18532e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78801
2023-02-21 11:09:06 - progress_bar.py[line:274] - INFO: epoch 001:  26397 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=112.4, bsz=40, num_updates=26360, lr=4.18496e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78812
2023-02-21 11:09:17 - progress_bar.py[line:274] - INFO: epoch 001:  26407 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.89, wpb=109.1, bsz=40, num_updates=26370, lr=4.1846e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78823
2023-02-21 11:09:28 - progress_bar.py[line:274] - INFO: epoch 001:  26417 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.93, wpb=111.3, bsz=40, num_updates=26380, lr=4.18424e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78834
2023-02-21 11:09:39 - progress_bar.py[line:274] - INFO: epoch 001:  26427 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.2, bsz=40, num_updates=26390, lr=4.18388e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=78845
2023-02-21 11:09:50 - progress_bar.py[line:274] - INFO: epoch 001:  26437 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112, bsz=40, num_updates=26400, lr=4.18352e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=78856
2023-02-21 11:10:01 - progress_bar.py[line:274] - INFO: epoch 001:  26447 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=111, bsz=40, num_updates=26410, lr=4.18315e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=78868
2023-02-21 11:10:12 - progress_bar.py[line:274] - INFO: epoch 001:  26457 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=110.7, bsz=40, num_updates=26420, lr=4.18279e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78879
2023-02-21 11:10:24 - progress_bar.py[line:274] - INFO: epoch 001:  26467 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.86, wpb=111.5, bsz=40, num_updates=26430, lr=4.18243e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=78890
2023-02-21 11:10:35 - progress_bar.py[line:274] - INFO: epoch 001:  26477 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.4, bsz=40, num_updates=26440, lr=4.18207e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=78902
2023-02-21 11:10:46 - progress_bar.py[line:274] - INFO: epoch 001:  26487 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.92, wpb=112.2, bsz=40, num_updates=26450, lr=4.18171e-05, gnorm=0.061, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=78913
2023-02-21 11:10:57 - progress_bar.py[line:274] - INFO: epoch 001:  26497 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.9, nsentences=40, sample_size=113.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.89, wpb=113.9, bsz=40, num_updates=26460, lr=4.18134e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=78924
2023-02-21 11:11:09 - progress_bar.py[line:274] - INFO: epoch 001:  26507 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=111.6, bsz=40, num_updates=26470, lr=4.18098e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=78935
2023-02-21 11:11:20 - progress_bar.py[line:274] - INFO: epoch 001:  26517 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=112.1, bsz=40, num_updates=26480, lr=4.18062e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78947
2023-02-21 11:11:32 - progress_bar.py[line:274] - INFO: epoch 001:  26527 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.2, bsz=40, num_updates=26490, lr=4.18026e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=78958
2023-02-21 11:11:43 - progress_bar.py[line:274] - INFO: epoch 001:  26537 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.6, bsz=40, num_updates=26500, lr=4.1799e-05, gnorm=0.072, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=78969
2023-02-21 11:11:54 - progress_bar.py[line:274] - INFO: epoch 001:  26547 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.6, bsz=40, num_updates=26510, lr=4.17954e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78980
2023-02-21 11:12:05 - progress_bar.py[line:274] - INFO: epoch 001:  26557 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=112.2, bsz=40, num_updates=26520, lr=4.17917e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=78992
2023-02-21 11:12:17 - progress_bar.py[line:274] - INFO: epoch 001:  26567 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111, bsz=40, num_updates=26530, lr=4.17881e-05, gnorm=0.132, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79003
2023-02-21 11:12:28 - progress_bar.py[line:274] - INFO: epoch 001:  26577 / 71012 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=99.7, ups=0.9, wpb=111.2, bsz=40, num_updates=26540, lr=4.17845e-05, gnorm=0.061, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79014
2023-02-21 11:12:39 - progress_bar.py[line:274] - INFO: epoch 001:  26587 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112.9, bsz=40, num_updates=26550, lr=4.17809e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=79026
2023-02-21 11:12:51 - progress_bar.py[line:274] - INFO: epoch 001:  26597 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=26560, lr=4.17773e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79037
2023-02-21 11:13:01 - progress_bar.py[line:274] - INFO: epoch 001:  26607 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.93, wpb=112.6, bsz=40, num_updates=26570, lr=4.17736e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79048
2023-02-21 11:13:13 - progress_bar.py[line:274] - INFO: epoch 001:  26617 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.5, bsz=40, num_updates=26580, lr=4.177e-05, gnorm=0.105, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79059
2023-02-21 11:13:24 - progress_bar.py[line:274] - INFO: epoch 001:  26627 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.1, bsz=40, num_updates=26590, lr=4.17664e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79070
2023-02-21 11:13:35 - progress_bar.py[line:274] - INFO: epoch 001:  26637 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.88, wpb=109.5, bsz=40, num_updates=26600, lr=4.17628e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79082
2023-02-21 11:13:47 - progress_bar.py[line:274] - INFO: epoch 001:  26647 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=111, bsz=40, num_updates=26610, lr=4.17592e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79093
2023-02-21 11:13:58 - progress_bar.py[line:274] - INFO: epoch 001:  26657 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=26620, lr=4.17556e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79104
2023-02-21 11:14:09 - progress_bar.py[line:274] - INFO: epoch 001:  26667 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=114.1, nsentences=40, sample_size=114.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.88, wpb=114.1, bsz=40, num_updates=26630, lr=4.17519e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79116
2023-02-21 11:14:21 - progress_bar.py[line:274] - INFO: epoch 001:  26677 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112.7, bsz=40, num_updates=26640, lr=4.17483e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79127
2023-02-21 11:14:32 - progress_bar.py[line:274] - INFO: epoch 001:  26687 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.9, bsz=40, num_updates=26650, lr=4.17447e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79138
2023-02-21 11:14:43 - progress_bar.py[line:274] - INFO: epoch 001:  26697 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.86, wpb=112.1, bsz=40, num_updates=26660, lr=4.17411e-05, gnorm=0.12, clip=0, loss_scale=4096, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=79150
2023-02-21 11:14:55 - progress_bar.py[line:274] - INFO: epoch 001:  26707 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.1, bsz=40, num_updates=26670, lr=4.17375e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79161
2023-02-21 11:15:06 - progress_bar.py[line:274] - INFO: epoch 001:  26717 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112.1, bsz=40, num_updates=26680, lr=4.17338e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79172
2023-02-21 11:15:17 - progress_bar.py[line:274] - INFO: epoch 001:  26727 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.89, wpb=113, bsz=40, num_updates=26690, lr=4.17302e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79183
2023-02-21 11:15:28 - progress_bar.py[line:274] - INFO: epoch 001:  26737 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.5, bsz=40, num_updates=26700, lr=4.17266e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79195
2023-02-21 11:15:39 - progress_bar.py[line:274] - INFO: epoch 001:  26747 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=26710, lr=4.1723e-05, gnorm=0.135, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79206
2023-02-21 11:15:51 - progress_bar.py[line:274] - INFO: epoch 001:  26757 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=112.1, bsz=40, num_updates=26720, lr=4.17194e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79217
2023-02-21 11:16:02 - progress_bar.py[line:274] - INFO: epoch 001:  26767 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.7, bsz=40, num_updates=26730, lr=4.17158e-05, gnorm=0.112, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79228
2023-02-21 11:16:10 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 11:16:14 - progress_bar.py[line:274] - INFO: epoch 001:  26778 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88.9, ups=0.8, wpb=110.5, bsz=40, num_updates=26740, lr=4.17121e-05, gnorm=0.063, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=79241
2023-02-21 11:16:26 - progress_bar.py[line:274] - INFO: epoch 001:  26788 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.4, ups=0.86, wpb=110.4, bsz=40, num_updates=26750, lr=4.17085e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=79252
2023-02-21 11:16:37 - progress_bar.py[line:274] - INFO: epoch 001:  26798 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=114, nsentences=40, sample_size=114, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.91, wpb=114, bsz=40, num_updates=26760, lr=4.17049e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79263
2023-02-21 11:16:48 - progress_bar.py[line:274] - INFO: epoch 001:  26808 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=110.8, bsz=40, num_updates=26770, lr=4.17013e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79274
2023-02-21 11:16:59 - progress_bar.py[line:274] - INFO: epoch 001:  26818 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.7, bsz=40, num_updates=26780, lr=4.16977e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79286
2023-02-21 11:17:11 - progress_bar.py[line:274] - INFO: epoch 001:  26828 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.2, bsz=40, num_updates=26790, lr=4.1694e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79297
2023-02-21 11:17:22 - progress_bar.py[line:274] - INFO: epoch 001:  26838 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.1, bsz=40, num_updates=26800, lr=4.16904e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79308
2023-02-21 11:17:33 - progress_bar.py[line:274] - INFO: epoch 001:  26848 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.92, wpb=112, bsz=40, num_updates=26810, lr=4.16868e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=79319
2023-02-21 11:17:44 - progress_bar.py[line:274] - INFO: epoch 001:  26858 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.8, bsz=40, num_updates=26820, lr=4.16832e-05, gnorm=0.195, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79331
2023-02-21 11:17:56 - progress_bar.py[line:274] - INFO: epoch 001:  26868 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.8, bsz=40, num_updates=26830, lr=4.16796e-05, gnorm=0.131, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79342
2023-02-21 11:18:07 - progress_bar.py[line:274] - INFO: epoch 001:  26878 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.5, bsz=40, num_updates=26840, lr=4.1676e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79353
2023-02-21 11:18:18 - progress_bar.py[line:274] - INFO: epoch 001:  26888 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112, bsz=40, num_updates=26850, lr=4.16723e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79364
2023-02-21 11:18:29 - progress_bar.py[line:274] - INFO: epoch 001:  26898 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=26860, lr=4.16687e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79375
2023-02-21 11:18:40 - progress_bar.py[line:274] - INFO: epoch 001:  26908 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.88, wpb=109.2, bsz=40, num_updates=26870, lr=4.16651e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79387
2023-02-21 11:18:53 - progress_bar.py[line:274] - INFO: epoch 001:  26918 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.7, ups=0.85, wpb=111.4, bsz=40, num_updates=26880, lr=4.16615e-05, gnorm=0.156, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=79399
2023-02-21 11:19:04 - progress_bar.py[line:274] - INFO: epoch 001:  26928 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=26890, lr=4.16579e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79410
2023-02-21 11:19:15 - progress_bar.py[line:274] - INFO: epoch 001:  26938 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.6, bsz=40, num_updates=26900, lr=4.16542e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=79422
2023-02-21 11:19:27 - progress_bar.py[line:274] - INFO: epoch 001:  26948 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110.2, bsz=40, num_updates=26910, lr=4.16506e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=79433
2023-02-21 11:19:38 - progress_bar.py[line:274] - INFO: epoch 001:  26958 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=111.1, bsz=40, num_updates=26920, lr=4.1647e-05, gnorm=0.117, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79444
2023-02-21 11:19:50 - progress_bar.py[line:274] - INFO: epoch 001:  26968 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.86, wpb=113.1, bsz=40, num_updates=26930, lr=4.16434e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=79456
2023-02-21 11:20:01 - progress_bar.py[line:274] - INFO: epoch 001:  26978 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=26940, lr=4.16398e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=79467
2023-02-21 11:20:12 - progress_bar.py[line:274] - INFO: epoch 001:  26988 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=113.2, bsz=40, num_updates=26950, lr=4.16362e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79479
2023-02-21 11:20:23 - progress_bar.py[line:274] - INFO: epoch 001:  26998 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.8, bsz=40, num_updates=26960, lr=4.16325e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79490
2023-02-21 11:20:35 - progress_bar.py[line:274] - INFO: epoch 001:  27008 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.4, bsz=40, num_updates=26970, lr=4.16289e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79501
2023-02-21 11:20:46 - progress_bar.py[line:274] - INFO: epoch 001:  27018 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.1, bsz=40, num_updates=26980, lr=4.16253e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79512
2023-02-21 11:20:57 - progress_bar.py[line:274] - INFO: epoch 001:  27028 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=26990, lr=4.16217e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79524
2023-02-21 11:21:09 - progress_bar.py[line:274] - INFO: epoch 001:  27038 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=111.8, bsz=40, num_updates=27000, lr=4.16181e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79535
2023-02-21 11:21:21 - progress_bar.py[line:274] - INFO: epoch 001:  27048 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.4, ups=0.85, wpb=111.2, bsz=40, num_updates=27010, lr=4.16144e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=79547
2023-02-21 11:21:32 - progress_bar.py[line:274] - INFO: epoch 001:  27058 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.8, bsz=40, num_updates=27020, lr=4.16108e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79558
2023-02-21 11:21:44 - progress_bar.py[line:274] - INFO: epoch 001:  27068 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.86, wpb=111.2, bsz=40, num_updates=27030, lr=4.16072e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=79570
2023-02-21 11:21:55 - progress_bar.py[line:274] - INFO: epoch 001:  27078 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.86, wpb=111.6, bsz=40, num_updates=27040, lr=4.16036e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=79582
2023-02-21 11:22:06 - progress_bar.py[line:274] - INFO: epoch 001:  27088 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.91, wpb=112.2, bsz=40, num_updates=27050, lr=4.16e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79593
2023-02-21 11:22:17 - progress_bar.py[line:274] - INFO: epoch 001:  27098 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.9, bsz=40, num_updates=27060, lr=4.15964e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79604
2023-02-21 11:22:29 - progress_bar.py[line:274] - INFO: epoch 001:  27108 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.89, wpb=112.8, bsz=40, num_updates=27070, lr=4.15927e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79615
2023-02-21 11:22:40 - progress_bar.py[line:274] - INFO: epoch 001:  27118 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=111.3, bsz=40, num_updates=27080, lr=4.15891e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=79626
2023-02-21 11:22:51 - progress_bar.py[line:274] - INFO: epoch 001:  27128 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.7, bsz=40, num_updates=27090, lr=4.15855e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79637
2023-02-21 11:23:02 - progress_bar.py[line:274] - INFO: epoch 001:  27138 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112, bsz=40, num_updates=27100, lr=4.15819e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79649
2023-02-21 11:23:14 - progress_bar.py[line:274] - INFO: epoch 001:  27148 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.85, wpb=112.7, bsz=40, num_updates=27110, lr=4.15783e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=79660
2023-02-21 11:23:25 - progress_bar.py[line:274] - INFO: epoch 001:  27158 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=112.2, bsz=40, num_updates=27120, lr=4.15746e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79672
2023-02-21 11:23:36 - progress_bar.py[line:274] - INFO: epoch 001:  27168 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.8, bsz=40, num_updates=27130, lr=4.1571e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79683
2023-02-21 11:23:47 - progress_bar.py[line:274] - INFO: epoch 001:  27178 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112.1, bsz=40, num_updates=27140, lr=4.15674e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79694
2023-02-21 11:23:58 - progress_bar.py[line:274] - INFO: epoch 001:  27188 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.93, wpb=110.2, bsz=40, num_updates=27150, lr=4.15638e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79705
2023-02-21 11:24:10 - progress_bar.py[line:274] - INFO: epoch 001:  27198 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.87, wpb=112.1, bsz=40, num_updates=27160, lr=4.15602e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79716
2023-02-21 11:24:21 - progress_bar.py[line:274] - INFO: epoch 001:  27208 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=27170, lr=4.15566e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79727
2023-02-21 11:24:33 - progress_bar.py[line:274] - INFO: epoch 001:  27218 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.86, wpb=111.6, bsz=40, num_updates=27180, lr=4.15529e-05, gnorm=0.07, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=79739
2023-02-21 11:24:44 - progress_bar.py[line:274] - INFO: epoch 001:  27228 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.86, wpb=112.1, bsz=40, num_updates=27190, lr=4.15493e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=79751
2023-02-21 11:24:55 - progress_bar.py[line:274] - INFO: epoch 001:  27238 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=100.1, ups=0.89, wpb=112.5, bsz=40, num_updates=27200, lr=4.15457e-05, gnorm=0.061, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79762
2023-02-21 11:25:07 - progress_bar.py[line:274] - INFO: epoch 001:  27248 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.5, bsz=40, num_updates=27210, lr=4.15421e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79773
2023-02-21 11:25:18 - progress_bar.py[line:274] - INFO: epoch 001:  27258 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.7, bsz=40, num_updates=27220, lr=4.15385e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79784
2023-02-21 11:25:29 - progress_bar.py[line:274] - INFO: epoch 001:  27268 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.7, bsz=40, num_updates=27230, lr=4.15348e-05, gnorm=0.053, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79795
2023-02-21 11:25:41 - progress_bar.py[line:274] - INFO: epoch 001:  27278 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.4, ups=0.85, wpb=111.9, bsz=40, num_updates=27240, lr=4.15312e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=79807
2023-02-21 11:25:52 - progress_bar.py[line:274] - INFO: epoch 001:  27288 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=99.6, ups=0.89, wpb=111.7, bsz=40, num_updates=27250, lr=4.15276e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79818
2023-02-21 11:26:03 - progress_bar.py[line:274] - INFO: epoch 001:  27298 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=27260, lr=4.1524e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79830
2023-02-21 11:26:15 - progress_bar.py[line:274] - INFO: epoch 001:  27308 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.4, bsz=40, num_updates=27270, lr=4.15204e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79841
2023-02-21 11:26:26 - progress_bar.py[line:274] - INFO: epoch 001:  27318 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=111.6, bsz=40, num_updates=27280, lr=4.15168e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79852
2023-02-21 11:26:38 - progress_bar.py[line:274] - INFO: epoch 001:  27328 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=112.3, bsz=40, num_updates=27290, lr=4.15131e-05, gnorm=0.137, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79864
2023-02-21 11:26:49 - progress_bar.py[line:274] - INFO: epoch 001:  27338 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.9, wpb=113.3, bsz=40, num_updates=27300, lr=4.15095e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79875
2023-02-21 11:27:00 - progress_bar.py[line:274] - INFO: epoch 001:  27348 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=114.4, nsentences=40, sample_size=114.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.88, wpb=114.4, bsz=40, num_updates=27310, lr=4.15059e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79886
2023-02-21 11:27:11 - progress_bar.py[line:274] - INFO: epoch 001:  27358 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.9, wpb=112.3, bsz=40, num_updates=27320, lr=4.15023e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79897
2023-02-21 11:27:21 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 11:27:23 - progress_bar.py[line:274] - INFO: epoch 001:  27369 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.9, ups=0.84, wpb=111.2, bsz=40, num_updates=27330, lr=4.14987e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=79909
2023-02-21 11:27:34 - progress_bar.py[line:274] - INFO: epoch 001:  27379 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=112.3, bsz=40, num_updates=27340, lr=4.1495e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79921
2023-02-21 11:27:46 - progress_bar.py[line:274] - INFO: epoch 001:  27389 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112.1, bsz=40, num_updates=27350, lr=4.14914e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79932
2023-02-21 11:27:57 - progress_bar.py[line:274] - INFO: epoch 001:  27399 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.3, bsz=40, num_updates=27360, lr=4.14878e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79944
2023-02-21 11:28:08 - progress_bar.py[line:274] - INFO: epoch 001:  27409 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=27370, lr=4.14842e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79955
2023-02-21 11:28:20 - progress_bar.py[line:274] - INFO: epoch 001:  27419 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.5, bsz=40, num_updates=27380, lr=4.14806e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79966
2023-02-21 11:28:31 - progress_bar.py[line:274] - INFO: epoch 001:  27429 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.1, bsz=40, num_updates=27390, lr=4.1477e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79977
2023-02-21 11:28:42 - progress_bar.py[line:274] - INFO: epoch 001:  27439 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112, bsz=40, num_updates=27400, lr=4.14733e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79988
2023-02-21 11:28:54 - progress_bar.py[line:274] - INFO: epoch 001:  27449 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.8, ups=0.86, wpb=111.7, bsz=40, num_updates=27410, lr=4.14697e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=80000
2023-02-21 11:29:05 - progress_bar.py[line:274] - INFO: epoch 001:  27459 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=111.5, bsz=40, num_updates=27420, lr=4.14661e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80011
2023-02-21 11:29:16 - progress_bar.py[line:274] - INFO: epoch 001:  27469 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.2, bsz=40, num_updates=27430, lr=4.14625e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=80023
2023-02-21 11:29:28 - progress_bar.py[line:274] - INFO: epoch 001:  27479 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.2, bsz=40, num_updates=27440, lr=4.14589e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80034
2023-02-21 11:29:39 - progress_bar.py[line:274] - INFO: epoch 001:  27489 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=112.2, bsz=40, num_updates=27450, lr=4.14552e-05, gnorm=0.051, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=80046
2023-02-21 11:29:50 - progress_bar.py[line:274] - INFO: epoch 001:  27499 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.1, bsz=40, num_updates=27460, lr=4.14516e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80057
2023-02-21 11:30:02 - progress_bar.py[line:274] - INFO: epoch 001:  27509 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.8, bsz=40, num_updates=27470, lr=4.1448e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=80068
2023-02-21 11:30:13 - progress_bar.py[line:274] - INFO: epoch 001:  27519 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.3, bsz=40, num_updates=27480, lr=4.14444e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80079
2023-02-21 11:30:24 - progress_bar.py[line:274] - INFO: epoch 001:  27529 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=112.2, bsz=40, num_updates=27490, lr=4.14408e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80091
2023-02-21 11:30:36 - progress_bar.py[line:274] - INFO: epoch 001:  27539 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.4, bsz=40, num_updates=27500, lr=4.14372e-05, gnorm=0.057, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80102
2023-02-21 11:30:47 - progress_bar.py[line:274] - INFO: epoch 001:  27549 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111, bsz=40, num_updates=27510, lr=4.14335e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80113
2023-02-21 11:30:58 - progress_bar.py[line:274] - INFO: epoch 001:  27559 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=27520, lr=4.14299e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80124
2023-02-21 11:31:10 - progress_bar.py[line:274] - INFO: epoch 001:  27569 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.7, ups=0.87, wpb=110.6, bsz=40, num_updates=27530, lr=4.14263e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80136
2023-02-21 11:31:21 - progress_bar.py[line:274] - INFO: epoch 001:  27579 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.4, bsz=40, num_updates=27540, lr=4.14227e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80147
2023-02-21 11:31:32 - progress_bar.py[line:274] - INFO: epoch 001:  27589 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.88, wpb=112.9, bsz=40, num_updates=27550, lr=4.14191e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80158
2023-02-21 11:31:43 - progress_bar.py[line:274] - INFO: epoch 001:  27599 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.3, bsz=40, num_updates=27560, lr=4.14154e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80170
2023-02-21 11:31:54 - progress_bar.py[line:274] - INFO: epoch 001:  27609 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.91, wpb=112.3, bsz=40, num_updates=27570, lr=4.14118e-05, gnorm=0.072, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80181
2023-02-21 11:32:05 - progress_bar.py[line:274] - INFO: epoch 001:  27619 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.8, bsz=40, num_updates=27580, lr=4.14082e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80192
2023-02-21 11:32:16 - progress_bar.py[line:274] - INFO: epoch 001:  27629 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.91, wpb=109.8, bsz=40, num_updates=27590, lr=4.14046e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=80203
2023-02-21 11:32:28 - progress_bar.py[line:274] - INFO: epoch 001:  27639 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.88, wpb=113.1, bsz=40, num_updates=27600, lr=4.1401e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80214
2023-02-21 11:32:39 - progress_bar.py[line:274] - INFO: epoch 001:  27649 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.91, wpb=108.4, bsz=40, num_updates=27610, lr=4.13974e-05, gnorm=0.163, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80225
2023-02-21 11:32:50 - progress_bar.py[line:274] - INFO: epoch 001:  27659 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=27620, lr=4.13937e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80237
2023-02-21 11:33:01 - progress_bar.py[line:274] - INFO: epoch 001:  27669 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=111.5, bsz=40, num_updates=27630, lr=4.13901e-05, gnorm=0.057, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80248
2023-02-21 11:33:12 - progress_bar.py[line:274] - INFO: epoch 001:  27679 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=27640, lr=4.13865e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=80259
2023-02-21 11:33:24 - progress_bar.py[line:274] - INFO: epoch 001:  27689 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=112.6, bsz=40, num_updates=27650, lr=4.13829e-05, gnorm=0.07, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=80270
2023-02-21 11:33:35 - progress_bar.py[line:274] - INFO: epoch 001:  27699 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=27660, lr=4.13793e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80281
2023-02-21 11:33:46 - progress_bar.py[line:274] - INFO: epoch 001:  27709 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.3, bsz=40, num_updates=27670, lr=4.13756e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80293
2023-02-21 11:33:58 - progress_bar.py[line:274] - INFO: epoch 001:  27719 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.9, bsz=40, num_updates=27680, lr=4.1372e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80304
2023-02-21 11:34:09 - progress_bar.py[line:274] - INFO: epoch 001:  27729 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.87, wpb=112.7, bsz=40, num_updates=27690, lr=4.13684e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=80315
2023-02-21 11:34:20 - progress_bar.py[line:274] - INFO: epoch 001:  27739 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.5, bsz=40, num_updates=27700, lr=4.13648e-05, gnorm=0.117, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80327
2023-02-21 11:34:32 - progress_bar.py[line:274] - INFO: epoch 001:  27749 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.8, ups=0.86, wpb=112, bsz=40, num_updates=27710, lr=4.13612e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=80338
2023-02-21 11:34:44 - progress_bar.py[line:274] - INFO: epoch 001:  27759 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.86, wpb=112.4, bsz=40, num_updates=27720, lr=4.13576e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80350
2023-02-21 11:34:55 - progress_bar.py[line:274] - INFO: epoch 001:  27769 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.86, wpb=111.5, bsz=40, num_updates=27730, lr=4.13539e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=80362
2023-02-21 11:35:07 - progress_bar.py[line:274] - INFO: epoch 001:  27779 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=112.1, bsz=40, num_updates=27740, lr=4.13503e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80373
2023-02-21 11:35:18 - progress_bar.py[line:274] - INFO: epoch 001:  27789 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.9, bsz=40, num_updates=27750, lr=4.13467e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80385
2023-02-21 11:35:30 - progress_bar.py[line:274] - INFO: epoch 001:  27799 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=111.8, bsz=40, num_updates=27760, lr=4.13431e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=80396
2023-02-21 11:35:41 - progress_bar.py[line:274] - INFO: epoch 001:  27809 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=112.1, bsz=40, num_updates=27770, lr=4.13395e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80407
2023-02-21 11:35:52 - progress_bar.py[line:274] - INFO: epoch 001:  27819 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.8, ups=0.87, wpb=110.2, bsz=40, num_updates=27780, lr=4.13358e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80419
2023-02-21 11:36:03 - progress_bar.py[line:274] - INFO: epoch 001:  27829 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.91, wpb=112.3, bsz=40, num_updates=27790, lr=4.13322e-05, gnorm=0.053, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80430
2023-02-21 11:36:15 - progress_bar.py[line:274] - INFO: epoch 001:  27839 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.86, wpb=113, bsz=40, num_updates=27800, lr=4.13286e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=80441
2023-02-21 11:36:26 - progress_bar.py[line:274] - INFO: epoch 001:  27849 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=111.7, bsz=40, num_updates=27810, lr=4.1325e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=80453
2023-02-21 11:36:38 - progress_bar.py[line:274] - INFO: epoch 001:  27859 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.6, nsentences=40, sample_size=113.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.88, wpb=113.6, bsz=40, num_updates=27820, lr=4.13214e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80464
2023-02-21 11:36:49 - progress_bar.py[line:274] - INFO: epoch 001:  27869 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.6, ups=0.86, wpb=111.2, bsz=40, num_updates=27830, lr=4.13178e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=80476
2023-02-21 11:37:01 - progress_bar.py[line:274] - INFO: epoch 001:  27879 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.8, ups=0.86, wpb=111.2, bsz=40, num_updates=27840, lr=4.13141e-05, gnorm=0.12, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=80487
2023-02-21 11:37:12 - progress_bar.py[line:274] - INFO: epoch 001:  27889 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.9, bsz=40, num_updates=27850, lr=4.13105e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80498
2023-02-21 11:37:23 - progress_bar.py[line:274] - INFO: epoch 001:  27899 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=111.1, bsz=40, num_updates=27860, lr=4.13069e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80510
2023-02-21 11:37:34 - progress_bar.py[line:274] - INFO: epoch 001:  27909 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.7, bsz=40, num_updates=27870, lr=4.13033e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=80521
2023-02-21 11:37:45 - progress_bar.py[line:274] - INFO: epoch 001:  27919 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=109.8, bsz=40, num_updates=27880, lr=4.12997e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80532
2023-02-21 11:37:56 - progress_bar.py[line:274] - INFO: epoch 001:  27929 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.2, bsz=40, num_updates=27890, lr=4.1296e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=80543
2023-02-21 11:38:08 - progress_bar.py[line:274] - INFO: epoch 001:  27939 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.4, bsz=40, num_updates=27900, lr=4.12924e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80554
2023-02-21 11:38:19 - progress_bar.py[line:274] - INFO: epoch 001:  27949 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=112.4, bsz=40, num_updates=27910, lr=4.12888e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80565
2023-02-21 11:38:30 - progress_bar.py[line:274] - INFO: epoch 001:  27959 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=27920, lr=4.12852e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80577
2023-02-21 11:38:42 - progress_bar.py[line:274] - INFO: epoch 001:  27969 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.9, bsz=40, num_updates=27930, lr=4.12816e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80588
2023-02-21 11:38:53 - progress_bar.py[line:274] - INFO: epoch 001:  27979 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.9, wpb=113.3, bsz=40, num_updates=27940, lr=4.1278e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80599
2023-02-21 11:39:04 - progress_bar.py[line:274] - INFO: epoch 001:  27989 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=110.9, bsz=40, num_updates=27950, lr=4.12743e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80611
2023-02-21 11:39:16 - progress_bar.py[line:274] - INFO: epoch 001:  27999 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.6, bsz=40, num_updates=27960, lr=4.12707e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80622
2023-02-21 11:39:23 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 11:39:28 - progress_bar.py[line:274] - INFO: epoch 001:  28010 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91.4, ups=0.82, wpb=111.8, bsz=40, num_updates=27970, lr=4.12671e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=80634
2023-02-21 11:39:39 - progress_bar.py[line:274] - INFO: epoch 001:  28020 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.86, wpb=111.8, bsz=40, num_updates=27980, lr=4.12635e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=80646
2023-02-21 11:39:51 - progress_bar.py[line:274] - INFO: epoch 001:  28030 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.5, bsz=40, num_updates=27990, lr=4.12599e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80657
2023-02-21 11:40:02 - progress_bar.py[line:274] - INFO: epoch 001:  28040 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.4, bsz=40, num_updates=28000, lr=4.12562e-05, gnorm=0.141, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80668
2023-02-21 11:40:02 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 11:40:03 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 11:40:03 - train.py[line:551] - INFO: load:0.99 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 11:42:07 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 11:42:07 - train.py[line:551] - INFO: load:1.02 valid_run:123.59 task_valid:120.06 collect_output:2.31
2023-02-21 11:44:09 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 11:44:09 - train.py[line:551] - INFO: load:1.04 valid_run:245.30 task_valid:237.16 collect_output:5.68
2023-02-21 11:46:13 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 11:46:13 - train.py[line:551] - INFO: load:1.07 valid_run:369.37 task_valid:354.78 collect_output:10.95
2023-02-21 11:48:16 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 11:48:16 - train.py[line:551] - INFO: load:1.09 valid_run:492.69 task_valid:469.48 collect_output:18.41
2023-02-21 11:50:16 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 11:50:16 - train.py[line:551] - INFO: load:1.12 valid_run:612.56 task_valid:586.26 collect_output:20.50
2023-02-21 11:52:19 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 11:52:19 - train.py[line:551] - INFO: load:1.14 valid_run:735.03 task_valid:704.57 collect_output:23.64
2023-02-21 11:54:21 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 11:54:21 - train.py[line:551] - INFO: load:1.16 valid_run:857.48 task_valid:822.10 collect_output:27.56
2023-02-21 11:56:23 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 11:56:23 - train.py[line:551] - INFO: load:1.18 valid_run:978.92 task_valid:938.11 collect_output:31.97
2023-02-21 11:58:26 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 11:58:26 - train.py[line:551] - INFO: load:1.21 valid_run:1102.41 task_valid:1055.00 collect_output:37.50
2023-02-21 12:00:27 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 12:00:27 - train.py[line:551] - INFO: load:1.23 valid_run:1223.57 task_valid:1167.03 collect_output:45.64
2023-02-21 12:02:27 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 12:02:27 - train.py[line:551] - INFO: load:1.25 valid_run:1343.15 task_valid:1282.17 collect_output:49.04
2023-02-21 12:04:28 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 12:04:28 - train.py[line:551] - INFO: load:1.27 valid_run:1464.22 task_valid:1398.73 collect_output:52.52
2023-02-21 12:06:27 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 12:06:27 - train.py[line:551] - INFO: load:1.30 valid_run:1582.59 task_valid:1511.94 collect_output:56.68
2023-02-21 12:08:27 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 12:08:27 - train.py[line:551] - INFO: load:1.32 valid_run:1703.21 task_valid:1629.37 collect_output:58.82
2023-02-21 12:10:28 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 12:10:28 - train.py[line:551] - INFO: load:1.34 valid_run:1823.62 task_valid:1745.02 collect_output:62.60
2023-02-21 12:12:28 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 12:12:28 - train.py[line:551] - INFO: load:1.37 valid_run:1944.20 task_valid:1858.57 collect_output:68.60
2023-02-21 12:14:29 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 12:14:29 - train.py[line:551] - INFO: load:1.39 valid_run:2065.03 task_valid:1974.16 collect_output:72.83
2023-02-21 12:16:30 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 12:16:30 - train.py[line:551] - INFO: load:1.41 valid_run:2185.38 task_valid:2091.75 collect_output:74.56
2023-02-21 12:18:30 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 12:18:30 - train.py[line:551] - INFO: load:1.44 valid_run:2306.13 task_valid:2208.34 collect_output:77.69
2023-02-21 12:20:30 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 12:20:30 - train.py[line:551] - INFO: load:1.46 valid_run:2425.99 task_valid:2324.52 collect_output:80.35
2023-02-21 12:22:32 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 12:22:32 - train.py[line:551] - INFO: load:1.48 valid_run:2547.27 task_valid:2440.69 collect_output:84.46
2023-02-21 12:24:34 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 12:24:34 - train.py[line:551] - INFO: load:1.51 valid_run:2669.04 task_valid:2559.41 collect_output:86.45
2023-02-21 12:26:33 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 12:26:33 - train.py[line:551] - INFO: load:1.53 valid_run:2788.91 task_valid:2673.39 collect_output:91.32
2023-02-21 12:28:33 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 12:28:33 - train.py[line:551] - INFO: load:1.55 valid_run:2908.34 task_valid:2789.16 collect_output:93.97
2023-02-21 12:30:34 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 12:30:34 - train.py[line:551] - INFO: load:1.58 valid_run:3029.42 task_valid:2904.90 collect_output:98.29
2023-02-21 12:32:36 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 12:32:36 - train.py[line:551] - INFO: load:1.60 valid_run:3151.75 task_valid:3020.36 collect_output:104.17
2023-02-21 12:34:36 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 12:34:36 - train.py[line:551] - INFO: load:1.62 valid_run:3270.93 task_valid:3134.02 collect_output:108.65
2023-02-21 12:36:37 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 12:36:37 - train.py[line:551] - INFO: load:1.65 valid_run:3392.20 task_valid:3252.88 collect_output:110.07
2023-02-21 12:38:38 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 12:38:38 - train.py[line:551] - INFO: load:1.67 valid_run:3513.39 task_valid:3368.07 collect_output:115.04
2023-02-21 12:40:40 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 12:40:40 - train.py[line:551] - INFO: load:1.69 valid_run:3634.79 task_valid:3486.06 collect_output:117.43
2023-02-21 12:42:40 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 12:42:40 - train.py[line:551] - INFO: load:1.72 valid_run:3755.31 task_valid:3604.03 collect_output:118.97

====================================================================================================
SGG eval:     R @ 50: 0.5770;     R @ 100: 0.6109;     R @ 500: 0.6347;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3500;    mR @ 100: 0.3908;    mR @ 500: 0.4182;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.8750) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.2500) (hanging from:0.3387) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9216) (says:0.0000) (sitting on:0.6684) (standing on:0.3727) (using:0.5500) (walking in:0.0000) (walking on:0.6757) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-02-21 12:43:11 - train.py[line:487] - INFO: 0.6109148459383753

====================================================================================================
SGG eval:     R @ 50: 0.5770;     R @ 100: 0.6109;     R @ 500: 0.6347;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3500;    mR @ 100: 0.3908;    mR @ 500: 0.4182;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.8750) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.2500) (hanging from:0.3387) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9216) (says:0.0000) (sitting on:0.6684) (standing on:0.3727) (using:0.5500) (walking in:0.0000) (walking on:0.6757) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-02-21 12:43:11 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 12:43:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.238 | loss_v1 0 | loss_v2 0 | nll_loss 0.074 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.610915 | ppl 1.05 | vqa_score 0.4617 | wps 118.4 | wpb 72 | bsz 24 | num_updates 28000 | best_R@100 0.691462
2023-02-21 12:43:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 28000 updates
2023-02-21 12:43:11 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_28000.pt
2023-02-21 12:43:17 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_28000.pt
2023-02-21 12:43:19 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_28000.pt (epoch 1 @ 28000 updates, score 0.6109148459383753) (writing took 8.013110836967826 seconds)
2023-02-21 12:43:30 - progress_bar.py[line:274] - INFO: epoch 001:  28050 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=112.4, bsz=40, num_updates=28010, lr=4.12526e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84477
2023-02-21 12:43:41 - progress_bar.py[line:274] - INFO: epoch 001:  28060 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.93, wpb=111.3, bsz=40, num_updates=28020, lr=4.1249e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=84488
2023-02-21 12:43:53 - progress_bar.py[line:274] - INFO: epoch 001:  28070 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.8, bsz=40, num_updates=28030, lr=4.12454e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84499
2023-02-21 12:44:04 - progress_bar.py[line:274] - INFO: epoch 001:  28080 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=28040, lr=4.12418e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84510
2023-02-21 12:44:15 - progress_bar.py[line:274] - INFO: epoch 001:  28090 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.4, bsz=40, num_updates=28050, lr=4.12382e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84521
2023-02-21 12:44:26 - progress_bar.py[line:274] - INFO: epoch 001:  28100 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.1, bsz=40, num_updates=28060, lr=4.12345e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84532
2023-02-21 12:44:37 - progress_bar.py[line:274] - INFO: epoch 001:  28110 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110.6, bsz=40, num_updates=28070, lr=4.12309e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84544
2023-02-21 12:44:48 - progress_bar.py[line:274] - INFO: epoch 001:  28120 / 71012 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.88, wpb=109.6, bsz=40, num_updates=28080, lr=4.12273e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84555
2023-02-21 12:44:59 - progress_bar.py[line:274] - INFO: epoch 001:  28130 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.92, wpb=110.3, bsz=40, num_updates=28090, lr=4.12237e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=84566
2023-02-21 12:45:11 - progress_bar.py[line:274] - INFO: epoch 001:  28140 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.033, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=99.9, ups=0.9, wpb=111.3, bsz=40, num_updates=28100, lr=4.12201e-05, gnorm=0.055, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84577
2023-02-21 12:45:22 - progress_bar.py[line:274] - INFO: epoch 001:  28150 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111.2, bsz=40, num_updates=28110, lr=4.12164e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84588
2023-02-21 12:45:33 - progress_bar.py[line:274] - INFO: epoch 001:  28160 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.92, wpb=112.2, bsz=40, num_updates=28120, lr=4.12128e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=84599
2023-02-21 12:45:44 - progress_bar.py[line:274] - INFO: epoch 001:  28170 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110.6, bsz=40, num_updates=28130, lr=4.12092e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84610
2023-02-21 12:45:55 - progress_bar.py[line:274] - INFO: epoch 001:  28180 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.4, bsz=40, num_updates=28140, lr=4.12056e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84621
2023-02-21 12:46:06 - progress_bar.py[line:274] - INFO: epoch 001:  28190 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=28150, lr=4.1202e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84632
2023-02-21 12:46:17 - progress_bar.py[line:274] - INFO: epoch 001:  28200 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.6, bsz=40, num_updates=28160, lr=4.11984e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84644
2023-02-21 12:46:29 - progress_bar.py[line:274] - INFO: epoch 001:  28210 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113.5, nsentences=40, sample_size=113.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.87, wpb=113.5, bsz=40, num_updates=28170, lr=4.11947e-05, gnorm=0.156, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84655
2023-02-21 12:46:40 - progress_bar.py[line:274] - INFO: epoch 001:  28220 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.4, bsz=40, num_updates=28180, lr=4.11911e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84666
2023-02-21 12:46:51 - progress_bar.py[line:274] - INFO: epoch 001:  28230 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.1, bsz=40, num_updates=28190, lr=4.11875e-05, gnorm=0.156, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84677
2023-02-21 12:47:02 - progress_bar.py[line:274] - INFO: epoch 001:  28240 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.9, bsz=40, num_updates=28200, lr=4.11839e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=11.4, ema_decay=0.9999, wall=84689
2023-02-21 12:47:13 - progress_bar.py[line:274] - INFO: epoch 001:  28250 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.92, wpb=111.6, bsz=40, num_updates=28210, lr=4.11803e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84699
2023-02-21 12:47:24 - progress_bar.py[line:274] - INFO: epoch 001:  28260 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.3, bsz=40, num_updates=28220, lr=4.11766e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84710
2023-02-21 12:47:35 - progress_bar.py[line:274] - INFO: epoch 001:  28270 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.9, bsz=40, num_updates=28230, lr=4.1173e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84721
2023-02-21 12:47:46 - progress_bar.py[line:274] - INFO: epoch 001:  28280 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=112, bsz=40, num_updates=28240, lr=4.11694e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=84733
2023-02-21 12:47:57 - progress_bar.py[line:274] - INFO: epoch 001:  28290 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105, ups=0.94, wpb=112.3, bsz=40, num_updates=28250, lr=4.11658e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84743
2023-02-21 12:48:08 - progress_bar.py[line:274] - INFO: epoch 001:  28300 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112.4, bsz=40, num_updates=28260, lr=4.11622e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84754
2023-02-21 12:48:19 - progress_bar.py[line:274] - INFO: epoch 001:  28310 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.5, bsz=40, num_updates=28270, lr=4.11585e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84766
2023-02-21 12:48:31 - progress_bar.py[line:274] - INFO: epoch 001:  28320 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110.7, bsz=40, num_updates=28280, lr=4.11549e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84777
2023-02-21 12:48:42 - progress_bar.py[line:274] - INFO: epoch 001:  28330 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=28290, lr=4.11513e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84788
2023-02-21 12:48:53 - progress_bar.py[line:274] - INFO: epoch 001:  28340 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=28300, lr=4.11477e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=84799
2023-02-21 12:49:04 - progress_bar.py[line:274] - INFO: epoch 001:  28350 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.89, wpb=112.3, bsz=40, num_updates=28310, lr=4.11441e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84811
2023-02-21 12:49:15 - progress_bar.py[line:274] - INFO: epoch 001:  28360 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.9, bsz=40, num_updates=28320, lr=4.11405e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84822
2023-02-21 12:49:26 - progress_bar.py[line:274] - INFO: epoch 001:  28370 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=28330, lr=4.11368e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84833
2023-02-21 12:49:38 - progress_bar.py[line:274] - INFO: epoch 001:  28380 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=109.7, bsz=40, num_updates=28340, lr=4.11332e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84844
2023-02-21 12:49:49 - progress_bar.py[line:274] - INFO: epoch 001:  28390 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.4, bsz=40, num_updates=28350, lr=4.11296e-05, gnorm=0.062, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84855
2023-02-21 12:50:00 - progress_bar.py[line:274] - INFO: epoch 001:  28400 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=110.6, bsz=40, num_updates=28360, lr=4.1126e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=84867
2023-02-21 12:50:11 - progress_bar.py[line:274] - INFO: epoch 001:  28410 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.9, ups=0.93, wpb=111.5, bsz=40, num_updates=28370, lr=4.11224e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84877
2023-02-21 12:50:23 - progress_bar.py[line:274] - INFO: epoch 001:  28420 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=110.6, bsz=40, num_updates=28380, lr=4.11187e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84889
2023-02-21 12:50:34 - progress_bar.py[line:274] - INFO: epoch 001:  28430 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.8, bsz=40, num_updates=28390, lr=4.11151e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84900
2023-02-21 12:50:45 - progress_bar.py[line:274] - INFO: epoch 001:  28440 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.7, bsz=40, num_updates=28400, lr=4.11115e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84911
2023-02-21 12:50:56 - progress_bar.py[line:274] - INFO: epoch 001:  28450 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.5, bsz=40, num_updates=28410, lr=4.11079e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84922
2023-02-21 12:51:07 - progress_bar.py[line:274] - INFO: epoch 001:  28460 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.9, bsz=40, num_updates=28420, lr=4.11043e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84933
2023-02-21 12:51:18 - progress_bar.py[line:274] - INFO: epoch 001:  28470 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.1, bsz=40, num_updates=28430, lr=4.11007e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84945
2023-02-21 12:51:30 - progress_bar.py[line:274] - INFO: epoch 001:  28480 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.89, wpb=113.3, bsz=40, num_updates=28440, lr=4.1097e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84956
2023-02-21 12:51:41 - progress_bar.py[line:274] - INFO: epoch 001:  28490 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.1, bsz=40, num_updates=28450, lr=4.10934e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84967
2023-02-21 12:51:52 - progress_bar.py[line:274] - INFO: epoch 001:  28500 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.91, wpb=112.8, bsz=40, num_updates=28460, lr=4.10898e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84978
2023-02-21 12:52:03 - progress_bar.py[line:274] - INFO: epoch 001:  28510 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=110.7, bsz=40, num_updates=28470, lr=4.10862e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84990
2023-02-21 12:52:14 - progress_bar.py[line:274] - INFO: epoch 001:  28520 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=112.8, bsz=40, num_updates=28480, lr=4.10826e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85001
2023-02-21 12:52:25 - progress_bar.py[line:274] - INFO: epoch 001:  28530 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.6, bsz=40, num_updates=28490, lr=4.10789e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85012
2023-02-21 12:52:36 - progress_bar.py[line:274] - INFO: epoch 001:  28540 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.5, bsz=40, num_updates=28500, lr=4.10753e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85023
2023-02-21 12:52:38 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 12:52:48 - progress_bar.py[line:274] - INFO: epoch 001:  28551 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.6, ups=0.83, wpb=111.3, bsz=40, num_updates=28510, lr=4.10717e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=85035
2023-02-21 12:53:00 - progress_bar.py[line:274] - INFO: epoch 001:  28561 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.3, bsz=40, num_updates=28520, lr=4.10681e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85046
2023-02-21 12:53:11 - progress_bar.py[line:274] - INFO: epoch 001:  28571 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=28530, lr=4.10645e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85057
2023-02-21 12:53:22 - progress_bar.py[line:274] - INFO: epoch 001:  28581 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.9, bsz=40, num_updates=28540, lr=4.10609e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=85069
2023-02-21 12:53:33 - progress_bar.py[line:274] - INFO: epoch 001:  28591 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.91, wpb=113, bsz=40, num_updates=28550, lr=4.10572e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85080
2023-02-21 12:53:45 - progress_bar.py[line:274] - INFO: epoch 001:  28601 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=28560, lr=4.10536e-05, gnorm=0.055, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85091
2023-02-21 12:53:56 - progress_bar.py[line:274] - INFO: epoch 001:  28611 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.7, bsz=40, num_updates=28570, lr=4.105e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85103
2023-02-21 12:54:07 - progress_bar.py[line:274] - INFO: epoch 001:  28621 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.6, bsz=40, num_updates=28580, lr=4.10464e-05, gnorm=0.143, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85114
2023-02-21 12:54:19 - progress_bar.py[line:274] - INFO: epoch 001:  28631 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.4, bsz=40, num_updates=28590, lr=4.10428e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85125
2023-02-21 12:54:29 - progress_bar.py[line:274] - INFO: epoch 001:  28641 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112.2, bsz=40, num_updates=28600, lr=4.10391e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85136
2023-02-21 12:54:40 - progress_bar.py[line:274] - INFO: epoch 001:  28651 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=112.1, bsz=40, num_updates=28610, lr=4.10355e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=85147
2023-02-21 12:54:51 - progress_bar.py[line:274] - INFO: epoch 001:  28661 / 71012 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.1, ups=0.91, wpb=112.5, bsz=40, num_updates=28620, lr=4.10319e-05, gnorm=0.132, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85158
2023-02-21 12:55:02 - progress_bar.py[line:274] - INFO: epoch 001:  28671 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=112.2, bsz=40, num_updates=28630, lr=4.10283e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85169
2023-02-21 12:55:13 - progress_bar.py[line:274] - INFO: epoch 001:  28681 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=28640, lr=4.10247e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85180
2023-02-21 12:55:24 - progress_bar.py[line:274] - INFO: epoch 001:  28691 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111, bsz=40, num_updates=28650, lr=4.10211e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85191
2023-02-21 12:55:35 - progress_bar.py[line:274] - INFO: epoch 001:  28701 / 71012 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.2, bsz=40, num_updates=28660, lr=4.10174e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85202
2023-02-21 12:55:47 - progress_bar.py[line:274] - INFO: epoch 001:  28711 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.87, wpb=111.9, bsz=40, num_updates=28670, lr=4.10138e-05, gnorm=0.127, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=85213
2023-02-21 12:55:58 - progress_bar.py[line:274] - INFO: epoch 001:  28721 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.8, bsz=40, num_updates=28680, lr=4.10102e-05, gnorm=0.063, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85224
2023-02-21 12:56:09 - progress_bar.py[line:274] - INFO: epoch 001:  28731 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=112.9, bsz=40, num_updates=28690, lr=4.10066e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85235
2023-02-21 12:56:20 - progress_bar.py[line:274] - INFO: epoch 001:  28741 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=28700, lr=4.1003e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85246
2023-02-21 12:56:31 - progress_bar.py[line:274] - INFO: epoch 001:  28751 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.8, bsz=40, num_updates=28710, lr=4.09993e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85257
2023-02-21 12:56:42 - progress_bar.py[line:274] - INFO: epoch 001:  28761 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.5, bsz=40, num_updates=28720, lr=4.09957e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85268
2023-02-21 12:56:53 - progress_bar.py[line:274] - INFO: epoch 001:  28771 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.91, wpb=112.7, bsz=40, num_updates=28730, lr=4.09921e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85279
2023-02-21 12:57:04 - progress_bar.py[line:274] - INFO: epoch 001:  28781 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.3, bsz=40, num_updates=28740, lr=4.09885e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85291
2023-02-21 12:57:15 - progress_bar.py[line:274] - INFO: epoch 001:  28791 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112.1, bsz=40, num_updates=28750, lr=4.09849e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85302
2023-02-21 12:57:26 - progress_bar.py[line:274] - INFO: epoch 001:  28801 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=111.8, bsz=40, num_updates=28760, lr=4.09813e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85313
2023-02-21 12:57:38 - progress_bar.py[line:274] - INFO: epoch 001:  28811 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.9, bsz=40, num_updates=28770, lr=4.09776e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85324
2023-02-21 12:57:49 - progress_bar.py[line:274] - INFO: epoch 001:  28821 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.5, bsz=40, num_updates=28780, lr=4.0974e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85335
2023-02-21 12:58:00 - progress_bar.py[line:274] - INFO: epoch 001:  28831 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.7, bsz=40, num_updates=28790, lr=4.09704e-05, gnorm=0.07, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85346
2023-02-21 12:58:11 - progress_bar.py[line:274] - INFO: epoch 001:  28841 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110.5, bsz=40, num_updates=28800, lr=4.09668e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=85358
2023-02-21 12:58:23 - progress_bar.py[line:274] - INFO: epoch 001:  28851 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.7, bsz=40, num_updates=28810, lr=4.09632e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85369
2023-02-21 12:58:33 - progress_bar.py[line:274] - INFO: epoch 001:  28861 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=111.9, bsz=40, num_updates=28820, lr=4.09595e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85380
2023-02-21 12:58:44 - progress_bar.py[line:274] - INFO: epoch 001:  28871 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=112.2, bsz=40, num_updates=28830, lr=4.09559e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85391
2023-02-21 12:58:55 - progress_bar.py[line:274] - INFO: epoch 001:  28881 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.1, ups=0.93, wpb=111.6, bsz=40, num_updates=28840, lr=4.09523e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=85402
2023-02-21 12:59:06 - progress_bar.py[line:274] - INFO: epoch 001:  28891 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=28850, lr=4.09487e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85413
2023-02-21 12:59:18 - progress_bar.py[line:274] - INFO: epoch 001:  28901 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.5, bsz=40, num_updates=28860, lr=4.09451e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85424
2023-02-21 12:59:29 - progress_bar.py[line:274] - INFO: epoch 001:  28911 / 71012 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.8, bsz=40, num_updates=28870, lr=4.09415e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=85435
2023-02-21 12:59:40 - progress_bar.py[line:274] - INFO: epoch 001:  28921 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=111.1, bsz=40, num_updates=28880, lr=4.09378e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85446
2023-02-21 12:59:51 - progress_bar.py[line:274] - INFO: epoch 001:  28931 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=114, nsentences=40, sample_size=114, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.9, wpb=114, bsz=40, num_updates=28890, lr=4.09342e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85458
2023-02-21 13:00:02 - progress_bar.py[line:274] - INFO: epoch 001:  28941 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=111.9, bsz=40, num_updates=28900, lr=4.09306e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85469
2023-02-21 13:00:14 - progress_bar.py[line:274] - INFO: epoch 001:  28951 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.2, bsz=40, num_updates=28910, lr=4.0927e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85480
2023-02-21 13:00:25 - progress_bar.py[line:274] - INFO: epoch 001:  28961 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.88, wpb=112.9, bsz=40, num_updates=28920, lr=4.09234e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85492
2023-02-21 13:00:36 - progress_bar.py[line:274] - INFO: epoch 001:  28971 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.8, bsz=40, num_updates=28930, lr=4.09197e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85503
2023-02-21 13:00:48 - progress_bar.py[line:274] - INFO: epoch 001:  28981 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=28940, lr=4.09161e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85514
2023-02-21 13:00:59 - progress_bar.py[line:274] - INFO: epoch 001:  28991 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.6, bsz=40, num_updates=28950, lr=4.09125e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85525
2023-02-21 13:01:10 - progress_bar.py[line:274] - INFO: epoch 001:  29001 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.7, bsz=40, num_updates=28960, lr=4.09089e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85536
2023-02-21 13:01:21 - progress_bar.py[line:274] - INFO: epoch 001:  29011 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.4, bsz=40, num_updates=28970, lr=4.09053e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85548
2023-02-21 13:01:32 - progress_bar.py[line:274] - INFO: epoch 001:  29021 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.8, bsz=40, num_updates=28980, lr=4.09017e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85558
2023-02-21 13:01:43 - progress_bar.py[line:274] - INFO: epoch 001:  29031 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.6, bsz=40, num_updates=28990, lr=4.0898e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85570
2023-02-21 13:01:54 - progress_bar.py[line:274] - INFO: epoch 001:  29041 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.6, bsz=40, num_updates=29000, lr=4.08944e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85581
2023-02-21 13:02:06 - progress_bar.py[line:274] - INFO: epoch 001:  29051 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=29010, lr=4.08908e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85592
2023-02-21 13:02:17 - progress_bar.py[line:274] - INFO: epoch 001:  29061 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.8, bsz=40, num_updates=29020, lr=4.08872e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85603
2023-02-21 13:02:28 - progress_bar.py[line:274] - INFO: epoch 001:  29071 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.4, bsz=40, num_updates=29030, lr=4.08836e-05, gnorm=0.146, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85614
2023-02-21 13:02:39 - progress_bar.py[line:274] - INFO: epoch 001:  29081 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.8, bsz=40, num_updates=29040, lr=4.08799e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85625
2023-02-21 13:02:50 - progress_bar.py[line:274] - INFO: epoch 001:  29091 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.2, bsz=40, num_updates=29050, lr=4.08763e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85636
2023-02-21 13:03:01 - progress_bar.py[line:274] - INFO: epoch 001:  29101 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.5, bsz=40, num_updates=29060, lr=4.08727e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=85648
2023-02-21 13:03:13 - progress_bar.py[line:274] - INFO: epoch 001:  29111 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=29070, lr=4.08691e-05, gnorm=0.146, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85659
2023-02-21 13:03:24 - progress_bar.py[line:274] - INFO: epoch 001:  29121 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.9, bsz=40, num_updates=29080, lr=4.08655e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85670
2023-02-21 13:03:35 - progress_bar.py[line:274] - INFO: epoch 001:  29131 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.1, bsz=40, num_updates=29090, lr=4.08619e-05, gnorm=0.135, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85681
2023-02-21 13:03:45 - progress_bar.py[line:274] - INFO: epoch 001:  29141 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.9, ups=0.96, wpb=111.7, bsz=40, num_updates=29100, lr=4.08582e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=85692
2023-02-21 13:03:57 - progress_bar.py[line:274] - INFO: epoch 001:  29151 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=112.6, bsz=40, num_updates=29110, lr=4.08546e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85703
2023-02-21 13:04:07 - progress_bar.py[line:274] - INFO: epoch 001:  29161 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.6, ups=0.95, wpb=111.4, bsz=40, num_updates=29120, lr=4.0851e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85714
2023-02-21 13:04:18 - progress_bar.py[line:274] - INFO: epoch 001:  29171 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=102.1, ups=0.91, wpb=112.5, bsz=40, num_updates=29130, lr=4.08474e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85725
2023-02-21 13:04:26 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 13:04:30 - progress_bar.py[line:274] - INFO: epoch 001:  29182 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.9, ups=0.83, wpb=111.7, bsz=40, num_updates=29140, lr=4.08438e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=85737
2023-02-21 13:04:42 - progress_bar.py[line:274] - INFO: epoch 001:  29192 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.1, bsz=40, num_updates=29150, lr=4.08401e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=85748
2023-02-21 13:04:53 - progress_bar.py[line:274] - INFO: epoch 001:  29202 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.1, bsz=40, num_updates=29160, lr=4.08365e-05, gnorm=0.053, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85759
2023-02-21 13:05:04 - progress_bar.py[line:274] - INFO: epoch 001:  29212 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.1, bsz=40, num_updates=29170, lr=4.08329e-05, gnorm=0.063, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85770
2023-02-21 13:05:15 - progress_bar.py[line:274] - INFO: epoch 001:  29222 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=29180, lr=4.08293e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85782
2023-02-21 13:05:27 - progress_bar.py[line:274] - INFO: epoch 001:  29232 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.3, bsz=40, num_updates=29190, lr=4.08257e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85793
2023-02-21 13:05:38 - progress_bar.py[line:274] - INFO: epoch 001:  29242 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111, bsz=40, num_updates=29200, lr=4.08221e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85804
2023-02-21 13:05:49 - progress_bar.py[line:274] - INFO: epoch 001:  29252 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=110.9, bsz=40, num_updates=29210, lr=4.08184e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85815
2023-02-21 13:06:00 - progress_bar.py[line:274] - INFO: epoch 001:  29262 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=100.1, ups=0.89, wpb=112.9, bsz=40, num_updates=29220, lr=4.08148e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85826
2023-02-21 13:06:11 - progress_bar.py[line:274] - INFO: epoch 001:  29272 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112, bsz=40, num_updates=29230, lr=4.08112e-05, gnorm=0.072, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85837
2023-02-21 13:06:22 - progress_bar.py[line:274] - INFO: epoch 001:  29282 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.91, wpb=112.7, bsz=40, num_updates=29240, lr=4.08076e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85848
2023-02-21 13:06:33 - progress_bar.py[line:274] - INFO: epoch 001:  29292 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.9, ups=0.92, wpb=112.8, bsz=40, num_updates=29250, lr=4.0804e-05, gnorm=0.132, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85859
2023-02-21 13:06:44 - progress_bar.py[line:274] - INFO: epoch 001:  29302 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.4, bsz=40, num_updates=29260, lr=4.08003e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85870
2023-02-21 13:06:55 - progress_bar.py[line:274] - INFO: epoch 001:  29312 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.6, bsz=40, num_updates=29270, lr=4.07967e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85881
2023-02-21 13:07:06 - progress_bar.py[line:274] - INFO: epoch 001:  29322 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.6, bsz=40, num_updates=29280, lr=4.07931e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=85893
2023-02-21 13:07:17 - progress_bar.py[line:274] - INFO: epoch 001:  29332 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.5, ups=0.94, wpb=111.3, bsz=40, num_updates=29290, lr=4.07895e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85903
2023-02-21 13:07:28 - progress_bar.py[line:274] - INFO: epoch 001:  29342 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.1, bsz=40, num_updates=29300, lr=4.07859e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85914
2023-02-21 13:07:39 - progress_bar.py[line:274] - INFO: epoch 001:  29352 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111.1, bsz=40, num_updates=29310, lr=4.07823e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=85925
2023-02-21 13:07:50 - progress_bar.py[line:274] - INFO: epoch 001:  29362 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.8, bsz=40, num_updates=29320, lr=4.07786e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85936
2023-02-21 13:08:01 - progress_bar.py[line:274] - INFO: epoch 001:  29372 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.3, bsz=40, num_updates=29330, lr=4.0775e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85947
2023-02-21 13:08:12 - progress_bar.py[line:274] - INFO: epoch 001:  29382 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.6, bsz=40, num_updates=29340, lr=4.07714e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85958
2023-02-21 13:08:23 - progress_bar.py[line:274] - INFO: epoch 001:  29392 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.88, wpb=112.8, bsz=40, num_updates=29350, lr=4.07678e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85970
2023-02-21 13:08:34 - progress_bar.py[line:274] - INFO: epoch 001:  29402 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112, bsz=40, num_updates=29360, lr=4.07642e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=85981
2023-02-21 13:08:45 - progress_bar.py[line:274] - INFO: epoch 001:  29412 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.91, wpb=109.6, bsz=40, num_updates=29370, lr=4.07605e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=85992
2023-02-21 13:08:57 - progress_bar.py[line:274] - INFO: epoch 001:  29422 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=112.1, bsz=40, num_updates=29380, lr=4.07569e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86003
2023-02-21 13:09:08 - progress_bar.py[line:274] - INFO: epoch 001:  29432 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.3, bsz=40, num_updates=29390, lr=4.07533e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86014
2023-02-21 13:09:19 - progress_bar.py[line:274] - INFO: epoch 001:  29442 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.1, ups=0.94, wpb=111.5, bsz=40, num_updates=29400, lr=4.07497e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86025
2023-02-21 13:09:30 - progress_bar.py[line:274] - INFO: epoch 001:  29452 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=29410, lr=4.07461e-05, gnorm=0.059, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86036
2023-02-21 13:09:41 - progress_bar.py[line:274] - INFO: epoch 001:  29462 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=29420, lr=4.07425e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86047
2023-02-21 13:09:52 - progress_bar.py[line:274] - INFO: epoch 001:  29472 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113.4, nsentences=40, sample_size=113.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.88, wpb=113.4, bsz=40, num_updates=29430, lr=4.07388e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86059
2023-02-21 13:10:04 - progress_bar.py[line:274] - INFO: epoch 001:  29482 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.5, bsz=40, num_updates=29440, lr=4.07352e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86070
2023-02-21 13:10:15 - progress_bar.py[line:274] - INFO: epoch 001:  29492 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.1, bsz=40, num_updates=29450, lr=4.07316e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86081
2023-02-21 13:10:26 - progress_bar.py[line:274] - INFO: epoch 001:  29502 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=112.1, bsz=40, num_updates=29460, lr=4.0728e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86092
2023-02-21 13:10:37 - progress_bar.py[line:274] - INFO: epoch 001:  29512 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.8, bsz=40, num_updates=29470, lr=4.07244e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86103
2023-02-21 13:10:48 - progress_bar.py[line:274] - INFO: epoch 001:  29522 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.033, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=99.2, ups=0.9, wpb=110.6, bsz=40, num_updates=29480, lr=4.07207e-05, gnorm=0.049, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86114
2023-02-21 13:10:59 - progress_bar.py[line:274] - INFO: epoch 001:  29532 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.5, bsz=40, num_updates=29490, lr=4.07171e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86126
2023-02-21 13:11:10 - progress_bar.py[line:274] - INFO: epoch 001:  29542 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.2, bsz=40, num_updates=29500, lr=4.07135e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=86136
2023-02-21 13:11:21 - progress_bar.py[line:274] - INFO: epoch 001:  29552 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.2, bsz=40, num_updates=29510, lr=4.07099e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86147
2023-02-21 13:11:32 - progress_bar.py[line:274] - INFO: epoch 001:  29562 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.6, ups=0.93, wpb=112.2, bsz=40, num_updates=29520, lr=4.07063e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86158
2023-02-21 13:11:43 - progress_bar.py[line:274] - INFO: epoch 001:  29572 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.4, bsz=40, num_updates=29530, lr=4.07027e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86169
2023-02-21 13:11:54 - progress_bar.py[line:274] - INFO: epoch 001:  29582 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.4, bsz=40, num_updates=29540, lr=4.0699e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86181
2023-02-21 13:12:05 - progress_bar.py[line:274] - INFO: epoch 001:  29592 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.9, bsz=40, num_updates=29550, lr=4.06954e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86192
2023-02-21 13:12:16 - progress_bar.py[line:274] - INFO: epoch 001:  29602 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.2, bsz=40, num_updates=29560, lr=4.06918e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86203
2023-02-21 13:12:27 - progress_bar.py[line:274] - INFO: epoch 001:  29612 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.92, wpb=112.4, bsz=40, num_updates=29570, lr=4.06882e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86214
2023-02-21 13:12:39 - progress_bar.py[line:274] - INFO: epoch 001:  29622 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.87, wpb=112.2, bsz=40, num_updates=29580, lr=4.06846e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=86225
2023-02-21 13:12:50 - progress_bar.py[line:274] - INFO: epoch 001:  29632 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.7, bsz=40, num_updates=29590, lr=4.06809e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86236
2023-02-21 13:13:01 - progress_bar.py[line:274] - INFO: epoch 001:  29642 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.8, bsz=40, num_updates=29600, lr=4.06773e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86247
2023-02-21 13:13:12 - progress_bar.py[line:274] - INFO: epoch 001:  29652 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112, bsz=40, num_updates=29610, lr=4.06737e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86258
2023-02-21 13:13:23 - progress_bar.py[line:274] - INFO: epoch 001:  29662 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=29620, lr=4.06701e-05, gnorm=0.062, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86269
2023-02-21 13:13:34 - progress_bar.py[line:274] - INFO: epoch 001:  29672 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.2, bsz=40, num_updates=29630, lr=4.06665e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86280
2023-02-21 13:13:44 - progress_bar.py[line:274] - INFO: epoch 001:  29682 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=104.7, ups=0.93, wpb=113.1, bsz=40, num_updates=29640, lr=4.06629e-05, gnorm=0.065, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86291
2023-02-21 13:13:55 - progress_bar.py[line:274] - INFO: epoch 001:  29692 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.1, bsz=40, num_updates=29650, lr=4.06592e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86302
2023-02-21 13:14:05 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 13:14:08 - progress_bar.py[line:274] - INFO: epoch 001:  29703 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.3, ups=0.81, wpb=111.1, bsz=40, num_updates=29660, lr=4.06556e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=86314
2023-02-21 13:14:19 - progress_bar.py[line:274] - INFO: epoch 001:  29713 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.8, bsz=40, num_updates=29670, lr=4.0652e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86325
2023-02-21 13:14:30 - progress_bar.py[line:274] - INFO: epoch 001:  29723 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.3, bsz=40, num_updates=29680, lr=4.06484e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86336
2023-02-21 13:14:41 - progress_bar.py[line:274] - INFO: epoch 001:  29733 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.89, wpb=112.2, bsz=40, num_updates=29690, lr=4.06448e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86348
2023-02-21 13:14:52 - progress_bar.py[line:274] - INFO: epoch 001:  29743 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.91, wpb=113.2, bsz=40, num_updates=29700, lr=4.06411e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86359
2023-02-21 13:15:04 - progress_bar.py[line:274] - INFO: epoch 001:  29753 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.87, wpb=111, bsz=40, num_updates=29710, lr=4.06375e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86370
2023-02-21 13:15:14 - progress_bar.py[line:274] - INFO: epoch 001:  29763 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.93, wpb=110.6, bsz=40, num_updates=29720, lr=4.06339e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86381
2023-02-21 13:15:26 - progress_bar.py[line:274] - INFO: epoch 001:  29773 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.3, bsz=40, num_updates=29730, lr=4.06303e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86392
2023-02-21 13:15:37 - progress_bar.py[line:274] - INFO: epoch 001:  29783 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=112, bsz=40, num_updates=29740, lr=4.06267e-05, gnorm=0.149, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86403
2023-02-21 13:15:48 - progress_bar.py[line:274] - INFO: epoch 001:  29793 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=29750, lr=4.06231e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86414
2023-02-21 13:15:59 - progress_bar.py[line:274] - INFO: epoch 001:  29803 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.3, bsz=40, num_updates=29760, lr=4.06194e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86425
2023-02-21 13:16:10 - progress_bar.py[line:274] - INFO: epoch 001:  29813 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.9, bsz=40, num_updates=29770, lr=4.06158e-05, gnorm=0.065, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86437
2023-02-21 13:16:21 - progress_bar.py[line:274] - INFO: epoch 001:  29823 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.88, wpb=109.2, bsz=40, num_updates=29780, lr=4.06122e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86448
2023-02-21 13:16:32 - progress_bar.py[line:274] - INFO: epoch 001:  29833 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.2, bsz=40, num_updates=29790, lr=4.06086e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86459
2023-02-21 13:16:44 - progress_bar.py[line:274] - INFO: epoch 001:  29843 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.4, bsz=40, num_updates=29800, lr=4.0605e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=86470
2023-02-21 13:16:54 - progress_bar.py[line:274] - INFO: epoch 001:  29853 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.93, wpb=111.5, bsz=40, num_updates=29810, lr=4.06013e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86481
2023-02-21 13:17:06 - progress_bar.py[line:274] - INFO: epoch 001:  29863 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=110.6, bsz=40, num_updates=29820, lr=4.05977e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86492
2023-02-21 13:17:17 - progress_bar.py[line:274] - INFO: epoch 001:  29873 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=110.9, bsz=40, num_updates=29830, lr=4.05941e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86503
2023-02-21 13:17:27 - progress_bar.py[line:274] - INFO: epoch 001:  29883 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.2, ups=0.94, wpb=111, bsz=40, num_updates=29840, lr=4.05905e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86514
2023-02-21 13:17:39 - progress_bar.py[line:274] - INFO: epoch 001:  29893 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.1, bsz=40, num_updates=29850, lr=4.05869e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86525
2023-02-21 13:17:50 - progress_bar.py[line:274] - INFO: epoch 001:  29903 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.1, bsz=40, num_updates=29860, lr=4.05833e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86536
2023-02-21 13:18:01 - progress_bar.py[line:274] - INFO: epoch 001:  29913 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.1, bsz=40, num_updates=29870, lr=4.05796e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86547
2023-02-21 13:18:12 - progress_bar.py[line:274] - INFO: epoch 001:  29923 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.2, bsz=40, num_updates=29880, lr=4.0576e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86559
2023-02-21 13:18:23 - progress_bar.py[line:274] - INFO: epoch 001:  29933 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.89, wpb=113, bsz=40, num_updates=29890, lr=4.05724e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86570
2023-02-21 13:18:35 - progress_bar.py[line:274] - INFO: epoch 001:  29943 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=111.6, bsz=40, num_updates=29900, lr=4.05688e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86581
2023-02-21 13:18:46 - progress_bar.py[line:274] - INFO: epoch 001:  29953 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.4, bsz=40, num_updates=29910, lr=4.05652e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86592
2023-02-21 13:18:57 - progress_bar.py[line:274] - INFO: epoch 001:  29963 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=111.1, bsz=40, num_updates=29920, lr=4.05615e-05, gnorm=0.065, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86604
2023-02-21 13:19:09 - progress_bar.py[line:274] - INFO: epoch 001:  29973 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.6, bsz=40, num_updates=29930, lr=4.05579e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86615
2023-02-21 13:19:20 - progress_bar.py[line:274] - INFO: epoch 001:  29983 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.9, wpb=112.8, bsz=40, num_updates=29940, lr=4.05543e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86626
2023-02-21 13:19:31 - progress_bar.py[line:274] - INFO: epoch 001:  29993 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=103.7, ups=0.93, wpb=111.1, bsz=40, num_updates=29950, lr=4.05507e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86637
2023-02-21 13:19:42 - progress_bar.py[line:274] - INFO: epoch 001:  30003 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.2, ups=0.91, wpb=111.3, bsz=40, num_updates=29960, lr=4.05471e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86648
2023-02-21 13:19:53 - progress_bar.py[line:274] - INFO: epoch 001:  30013 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=29970, lr=4.05435e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86659
2023-02-21 13:20:04 - progress_bar.py[line:274] - INFO: epoch 001:  30023 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.6, bsz=40, num_updates=29980, lr=4.05398e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86670
2023-02-21 13:20:15 - progress_bar.py[line:274] - INFO: epoch 001:  30033 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.3, bsz=40, num_updates=29990, lr=4.05362e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86682
2023-02-21 13:20:26 - progress_bar.py[line:274] - INFO: epoch 001:  30043 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.3, ups=0.91, wpb=113, bsz=40, num_updates=30000, lr=4.05326e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86693
2023-02-21 13:20:26 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 13:20:28 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 13:20:28 - train.py[line:551] - INFO: load:0.98 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 13:22:29 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 13:22:29 - train.py[line:551] - INFO: load:1.01 valid_run:121.51 task_valid:118.44 collect_output:2.03
2023-02-21 13:24:29 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 13:24:29 - train.py[line:551] - INFO: load:1.03 valid_run:240.87 task_valid:233.91 collect_output:4.86
2023-02-21 13:26:30 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 13:26:30 - train.py[line:551] - INFO: load:1.05 valid_run:362.10 task_valid:349.94 collect_output:9.04
2023-02-21 13:28:33 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 13:28:33 - train.py[line:551] - INFO: load:1.08 valid_run:484.66 task_valid:463.30 collect_output:17.20
2023-02-21 13:30:34 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 13:30:34 - train.py[line:551] - INFO: load:1.10 valid_run:605.86 task_valid:580.31 collect_output:20.32
2023-02-21 13:32:36 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 13:32:36 - train.py[line:551] - INFO: load:1.13 valid_run:728.28 task_valid:698.66 collect_output:23.34
2023-02-21 13:34:39 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 13:34:39 - train.py[line:551] - INFO: load:1.15 valid_run:850.69 task_valid:816.22 collect_output:27.17
2023-02-21 13:36:40 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 13:36:40 - train.py[line:551] - INFO: load:1.18 valid_run:971.77 task_valid:932.27 collect_output:31.18
2023-02-21 13:38:43 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 13:38:43 - train.py[line:551] - INFO: load:1.20 valid_run:1094.77 task_valid:1049.03 collect_output:36.41
2023-02-21 13:40:44 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 13:40:44 - train.py[line:551] - INFO: load:1.22 valid_run:1215.78 task_valid:1161.12 collect_output:44.31
2023-02-21 13:42:44 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 13:42:44 - train.py[line:551] - INFO: load:1.25 valid_run:1335.37 task_valid:1276.37 collect_output:47.59
2023-02-21 13:44:45 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 13:44:45 - train.py[line:551] - INFO: load:1.27 valid_run:1456.32 task_valid:1392.93 collect_output:50.96
2023-02-21 13:46:43 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 13:46:43 - train.py[line:551] - INFO: load:1.30 valid_run:1574.72 task_valid:1506.39 collect_output:54.88
2023-02-21 13:48:44 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 13:48:44 - train.py[line:551] - INFO: load:1.32 valid_run:1695.17 task_valid:1623.71 collect_output:56.99
2023-02-21 13:50:44 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 13:50:44 - train.py[line:551] - INFO: load:1.35 valid_run:1815.64 task_valid:1739.41 collect_output:60.74
2023-02-21 13:52:45 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 13:52:45 - train.py[line:551] - INFO: load:1.37 valid_run:1936.17 task_valid:1852.93 collect_output:66.73
2023-02-21 13:54:46 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 13:54:46 - train.py[line:551] - INFO: load:1.39 valid_run:2057.17 task_valid:1968.78 collect_output:70.84
2023-02-21 13:56:46 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 13:56:46 - train.py[line:551] - INFO: load:1.42 valid_run:2177.36 task_valid:2086.26 collect_output:72.52
2023-02-21 13:58:47 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 13:58:47 - train.py[line:551] - INFO: load:1.44 valid_run:2298.13 task_valid:2202.83 collect_output:75.69
2023-02-21 14:00:47 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 14:00:47 - train.py[line:551] - INFO: load:1.47 valid_run:2417.92 task_valid:2318.93 collect_output:78.38
2023-02-21 14:02:48 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 14:02:48 - train.py[line:551] - INFO: load:1.49 valid_run:2539.05 task_valid:2435.12 collect_output:82.31
2023-02-21 14:04:50 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 14:04:50 - train.py[line:551] - INFO: load:1.52 valid_run:2660.70 task_valid:2553.78 collect_output:84.25
2023-02-21 14:06:49 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 14:06:49 - train.py[line:551] - INFO: load:1.54 valid_run:2780.43 task_valid:2667.75 collect_output:88.98
2023-02-21 14:08:49 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 14:08:49 - train.py[line:551] - INFO: load:1.57 valid_run:2899.76 task_valid:2783.66 collect_output:91.37
2023-02-21 14:10:50 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 14:10:50 - train.py[line:551] - INFO: load:1.59 valid_run:3020.94 task_valid:2899.60 collect_output:95.57
2023-02-21 14:12:52 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 14:12:52 - train.py[line:551] - INFO: load:1.61 valid_run:3143.14 task_valid:3015.12 collect_output:101.25
2023-02-21 14:14:51 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 14:14:51 - train.py[line:551] - INFO: load:1.64 valid_run:3262.12 task_valid:3128.86 collect_output:105.47
2023-02-21 14:16:53 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 14:16:53 - train.py[line:551] - INFO: load:1.66 valid_run:3383.37 task_valid:3247.79 collect_output:106.78
2023-02-21 14:18:54 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 14:18:54 - train.py[line:551] - INFO: load:1.69 valid_run:3504.36 task_valid:3362.87 collect_output:111.67
2023-02-21 14:20:55 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 14:20:55 - train.py[line:551] - INFO: load:1.71 valid_run:3625.76 task_valid:3480.93 collect_output:113.99
2023-02-21 14:22:56 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 14:22:56 - train.py[line:551] - INFO: load:1.73 valid_run:3746.47 task_valid:3599.06 collect_output:115.54

====================================================================================================
SGG eval:     R @ 50: 0.5740;     R @ 100: 0.6057;     R @ 500: 0.6292;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3500;    mR @ 100: 0.3813;    mR @ 500: 0.4143;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.7500) (covering:0.2286) (eating:0.7647) (flying in:0.0000) (growing on:0.2500) (hanging from:0.3710) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9118) (says:0.0000) (sitting on:0.6616) (standing on:0.3627) (using:0.5500) (walking in:0.0000) (walking on:0.6757) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-02-21 14:23:26 - train.py[line:487] - INFO: 0.6057481792717087
2023-02-21 14:23:27 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.5740;     R @ 100: 0.6057;     R @ 500: 0.6292;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3500;    mR @ 100: 0.3813;    mR @ 500: 0.4143;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.7500) (covering:0.2286) (eating:0.7647) (flying in:0.0000) (growing on:0.2500) (hanging from:0.3710) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9118) (says:0.0000) (sitting on:0.6616) (standing on:0.3627) (using:0.5500) (walking in:0.0000) (walking on:0.6757) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-02-21 14:23:27 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.231 | loss_v1 0 | loss_v2 0 | nll_loss 0.062 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.605748 | ppl 1.04 | vqa_score 0.4606 | wps 118.7 | wpb 72 | bsz 24 | num_updates 30000 | best_R@100 0.691462
2023-02-21 14:23:27 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 30000 updates
2023-02-21 14:23:27 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_30000.pt
2023-02-21 14:23:32 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_30000.pt
2023-02-21 14:23:35 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k50alpha1.0_/1_B20_A1_E2_0.027_5e-5_480/checkpoint_1_30000.pt (epoch 1 @ 30000 updates, score 0.6057481792717087) (writing took 8.008138852193952 seconds)
2023-02-21 14:23:46 - progress_bar.py[line:274] - INFO: epoch 001:  30053 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=110.5, bsz=40, num_updates=30010, lr=4.0529e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=90492
2023-02-21 14:23:57 - progress_bar.py[line:274] - INFO: epoch 001:  30063 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.5, bsz=40, num_updates=30020, lr=4.05254e-05, gnorm=0.065, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=90503
2023-02-21 14:24:08 - progress_bar.py[line:274] - INFO: epoch 001:  30073 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.87, wpb=112.3, bsz=40, num_updates=30030, lr=4.05217e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90515
2023-02-21 14:24:20 - progress_bar.py[line:274] - INFO: epoch 001:  30083 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=110.7, bsz=40, num_updates=30040, lr=4.05181e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90526
2023-02-21 14:24:31 - progress_bar.py[line:274] - INFO: epoch 001:  30093 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.93, wpb=110.4, bsz=40, num_updates=30050, lr=4.05145e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=90537
2023-02-21 14:24:42 - progress_bar.py[line:274] - INFO: epoch 001:  30103 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.89, wpb=110.1, bsz=40, num_updates=30060, lr=4.05109e-05, gnorm=0.065, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90548
2023-02-21 14:24:53 - progress_bar.py[line:274] - INFO: epoch 001:  30113 / 71012 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=109.9, bsz=40, num_updates=30070, lr=4.05073e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=90560
2023-02-21 14:25:04 - progress_bar.py[line:274] - INFO: epoch 001:  30123 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.9, bsz=40, num_updates=30080, lr=4.05037e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90571
2023-02-21 14:25:16 - progress_bar.py[line:274] - INFO: epoch 001:  30133 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.2, bsz=40, num_updates=30090, lr=4.05e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=90582
2023-02-21 14:25:27 - progress_bar.py[line:274] - INFO: epoch 001:  30143 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=30100, lr=4.04964e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90593
2023-02-21 14:25:38 - progress_bar.py[line:274] - INFO: epoch 001:  30153 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.9, bsz=40, num_updates=30110, lr=4.04928e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=90605
2023-02-21 14:25:49 - progress_bar.py[line:274] - INFO: epoch 001:  30163 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=30120, lr=4.04892e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=90616
2023-02-21 14:26:00 - progress_bar.py[line:274] - INFO: epoch 001:  30173 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=112, bsz=40, num_updates=30130, lr=4.04856e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90626
2023-02-21 14:26:11 - progress_bar.py[line:274] - INFO: epoch 001:  30183 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.2, bsz=40, num_updates=30140, lr=4.04819e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=90638
2023-02-21 14:26:23 - progress_bar.py[line:274] - INFO: epoch 001:  30193 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.4, bsz=40, num_updates=30150, lr=4.04783e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90649
2023-02-21 14:26:34 - progress_bar.py[line:274] - INFO: epoch 001:  30203 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111, bsz=40, num_updates=30160, lr=4.04747e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=90660
2023-02-21 14:26:44 - progress_bar.py[line:274] - INFO: epoch 001:  30213 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.8, ups=0.93, wpb=112.3, bsz=40, num_updates=30170, lr=4.04711e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90671
2023-02-21 14:26:55 - progress_bar.py[line:274] - INFO: epoch 001:  30223 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.1, ups=0.93, wpb=112.8, bsz=40, num_updates=30180, lr=4.04675e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90682
2023-02-21 14:27:06 - progress_bar.py[line:274] - INFO: epoch 001:  30233 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.2, bsz=40, num_updates=30190, lr=4.04639e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90693
2023-02-21 14:27:17 - progress_bar.py[line:274] - INFO: epoch 001:  30243 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112.1, bsz=40, num_updates=30200, lr=4.04602e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=90703
2023-02-21 14:27:28 - progress_bar.py[line:274] - INFO: epoch 001:  30253 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111, bsz=40, num_updates=30210, lr=4.04566e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90714
2023-02-21 14:27:39 - progress_bar.py[line:274] - INFO: epoch 001:  30263 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=111.7, bsz=40, num_updates=30220, lr=4.0453e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90726
2023-02-21 14:27:51 - progress_bar.py[line:274] - INFO: epoch 001:  30273 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.2, bsz=40, num_updates=30230, lr=4.04494e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=90737
2023-02-21 14:28:02 - progress_bar.py[line:274] - INFO: epoch 001:  30283 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.89, wpb=110.2, bsz=40, num_updates=30240, lr=4.04458e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90748
2023-02-21 14:28:13 - progress_bar.py[line:274] - INFO: epoch 001:  30293 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=112.7, bsz=40, num_updates=30250, lr=4.04421e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90759
2023-02-21 14:28:24 - progress_bar.py[line:274] - INFO: epoch 001:  30303 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=30260, lr=4.04385e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=90770
2023-02-21 14:28:35 - progress_bar.py[line:274] - INFO: epoch 001:  30313 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.1, bsz=40, num_updates=30270, lr=4.04349e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90781
2023-02-21 14:28:46 - progress_bar.py[line:274] - INFO: epoch 001:  30323 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.5, bsz=40, num_updates=30280, lr=4.04313e-05, gnorm=0.12, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90793
2023-02-21 14:28:58 - progress_bar.py[line:274] - INFO: epoch 001:  30333 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.3, bsz=40, num_updates=30290, lr=4.04277e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90804
2023-02-21 14:29:09 - progress_bar.py[line:274] - INFO: epoch 001:  30343 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.9, bsz=40, num_updates=30300, lr=4.04241e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90815
2023-02-21 14:29:20 - progress_bar.py[line:274] - INFO: epoch 001:  30353 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.7, bsz=40, num_updates=30310, lr=4.04204e-05, gnorm=0.111, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90826
2023-02-21 14:29:31 - progress_bar.py[line:274] - INFO: epoch 001:  30363 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.3, bsz=40, num_updates=30320, lr=4.04168e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=90837
2023-02-21 14:29:42 - progress_bar.py[line:274] - INFO: epoch 001:  30373 / 71012 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.9, wpb=111.7, bsz=40, num_updates=30330, lr=4.04132e-05, gnorm=0.129, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90848
2023-02-21 14:29:52 - progress_bar.py[line:274] - INFO: epoch 001:  30383 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=107, ups=0.95, wpb=113.2, bsz=40, num_updates=30340, lr=4.04096e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90859
2023-02-21 14:29:59 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 14:30:04 - progress_bar.py[line:274] - INFO: epoch 001:  30394 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.1, ups=0.84, wpb=110.8, bsz=40, num_updates=30350, lr=4.0406e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=90871
2023-02-21 14:30:15 - progress_bar.py[line:274] - INFO: epoch 001:  30404 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.5, bsz=40, num_updates=30360, lr=4.04023e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90882
2023-02-21 14:30:27 - progress_bar.py[line:274] - INFO: epoch 001:  30414 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112, bsz=40, num_updates=30370, lr=4.03987e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=90893
2023-02-21 14:30:38 - progress_bar.py[line:274] - INFO: epoch 001:  30424 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.5, bsz=40, num_updates=30380, lr=4.03951e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90904
2023-02-21 14:30:49 - progress_bar.py[line:274] - INFO: epoch 001:  30434 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=111.8, bsz=40, num_updates=30390, lr=4.03915e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=90915
2023-02-21 14:31:00 - progress_bar.py[line:274] - INFO: epoch 001:  30444 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.6, bsz=40, num_updates=30400, lr=4.03879e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=90926
2023-02-21 14:31:11 - progress_bar.py[line:274] - INFO: epoch 001:  30454 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=98.8, ups=0.89, wpb=111.5, bsz=40, num_updates=30410, lr=4.03843e-05, gnorm=0.056, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=90937
2023-02-21 14:31:22 - progress_bar.py[line:274] - INFO: epoch 001:  30464 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.8, bsz=40, num_updates=30420, lr=4.03806e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90948
2023-02-21 14:31:33 - progress_bar.py[line:274] - INFO: epoch 001:  30474 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=112.5, bsz=40, num_updates=30430, lr=4.0377e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=90960
2023-02-21 14:31:45 - progress_bar.py[line:274] - INFO: epoch 001:  30484 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=112.9, bsz=40, num_updates=30440, lr=4.03734e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=90971
2023-02-21 14:31:56 - progress_bar.py[line:274] - INFO: epoch 001:  30494 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.3, bsz=40, num_updates=30450, lr=4.03698e-05, gnorm=0.142, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=90982
2023-02-21 14:32:07 - progress_bar.py[line:274] - INFO: epoch 001:  30504 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.95, wpb=110.2, bsz=40, num_updates=30460, lr=4.03662e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=90993
2023-02-21 14:32:18 - progress_bar.py[line:274] - INFO: epoch 001:  30514 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=30470, lr=4.03625e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91004
2023-02-21 14:32:29 - progress_bar.py[line:274] - INFO: epoch 001:  30524 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=30480, lr=4.03589e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91015
2023-02-21 14:32:40 - progress_bar.py[line:274] - INFO: epoch 001:  30534 / 71012 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.89, wpb=113.1, bsz=40, num_updates=30490, lr=4.03553e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91026
2023-02-21 14:32:51 - progress_bar.py[line:274] - INFO: epoch 001:  30544 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=96.8, ups=0.87, wpb=110.6, bsz=40, num_updates=30500, lr=4.03517e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91038
2023-02-21 14:33:03 - progress_bar.py[line:274] - INFO: epoch 001:  30554 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.6, bsz=40, num_updates=30510, lr=4.03481e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=91049
2023-02-21 14:33:14 - progress_bar.py[line:274] - INFO: epoch 001:  30564 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.3, bsz=40, num_updates=30520, lr=4.03445e-05, gnorm=0.06, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91060
2023-02-21 14:33:25 - progress_bar.py[line:274] - INFO: epoch 001:  30574 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.5, bsz=40, num_updates=30530, lr=4.03408e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=91071
2023-02-21 14:33:36 - progress_bar.py[line:274] - INFO: epoch 001:  30584 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=111.8, bsz=40, num_updates=30540, lr=4.03372e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91083
2023-02-21 14:33:48 - progress_bar.py[line:274] - INFO: epoch 001:  30594 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.6, bsz=40, num_updates=30550, lr=4.03336e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91094
2023-02-21 14:33:59 - progress_bar.py[line:274] - INFO: epoch 001:  30604 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.3, bsz=40, num_updates=30560, lr=4.033e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91105
2023-02-21 14:34:10 - progress_bar.py[line:274] - INFO: epoch 001:  30614 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.3, bsz=40, num_updates=30570, lr=4.03264e-05, gnorm=0.056, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=91117
2023-02-21 14:34:21 - progress_bar.py[line:274] - INFO: epoch 001:  30624 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.92, wpb=112.4, bsz=40, num_updates=30580, lr=4.03227e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91128
2023-02-21 14:34:32 - progress_bar.py[line:274] - INFO: epoch 001:  30634 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.2, bsz=40, num_updates=30590, lr=4.03191e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91139
2023-02-21 14:34:43 - progress_bar.py[line:274] - INFO: epoch 001:  30644 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=30600, lr=4.03155e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=91150
2023-02-21 14:34:55 - progress_bar.py[line:274] - INFO: epoch 001:  30654 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.5, bsz=40, num_updates=30610, lr=4.03119e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91161
2023-02-21 14:35:06 - progress_bar.py[line:274] - INFO: epoch 001:  30664 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.2, bsz=40, num_updates=30620, lr=4.03083e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91173
2023-02-21 14:35:17 - progress_bar.py[line:274] - INFO: epoch 001:  30674 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=98.5, ups=0.89, wpb=111.2, bsz=40, num_updates=30630, lr=4.03047e-05, gnorm=0.061, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91184
2023-02-21 14:35:29 - progress_bar.py[line:274] - INFO: epoch 001:  30684 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112, bsz=40, num_updates=30640, lr=4.0301e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91195
2023-02-21 14:35:40 - progress_bar.py[line:274] - INFO: epoch 001:  30694 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=111.4, bsz=40, num_updates=30650, lr=4.02974e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=91206
2023-02-21 14:35:51 - progress_bar.py[line:274] - INFO: epoch 001:  30704 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=112.2, bsz=40, num_updates=30660, lr=4.02938e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91217
2023-02-21 14:36:02 - progress_bar.py[line:274] - INFO: epoch 001:  30714 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.92, wpb=110.1, bsz=40, num_updates=30670, lr=4.02902e-05, gnorm=0.06, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91228
2023-02-21 14:36:13 - progress_bar.py[line:274] - INFO: epoch 001:  30724 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=110.9, bsz=40, num_updates=30680, lr=4.02866e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91239
2023-02-21 14:36:24 - progress_bar.py[line:274] - INFO: epoch 001:  30734 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.2, bsz=40, num_updates=30690, lr=4.02829e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91251
2023-02-21 14:36:35 - progress_bar.py[line:274] - INFO: epoch 001:  30744 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.8, bsz=40, num_updates=30700, lr=4.02793e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91262
2023-02-21 14:36:47 - progress_bar.py[line:274] - INFO: epoch 001:  30754 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=30710, lr=4.02757e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91273
2023-02-21 14:36:58 - progress_bar.py[line:274] - INFO: epoch 001:  30764 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112.6, bsz=40, num_updates=30720, lr=4.02721e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91284
2023-02-21 14:37:09 - progress_bar.py[line:274] - INFO: epoch 001:  30774 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.7, bsz=40, num_updates=30730, lr=4.02685e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91295
2023-02-21 14:37:20 - progress_bar.py[line:274] - INFO: epoch 001:  30784 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.6, bsz=40, num_updates=30740, lr=4.02649e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=91306
2023-02-21 14:37:31 - progress_bar.py[line:274] - INFO: epoch 001:  30794 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.7, bsz=40, num_updates=30750, lr=4.02612e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91317
2023-02-21 14:37:42 - progress_bar.py[line:274] - INFO: epoch 001:  30804 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.4, bsz=40, num_updates=30760, lr=4.02576e-05, gnorm=0.146, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91329
2023-02-21 14:37:53 - progress_bar.py[line:274] - INFO: epoch 001:  30814 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.1, bsz=40, num_updates=30770, lr=4.0254e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=91340
2023-02-21 14:38:04 - progress_bar.py[line:274] - INFO: epoch 001:  30824 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.9, bsz=40, num_updates=30780, lr=4.02504e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91351
2023-02-21 14:38:15 - progress_bar.py[line:274] - INFO: epoch 001:  30834 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.4, bsz=40, num_updates=30790, lr=4.02468e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91362
2023-02-21 14:38:26 - progress_bar.py[line:274] - INFO: epoch 001:  30844 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.2, bsz=40, num_updates=30800, lr=4.02431e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=91373
2023-02-21 14:38:37 - progress_bar.py[line:274] - INFO: epoch 001:  30854 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.1, bsz=40, num_updates=30810, lr=4.02395e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91384
2023-02-21 14:38:48 - progress_bar.py[line:274] - INFO: epoch 001:  30864 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.7, bsz=40, num_updates=30820, lr=4.02359e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91395
2023-02-21 14:39:00 - progress_bar.py[line:274] - INFO: epoch 001:  30874 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110.6, bsz=40, num_updates=30830, lr=4.02323e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91406
2023-02-21 14:39:10 - progress_bar.py[line:274] - INFO: epoch 001:  30884 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=105, ups=0.95, wpb=110.7, bsz=40, num_updates=30840, lr=4.02287e-05, gnorm=0.053, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91416
2023-02-21 14:39:21 - progress_bar.py[line:274] - INFO: epoch 001:  30894 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.1, bsz=40, num_updates=30850, lr=4.02251e-05, gnorm=0.073, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91427
2023-02-21 14:39:32 - progress_bar.py[line:274] - INFO: epoch 001:  30904 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.93, wpb=110.6, bsz=40, num_updates=30860, lr=4.02214e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91438
2023-02-21 14:39:43 - progress_bar.py[line:274] - INFO: epoch 001:  30914 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.6, bsz=40, num_updates=30870, lr=4.02178e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91449
2023-02-21 14:39:54 - progress_bar.py[line:274] - INFO: epoch 001:  30924 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.1, bsz=40, num_updates=30880, lr=4.02142e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91461
2023-02-21 14:39:58 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 14:40:06 - progress_bar.py[line:274] - INFO: epoch 001:  30935 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.5, ups=0.83, wpb=112.4, bsz=40, num_updates=30890, lr=4.02106e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=91473
2023-02-21 14:40:17 - progress_bar.py[line:274] - INFO: epoch 001:  30945 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.93, wpb=111.9, bsz=40, num_updates=30900, lr=4.0207e-05, gnorm=0.122, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91483
2023-02-21 14:40:28 - progress_bar.py[line:274] - INFO: epoch 001:  30955 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.93, wpb=109.8, bsz=40, num_updates=30910, lr=4.02033e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91494
2023-02-21 14:40:39 - progress_bar.py[line:274] - INFO: epoch 001:  30965 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.92, wpb=112.7, bsz=40, num_updates=30920, lr=4.01997e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=91505
2023-02-21 14:40:50 - progress_bar.py[line:274] - INFO: epoch 001:  30975 / 71012 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.9, bsz=40, num_updates=30930, lr=4.01961e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91516
2023-02-21 14:41:01 - progress_bar.py[line:274] - INFO: epoch 001:  30985 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=30940, lr=4.01925e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91527
2023-02-21 14:41:12 - progress_bar.py[line:274] - INFO: epoch 001:  30995 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112, bsz=40, num_updates=30950, lr=4.01889e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91539
2023-02-21 14:41:23 - progress_bar.py[line:274] - INFO: epoch 001:  31005 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.3, bsz=40, num_updates=30960, lr=4.01853e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91550
2023-02-21 14:41:34 - progress_bar.py[line:274] - INFO: epoch 001:  31015 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=30970, lr=4.01816e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91561
2023-02-21 14:41:45 - progress_bar.py[line:274] - INFO: epoch 001:  31025 / 71012 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=110.2, bsz=40, num_updates=30980, lr=4.0178e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91572
2023-02-21 14:41:57 - progress_bar.py[line:274] - INFO: epoch 001:  31035 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.5, bsz=40, num_updates=30990, lr=4.01744e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91583
2023-02-21 14:42:08 - progress_bar.py[line:274] - INFO: epoch 001:  31045 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=112.2, bsz=40, num_updates=31000, lr=4.01708e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91594
2023-02-21 14:42:19 - progress_bar.py[line:274] - INFO: epoch 001:  31055 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.2, bsz=40, num_updates=31010, lr=4.01672e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=91605
2023-02-21 14:42:30 - progress_bar.py[line:274] - INFO: epoch 001:  31065 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=31020, lr=4.01635e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91617
2023-02-21 14:42:41 - progress_bar.py[line:274] - INFO: epoch 001:  31075 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.93, wpb=110.9, bsz=40, num_updates=31030, lr=4.01599e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=91628
2023-02-21 14:42:52 - progress_bar.py[line:274] - INFO: epoch 001:  31085 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=31040, lr=4.01563e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91639
2023-02-21 14:43:03 - progress_bar.py[line:274] - INFO: epoch 001:  31095 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.1, bsz=40, num_updates=31050, lr=4.01527e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91650
2023-02-21 14:43:15 - progress_bar.py[line:274] - INFO: epoch 001:  31105 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.2, bsz=40, num_updates=31060, lr=4.01491e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=91661
2023-02-21 14:43:26 - progress_bar.py[line:274] - INFO: epoch 001:  31115 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.8, bsz=40, num_updates=31070, lr=4.01455e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91672
2023-02-21 14:43:37 - progress_bar.py[line:274] - INFO: epoch 001:  31125 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.5, bsz=40, num_updates=31080, lr=4.01418e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=91683
2023-02-21 14:43:48 - progress_bar.py[line:274] - INFO: epoch 001:  31135 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.1, bsz=40, num_updates=31090, lr=4.01382e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91694
2023-02-21 14:43:59 - progress_bar.py[line:274] - INFO: epoch 001:  31145 / 71012 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=104.5, ups=0.93, wpb=111.9, bsz=40, num_updates=31100, lr=4.01346e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=91705
2023-02-21 14:44:10 - progress_bar.py[line:274] - INFO: epoch 001:  31155 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.1, bsz=40, num_updates=31110, lr=4.0131e-05, gnorm=0.052, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91716
2023-02-21 14:44:21 - progress_bar.py[line:274] - INFO: epoch 001:  31165 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.3, bsz=40, num_updates=31120, lr=4.01274e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91728
2023-02-21 14:44:32 - progress_bar.py[line:274] - INFO: epoch 001:  31175 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.3, bsz=40, num_updates=31130, lr=4.01237e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91739
2023-02-21 14:44:44 - progress_bar.py[line:274] - INFO: epoch 001:  31185 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112.3, bsz=40, num_updates=31140, lr=4.01201e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91750
2023-02-21 14:44:55 - progress_bar.py[line:274] - INFO: epoch 001:  31195 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.88, wpb=112.7, bsz=40, num_updates=31150, lr=4.01165e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91761
2023-02-21 14:45:06 - progress_bar.py[line:274] - INFO: epoch 001:  31205 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=31160, lr=4.01129e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91772
2023-02-21 14:45:17 - progress_bar.py[line:274] - INFO: epoch 001:  31215 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.4, bsz=40, num_updates=31170, lr=4.01093e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91783
2023-02-21 14:45:28 - progress_bar.py[line:274] - INFO: epoch 001:  31225 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.7, ups=0.95, wpb=111.7, bsz=40, num_updates=31180, lr=4.01057e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91794
2023-02-21 14:45:38 - progress_bar.py[line:274] - INFO: epoch 001:  31235 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.93, wpb=111, bsz=40, num_updates=31190, lr=4.0102e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91805
2023-02-21 14:45:50 - progress_bar.py[line:274] - INFO: epoch 001:  31245 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.8, bsz=40, num_updates=31200, lr=4.00984e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91816
2023-02-21 14:46:01 - progress_bar.py[line:274] - INFO: epoch 001:  31255 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.87, wpb=112.6, bsz=40, num_updates=31210, lr=4.00948e-05, gnorm=0.059, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91827
2023-02-21 14:46:12 - progress_bar.py[line:274] - INFO: epoch 001:  31265 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.5, bsz=40, num_updates=31220, lr=4.00912e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91838
2023-02-21 14:46:23 - progress_bar.py[line:274] - INFO: epoch 001:  31275 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.7, bsz=40, num_updates=31230, lr=4.00876e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91849
2023-02-21 14:46:34 - progress_bar.py[line:274] - INFO: epoch 001:  31285 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.6, bsz=40, num_updates=31240, lr=4.00839e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=91861
2023-02-21 14:46:46 - progress_bar.py[line:274] - INFO: epoch 001:  31295 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.5, bsz=40, num_updates=31250, lr=4.00803e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91872
2023-02-21 14:46:57 - progress_bar.py[line:274] - INFO: epoch 001:  31305 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=31260, lr=4.00767e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91883
2023-02-21 14:47:08 - progress_bar.py[line:274] - INFO: epoch 001:  31315 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=112.1, bsz=40, num_updates=31270, lr=4.00731e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91894
2023-02-21 14:47:19 - progress_bar.py[line:274] - INFO: epoch 001:  31325 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.7, bsz=40, num_updates=31280, lr=4.00695e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=91906
2023-02-21 14:47:31 - progress_bar.py[line:274] - INFO: epoch 001:  31335 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112.3, bsz=40, num_updates=31290, lr=4.00659e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=91917
2023-02-21 14:47:41 - progress_bar.py[line:274] - INFO: epoch 001:  31345 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.2, ups=0.95, wpb=111.1, bsz=40, num_updates=31300, lr=4.00622e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91928
2023-02-21 14:47:52 - progress_bar.py[line:274] - INFO: epoch 001:  31355 / 71012 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=110.1, bsz=40, num_updates=31310, lr=4.00586e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91939
2023-02-21 14:48:04 - progress_bar.py[line:274] - INFO: epoch 001:  31365 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.033, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=99.2, ups=0.89, wpb=111.6, bsz=40, num_updates=31320, lr=4.0055e-05, gnorm=0.06, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91950
2023-02-21 14:48:15 - progress_bar.py[line:274] - INFO: epoch 001:  31375 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=112, bsz=40, num_updates=31330, lr=4.00514e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91961
2023-02-21 14:48:26 - progress_bar.py[line:274] - INFO: epoch 001:  31385 / 71012 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=31340, lr=4.00478e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91972
2023-02-21 14:48:37 - progress_bar.py[line:274] - INFO: epoch 001:  31395 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.9, wpb=109.7, bsz=40, num_updates=31350, lr=4.00441e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91983
2023-02-21 14:48:48 - progress_bar.py[line:274] - INFO: epoch 001:  31405 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113.4, nsentences=40, sample_size=113.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.92, wpb=113.4, bsz=40, num_updates=31360, lr=4.00405e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91994
2023-02-21 14:48:59 - progress_bar.py[line:274] - INFO: epoch 001:  31415 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.4, bsz=40, num_updates=31370, lr=4.00369e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=92006
2023-02-21 14:49:11 - progress_bar.py[line:274] - INFO: epoch 001:  31425 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.88, wpb=112.6, bsz=40, num_updates=31380, lr=4.00333e-05, gnorm=0.061, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92017
2023-02-21 14:49:22 - progress_bar.py[line:274] - INFO: epoch 001:  31435 / 71012 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=31390, lr=4.00297e-05, gnorm=0.048, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92028
2023-02-21 14:49:33 - progress_bar.py[line:274] - INFO: epoch 001:  31445 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.8, bsz=40, num_updates=31400, lr=4.00261e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92039
2023-02-21 14:49:44 - progress_bar.py[line:274] - INFO: epoch 001:  31455 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.92, wpb=109.3, bsz=40, num_updates=31410, lr=4.00224e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=92050
2023-02-21 14:49:55 - progress_bar.py[line:274] - INFO: epoch 001:  31465 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=111, bsz=40, num_updates=31420, lr=4.00188e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92061
2023-02-21 14:50:06 - progress_bar.py[line:274] - INFO: epoch 001:  31475 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=113.4, nsentences=40, sample_size=113.4, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=98.7, ups=0.87, wpb=113.4, bsz=40, num_updates=31430, lr=4.00152e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92073
2023-02-21 14:50:17 - progress_bar.py[line:274] - INFO: epoch 001:  31485 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.6, bsz=40, num_updates=31440, lr=4.00116e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=92084
2023-02-21 14:50:28 - progress_bar.py[line:274] - INFO: epoch 001:  31495 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.1, ups=0.94, wpb=112, bsz=40, num_updates=31450, lr=4.0008e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92094
2023-02-21 14:50:39 - progress_bar.py[line:274] - INFO: epoch 001:  31505 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.4, bsz=40, num_updates=31460, lr=4.00043e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92105
2023-02-21 14:50:50 - progress_bar.py[line:274] - INFO: epoch 001:  31515 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.4, bsz=40, num_updates=31470, lr=4.00007e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92116
2023-02-21 14:51:01 - progress_bar.py[line:274] - INFO: epoch 001:  31525 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.3, bsz=40, num_updates=31480, lr=3.99971e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92128
2023-02-21 14:51:13 - progress_bar.py[line:274] - INFO: epoch 001:  31535 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=31490, lr=3.99935e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92139
2023-02-21 14:51:24 - progress_bar.py[line:274] - INFO: epoch 001:  31545 / 71012 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.9, wpb=109.6, bsz=40, num_updates=31500, lr=3.99899e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92150
2023-02-21 14:51:35 - progress_bar.py[line:274] - INFO: epoch 001:  31555 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111.1, bsz=40, num_updates=31510, lr=3.99863e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=92161
2023-02-21 14:51:47 - progress_bar.py[line:274] - INFO: epoch 001:  31565 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=110.6, bsz=40, num_updates=31520, lr=3.99826e-05, gnorm=0.131, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92173
2023-02-21 14:51:57 - progress_bar.py[line:274] - INFO: epoch 001:  31575 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.8, bsz=40, num_updates=31530, lr=3.9979e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=92184
2023-02-21 14:52:03 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-21 14:52:09 - progress_bar.py[line:274] - INFO: epoch 001:  31586 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93, ups=0.83, wpb=112.1, bsz=40, num_updates=31540, lr=3.99754e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=92196
2023-02-21 14:52:21 - progress_bar.py[line:274] - INFO: epoch 001:  31596 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.8, bsz=40, num_updates=31550, lr=3.99718e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92207
2023-02-21 14:52:32 - progress_bar.py[line:274] - INFO: epoch 001:  31606 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=112.2, bsz=40, num_updates=31560, lr=3.99682e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92218
2023-02-21 14:52:43 - progress_bar.py[line:274] - INFO: epoch 001:  31616 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.7, bsz=40, num_updates=31570, lr=3.99645e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92229
2023-02-21 14:52:54 - progress_bar.py[line:274] - INFO: epoch 001:  31626 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.4, bsz=40, num_updates=31580, lr=3.99609e-05, gnorm=0.057, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92241
2023-02-21 14:53:05 - progress_bar.py[line:274] - INFO: epoch 001:  31636 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.89, wpb=112.5, bsz=40, num_updates=31590, lr=3.99573e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92252
2023-02-21 14:53:16 - progress_bar.py[line:274] - INFO: epoch 001:  31646 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.93, wpb=110.2, bsz=40, num_updates=31600, lr=3.99537e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=92263
2023-02-21 14:53:27 - progress_bar.py[line:274] - INFO: epoch 001:  31656 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.91, wpb=112.8, bsz=40, num_updates=31610, lr=3.99501e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92274
2023-02-21 14:53:38 - progress_bar.py[line:274] - INFO: epoch 001:  31666 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.6, bsz=40, num_updates=31620, lr=3.99465e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92285
2023-02-21 14:53:49 - progress_bar.py[line:274] - INFO: epoch 001:  31676 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.5, bsz=40, num_updates=31630, lr=3.99428e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92296
2023-02-21 14:54:00 - progress_bar.py[line:274] - INFO: epoch 001:  31686 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.9, bsz=40, num_updates=31640, lr=3.99392e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92307
2023-02-21 14:54:11 - progress_bar.py[line:274] - INFO: epoch 001:  31696 / 71012 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.92, wpb=112.3, bsz=40, num_updates=31650, lr=3.99356e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92318
2023-02-21 14:54:23 - progress_bar.py[line:274] - INFO: epoch 001:  31706 / 71012 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.2, bsz=40, num_updates=31660, lr=3.9932e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92329
2023-02-21 14:54:34 - progress_bar.py[line:274] - INFO: epoch 001:  31716 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.4, bsz=40, num_updates=31670, lr=3.99284e-05, gnorm=0.079, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92340
2023-02-21 14:54:45 - progress_bar.py[line:274] - INFO: epoch 001:  31726 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.7, bsz=40, num_updates=31680, lr=3.99247e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92352
2023-02-21 14:54:56 - progress_bar.py[line:274] - INFO: epoch 001:  31736 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113.5, nsentences=40, sample_size=113.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.92, wpb=113.5, bsz=40, num_updates=31690, lr=3.99211e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92363
2023-02-21 14:55:07 - progress_bar.py[line:274] - INFO: epoch 001:  31746 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.2, bsz=40, num_updates=31700, lr=3.99175e-05, gnorm=0.092, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92373
2023-02-21 14:55:18 - progress_bar.py[line:274] - INFO: epoch 001:  31756 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.2, bsz=40, num_updates=31710, lr=3.99139e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=92385
2023-02-21 14:55:29 - progress_bar.py[line:274] - INFO: epoch 001:  31766 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.5, bsz=40, num_updates=31720, lr=3.99103e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92396
2023-02-21 14:55:40 - progress_bar.py[line:274] - INFO: epoch 001:  31776 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.7, bsz=40, num_updates=31730, lr=3.99067e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92406
2023-02-21 14:55:51 - progress_bar.py[line:274] - INFO: epoch 001:  31786 / 71012 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=31740, lr=3.9903e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92418
2023-02-21 14:56:03 - progress_bar.py[line:274] - INFO: epoch 001:  31796 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=31750, lr=3.98994e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=92429
2023-02-21 14:56:14 - progress_bar.py[line:274] - INFO: epoch 001:  31806 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.3, bsz=40, num_updates=31760, lr=3.98958e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92440
2023-02-21 14:56:25 - progress_bar.py[line:274] - INFO: epoch 001:  31816 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.5, bsz=40, num_updates=31770, lr=3.98922e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=92452
2023-02-21 14:56:36 - progress_bar.py[line:274] - INFO: epoch 001:  31826 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.6, bsz=40, num_updates=31780, lr=3.98886e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92463
2023-02-21 14:56:47 - progress_bar.py[line:274] - INFO: epoch 001:  31836 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.9, ups=0.95, wpb=112, bsz=40, num_updates=31790, lr=3.98849e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92473
2023-02-21 14:56:58 - progress_bar.py[line:274] - INFO: epoch 001:  31846 / 71012 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111, bsz=40, num_updates=31800, lr=3.98813e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92484
2023-02-21 14:57:09 - progress_bar.py[line:274] - INFO: epoch 001:  31856 / 71012 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112, bsz=40, num_updates=31810, lr=3.98777e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92495
2023-02-21 14:57:20 - progress_bar.py[line:274] - INFO: epoch 001:  31866 / 71012 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.5, bsz=40, num_updates=31820, lr=3.98741e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92507
2023-02-21 14:57:32 - progress_bar.py[line:274] - INFO: epoch 001:  31876 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.6, bsz=40, num_updates=31830, lr=3.98705e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=92518
2023-02-21 14:57:43 - progress_bar.py[line:274] - INFO: epoch 001:  31886 / 71012 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=31840, lr=3.98668e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=92529
2023-02-21 14:57:54 - progress_bar.py[line:274] - INFO: epoch 001:  31896 / 71012 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.9, wpb=109.9, bsz=40, num_updates=31850, lr=3.98632e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92540
2023-02-21 14:58:05 - progress_bar.py[line:274] - INFO: epoch 001:  31906 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.3, bsz=40, num_updates=31860, lr=3.98596e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92551
2023-02-21 14:58:16 - progress_bar.py[line:274] - INFO: epoch 001:  31916 / 71012 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.92, wpb=110, bsz=40, num_updates=31870, lr=3.9856e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92562
2023-02-21 14:58:27 - progress_bar.py[line:274] - INFO: epoch 001:  31926 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=31880, lr=3.98524e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=92573
2023-02-21 14:58:38 - progress_bar.py[line:274] - INFO: epoch 001:  31936 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.88, wpb=113, bsz=40, num_updates=31890, lr=3.98488e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92585
2023-02-21 14:58:49 - progress_bar.py[line:274] - INFO: epoch 001:  31946 / 71012 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.9, bsz=40, num_updates=31900, lr=3.98451e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92596
2023-02-21 14:59:01 - progress_bar.py[line:274] - INFO: epoch 001:  31956 / 71012 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.1, bsz=40, num_updates=31910, lr=3.98415e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92607
2023-02-21 14:59:12 - progress_bar.py[line:274] - INFO: epoch 001:  31966 / 71012 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.5, bsz=40, num_updates=31920, lr=3.98379e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92618
2023-02-21 14:59:23 - progress_bar.py[line:274] - INFO: epoch 001:  31976 / 71012 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=110.6, bsz=40, num_updates=31930, lr=3.98343e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=92630
2023-02-21 14:59:34 - progress_bar.py[line:274] - INFO: epoch 001:  31986 / 71012 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.94, wpb=111.5, bsz=40, num_updates=31940, lr=3.98307e-05, gnorm=0.063, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92641
2023-02-21 14:59:45 - progress_bar.py[line:274] - INFO: epoch 001:  31996 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.1, bsz=40, num_updates=31950, lr=3.9827e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92652
2023-02-21 14:59:57 - progress_bar.py[line:274] - INFO: epoch 001:  32006 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=31960, lr=3.98234e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=92663
2023-02-21 15:00:08 - progress_bar.py[line:274] - INFO: epoch 001:  32016 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.89, wpb=110.3, bsz=40, num_updates=31970, lr=3.98198e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=92674
2023-02-21 15:00:19 - progress_bar.py[line:274] - INFO: epoch 001:  32026 / 71012 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112.7, bsz=40, num_updates=31980, lr=3.98162e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92685
2023-02-21 15:00:30 - progress_bar.py[line:274] - INFO: epoch 001:  32036 / 71012 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.93, wpb=111.6, bsz=40, num_updates=31990, lr=3.98126e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=92696
2023-02-21 15:00:41 - progress_bar.py[line:274] - INFO: epoch 001:  32046 / 71012 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=99.2, ups=0.88, wpb=112.4, bsz=40, num_updates=32000, lr=3.9809e-05, gnorm=0.059, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92708
2023-02-21 15:00:41 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 15:00:42 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 15:00:42 - train.py[line:551] - INFO: load:0.84 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 15:02:45 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 15:02:45 - train.py[line:551] - INFO: load:0.87 valid_run:122.32 task_valid:119.00 collect_output:2.18
2023-02-21 15:04:45 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 15:04:45 - train.py[line:551] - INFO: load:0.90 valid_run:241.94 task_valid:234.62 collect_output:5.10
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 3568216
Killing subprocess 3568217
Main process received SIGINT, exiting
