2023-01-05 11:57:20 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2023-01-05 11:57:20 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2023-01-05 11:57:20 - utils.py[line:261] - INFO: Start init
2023-01-05 11:57:20 - utils.py[line:261] - INFO: Start init
2023-01-05 11:57:21 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-01-05 11:57:21 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-01-05 11:57:21 - utils.py[line:274] - INFO: initialized host node4 as rank 1
2023-01-05 11:57:21 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
single-machine distributed training is initialized.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 2173105
Killing subprocess 2173106
Main process received SIGINT, exiting
2023-01-05 11:57:33 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2023-01-05 11:57:33 - utils.py[line:261] - INFO: Start init
2023-01-05 11:57:33 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2023-01-05 11:57:33 - utils.py[line:261] - INFO: Start init
2023-01-05 11:57:34 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-01-05 11:57:34 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-01-05 11:57:34 - utils.py[line:274] - INFO: initialized host node4 as rank 1
2023-01-05 11:57:34 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.single-machine distributed training is initialized.

2023-01-05 11:57:40 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_visualDS_momentum1.0_alpha1.0', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 2000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 2000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=1, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480', save_interval=10, save_interval_updates=2000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_visualDS_momentum1.0_alpha1.0', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=2000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-01-05 11:57:40 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-01-05 11:57:41 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2023-01-05 11:57:45 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-01-05 11:57:45 - train.py[line:118] - INFO: task: VqaGenTask
2023-01-05 11:57:45 - train.py[line:119] - INFO: model: OFAModel
2023-01-05 11:57:45 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-01-05 11:57:45 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-01-05 11:57:45 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2023-01-05 11:57:45 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-01-05 11:57:45 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-01-05 11:57:46 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-01-05 11:57:47 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-01-05 11:57:47 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-01-05 11:57:47 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-01-05 11:57:47 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
Done cuda cpu, cpu
Done cuda cpu, cpu
2023-01-05 11:57:48 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2023-01-05 11:57:49 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2023-01-05 11:57:49 - trainer.py[line:499] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2023-01-05 11:57:58 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-01-05 11:57:59 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-01-05 11:57:59 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-01-05 11:57:59 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-01-05 11:57:59 - trainer.py[line:314] - INFO: Exponential Moving Average Shadow Model is initialized.
2023-01-05 11:58:00 - trainer.py[line:674] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2023-01-05 11:58:00 - trainer.py[line:694] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv slice_id 1 row count 2316893 total row count 4633786
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv slice_id 0 row count 2316893 total row count 4633786
2023-01-05 11:58:04 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 115845, warmup steps 4633, warmup_factor 0.0002158428663932657
Total steps 115845, warmup steps 4633, warmup_factor 0.0002158428663932657
2023-01-05 11:58:04 - trainer.py[line:758] - INFO: begin training epoch 1
2023-01-05 11:58:04 - train.py[line:312] - INFO: Start iterating over samples
From cpu to cuda:1
From cpu to cuda:0
2023-01-05 11:58:36 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 115845 loss=0.977, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, vqa_score=0.0363, wps=92.1, ups=0.42, wpb=109.9, bsz=40, num_updates=10, lr=1.07921e-07, gnorm=7.478, clip=100, loss_scale=128, train_wall=27, gb_free=10.4, ema_decay=0.9999, wall=47
2023-01-05 11:58:58 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 115845 loss=1.01, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, vqa_score=0.0308, wps=100.1, ups=0.46, wpb=109.6, bsz=40, num_updates=20, lr=2.15843e-07, gnorm=8.016, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70
2023-01-05 11:59:21 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0245, wps=101.7, ups=0.47, wpb=109, bsz=40, num_updates=30, lr=3.23764e-07, gnorm=9.021, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=93
2023-01-05 11:59:43 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 115845 loss=1.005, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, vqa_score=0.0263, wps=101.2, ups=0.47, wpb=108.7, bsz=40, num_updates=40, lr=4.31686e-07, gnorm=7.72, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=115
2023-01-05 12:00:06 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0297, wps=101, ups=0.46, wpb=108.8, bsz=40, num_updates=50, lr=5.39607e-07, gnorm=7.308, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=138
2023-01-05 12:00:28 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 115845 loss=1.084, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, vqa_score=0.0332, wps=100.9, ups=0.47, wpb=108.3, bsz=40, num_updates=60, lr=6.47529e-07, gnorm=8.536, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=160
2023-01-05 12:00:52 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 115845 loss=1.035, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, vqa_score=0.0283, wps=98, ups=0.45, wpb=109.6, bsz=40, num_updates=70, lr=7.5545e-07, gnorm=7.204, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=184
2023-01-05 12:01:15 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 115845 loss=0.99, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, vqa_score=0.0287, wps=97, ups=0.45, wpb=108.3, bsz=40, num_updates=80, lr=8.63371e-07, gnorm=6.813, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=207
2023-01-05 12:01:38 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 115845 loss=0.891, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.7, vqa_score=0.0291, wps=99.8, ups=0.46, wpb=109.4, bsz=40, num_updates=90, lr=9.71293e-07, gnorm=5.634, clip=100, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=230
2023-01-05 12:02:01 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 115845 loss=0.867, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.68, vqa_score=0.0205, wps=103.6, ups=0.48, wpb=109, bsz=40, num_updates=100, lr=1.07921e-06, gnorm=5.19, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=252
2023-01-05 12:02:25 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 115845 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, vqa_score=0.0321, wps=94.1, ups=0.43, wpb=108.4, bsz=40, num_updates=110, lr=1.18714e-06, gnorm=5.274, clip=100, loss_scale=128, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=277
2023-01-05 12:02:47 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 115845 loss=0.797, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, vqa_score=0.0412, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=120, lr=1.29506e-06, gnorm=4.533, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=299
2023-01-05 12:03:10 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 115845 loss=0.751, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, vqa_score=0.0217, wps=101.2, ups=0.46, wpb=109.7, bsz=40, num_updates=130, lr=1.40298e-06, gnorm=3.786, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=322
2023-01-05 12:03:32 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0457, wps=99.4, ups=0.46, wpb=108.1, bsz=40, num_updates=140, lr=1.5109e-06, gnorm=3.857, clip=100, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=344
2023-01-05 12:03:55 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0337, wps=101, ups=0.46, wpb=108.7, bsz=40, num_updates=150, lr=1.61882e-06, gnorm=3.658, clip=100, loss_scale=128, train_wall=21, gb_free=10, ema_decay=0.9999, wall=367
2023-01-05 12:04:17 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 115845 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.56, vqa_score=0.0195, wps=101.8, ups=0.46, wpb=110, bsz=40, num_updates=160, lr=1.72674e-06, gnorm=3.282, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=389
2023-01-05 12:04:40 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0263, wps=104, ups=0.47, wpb=110.4, bsz=40, num_updates=170, lr=1.83466e-06, gnorm=2.669, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=412
2023-01-05 12:05:02 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 115845 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, vqa_score=0.0048, wps=98.9, ups=0.46, wpb=107.2, bsz=40, num_updates=180, lr=1.94259e-06, gnorm=3.216, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=434
2023-01-05 12:05:25 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 115845 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, vqa_score=0.0243, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=190, lr=2.05051e-06, gnorm=2.931, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=457
2023-01-05 12:05:47 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 115845 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, vqa_score=0.0187, wps=100, ups=0.46, wpb=108.6, bsz=40, num_updates=200, lr=2.15843e-06, gnorm=2.671, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=479
2023-01-05 12:06:10 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 115845 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.615, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, vqa_score=0.0147, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=210, lr=2.26635e-06, gnorm=2.56, clip=100, loss_scale=128, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=502
2023-01-05 12:06:33 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 115845 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, vqa_score=0.0194, wps=97.5, ups=0.44, wpb=110.1, bsz=40, num_updates=220, lr=2.37427e-06, gnorm=2.398, clip=100, loss_scale=128, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=525
2023-01-05 12:06:56 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 115845 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, vqa_score=0.0303, wps=98.8, ups=0.45, wpb=109.2, bsz=40, num_updates=230, lr=2.48219e-06, gnorm=2.235, clip=100, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=548
2023-01-05 12:07:19 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0156, wps=101.5, ups=0.47, wpb=108.8, bsz=40, num_updates=240, lr=2.59011e-06, gnorm=2.143, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=571
2023-01-05 12:07:41 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.8, nsentences=40, sample_size=106.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0431, wps=99.6, ups=0.47, wpb=106.8, bsz=40, num_updates=250, lr=2.69804e-06, gnorm=2.074, clip=100, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=593
2023-01-05 12:08:04 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.04, wps=100.9, ups=0.47, wpb=108.1, bsz=40, num_updates=260, lr=2.80596e-06, gnorm=2.205, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=616
2023-01-05 12:08:26 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 115845 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, vqa_score=0.011, wps=106, ups=0.48, wpb=110.3, bsz=40, num_updates=270, lr=2.91388e-06, gnorm=2.066, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=637
2023-01-05 12:08:48 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 115845 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, vqa_score=0.0047, wps=100.7, ups=0.47, wpb=107.1, bsz=40, num_updates=280, lr=3.0218e-06, gnorm=1.96, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=660
2023-01-05 12:09:10 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 115845 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0269, wps=102, ups=0.47, wpb=109.5, bsz=40, num_updates=290, lr=3.12972e-06, gnorm=1.669, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=683
2023-01-05 12:09:33 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0052, wps=102.9, ups=0.47, wpb=109.2, bsz=40, num_updates=300, lr=3.23764e-06, gnorm=1.82, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=705
2023-01-05 12:09:56 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 115845 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, vqa_score=0.0348, wps=100.5, ups=0.46, wpb=110.3, bsz=40, num_updates=310, lr=3.34556e-06, gnorm=1.697, clip=100, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=728
2023-01-05 12:10:18 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0146, wps=99.2, ups=0.46, wpb=107.3, bsz=40, num_updates=320, lr=3.45349e-06, gnorm=1.711, clip=100, loss_scale=128, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=750
2023-01-05 12:10:41 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0047, wps=100.6, ups=0.46, wpb=108.5, bsz=40, num_updates=330, lr=3.56141e-06, gnorm=1.713, clip=100, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=773
2023-01-05 12:11:04 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 115845 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, vqa_score=0.0204, wps=100.5, ups=0.46, wpb=109.1, bsz=40, num_updates=340, lr=3.66933e-06, gnorm=1.631, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=795
2023-01-05 12:11:26 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 115845 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, vqa_score=0.0317, wps=98.9, ups=0.45, wpb=109.1, bsz=40, num_updates=350, lr=3.77725e-06, gnorm=1.419, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=819
2023-01-05 12:11:49 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 115845 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, vqa_score=0.024, wps=102.7, ups=0.47, wpb=108.9, bsz=40, num_updates=360, lr=3.88517e-06, gnorm=1.488, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=841
2023-01-05 12:12:11 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 115845 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0156, wps=99.9, ups=0.46, wpb=108.3, bsz=40, num_updates=370, lr=3.99309e-06, gnorm=1.634, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=863
2023-01-05 12:12:34 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 115845 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0452, wps=100.1, ups=0.46, wpb=108.5, bsz=40, num_updates=380, lr=4.10101e-06, gnorm=1.431, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=886
2023-01-05 12:12:56 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 115845 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, vqa_score=0.0376, wps=100.3, ups=0.46, wpb=108.6, bsz=40, num_updates=390, lr=4.20894e-06, gnorm=1.708, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=909
2023-01-05 12:13:19 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 115845 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, vqa_score=0.0281, wps=102.1, ups=0.46, wpb=110.6, bsz=40, num_updates=400, lr=4.31686e-06, gnorm=1.605, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=931
2023-01-05 12:13:42 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0296, wps=99.4, ups=0.46, wpb=108.1, bsz=40, num_updates=410, lr=4.42478e-06, gnorm=1.537, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=954
2023-01-05 12:14:05 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 115845 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0323, wps=99.5, ups=0.46, wpb=108.4, bsz=40, num_updates=420, lr=4.5327e-06, gnorm=1.505, clip=100, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=977
2023-01-05 12:14:27 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 115845 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, vqa_score=0.0309, wps=102.3, ups=0.47, wpb=109.4, bsz=40, num_updates=430, lr=4.64062e-06, gnorm=1.752, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=999
2023-01-05 12:14:50 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 115845 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0051, wps=99.6, ups=0.46, wpb=108.8, bsz=40, num_updates=440, lr=4.74854e-06, gnorm=1.513, clip=100, loss_scale=128, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=1022
2023-01-05 12:15:13 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 115845 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0472, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=450, lr=4.85646e-06, gnorm=1.338, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1045
2023-01-05 12:15:36 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 115845 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, vqa_score=0.0329, wps=100.8, ups=0.47, wpb=108.3, bsz=40, num_updates=460, lr=4.96439e-06, gnorm=1.481, clip=100, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1068
2023-01-05 12:15:58 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 115845 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, vqa_score=0.0096, wps=101.4, ups=0.46, wpb=109.5, bsz=40, num_updates=470, lr=5.07231e-06, gnorm=1.23, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1090
2023-01-05 12:16:20 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 115845 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0538, wps=103.9, ups=0.47, wpb=110.5, bsz=40, num_updates=480, lr=5.18023e-06, gnorm=1.533, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1112
2023-01-05 12:16:43 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 115845 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, vqa_score=0.0242, wps=99.4, ups=0.46, wpb=108.7, bsz=40, num_updates=490, lr=5.28815e-06, gnorm=1.483, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1135
2023-01-05 12:17:06 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0266, wps=102.6, ups=0.47, wpb=109.9, bsz=40, num_updates=500, lr=5.39607e-06, gnorm=1.633, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1158
2023-01-05 12:17:28 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.058, wps=103.6, ups=0.47, wpb=109.7, bsz=40, num_updates=510, lr=5.50399e-06, gnorm=1.52, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1180
2023-01-05 12:17:51 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 115845 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0286, wps=98.9, ups=0.46, wpb=107.9, bsz=40, num_updates=520, lr=5.61191e-06, gnorm=1.473, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1203
2023-01-05 12:18:13 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 115845 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0199, wps=101.1, ups=0.47, wpb=108.5, bsz=40, num_updates=530, lr=5.71984e-06, gnorm=1.417, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1225
2023-01-05 12:18:36 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 115845 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0273, wps=103.1, ups=0.47, wpb=109.5, bsz=40, num_updates=540, lr=5.82776e-06, gnorm=1.363, clip=80, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1248
2023-01-05 12:18:59 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 115845 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0294, wps=99.8, ups=0.45, wpb=110.6, bsz=40, num_updates=550, lr=5.93568e-06, gnorm=1.445, clip=90, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=1271
2023-01-05 12:19:22 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 115845 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.051, wps=100.2, ups=0.46, wpb=109.3, bsz=40, num_updates=560, lr=6.0436e-06, gnorm=1.58, clip=100, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=1294
2023-01-05 12:19:44 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 115845 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0299, wps=103.2, ups=0.47, wpb=109.5, bsz=40, num_updates=570, lr=6.15152e-06, gnorm=1.301, clip=100, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1316
2023-01-05 12:20:07 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 115845 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0469, wps=101.5, ups=0.47, wpb=108.7, bsz=40, num_updates=580, lr=6.25944e-06, gnorm=1.317, clip=90, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=1339
2023-01-05 12:20:29 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 115845 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0198, wps=102.7, ups=0.47, wpb=109.4, bsz=40, num_updates=590, lr=6.36736e-06, gnorm=1.515, clip=100, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1361
2023-01-05 12:20:52 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0153, wps=99.6, ups=0.45, wpb=109.6, bsz=40, num_updates=600, lr=6.47529e-06, gnorm=1.27, clip=90, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=1384
2023-01-05 12:21:15 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 115845 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0443, wps=101.4, ups=0.47, wpb=108.7, bsz=40, num_updates=610, lr=6.58321e-06, gnorm=1.418, clip=100, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1407
2023-01-05 12:21:37 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 115845 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, vqa_score=0.0202, wps=103.4, ups=0.47, wpb=109.6, bsz=40, num_updates=620, lr=6.69113e-06, gnorm=1.309, clip=90, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1429
2023-01-05 12:21:59 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0253, wps=101.6, ups=0.46, wpb=109.9, bsz=40, num_updates=630, lr=6.79905e-06, gnorm=1.351, clip=90, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1451
2023-01-05 12:22:22 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0514, wps=102.9, ups=0.46, wpb=111, bsz=40, num_updates=640, lr=6.90697e-06, gnorm=1.46, clip=100, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=1474
2023-01-05 12:22:46 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0326, wps=98.9, ups=0.46, wpb=107.6, bsz=40, num_updates=650, lr=7.01489e-06, gnorm=1.457, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1497
2023-01-05 12:23:10 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 115845 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0254, wps=100, ups=0.46, wpb=109, bsz=40, num_updates=660, lr=7.12281e-06, gnorm=1.535, clip=100, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=1522
2023-01-05 12:23:32 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 115845 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0294, wps=103.6, ups=0.47, wpb=109.9, bsz=40, num_updates=670, lr=7.23074e-06, gnorm=1.208, clip=60, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1544
2023-01-05 12:23:55 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 115845 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0202, wps=101.4, ups=0.46, wpb=109.6, bsz=40, num_updates=680, lr=7.33866e-06, gnorm=1.3, clip=90, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=1567
2023-01-05 12:24:17 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0394, wps=101.9, ups=0.47, wpb=109.4, bsz=40, num_updates=690, lr=7.44658e-06, gnorm=1.367, clip=100, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1589
2023-01-05 12:24:40 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 115845 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0205, wps=101.3, ups=0.46, wpb=109.2, bsz=40, num_updates=700, lr=7.5545e-06, gnorm=1.475, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1612
2023-01-05 12:25:02 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0107, wps=103.7, ups=0.47, wpb=110.3, bsz=40, num_updates=710, lr=7.66242e-06, gnorm=1.263, clip=90, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1634
2023-01-05 12:25:24 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0306, wps=103.4, ups=0.47, wpb=109.2, bsz=40, num_updates=720, lr=7.77034e-06, gnorm=1.315, clip=100, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1656
2023-01-05 12:25:47 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 115845 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0324, wps=101.4, ups=0.46, wpb=110.5, bsz=40, num_updates=730, lr=7.87826e-06, gnorm=1.306, clip=80, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=1679
2023-01-05 12:26:10 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 115845 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, vqa_score=0.0151, wps=102.2, ups=0.47, wpb=109.5, bsz=40, num_updates=740, lr=7.98619e-06, gnorm=1.328, clip=90, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1701
2023-01-05 12:26:32 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 115845 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.044, wps=103.2, ups=0.47, wpb=110.4, bsz=40, num_updates=750, lr=8.09411e-06, gnorm=1.412, clip=100, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1724
2023-01-05 12:26:54 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0107, wps=100.3, ups=0.46, wpb=109.3, bsz=40, num_updates=760, lr=8.20203e-06, gnorm=1.148, clip=70, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=1747
2023-01-05 12:27:16 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 115845 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0259, wps=105, ups=0.47, wpb=111.5, bsz=40, num_updates=770, lr=8.30995e-06, gnorm=1.266, clip=90, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1769
2023-01-05 12:27:38 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0203, wps=100.2, ups=0.46, wpb=108.6, bsz=40, num_updates=780, lr=8.41787e-06, gnorm=1.352, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1791
2023-01-05 12:28:00 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 115845 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0359, wps=101.4, ups=0.46, wpb=109.5, bsz=40, num_updates=790, lr=8.52579e-06, gnorm=1.298, clip=80, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=1813
2023-01-05 12:28:22 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0294, wps=101, ups=0.47, wpb=108, bsz=40, num_updates=800, lr=8.63371e-06, gnorm=1.509, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1834
2023-01-05 12:28:44 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 115845 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0248, wps=101.9, ups=0.47, wpb=108.6, bsz=40, num_updates=810, lr=8.74164e-06, gnorm=1.56, clip=100, loss_scale=256, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=1856
2023-01-05 12:29:06 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 115845 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0201, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=820, lr=8.84956e-06, gnorm=1.342, clip=100, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=1878
2023-01-05 12:29:27 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 115845 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0153, wps=101.7, ups=0.47, wpb=107.8, bsz=40, num_updates=830, lr=8.95748e-06, gnorm=1.379, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1900
2023-01-05 12:29:49 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 115845 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.035, wps=100.5, ups=0.46, wpb=108.5, bsz=40, num_updates=840, lr=9.0654e-06, gnorm=1.177, clip=90, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=1922
2023-01-05 12:30:11 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0239, wps=101.8, ups=0.47, wpb=109.3, bsz=40, num_updates=850, lr=9.17332e-06, gnorm=1.26, clip=80, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1944
2023-01-05 12:30:33 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 115845 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0385, wps=102, ups=0.46, wpb=109.9, bsz=40, num_updates=860, lr=9.28124e-06, gnorm=1.316, clip=80, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=1966
2023-01-05 12:30:55 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 115845 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0246, wps=100.5, ups=0.46, wpb=108.2, bsz=40, num_updates=870, lr=9.38916e-06, gnorm=1.297, clip=80, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1988
2023-01-05 12:31:18 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0287, wps=100.8, ups=0.46, wpb=110.8, bsz=40, num_updates=880, lr=9.49709e-06, gnorm=1.302, clip=90, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=2010
2023-01-05 12:31:39 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0153, wps=104.1, ups=0.47, wpb=111.1, bsz=40, num_updates=890, lr=9.60501e-06, gnorm=1.288, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2032
2023-01-05 12:32:01 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 115845 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0154, wps=101.4, ups=0.47, wpb=108.3, bsz=40, num_updates=900, lr=9.71293e-06, gnorm=1.386, clip=100, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2054
2023-01-05 12:32:24 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 115845 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0381, wps=100.5, ups=0.46, wpb=108.9, bsz=40, num_updates=910, lr=9.82085e-06, gnorm=1.328, clip=90, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=2076
2023-01-05 12:32:46 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 115845 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0192, wps=98.2, ups=0.46, wpb=107.9, bsz=40, num_updates=920, lr=9.92877e-06, gnorm=1.621, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2099
2023-01-05 12:33:09 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 115845 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0265, wps=98.7, ups=0.46, wpb=107.7, bsz=40, num_updates=930, lr=1.00367e-05, gnorm=1.412, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2121
2023-01-05 12:33:31 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 115845 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0253, wps=99.6, ups=0.46, wpb=108.5, bsz=40, num_updates=940, lr=1.01446e-05, gnorm=1.459, clip=100, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=2143
2023-01-05 12:33:52 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 115845 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0343, wps=102.8, ups=0.47, wpb=108.8, bsz=40, num_updates=950, lr=1.02525e-05, gnorm=1.369, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2165
2023-01-05 12:34:14 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0197, wps=102.6, ups=0.47, wpb=109.3, bsz=40, num_updates=960, lr=1.03605e-05, gnorm=1.246, clip=80, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2187
2023-01-05 12:34:37 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0243, wps=98.1, ups=0.45, wpb=107.9, bsz=40, num_updates=970, lr=1.04684e-05, gnorm=1.13, clip=60, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=2209
2023-01-05 12:34:59 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0146, wps=101.7, ups=0.47, wpb=108.9, bsz=40, num_updates=980, lr=1.05763e-05, gnorm=1.312, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2232
2023-01-05 12:35:21 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 115845 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0377, wps=102.4, ups=0.47, wpb=109.5, bsz=40, num_updates=990, lr=1.06842e-05, gnorm=1.413, clip=90, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2254
2023-01-05 12:35:44 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 115845 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0296, wps=101.3, ups=0.47, wpb=107.8, bsz=40, num_updates=1000, lr=1.07921e-05, gnorm=1.398, clip=100, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=2276
2023-01-05 12:36:06 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 115845 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0242, wps=100.8, ups=0.46, wpb=108.4, bsz=40, num_updates=1010, lr=1.09001e-05, gnorm=1.403, clip=90, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=2298
2023-01-05 12:36:28 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 115845 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0201, wps=102.1, ups=0.46, wpb=110.2, bsz=40, num_updates=1020, lr=1.1008e-05, gnorm=1.269, clip=90, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=2320
2023-01-05 12:36:50 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 115845 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0383, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=1030, lr=1.11159e-05, gnorm=1.278, clip=90, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=2343
2023-01-05 12:37:14 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 115845 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0195, wps=100.1, ups=0.46, wpb=108.9, bsz=40, num_updates=1040, lr=1.12238e-05, gnorm=1.381, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2365
2023-01-05 12:37:36 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0202, wps=101.5, ups=0.46, wpb=109.4, bsz=40, num_updates=1050, lr=1.13318e-05, gnorm=1.32, clip=90, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=2388
2023-01-05 12:37:58 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0321, wps=103.2, ups=0.47, wpb=110.4, bsz=40, num_updates=1060, lr=1.14397e-05, gnorm=1.033, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2410
2023-01-05 12:38:19 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 115845 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0388, wps=102.5, ups=0.47, wpb=108.7, bsz=40, num_updates=1070, lr=1.15476e-05, gnorm=1.325, clip=100, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2432
2023-01-05 12:38:42 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0421, wps=101.4, ups=0.46, wpb=110.1, bsz=40, num_updates=1080, lr=1.16555e-05, gnorm=1.278, clip=90, loss_scale=512, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=2454
2023-01-05 12:39:04 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 115845 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0258, wps=102.9, ups=0.47, wpb=109.8, bsz=40, num_updates=1090, lr=1.17634e-05, gnorm=1.268, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2476
2023-01-05 12:39:26 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0335, wps=103.3, ups=0.47, wpb=110.1, bsz=40, num_updates=1100, lr=1.18714e-05, gnorm=1.229, clip=70, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2498
2023-01-05 12:39:48 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 115845 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0154, wps=102, ups=0.47, wpb=109, bsz=40, num_updates=1110, lr=1.19793e-05, gnorm=1.329, clip=100, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=2520
2023-01-05 12:40:10 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0048, wps=101.8, ups=0.47, wpb=108.2, bsz=40, num_updates=1120, lr=1.20872e-05, gnorm=1.347, clip=100, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2542
2023-01-05 12:40:32 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 115845 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.03, wps=100.2, ups=0.46, wpb=108.8, bsz=40, num_updates=1130, lr=1.21951e-05, gnorm=1.38, clip=100, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=2564
2023-01-05 12:40:54 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 115845 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0049, wps=101.1, ups=0.46, wpb=109.4, bsz=40, num_updates=1140, lr=1.2303e-05, gnorm=1.147, clip=70, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=2587
2023-01-05 12:41:17 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 115845 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0426, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=1150, lr=1.2411e-05, gnorm=1.239, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2609
2023-01-05 12:41:39 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 115845 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0327, wps=100.8, ups=0.47, wpb=108.3, bsz=40, num_updates=1160, lr=1.25189e-05, gnorm=1.282, clip=100, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2631
2023-01-05 12:42:01 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 115845 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0308, wps=101.2, ups=0.46, wpb=109.9, bsz=40, num_updates=1170, lr=1.26268e-05, gnorm=1.289, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2653
2023-01-05 12:42:24 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0333, wps=99.5, ups=0.46, wpb=108.8, bsz=40, num_updates=1180, lr=1.27347e-05, gnorm=1.37, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2676
2023-01-05 12:42:46 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 115845 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0242, wps=100.1, ups=0.46, wpb=109.1, bsz=40, num_updates=1190, lr=1.28427e-05, gnorm=1.17, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2698
2023-01-05 12:43:08 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 115845 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0234, wps=102.4, ups=0.47, wpb=107.9, bsz=40, num_updates=1200, lr=1.29506e-05, gnorm=1.198, clip=100, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=2720
2023-01-05 12:43:31 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 115845 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0431, wps=97.1, ups=0.45, wpb=108.4, bsz=40, num_updates=1210, lr=1.30585e-05, gnorm=1.342, clip=100, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=2743
2023-01-05 12:43:53 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0254, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=1220, lr=1.31664e-05, gnorm=1.235, clip=90, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=2765
2023-01-05 12:44:16 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 115845 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0481, wps=99.3, ups=0.46, wpb=108.2, bsz=40, num_updates=1230, lr=1.32743e-05, gnorm=1.408, clip=90, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=2788
2023-01-05 12:44:38 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0103, wps=101.8, ups=0.47, wpb=108.5, bsz=40, num_updates=1240, lr=1.33823e-05, gnorm=1.21, clip=70, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=2810
2023-01-05 12:45:00 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 115845 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0156, wps=100.5, ups=0.46, wpb=109.3, bsz=40, num_updates=1250, lr=1.34902e-05, gnorm=1.222, clip=70, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2832
2023-01-05 12:45:22 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0106, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=1260, lr=1.35981e-05, gnorm=1.121, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2855
2023-01-05 12:45:44 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0051, wps=101.8, ups=0.47, wpb=108.3, bsz=40, num_updates=1270, lr=1.3706e-05, gnorm=1.189, clip=90, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=2877
2023-01-05 12:46:07 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 115845 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0207, wps=101.9, ups=0.46, wpb=110, bsz=40, num_updates=1280, lr=1.38139e-05, gnorm=1.131, clip=70, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=2899
2023-01-05 12:46:29 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 115845 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0211, wps=100, ups=0.46, wpb=108.7, bsz=40, num_updates=1290, lr=1.39219e-05, gnorm=1.439, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2921
2023-01-05 12:46:51 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.01, wps=105.5, ups=0.48, wpb=109.3, bsz=40, num_updates=1300, lr=1.40298e-05, gnorm=1.207, clip=80, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2943
2023-01-05 12:47:13 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 115845 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0345, wps=103.1, ups=0.47, wpb=109.4, bsz=40, num_updates=1310, lr=1.41377e-05, gnorm=1.286, clip=90, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2965
2023-01-05 12:47:35 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0303, wps=101.7, ups=0.46, wpb=110.2, bsz=40, num_updates=1320, lr=1.42456e-05, gnorm=1.188, clip=90, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=2987
2023-01-05 12:47:57 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0183, wps=103.4, ups=0.48, wpb=108.3, bsz=40, num_updates=1330, lr=1.43536e-05, gnorm=1.292, clip=90, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=3009
2023-01-05 12:48:19 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 115845 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0237, wps=100.6, ups=0.47, wpb=108.1, bsz=40, num_updates=1340, lr=1.44615e-05, gnorm=1.138, clip=70, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3031
2023-01-05 12:48:41 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 115845 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0145, wps=99.1, ups=0.46, wpb=107.3, bsz=40, num_updates=1350, lr=1.45694e-05, gnorm=1.285, clip=90, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=3053
2023-01-05 12:49:03 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 115845 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.025, wps=101.6, ups=0.47, wpb=108, bsz=40, num_updates=1360, lr=1.46773e-05, gnorm=1.444, clip=100, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3075
2023-01-05 12:49:25 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0206, wps=102.3, ups=0.47, wpb=109.1, bsz=40, num_updates=1370, lr=1.47852e-05, gnorm=1.382, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3097
2023-01-05 12:49:48 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 115845 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0097, wps=97.8, ups=0.45, wpb=108.7, bsz=40, num_updates=1380, lr=1.48932e-05, gnorm=1.151, clip=70, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3120
2023-01-05 12:50:10 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0273, wps=102.8, ups=0.47, wpb=109.4, bsz=40, num_updates=1390, lr=1.50011e-05, gnorm=1.258, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3142
2023-01-05 12:50:32 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 115845 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0185, wps=101.9, ups=0.47, wpb=108.8, bsz=40, num_updates=1400, lr=1.5109e-05, gnorm=1.151, clip=90, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3164
2023-01-05 12:50:54 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0093, wps=100.4, ups=0.46, wpb=108.6, bsz=40, num_updates=1410, lr=1.52169e-05, gnorm=1.257, clip=80, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3187
2023-01-05 12:51:17 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 115845 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0291, wps=99.6, ups=0.46, wpb=108.5, bsz=40, num_updates=1420, lr=1.53248e-05, gnorm=1.375, clip=90, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3209
2023-01-05 12:51:39 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0155, wps=101, ups=0.47, wpb=108.4, bsz=40, num_updates=1430, lr=1.54328e-05, gnorm=1.346, clip=90, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=3231
2023-01-05 12:52:01 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 115845 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0419, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=1440, lr=1.55407e-05, gnorm=1.145, clip=70, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3254
2023-01-05 12:52:23 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0211, wps=104.8, ups=0.48, wpb=109.1, bsz=40, num_updates=1450, lr=1.56486e-05, gnorm=1.199, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3275
2023-01-05 12:52:45 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 115845 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0317, wps=102.7, ups=0.47, wpb=109.9, bsz=40, num_updates=1460, lr=1.57565e-05, gnorm=1.114, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=3297
2023-01-05 12:53:07 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 115845 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0347, wps=103.4, ups=0.47, wpb=110.7, bsz=40, num_updates=1470, lr=1.58645e-05, gnorm=1.132, clip=70, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=3319
2023-01-05 12:53:29 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 115845 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0293, wps=102.5, ups=0.47, wpb=109.8, bsz=40, num_updates=1480, lr=1.59724e-05, gnorm=1.318, clip=80, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=3342
2023-01-05 12:53:51 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 115845 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0187, wps=102.3, ups=0.47, wpb=109.4, bsz=40, num_updates=1490, lr=1.60803e-05, gnorm=1.294, clip=90, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=3364
2023-01-05 12:54:14 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0235, wps=99.1, ups=0.45, wpb=108.9, bsz=40, num_updates=1500, lr=1.61882e-05, gnorm=1.242, clip=70, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3386
2023-01-05 12:54:36 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 115845 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.033, wps=98.2, ups=0.46, wpb=107.7, bsz=40, num_updates=1510, lr=1.62961e-05, gnorm=1.31, clip=80, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3409
2023-01-05 12:54:59 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0193, wps=100.9, ups=0.47, wpb=107.9, bsz=40, num_updates=1520, lr=1.64041e-05, gnorm=1.166, clip=80, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3431
2023-01-05 12:55:21 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0251, wps=102.1, ups=0.47, wpb=109.7, bsz=40, num_updates=1530, lr=1.6512e-05, gnorm=1.103, clip=70, loss_scale=512, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=3453
2023-01-05 12:55:43 - progress_bar.py[line:274] - INFO: epoch 001:   1540 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.033, wps=100.6, ups=0.46, wpb=109.9, bsz=40, num_updates=1540, lr=1.66199e-05, gnorm=1.264, clip=100, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3476
2023-01-05 12:56:05 - progress_bar.py[line:274] - INFO: epoch 001:   1550 / 115845 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0209, wps=102.2, ups=0.47, wpb=109, bsz=40, num_updates=1550, lr=1.67278e-05, gnorm=1.181, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3498
2023-01-05 12:56:27 - progress_bar.py[line:274] - INFO: epoch 001:   1560 / 115845 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0097, wps=100.5, ups=0.46, wpb=108.8, bsz=40, num_updates=1560, lr=1.68357e-05, gnorm=1.229, clip=70, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3520
2023-01-05 12:56:49 - progress_bar.py[line:274] - INFO: epoch 001:   1570 / 115845 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.05, wps=101.3, ups=0.47, wpb=108.5, bsz=40, num_updates=1570, lr=1.69437e-05, gnorm=1.14, clip=80, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3542
2023-01-05 12:57:11 - progress_bar.py[line:274] - INFO: epoch 001:   1580 / 115845 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0207, wps=104, ups=0.47, wpb=110.1, bsz=40, num_updates=1580, lr=1.70516e-05, gnorm=1.138, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3564
2023-01-05 12:57:34 - progress_bar.py[line:274] - INFO: epoch 001:   1590 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0105, wps=99.3, ups=0.46, wpb=108.7, bsz=40, num_updates=1590, lr=1.71595e-05, gnorm=0.998, clip=50, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3586
2023-01-05 12:57:56 - progress_bar.py[line:274] - INFO: epoch 001:   1600 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0335, wps=98.3, ups=0.46, wpb=107, bsz=40, num_updates=1600, lr=1.72674e-05, gnorm=1.438, clip=100, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3609
2023-01-05 12:58:18 - progress_bar.py[line:274] - INFO: epoch 001:   1610 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0095, wps=100.8, ups=0.47, wpb=107.3, bsz=40, num_updates=1610, lr=1.73754e-05, gnorm=1.237, clip=90, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3631
2023-01-05 12:58:40 - progress_bar.py[line:274] - INFO: epoch 001:   1620 / 115845 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0306, wps=101.6, ups=0.46, wpb=109.4, bsz=40, num_updates=1620, lr=1.74833e-05, gnorm=1.126, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3653
2023-01-05 12:59:02 - progress_bar.py[line:274] - INFO: epoch 001:   1630 / 115845 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0363, wps=104, ups=0.48, wpb=108.1, bsz=40, num_updates=1630, lr=1.75912e-05, gnorm=1.149, clip=80, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3674
2023-01-05 12:59:24 - progress_bar.py[line:274] - INFO: epoch 001:   1640 / 115845 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0198, wps=101.3, ups=0.46, wpb=108.9, bsz=40, num_updates=1640, lr=1.76991e-05, gnorm=1.163, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3696
2023-01-05 12:59:46 - progress_bar.py[line:274] - INFO: epoch 001:   1650 / 115845 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0441, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=1650, lr=1.7807e-05, gnorm=1.131, clip=60, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3719
2023-01-05 13:00:08 - progress_bar.py[line:274] - INFO: epoch 001:   1660 / 115845 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0251, wps=102, ups=0.47, wpb=109.3, bsz=40, num_updates=1660, lr=1.7915e-05, gnorm=1.127, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3740
2023-01-05 13:00:16 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-05 13:00:31 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=109.476, nsentences=40, sample_size=109.476, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0327, wps=98.8, ups=0.43, wpb=109.5, bsz=40, num_updates=1670, lr=1.80229e-05, gnorm=1.199, clip=90, loss_scale=512, train_wall=23, gb_free=9.7, ema_decay=0.9999, wall=3764
2023-01-05 13:00:53 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 115845 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0404, wps=103.9, ups=0.47, wpb=110.1, bsz=40, num_updates=1680, lr=1.81308e-05, gnorm=1.05, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3786
2023-01-05 13:01:14 - progress_bar.py[line:274] - INFO: epoch 001:   1691 / 115845 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0291, wps=104.5, ups=0.48, wpb=109.7, bsz=40, num_updates=1690, lr=1.82387e-05, gnorm=1.103, clip=70, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=3807
2023-01-05 13:01:36 - progress_bar.py[line:274] - INFO: epoch 001:   1701 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0113, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=1700, lr=1.83466e-05, gnorm=1.094, clip=60, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3829
2023-01-05 13:01:58 - progress_bar.py[line:274] - INFO: epoch 001:   1711 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0256, wps=100.3, ups=0.46, wpb=109, bsz=40, num_updates=1710, lr=1.84546e-05, gnorm=1.238, clip=100, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3851
2023-01-05 13:02:20 - progress_bar.py[line:274] - INFO: epoch 001:   1721 / 115845 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0567, wps=101.4, ups=0.46, wpb=110, bsz=40, num_updates=1720, lr=1.85625e-05, gnorm=0.996, clip=50, loss_scale=512, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=3873
2023-01-05 13:02:43 - progress_bar.py[line:274] - INFO: epoch 001:   1731 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0273, wps=100.1, ups=0.46, wpb=109.4, bsz=40, num_updates=1730, lr=1.86704e-05, gnorm=1.059, clip=30, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=3895
2023-01-05 13:03:05 - progress_bar.py[line:274] - INFO: epoch 001:   1741 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0201, wps=100.5, ups=0.46, wpb=108.6, bsz=40, num_updates=1740, lr=1.87783e-05, gnorm=1.316, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3917
2023-01-05 13:03:27 - progress_bar.py[line:274] - INFO: epoch 001:   1751 / 115845 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.026, wps=99.3, ups=0.45, wpb=109.1, bsz=40, num_updates=1750, lr=1.88863e-05, gnorm=1.055, clip=40, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3940
2023-01-05 13:03:50 - progress_bar.py[line:274] - INFO: epoch 001:   1761 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0192, wps=98.6, ups=0.45, wpb=108.9, bsz=40, num_updates=1760, lr=1.89942e-05, gnorm=1.055, clip=60, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=3962
2023-01-05 13:04:11 - progress_bar.py[line:274] - INFO: epoch 001:   1771 / 115845 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0148, wps=103.7, ups=0.48, wpb=108.7, bsz=40, num_updates=1770, lr=1.91021e-05, gnorm=1.199, clip=80, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3984
2023-01-05 13:04:33 - progress_bar.py[line:274] - INFO: epoch 001:   1781 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0155, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=1780, lr=1.921e-05, gnorm=1.136, clip=60, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=4006
2023-01-05 13:04:55 - progress_bar.py[line:274] - INFO: epoch 001:   1791 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0326, wps=102.4, ups=0.46, wpb=110.5, bsz=40, num_updates=1790, lr=1.93179e-05, gnorm=1.085, clip=80, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4027
2023-01-05 13:05:16 - progress_bar.py[line:274] - INFO: epoch 001:   1801 / 115845 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.035, wps=101, ups=0.46, wpb=108.8, bsz=40, num_updates=1800, lr=1.94259e-05, gnorm=1.109, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4049
2023-01-05 13:05:38 - progress_bar.py[line:274] - INFO: epoch 001:   1811 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0196, wps=102.8, ups=0.47, wpb=108.7, bsz=40, num_updates=1810, lr=1.95338e-05, gnorm=1.115, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4071
2023-01-05 13:05:59 - progress_bar.py[line:274] - INFO: epoch 001:   1821 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0433, wps=103, ups=0.47, wpb=110, bsz=40, num_updates=1820, lr=1.96417e-05, gnorm=1.07, clip=70, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=4092
2023-01-05 13:06:22 - progress_bar.py[line:274] - INFO: epoch 001:   1831 / 115845 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0243, wps=98.2, ups=0.46, wpb=107.8, bsz=40, num_updates=1830, lr=1.97496e-05, gnorm=1.131, clip=60, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=4114
2023-01-05 13:06:43 - progress_bar.py[line:274] - INFO: epoch 001:   1841 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0242, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=1840, lr=1.98575e-05, gnorm=1.226, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4136
2023-01-05 13:07:06 - progress_bar.py[line:274] - INFO: epoch 001:   1851 / 115845 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0249, wps=98.6, ups=0.45, wpb=108.6, bsz=40, num_updates=1850, lr=1.99655e-05, gnorm=1.152, clip=80, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4158
2023-01-05 13:07:28 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 115845 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.041, wps=100.3, ups=0.46, wpb=108.6, bsz=40, num_updates=1860, lr=2.00734e-05, gnorm=1.168, clip=60, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4180
2023-01-05 13:07:49 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 115845 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0145, wps=99.8, ups=0.47, wpb=107.3, bsz=40, num_updates=1870, lr=2.01813e-05, gnorm=1.095, clip=70, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=4202
2023-01-05 13:08:11 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 115845 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0291, wps=100.2, ups=0.46, wpb=108.2, bsz=40, num_updates=1880, lr=2.02892e-05, gnorm=1.127, clip=70, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=4224
2023-01-05 13:08:33 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 115845 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.034, wps=104, ups=0.47, wpb=109.9, bsz=40, num_updates=1890, lr=2.03972e-05, gnorm=1.161, clip=80, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4245
2023-01-05 13:08:54 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 115845 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0243, wps=101.8, ups=0.46, wpb=109.7, bsz=40, num_updates=1900, lr=2.05051e-05, gnorm=1.171, clip=80, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4267
2023-01-05 13:09:16 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0226, wps=102.6, ups=0.46, wpb=111.5, bsz=40, num_updates=1910, lr=2.0613e-05, gnorm=1.173, clip=80, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=4289
2023-01-05 13:09:37 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 115845 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0151, wps=105.1, ups=0.48, wpb=109.2, bsz=40, num_updates=1920, lr=2.07209e-05, gnorm=1.06, clip=70, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=4310
2023-01-05 13:09:59 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0191, wps=99.3, ups=0.46, wpb=108.2, bsz=40, num_updates=1930, lr=2.08288e-05, gnorm=1.291, clip=100, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=4332
2023-01-05 13:10:21 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 115845 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0102, wps=102.8, ups=0.47, wpb=109.6, bsz=40, num_updates=1940, lr=2.09368e-05, gnorm=1.147, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4354
2023-01-05 13:10:43 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0237, wps=99.7, ups=0.46, wpb=109.5, bsz=40, num_updates=1950, lr=2.10447e-05, gnorm=1.021, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4376
2023-01-05 13:11:04 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 115845 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0191, wps=103, ups=0.47, wpb=109.1, bsz=40, num_updates=1960, lr=2.11526e-05, gnorm=1.19, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4397
2023-01-05 13:11:27 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 115845 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0243, wps=98.1, ups=0.45, wpb=108.1, bsz=40, num_updates=1970, lr=2.12605e-05, gnorm=1.125, clip=70, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=4419
2023-01-05 13:11:49 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 115845 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0208, wps=100, ups=0.46, wpb=108.4, bsz=40, num_updates=1980, lr=2.13684e-05, gnorm=1.062, clip=60, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4441
2023-01-05 13:12:10 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0231, wps=100.3, ups=0.46, wpb=107.9, bsz=40, num_updates=1990, lr=2.14764e-05, gnorm=1.169, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4463
2023-01-05 13:12:32 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 115845 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0198, wps=101.3, ups=0.47, wpb=108.7, bsz=40, num_updates=2000, lr=2.15843e-05, gnorm=1.119, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4485
2023-01-05 13:12:32 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-05 13:12:32 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-01-05 13:12:33 - train.py[line:549] - INFO: 0 / 4988
2023-01-05 13:12:33 - train.py[line:551] - INFO: load:1.00 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-05 13:15:07 - train.py[line:549] - INFO: 200 / 4988
2023-01-05 13:15:07 - train.py[line:551] - INFO: load:1.02 valid_run:153.96 task_valid:150.43 collect_output:2.39
2023-01-05 13:17:37 - train.py[line:549] - INFO: 400 / 4988
2023-01-05 13:17:37 - train.py[line:551] - INFO: load:1.05 valid_run:303.77 task_valid:294.50 collect_output:7.06
2023-01-05 13:20:11 - train.py[line:549] - INFO: 600 / 4988
2023-01-05 13:20:11 - train.py[line:551] - INFO: load:1.07 valid_run:457.29 task_valid:438.72 collect_output:15.27
2023-01-05 13:22:41 - train.py[line:549] - INFO: 800 / 4988
2023-01-05 13:22:41 - train.py[line:551] - INFO: load:1.10 valid_run:607.35 task_valid:584.53 collect_output:18.47
2023-01-05 13:25:15 - train.py[line:549] - INFO: 1000 / 4988
2023-01-05 13:25:15 - train.py[line:551] - INFO: load:1.12 valid_run:760.95 task_valid:733.13 collect_output:22.41
2023-01-05 13:27:48 - train.py[line:549] - INFO: 1200 / 4988
2023-01-05 13:27:49 - train.py[line:551] - INFO: load:1.15 valid_run:913.93 task_valid:879.62 collect_output:27.83
2023-01-05 13:30:23 - train.py[line:549] - INFO: 1400 / 4988
2023-01-05 13:30:23 - train.py[line:551] - INFO: load:1.18 valid_run:1068.46 task_valid:1026.58 collect_output:34.32
2023-01-05 13:32:56 - train.py[line:549] - INFO: 1600 / 4988
2023-01-05 13:32:56 - train.py[line:551] - INFO: load:1.20 valid_run:1220.85 task_valid:1168.56 collect_output:43.67
2023-01-05 13:35:27 - train.py[line:549] - INFO: 1800 / 4988
2023-01-05 13:35:27 - train.py[line:551] - INFO: load:1.23 valid_run:1371.68 task_valid:1314.28 collect_output:47.74
2023-01-05 13:37:57 - train.py[line:549] - INFO: 2000 / 4988
2023-01-05 13:37:57 - train.py[line:551] - INFO: load:1.25 valid_run:1521.21 task_valid:1458.28 collect_output:52.23
2023-01-05 13:40:28 - train.py[line:549] - INFO: 2200 / 4988
2023-01-05 13:40:28 - train.py[line:551] - INFO: load:1.28 valid_run:1671.98 task_valid:1603.99 collect_output:56.23
2023-01-05 13:42:59 - train.py[line:549] - INFO: 2400 / 4988
2023-01-05 13:42:59 - train.py[line:551] - INFO: load:1.31 valid_run:1822.93 task_valid:1749.77 collect_output:60.36
2023-01-05 13:45:31 - train.py[line:549] - INFO: 2600 / 4988
2023-01-05 13:45:31 - train.py[line:551] - INFO: load:1.33 valid_run:1974.20 task_valid:1892.66 collect_output:67.67
2023-01-05 13:48:03 - train.py[line:549] - INFO: 2800 / 4988
2023-01-05 13:48:03 - train.py[line:551] - INFO: load:1.36 valid_run:2126.03 task_valid:2039.13 collect_output:71.97
2023-01-05 13:50:34 - train.py[line:549] - INFO: 3000 / 4988
2023-01-05 13:50:34 - train.py[line:551] - INFO: load:1.39 valid_run:2277.16 task_valid:2186.47 collect_output:74.70
2023-01-05 13:53:06 - train.py[line:549] - INFO: 3200 / 4988
2023-01-05 13:53:06 - train.py[line:551] - INFO: load:1.41 valid_run:2428.25 task_valid:2331.49 collect_output:79.70
2023-01-05 13:55:39 - train.py[line:549] - INFO: 3400 / 4988
2023-01-05 13:55:39 - train.py[line:551] - INFO: load:1.44 valid_run:2581.07 task_valid:2477.98 collect_output:84.96
2023-01-05 13:58:10 - train.py[line:549] - INFO: 3600 / 4988
2023-01-05 13:58:11 - train.py[line:551] - INFO: load:1.46 valid_run:2732.64 task_valid:2625.66 collect_output:87.81
2023-01-05 14:00:40 - train.py[line:549] - INFO: 3800 / 4988
2023-01-05 14:00:40 - train.py[line:551] - INFO: load:1.49 valid_run:2882.16 task_valid:2767.98 collect_output:93.95
2023-01-05 14:03:12 - train.py[line:549] - INFO: 4000 / 4988
2023-01-05 14:03:12 - train.py[line:551] - INFO: load:1.52 valid_run:3033.42 task_valid:2913.69 collect_output:98.44
2023-01-05 14:05:45 - train.py[line:549] - INFO: 4200 / 4988
2023-01-05 14:05:45 - train.py[line:551] - INFO: load:1.54 valid_run:3186.61 task_valid:3059.32 collect_output:104.93
2023-01-05 14:08:16 - train.py[line:549] - INFO: 4400 / 4988
2023-01-05 14:08:16 - train.py[line:551] - INFO: load:1.57 valid_run:3336.96 task_valid:3204.80 collect_output:108.75
2023-01-05 14:10:48 - train.py[line:549] - INFO: 4600 / 4988
2023-01-05 14:10:48 - train.py[line:551] - INFO: load:1.60 valid_run:3488.95 task_valid:3351.69 collect_output:112.81
2023-01-05 14:13:20 - train.py[line:549] - INFO: 4800 / 4988
2023-01-05 14:13:20 - train.py[line:551] - INFO: load:1.62 valid_run:3641.22 task_valid:3498.88 collect_output:116.86

====================================================================================================
SGG eval:     R @ 50: 0.2783;     R @ 100: 0.3453;     R @ 500: 0.4070;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1250;    mR @ 100: 0.1788;    mR @ 500: 0.2215;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0439) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1667) (playing:0.0000) (riding:0.3843) (says:0.0000) (sitting on:0.4221) (standing on:0.5183) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2783;     R @ 100: 0.3453;     R @ 500: 0.4070;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1250;    mR @ 100: 0.1788;    mR @ 500: 0.2215;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0439) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1667) (playing:0.0000) (riding:0.3843) (says:0.0000) (sitting on:0.4221) (standing on:0.5183) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-01-05 14:15:52 - train.py[line:487] - INFO: 0.34526666666666667
2023-01-05 14:15:52 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-05 14:15:52 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.318 | loss_v1 0 | loss_v2 0 | nll_loss 0.161 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.345267 | ppl 1.12 | vqa_score 0.1779 | wps 118.1 | wpb 89.9 | bsz 30 | num_updates 2000
2023-01-05 14:15:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2023-01-05 14:15:52 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_2000.pt
2023-01-05 14:16:39 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_2000.pt
2023-01-05 14:19:57 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.34526666666666667) (writing took 244.44575872272253 seconds)
2023-01-05 14:20:19 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0099, wps=0.5, ups=0, wpb=108.2, bsz=40, num_updates=2010, lr=2.16922e-05, gnorm=1.047, clip=50, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=8551
2023-01-05 14:20:41 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0267, wps=100.7, ups=0.46, wpb=110, bsz=40, num_updates=2020, lr=2.18001e-05, gnorm=1.116, clip=70, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8573
2023-01-05 14:21:03 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 115845 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0193, wps=101.6, ups=0.47, wpb=108.4, bsz=40, num_updates=2030, lr=2.19081e-05, gnorm=1.038, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8595
2023-01-05 14:21:25 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0169, wps=102.8, ups=0.47, wpb=110.2, bsz=40, num_updates=2040, lr=2.2016e-05, gnorm=1.171, clip=90, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=8618
2023-01-05 14:21:47 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0222, wps=103.3, ups=0.47, wpb=111, bsz=40, num_updates=2050, lr=2.21239e-05, gnorm=1.077, clip=60, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=8640
2023-01-05 14:22:09 - progress_bar.py[line:274] - INFO: epoch 001:   2061 / 115845 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0244, wps=103.1, ups=0.47, wpb=110, bsz=40, num_updates=2060, lr=2.22318e-05, gnorm=1.096, clip=60, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=8661
2023-01-05 14:22:32 - progress_bar.py[line:274] - INFO: epoch 001:   2071 / 115845 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0287, wps=97.6, ups=0.45, wpb=108.8, bsz=40, num_updates=2070, lr=2.23397e-05, gnorm=1.08, clip=70, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8684
2023-01-05 14:22:54 - progress_bar.py[line:274] - INFO: epoch 001:   2081 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0376, wps=101.5, ups=0.46, wpb=109.8, bsz=40, num_updates=2080, lr=2.24477e-05, gnorm=1.079, clip=50, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8707
2023-01-05 14:23:16 - progress_bar.py[line:274] - INFO: epoch 001:   2091 / 115845 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0425, wps=100.4, ups=0.46, wpb=109.2, bsz=40, num_updates=2090, lr=2.25556e-05, gnorm=1.039, clip=60, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8729
2023-01-05 14:23:38 - progress_bar.py[line:274] - INFO: epoch 001:   2101 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0093, wps=103.9, ups=0.48, wpb=108, bsz=40, num_updates=2100, lr=2.26635e-05, gnorm=1.157, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8750
2023-01-05 14:24:00 - progress_bar.py[line:274] - INFO: epoch 001:   2111 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0366, wps=102.5, ups=0.47, wpb=108.9, bsz=40, num_updates=2110, lr=2.27714e-05, gnorm=0.975, clip=40, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=8772
2023-01-05 14:24:22 - progress_bar.py[line:274] - INFO: epoch 001:   2121 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0253, wps=102.1, ups=0.47, wpb=108.4, bsz=40, num_updates=2120, lr=2.28793e-05, gnorm=1.055, clip=60, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=8794
2023-01-05 14:24:44 - progress_bar.py[line:274] - INFO: epoch 001:   2131 / 115845 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0214, wps=101, ups=0.46, wpb=110.1, bsz=40, num_updates=2130, lr=2.29873e-05, gnorm=1.041, clip=60, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8816
2023-01-05 14:25:06 - progress_bar.py[line:274] - INFO: epoch 001:   2141 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0215, wps=101, ups=0.46, wpb=109, bsz=40, num_updates=2140, lr=2.30952e-05, gnorm=1.03, clip=60, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8838
2023-01-05 14:25:28 - progress_bar.py[line:274] - INFO: epoch 001:   2151 / 115845 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=106.7, nsentences=40, sample_size=106.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0185, wps=99.3, ups=0.47, wpb=106.7, bsz=40, num_updates=2150, lr=2.32031e-05, gnorm=1.009, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8861
2023-01-05 14:25:50 - progress_bar.py[line:274] - INFO: epoch 001:   2161 / 115845 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0248, wps=102.3, ups=0.47, wpb=108.6, bsz=40, num_updates=2160, lr=2.3311e-05, gnorm=1.036, clip=60, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=8882
2023-01-05 14:26:12 - progress_bar.py[line:274] - INFO: epoch 001:   2171 / 115845 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0191, wps=102.1, ups=0.47, wpb=108.4, bsz=40, num_updates=2170, lr=2.3419e-05, gnorm=0.962, clip=40, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=8904
2023-01-05 14:26:34 - progress_bar.py[line:274] - INFO: epoch 001:   2181 / 115845 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0144, wps=100.3, ups=0.46, wpb=108.6, bsz=40, num_updates=2180, lr=2.35269e-05, gnorm=1.143, clip=40, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8926
2023-01-05 14:26:56 - progress_bar.py[line:274] - INFO: epoch 001:   2191 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0239, wps=99.9, ups=0.46, wpb=107.8, bsz=40, num_updates=2190, lr=2.36348e-05, gnorm=1.158, clip=70, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8948
2023-01-05 14:27:00 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-05 14:27:20 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 115845 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=110.048, nsentences=40, sample_size=110.048, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0271, wps=97.2, ups=0.42, wpb=110, bsz=40, num_updates=2200, lr=2.37427e-05, gnorm=1.113, clip=70, loss_scale=512, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=8973
2023-01-05 14:27:43 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0246, wps=101.5, ups=0.46, wpb=109.7, bsz=40, num_updates=2210, lr=2.38506e-05, gnorm=0.941, clip=30, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8995
2023-01-05 14:28:04 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0226, wps=101, ups=0.47, wpb=107.6, bsz=40, num_updates=2220, lr=2.39586e-05, gnorm=0.948, clip=40, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=9017
2023-01-05 14:28:26 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 115845 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0205, wps=101.7, ups=0.47, wpb=109, bsz=40, num_updates=2230, lr=2.40665e-05, gnorm=1.298, clip=100, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=9039
2023-01-05 14:28:49 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 115845 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0347, wps=100.8, ups=0.46, wpb=110, bsz=40, num_updates=2240, lr=2.41744e-05, gnorm=1.004, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9061
2023-01-05 14:29:11 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0049, wps=100.3, ups=0.47, wpb=107.6, bsz=40, num_updates=2250, lr=2.42823e-05, gnorm=1.074, clip=70, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=9083
2023-01-05 14:29:33 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0343, wps=100.3, ups=0.46, wpb=108.1, bsz=40, num_updates=2260, lr=2.43902e-05, gnorm=1.196, clip=60, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=9105
2023-01-05 14:29:56 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.005, wps=98.8, ups=0.46, wpb=108.5, bsz=40, num_updates=2270, lr=2.44982e-05, gnorm=1.169, clip=70, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9128
2023-01-05 14:30:18 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0254, wps=101.7, ups=0.47, wpb=109.1, bsz=40, num_updates=2280, lr=2.46061e-05, gnorm=0.95, clip=40, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9150
2023-01-05 14:30:40 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0314, wps=100.9, ups=0.46, wpb=109.3, bsz=40, num_updates=2290, lr=2.4714e-05, gnorm=0.924, clip=40, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9173
2023-01-05 14:31:03 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 115845 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0196, wps=99.2, ups=0.46, wpb=108, bsz=40, num_updates=2300, lr=2.48219e-05, gnorm=1.034, clip=50, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9195
2023-01-05 14:31:25 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0508, wps=99.1, ups=0.46, wpb=108.7, bsz=40, num_updates=2310, lr=2.49299e-05, gnorm=1.053, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9218
2023-01-05 14:31:47 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 115845 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0335, wps=101.6, ups=0.47, wpb=109, bsz=40, num_updates=2320, lr=2.50378e-05, gnorm=1.086, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=9240
2023-01-05 14:32:09 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0144, wps=100.1, ups=0.46, wpb=107.9, bsz=40, num_updates=2330, lr=2.51457e-05, gnorm=1.038, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9262
2023-01-05 14:32:32 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 115845 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.029, wps=100.8, ups=0.47, wpb=108.3, bsz=40, num_updates=2340, lr=2.52536e-05, gnorm=1.038, clip=70, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=9284
2023-01-05 14:32:54 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 115845 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0242, wps=101.5, ups=0.46, wpb=109.6, bsz=40, num_updates=2350, lr=2.53615e-05, gnorm=1.088, clip=50, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=9306
2023-01-05 14:33:16 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0273, wps=105, ups=0.47, wpb=111.2, bsz=40, num_updates=2360, lr=2.54695e-05, gnorm=0.92, clip=30, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=9328
2023-01-05 14:33:38 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 115845 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0273, wps=100.6, ups=0.46, wpb=109.5, bsz=40, num_updates=2370, lr=2.55774e-05, gnorm=1.017, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9350
2023-01-05 14:34:00 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0345, wps=102.4, ups=0.47, wpb=108.5, bsz=40, num_updates=2380, lr=2.56853e-05, gnorm=0.975, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9372
2023-01-05 14:34:22 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0198, wps=100, ups=0.46, wpb=108.7, bsz=40, num_updates=2390, lr=2.57932e-05, gnorm=0.899, clip=30, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=9395
2023-01-05 14:34:44 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0153, wps=102.2, ups=0.47, wpb=108.4, bsz=40, num_updates=2400, lr=2.59011e-05, gnorm=1.018, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9416
2023-01-05 14:35:06 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0457, wps=100.9, ups=0.46, wpb=108.6, bsz=40, num_updates=2410, lr=2.60091e-05, gnorm=0.994, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9439
2023-01-05 14:35:28 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 115845 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0299, wps=103.1, ups=0.47, wpb=109.7, bsz=40, num_updates=2420, lr=2.6117e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=9460
2023-01-05 14:35:50 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 115845 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0139, wps=99.7, ups=0.47, wpb=106.5, bsz=40, num_updates=2430, lr=2.62249e-05, gnorm=0.92, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9483
2023-01-05 14:36:12 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0338, wps=102.5, ups=0.47, wpb=109.3, bsz=40, num_updates=2440, lr=2.63328e-05, gnorm=1.112, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9504
2023-01-05 14:36:34 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0471, wps=103.2, ups=0.47, wpb=110.4, bsz=40, num_updates=2450, lr=2.64408e-05, gnorm=1.032, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9527
2023-01-05 14:36:56 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 115845 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0312, wps=101.4, ups=0.46, wpb=109.4, bsz=40, num_updates=2460, lr=2.65487e-05, gnorm=1.042, clip=70, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=9548
2023-01-05 14:37:17 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0332, wps=102.2, ups=0.47, wpb=109.2, bsz=40, num_updates=2470, lr=2.66566e-05, gnorm=0.983, clip=30, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=9570
2023-01-05 14:37:39 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0333, wps=102, ups=0.47, wpb=109.6, bsz=40, num_updates=2480, lr=2.67645e-05, gnorm=0.978, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9592
2023-01-05 14:38:01 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 115845 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0478, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=2490, lr=2.68724e-05, gnorm=0.938, clip=30, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9614
2023-01-05 14:38:23 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0245, wps=100.5, ups=0.46, wpb=108.5, bsz=40, num_updates=2500, lr=2.69804e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9636
2023-01-05 14:38:44 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0248, wps=103.3, ups=0.47, wpb=109.4, bsz=40, num_updates=2510, lr=2.70883e-05, gnorm=0.981, clip=50, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=9657
2023-01-05 14:39:06 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.019, wps=99.7, ups=0.46, wpb=109.4, bsz=40, num_updates=2520, lr=2.71962e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=9679
2023-01-05 14:39:28 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0262, wps=102.9, ups=0.47, wpb=109.7, bsz=40, num_updates=2530, lr=2.73041e-05, gnorm=0.874, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9701
2023-01-05 14:39:50 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 115845 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0296, wps=102.5, ups=0.47, wpb=109.2, bsz=40, num_updates=2540, lr=2.7412e-05, gnorm=0.957, clip=30, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=9722
2023-01-05 14:40:11 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0374, wps=102.8, ups=0.47, wpb=109.8, bsz=40, num_updates=2550, lr=2.752e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9744
2023-01-05 14:40:33 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0303, wps=101.1, ups=0.46, wpb=108.9, bsz=40, num_updates=2560, lr=2.76279e-05, gnorm=0.851, clip=30, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9766
2023-01-05 14:40:55 - progress_bar.py[line:274] - INFO: epoch 001:   2572 / 115845 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0372, wps=100.9, ups=0.47, wpb=108.2, bsz=40, num_updates=2570, lr=2.77358e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=9787
2023-01-05 14:41:17 - progress_bar.py[line:274] - INFO: epoch 001:   2582 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0419, wps=101, ups=0.46, wpb=109.9, bsz=40, num_updates=2580, lr=2.78437e-05, gnorm=0.992, clip=50, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=9809
2023-01-05 14:41:39 - progress_bar.py[line:274] - INFO: epoch 001:   2592 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0233, wps=97.6, ups=0.45, wpb=107.9, bsz=40, num_updates=2590, lr=2.79517e-05, gnorm=0.961, clip=30, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9832
2023-01-05 14:42:01 - progress_bar.py[line:274] - INFO: epoch 001:   2602 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.035, wps=102.1, ups=0.47, wpb=109.1, bsz=40, num_updates=2600, lr=2.80596e-05, gnorm=0.923, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9853
2023-01-05 14:42:23 - progress_bar.py[line:274] - INFO: epoch 001:   2612 / 115845 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0291, wps=102.5, ups=0.47, wpb=110.1, bsz=40, num_updates=2610, lr=2.81675e-05, gnorm=1.027, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9875
2023-01-05 14:42:45 - progress_bar.py[line:274] - INFO: epoch 001:   2622 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0404, wps=101.4, ups=0.46, wpb=109.5, bsz=40, num_updates=2620, lr=2.82754e-05, gnorm=1.036, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9897
2023-01-05 14:43:06 - progress_bar.py[line:274] - INFO: epoch 001:   2632 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0281, wps=102.2, ups=0.47, wpb=109.7, bsz=40, num_updates=2630, lr=2.83833e-05, gnorm=0.913, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9919
2023-01-05 14:43:28 - progress_bar.py[line:274] - INFO: epoch 001:   2642 / 115845 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0154, wps=100, ups=0.46, wpb=108, bsz=40, num_updates=2640, lr=2.84913e-05, gnorm=0.943, clip=40, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=9941
2023-01-05 14:43:50 - progress_bar.py[line:274] - INFO: epoch 001:   2652 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.019, wps=101.7, ups=0.47, wpb=107.5, bsz=40, num_updates=2650, lr=2.85992e-05, gnorm=0.993, clip=60, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=9962
2023-01-05 14:44:11 - progress_bar.py[line:274] - INFO: epoch 001:   2662 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0492, wps=102.3, ups=0.46, wpb=110.4, bsz=40, num_updates=2660, lr=2.87071e-05, gnorm=0.865, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=9984
2023-01-05 14:44:33 - progress_bar.py[line:274] - INFO: epoch 001:   2672 / 115845 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0237, wps=101.1, ups=0.46, wpb=109.9, bsz=40, num_updates=2670, lr=2.8815e-05, gnorm=0.844, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10006
2023-01-05 14:44:55 - progress_bar.py[line:274] - INFO: epoch 001:   2682 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0326, wps=99.9, ups=0.46, wpb=108.6, bsz=40, num_updates=2680, lr=2.89229e-05, gnorm=0.988, clip=40, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10028
2023-01-05 14:45:17 - progress_bar.py[line:274] - INFO: epoch 001:   2692 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0311, wps=100.4, ups=0.46, wpb=108.5, bsz=40, num_updates=2690, lr=2.90309e-05, gnorm=0.845, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10050
2023-01-05 14:45:39 - progress_bar.py[line:274] - INFO: epoch 001:   2702 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0402, wps=102.5, ups=0.47, wpb=109.7, bsz=40, num_updates=2700, lr=2.91388e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10072
2023-01-05 14:46:01 - progress_bar.py[line:274] - INFO: epoch 001:   2712 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0219, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=2710, lr=2.92467e-05, gnorm=0.796, clip=20, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=10094
2023-01-05 14:46:23 - progress_bar.py[line:274] - INFO: epoch 001:   2722 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.02, wps=101.4, ups=0.46, wpb=109.6, bsz=40, num_updates=2720, lr=2.93546e-05, gnorm=0.879, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10115
2023-01-05 14:46:44 - progress_bar.py[line:274] - INFO: epoch 001:   2732 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.037, wps=101.7, ups=0.47, wpb=107.8, bsz=40, num_updates=2730, lr=2.94626e-05, gnorm=0.935, clip=30, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10137
2023-01-05 14:47:06 - progress_bar.py[line:274] - INFO: epoch 001:   2742 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0152, wps=103.9, ups=0.47, wpb=110, bsz=40, num_updates=2740, lr=2.95705e-05, gnorm=0.988, clip=50, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10158
2023-01-05 14:47:27 - progress_bar.py[line:274] - INFO: epoch 001:   2752 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0319, wps=100.7, ups=0.47, wpb=108, bsz=40, num_updates=2750, lr=2.96784e-05, gnorm=0.964, clip=40, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10180
2023-01-05 14:47:49 - progress_bar.py[line:274] - INFO: epoch 001:   2762 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0253, wps=105.3, ups=0.48, wpb=110.4, bsz=40, num_updates=2760, lr=2.97863e-05, gnorm=1.035, clip=40, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=10201
2023-01-05 14:48:11 - progress_bar.py[line:274] - INFO: epoch 001:   2772 / 115845 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0386, wps=98.9, ups=0.46, wpb=107.9, bsz=40, num_updates=2770, lr=2.98942e-05, gnorm=1.009, clip=30, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10224
2023-01-05 14:48:33 - progress_bar.py[line:274] - INFO: epoch 001:   2782 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0429, wps=99.2, ups=0.46, wpb=108.8, bsz=40, num_updates=2780, lr=3.00022e-05, gnorm=0.973, clip=50, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10246
2023-01-05 14:48:54 - progress_bar.py[line:274] - INFO: epoch 001:   2792 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0469, wps=102.4, ups=0.47, wpb=108.9, bsz=40, num_updates=2790, lr=3.01101e-05, gnorm=0.97, clip=50, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10267
2023-01-05 14:49:16 - progress_bar.py[line:274] - INFO: epoch 001:   2802 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0481, wps=101.3, ups=0.46, wpb=109.2, bsz=40, num_updates=2800, lr=3.0218e-05, gnorm=0.892, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=10289
2023-01-05 14:49:38 - progress_bar.py[line:274] - INFO: epoch 001:   2812 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0405, wps=104.6, ups=0.47, wpb=111.3, bsz=40, num_updates=2810, lr=3.03259e-05, gnorm=0.886, clip=20, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10311
2023-01-05 14:49:59 - progress_bar.py[line:274] - INFO: epoch 001:   2822 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0406, wps=102.5, ups=0.47, wpb=108.7, bsz=40, num_updates=2820, lr=3.04338e-05, gnorm=0.988, clip=50, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10332
2023-01-05 14:50:21 - progress_bar.py[line:274] - INFO: epoch 001:   2832 / 115845 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0051, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=2830, lr=3.05418e-05, gnorm=1.042, clip=40, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10354
2023-01-05 14:50:43 - progress_bar.py[line:274] - INFO: epoch 001:   2842 / 115845 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0166, wps=102.3, ups=0.47, wpb=109.3, bsz=40, num_updates=2840, lr=3.06497e-05, gnorm=0.926, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10375
2023-01-05 14:51:04 - progress_bar.py[line:274] - INFO: epoch 001:   2852 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.015, wps=104.3, ups=0.48, wpb=109.3, bsz=40, num_updates=2850, lr=3.07576e-05, gnorm=0.89, clip=40, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10397
2023-01-05 14:51:26 - progress_bar.py[line:274] - INFO: epoch 001:   2862 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.029, wps=98.9, ups=0.46, wpb=108.6, bsz=40, num_updates=2860, lr=3.08655e-05, gnorm=0.768, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10419
2023-01-05 14:51:48 - progress_bar.py[line:274] - INFO: epoch 001:   2872 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0386, wps=101, ups=0.46, wpb=109.3, bsz=40, num_updates=2870, lr=3.09735e-05, gnorm=0.895, clip=30, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=10441
2023-01-05 14:52:10 - progress_bar.py[line:274] - INFO: epoch 001:   2882 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0152, wps=102, ups=0.47, wpb=109.1, bsz=40, num_updates=2880, lr=3.10814e-05, gnorm=0.878, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10462
2023-01-05 14:52:31 - progress_bar.py[line:274] - INFO: epoch 001:   2892 / 115845 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.025, wps=103, ups=0.47, wpb=109.3, bsz=40, num_updates=2890, lr=3.11893e-05, gnorm=0.848, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10484
2023-01-05 14:52:53 - progress_bar.py[line:274] - INFO: epoch 001:   2902 / 115845 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0244, wps=102, ups=0.47, wpb=109.3, bsz=40, num_updates=2900, lr=3.12972e-05, gnorm=0.816, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10506
2023-01-05 14:53:14 - progress_bar.py[line:274] - INFO: epoch 001:   2912 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0253, wps=103.5, ups=0.48, wpb=108.8, bsz=40, num_updates=2910, lr=3.14051e-05, gnorm=0.853, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10527
2023-01-05 14:53:36 - progress_bar.py[line:274] - INFO: epoch 001:   2922 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0048, wps=102.6, ups=0.47, wpb=109.6, bsz=40, num_updates=2920, lr=3.15131e-05, gnorm=0.894, clip=30, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10548
2023-01-05 14:53:57 - progress_bar.py[line:274] - INFO: epoch 001:   2932 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0306, wps=102.4, ups=0.47, wpb=109.1, bsz=40, num_updates=2930, lr=3.1621e-05, gnorm=0.953, clip=40, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10570
2023-01-05 14:54:19 - progress_bar.py[line:274] - INFO: epoch 001:   2942 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0291, wps=101, ups=0.47, wpb=108.1, bsz=40, num_updates=2940, lr=3.17289e-05, gnorm=0.757, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10592
2023-01-05 14:54:41 - progress_bar.py[line:274] - INFO: epoch 001:   2952 / 115845 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0309, wps=100.5, ups=0.46, wpb=109.7, bsz=40, num_updates=2950, lr=3.18368e-05, gnorm=0.877, clip=20, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=10614
2023-01-05 14:55:03 - progress_bar.py[line:274] - INFO: epoch 001:   2962 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.05, wps=102.2, ups=0.47, wpb=109.8, bsz=40, num_updates=2960, lr=3.19447e-05, gnorm=0.847, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10635
2023-01-05 14:55:24 - progress_bar.py[line:274] - INFO: epoch 001:   2972 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0374, wps=102.7, ups=0.47, wpb=109.4, bsz=40, num_updates=2970, lr=3.20527e-05, gnorm=0.968, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10657
2023-01-05 14:55:46 - progress_bar.py[line:274] - INFO: epoch 001:   2982 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0297, wps=100.4, ups=0.46, wpb=108.8, bsz=40, num_updates=2980, lr=3.21606e-05, gnorm=0.865, clip=30, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10679
2023-01-05 14:56:08 - progress_bar.py[line:274] - INFO: epoch 001:   2992 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0149, wps=101.9, ups=0.47, wpb=108.7, bsz=40, num_updates=2990, lr=3.22685e-05, gnorm=0.85, clip=30, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=10701
2023-01-05 14:56:30 - progress_bar.py[line:274] - INFO: epoch 001:   3002 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0, wps=102.4, ups=0.47, wpb=109.4, bsz=40, num_updates=3000, lr=3.23764e-05, gnorm=0.776, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=10722
2023-01-05 14:56:52 - progress_bar.py[line:274] - INFO: epoch 001:   3012 / 115845 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0149, wps=101.6, ups=0.46, wpb=109.4, bsz=40, num_updates=3010, lr=3.24844e-05, gnorm=0.782, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10744
2023-01-05 14:57:13 - progress_bar.py[line:274] - INFO: epoch 001:   3022 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0202, wps=100.9, ups=0.46, wpb=109, bsz=40, num_updates=3020, lr=3.25923e-05, gnorm=0.91, clip=30, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=10766
2023-01-05 14:57:35 - progress_bar.py[line:274] - INFO: epoch 001:   3032 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0245, wps=102.6, ups=0.47, wpb=109.9, bsz=40, num_updates=3030, lr=3.27002e-05, gnorm=0.785, clip=20, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10788
2023-01-05 14:57:57 - progress_bar.py[line:274] - INFO: epoch 001:   3042 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0296, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=3040, lr=3.28081e-05, gnorm=0.852, clip=20, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=10809
2023-01-05 14:58:18 - progress_bar.py[line:274] - INFO: epoch 001:   3052 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0242, wps=101.5, ups=0.47, wpb=108.5, bsz=40, num_updates=3050, lr=3.2916e-05, gnorm=0.974, clip=50, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10831
2023-01-05 14:58:40 - progress_bar.py[line:274] - INFO: epoch 001:   3062 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0148, wps=102.1, ups=0.47, wpb=108.9, bsz=40, num_updates=3060, lr=3.3024e-05, gnorm=0.926, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10853
2023-01-05 14:59:02 - progress_bar.py[line:274] - INFO: epoch 001:   3072 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0163, wps=102, ups=0.46, wpb=109.9, bsz=40, num_updates=3070, lr=3.31319e-05, gnorm=0.86, clip=30, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=10875
2023-01-05 14:59:24 - progress_bar.py[line:274] - INFO: epoch 001:   3082 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0051, wps=99, ups=0.46, wpb=108.2, bsz=40, num_updates=3080, lr=3.32398e-05, gnorm=0.885, clip=30, loss_scale=1024, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=10897
2023-01-05 14:59:45 - progress_bar.py[line:274] - INFO: epoch 001:   3092 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0236, wps=102.9, ups=0.47, wpb=108.8, bsz=40, num_updates=3090, lr=3.33477e-05, gnorm=0.746, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=10918
2023-01-05 15:00:06 - progress_bar.py[line:274] - INFO: epoch 001:   3102 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0094, wps=104.7, ups=0.48, wpb=109.6, bsz=40, num_updates=3100, lr=3.34556e-05, gnorm=0.86, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10939
2023-01-05 15:00:29 - progress_bar.py[line:274] - INFO: epoch 001:   3112 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0323, wps=101.2, ups=0.46, wpb=110.5, bsz=40, num_updates=3110, lr=3.35636e-05, gnorm=0.826, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=10961
2023-01-05 15:00:50 - progress_bar.py[line:274] - INFO: epoch 001:   3122 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0591, wps=102.1, ups=0.46, wpb=110, bsz=40, num_updates=3120, lr=3.36715e-05, gnorm=0.812, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10983
2023-01-05 15:01:12 - progress_bar.py[line:274] - INFO: epoch 001:   3132 / 115845 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0236, wps=100.5, ups=0.47, wpb=107.5, bsz=40, num_updates=3130, lr=3.37794e-05, gnorm=0.801, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11005
2023-01-05 15:01:34 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-05 15:01:36 - progress_bar.py[line:274] - INFO: epoch 001:   3143 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.476, nsentences=40, sample_size=109.476, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0365, wps=96.5, ups=0.42, wpb=109.5, bsz=40, num_updates=3140, lr=3.38873e-05, gnorm=0.917, clip=40, loss_scale=512, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=11029
2023-01-05 15:01:58 - progress_bar.py[line:274] - INFO: epoch 001:   3153 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0053, wps=100.8, ups=0.46, wpb=110.3, bsz=40, num_updates=3150, lr=3.39953e-05, gnorm=0.878, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11051
2023-01-05 15:02:20 - progress_bar.py[line:274] - INFO: epoch 001:   3163 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0259, wps=101.9, ups=0.47, wpb=109.4, bsz=40, num_updates=3160, lr=3.41032e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11073
2023-01-05 15:02:42 - progress_bar.py[line:274] - INFO: epoch 001:   3173 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0186, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=3170, lr=3.42111e-05, gnorm=0.765, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=11094
2023-01-05 15:03:04 - progress_bar.py[line:274] - INFO: epoch 001:   3183 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.015, wps=100.8, ups=0.46, wpb=109.6, bsz=40, num_updates=3180, lr=3.4319e-05, gnorm=0.958, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11116
2023-01-05 15:03:25 - progress_bar.py[line:274] - INFO: epoch 001:   3193 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0227, wps=101.1, ups=0.47, wpb=107.6, bsz=40, num_updates=3190, lr=3.44269e-05, gnorm=0.877, clip=30, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=11138
2023-01-05 15:03:47 - progress_bar.py[line:274] - INFO: epoch 001:   3203 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0159, wps=103.4, ups=0.47, wpb=109.5, bsz=40, num_updates=3200, lr=3.45349e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11160
2023-01-05 15:04:09 - progress_bar.py[line:274] - INFO: epoch 001:   3213 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0152, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=3210, lr=3.46428e-05, gnorm=0.784, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11181
2023-01-05 15:04:32 - progress_bar.py[line:274] - INFO: epoch 001:   3223 / 115845 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0303, wps=99.5, ups=0.46, wpb=108.4, bsz=40, num_updates=3220, lr=3.47507e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11203
2023-01-05 15:04:54 - progress_bar.py[line:274] - INFO: epoch 001:   3233 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0214, wps=101.9, ups=0.47, wpb=108.9, bsz=40, num_updates=3230, lr=3.48586e-05, gnorm=0.756, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11227
2023-01-05 15:05:16 - progress_bar.py[line:274] - INFO: epoch 001:   3243 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.024, wps=101.5, ups=0.46, wpb=109.2, bsz=40, num_updates=3240, lr=3.49665e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11249
2023-01-05 15:05:38 - progress_bar.py[line:274] - INFO: epoch 001:   3253 / 115845 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0398, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=3250, lr=3.50745e-05, gnorm=0.799, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11270
2023-01-05 15:05:59 - progress_bar.py[line:274] - INFO: epoch 001:   3263 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0146, wps=102.9, ups=0.47, wpb=108.5, bsz=40, num_updates=3260, lr=3.51824e-05, gnorm=0.735, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11292
2023-01-05 15:06:21 - progress_bar.py[line:274] - INFO: epoch 001:   3273 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0498, wps=102.5, ups=0.47, wpb=108.9, bsz=40, num_updates=3270, lr=3.52903e-05, gnorm=0.771, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11313
2023-01-05 15:06:42 - progress_bar.py[line:274] - INFO: epoch 001:   3283 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0383, wps=104.4, ups=0.48, wpb=109.2, bsz=40, num_updates=3280, lr=3.53982e-05, gnorm=0.927, clip=30, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=11335
2023-01-05 15:07:04 - progress_bar.py[line:274] - INFO: epoch 001:   3293 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.005, wps=101.6, ups=0.47, wpb=109.2, bsz=40, num_updates=3290, lr=3.55062e-05, gnorm=0.765, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11356
2023-01-05 15:07:25 - progress_bar.py[line:274] - INFO: epoch 001:   3303 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.043, wps=103.5, ups=0.47, wpb=109.5, bsz=40, num_updates=3300, lr=3.56141e-05, gnorm=0.833, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11378
2023-01-05 15:07:48 - progress_bar.py[line:274] - INFO: epoch 001:   3313 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0341, wps=97.7, ups=0.45, wpb=108.8, bsz=40, num_updates=3310, lr=3.5722e-05, gnorm=0.792, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=11400
2023-01-05 15:08:10 - progress_bar.py[line:274] - INFO: epoch 001:   3323 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=106.6, nsentences=40, sample_size=106.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0429, wps=95.9, ups=0.45, wpb=106.6, bsz=40, num_updates=3320, lr=3.58299e-05, gnorm=0.885, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11423
2023-01-05 15:08:32 - progress_bar.py[line:274] - INFO: epoch 001:   3333 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0478, wps=99, ups=0.46, wpb=107.7, bsz=40, num_updates=3330, lr=3.59378e-05, gnorm=0.874, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11445
2023-01-05 15:08:54 - progress_bar.py[line:274] - INFO: epoch 001:   3343 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0337, wps=104.6, ups=0.47, wpb=110.9, bsz=40, num_updates=3340, lr=3.60458e-05, gnorm=0.788, clip=20, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11466
2023-01-05 15:09:16 - progress_bar.py[line:274] - INFO: epoch 001:   3353 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0196, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=3350, lr=3.61537e-05, gnorm=0.935, clip=20, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=11488
2023-01-05 15:09:37 - progress_bar.py[line:274] - INFO: epoch 001:   3363 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0193, wps=104.5, ups=0.48, wpb=109.1, bsz=40, num_updates=3360, lr=3.62616e-05, gnorm=0.882, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=11509
2023-01-05 15:09:58 - progress_bar.py[line:274] - INFO: epoch 001:   3373 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0387, wps=105.7, ups=0.48, wpb=109.3, bsz=40, num_updates=3370, lr=3.63695e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11530
2023-01-05 15:10:20 - progress_bar.py[line:274] - INFO: epoch 001:   3383 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0635, wps=103.3, ups=0.47, wpb=110.3, bsz=40, num_updates=3380, lr=3.64774e-05, gnorm=0.78, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11552
2023-01-05 15:10:41 - progress_bar.py[line:274] - INFO: epoch 001:   3393 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0102, wps=102.4, ups=0.47, wpb=109.4, bsz=40, num_updates=3390, lr=3.65854e-05, gnorm=0.806, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11574
2023-01-05 15:11:03 - progress_bar.py[line:274] - INFO: epoch 001:   3403 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0282, wps=101, ups=0.47, wpb=108.6, bsz=40, num_updates=3400, lr=3.66933e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11596
2023-01-05 15:11:25 - progress_bar.py[line:274] - INFO: epoch 001:   3413 / 115845 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0296, wps=101.5, ups=0.47, wpb=108.2, bsz=40, num_updates=3410, lr=3.68012e-05, gnorm=0.837, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11617
2023-01-05 15:11:47 - progress_bar.py[line:274] - INFO: epoch 001:   3423 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.029, wps=100, ups=0.46, wpb=108.3, bsz=40, num_updates=3420, lr=3.69091e-05, gnorm=0.925, clip=50, loss_scale=512, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=11639
2023-01-05 15:12:08 - progress_bar.py[line:274] - INFO: epoch 001:   3433 / 115845 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0329, wps=102.7, ups=0.47, wpb=108.8, bsz=40, num_updates=3430, lr=3.70171e-05, gnorm=0.835, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11661
2023-01-05 15:12:30 - progress_bar.py[line:274] - INFO: epoch 001:   3443 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0253, wps=103, ups=0.47, wpb=109.6, bsz=40, num_updates=3440, lr=3.7125e-05, gnorm=0.812, clip=30, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11682
2023-01-05 15:12:52 - progress_bar.py[line:274] - INFO: epoch 001:   3453 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0249, wps=100.6, ups=0.46, wpb=109.9, bsz=40, num_updates=3450, lr=3.72329e-05, gnorm=0.874, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11705
2023-01-05 15:13:13 - progress_bar.py[line:274] - INFO: epoch 001:   3463 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0479, wps=104.5, ups=0.47, wpb=110.7, bsz=40, num_updates=3460, lr=3.73408e-05, gnorm=0.687, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11726
2023-01-05 15:13:35 - progress_bar.py[line:274] - INFO: epoch 001:   3473 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0338, wps=103.3, ups=0.47, wpb=110, bsz=40, num_updates=3470, lr=3.74487e-05, gnorm=0.768, clip=20, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=11748
2023-01-05 15:13:56 - progress_bar.py[line:274] - INFO: epoch 001:   3483 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0479, wps=103.1, ups=0.47, wpb=109.4, bsz=40, num_updates=3480, lr=3.75567e-05, gnorm=0.725, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11769
2023-01-05 15:14:18 - progress_bar.py[line:274] - INFO: epoch 001:   3493 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.033, wps=103.5, ups=0.47, wpb=109.1, bsz=40, num_updates=3490, lr=3.76646e-05, gnorm=0.715, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11790
2023-01-05 15:14:39 - progress_bar.py[line:274] - INFO: epoch 001:   3503 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0465, wps=101.6, ups=0.47, wpb=108.4, bsz=40, num_updates=3500, lr=3.77725e-05, gnorm=0.774, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11812
2023-01-05 15:15:01 - progress_bar.py[line:274] - INFO: epoch 001:   3513 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0308, wps=100.7, ups=0.47, wpb=107.2, bsz=40, num_updates=3510, lr=3.78804e-05, gnorm=0.842, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=11834
2023-01-05 15:15:23 - progress_bar.py[line:274] - INFO: epoch 001:   3523 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.02, wps=101.2, ups=0.46, wpb=110.2, bsz=40, num_updates=3520, lr=3.79883e-05, gnorm=0.792, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11856
2023-01-05 15:15:44 - progress_bar.py[line:274] - INFO: epoch 001:   3533 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0329, wps=101.4, ups=0.47, wpb=107.7, bsz=40, num_updates=3530, lr=3.80963e-05, gnorm=0.952, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11877
2023-01-05 15:16:06 - progress_bar.py[line:274] - INFO: epoch 001:   3543 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0237, wps=100.5, ups=0.46, wpb=108.9, bsz=40, num_updates=3540, lr=3.82042e-05, gnorm=0.727, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11899
2023-01-05 15:16:29 - progress_bar.py[line:274] - INFO: epoch 001:   3553 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0155, wps=101.1, ups=0.46, wpb=110.5, bsz=40, num_updates=3550, lr=3.83121e-05, gnorm=0.779, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11921
2023-01-05 15:16:50 - progress_bar.py[line:274] - INFO: epoch 001:   3563 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0309, wps=102.8, ups=0.47, wpb=109.8, bsz=40, num_updates=3560, lr=3.842e-05, gnorm=0.75, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11943
2023-01-05 15:17:12 - progress_bar.py[line:274] - INFO: epoch 001:   3573 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0372, wps=99.6, ups=0.46, wpb=108.2, bsz=40, num_updates=3570, lr=3.8528e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=11965
2023-01-05 15:17:34 - progress_bar.py[line:274] - INFO: epoch 001:   3583 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.024, wps=101.1, ups=0.47, wpb=107.7, bsz=40, num_updates=3580, lr=3.86359e-05, gnorm=0.873, clip=30, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11987
2023-01-05 15:17:55 - progress_bar.py[line:274] - INFO: epoch 001:   3593 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0435, wps=102.9, ups=0.47, wpb=109.9, bsz=40, num_updates=3590, lr=3.87438e-05, gnorm=0.783, clip=20, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=12008
2023-01-05 15:18:17 - progress_bar.py[line:274] - INFO: epoch 001:   3603 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0448, wps=101.5, ups=0.46, wpb=109.6, bsz=40, num_updates=3600, lr=3.88517e-05, gnorm=0.808, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=12030
2023-01-05 15:18:39 - progress_bar.py[line:274] - INFO: epoch 001:   3613 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0198, wps=102.6, ups=0.47, wpb=109.1, bsz=40, num_updates=3610, lr=3.89596e-05, gnorm=0.815, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12052
2023-01-05 15:19:01 - progress_bar.py[line:274] - INFO: epoch 001:   3623 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0466, wps=101.4, ups=0.46, wpb=110.3, bsz=40, num_updates=3620, lr=3.90676e-05, gnorm=0.788, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=12074
2023-01-05 15:19:23 - progress_bar.py[line:274] - INFO: epoch 001:   3633 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0345, wps=99.2, ups=0.46, wpb=107.8, bsz=40, num_updates=3630, lr=3.91755e-05, gnorm=0.669, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=12096
2023-01-05 15:19:45 - progress_bar.py[line:274] - INFO: epoch 001:   3643 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0404, wps=99.8, ups=0.46, wpb=108.5, bsz=40, num_updates=3640, lr=3.92834e-05, gnorm=0.74, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=12118
2023-01-05 15:20:07 - progress_bar.py[line:274] - INFO: epoch 001:   3653 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0321, wps=99.5, ups=0.46, wpb=108.2, bsz=40, num_updates=3650, lr=3.93913e-05, gnorm=0.653, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=12140
2023-01-05 15:20:29 - progress_bar.py[line:274] - INFO: epoch 001:   3663 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0197, wps=101.7, ups=0.46, wpb=109.6, bsz=40, num_updates=3660, lr=3.94992e-05, gnorm=0.741, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=12161
2023-01-05 15:20:50 - progress_bar.py[line:274] - INFO: epoch 001:   3673 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0439, wps=103.3, ups=0.47, wpb=109.5, bsz=40, num_updates=3670, lr=3.96072e-05, gnorm=0.727, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12183
2023-01-05 15:21:12 - progress_bar.py[line:274] - INFO: epoch 001:   3683 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0104, wps=102.3, ups=0.47, wpb=110, bsz=40, num_updates=3680, lr=3.97151e-05, gnorm=0.773, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12204
2023-01-05 15:21:33 - progress_bar.py[line:274] - INFO: epoch 001:   3693 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0215, wps=103.9, ups=0.47, wpb=110, bsz=40, num_updates=3690, lr=3.9823e-05, gnorm=0.802, clip=10, loss_scale=1024, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=12226
2023-01-05 15:21:55 - progress_bar.py[line:274] - INFO: epoch 001:   3703 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0284, wps=103.5, ups=0.47, wpb=109.6, bsz=40, num_updates=3700, lr=3.99309e-05, gnorm=0.714, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12248
2023-01-05 15:22:16 - progress_bar.py[line:274] - INFO: epoch 001:   3713 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0299, wps=104.4, ups=0.48, wpb=109.8, bsz=40, num_updates=3710, lr=4.00389e-05, gnorm=0.694, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12269
2023-01-05 15:22:38 - progress_bar.py[line:274] - INFO: epoch 001:   3723 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0209, wps=103.1, ups=0.47, wpb=109.7, bsz=40, num_updates=3720, lr=4.01468e-05, gnorm=0.735, clip=10, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=12291
2023-01-05 15:23:00 - progress_bar.py[line:274] - INFO: epoch 001:   3733 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0303, wps=101, ups=0.46, wpb=109.9, bsz=40, num_updates=3730, lr=4.02547e-05, gnorm=0.616, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=12313
2023-01-05 15:23:22 - progress_bar.py[line:274] - INFO: epoch 001:   3743 / 115845 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0512, wps=98.9, ups=0.46, wpb=107.5, bsz=40, num_updates=3740, lr=4.03626e-05, gnorm=0.862, clip=10, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=12335
2023-01-05 15:23:37 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-05 15:23:46 - progress_bar.py[line:274] - INFO: epoch 001:   3754 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0348, wps=96.7, ups=0.42, wpb=109, bsz=40, num_updates=3750, lr=4.04705e-05, gnorm=0.712, clip=10, loss_scale=512, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=12359
2023-01-05 15:24:08 - progress_bar.py[line:274] - INFO: epoch 001:   3764 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.051, wps=102, ups=0.47, wpb=109.3, bsz=40, num_updates=3760, lr=4.05785e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=12381
2023-01-05 15:24:30 - progress_bar.py[line:274] - INFO: epoch 001:   3774 / 115845 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0337, wps=101.4, ups=0.47, wpb=108.6, bsz=40, num_updates=3770, lr=4.06864e-05, gnorm=0.796, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=12402
2023-01-05 15:24:52 - progress_bar.py[line:274] - INFO: epoch 001:   3784 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0532, wps=101.4, ups=0.46, wpb=110.4, bsz=40, num_updates=3780, lr=4.07943e-05, gnorm=0.723, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12424
2023-01-05 15:25:14 - progress_bar.py[line:274] - INFO: epoch 001:   3794 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0191, wps=99.3, ups=0.46, wpb=108.3, bsz=40, num_updates=3790, lr=4.09022e-05, gnorm=0.701, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=12447
2023-01-05 15:25:36 - progress_bar.py[line:274] - INFO: epoch 001:   3804 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0305, wps=101.6, ups=0.47, wpb=108.7, bsz=40, num_updates=3800, lr=4.10101e-05, gnorm=0.781, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12468
2023-01-05 15:25:58 - progress_bar.py[line:274] - INFO: epoch 001:   3814 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0203, wps=101, ups=0.47, wpb=108.4, bsz=40, num_updates=3810, lr=4.11181e-05, gnorm=0.805, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12490
2023-01-05 15:26:19 - progress_bar.py[line:274] - INFO: epoch 001:   3824 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0464, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=3820, lr=4.1226e-05, gnorm=0.576, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=12512
2023-01-05 15:26:41 - progress_bar.py[line:274] - INFO: epoch 001:   3834 / 115845 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0362, wps=100.8, ups=0.47, wpb=107.7, bsz=40, num_updates=3830, lr=4.13339e-05, gnorm=0.82, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12534
2023-01-05 15:27:03 - progress_bar.py[line:274] - INFO: epoch 001:   3844 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0404, wps=100.6, ups=0.46, wpb=108.9, bsz=40, num_updates=3840, lr=4.14418e-05, gnorm=0.764, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12556
2023-01-05 15:27:25 - progress_bar.py[line:274] - INFO: epoch 001:   3854 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0363, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=3850, lr=4.15498e-05, gnorm=0.614, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=12578
2023-01-05 15:27:47 - progress_bar.py[line:274] - INFO: epoch 001:   3864 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0309, wps=101.7, ups=0.47, wpb=108.9, bsz=40, num_updates=3860, lr=4.16577e-05, gnorm=0.58, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=12600
2023-01-05 15:28:09 - progress_bar.py[line:274] - INFO: epoch 001:   3874 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0376, wps=101.2, ups=0.47, wpb=108.2, bsz=40, num_updates=3870, lr=4.17656e-05, gnorm=0.762, clip=10, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=12621
2023-01-05 15:28:30 - progress_bar.py[line:274] - INFO: epoch 001:   3884 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.051, wps=102.1, ups=0.47, wpb=108.8, bsz=40, num_updates=3880, lr=4.18735e-05, gnorm=0.837, clip=40, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=12643
2023-01-05 15:28:52 - progress_bar.py[line:274] - INFO: epoch 001:   3894 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0346, wps=100.1, ups=0.47, wpb=106.9, bsz=40, num_updates=3890, lr=4.19814e-05, gnorm=0.806, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12665
2023-01-05 15:29:14 - progress_bar.py[line:274] - INFO: epoch 001:   3904 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0053, wps=101, ups=0.46, wpb=109.8, bsz=40, num_updates=3900, lr=4.20894e-05, gnorm=0.859, clip=30, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=12687
2023-01-05 15:29:35 - progress_bar.py[line:274] - INFO: epoch 001:   3914 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0235, wps=103, ups=0.47, wpb=108.7, bsz=40, num_updates=3910, lr=4.21973e-05, gnorm=0.642, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12708
2023-01-05 15:29:57 - progress_bar.py[line:274] - INFO: epoch 001:   3924 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0253, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=3920, lr=4.23052e-05, gnorm=0.679, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12730
2023-01-05 15:30:19 - progress_bar.py[line:274] - INFO: epoch 001:   3934 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0102, wps=102.1, ups=0.47, wpb=109.1, bsz=40, num_updates=3930, lr=4.24131e-05, gnorm=0.735, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=12752
2023-01-05 15:30:41 - progress_bar.py[line:274] - INFO: epoch 001:   3944 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0376, wps=100.2, ups=0.46, wpb=109, bsz=40, num_updates=3940, lr=4.2521e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=12774
2023-01-05 15:31:03 - progress_bar.py[line:274] - INFO: epoch 001:   3954 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0251, wps=100.5, ups=0.45, wpb=110.6, bsz=40, num_updates=3950, lr=4.2629e-05, gnorm=0.6, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=12796
2023-01-05 15:31:26 - progress_bar.py[line:274] - INFO: epoch 001:   3964 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0306, wps=102.9, ups=0.46, wpb=110.9, bsz=40, num_updates=3960, lr=4.27369e-05, gnorm=0.719, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12818
2023-01-05 15:31:48 - progress_bar.py[line:274] - INFO: epoch 001:   3974 / 115845 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0653, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=3970, lr=4.28448e-05, gnorm=0.701, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=12841
2023-01-05 15:32:10 - progress_bar.py[line:274] - INFO: epoch 001:   3984 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0365, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=3980, lr=4.29527e-05, gnorm=0.636, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12863
2023-01-05 15:32:32 - progress_bar.py[line:274] - INFO: epoch 001:   3994 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0466, wps=101.2, ups=0.46, wpb=109.8, bsz=40, num_updates=3990, lr=4.30607e-05, gnorm=0.673, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12885
2023-01-05 15:32:54 - progress_bar.py[line:274] - INFO: epoch 001:   4004 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0603, wps=100.7, ups=0.46, wpb=109.5, bsz=40, num_updates=4000, lr=4.31686e-05, gnorm=0.678, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=12907
2023-01-05 15:32:54 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-05 15:32:56 - train.py[line:549] - INFO: 0 / 4988
2023-01-05 15:32:56 - train.py[line:551] - INFO: load:1.08 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-05 15:32:56 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 9.28 GiB already allocated; 6.12 GiB free; 30.98 GiB reserved in total by PyTorch)
2023-01-05 15:32:57 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-05 15:32:57 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 7         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9500 MB |   10725 MB |    1825 TB |    1825 TB |
|       from large pool |    9326 MB |   10551 MB |    1824 TB |    1824 TB |
|       from small pool |     174 MB |     175 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9500 MB |   10725 MB |    1825 TB |    1825 TB |
|       from large pool |    9326 MB |   10551 MB |    1824 TB |    1824 TB |
|       from small pool |     174 MB |     175 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   31720 MB |   33108 MB |  143268 MB |  111548 MB |
|       from large pool |   31544 MB |   32930 MB |  142946 MB |  111402 MB |
|       from small pool |     176 MB |     178 MB |     322 MB |     146 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22219 MB |   26675 MB |    1686 TB |    1686 TB |
|       from large pool |   22217 MB |   26673 MB |    1685 TB |    1685 TB |
|       from small pool |       1 MB |       3 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |   84356 K  |   84351 K  |
|       from large pool |     698    |     710    |   26548 K  |   26548 K  |
|       from small pool |    3925    |    3943    |   57807 K  |   57803 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |   84356 K  |   84351 K  |
|       from large pool |     698    |     710    |   26548 K  |   26548 K  |
|       from small pool |    3925    |    3943    |   57807 K  |   57803 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     201    |     210    |     519    |     318    |
|       from large pool |     113    |     121    |     358    |     245    |
|       from small pool |      88    |      89    |     161    |      73    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     146    |     151    |   63359 K  |   63359 K  |
|       from large pool |      74    |      77    |   14063 K  |   14063 K  |
|       from small pool |      72    |      80    |   49296 K  |   49296 K  |
|===========================================================================|

2023-01-05 15:32:57 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-05 15:35:30 - train.py[line:549] - INFO: 200 / 4988
2023-01-05 15:35:30 - train.py[line:551] - INFO: load:1.11 valid_run:153.76 task_valid:149.64 collect_output:2.99
2023-01-05 15:38:00 - train.py[line:549] - INFO: 400 / 4988
2023-01-05 15:38:00 - train.py[line:551] - INFO: load:1.13 valid_run:303.09 task_valid:293.33 collect_output:7.58
2023-01-05 15:40:34 - train.py[line:549] - INFO: 600 / 4988
2023-01-05 15:40:34 - train.py[line:551] - INFO: load:1.16 valid_run:456.43 task_valid:437.07 collect_output:16.11
2023-01-05 15:43:04 - train.py[line:549] - INFO: 800 / 4988
2023-01-05 15:43:04 - train.py[line:551] - INFO: load:1.18 valid_run:606.41 task_valid:582.77 collect_output:19.32
2023-01-05 15:45:38 - train.py[line:549] - INFO: 1000 / 4988
2023-01-05 15:45:38 - train.py[line:551] - INFO: load:1.21 valid_run:759.58 task_valid:730.75 collect_output:23.42
2023-01-05 15:48:11 - train.py[line:549] - INFO: 1200 / 4988
2023-01-05 15:48:11 - train.py[line:551] - INFO: load:1.23 valid_run:912.09 task_valid:876.76 collect_output:28.88
2023-01-05 15:50:46 - train.py[line:549] - INFO: 1400 / 4988
2023-01-05 15:50:46 - train.py[line:551] - INFO: load:1.26 valid_run:1066.73 task_valid:1023.40 collect_output:35.81
2023-01-05 15:53:19 - train.py[line:549] - INFO: 1600 / 4988
2023-01-05 15:53:19 - train.py[line:551] - INFO: load:1.28 valid_run:1219.40 task_valid:1165.67 collect_output:45.12
2023-01-05 15:55:50 - train.py[line:549] - INFO: 1800 / 4988
2023-01-05 15:55:50 - train.py[line:551] - INFO: load:1.31 valid_run:1370.26 task_valid:1311.13 collect_output:49.43
2023-01-05 15:58:20 - train.py[line:549] - INFO: 2000 / 4988
2023-01-05 15:58:20 - train.py[line:551] - INFO: load:1.34 valid_run:1520.08 task_valid:1455.12 collect_output:54.15
2023-01-05 16:00:51 - train.py[line:549] - INFO: 2200 / 4988
2023-01-05 16:00:51 - train.py[line:551] - INFO: load:1.36 valid_run:1671.25 task_valid:1600.84 collect_output:58.46
2023-01-05 16:03:22 - train.py[line:549] - INFO: 2400 / 4988
2023-01-05 16:03:23 - train.py[line:551] - INFO: load:1.39 valid_run:1822.32 task_valid:1746.72 collect_output:62.56
2023-01-05 16:05:54 - train.py[line:549] - INFO: 2600 / 4988
2023-01-05 16:05:54 - train.py[line:551] - INFO: load:1.42 valid_run:1973.45 task_valid:1889.51 collect_output:69.78
2023-01-05 16:08:26 - train.py[line:549] - INFO: 2800 / 4988
2023-01-05 16:08:26 - train.py[line:551] - INFO: load:1.45 valid_run:2125.10 task_valid:2035.87 collect_output:73.93
2023-01-05 16:10:57 - train.py[line:549] - INFO: 3000 / 4988
2023-01-05 16:10:57 - train.py[line:551] - INFO: load:1.47 valid_run:2276.07 task_valid:2182.90 collect_output:76.78
2023-01-05 16:13:29 - train.py[line:549] - INFO: 3200 / 4988
2023-01-05 16:13:29 - train.py[line:551] - INFO: load:1.50 valid_run:2427.05 task_valid:2327.83 collect_output:81.76
2023-01-05 16:16:02 - train.py[line:549] - INFO: 3400 / 4988
2023-01-05 16:16:02 - train.py[line:551] - INFO: load:1.53 valid_run:2579.66 task_valid:2474.13 collect_output:86.99
2023-01-05 16:18:33 - train.py[line:549] - INFO: 3600 / 4988
2023-01-05 16:18:33 - train.py[line:551] - INFO: load:1.55 valid_run:2730.60 task_valid:2621.43 collect_output:89.59
2023-01-05 16:21:03 - train.py[line:549] - INFO: 3800 / 4988
2023-01-05 16:21:03 - train.py[line:551] - INFO: load:1.58 valid_run:2880.32 task_valid:2763.81 collect_output:95.88
2023-01-05 16:23:34 - train.py[line:549] - INFO: 4000 / 4988
2023-01-05 16:23:34 - train.py[line:551] - INFO: load:1.61 valid_run:3031.74 task_valid:2909.68 collect_output:100.39
2023-01-05 16:26:07 - train.py[line:549] - INFO: 4200 / 4988
2023-01-05 16:26:07 - train.py[line:551] - INFO: load:1.64 valid_run:3184.53 task_valid:3054.64 collect_output:107.15
2023-01-05 16:28:38 - train.py[line:549] - INFO: 4400 / 4988
2023-01-05 16:28:38 - train.py[line:551] - INFO: load:1.66 valid_run:3334.62 task_valid:3199.59 collect_output:111.23
2023-01-05 16:31:10 - train.py[line:549] - INFO: 4600 / 4988
2023-01-05 16:31:10 - train.py[line:551] - INFO: load:1.69 valid_run:3486.72 task_valid:3346.12 collect_output:115.74
2023-01-05 16:33:42 - train.py[line:549] - INFO: 4800 / 4988
2023-01-05 16:33:42 - train.py[line:551] - INFO: load:1.71 valid_run:3638.73 task_valid:3493.12 collect_output:119.71

====================================================================================================
SGG eval:     R @ 50: 0.5183;     R @ 100: 0.5710;     R @ 500: 0.6194;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3040;    mR @ 100: 0.3836;    mR @ 500: 0.4270;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5683) (covered in:0.1875) (covering:0.5714) (eating:0.7647) (flying in:0.7273) (growing on:0.5000) (hanging from:0.4194) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7500) (playing:0.0000) (riding:0.7761) (says:0.0000) (sitting on:0.6667) (standing on:0.4050) (using:0.4000) (walking in:0.0000) (walking on:0.5946) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================

2023-01-05 16:36:13 - train.py[line:487] - INFO: 0.5709709956709956

====================================================================================================
SGG eval:     R @ 50: 0.5183;     R @ 100: 0.5710;     R @ 500: 0.6194;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3040;    mR @ 100: 0.3836;    mR @ 500: 0.4270;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5683) (covered in:0.1875) (covering:0.5714) (eating:0.7647) (flying in:0.7273) (growing on:0.5000) (hanging from:0.4194) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7500) (playing:0.0000) (riding:0.7761) (says:0.0000) (sitting on:0.6667) (standing on:0.4050) (using:0.4000) (walking in:0.0000) (walking on:0.5946) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================

2023-01-05 16:36:13 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-05 16:36:13 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.357 | loss_v1 0 | loss_v2 0 | nll_loss 0.209 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.570971 | ppl 1.16 | vqa_score 0.3063 | wps 118.2 | wpb 89.9 | bsz 30 | num_updates 4000 | best_R@100 0.570971
2023-01-05 16:36:13 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2023-01-05 16:36:13 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_4000.pt
2023-01-05 16:37:05 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_4000.pt
2023-01-05 16:40:22 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.5709709956709956) (writing took 248.34811664372683 seconds)
2023-01-05 16:40:45 - progress_bar.py[line:274] - INFO: epoch 001:   4014 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0326, wps=0.5, ups=0, wpb=109.1, bsz=40, num_updates=4010, lr=4.32765e-05, gnorm=0.639, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=16977
2023-01-05 16:41:07 - progress_bar.py[line:274] - INFO: epoch 001:   4024 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0199, wps=102.5, ups=0.47, wpb=109.2, bsz=40, num_updates=4020, lr=4.33844e-05, gnorm=0.78, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=16999
2023-01-05 16:41:29 - progress_bar.py[line:274] - INFO: epoch 001:   4034 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0521, wps=102.5, ups=0.47, wpb=108.3, bsz=40, num_updates=4030, lr=4.34923e-05, gnorm=0.621, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=17021
2023-01-05 16:41:52 - progress_bar.py[line:274] - INFO: epoch 001:   4044 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0441, wps=98.8, ups=0.45, wpb=109.3, bsz=40, num_updates=4040, lr=4.36003e-05, gnorm=0.667, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17044
2023-01-05 16:42:15 - progress_bar.py[line:274] - INFO: epoch 001:   4054 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0392, wps=100.1, ups=0.46, wpb=108.4, bsz=40, num_updates=4050, lr=4.37082e-05, gnorm=0.675, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=17067
2023-01-05 16:42:38 - progress_bar.py[line:274] - INFO: epoch 001:   4064 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0481, wps=99.4, ups=0.46, wpb=108.9, bsz=40, num_updates=4060, lr=4.38161e-05, gnorm=0.701, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17090
2023-01-05 16:43:00 - progress_bar.py[line:274] - INFO: epoch 001:   4074 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0311, wps=100.9, ups=0.46, wpb=110.3, bsz=40, num_updates=4070, lr=4.3924e-05, gnorm=0.694, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17112
2023-01-05 16:43:23 - progress_bar.py[line:274] - INFO: epoch 001:   4084 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0564, wps=100.1, ups=0.46, wpb=109.3, bsz=40, num_updates=4080, lr=4.40319e-05, gnorm=0.79, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=17135
2023-01-05 16:43:46 - progress_bar.py[line:274] - INFO: epoch 001:   4094 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0415, wps=100.9, ups=0.46, wpb=109, bsz=40, num_updates=4090, lr=4.41399e-05, gnorm=0.773, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17158
2023-01-05 16:44:08 - progress_bar.py[line:274] - INFO: epoch 001:   4104 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0212, wps=102.2, ups=0.47, wpb=109, bsz=40, num_updates=4100, lr=4.42478e-05, gnorm=0.741, clip=30, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17180
2023-01-05 16:44:30 - progress_bar.py[line:274] - INFO: epoch 001:   4114 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0447, wps=103.4, ups=0.47, wpb=110.4, bsz=40, num_updates=4110, lr=4.43557e-05, gnorm=0.685, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17202
2023-01-05 16:44:53 - progress_bar.py[line:274] - INFO: epoch 001:   4124 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0457, wps=98.2, ups=0.46, wpb=107.5, bsz=40, num_updates=4120, lr=4.44636e-05, gnorm=0.706, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=17225
2023-01-05 16:45:15 - progress_bar.py[line:274] - INFO: epoch 001:   4134 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0404, wps=103.1, ups=0.47, wpb=109.7, bsz=40, num_updates=4130, lr=4.45716e-05, gnorm=0.763, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17247
2023-01-05 16:45:38 - progress_bar.py[line:274] - INFO: epoch 001:   4144 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0377, wps=100.1, ups=0.46, wpb=109.3, bsz=40, num_updates=4140, lr=4.46795e-05, gnorm=0.741, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17270
2023-01-05 16:46:01 - progress_bar.py[line:274] - INFO: epoch 001:   4154 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0508, wps=99.4, ups=0.45, wpb=109.4, bsz=40, num_updates=4150, lr=4.47874e-05, gnorm=0.7, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17293
2023-01-05 16:46:24 - progress_bar.py[line:274] - INFO: epoch 001:   4164 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.028, wps=101, ups=0.47, wpb=108.3, bsz=40, num_updates=4160, lr=4.48953e-05, gnorm=0.777, clip=40, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17316
2023-01-05 16:46:46 - progress_bar.py[line:274] - INFO: epoch 001:   4174 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0101, wps=104.2, ups=0.47, wpb=110, bsz=40, num_updates=4170, lr=4.50032e-05, gnorm=0.798, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17338
2023-01-05 16:47:08 - progress_bar.py[line:274] - INFO: epoch 001:   4184 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0372, wps=100.5, ups=0.46, wpb=109.2, bsz=40, num_updates=4180, lr=4.51112e-05, gnorm=0.759, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=17360
2023-01-05 16:47:31 - progress_bar.py[line:274] - INFO: epoch 001:   4194 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0561, wps=100.3, ups=0.46, wpb=108.3, bsz=40, num_updates=4190, lr=4.52191e-05, gnorm=0.763, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17383
2023-01-05 16:47:53 - progress_bar.py[line:274] - INFO: epoch 001:   4204 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0508, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=4200, lr=4.5327e-05, gnorm=0.724, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17405
2023-01-05 16:48:15 - progress_bar.py[line:274] - INFO: epoch 001:   4214 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0545, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=4210, lr=4.54349e-05, gnorm=0.615, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17428
2023-01-05 16:48:38 - progress_bar.py[line:274] - INFO: epoch 001:   4224 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0711, wps=102.3, ups=0.47, wpb=107.9, bsz=40, num_updates=4220, lr=4.55428e-05, gnorm=0.684, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17450
2023-01-05 16:49:00 - progress_bar.py[line:274] - INFO: epoch 001:   4234 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0441, wps=102.9, ups=0.47, wpb=109.2, bsz=40, num_updates=4230, lr=4.56508e-05, gnorm=0.725, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17472
2023-01-05 16:49:22 - progress_bar.py[line:274] - INFO: epoch 001:   4244 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0335, wps=100.5, ups=0.47, wpb=107.5, bsz=40, num_updates=4240, lr=4.57587e-05, gnorm=0.707, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17494
2023-01-05 16:49:44 - progress_bar.py[line:274] - INFO: epoch 001:   4254 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0591, wps=103.2, ups=0.47, wpb=109.3, bsz=40, num_updates=4250, lr=4.58666e-05, gnorm=0.828, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17516
2023-01-05 16:50:06 - progress_bar.py[line:274] - INFO: epoch 001:   4264 / 115845 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0463, wps=100.8, ups=0.47, wpb=108, bsz=40, num_updates=4260, lr=4.59745e-05, gnorm=0.825, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17538
2023-01-05 16:50:29 - progress_bar.py[line:274] - INFO: epoch 001:   4274 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0386, wps=99.5, ups=0.46, wpb=108.1, bsz=40, num_updates=4270, lr=4.60825e-05, gnorm=0.827, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17561
2023-01-05 16:50:50 - progress_bar.py[line:274] - INFO: epoch 001:   4284 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0498, wps=102.2, ups=0.47, wpb=109.6, bsz=40, num_updates=4280, lr=4.61904e-05, gnorm=0.766, clip=20, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17583
2023-01-05 16:51:12 - progress_bar.py[line:274] - INFO: epoch 001:   4294 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0664, wps=100.5, ups=0.46, wpb=108.3, bsz=40, num_updates=4290, lr=4.62983e-05, gnorm=0.689, clip=10, loss_scale=1024, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=17605
2023-01-05 16:51:34 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-05 16:51:37 - progress_bar.py[line:274] - INFO: epoch 001:   4305 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=109.19, nsentences=40, sample_size=109.19, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0323, wps=95.8, ups=0.42, wpb=109.2, bsz=40, num_updates=4300, lr=4.64062e-05, gnorm=0.648, clip=10, loss_scale=512, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=17629
2023-01-05 16:51:59 - progress_bar.py[line:274] - INFO: epoch 001:   4315 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0462, wps=100.9, ups=0.46, wpb=109.3, bsz=40, num_updates=4310, lr=4.65141e-05, gnorm=0.778, clip=30, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17651
2023-01-05 16:52:20 - progress_bar.py[line:274] - INFO: epoch 001:   4325 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0455, wps=102.5, ups=0.47, wpb=108.6, bsz=40, num_updates=4320, lr=4.66221e-05, gnorm=0.625, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17673
2023-01-05 16:52:42 - progress_bar.py[line:274] - INFO: epoch 001:   4335 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0312, wps=101.4, ups=0.46, wpb=110.2, bsz=40, num_updates=4330, lr=4.673e-05, gnorm=0.645, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17695
2023-01-05 16:53:05 - progress_bar.py[line:274] - INFO: epoch 001:   4345 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0455, wps=99.5, ups=0.46, wpb=108.2, bsz=40, num_updates=4340, lr=4.68379e-05, gnorm=0.717, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17717
2023-01-05 16:53:27 - progress_bar.py[line:274] - INFO: epoch 001:   4355 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0357, wps=101.3, ups=0.46, wpb=109.7, bsz=40, num_updates=4350, lr=4.69458e-05, gnorm=0.717, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=17739
2023-01-05 16:53:48 - progress_bar.py[line:274] - INFO: epoch 001:   4365 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0495, wps=101, ups=0.47, wpb=108.1, bsz=40, num_updates=4360, lr=4.70537e-05, gnorm=0.695, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=17761
2023-01-05 16:54:10 - progress_bar.py[line:274] - INFO: epoch 001:   4375 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0328, wps=106.6, ups=0.48, wpb=110.6, bsz=40, num_updates=4370, lr=4.71617e-05, gnorm=0.784, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=17782
2023-01-05 16:54:31 - progress_bar.py[line:274] - INFO: epoch 001:   4385 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0306, wps=104.5, ups=0.48, wpb=109.6, bsz=40, num_updates=4380, lr=4.72696e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17803
2023-01-05 16:54:53 - progress_bar.py[line:274] - INFO: epoch 001:   4395 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0153, wps=102.1, ups=0.47, wpb=109.1, bsz=40, num_updates=4390, lr=4.73775e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17825
2023-01-05 16:55:15 - progress_bar.py[line:274] - INFO: epoch 001:   4405 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0683, wps=99.6, ups=0.46, wpb=107.8, bsz=40, num_updates=4400, lr=4.74854e-05, gnorm=0.597, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17847
2023-01-05 16:55:37 - progress_bar.py[line:274] - INFO: epoch 001:   4415 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0193, wps=99.1, ups=0.46, wpb=108.2, bsz=40, num_updates=4410, lr=4.75934e-05, gnorm=0.689, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=17869
2023-01-05 16:55:59 - progress_bar.py[line:274] - INFO: epoch 001:   4425 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0348, wps=101.2, ups=0.47, wpb=108.5, bsz=40, num_updates=4420, lr=4.77013e-05, gnorm=0.684, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17891
2023-01-05 16:56:21 - progress_bar.py[line:274] - INFO: epoch 001:   4435 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0439, wps=100.3, ups=0.46, wpb=108, bsz=40, num_updates=4430, lr=4.78092e-05, gnorm=0.778, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17913
2023-01-05 16:56:43 - progress_bar.py[line:274] - INFO: epoch 001:   4445 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0205, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=4440, lr=4.79171e-05, gnorm=0.731, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17935
2023-01-05 16:57:06 - progress_bar.py[line:274] - INFO: epoch 001:   4455 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0376, wps=97.6, ups=0.45, wpb=109.3, bsz=40, num_updates=4450, lr=4.8025e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17958
2023-01-05 16:57:28 - progress_bar.py[line:274] - INFO: epoch 001:   4465 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0379, wps=99.2, ups=0.46, wpb=108.5, bsz=40, num_updates=4460, lr=4.8133e-05, gnorm=0.59, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=17980
2023-01-05 16:57:50 - progress_bar.py[line:274] - INFO: epoch 001:   4475 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0357, wps=100.3, ups=0.46, wpb=108.4, bsz=40, num_updates=4470, lr=4.82409e-05, gnorm=0.611, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=18002
2023-01-05 16:58:12 - progress_bar.py[line:274] - INFO: epoch 001:   4485 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0603, wps=101.2, ups=0.47, wpb=108.4, bsz=40, num_updates=4480, lr=4.83488e-05, gnorm=0.731, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18024
2023-01-05 16:58:34 - progress_bar.py[line:274] - INFO: epoch 001:   4495 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0704, wps=102.7, ups=0.46, wpb=110.5, bsz=40, num_updates=4490, lr=4.84567e-05, gnorm=0.679, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18046
2023-01-05 16:58:55 - progress_bar.py[line:274] - INFO: epoch 001:   4505 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0352, wps=102.5, ups=0.47, wpb=108.4, bsz=40, num_updates=4500, lr=4.85646e-05, gnorm=0.677, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18068
2023-01-05 16:59:17 - progress_bar.py[line:274] - INFO: epoch 001:   4515 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0634, wps=98.9, ups=0.46, wpb=108, bsz=40, num_updates=4510, lr=4.86726e-05, gnorm=0.665, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18090
2023-01-05 16:59:39 - progress_bar.py[line:274] - INFO: epoch 001:   4525 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0392, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=4520, lr=4.87805e-05, gnorm=0.67, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=18112
2023-01-05 17:00:01 - progress_bar.py[line:274] - INFO: epoch 001:   4535 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.04, wps=101.5, ups=0.47, wpb=109, bsz=40, num_updates=4530, lr=4.88884e-05, gnorm=0.616, clip=0, loss_scale=512, train_wall=21, gb_free=9.4, ema_decay=0.9999, wall=18134
2023-01-05 17:00:23 - progress_bar.py[line:274] - INFO: epoch 001:   4545 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.034, wps=101, ups=0.47, wpb=108.2, bsz=40, num_updates=4540, lr=4.89963e-05, gnorm=0.686, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18155
2023-01-05 17:00:45 - progress_bar.py[line:274] - INFO: epoch 001:   4555 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0201, wps=98.9, ups=0.46, wpb=108.2, bsz=40, num_updates=4550, lr=4.91043e-05, gnorm=0.672, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18178
2023-01-05 17:01:08 - progress_bar.py[line:274] - INFO: epoch 001:   4565 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0529, wps=99.6, ups=0.46, wpb=108.6, bsz=40, num_updates=4560, lr=4.92122e-05, gnorm=0.61, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18200
2023-01-05 17:01:30 - progress_bar.py[line:274] - INFO: epoch 001:   4575 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.041, wps=99.6, ups=0.46, wpb=109.2, bsz=40, num_updates=4570, lr=4.93201e-05, gnorm=0.69, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=18222
2023-01-05 17:01:52 - progress_bar.py[line:274] - INFO: epoch 001:   4585 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0488, wps=103, ups=0.47, wpb=110.3, bsz=40, num_updates=4580, lr=4.9428e-05, gnorm=0.635, clip=10, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=18244
2023-01-05 17:02:14 - progress_bar.py[line:274] - INFO: epoch 001:   4595 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.034, wps=100.9, ups=0.47, wpb=108.5, bsz=40, num_updates=4590, lr=4.95359e-05, gnorm=0.613, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18266
2023-01-05 17:02:36 - progress_bar.py[line:274] - INFO: epoch 001:   4605 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0505, wps=101, ups=0.46, wpb=109.2, bsz=40, num_updates=4600, lr=4.96439e-05, gnorm=0.607, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18288
2023-01-05 17:02:57 - progress_bar.py[line:274] - INFO: epoch 001:   4615 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0563, wps=99.7, ups=0.47, wpb=106.5, bsz=40, num_updates=4610, lr=4.97518e-05, gnorm=0.666, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18310
2023-01-05 17:03:19 - progress_bar.py[line:274] - INFO: epoch 001:   4625 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0343, wps=102.3, ups=0.47, wpb=108.8, bsz=40, num_updates=4620, lr=4.98597e-05, gnorm=0.648, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18332
2023-01-05 17:03:41 - progress_bar.py[line:274] - INFO: epoch 001:   4635 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0203, wps=102.4, ups=0.47, wpb=109.8, bsz=40, num_updates=4630, lr=4.99676e-05, gnorm=0.556, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18354
2023-01-05 17:04:03 - progress_bar.py[line:274] - INFO: epoch 001:   4645 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0583, wps=100.1, ups=0.46, wpb=109.2, bsz=40, num_updates=4640, lr=4.99969e-05, gnorm=0.528, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18376
2023-01-05 17:04:25 - progress_bar.py[line:274] - INFO: epoch 001:   4655 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0707, wps=102.3, ups=0.47, wpb=108.6, bsz=40, num_updates=4650, lr=4.99924e-05, gnorm=0.712, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18397
2023-01-05 17:04:47 - progress_bar.py[line:274] - INFO: epoch 001:   4665 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.041, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=4660, lr=4.99879e-05, gnorm=0.631, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=18419
2023-01-05 17:05:09 - progress_bar.py[line:274] - INFO: epoch 001:   4675 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0683, wps=102.4, ups=0.47, wpb=109.8, bsz=40, num_updates=4670, lr=4.99834e-05, gnorm=0.62, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=18441
2023-01-05 17:05:31 - progress_bar.py[line:274] - INFO: epoch 001:   4685 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0374, wps=100.1, ups=0.46, wpb=107.8, bsz=40, num_updates=4680, lr=4.99789e-05, gnorm=0.647, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18463
2023-01-05 17:05:53 - progress_bar.py[line:274] - INFO: epoch 001:   4695 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0314, wps=98.7, ups=0.45, wpb=110.1, bsz=40, num_updates=4690, lr=4.99744e-05, gnorm=0.624, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18486
2023-01-05 17:06:15 - progress_bar.py[line:274] - INFO: epoch 001:   4705 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0365, wps=100.1, ups=0.46, wpb=108, bsz=40, num_updates=4700, lr=4.99699e-05, gnorm=0.688, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18508
2023-01-05 17:06:37 - progress_bar.py[line:274] - INFO: epoch 001:   4715 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0785, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=4710, lr=4.99654e-05, gnorm=0.577, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18530
2023-01-05 17:06:59 - progress_bar.py[line:274] - INFO: epoch 001:   4725 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0452, wps=101, ups=0.46, wpb=109, bsz=40, num_updates=4720, lr=4.99609e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18552
2023-01-05 17:07:21 - progress_bar.py[line:274] - INFO: epoch 001:   4735 / 115845 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0588, wps=100, ups=0.46, wpb=107.7, bsz=40, num_updates=4730, lr=4.99564e-05, gnorm=0.762, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=18574
2023-01-05 17:07:43 - progress_bar.py[line:274] - INFO: epoch 001:   4745 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0556, wps=99.8, ups=0.46, wpb=108.9, bsz=40, num_updates=4740, lr=4.99519e-05, gnorm=0.682, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18596
2023-01-05 17:08:05 - progress_bar.py[line:274] - INFO: epoch 001:   4755 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0348, wps=103, ups=0.47, wpb=110, bsz=40, num_updates=4750, lr=4.99474e-05, gnorm=0.684, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18617
2023-01-05 17:08:26 - progress_bar.py[line:274] - INFO: epoch 001:   4765 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0576, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=4760, lr=4.99429e-05, gnorm=0.555, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18639
2023-01-05 17:08:48 - progress_bar.py[line:274] - INFO: epoch 001:   4775 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0538, wps=101.2, ups=0.46, wpb=109.4, bsz=40, num_updates=4770, lr=4.99384e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18661
2023-01-05 17:09:10 - progress_bar.py[line:274] - INFO: epoch 001:   4785 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0483, wps=100.8, ups=0.47, wpb=107.8, bsz=40, num_updates=4780, lr=4.99339e-05, gnorm=0.564, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18683
2023-01-05 17:09:32 - progress_bar.py[line:274] - INFO: epoch 001:   4795 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0317, wps=97, ups=0.45, wpb=107.6, bsz=40, num_updates=4790, lr=4.99294e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18705
2023-01-05 17:09:54 - progress_bar.py[line:274] - INFO: epoch 001:   4805 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0699, wps=100.6, ups=0.46, wpb=110.4, bsz=40, num_updates=4800, lr=4.99249e-05, gnorm=0.633, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18727
2023-01-05 17:10:17 - progress_bar.py[line:274] - INFO: epoch 001:   4815 / 115845 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0714, wps=99.9, ups=0.46, wpb=109.4, bsz=40, num_updates=4810, lr=4.99204e-05, gnorm=0.64, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18749
2023-01-05 17:10:38 - progress_bar.py[line:274] - INFO: epoch 001:   4825 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0591, wps=101.1, ups=0.47, wpb=108.5, bsz=40, num_updates=4820, lr=4.99159e-05, gnorm=0.624, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18771
2023-01-05 17:11:00 - progress_bar.py[line:274] - INFO: epoch 001:   4835 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0647, wps=100.4, ups=0.46, wpb=109.9, bsz=40, num_updates=4830, lr=4.99114e-05, gnorm=0.574, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18793
2023-01-05 17:11:22 - progress_bar.py[line:274] - INFO: epoch 001:   4845 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.057, wps=101.9, ups=0.47, wpb=108.3, bsz=40, num_updates=4840, lr=4.99069e-05, gnorm=0.731, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18815
2023-01-05 17:11:44 - progress_bar.py[line:274] - INFO: epoch 001:   4855 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0516, wps=98.5, ups=0.46, wpb=107.5, bsz=40, num_updates=4850, lr=4.99024e-05, gnorm=0.642, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18837
2023-01-05 17:12:06 - progress_bar.py[line:274] - INFO: epoch 001:   4865 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0725, wps=97.7, ups=0.45, wpb=108.3, bsz=40, num_updates=4860, lr=4.98979e-05, gnorm=0.66, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18859
2023-01-05 17:12:28 - progress_bar.py[line:274] - INFO: epoch 001:   4875 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0461, wps=99.5, ups=0.46, wpb=107.6, bsz=40, num_updates=4870, lr=4.98934e-05, gnorm=0.635, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18881
2023-01-05 17:12:50 - progress_bar.py[line:274] - INFO: epoch 001:   4885 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.05, wps=104.2, ups=0.48, wpb=109.5, bsz=40, num_updates=4880, lr=4.9889e-05, gnorm=0.647, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=18902
2023-01-05 17:13:12 - progress_bar.py[line:274] - INFO: epoch 001:   4895 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.08, wps=100.5, ups=0.46, wpb=109.3, bsz=40, num_updates=4890, lr=4.98845e-05, gnorm=0.631, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18924
2023-01-05 17:13:34 - progress_bar.py[line:274] - INFO: epoch 001:   4905 / 115845 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0564, wps=100.4, ups=0.46, wpb=109.6, bsz=40, num_updates=4900, lr=4.988e-05, gnorm=0.529, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=18946
2023-01-05 17:13:55 - progress_bar.py[line:274] - INFO: epoch 001:   4915 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0431, wps=102.4, ups=0.47, wpb=109, bsz=40, num_updates=4910, lr=4.98755e-05, gnorm=0.739, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18968
2023-01-05 17:14:16 - progress_bar.py[line:274] - INFO: epoch 001:   4925 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0493, wps=103.9, ups=0.47, wpb=109.4, bsz=40, num_updates=4920, lr=4.9871e-05, gnorm=0.724, clip=20, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=18989
2023-01-05 17:14:38 - progress_bar.py[line:274] - INFO: epoch 001:   4935 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0725, wps=100.9, ups=0.46, wpb=108.6, bsz=40, num_updates=4930, lr=4.98665e-05, gnorm=0.562, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19011
2023-01-05 17:15:00 - progress_bar.py[line:274] - INFO: epoch 001:   4945 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0606, wps=100.6, ups=0.46, wpb=108.8, bsz=40, num_updates=4940, lr=4.9862e-05, gnorm=0.593, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19033
2023-01-05 17:15:23 - progress_bar.py[line:274] - INFO: epoch 001:   4955 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0426, wps=96.9, ups=0.45, wpb=108.9, bsz=40, num_updates=4950, lr=4.98575e-05, gnorm=0.564, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19056
2023-01-05 17:15:45 - progress_bar.py[line:274] - INFO: epoch 001:   4965 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0483, wps=99, ups=0.46, wpb=108.5, bsz=40, num_updates=4960, lr=4.9853e-05, gnorm=0.625, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=19078
2023-01-05 17:16:06 - progress_bar.py[line:274] - INFO: epoch 001:   4975 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0591, wps=103.1, ups=0.47, wpb=108.7, bsz=40, num_updates=4970, lr=4.98485e-05, gnorm=0.631, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=19099
2023-01-05 17:16:28 - progress_bar.py[line:274] - INFO: epoch 001:   4985 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0657, wps=98.9, ups=0.46, wpb=108.2, bsz=40, num_updates=4980, lr=4.9844e-05, gnorm=0.743, clip=20, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19121
2023-01-05 17:16:50 - progress_bar.py[line:274] - INFO: epoch 001:   4995 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0639, wps=100.3, ups=0.47, wpb=107.7, bsz=40, num_updates=4990, lr=4.98395e-05, gnorm=0.601, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19143
2023-01-05 17:17:12 - progress_bar.py[line:274] - INFO: epoch 001:   5005 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0531, wps=101.4, ups=0.47, wpb=107.3, bsz=40, num_updates=5000, lr=4.9835e-05, gnorm=0.615, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19164
2023-01-05 17:17:34 - progress_bar.py[line:274] - INFO: epoch 001:   5015 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0443, wps=99.7, ups=0.46, wpb=108.5, bsz=40, num_updates=5010, lr=4.98305e-05, gnorm=0.586, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19186
2023-01-05 17:17:56 - progress_bar.py[line:274] - INFO: epoch 001:   5025 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0628, wps=99.6, ups=0.46, wpb=108.6, bsz=40, num_updates=5020, lr=4.9826e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=19208
2023-01-05 17:18:17 - progress_bar.py[line:274] - INFO: epoch 001:   5035 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0366, wps=104.7, ups=0.48, wpb=108.9, bsz=40, num_updates=5030, lr=4.98215e-05, gnorm=0.533, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=19229
2023-01-05 17:18:38 - progress_bar.py[line:274] - INFO: epoch 001:   5045 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.05, wps=103.1, ups=0.47, wpb=109.6, bsz=40, num_updates=5040, lr=4.9817e-05, gnorm=0.591, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19251
2023-01-05 17:19:00 - progress_bar.py[line:274] - INFO: epoch 001:   5055 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0524, wps=104.4, ups=0.47, wpb=110.6, bsz=40, num_updates=5050, lr=4.98125e-05, gnorm=0.538, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19272
2023-01-05 17:19:22 - progress_bar.py[line:274] - INFO: epoch 001:   5065 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0558, wps=100.2, ups=0.46, wpb=109.4, bsz=40, num_updates=5060, lr=4.9808e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=19294
2023-01-05 17:19:44 - progress_bar.py[line:274] - INFO: epoch 001:   5075 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0505, wps=98.8, ups=0.45, wpb=108.9, bsz=40, num_updates=5070, lr=4.98035e-05, gnorm=0.608, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19317
2023-01-05 17:20:06 - progress_bar.py[line:274] - INFO: epoch 001:   5085 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0691, wps=100.6, ups=0.46, wpb=109.3, bsz=40, num_updates=5080, lr=4.9799e-05, gnorm=0.516, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19339
2023-01-05 17:20:28 - progress_bar.py[line:274] - INFO: epoch 001:   5095 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0909, wps=97.2, ups=0.45, wpb=108.2, bsz=40, num_updates=5090, lr=4.97945e-05, gnorm=0.569, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19361
2023-01-05 17:20:51 - progress_bar.py[line:274] - INFO: epoch 001:   5105 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0628, wps=99.5, ups=0.46, wpb=109.2, bsz=40, num_updates=5100, lr=4.979e-05, gnorm=0.54, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19383
2023-01-05 17:21:12 - progress_bar.py[line:274] - INFO: epoch 001:   5115 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0637, wps=103, ups=0.47, wpb=110.2, bsz=40, num_updates=5110, lr=4.97855e-05, gnorm=0.602, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=19405
2023-01-05 17:21:34 - progress_bar.py[line:274] - INFO: epoch 001:   5125 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0461, wps=100.6, ups=0.46, wpb=108.9, bsz=40, num_updates=5120, lr=4.9781e-05, gnorm=0.635, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19427
2023-01-05 17:21:36 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-05 17:21:58 - progress_bar.py[line:274] - INFO: epoch 001:   5136 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108.429, nsentences=40, sample_size=108.429, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0398, wps=96.6, ups=0.42, wpb=108.4, bsz=40, num_updates=5130, lr=4.97766e-05, gnorm=0.67, clip=10, loss_scale=512, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=19451
2023-01-05 17:22:20 - progress_bar.py[line:274] - INFO: epoch 001:   5146 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0428, wps=103.2, ups=0.46, wpb=111.8, bsz=40, num_updates=5140, lr=4.97721e-05, gnorm=0.638, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19473
2023-01-05 17:22:41 - progress_bar.py[line:274] - INFO: epoch 001:   5156 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0616, wps=101.7, ups=0.47, wpb=107.8, bsz=40, num_updates=5150, lr=4.97676e-05, gnorm=0.643, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19494
2023-01-05 17:23:03 - progress_bar.py[line:274] - INFO: epoch 001:   5166 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0757, wps=99.6, ups=0.46, wpb=108.8, bsz=40, num_updates=5160, lr=4.97631e-05, gnorm=0.611, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=19516
2023-01-05 17:23:25 - progress_bar.py[line:274] - INFO: epoch 001:   5176 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0667, wps=101.3, ups=0.46, wpb=108.9, bsz=40, num_updates=5170, lr=4.97586e-05, gnorm=0.615, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19538
2023-01-05 17:23:47 - progress_bar.py[line:274] - INFO: epoch 001:   5186 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0635, wps=99.1, ups=0.45, wpb=109.2, bsz=40, num_updates=5180, lr=4.97541e-05, gnorm=0.555, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19560
2023-01-05 17:24:09 - progress_bar.py[line:274] - INFO: epoch 001:   5196 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0374, wps=101.9, ups=0.46, wpb=110.4, bsz=40, num_updates=5190, lr=4.97496e-05, gnorm=0.645, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19582
2023-01-05 17:24:31 - progress_bar.py[line:274] - INFO: epoch 001:   5206 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0691, wps=101.2, ups=0.46, wpb=109.2, bsz=40, num_updates=5200, lr=4.97451e-05, gnorm=0.644, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19604
2023-01-05 17:24:53 - progress_bar.py[line:274] - INFO: epoch 001:   5216 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0524, wps=99, ups=0.46, wpb=108, bsz=40, num_updates=5210, lr=4.97406e-05, gnorm=0.631, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19626
2023-01-05 17:25:15 - progress_bar.py[line:274] - INFO: epoch 001:   5226 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0566, wps=99.2, ups=0.46, wpb=108.2, bsz=40, num_updates=5220, lr=4.97361e-05, gnorm=0.657, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19648
2023-01-05 17:25:37 - progress_bar.py[line:274] - INFO: epoch 001:   5236 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0633, wps=101.3, ups=0.47, wpb=108.2, bsz=40, num_updates=5230, lr=4.97316e-05, gnorm=0.679, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=19670
2023-01-05 17:25:59 - progress_bar.py[line:274] - INFO: epoch 001:   5246 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0606, wps=101.9, ups=0.47, wpb=108.5, bsz=40, num_updates=5240, lr=4.97271e-05, gnorm=0.735, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19691
2023-01-05 17:26:21 - progress_bar.py[line:274] - INFO: epoch 001:   5256 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0569, wps=99.8, ups=0.46, wpb=108.3, bsz=40, num_updates=5250, lr=4.97226e-05, gnorm=0.521, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19713
2023-01-05 17:26:42 - progress_bar.py[line:274] - INFO: epoch 001:   5266 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0941, wps=102.7, ups=0.47, wpb=110, bsz=40, num_updates=5260, lr=4.97181e-05, gnorm=0.637, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=19735
2023-01-05 17:27:05 - progress_bar.py[line:274] - INFO: epoch 001:   5276 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0539, wps=99.6, ups=0.46, wpb=109.2, bsz=40, num_updates=5270, lr=4.97136e-05, gnorm=0.528, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19757
2023-01-05 17:27:27 - progress_bar.py[line:274] - INFO: epoch 001:   5286 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0419, wps=98.7, ups=0.45, wpb=108.5, bsz=40, num_updates=5280, lr=4.97091e-05, gnorm=0.647, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19779
2023-01-05 17:27:49 - progress_bar.py[line:274] - INFO: epoch 001:   5296 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0429, wps=99.4, ups=0.46, wpb=108.9, bsz=40, num_updates=5290, lr=4.97046e-05, gnorm=0.642, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19802
2023-01-05 17:28:11 - progress_bar.py[line:274] - INFO: epoch 001:   5306 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0985, wps=98.2, ups=0.45, wpb=108.3, bsz=40, num_updates=5300, lr=4.97001e-05, gnorm=0.646, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=19824
2023-01-05 17:28:33 - progress_bar.py[line:274] - INFO: epoch 001:   5316 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0895, wps=103.7, ups=0.48, wpb=108.8, bsz=40, num_updates=5310, lr=4.96956e-05, gnorm=0.62, clip=0, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=19845
2023-01-05 17:28:54 - progress_bar.py[line:274] - INFO: epoch 001:   5326 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0547, wps=101.7, ups=0.47, wpb=108.7, bsz=40, num_updates=5320, lr=4.96911e-05, gnorm=0.575, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19867
2023-01-05 17:29:16 - progress_bar.py[line:274] - INFO: epoch 001:   5336 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0698, wps=101.3, ups=0.47, wpb=107.5, bsz=40, num_updates=5330, lr=4.96866e-05, gnorm=0.605, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19888
2023-01-05 17:29:38 - progress_bar.py[line:274] - INFO: epoch 001:   5346 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0945, wps=100.6, ups=0.46, wpb=109.2, bsz=40, num_updates=5340, lr=4.96821e-05, gnorm=0.559, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19910
2023-01-05 17:29:59 - progress_bar.py[line:274] - INFO: epoch 001:   5356 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0885, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=5350, lr=4.96776e-05, gnorm=0.566, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19932
2023-01-05 17:30:21 - progress_bar.py[line:274] - INFO: epoch 001:   5366 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0545, wps=100.1, ups=0.46, wpb=108.3, bsz=40, num_updates=5360, lr=4.96731e-05, gnorm=0.535, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19954
2023-01-05 17:30:43 - progress_bar.py[line:274] - INFO: epoch 001:   5376 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0691, wps=102.5, ups=0.47, wpb=110, bsz=40, num_updates=5370, lr=4.96687e-05, gnorm=0.778, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19976
2023-01-05 17:31:05 - progress_bar.py[line:274] - INFO: epoch 001:   5386 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0691, wps=102.3, ups=0.46, wpb=110.2, bsz=40, num_updates=5380, lr=4.96642e-05, gnorm=0.589, clip=0, loss_scale=512, train_wall=21, gb_free=9.4, ema_decay=0.9999, wall=19997
2023-01-05 17:31:27 - progress_bar.py[line:274] - INFO: epoch 001:   5396 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1024, wps=101.2, ups=0.46, wpb=109.8, bsz=40, num_updates=5390, lr=4.96597e-05, gnorm=0.584, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=20019
2023-01-05 17:31:49 - progress_bar.py[line:274] - INFO: epoch 001:   5406 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0773, wps=98, ups=0.45, wpb=107.8, bsz=40, num_updates=5400, lr=4.96552e-05, gnorm=0.739, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20041
2023-01-05 17:32:11 - progress_bar.py[line:274] - INFO: epoch 001:   5416 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0663, wps=100.1, ups=0.46, wpb=108.8, bsz=40, num_updates=5410, lr=4.96507e-05, gnorm=0.836, clip=30, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20064
2023-01-05 17:32:32 - progress_bar.py[line:274] - INFO: epoch 001:   5426 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0326, wps=102.7, ups=0.47, wpb=108.6, bsz=40, num_updates=5420, lr=4.96462e-05, gnorm=0.714, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20085
2023-01-05 17:32:54 - progress_bar.py[line:274] - INFO: epoch 001:   5436 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0645, wps=103.6, ups=0.47, wpb=110.2, bsz=40, num_updates=5430, lr=4.96417e-05, gnorm=0.743, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20107
2023-01-05 17:33:16 - progress_bar.py[line:274] - INFO: epoch 001:   5446 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0804, wps=99.3, ups=0.46, wpb=108.2, bsz=40, num_updates=5440, lr=4.96372e-05, gnorm=0.747, clip=30, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20129
2023-01-05 17:33:38 - progress_bar.py[line:274] - INFO: epoch 001:   5456 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0874, wps=102.2, ups=0.47, wpb=109.7, bsz=40, num_updates=5450, lr=4.96327e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20150
2023-01-05 17:33:59 - progress_bar.py[line:274] - INFO: epoch 001:   5466 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0428, wps=103.9, ups=0.48, wpb=108.9, bsz=40, num_updates=5460, lr=4.96282e-05, gnorm=0.695, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20171
2023-01-05 17:34:21 - progress_bar.py[line:274] - INFO: epoch 001:   5476 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0769, wps=99.8, ups=0.46, wpb=108.4, bsz=40, num_updates=5470, lr=4.96237e-05, gnorm=0.665, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20193
2023-01-05 17:34:43 - progress_bar.py[line:274] - INFO: epoch 001:   5486 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0511, wps=103, ups=0.46, wpb=111.5, bsz=40, num_updates=5480, lr=4.96192e-05, gnorm=0.737, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20215
2023-01-05 17:35:05 - progress_bar.py[line:274] - INFO: epoch 001:   5496 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0615, wps=98.9, ups=0.46, wpb=108, bsz=40, num_updates=5490, lr=4.96147e-05, gnorm=0.582, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=20237
2023-01-05 17:35:26 - progress_bar.py[line:274] - INFO: epoch 001:   5506 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0776, wps=102.7, ups=0.47, wpb=108.7, bsz=40, num_updates=5500, lr=4.96102e-05, gnorm=0.637, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20259
2023-01-05 17:35:48 - progress_bar.py[line:274] - INFO: epoch 001:   5516 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0733, wps=102.7, ups=0.47, wpb=110.1, bsz=40, num_updates=5510, lr=4.96057e-05, gnorm=0.642, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20280
2023-01-05 17:36:10 - progress_bar.py[line:274] - INFO: epoch 001:   5526 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0765, wps=100.7, ups=0.45, wpb=110.9, bsz=40, num_updates=5520, lr=4.96012e-05, gnorm=0.613, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20303
2023-01-05 17:36:32 - progress_bar.py[line:274] - INFO: epoch 001:   5536 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0495, wps=101, ups=0.46, wpb=110.1, bsz=40, num_updates=5530, lr=4.95967e-05, gnorm=0.717, clip=10, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=20325
2023-01-05 17:36:54 - progress_bar.py[line:274] - INFO: epoch 001:   5546 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1053, wps=98.6, ups=0.46, wpb=107.5, bsz=40, num_updates=5540, lr=4.95922e-05, gnorm=0.682, clip=10, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=20347
2023-01-05 17:37:16 - progress_bar.py[line:274] - INFO: epoch 001:   5556 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0498, wps=103.8, ups=0.47, wpb=110, bsz=40, num_updates=5550, lr=4.95877e-05, gnorm=0.658, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20368
2023-01-05 17:37:37 - progress_bar.py[line:274] - INFO: epoch 001:   5566 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0398, wps=101.2, ups=0.47, wpb=108.5, bsz=40, num_updates=5560, lr=4.95832e-05, gnorm=0.557, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20390
2023-01-05 17:38:00 - progress_bar.py[line:274] - INFO: epoch 001:   5576 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0905, wps=100.1, ups=0.45, wpb=110.3, bsz=40, num_updates=5570, lr=4.95787e-05, gnorm=0.702, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20412
2023-01-05 17:38:22 - progress_bar.py[line:274] - INFO: epoch 001:   5586 / 115845 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.07, wps=99.7, ups=0.45, wpb=110, bsz=40, num_updates=5580, lr=4.95742e-05, gnorm=0.572, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20435
2023-01-05 17:38:44 - progress_bar.py[line:274] - INFO: epoch 001:   5596 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0788, wps=99.1, ups=0.46, wpb=107.5, bsz=40, num_updates=5590, lr=4.95697e-05, gnorm=0.655, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20457
2023-01-05 17:39:06 - progress_bar.py[line:274] - INFO: epoch 001:   5606 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1123, wps=102.1, ups=0.46, wpb=110.6, bsz=40, num_updates=5600, lr=4.95652e-05, gnorm=0.7, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20479
2023-01-05 17:39:28 - progress_bar.py[line:274] - INFO: epoch 001:   5616 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.037, wps=102.6, ups=0.47, wpb=109.9, bsz=40, num_updates=5610, lr=4.95607e-05, gnorm=0.71, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=20500
2023-01-05 17:39:49 - progress_bar.py[line:274] - INFO: epoch 001:   5626 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.101, wps=102.1, ups=0.47, wpb=108.3, bsz=40, num_updates=5620, lr=4.95563e-05, gnorm=0.612, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=20522
2023-01-05 17:40:11 - progress_bar.py[line:274] - INFO: epoch 001:   5636 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0773, wps=99.6, ups=0.46, wpb=108.9, bsz=40, num_updates=5630, lr=4.95518e-05, gnorm=0.84, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20544
2023-01-05 17:40:19 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-05 17:40:35 - progress_bar.py[line:274] - INFO: epoch 001:   5647 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=109.905, nsentences=40, sample_size=109.905, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0714, wps=99, ups=0.43, wpb=109.9, bsz=40, num_updates=5640, lr=4.95473e-05, gnorm=0.642, clip=10, loss_scale=512, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=20567
2023-01-05 17:40:57 - progress_bar.py[line:274] - INFO: epoch 001:   5657 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1146, wps=100.1, ups=0.46, wpb=109.5, bsz=40, num_updates=5650, lr=4.95428e-05, gnorm=0.589, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20589
2023-01-05 17:41:19 - progress_bar.py[line:274] - INFO: epoch 001:   5667 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0909, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=5660, lr=4.95383e-05, gnorm=0.635, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20611
2023-01-05 17:41:40 - progress_bar.py[line:274] - INFO: epoch 001:   5677 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0919, wps=103, ups=0.47, wpb=110.3, bsz=40, num_updates=5670, lr=4.95338e-05, gnorm=0.567, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20633
2023-01-05 17:42:03 - progress_bar.py[line:274] - INFO: epoch 001:   5687 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0707, wps=100.5, ups=0.46, wpb=110.1, bsz=40, num_updates=5680, lr=4.95293e-05, gnorm=0.615, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20655
2023-01-05 17:42:25 - progress_bar.py[line:274] - INFO: epoch 001:   5697 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0734, wps=100.6, ups=0.46, wpb=109.9, bsz=40, num_updates=5690, lr=4.95248e-05, gnorm=0.519, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20677
2023-01-05 17:42:46 - progress_bar.py[line:274] - INFO: epoch 001:   5707 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0588, wps=103.1, ups=0.47, wpb=109.1, bsz=40, num_updates=5700, lr=4.95203e-05, gnorm=0.578, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20699
2023-01-05 17:43:08 - progress_bar.py[line:274] - INFO: epoch 001:   5717 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0729, wps=101.6, ups=0.46, wpb=110.6, bsz=40, num_updates=5710, lr=4.95158e-05, gnorm=0.561, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20721
2023-01-05 17:43:29 - progress_bar.py[line:274] - INFO: epoch 001:   5727 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0905, wps=104.2, ups=0.48, wpb=109.1, bsz=40, num_updates=5720, lr=4.95113e-05, gnorm=0.473, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20742
2023-01-05 17:43:52 - progress_bar.py[line:274] - INFO: epoch 001:   5737 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0691, wps=101.1, ups=0.46, wpb=109.5, bsz=40, num_updates=5730, lr=4.95068e-05, gnorm=0.62, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20764
2023-01-05 17:44:14 - progress_bar.py[line:274] - INFO: epoch 001:   5747 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0561, wps=101.7, ups=0.47, wpb=108.4, bsz=40, num_updates=5740, lr=4.95023e-05, gnorm=0.823, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20786
2023-01-05 17:44:37 - progress_bar.py[line:274] - INFO: epoch 001:   5757 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0761, wps=99.6, ups=0.46, wpb=108, bsz=40, num_updates=5750, lr=4.94978e-05, gnorm=0.767, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20809
2023-01-05 17:45:01 - progress_bar.py[line:274] - INFO: epoch 001:   5767 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.108, wps=101.5, ups=0.47, wpb=108.3, bsz=40, num_updates=5760, lr=4.94933e-05, gnorm=0.724, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20831
2023-01-05 17:45:22 - progress_bar.py[line:274] - INFO: epoch 001:   5777 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0984, wps=102.5, ups=0.47, wpb=108.9, bsz=40, num_updates=5770, lr=4.94888e-05, gnorm=0.617, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20855
2023-01-05 17:45:45 - progress_bar.py[line:274] - INFO: epoch 001:   5787 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0914, wps=100.1, ups=0.46, wpb=109.2, bsz=40, num_updates=5780, lr=4.94843e-05, gnorm=0.544, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20877
2023-01-05 17:46:08 - progress_bar.py[line:274] - INFO: epoch 001:   5797 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1026, wps=98.3, ups=0.45, wpb=108.7, bsz=40, num_updates=5790, lr=4.94798e-05, gnorm=0.576, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20900
2023-01-05 17:46:30 - progress_bar.py[line:274] - INFO: epoch 001:   5807 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0558, wps=100, ups=0.46, wpb=107.8, bsz=40, num_updates=5800, lr=4.94753e-05, gnorm=0.534, clip=0, loss_scale=512, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=20923
2023-01-05 17:46:52 - progress_bar.py[line:274] - INFO: epoch 001:   5817 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0612, wps=102, ups=0.47, wpb=108.9, bsz=40, num_updates=5810, lr=4.94708e-05, gnorm=0.593, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20945
2023-01-05 17:47:15 - progress_bar.py[line:274] - INFO: epoch 001:   5827 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0817, wps=98, ups=0.45, wpb=107.9, bsz=40, num_updates=5820, lr=4.94663e-05, gnorm=0.636, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20967
2023-01-05 17:47:36 - progress_bar.py[line:274] - INFO: epoch 001:   5837 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1042, wps=100.6, ups=0.47, wpb=107.8, bsz=40, num_updates=5830, lr=4.94618e-05, gnorm=0.642, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20989
2023-01-05 17:47:58 - progress_bar.py[line:274] - INFO: epoch 001:   5847 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0942, wps=102.9, ups=0.47, wpb=109.9, bsz=40, num_updates=5840, lr=4.94573e-05, gnorm=0.498, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=21011
2023-01-05 17:48:20 - progress_bar.py[line:274] - INFO: epoch 001:   5857 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0924, wps=101.9, ups=0.46, wpb=110, bsz=40, num_updates=5850, lr=4.94528e-05, gnorm=0.612, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=21033
2023-01-05 17:48:42 - progress_bar.py[line:274] - INFO: epoch 001:   5867 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0553, wps=100.8, ups=0.47, wpb=108.2, bsz=40, num_updates=5860, lr=4.94484e-05, gnorm=0.522, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=21054
2023-01-05 17:49:04 - progress_bar.py[line:274] - INFO: epoch 001:   5877 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.06, wps=102.2, ups=0.47, wpb=109.8, bsz=40, num_updates=5870, lr=4.94439e-05, gnorm=0.544, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=21076
2023-01-05 17:49:25 - progress_bar.py[line:274] - INFO: epoch 001:   5887 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0769, wps=101.3, ups=0.47, wpb=108.8, bsz=40, num_updates=5880, lr=4.94394e-05, gnorm=0.469, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=21098
2023-01-05 17:49:47 - progress_bar.py[line:274] - INFO: epoch 001:   5897 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0642, wps=103.3, ups=0.47, wpb=109.6, bsz=40, num_updates=5890, lr=4.94349e-05, gnorm=0.621, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=21119
2023-01-05 17:50:09 - progress_bar.py[line:274] - INFO: epoch 001:   5907 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0821, wps=99.7, ups=0.46, wpb=108, bsz=40, num_updates=5900, lr=4.94304e-05, gnorm=0.735, clip=30, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=21141
2023-01-05 17:50:31 - progress_bar.py[line:274] - INFO: epoch 001:   5917 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0704, wps=102.4, ups=0.47, wpb=110, bsz=40, num_updates=5910, lr=4.94259e-05, gnorm=0.554, clip=0, loss_scale=512, train_wall=21, gb_free=9.5, ema_decay=0.9999, wall=21163
2023-01-05 17:50:53 - progress_bar.py[line:274] - INFO: epoch 001:   5927 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0952, wps=100.3, ups=0.46, wpb=110, bsz=40, num_updates=5920, lr=4.94214e-05, gnorm=0.914, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=21186
2023-01-05 17:51:15 - progress_bar.py[line:274] - INFO: epoch 001:   5937 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.075, wps=100.5, ups=0.46, wpb=108.5, bsz=40, num_updates=5930, lr=4.94169e-05, gnorm=0.604, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=21207
2023-01-05 17:51:36 - progress_bar.py[line:274] - INFO: epoch 001:   5947 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0524, wps=101.9, ups=0.46, wpb=109.8, bsz=40, num_updates=5940, lr=4.94124e-05, gnorm=0.56, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=21229
2023-01-05 17:51:59 - progress_bar.py[line:274] - INFO: epoch 001:   5957 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1263, wps=99.7, ups=0.46, wpb=109, bsz=40, num_updates=5950, lr=4.94079e-05, gnorm=0.54, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=21251
2023-01-05 17:52:20 - progress_bar.py[line:274] - INFO: epoch 001:   5967 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0758, wps=102, ups=0.47, wpb=108.7, bsz=40, num_updates=5960, lr=4.94034e-05, gnorm=0.684, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=21273
2023-01-05 17:52:42 - progress_bar.py[line:274] - INFO: epoch 001:   5977 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1029, wps=100.8, ups=0.46, wpb=109, bsz=40, num_updates=5970, lr=4.93989e-05, gnorm=0.513, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=21295
2023-01-05 17:53:04 - progress_bar.py[line:274] - INFO: epoch 001:   5987 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0933, wps=103.6, ups=0.47, wpb=110.5, bsz=40, num_updates=5980, lr=4.93944e-05, gnorm=0.545, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=21316
2023-01-05 17:53:25 - progress_bar.py[line:274] - INFO: epoch 001:   5997 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1137, wps=101.3, ups=0.47, wpb=108.3, bsz=40, num_updates=5990, lr=4.93899e-05, gnorm=0.54, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=21338
2023-01-05 17:53:47 - progress_bar.py[line:274] - INFO: epoch 001:   6007 / 115845 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0718, wps=101.1, ups=0.46, wpb=109.1, bsz=40, num_updates=6000, lr=4.93854e-05, gnorm=0.548, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=21360
2023-01-05 17:53:47 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-05 17:53:48 - train.py[line:549] - INFO: 0 / 4988
2023-01-05 17:53:48 - train.py[line:551] - INFO: load:1.00 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-05 17:56:23 - train.py[line:549] - INFO: 200 / 4988
2023-01-05 17:56:23 - train.py[line:551] - INFO: load:1.03 valid_run:153.95 task_valid:150.14 collect_output:2.62
2023-01-05 17:58:54 - train.py[line:549] - INFO: 400 / 4988
2023-01-05 17:58:54 - train.py[line:551] - INFO: load:1.05 valid_run:305.38 task_valid:296.52 collect_output:6.44
2023-01-05 18:01:29 - train.py[line:549] - INFO: 600 / 4988
2023-01-05 18:01:29 - train.py[line:551] - INFO: load:1.08 valid_run:460.14 task_valid:442.44 collect_output:14.10
2023-01-05 18:04:00 - train.py[line:549] - INFO: 800 / 4988
2023-01-05 18:04:00 - train.py[line:551] - INFO: load:1.11 valid_run:611.41 task_valid:589.79 collect_output:16.86
2023-01-05 18:06:35 - train.py[line:549] - INFO: 1000 / 4988
2023-01-05 18:06:35 - train.py[line:551] - INFO: load:1.14 valid_run:765.59 task_valid:739.39 collect_output:20.25
2023-01-05 18:09:08 - train.py[line:549] - INFO: 1200 / 4988
2023-01-05 18:09:08 - train.py[line:551] - INFO: load:1.16 valid_run:919.16 task_valid:886.97 collect_output:25.12
2023-01-05 18:11:43 - train.py[line:549] - INFO: 1400 / 4988
2023-01-05 18:11:43 - train.py[line:551] - INFO: load:1.19 valid_run:1073.93 task_valid:1034.97 collect_output:30.72
2023-01-05 18:14:16 - train.py[line:549] - INFO: 1600 / 4988
2023-01-05 18:14:16 - train.py[line:551] - INFO: load:1.22 valid_run:1226.64 task_valid:1178.00 collect_output:39.28
2023-01-05 18:16:47 - train.py[line:549] - INFO: 1800 / 4988
2023-01-05 18:16:47 - train.py[line:551] - INFO: load:1.24 valid_run:1377.57 task_valid:1324.17 collect_output:42.94
2023-01-05 18:19:17 - train.py[line:549] - INFO: 2000 / 4988
2023-01-05 18:19:17 - train.py[line:551] - INFO: load:1.27 valid_run:1528.02 task_valid:1469.64 collect_output:46.77
2023-01-05 18:21:49 - train.py[line:549] - INFO: 2200 / 4988
2023-01-05 18:21:49 - train.py[line:551] - INFO: load:1.30 valid_run:1679.57 task_valid:1616.35 collect_output:50.46
2023-01-05 18:24:21 - train.py[line:549] - INFO: 2400 / 4988
2023-01-05 18:24:21 - train.py[line:551] - INFO: load:1.33 valid_run:1831.52 task_valid:1763.70 collect_output:53.94
2023-01-05 18:26:53 - train.py[line:549] - INFO: 2600 / 4988
2023-01-05 18:26:53 - train.py[line:551] - INFO: load:1.36 valid_run:1983.13 task_valid:1907.72 collect_output:60.38
2023-01-05 18:29:25 - train.py[line:549] - INFO: 2800 / 4988
2023-01-05 18:29:25 - train.py[line:551] - INFO: load:1.38 valid_run:2135.24 task_valid:2055.28 collect_output:63.78
2023-01-05 18:31:57 - train.py[line:549] - INFO: 3000 / 4988
2023-01-05 18:31:57 - train.py[line:551] - INFO: load:1.41 valid_run:2287.09 task_valid:2203.57 collect_output:66.19
2023-01-05 18:34:28 - train.py[line:549] - INFO: 3200 / 4988
2023-01-05 18:34:28 - train.py[line:551] - INFO: load:1.44 valid_run:2438.64 task_valid:2349.78 collect_output:70.41
2023-01-05 18:37:02 - train.py[line:549] - INFO: 3400 / 4988
2023-01-05 18:37:02 - train.py[line:551] - INFO: load:1.50 valid_run:2591.55 task_valid:2497.07 collect_output:74.90
2023-01-05 18:39:34 - train.py[line:549] - INFO: 3600 / 4988
2023-01-05 18:39:34 - train.py[line:551] - INFO: load:1.52 valid_run:2743.61 task_valid:2645.78 collect_output:77.11
2023-01-05 18:42:05 - train.py[line:549] - INFO: 3800 / 4988
2023-01-05 18:42:05 - train.py[line:551] - INFO: load:1.55 valid_run:2894.47 task_valid:2791.12 collect_output:81.39
2023-01-05 18:44:37 - train.py[line:549] - INFO: 4000 / 4988
2023-01-05 18:44:37 - train.py[line:551] - INFO: load:1.58 valid_run:3047.19 task_valid:2939.37 collect_output:84.71
2023-01-05 18:47:11 - train.py[line:549] - INFO: 4200 / 4988
2023-01-05 18:47:11 - train.py[line:551] - INFO: load:1.61 valid_run:3200.22 task_valid:3086.01 collect_output:89.92
2023-01-05 18:49:42 - train.py[line:549] - INFO: 4400 / 4988
2023-01-05 18:49:42 - train.py[line:551] - INFO: load:1.64 valid_run:3351.26 task_valid:3233.09 collect_output:92.72
2023-01-05 18:52:14 - train.py[line:549] - INFO: 4600 / 4988
2023-01-05 18:52:15 - train.py[line:551] - INFO: load:1.66 valid_run:3503.94 task_valid:3381.31 collect_output:96.07
2023-01-05 18:54:48 - train.py[line:549] - INFO: 4800 / 4988
2023-01-05 18:54:48 - train.py[line:551] - INFO: load:1.69 valid_run:3657.67 task_valid:3530.82 collect_output:99.12

====================================================================================================
SGG eval:     R @ 50: 0.5906;     R @ 100: 0.6426;     R @ 500: 0.6762;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3671;    mR @ 100: 0.4497;    mR @ 500: 0.4976;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7561) (covered in:0.8125) (covering:0.3714) (eating:0.7647) (flying in:0.7273) (growing on:0.3750) (hanging from:0.4839) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9167) (playing:0.0000) (riding:0.9232) (says:0.0000) (sitting on:0.7370) (standing on:0.2850) (using:0.6000) (walking in:0.0000) (walking on:0.7838) (watching:0.3750) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5906;     R @ 100: 0.6426;     R @ 500: 0.6762;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3671;    mR @ 100: 0.4497;    mR @ 500: 0.4976;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7561) (covered in:0.8125) (covering:0.3714) (eating:0.7647) (flying in:0.7273) (growing on:0.3750) (hanging from:0.4839) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9167) (playing:0.0000) (riding:0.9232) (says:0.0000) (sitting on:0.7370) (standing on:0.2850) (using:0.6000) (walking in:0.0000) (walking on:0.7838) (watching:0.3750) 
--------------------------------------------------------
====================================================================================================

2023-01-05 18:57:21 - train.py[line:487] - INFO: 0.6425539088362617
2023-01-05 18:57:21 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-05 18:57:21 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.36 | loss_v1 0 | loss_v2 0 | nll_loss 0.211 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.642554 | ppl 1.16 | vqa_score 0.4572 | wps 117.7 | wpb 89.9 | bsz 30 | num_updates 6000 | best_R@100 0.642554
2023-01-05 18:57:21 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2023-01-05 18:57:21 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_6000.pt
2023-01-05 18:58:07 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_6000.pt
2023-01-05 19:01:10 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.6425539088362617) (writing took 228.65195330232382 seconds)
2023-01-05 19:01:32 - progress_bar.py[line:274] - INFO: epoch 001:   6017 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1156, wps=0.5, ups=0, wpb=108.3, bsz=40, num_updates=6010, lr=4.93809e-05, gnorm=0.645, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=25424
2023-01-05 19:01:55 - progress_bar.py[line:274] - INFO: epoch 001:   6027 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0938, wps=101.7, ups=0.47, wpb=109.1, bsz=40, num_updates=6020, lr=4.93764e-05, gnorm=0.542, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25447
2023-01-05 19:02:19 - progress_bar.py[line:274] - INFO: epoch 001:   6037 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0952, wps=99.2, ups=0.46, wpb=107.4, bsz=40, num_updates=6030, lr=4.93719e-05, gnorm=0.542, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=25470
2023-01-05 19:02:42 - progress_bar.py[line:274] - INFO: epoch 001:   6047 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0854, wps=98.8, ups=0.45, wpb=108.9, bsz=40, num_updates=6040, lr=4.93674e-05, gnorm=0.596, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25494
2023-01-05 19:03:05 - progress_bar.py[line:274] - INFO: epoch 001:   6057 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0579, wps=100.3, ups=0.46, wpb=108.7, bsz=40, num_updates=6050, lr=4.93629e-05, gnorm=0.576, clip=10, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=25517
2023-01-05 19:03:28 - progress_bar.py[line:274] - INFO: epoch 001:   6067 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0474, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=6060, lr=4.93584e-05, gnorm=0.572, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25540
2023-01-05 19:03:51 - progress_bar.py[line:274] - INFO: epoch 001:   6077 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1068, wps=100.6, ups=0.47, wpb=108, bsz=40, num_updates=6070, lr=4.93539e-05, gnorm=0.517, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25563
2023-01-05 19:04:16 - progress_bar.py[line:274] - INFO: epoch 001:   6087 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0904, wps=101.2, ups=0.46, wpb=110.2, bsz=40, num_updates=6080, lr=4.93494e-05, gnorm=0.597, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=25586
2023-01-05 19:04:39 - progress_bar.py[line:274] - INFO: epoch 001:   6097 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0991, wps=98.9, ups=0.46, wpb=108.1, bsz=40, num_updates=6090, lr=4.93449e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=25611
2023-01-05 19:05:02 - progress_bar.py[line:274] - INFO: epoch 001:   6107 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0825, wps=101.7, ups=0.46, wpb=109.9, bsz=40, num_updates=6100, lr=4.93404e-05, gnorm=0.575, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25634
2023-01-05 19:05:25 - progress_bar.py[line:274] - INFO: epoch 001:   6117 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0653, wps=103.7, ups=0.47, wpb=109.8, bsz=40, num_updates=6110, lr=4.9336e-05, gnorm=0.685, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=25657
2023-01-05 19:05:48 - progress_bar.py[line:274] - INFO: epoch 001:   6127 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0881, wps=99.6, ups=0.46, wpb=108.3, bsz=40, num_updates=6120, lr=4.93315e-05, gnorm=0.555, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=25680
2023-01-05 19:06:11 - progress_bar.py[line:274] - INFO: epoch 001:   6137 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1282, wps=104.1, ups=0.47, wpb=111, bsz=40, num_updates=6130, lr=4.9327e-05, gnorm=0.512, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=25702
2023-01-05 19:06:34 - progress_bar.py[line:274] - INFO: epoch 001:   6147 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0895, wps=100.7, ups=0.46, wpb=108.9, bsz=40, num_updates=6140, lr=4.93225e-05, gnorm=0.599, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=25726
2023-01-05 19:06:42 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-05 19:06:59 - progress_bar.py[line:274] - INFO: epoch 001:   6158 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.286, nsentences=40, sample_size=109.286, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0955, wps=97.5, ups=0.42, wpb=109.3, bsz=40, num_updates=6150, lr=4.9318e-05, gnorm=0.506, clip=0, loss_scale=256, train_wall=23, gb_free=10.4, ema_decay=0.9999, wall=25750
2023-01-05 19:07:22 - progress_bar.py[line:274] - INFO: epoch 001:   6168 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0833, wps=101.8, ups=0.46, wpb=109.7, bsz=40, num_updates=6160, lr=4.93135e-05, gnorm=0.528, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25773
2023-01-05 19:07:45 - progress_bar.py[line:274] - INFO: epoch 001:   6178 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0861, wps=101.4, ups=0.46, wpb=109, bsz=40, num_updates=6170, lr=4.9309e-05, gnorm=0.635, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25796
2023-01-05 19:08:08 - progress_bar.py[line:274] - INFO: epoch 001:   6188 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0787, wps=103.9, ups=0.47, wpb=111.3, bsz=40, num_updates=6180, lr=4.93045e-05, gnorm=0.52, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=25820
2023-01-05 19:08:32 - progress_bar.py[line:274] - INFO: epoch 001:   6198 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0459, wps=101.9, ups=0.46, wpb=109.9, bsz=40, num_updates=6190, lr=4.93e-05, gnorm=0.536, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=25843
2023-01-05 19:08:55 - progress_bar.py[line:274] - INFO: epoch 001:   6208 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1063, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=6200, lr=4.92955e-05, gnorm=0.536, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=25866
2023-01-05 19:09:18 - progress_bar.py[line:274] - INFO: epoch 001:   6218 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1061, wps=100.7, ups=0.46, wpb=109.1, bsz=40, num_updates=6210, lr=4.9291e-05, gnorm=0.517, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=25890
2023-01-05 19:09:41 - progress_bar.py[line:274] - INFO: epoch 001:   6228 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1324, wps=102, ups=0.47, wpb=108.9, bsz=40, num_updates=6220, lr=4.92865e-05, gnorm=0.51, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25912
2023-01-05 19:10:04 - progress_bar.py[line:274] - INFO: epoch 001:   6238 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1204, wps=103.1, ups=0.47, wpb=109.6, bsz=40, num_updates=6230, lr=4.9282e-05, gnorm=0.586, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25936
2023-01-05 19:10:26 - progress_bar.py[line:274] - INFO: epoch 001:   6248 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.102, wps=103.8, ups=0.48, wpb=108.8, bsz=40, num_updates=6240, lr=4.92775e-05, gnorm=0.501, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25958
2023-01-05 19:10:50 - progress_bar.py[line:274] - INFO: epoch 001:   6258 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1016, wps=102.6, ups=0.47, wpb=109.7, bsz=40, num_updates=6250, lr=4.9273e-05, gnorm=0.509, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=25981
2023-01-05 19:11:14 - progress_bar.py[line:274] - INFO: epoch 001:   6268 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.096, wps=99.7, ups=0.46, wpb=108.8, bsz=40, num_updates=6260, lr=4.92685e-05, gnorm=0.502, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26005
2023-01-05 19:11:36 - progress_bar.py[line:274] - INFO: epoch 001:   6278 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1019, wps=101.8, ups=0.47, wpb=108.5, bsz=40, num_updates=6270, lr=4.9264e-05, gnorm=0.5, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26028
2023-01-05 19:11:59 - progress_bar.py[line:274] - INFO: epoch 001:   6288 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1311, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=6280, lr=4.92595e-05, gnorm=0.455, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=26051
2023-01-05 19:12:24 - progress_bar.py[line:274] - INFO: epoch 001:   6298 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1337, wps=100.7, ups=0.46, wpb=109.4, bsz=40, num_updates=6290, lr=4.9255e-05, gnorm=0.533, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26074
2023-01-05 19:12:47 - progress_bar.py[line:274] - INFO: epoch 001:   6308 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1256, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=6300, lr=4.92505e-05, gnorm=0.549, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=26098
2023-01-05 19:13:10 - progress_bar.py[line:274] - INFO: epoch 001:   6318 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1311, wps=103.2, ups=0.47, wpb=110.3, bsz=40, num_updates=6310, lr=4.9246e-05, gnorm=0.516, clip=0, loss_scale=256, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=26121
2023-01-05 19:13:33 - progress_bar.py[line:274] - INFO: epoch 001:   6328 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0941, wps=101.4, ups=0.47, wpb=108.3, bsz=40, num_updates=6320, lr=4.92415e-05, gnorm=0.471, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=26144
2023-01-05 19:13:55 - progress_bar.py[line:274] - INFO: epoch 001:   6338 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.16, wps=103.2, ups=0.48, wpb=108.2, bsz=40, num_updates=6330, lr=4.9237e-05, gnorm=0.607, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=26167
2023-01-05 19:14:18 - progress_bar.py[line:274] - INFO: epoch 001:   6348 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1374, wps=103.9, ups=0.47, wpb=110.8, bsz=40, num_updates=6340, lr=4.92325e-05, gnorm=0.559, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26190
2023-01-05 19:14:41 - progress_bar.py[line:274] - INFO: epoch 001:   6358 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.099, wps=102.1, ups=0.48, wpb=107.2, bsz=40, num_updates=6350, lr=4.92281e-05, gnorm=0.938, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26212
2023-01-05 19:15:04 - progress_bar.py[line:274] - INFO: epoch 001:   6368 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0984, wps=102.9, ups=0.47, wpb=110, bsz=40, num_updates=6360, lr=4.92236e-05, gnorm=0.518, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26235
2023-01-05 19:15:27 - progress_bar.py[line:274] - INFO: epoch 001:   6378 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0833, wps=101.4, ups=0.47, wpb=108.3, bsz=40, num_updates=6370, lr=4.92191e-05, gnorm=0.547, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=26258
2023-01-05 19:15:50 - progress_bar.py[line:274] - INFO: epoch 001:   6388 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1359, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=6380, lr=4.92146e-05, gnorm=0.556, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26281
2023-01-05 19:16:13 - progress_bar.py[line:274] - INFO: epoch 001:   6398 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1202, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=6390, lr=4.92101e-05, gnorm=0.61, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26304
2023-01-05 19:16:15 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-01-05 19:16:39 - progress_bar.py[line:274] - INFO: epoch 001:   6409 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.667, nsentences=40, sample_size=108.667, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.163, wps=95.8, ups=0.42, wpb=108.7, bsz=40, num_updates=6400, lr=4.92056e-05, gnorm=0.474, clip=0, loss_scale=128, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=26330
2023-01-05 19:17:02 - progress_bar.py[line:274] - INFO: epoch 001:   6419 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0788, wps=100.5, ups=0.46, wpb=109.6, bsz=40, num_updates=6410, lr=4.92011e-05, gnorm=0.582, clip=10, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26354
2023-01-05 19:17:25 - progress_bar.py[line:274] - INFO: epoch 001:   6429 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.075, wps=103.8, ups=0.47, wpb=110.1, bsz=40, num_updates=6420, lr=4.91966e-05, gnorm=0.707, clip=10, loss_scale=128, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=26376
2023-01-05 19:17:49 - progress_bar.py[line:274] - INFO: epoch 001:   6439 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1717, wps=103.7, ups=0.47, wpb=109.5, bsz=40, num_updates=6430, lr=4.91921e-05, gnorm=0.557, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26399
2023-01-05 19:18:12 - progress_bar.py[line:274] - INFO: epoch 001:   6449 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0948, wps=99.3, ups=0.46, wpb=107, bsz=40, num_updates=6440, lr=4.91876e-05, gnorm=0.532, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26423
2023-01-05 19:18:35 - progress_bar.py[line:274] - INFO: epoch 001:   6459 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1512, wps=100.9, ups=0.46, wpb=109.7, bsz=40, num_updates=6450, lr=4.91831e-05, gnorm=0.557, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26446
2023-01-05 19:18:58 - progress_bar.py[line:274] - INFO: epoch 001:   6469 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1471, wps=102.4, ups=0.47, wpb=108.7, bsz=40, num_updates=6460, lr=4.91786e-05, gnorm=0.518, clip=10, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26469
2023-01-05 19:19:21 - progress_bar.py[line:274] - INFO: epoch 001:   6479 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1159, wps=101, ups=0.46, wpb=109.2, bsz=40, num_updates=6470, lr=4.91741e-05, gnorm=0.536, clip=0, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26492
2023-01-05 19:19:42 - progress_bar.py[line:274] - INFO: epoch 001:   6489 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1321, wps=103.4, ups=0.48, wpb=107.2, bsz=40, num_updates=6480, lr=4.91696e-05, gnorm=0.479, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26515
2023-01-05 19:20:04 - progress_bar.py[line:274] - INFO: epoch 001:   6499 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1105, wps=99.5, ups=0.46, wpb=108.4, bsz=40, num_updates=6490, lr=4.91651e-05, gnorm=0.481, clip=0, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26537
2023-01-05 19:20:26 - progress_bar.py[line:274] - INFO: epoch 001:   6509 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1237, wps=102.3, ups=0.47, wpb=109.7, bsz=40, num_updates=6500, lr=4.91606e-05, gnorm=0.416, clip=0, loss_scale=128, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=26558
2023-01-05 19:20:48 - progress_bar.py[line:274] - INFO: epoch 001:   6519 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1176, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=6510, lr=4.91561e-05, gnorm=0.539, clip=0, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=26580
2023-01-05 19:21:09 - progress_bar.py[line:274] - INFO: epoch 001:   6529 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1036, wps=102.2, ups=0.47, wpb=109.2, bsz=40, num_updates=6520, lr=4.91516e-05, gnorm=0.52, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26602
2023-01-05 19:21:31 - progress_bar.py[line:274] - INFO: epoch 001:   6539 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1472, wps=101.6, ups=0.47, wpb=108.9, bsz=40, num_updates=6530, lr=4.91471e-05, gnorm=0.528, clip=0, loss_scale=128, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=26624
2023-01-05 19:21:53 - progress_bar.py[line:274] - INFO: epoch 001:   6549 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1471, wps=101.9, ups=0.47, wpb=108.3, bsz=40, num_updates=6540, lr=4.91426e-05, gnorm=0.666, clip=10, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26645
2023-01-05 19:22:14 - progress_bar.py[line:274] - INFO: epoch 001:   6559 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1592, wps=104.3, ups=0.48, wpb=109.4, bsz=40, num_updates=6550, lr=4.91381e-05, gnorm=0.603, clip=0, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=26666
2023-01-05 19:22:36 - progress_bar.py[line:274] - INFO: epoch 001:   6569 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1854, wps=100.5, ups=0.46, wpb=108.8, bsz=40, num_updates=6560, lr=4.91336e-05, gnorm=0.585, clip=10, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26688
2023-01-05 19:22:57 - progress_bar.py[line:274] - INFO: epoch 001:   6579 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1683, wps=102.5, ups=0.47, wpb=108.5, bsz=40, num_updates=6570, lr=4.91291e-05, gnorm=0.535, clip=0, loss_scale=128, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=26710
2023-01-05 19:23:19 - progress_bar.py[line:274] - INFO: epoch 001:   6589 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1422, wps=101.3, ups=0.46, wpb=109.2, bsz=40, num_updates=6580, lr=4.91246e-05, gnorm=0.584, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26732
2023-01-05 19:23:41 - progress_bar.py[line:274] - INFO: epoch 001:   6599 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1359, wps=102.9, ups=0.47, wpb=109.2, bsz=40, num_updates=6590, lr=4.91201e-05, gnorm=0.499, clip=0, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=26753
2023-01-05 19:24:03 - progress_bar.py[line:274] - INFO: epoch 001:   6609 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.151, wps=101.5, ups=0.46, wpb=110.5, bsz=40, num_updates=6600, lr=4.91157e-05, gnorm=0.595, clip=10, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=26775
2023-01-05 19:24:24 - progress_bar.py[line:274] - INFO: epoch 001:   6619 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1276, wps=100.6, ups=0.47, wpb=108.1, bsz=40, num_updates=6610, lr=4.91112e-05, gnorm=0.57, clip=0, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=26797
2023-01-05 19:24:47 - progress_bar.py[line:274] - INFO: epoch 001:   6629 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0521, wps=99.3, ups=0.46, wpb=108.9, bsz=40, num_updates=6620, lr=4.91067e-05, gnorm=0.571, clip=10, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=26819
2023-01-05 19:25:08 - progress_bar.py[line:274] - INFO: epoch 001:   6639 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1487, wps=106, ups=0.48, wpb=110.1, bsz=40, num_updates=6630, lr=4.91022e-05, gnorm=0.606, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26840
2023-01-05 19:25:30 - progress_bar.py[line:274] - INFO: epoch 001:   6649 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1442, wps=99.4, ups=0.46, wpb=108.7, bsz=40, num_updates=6640, lr=4.90977e-05, gnorm=0.522, clip=0, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26862
2023-01-05 19:25:51 - progress_bar.py[line:274] - INFO: epoch 001:   6659 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1373, wps=103.6, ups=0.47, wpb=109.8, bsz=40, num_updates=6650, lr=4.90932e-05, gnorm=0.481, clip=0, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=26884
2023-01-05 19:26:13 - progress_bar.py[line:274] - INFO: epoch 001:   6669 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1269, wps=100.5, ups=0.46, wpb=109.8, bsz=40, num_updates=6660, lr=4.90887e-05, gnorm=0.673, clip=10, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26906
2023-01-05 19:26:35 - progress_bar.py[line:274] - INFO: epoch 001:   6679 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1208, wps=102, ups=0.47, wpb=108.5, bsz=40, num_updates=6670, lr=4.90842e-05, gnorm=0.758, clip=10, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26928
2023-01-05 19:26:56 - progress_bar.py[line:274] - INFO: epoch 001:   6689 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1484, wps=103.6, ups=0.47, wpb=110, bsz=40, num_updates=6680, lr=4.90797e-05, gnorm=0.579, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26949
2023-01-05 19:27:18 - progress_bar.py[line:274] - INFO: epoch 001:   6699 / 115845 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.115, wps=102.8, ups=0.47, wpb=109.8, bsz=40, num_updates=6690, lr=4.90752e-05, gnorm=0.557, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26971
2023-01-05 19:27:40 - progress_bar.py[line:274] - INFO: epoch 001:   6709 / 115845 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1518, wps=101.9, ups=0.46, wpb=109.9, bsz=40, num_updates=6700, lr=4.90707e-05, gnorm=0.499, clip=0, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=26992
2023-01-05 19:28:01 - progress_bar.py[line:274] - INFO: epoch 001:   6719 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1111, wps=102.1, ups=0.47, wpb=107.8, bsz=40, num_updates=6710, lr=4.90662e-05, gnorm=0.636, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27014
2023-01-05 19:28:22 - progress_bar.py[line:274] - INFO: epoch 001:   6729 / 115845 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1282, wps=103.4, ups=0.47, wpb=109.3, bsz=40, num_updates=6720, lr=4.90617e-05, gnorm=0.508, clip=0, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27035
2023-01-05 19:28:44 - progress_bar.py[line:274] - INFO: epoch 001:   6739 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1531, wps=104, ups=0.47, wpb=110.1, bsz=40, num_updates=6730, lr=4.90572e-05, gnorm=0.493, clip=0, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27057
2023-01-05 19:29:05 - progress_bar.py[line:274] - INFO: epoch 001:   6749 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1449, wps=102, ups=0.47, wpb=108.6, bsz=40, num_updates=6740, lr=4.90527e-05, gnorm=0.565, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27078
2023-01-05 19:29:27 - progress_bar.py[line:274] - INFO: epoch 001:   6759 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1019, wps=100.9, ups=0.46, wpb=109.3, bsz=40, num_updates=6750, lr=4.90482e-05, gnorm=0.606, clip=0, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27100
2023-01-05 19:29:49 - progress_bar.py[line:274] - INFO: epoch 001:   6769 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1443, wps=103.4, ups=0.47, wpb=110.6, bsz=40, num_updates=6760, lr=4.90437e-05, gnorm=0.554, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27122
2023-01-05 19:30:11 - progress_bar.py[line:274] - INFO: epoch 001:   6779 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1314, wps=101, ups=0.46, wpb=110, bsz=40, num_updates=6770, lr=4.90392e-05, gnorm=0.484, clip=0, loss_scale=128, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=27144
2023-01-05 19:30:33 - progress_bar.py[line:274] - INFO: epoch 001:   6789 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1731, wps=100.8, ups=0.46, wpb=108.4, bsz=40, num_updates=6780, lr=4.90347e-05, gnorm=0.571, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27166
2023-01-05 19:30:55 - progress_bar.py[line:274] - INFO: epoch 001:   6799 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0899, wps=100.6, ups=0.46, wpb=109.3, bsz=40, num_updates=6790, lr=4.90302e-05, gnorm=0.745, clip=20, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27188
2023-01-05 19:31:17 - progress_bar.py[line:274] - INFO: epoch 001:   6809 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1476, wps=100.7, ups=0.46, wpb=108.5, bsz=40, num_updates=6800, lr=4.90257e-05, gnorm=0.562, clip=0, loss_scale=128, train_wall=21, gb_free=10, ema_decay=0.9999, wall=27210
2023-01-05 19:31:39 - progress_bar.py[line:274] - INFO: epoch 001:   6819 / 115845 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1531, wps=102.1, ups=0.46, wpb=110, bsz=40, num_updates=6810, lr=4.90212e-05, gnorm=0.523, clip=0, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27231
2023-01-05 19:32:01 - progress_bar.py[line:274] - INFO: epoch 001:   6829 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1373, wps=100.5, ups=0.46, wpb=109.4, bsz=40, num_updates=6820, lr=4.90167e-05, gnorm=0.494, clip=0, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27253
2023-01-05 19:32:22 - progress_bar.py[line:274] - INFO: epoch 001:   6839 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1308, wps=99.5, ups=0.46, wpb=107.7, bsz=40, num_updates=6830, lr=4.90122e-05, gnorm=0.598, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27275
2023-01-05 19:32:44 - progress_bar.py[line:274] - INFO: epoch 001:   6849 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1088, wps=102, ups=0.47, wpb=108.1, bsz=40, num_updates=6840, lr=4.90078e-05, gnorm=0.574, clip=0, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=27297
2023-01-05 19:33:06 - progress_bar.py[line:274] - INFO: epoch 001:   6859 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.148, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=6850, lr=4.90033e-05, gnorm=0.452, clip=0, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27318
2023-01-05 19:33:27 - progress_bar.py[line:274] - INFO: epoch 001:   6869 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1471, wps=101.5, ups=0.47, wpb=108.3, bsz=40, num_updates=6860, lr=4.89988e-05, gnorm=0.572, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27340
2023-01-05 19:33:49 - progress_bar.py[line:274] - INFO: epoch 001:   6879 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1472, wps=100.7, ups=0.46, wpb=109.6, bsz=40, num_updates=6870, lr=4.89943e-05, gnorm=0.526, clip=0, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=27362
2023-01-05 19:34:11 - progress_bar.py[line:274] - INFO: epoch 001:   6889 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1724, wps=101.8, ups=0.47, wpb=107.6, bsz=40, num_updates=6880, lr=4.89898e-05, gnorm=0.492, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27383
2023-01-05 19:34:32 - progress_bar.py[line:274] - INFO: epoch 001:   6899 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1684, wps=100.6, ups=0.46, wpb=108.4, bsz=40, num_updates=6890, lr=4.89853e-05, gnorm=0.569, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27405
2023-01-05 19:34:54 - progress_bar.py[line:274] - INFO: epoch 001:   6909 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1099, wps=103.8, ups=0.47, wpb=110.1, bsz=40, num_updates=6900, lr=4.89808e-05, gnorm=0.711, clip=20, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27427
2023-01-05 19:35:16 - progress_bar.py[line:274] - INFO: epoch 001:   6919 / 115845 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1512, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=6910, lr=4.89763e-05, gnorm=0.496, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=27449
2023-01-05 19:35:37 - progress_bar.py[line:274] - INFO: epoch 001:   6929 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.165, wps=102.1, ups=0.47, wpb=108.9, bsz=40, num_updates=6920, lr=4.89718e-05, gnorm=0.577, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27470
2023-01-05 19:35:59 - progress_bar.py[line:274] - INFO: epoch 001:   6939 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0986, wps=103.2, ups=0.48, wpb=108.1, bsz=40, num_updates=6930, lr=4.89673e-05, gnorm=0.669, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27491
2023-01-05 19:36:21 - progress_bar.py[line:274] - INFO: epoch 001:   6949 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1538, wps=101.5, ups=0.46, wpb=110.3, bsz=40, num_updates=6940, lr=4.89628e-05, gnorm=0.556, clip=10, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=27513
2023-01-05 19:36:43 - progress_bar.py[line:274] - INFO: epoch 001:   6959 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1596, wps=100.3, ups=0.46, wpb=109.9, bsz=40, num_updates=6950, lr=4.89583e-05, gnorm=0.762, clip=20, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27535
2023-01-05 19:37:04 - progress_bar.py[line:274] - INFO: epoch 001:   6969 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1683, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=6960, lr=4.89538e-05, gnorm=0.645, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27557
2023-01-05 19:37:26 - progress_bar.py[line:274] - INFO: epoch 001:   6979 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1549, wps=99, ups=0.46, wpb=108.1, bsz=40, num_updates=6970, lr=4.89493e-05, gnorm=0.578, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27579
2023-01-05 19:37:48 - progress_bar.py[line:274] - INFO: epoch 001:   6989 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1569, wps=101.7, ups=0.47, wpb=109.2, bsz=40, num_updates=6980, lr=4.89448e-05, gnorm=0.539, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27601
2023-01-05 19:38:10 - progress_bar.py[line:274] - INFO: epoch 001:   6999 / 115845 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1093, wps=100.1, ups=0.46, wpb=109.7, bsz=40, num_updates=6990, lr=4.89403e-05, gnorm=0.598, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27623
2023-01-05 19:38:32 - progress_bar.py[line:274] - INFO: epoch 001:   7009 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1571, wps=99.3, ups=0.46, wpb=108.2, bsz=40, num_updates=7000, lr=4.89358e-05, gnorm=0.545, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27645
2023-01-05 19:38:54 - progress_bar.py[line:274] - INFO: epoch 001:   7019 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1313, wps=99.8, ups=0.46, wpb=108.4, bsz=40, num_updates=7010, lr=4.89313e-05, gnorm=0.609, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27667
2023-01-05 19:39:16 - progress_bar.py[line:274] - INFO: epoch 001:   7029 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1356, wps=102.9, ups=0.47, wpb=110, bsz=40, num_updates=7020, lr=4.89268e-05, gnorm=0.68, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27688
2023-01-05 19:39:37 - progress_bar.py[line:274] - INFO: epoch 001:   7039 / 115845 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1842, wps=103, ups=0.47, wpb=110, bsz=40, num_updates=7030, lr=4.89223e-05, gnorm=0.45, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27710
2023-01-05 19:39:59 - progress_bar.py[line:274] - INFO: epoch 001:   7049 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1413, wps=102.9, ups=0.47, wpb=109, bsz=40, num_updates=7040, lr=4.89178e-05, gnorm=0.704, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27732
2023-01-05 19:40:21 - progress_bar.py[line:274] - INFO: epoch 001:   7059 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.173, wps=101.6, ups=0.46, wpb=110.5, bsz=40, num_updates=7050, lr=4.89133e-05, gnorm=0.542, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27754
2023-01-05 19:40:42 - progress_bar.py[line:274] - INFO: epoch 001:   7069 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1613, wps=105, ups=0.48, wpb=110.3, bsz=40, num_updates=7060, lr=4.89088e-05, gnorm=0.554, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27775
2023-01-05 19:41:04 - progress_bar.py[line:274] - INFO: epoch 001:   7079 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1795, wps=100.8, ups=0.46, wpb=109.7, bsz=40, num_updates=7070, lr=4.89043e-05, gnorm=0.611, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27797
2023-01-05 19:41:26 - progress_bar.py[line:274] - INFO: epoch 001:   7089 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1538, wps=101.2, ups=0.47, wpb=108.4, bsz=40, num_updates=7080, lr=4.88998e-05, gnorm=0.706, clip=10, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=27819
2023-01-05 19:41:48 - progress_bar.py[line:274] - INFO: epoch 001:   7099 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1472, wps=100, ups=0.46, wpb=107.6, bsz=40, num_updates=7090, lr=4.88954e-05, gnorm=0.732, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27840
2023-01-05 19:42:09 - progress_bar.py[line:274] - INFO: epoch 001:   7109 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1951, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=7100, lr=4.88909e-05, gnorm=0.602, clip=10, loss_scale=256, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=27862
2023-01-05 19:42:31 - progress_bar.py[line:274] - INFO: epoch 001:   7119 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1711, wps=101.8, ups=0.46, wpb=109.8, bsz=40, num_updates=7110, lr=4.88864e-05, gnorm=0.465, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27884
2023-01-05 19:42:53 - progress_bar.py[line:274] - INFO: epoch 001:   7129 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1545, wps=100.8, ups=0.47, wpb=107.5, bsz=40, num_updates=7120, lr=4.88819e-05, gnorm=0.585, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27906
2023-01-05 19:43:14 - progress_bar.py[line:274] - INFO: epoch 001:   7139 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1498, wps=102.6, ups=0.48, wpb=107.6, bsz=40, num_updates=7130, lr=4.88774e-05, gnorm=0.492, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27927
2023-01-05 19:43:36 - progress_bar.py[line:274] - INFO: epoch 001:   7149 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.201, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=7140, lr=4.88729e-05, gnorm=0.637, clip=10, loss_scale=256, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=27949
2023-01-05 19:43:58 - progress_bar.py[line:274] - INFO: epoch 001:   7159 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1925, wps=101.4, ups=0.46, wpb=110.8, bsz=40, num_updates=7150, lr=4.88684e-05, gnorm=0.566, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27971
2023-01-05 19:44:20 - progress_bar.py[line:274] - INFO: epoch 001:   7169 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1746, wps=99.9, ups=0.46, wpb=109.7, bsz=40, num_updates=7160, lr=4.88639e-05, gnorm=0.717, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27993
2023-01-05 19:44:42 - progress_bar.py[line:274] - INFO: epoch 001:   7179 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1746, wps=102.4, ups=0.46, wpb=110.4, bsz=40, num_updates=7170, lr=4.88594e-05, gnorm=0.492, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28015
2023-01-05 19:45:04 - progress_bar.py[line:274] - INFO: epoch 001:   7189 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1421, wps=100.7, ups=0.46, wpb=109.5, bsz=40, num_updates=7180, lr=4.88549e-05, gnorm=0.585, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28037
2023-01-05 19:45:25 - progress_bar.py[line:274] - INFO: epoch 001:   7199 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2031, wps=104.4, ups=0.48, wpb=109.2, bsz=40, num_updates=7190, lr=4.88504e-05, gnorm=0.659, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28058
2023-01-05 19:45:47 - progress_bar.py[line:274] - INFO: epoch 001:   7209 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1658, wps=101.5, ups=0.47, wpb=108.9, bsz=40, num_updates=7200, lr=4.88459e-05, gnorm=0.552, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28079
2023-01-05 19:46:09 - progress_bar.py[line:274] - INFO: epoch 001:   7219 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1684, wps=98.9, ups=0.46, wpb=108.5, bsz=40, num_updates=7210, lr=4.88414e-05, gnorm=0.614, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28102
2023-01-05 19:46:31 - progress_bar.py[line:274] - INFO: epoch 001:   7229 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1862, wps=104.3, ups=0.47, wpb=110.5, bsz=40, num_updates=7220, lr=4.88369e-05, gnorm=0.596, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=28123
2023-01-05 19:46:52 - progress_bar.py[line:274] - INFO: epoch 001:   7239 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1611, wps=101.6, ups=0.46, wpb=109.7, bsz=40, num_updates=7230, lr=4.88324e-05, gnorm=0.492, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28145
2023-01-05 19:47:14 - progress_bar.py[line:274] - INFO: epoch 001:   7249 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1981, wps=104, ups=0.48, wpb=108.3, bsz=40, num_updates=7240, lr=4.88279e-05, gnorm=0.558, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=28166
2023-01-05 19:47:35 - progress_bar.py[line:274] - INFO: epoch 001:   7259 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1707, wps=100.3, ups=0.47, wpb=107.3, bsz=40, num_updates=7250, lr=4.88234e-05, gnorm=0.505, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=28188
2023-01-05 19:47:57 - progress_bar.py[line:274] - INFO: epoch 001:   7269 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2228, wps=99.2, ups=0.46, wpb=108.9, bsz=40, num_updates=7260, lr=4.88189e-05, gnorm=0.63, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28210
2023-01-05 19:48:19 - progress_bar.py[line:274] - INFO: epoch 001:   7279 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1959, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=7270, lr=4.88144e-05, gnorm=0.567, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28232
2023-01-05 19:48:42 - progress_bar.py[line:274] - INFO: epoch 001:   7289 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.202, wps=99.5, ups=0.45, wpb=110.2, bsz=40, num_updates=7280, lr=4.88099e-05, gnorm=0.802, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28254
2023-01-05 19:49:04 - progress_bar.py[line:274] - INFO: epoch 001:   7299 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.206, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=7290, lr=4.88054e-05, gnorm=0.529, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=28276
2023-01-05 19:49:26 - progress_bar.py[line:274] - INFO: epoch 001:   7309 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1667, wps=99.7, ups=0.46, wpb=109.5, bsz=40, num_updates=7300, lr=4.88009e-05, gnorm=0.488, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28299
2023-01-05 19:49:48 - progress_bar.py[line:274] - INFO: epoch 001:   7319 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.153, wps=101.5, ups=0.46, wpb=109.6, bsz=40, num_updates=7310, lr=4.87964e-05, gnorm=0.984, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28320
2023-01-05 19:50:10 - progress_bar.py[line:274] - INFO: epoch 001:   7329 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.201, wps=100.9, ups=0.46, wpb=109, bsz=40, num_updates=7320, lr=4.87919e-05, gnorm=0.734, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28342
2023-01-05 19:50:32 - progress_bar.py[line:274] - INFO: epoch 001:   7339 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2133, wps=98.9, ups=0.46, wpb=107.5, bsz=40, num_updates=7330, lr=4.87875e-05, gnorm=0.675, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28364
2023-01-05 19:50:54 - progress_bar.py[line:274] - INFO: epoch 001:   7349 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2, wps=100.7, ups=0.46, wpb=108.4, bsz=40, num_updates=7340, lr=4.8783e-05, gnorm=0.723, clip=10, loss_scale=256, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=28386
2023-01-05 19:51:15 - progress_bar.py[line:274] - INFO: epoch 001:   7359 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2312, wps=103.6, ups=0.47, wpb=109.1, bsz=40, num_updates=7350, lr=4.87785e-05, gnorm=0.754, clip=10, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=28408
2023-01-05 19:51:37 - progress_bar.py[line:274] - INFO: epoch 001:   7369 / 115845 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1902, wps=100, ups=0.46, wpb=108.7, bsz=40, num_updates=7360, lr=4.8774e-05, gnorm=0.519, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28430
2023-01-05 19:51:58 - progress_bar.py[line:274] - INFO: epoch 001:   7379 / 115845 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2344, wps=105.6, ups=0.48, wpb=109.7, bsz=40, num_updates=7370, lr=4.87695e-05, gnorm=0.55, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28451
2023-01-05 19:52:20 - progress_bar.py[line:274] - INFO: epoch 001:   7389 / 115845 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2041, wps=103.7, ups=0.47, wpb=110.1, bsz=40, num_updates=7380, lr=4.8765e-05, gnorm=0.905, clip=20, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=28472
2023-01-05 19:52:41 - progress_bar.py[line:274] - INFO: epoch 001:   7399 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2196, wps=101.9, ups=0.47, wpb=107.9, bsz=40, num_updates=7390, lr=4.87605e-05, gnorm=0.677, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28494
2023-01-05 19:53:03 - progress_bar.py[line:274] - INFO: epoch 001:   7409 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1658, wps=102.3, ups=0.47, wpb=109.5, bsz=40, num_updates=7400, lr=4.8756e-05, gnorm=0.619, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28516
2023-01-05 19:53:25 - progress_bar.py[line:274] - INFO: epoch 001:   7419 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2289, wps=101.5, ups=0.46, wpb=109.3, bsz=40, num_updates=7410, lr=4.87515e-05, gnorm=0.565, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28538
2023-01-05 19:53:47 - progress_bar.py[line:274] - INFO: epoch 001:   7429 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1842, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=7420, lr=4.8747e-05, gnorm=0.764, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28560
2023-01-05 19:54:08 - progress_bar.py[line:274] - INFO: epoch 001:   7439 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1699, wps=101.2, ups=0.47, wpb=107.9, bsz=40, num_updates=7430, lr=4.87425e-05, gnorm=0.734, clip=30, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=28581
2023-01-05 19:54:30 - progress_bar.py[line:274] - INFO: epoch 001:   7449 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1961, wps=102.3, ups=0.47, wpb=109, bsz=40, num_updates=7440, lr=4.8738e-05, gnorm=0.6, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28603
2023-01-05 19:54:52 - progress_bar.py[line:274] - INFO: epoch 001:   7459 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2065, wps=104.5, ups=0.47, wpb=111.7, bsz=40, num_updates=7450, lr=4.87335e-05, gnorm=0.463, clip=0, loss_scale=512, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=28624
2023-01-05 19:55:14 - progress_bar.py[line:274] - INFO: epoch 001:   7469 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1667, wps=101.5, ups=0.46, wpb=110.3, bsz=40, num_updates=7460, lr=4.8729e-05, gnorm=0.512, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=28646
2023-01-05 19:55:18 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-05 19:55:37 - progress_bar.py[line:274] - INFO: epoch 001:   7480 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.429, nsentences=40, sample_size=108.429, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2033, wps=98.4, ups=0.43, wpb=108.4, bsz=40, num_updates=7470, lr=4.87245e-05, gnorm=0.935, clip=10, loss_scale=256, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=28670
2023-01-05 19:55:59 - progress_bar.py[line:274] - INFO: epoch 001:   7490 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2277, wps=103.1, ups=0.47, wpb=109, bsz=40, num_updates=7480, lr=4.872e-05, gnorm=0.767, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28691
2023-01-05 19:56:21 - progress_bar.py[line:274] - INFO: epoch 001:   7500 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2048, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=7490, lr=4.87155e-05, gnorm=0.583, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28713
2023-01-05 19:56:43 - progress_bar.py[line:274] - INFO: epoch 001:   7510 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1786, wps=100.2, ups=0.45, wpb=110.2, bsz=40, num_updates=7500, lr=4.8711e-05, gnorm=0.545, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28736
2023-01-05 19:57:05 - progress_bar.py[line:274] - INFO: epoch 001:   7520 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1731, wps=98.9, ups=0.46, wpb=108.3, bsz=40, num_updates=7510, lr=4.87065e-05, gnorm=0.59, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=28758
2023-01-05 19:57:27 - progress_bar.py[line:274] - INFO: epoch 001:   7530 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.25, wps=101.5, ups=0.46, wpb=109.1, bsz=40, num_updates=7520, lr=4.8702e-05, gnorm=0.59, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=28780
2023-01-05 19:57:49 - progress_bar.py[line:274] - INFO: epoch 001:   7540 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2217, wps=99.6, ups=0.46, wpb=108.5, bsz=40, num_updates=7530, lr=4.86975e-05, gnorm=0.573, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=28802
2023-01-05 19:58:11 - progress_bar.py[line:274] - INFO: epoch 001:   7550 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1719, wps=102.2, ups=0.46, wpb=110.4, bsz=40, num_updates=7540, lr=4.8693e-05, gnorm=0.612, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28824
2023-01-05 19:58:32 - progress_bar.py[line:274] - INFO: epoch 001:   7560 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1832, wps=103.5, ups=0.47, wpb=109.2, bsz=40, num_updates=7550, lr=4.86885e-05, gnorm=0.678, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28845
2023-01-05 19:58:54 - progress_bar.py[line:274] - INFO: epoch 001:   7570 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2132, wps=101.8, ups=0.47, wpb=109.2, bsz=40, num_updates=7560, lr=4.8684e-05, gnorm=0.48, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=28867
2023-01-05 19:59:16 - progress_bar.py[line:274] - INFO: epoch 001:   7580 / 115845 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1946, wps=101.3, ups=0.46, wpb=109.2, bsz=40, num_updates=7570, lr=4.86795e-05, gnorm=0.614, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28889
2023-01-05 19:59:37 - progress_bar.py[line:274] - INFO: epoch 001:   7590 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2149, wps=102.9, ups=0.48, wpb=107.5, bsz=40, num_updates=7580, lr=4.86751e-05, gnorm=0.596, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28910
2023-01-05 19:59:59 - progress_bar.py[line:274] - INFO: epoch 001:   7600 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2263, wps=101.9, ups=0.46, wpb=110.8, bsz=40, num_updates=7590, lr=4.86706e-05, gnorm=0.65, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28932
2023-01-05 20:00:21 - progress_bar.py[line:274] - INFO: epoch 001:   7610 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2222, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=7600, lr=4.86661e-05, gnorm=0.572, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28954
2023-01-05 20:00:42 - progress_bar.py[line:274] - INFO: epoch 001:   7620 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2562, wps=103.9, ups=0.48, wpb=107.7, bsz=40, num_updates=7610, lr=4.86616e-05, gnorm=0.493, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28975
2023-01-05 20:01:04 - progress_bar.py[line:274] - INFO: epoch 001:   7630 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2323, wps=104.7, ups=0.47, wpb=110.5, bsz=40, num_updates=7620, lr=4.86571e-05, gnorm=0.54, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28996
2023-01-05 20:01:26 - progress_bar.py[line:274] - INFO: epoch 001:   7640 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2129, wps=100.9, ups=0.47, wpb=108.4, bsz=40, num_updates=7630, lr=4.86526e-05, gnorm=0.606, clip=0, loss_scale=256, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=29018
2023-01-05 20:01:48 - progress_bar.py[line:274] - INFO: epoch 001:   7650 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1706, wps=100.2, ups=0.46, wpb=108.8, bsz=40, num_updates=7640, lr=4.86481e-05, gnorm=0.678, clip=10, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=29040
2023-01-05 20:02:09 - progress_bar.py[line:274] - INFO: epoch 001:   7660 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1969, wps=103.8, ups=0.47, wpb=110, bsz=40, num_updates=7650, lr=4.86436e-05, gnorm=0.538, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29062
2023-01-05 20:02:31 - progress_bar.py[line:274] - INFO: epoch 001:   7670 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2077, wps=100.4, ups=0.46, wpb=108.5, bsz=40, num_updates=7660, lr=4.86391e-05, gnorm=0.595, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=29084
2023-01-05 20:02:53 - progress_bar.py[line:274] - INFO: epoch 001:   7680 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1722, wps=102.5, ups=0.47, wpb=108.5, bsz=40, num_updates=7670, lr=4.86346e-05, gnorm=0.545, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=29105
2023-01-05 20:03:14 - progress_bar.py[line:274] - INFO: epoch 001:   7690 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.1917, wps=102.4, ups=0.47, wpb=109.5, bsz=40, num_updates=7680, lr=4.86301e-05, gnorm=0.467, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29127
2023-01-05 20:03:36 - progress_bar.py[line:274] - INFO: epoch 001:   7700 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2374, wps=102.1, ups=0.47, wpb=108.1, bsz=40, num_updates=7690, lr=4.86256e-05, gnorm=0.508, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29149
2023-01-05 20:03:58 - progress_bar.py[line:274] - INFO: epoch 001:   7710 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.205, wps=102, ups=0.47, wpb=109.4, bsz=40, num_updates=7700, lr=4.86211e-05, gnorm=0.53, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29170
2023-01-05 20:04:20 - progress_bar.py[line:274] - INFO: epoch 001:   7720 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2344, wps=98.9, ups=0.46, wpb=108.3, bsz=40, num_updates=7710, lr=4.86166e-05, gnorm=0.566, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=29193
2023-01-05 20:04:42 - progress_bar.py[line:274] - INFO: epoch 001:   7730 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2167, wps=99.3, ups=0.46, wpb=108.5, bsz=40, num_updates=7720, lr=4.86121e-05, gnorm=0.578, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=29215
2023-01-05 20:05:04 - progress_bar.py[line:274] - INFO: epoch 001:   7740 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.239, wps=100.9, ups=0.46, wpb=109.2, bsz=40, num_updates=7730, lr=4.86076e-05, gnorm=0.812, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29237
2023-01-05 20:05:25 - progress_bar.py[line:274] - INFO: epoch 001:   7750 / 115845 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2412, wps=103, ups=0.47, wpb=108.5, bsz=40, num_updates=7740, lr=4.86031e-05, gnorm=0.734, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29258
2023-01-05 20:05:47 - progress_bar.py[line:274] - INFO: epoch 001:   7760 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2, wps=99.5, ups=0.46, wpb=108.4, bsz=40, num_updates=7750, lr=4.85986e-05, gnorm=0.571, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=29280
2023-01-05 20:06:09 - progress_bar.py[line:274] - INFO: epoch 001:   7770 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2092, wps=103.1, ups=0.47, wpb=109.3, bsz=40, num_updates=7760, lr=4.85941e-05, gnorm=0.473, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=29302
2023-01-05 20:06:31 - progress_bar.py[line:274] - INFO: epoch 001:   7780 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1481, wps=102.6, ups=0.47, wpb=109.3, bsz=40, num_updates=7770, lr=4.85896e-05, gnorm=0.522, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29323
2023-01-05 20:06:53 - progress_bar.py[line:274] - INFO: epoch 001:   7790 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2823, wps=99.7, ups=0.46, wpb=108.5, bsz=40, num_updates=7780, lr=4.85851e-05, gnorm=0.583, clip=10, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=29345
2023-01-05 20:07:15 - progress_bar.py[line:274] - INFO: epoch 001:   7800 / 115845 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1919, wps=99.1, ups=0.46, wpb=108.7, bsz=40, num_updates=7790, lr=4.85806e-05, gnorm=0.507, clip=0, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=29368
2023-01-05 20:07:36 - progress_bar.py[line:274] - INFO: epoch 001:   7810 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2105, wps=103.8, ups=0.48, wpb=108.5, bsz=40, num_updates=7800, lr=4.85761e-05, gnorm=0.572, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29389
2023-01-05 20:07:58 - progress_bar.py[line:274] - INFO: epoch 001:   7820 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2172, wps=101.6, ups=0.46, wpb=109.5, bsz=40, num_updates=7810, lr=4.85716e-05, gnorm=0.471, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29411
2023-01-05 20:08:20 - progress_bar.py[line:274] - INFO: epoch 001:   7830 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3058, wps=101.4, ups=0.46, wpb=109.6, bsz=40, num_updates=7820, lr=4.85672e-05, gnorm=0.564, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29433
2023-01-05 20:08:42 - progress_bar.py[line:274] - INFO: epoch 001:   7840 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.268, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=7830, lr=4.85627e-05, gnorm=0.661, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29455
2023-01-05 20:09:04 - progress_bar.py[line:274] - INFO: epoch 001:   7850 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2161, wps=97, ups=0.45, wpb=108.6, bsz=40, num_updates=7840, lr=4.85582e-05, gnorm=0.561, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29477
2023-01-05 20:09:26 - progress_bar.py[line:274] - INFO: epoch 001:   7860 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2989, wps=100.7, ups=0.46, wpb=109.3, bsz=40, num_updates=7850, lr=4.85537e-05, gnorm=0.584, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=29499
2023-01-05 20:09:48 - progress_bar.py[line:274] - INFO: epoch 001:   7870 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1971, wps=102.7, ups=0.48, wpb=108, bsz=40, num_updates=7860, lr=4.85492e-05, gnorm=0.52, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=29520
2023-01-05 20:10:09 - progress_bar.py[line:274] - INFO: epoch 001:   7880 / 115845 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2293, wps=100.1, ups=0.46, wpb=107.7, bsz=40, num_updates=7870, lr=4.85447e-05, gnorm=0.461, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29542
2023-01-05 20:10:32 - progress_bar.py[line:274] - INFO: epoch 001:   7890 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2439, wps=98.1, ups=0.46, wpb=107.6, bsz=40, num_updates=7880, lr=4.85402e-05, gnorm=0.703, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29564
2023-01-05 20:10:54 - progress_bar.py[line:274] - INFO: epoch 001:   7900 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2379, wps=99.1, ups=0.46, wpb=107.6, bsz=40, num_updates=7890, lr=4.85357e-05, gnorm=0.698, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=29586
2023-01-05 20:11:15 - progress_bar.py[line:274] - INFO: epoch 001:   7910 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1542, wps=100, ups=0.46, wpb=107.9, bsz=40, num_updates=7900, lr=4.85312e-05, gnorm=0.476, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29608
2023-01-05 20:11:37 - progress_bar.py[line:274] - INFO: epoch 001:   7920 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.1957, wps=105.4, ups=0.47, wpb=111.1, bsz=40, num_updates=7910, lr=4.85267e-05, gnorm=0.609, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29629
2023-01-05 20:11:59 - progress_bar.py[line:274] - INFO: epoch 001:   7930 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2383, wps=99.5, ups=0.45, wpb=109.9, bsz=40, num_updates=7920, lr=4.85222e-05, gnorm=0.661, clip=0, loss_scale=256, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=29652
2023-01-05 20:12:21 - progress_bar.py[line:274] - INFO: epoch 001:   7940 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2316, wps=102.7, ups=0.47, wpb=110.2, bsz=40, num_updates=7930, lr=4.85177e-05, gnorm=0.528, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=29673
2023-01-05 20:12:42 - progress_bar.py[line:274] - INFO: epoch 001:   7950 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2228, wps=100.8, ups=0.47, wpb=108.2, bsz=40, num_updates=7940, lr=4.85132e-05, gnorm=0.476, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29695
2023-01-05 20:13:04 - progress_bar.py[line:274] - INFO: epoch 001:   7960 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.31, wps=102.1, ups=0.46, wpb=109.9, bsz=40, num_updates=7950, lr=4.85087e-05, gnorm=0.639, clip=10, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=29717
2023-01-05 20:13:26 - progress_bar.py[line:274] - INFO: epoch 001:   7970 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2245, wps=102, ups=0.47, wpb=109.1, bsz=40, num_updates=7960, lr=4.85042e-05, gnorm=0.599, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29739
2023-01-05 20:13:47 - progress_bar.py[line:274] - INFO: epoch 001:   7980 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2564, wps=102.5, ups=0.47, wpb=110.1, bsz=40, num_updates=7970, lr=4.84997e-05, gnorm=0.583, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29760
2023-01-05 20:14:09 - progress_bar.py[line:274] - INFO: epoch 001:   7990 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2649, wps=101.5, ups=0.46, wpb=109.7, bsz=40, num_updates=7980, lr=4.84952e-05, gnorm=0.598, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29782
2023-01-05 20:14:31 - progress_bar.py[line:274] - INFO: epoch 001:   8000 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.26, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=7990, lr=4.84907e-05, gnorm=0.482, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=29804
2023-01-05 20:14:53 - progress_bar.py[line:274] - INFO: epoch 001:   8010 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2426, wps=100.3, ups=0.46, wpb=109.2, bsz=40, num_updates=8000, lr=4.84862e-05, gnorm=0.491, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29826
2023-01-05 20:14:53 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-05 20:14:55 - train.py[line:549] - INFO: 0 / 4988
2023-01-05 20:14:55 - train.py[line:551] - INFO: load:0.90 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-05 20:14:56 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 9.26 GiB already allocated; 3.54 GiB free; 33.55 GiB reserved in total by PyTorch)
2023-01-05 20:14:56 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-05 20:14:56 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 15        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9485 MB |   10710 MB |    4191 TB |    4191 TB |
|       from large pool |    9310 MB |   10535 MB |    4189 TB |    4189 TB |
|       from small pool |     174 MB |     175 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9485 MB |   10710 MB |    4191 TB |    4191 TB |
|       from large pool |    9310 MB |   10535 MB |    4189 TB |    4189 TB |
|       from small pool |     174 MB |     175 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   34360 MB |   34838 MB |  215842 MB |  181482 MB |
|       from large pool |   34184 MB |   34656 MB |  215462 MB |  181278 MB |
|       from small pool |     176 MB |     182 MB |     380 MB |     204 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24874 MB |   29353 MB |    4335 TB |    4335 TB |
|       from large pool |   24873 MB |   29350 MB |    4333 TB |    4333 TB |
|       from small pool |       1 MB |       3 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  196586 K  |  196581 K  |
|       from large pool |     698    |     710    |   60966 K  |   60966 K  |
|       from small pool |    3925    |    3943    |  135619 K  |  135615 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  196586 K  |  196581 K  |
|       from large pool |     698    |     710    |   60966 K  |   60966 K  |
|       from small pool |    3925    |    3943    |  135619 K  |  135615 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     192    |     196    |     626    |     434    |
|       from large pool |     104    |     105    |     436    |     332    |
|       from small pool |      88    |      91    |     190    |     102    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     132    |     133    |  147673 K  |  147673 K  |
|       from large pool |      65    |      65    |   30951 K  |   30950 K  |
|       from small pool |      67    |      74    |  116722 K  |  116722 K  |
|===========================================================================|

2023-01-05 20:14:56 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-05 20:17:28 - train.py[line:549] - INFO: 200 / 4988
2023-01-05 20:17:28 - train.py[line:551] - INFO: load:0.93 valid_run:153.54 task_valid:149.20 collect_output:3.21
2023-01-05 20:19:58 - train.py[line:549] - INFO: 400 / 4988
2023-01-05 20:19:58 - train.py[line:551] - INFO: load:0.95 valid_run:303.36 task_valid:293.44 collect_output:7.69
2023-01-05 20:22:32 - train.py[line:549] - INFO: 600 / 4988
2023-01-05 20:22:32 - train.py[line:551] - INFO: load:0.98 valid_run:456.61 task_valid:437.55 collect_output:15.77
2023-01-05 20:25:02 - train.py[line:549] - INFO: 800 / 4988
2023-01-05 20:25:02 - train.py[line:551] - INFO: load:1.01 valid_run:606.62 task_valid:583.46 collect_output:18.81
2023-01-05 20:27:35 - train.py[line:549] - INFO: 1000 / 4988
2023-01-05 20:27:35 - train.py[line:551] - INFO: load:1.03 valid_run:759.83 task_valid:731.59 collect_output:22.78
2023-01-05 20:30:08 - train.py[line:549] - INFO: 1200 / 4988
2023-01-05 20:30:08 - train.py[line:551] - INFO: load:1.06 valid_run:912.64 task_valid:877.98 collect_output:28.13
2023-01-05 20:32:42 - train.py[line:549] - INFO: 1400 / 4988
2023-01-05 20:32:42 - train.py[line:551] - INFO: load:1.09 valid_run:1066.96 task_valid:1024.79 collect_output:34.58
2023-01-05 20:35:15 - train.py[line:549] - INFO: 1600 / 4988
2023-01-05 20:35:15 - train.py[line:551] - INFO: load:1.11 valid_run:1219.10 task_valid:1166.58 collect_output:43.86
2023-01-05 20:37:45 - train.py[line:549] - INFO: 1800 / 4988
2023-01-05 20:37:45 - train.py[line:551] - INFO: load:1.14 valid_run:1369.58 task_valid:1312.07 collect_output:47.79
2023-01-05 20:40:15 - train.py[line:549] - INFO: 2000 / 4988
2023-01-05 20:40:15 - train.py[line:551] - INFO: load:1.17 valid_run:1519.35 task_valid:1456.20 collect_output:52.37
2023-01-05 20:42:46 - train.py[line:549] - INFO: 2200 / 4988
2023-01-05 20:42:46 - train.py[line:551] - INFO: load:1.19 valid_run:1669.82 task_valid:1601.80 collect_output:56.20
2023-01-05 20:45:16 - train.py[line:549] - INFO: 2400 / 4988
2023-01-05 20:45:16 - train.py[line:551] - INFO: load:1.22 valid_run:1820.55 task_valid:1747.47 collect_output:60.19
2023-01-05 20:47:47 - train.py[line:549] - INFO: 2600 / 4988
2023-01-05 20:47:47 - train.py[line:551] - INFO: load:1.25 valid_run:1971.23 task_valid:1889.94 collect_output:67.33
2023-01-05 20:50:19 - train.py[line:549] - INFO: 2800 / 4988
2023-01-05 20:50:19 - train.py[line:551] - INFO: load:1.27 valid_run:2122.68 task_valid:2036.23 collect_output:71.41
2023-01-05 20:52:50 - train.py[line:549] - INFO: 3000 / 4988
2023-01-05 20:52:50 - train.py[line:551] - INFO: load:1.30 valid_run:2273.68 task_valid:2183.64 collect_output:73.89
2023-01-05 20:55:21 - train.py[line:549] - INFO: 3200 / 4988
2023-01-05 20:55:21 - train.py[line:551] - INFO: load:1.33 valid_run:2424.96 task_valid:2329.12 collect_output:78.59
2023-01-05 20:57:54 - train.py[line:549] - INFO: 3400 / 4988
2023-01-05 20:57:54 - train.py[line:551] - INFO: load:1.35 valid_run:2577.84 task_valid:2475.47 collect_output:84.07
2023-01-05 21:00:26 - train.py[line:549] - INFO: 3600 / 4988
2023-01-05 21:00:26 - train.py[line:551] - INFO: load:1.38 valid_run:2729.56 task_valid:2623.49 collect_output:86.70
2023-01-05 21:02:55 - train.py[line:549] - INFO: 3800 / 4988
2023-01-05 21:02:55 - train.py[line:551] - INFO: load:1.41 valid_run:2878.67 task_valid:2766.01 collect_output:92.23
2023-01-05 21:05:27 - train.py[line:549] - INFO: 4000 / 4988
2023-01-05 21:05:27 - train.py[line:551] - INFO: load:1.43 valid_run:3029.99 task_valid:2912.21 collect_output:96.28
2023-01-05 21:08:00 - train.py[line:549] - INFO: 4200 / 4988
2023-01-05 21:08:00 - train.py[line:551] - INFO: load:1.46 valid_run:3183.04 task_valid:3057.89 collect_output:102.55
2023-01-05 21:10:30 - train.py[line:549] - INFO: 4400 / 4988
2023-01-05 21:10:30 - train.py[line:551] - INFO: load:1.48 valid_run:3333.64 task_valid:3203.63 collect_output:106.33
2023-01-05 21:13:02 - train.py[line:549] - INFO: 4600 / 4988
2023-01-05 21:13:02 - train.py[line:551] - INFO: load:1.51 valid_run:3485.66 task_valid:3350.45 collect_output:110.45
2023-01-05 21:15:35 - train.py[line:549] - INFO: 4800 / 4988
2023-01-05 21:15:35 - train.py[line:551] - INFO: load:1.53 valid_run:3637.85 task_valid:3497.81 collect_output:114.20

====================================================================================================
SGG eval:     R @ 50: 0.5571;     R @ 100: 0.6263;     R @ 500: 0.6694;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3408;    mR @ 100: 0.4206;    mR @ 500: 0.4990;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.3182) (growing on:0.2500) (hanging from:0.4516) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9183) (says:0.0000) (sitting on:0.7353) (standing on:0.2133) (using:0.6000) (walking in:0.0000) (walking on:0.7838) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5571;     R @ 100: 0.6263;     R @ 500: 0.6694;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3408;    mR @ 100: 0.4206;    mR @ 500: 0.4990;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.3182) (growing on:0.2500) (hanging from:0.4516) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9183) (says:0.0000) (sitting on:0.7353) (standing on:0.2133) (using:0.6000) (walking in:0.0000) (walking on:0.7838) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-05 21:18:07 - train.py[line:487] - INFO: 0.6262508785332315
2023-01-05 21:18:07 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-05 21:18:07 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.336 | loss_v1 0 | loss_v2 0 | nll_loss 0.178 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.626251 | ppl 1.13 | vqa_score 0.5203 | wps 118.3 | wpb 89.9 | bsz 30 | num_updates 8000 | best_R@100 0.642554
2023-01-05 21:18:07 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2023-01-05 21:18:07 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_8000.pt
2023-01-05 21:18:55 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_8000.pt
2023-01-05 21:20:29 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.6262508785332315) (writing took 141.9737839847803 seconds)
2023-01-05 21:20:51 - progress_bar.py[line:274] - INFO: epoch 001:   8020 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2356, wps=0.6, ups=0, wpb=109.1, bsz=40, num_updates=8010, lr=4.84817e-05, gnorm=0.532, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=33784
2023-01-05 21:21:12 - progress_bar.py[line:274] - INFO: epoch 001:   8030 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2727, wps=104.1, ups=0.47, wpb=110.4, bsz=40, num_updates=8020, lr=4.84772e-05, gnorm=0.544, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33805
2023-01-05 21:21:34 - progress_bar.py[line:274] - INFO: epoch 001:   8040 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2304, wps=100.4, ups=0.46, wpb=108.9, bsz=40, num_updates=8030, lr=4.84727e-05, gnorm=0.544, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=33827
2023-01-05 21:21:56 - progress_bar.py[line:274] - INFO: epoch 001:   8050 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2574, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=8040, lr=4.84682e-05, gnorm=0.477, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=33848
2023-01-05 21:22:17 - progress_bar.py[line:274] - INFO: epoch 001:   8060 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2932, wps=104.5, ups=0.48, wpb=109.2, bsz=40, num_updates=8050, lr=4.84637e-05, gnorm=0.493, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=33870
2023-01-05 21:22:39 - progress_bar.py[line:274] - INFO: epoch 001:   8070 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2513, wps=102.4, ups=0.47, wpb=109.8, bsz=40, num_updates=8060, lr=4.84592e-05, gnorm=0.472, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=33891
2023-01-05 21:23:00 - progress_bar.py[line:274] - INFO: epoch 001:   8080 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2755, wps=103.2, ups=0.47, wpb=109.3, bsz=40, num_updates=8070, lr=4.84548e-05, gnorm=0.566, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33913
2023-01-05 21:23:22 - progress_bar.py[line:274] - INFO: epoch 001:   8090 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2547, wps=99.8, ups=0.46, wpb=108.2, bsz=40, num_updates=8080, lr=4.84503e-05, gnorm=0.512, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=33935
2023-01-05 21:23:44 - progress_bar.py[line:274] - INFO: epoch 001:   8100 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2389, wps=100.6, ups=0.47, wpb=107.9, bsz=40, num_updates=8090, lr=4.84458e-05, gnorm=0.517, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33956
2023-01-05 21:24:05 - progress_bar.py[line:274] - INFO: epoch 001:   8110 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.198, wps=102.5, ups=0.47, wpb=109.2, bsz=40, num_updates=8100, lr=4.84413e-05, gnorm=0.525, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=33978
2023-01-05 21:24:27 - progress_bar.py[line:274] - INFO: epoch 001:   8120 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2802, wps=100.8, ups=0.46, wpb=109.9, bsz=40, num_updates=8110, lr=4.84368e-05, gnorm=0.615, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34000
2023-01-05 21:24:49 - progress_bar.py[line:274] - INFO: epoch 001:   8130 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.1958, wps=102.1, ups=0.46, wpb=110.1, bsz=40, num_updates=8120, lr=4.84323e-05, gnorm=0.458, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=34022
2023-01-05 21:25:11 - progress_bar.py[line:274] - INFO: epoch 001:   8140 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.264, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=8130, lr=4.84278e-05, gnorm=0.621, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34044
2023-01-05 21:25:33 - progress_bar.py[line:274] - INFO: epoch 001:   8150 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2912, wps=100.6, ups=0.46, wpb=110.1, bsz=40, num_updates=8140, lr=4.84233e-05, gnorm=0.831, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34066
2023-01-05 21:25:55 - progress_bar.py[line:274] - INFO: epoch 001:   8160 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3148, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=8150, lr=4.84188e-05, gnorm=0.595, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=34087
2023-01-05 21:26:16 - progress_bar.py[line:274] - INFO: epoch 001:   8170 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2398, wps=102, ups=0.46, wpb=109.7, bsz=40, num_updates=8160, lr=4.84143e-05, gnorm=0.59, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34109
2023-01-05 21:26:38 - progress_bar.py[line:274] - INFO: epoch 001:   8180 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3279, wps=104.8, ups=0.47, wpb=111, bsz=40, num_updates=8170, lr=4.84098e-05, gnorm=0.479, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34131
2023-01-05 21:27:00 - progress_bar.py[line:274] - INFO: epoch 001:   8190 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.265, wps=100.8, ups=0.46, wpb=109.8, bsz=40, num_updates=8180, lr=4.84053e-05, gnorm=0.907, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=34153
2023-01-05 21:27:22 - progress_bar.py[line:274] - INFO: epoch 001:   8200 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2714, wps=101.6, ups=0.46, wpb=109.7, bsz=40, num_updates=8190, lr=4.84008e-05, gnorm=0.456, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=34174
2023-01-05 21:27:43 - progress_bar.py[line:274] - INFO: epoch 001:   8210 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2775, wps=101.4, ups=0.47, wpb=108.5, bsz=40, num_updates=8200, lr=4.83963e-05, gnorm=0.563, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34196
2023-01-05 21:28:05 - progress_bar.py[line:274] - INFO: epoch 001:   8220 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2591, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=8210, lr=4.83918e-05, gnorm=0.512, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34218
2023-01-05 21:28:27 - progress_bar.py[line:274] - INFO: epoch 001:   8230 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2607, wps=99.8, ups=0.46, wpb=109.1, bsz=40, num_updates=8220, lr=4.83873e-05, gnorm=0.505, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=34240
2023-01-05 21:28:49 - progress_bar.py[line:274] - INFO: epoch 001:   8240 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2794, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=8230, lr=4.83828e-05, gnorm=0.578, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34262
2023-01-05 21:29:11 - progress_bar.py[line:274] - INFO: epoch 001:   8250 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.266, wps=100, ups=0.46, wpb=108.2, bsz=40, num_updates=8240, lr=4.83783e-05, gnorm=0.58, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=34283
2023-01-05 21:29:33 - progress_bar.py[line:274] - INFO: epoch 001:   8260 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3394, wps=99.2, ups=0.45, wpb=109.2, bsz=40, num_updates=8250, lr=4.83738e-05, gnorm=0.555, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34306
2023-01-05 21:29:55 - progress_bar.py[line:274] - INFO: epoch 001:   8270 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2637, wps=100, ups=0.46, wpb=108.2, bsz=40, num_updates=8260, lr=4.83693e-05, gnorm=0.462, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34328
2023-01-05 21:30:17 - progress_bar.py[line:274] - INFO: epoch 001:   8280 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3, wps=100.9, ups=0.46, wpb=109, bsz=40, num_updates=8270, lr=4.83648e-05, gnorm=0.451, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=34349
2023-01-05 21:30:39 - progress_bar.py[line:274] - INFO: epoch 001:   8290 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2446, wps=100.4, ups=0.46, wpb=109.9, bsz=40, num_updates=8280, lr=4.83603e-05, gnorm=0.496, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=34372
2023-01-05 21:31:01 - progress_bar.py[line:274] - INFO: epoch 001:   8300 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.23, wps=99.9, ups=0.46, wpb=108, bsz=40, num_updates=8290, lr=4.83558e-05, gnorm=0.456, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=34393
2023-01-05 21:31:23 - progress_bar.py[line:274] - INFO: epoch 001:   8310 / 115845 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2864, wps=97.8, ups=0.45, wpb=109.3, bsz=40, num_updates=8300, lr=4.83513e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=34416
2023-01-05 21:31:45 - progress_bar.py[line:274] - INFO: epoch 001:   8320 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2747, wps=102.5, ups=0.47, wpb=109.8, bsz=40, num_updates=8310, lr=4.83469e-05, gnorm=0.699, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34438
2023-01-05 21:32:06 - progress_bar.py[line:274] - INFO: epoch 001:   8330 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3092, wps=102.9, ups=0.48, wpb=108.1, bsz=40, num_updates=8320, lr=4.83424e-05, gnorm=0.498, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34459
2023-01-05 21:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   8340 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.288, wps=102.1, ups=0.47, wpb=109.5, bsz=40, num_updates=8330, lr=4.83379e-05, gnorm=0.581, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34481
2023-01-05 21:32:50 - progress_bar.py[line:274] - INFO: epoch 001:   8350 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2755, wps=101.2, ups=0.46, wpb=109.1, bsz=40, num_updates=8340, lr=4.83334e-05, gnorm=0.569, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34502
2023-01-05 21:33:11 - progress_bar.py[line:274] - INFO: epoch 001:   8360 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3107, wps=102.1, ups=0.47, wpb=109.5, bsz=40, num_updates=8350, lr=4.83289e-05, gnorm=0.4, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34524
2023-01-05 21:33:33 - progress_bar.py[line:274] - INFO: epoch 001:   8370 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2819, wps=100.2, ups=0.46, wpb=109.3, bsz=40, num_updates=8360, lr=4.83244e-05, gnorm=0.515, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=34546
2023-01-05 21:33:55 - progress_bar.py[line:274] - INFO: epoch 001:   8380 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2642, wps=101, ups=0.47, wpb=108.4, bsz=40, num_updates=8370, lr=4.83199e-05, gnorm=0.464, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=34568
2023-01-05 21:34:18 - progress_bar.py[line:274] - INFO: epoch 001:   8390 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.274, wps=98.9, ups=0.45, wpb=108.7, bsz=40, num_updates=8380, lr=4.83154e-05, gnorm=0.436, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34590
2023-01-05 21:34:39 - progress_bar.py[line:274] - INFO: epoch 001:   8400 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.285, wps=101.3, ups=0.46, wpb=110, bsz=40, num_updates=8390, lr=4.83109e-05, gnorm=0.56, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34612
2023-01-05 21:35:02 - progress_bar.py[line:274] - INFO: epoch 001:   8410 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2513, wps=99.9, ups=0.46, wpb=109.1, bsz=40, num_updates=8400, lr=4.83064e-05, gnorm=0.578, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=34634
2023-01-05 21:35:23 - progress_bar.py[line:274] - INFO: epoch 001:   8420 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.305, wps=101.3, ups=0.47, wpb=108, bsz=40, num_updates=8410, lr=4.83019e-05, gnorm=0.593, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34656
2023-01-05 21:35:45 - progress_bar.py[line:274] - INFO: epoch 001:   8430 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3107, wps=102.1, ups=0.47, wpb=109, bsz=40, num_updates=8420, lr=4.82974e-05, gnorm=0.476, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34677
2023-01-05 21:36:06 - progress_bar.py[line:274] - INFO: epoch 001:   8440 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2571, wps=102.6, ups=0.47, wpb=108.8, bsz=40, num_updates=8430, lr=4.82929e-05, gnorm=0.514, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34699
2023-01-05 21:36:27 - progress_bar.py[line:274] - INFO: epoch 001:   8450 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2618, wps=105.1, ups=0.47, wpb=110.7, bsz=40, num_updates=8440, lr=4.82884e-05, gnorm=0.599, clip=0, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=34720
2023-01-05 21:36:49 - progress_bar.py[line:274] - INFO: epoch 001:   8460 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2704, wps=102.9, ups=0.47, wpb=110, bsz=40, num_updates=8450, lr=4.82839e-05, gnorm=0.567, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34742
2023-01-05 21:37:11 - progress_bar.py[line:274] - INFO: epoch 001:   8470 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3016, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=8460, lr=4.82794e-05, gnorm=0.49, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34763
2023-01-05 21:37:32 - progress_bar.py[line:274] - INFO: epoch 001:   8480 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2704, wps=102.4, ups=0.47, wpb=108.6, bsz=40, num_updates=8470, lr=4.82749e-05, gnorm=0.482, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34785
2023-01-05 21:37:54 - progress_bar.py[line:274] - INFO: epoch 001:   8490 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2685, wps=98.8, ups=0.46, wpb=107.6, bsz=40, num_updates=8480, lr=4.82704e-05, gnorm=0.468, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=34807
2023-01-05 21:38:15 - progress_bar.py[line:274] - INFO: epoch 001:   8500 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3212, wps=104.4, ups=0.47, wpb=110.1, bsz=40, num_updates=8490, lr=4.82659e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34828
2023-01-05 21:38:37 - progress_bar.py[line:274] - INFO: epoch 001:   8510 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3107, wps=102.3, ups=0.47, wpb=109, bsz=40, num_updates=8500, lr=4.82614e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34850
2023-01-05 21:38:59 - progress_bar.py[line:274] - INFO: epoch 001:   8520 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2732, wps=101.2, ups=0.46, wpb=110.2, bsz=40, num_updates=8510, lr=4.82569e-05, gnorm=0.505, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=34872
2023-01-05 21:39:21 - progress_bar.py[line:274] - INFO: epoch 001:   8530 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2708, wps=100, ups=0.46, wpb=108.5, bsz=40, num_updates=8520, lr=4.82524e-05, gnorm=0.466, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=34894
2023-01-05 21:39:43 - progress_bar.py[line:274] - INFO: epoch 001:   8540 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3158, wps=101.3, ups=0.46, wpb=109.4, bsz=40, num_updates=8530, lr=4.82479e-05, gnorm=0.597, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=34916
2023-01-05 21:40:05 - progress_bar.py[line:274] - INFO: epoch 001:   8550 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3005, wps=104, ups=0.47, wpb=109.8, bsz=40, num_updates=8540, lr=4.82434e-05, gnorm=0.424, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34937
2023-01-05 21:40:20 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-05 21:40:29 - progress_bar.py[line:274] - INFO: epoch 001:   8561 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.81, nsentences=40, sample_size=109.81, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3103, wps=97, ups=0.42, wpb=109.8, bsz=40, num_updates=8550, lr=4.82389e-05, gnorm=0.458, clip=0, loss_scale=512, train_wall=24, gb_free=10.1, ema_decay=0.9999, wall=34961
2023-01-05 21:40:51 - progress_bar.py[line:274] - INFO: epoch 001:   8571 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2979, wps=99.9, ups=0.46, wpb=109.3, bsz=40, num_updates=8560, lr=4.82345e-05, gnorm=0.421, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=34983
2023-01-05 21:41:12 - progress_bar.py[line:274] - INFO: epoch 001:   8581 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3317, wps=102, ups=0.47, wpb=109, bsz=40, num_updates=8570, lr=4.823e-05, gnorm=0.518, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35005
2023-01-05 21:41:34 - progress_bar.py[line:274] - INFO: epoch 001:   8591 / 115845 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2696, wps=99, ups=0.46, wpb=107.4, bsz=40, num_updates=8580, lr=4.82255e-05, gnorm=0.582, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=35027
2023-01-05 21:41:56 - progress_bar.py[line:274] - INFO: epoch 001:   8601 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2587, wps=102.2, ups=0.47, wpb=109.3, bsz=40, num_updates=8590, lr=4.8221e-05, gnorm=0.412, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=35049
2023-01-05 21:42:18 - progress_bar.py[line:274] - INFO: epoch 001:   8611 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2893, wps=102.1, ups=0.47, wpb=109.1, bsz=40, num_updates=8600, lr=4.82165e-05, gnorm=0.472, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35070
2023-01-05 21:42:40 - progress_bar.py[line:274] - INFO: epoch 001:   8621 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2921, wps=99.3, ups=0.46, wpb=108.8, bsz=40, num_updates=8610, lr=4.8212e-05, gnorm=0.468, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35092
2023-01-05 21:43:01 - progress_bar.py[line:274] - INFO: epoch 001:   8631 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3317, wps=102.7, ups=0.48, wpb=107.4, bsz=40, num_updates=8620, lr=4.82075e-05, gnorm=0.501, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35114
2023-01-05 21:43:23 - progress_bar.py[line:274] - INFO: epoch 001:   8641 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2877, wps=100.2, ups=0.46, wpb=108.8, bsz=40, num_updates=8630, lr=4.8203e-05, gnorm=0.556, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35136
2023-01-05 21:43:45 - progress_bar.py[line:274] - INFO: epoch 001:   8651 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3209, wps=101.8, ups=0.47, wpb=109.5, bsz=40, num_updates=8640, lr=4.81985e-05, gnorm=0.582, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=35157
2023-01-05 21:44:06 - progress_bar.py[line:274] - INFO: epoch 001:   8661 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2857, wps=100.8, ups=0.46, wpb=109.2, bsz=40, num_updates=8650, lr=4.8194e-05, gnorm=0.59, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35179
2023-01-05 21:44:28 - progress_bar.py[line:274] - INFO: epoch 001:   8671 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2974, wps=102.7, ups=0.47, wpb=109.9, bsz=40, num_updates=8660, lr=4.81895e-05, gnorm=0.631, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=35201
2023-01-05 21:44:50 - progress_bar.py[line:274] - INFO: epoch 001:   8681 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3721, wps=100.9, ups=0.47, wpb=107.8, bsz=40, num_updates=8670, lr=4.8185e-05, gnorm=0.547, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35222
2023-01-05 21:45:13 - progress_bar.py[line:274] - INFO: epoch 001:   8691 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2703, wps=100, ups=0.46, wpb=109.9, bsz=40, num_updates=8680, lr=4.81805e-05, gnorm=0.536, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35245
2023-01-05 21:45:35 - progress_bar.py[line:274] - INFO: epoch 001:   8701 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3231, wps=102.3, ups=0.47, wpb=109.3, bsz=40, num_updates=8690, lr=4.8176e-05, gnorm=0.515, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35267
2023-01-05 21:45:57 - progress_bar.py[line:274] - INFO: epoch 001:   8711 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.301, wps=102.6, ups=0.47, wpb=109.4, bsz=40, num_updates=8700, lr=4.81715e-05, gnorm=0.595, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35289
2023-01-05 21:46:19 - progress_bar.py[line:274] - INFO: epoch 001:   8721 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.268, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=8710, lr=4.8167e-05, gnorm=0.734, clip=30, loss_scale=512, train_wall=22, gb_free=9.5, ema_decay=0.9999, wall=35311
2023-01-05 21:46:42 - progress_bar.py[line:274] - INFO: epoch 001:   8731 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2615, wps=100.4, ups=0.46, wpb=109.5, bsz=40, num_updates=8720, lr=4.81625e-05, gnorm=0.409, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35334
2023-01-05 21:47:05 - progress_bar.py[line:274] - INFO: epoch 001:   8741 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3167, wps=101.2, ups=0.46, wpb=110.1, bsz=40, num_updates=8730, lr=4.8158e-05, gnorm=0.461, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=35357
2023-01-05 21:47:27 - progress_bar.py[line:274] - INFO: epoch 001:   8751 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3474, wps=99.8, ups=0.46, wpb=109.6, bsz=40, num_updates=8740, lr=4.81535e-05, gnorm=0.424, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35379
2023-01-05 21:47:48 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-05 21:47:51 - progress_bar.py[line:274] - INFO: epoch 001:   8762 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.381, nsentences=40, sample_size=110.381, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3125, wps=101.6, ups=0.44, wpb=110.4, bsz=40, num_updates=8750, lr=4.8149e-05, gnorm=0.528, clip=10, loss_scale=256, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=35403
2023-01-05 21:48:13 - progress_bar.py[line:274] - INFO: epoch 001:   8772 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2831, wps=99.9, ups=0.46, wpb=107.5, bsz=40, num_updates=8760, lr=4.81445e-05, gnorm=0.535, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35425
2023-01-05 21:48:35 - progress_bar.py[line:274] - INFO: epoch 001:   8782 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2972, wps=100.2, ups=0.47, wpb=107, bsz=40, num_updates=8770, lr=4.814e-05, gnorm=0.476, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35447
2023-01-05 21:48:57 - progress_bar.py[line:274] - INFO: epoch 001:   8792 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3077, wps=99.5, ups=0.46, wpb=108.4, bsz=40, num_updates=8780, lr=4.81355e-05, gnorm=0.501, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35470
2023-01-05 21:49:20 - progress_bar.py[line:274] - INFO: epoch 001:   8802 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2577, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=8790, lr=4.8131e-05, gnorm=0.525, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35492
2023-01-05 21:49:41 - progress_bar.py[line:274] - INFO: epoch 001:   8812 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3529, wps=104.6, ups=0.48, wpb=109.6, bsz=40, num_updates=8800, lr=4.81266e-05, gnorm=0.486, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35514
2023-01-05 21:50:03 - progress_bar.py[line:274] - INFO: epoch 001:   8822 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3692, wps=105.1, ups=0.48, wpb=110, bsz=40, num_updates=8810, lr=4.81221e-05, gnorm=0.436, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35535
2023-01-05 21:50:25 - progress_bar.py[line:274] - INFO: epoch 001:   8832 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3039, wps=100.8, ups=0.46, wpb=109.5, bsz=40, num_updates=8820, lr=4.81176e-05, gnorm=0.431, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35557
2023-01-05 21:50:46 - progress_bar.py[line:274] - INFO: epoch 001:   8842 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.315, wps=106.4, ups=0.49, wpb=109.2, bsz=40, num_updates=8830, lr=4.81131e-05, gnorm=0.557, clip=10, loss_scale=256, train_wall=20, gb_free=10.3, ema_decay=0.9999, wall=35579
2023-01-05 21:51:09 - progress_bar.py[line:274] - INFO: epoch 001:   8852 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2963, wps=99.7, ups=0.45, wpb=110.5, bsz=40, num_updates=8840, lr=4.81086e-05, gnorm=0.562, clip=0, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=35601
2023-01-05 21:51:32 - progress_bar.py[line:274] - INFO: epoch 001:   8862 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=106.4, nsentences=40, sample_size=106.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.3188, wps=99.9, ups=0.47, wpb=106.4, bsz=40, num_updates=8850, lr=4.81041e-05, gnorm=0.577, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35624
2023-01-05 21:51:53 - progress_bar.py[line:274] - INFO: epoch 001:   8872 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3722, wps=103.4, ups=0.47, wpb=109.7, bsz=40, num_updates=8860, lr=4.80996e-05, gnorm=0.423, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=35646
2023-01-05 21:52:16 - progress_bar.py[line:274] - INFO: epoch 001:   8882 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3713, wps=100.7, ups=0.46, wpb=108.3, bsz=40, num_updates=8870, lr=4.80951e-05, gnorm=0.453, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=35668
2023-01-05 21:52:38 - progress_bar.py[line:274] - INFO: epoch 001:   8892 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3447, wps=101.5, ups=0.47, wpb=108.9, bsz=40, num_updates=8880, lr=4.80906e-05, gnorm=0.443, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35690
2023-01-05 21:52:59 - progress_bar.py[line:274] - INFO: epoch 001:   8902 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3448, wps=104.9, ups=0.48, wpb=108.8, bsz=40, num_updates=8890, lr=4.80861e-05, gnorm=0.55, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35712
2023-01-05 21:53:22 - progress_bar.py[line:274] - INFO: epoch 001:   8912 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2437, wps=100.7, ups=0.46, wpb=109.6, bsz=40, num_updates=8900, lr=4.80816e-05, gnorm=0.414, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35734
2023-01-05 21:53:44 - progress_bar.py[line:274] - INFO: epoch 001:   8922 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3366, wps=103.5, ups=0.48, wpb=108.3, bsz=40, num_updates=8910, lr=4.80771e-05, gnorm=0.638, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35756
2023-01-05 21:54:06 - progress_bar.py[line:274] - INFO: epoch 001:   8932 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3333, wps=100.4, ups=0.46, wpb=108, bsz=40, num_updates=8920, lr=4.80726e-05, gnorm=0.614, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35778
2023-01-05 21:54:28 - progress_bar.py[line:274] - INFO: epoch 001:   8942 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3445, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=8930, lr=4.80681e-05, gnorm=0.508, clip=10, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=35800
2023-01-05 21:54:51 - progress_bar.py[line:274] - INFO: epoch 001:   8952 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3094, wps=101.7, ups=0.46, wpb=110.6, bsz=40, num_updates=8940, lr=4.80636e-05, gnorm=0.447, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35823
2023-01-05 21:55:14 - progress_bar.py[line:274] - INFO: epoch 001:   8962 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3478, wps=99.4, ups=0.46, wpb=109, bsz=40, num_updates=8950, lr=4.80591e-05, gnorm=0.405, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35846
2023-01-05 21:55:35 - progress_bar.py[line:274] - INFO: epoch 001:   8972 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3627, wps=102.6, ups=0.47, wpb=108.6, bsz=40, num_updates=8960, lr=4.80546e-05, gnorm=0.4, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35868
2023-01-05 21:55:57 - progress_bar.py[line:274] - INFO: epoch 001:   8982 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3081, wps=104.2, ups=0.47, wpb=111.1, bsz=40, num_updates=8970, lr=4.80501e-05, gnorm=0.464, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35890
2023-01-05 21:56:19 - progress_bar.py[line:274] - INFO: epoch 001:   8992 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2995, wps=101.2, ups=0.47, wpb=107.9, bsz=40, num_updates=8980, lr=4.80456e-05, gnorm=0.538, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35912
2023-01-05 21:56:42 - progress_bar.py[line:274] - INFO: epoch 001:   9002 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3191, wps=102.5, ups=0.46, wpb=110.2, bsz=40, num_updates=8990, lr=4.80411e-05, gnorm=0.434, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35934
2023-01-05 21:57:04 - progress_bar.py[line:274] - INFO: epoch 001:   9012 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3351, wps=103.9, ups=0.47, wpb=110.7, bsz=40, num_updates=9000, lr=4.80366e-05, gnorm=0.389, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35956
2023-01-05 21:57:26 - progress_bar.py[line:274] - INFO: epoch 001:   9022 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3137, wps=100.1, ups=0.46, wpb=108.8, bsz=40, num_updates=9010, lr=4.80321e-05, gnorm=0.432, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=35978
2023-01-05 21:57:48 - progress_bar.py[line:274] - INFO: epoch 001:   9032 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3646, wps=103.6, ups=0.47, wpb=110.4, bsz=40, num_updates=9020, lr=4.80276e-05, gnorm=0.633, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36000
2023-01-05 21:58:10 - progress_bar.py[line:274] - INFO: epoch 001:   9042 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3125, wps=100.3, ups=0.46, wpb=108.2, bsz=40, num_updates=9030, lr=4.80231e-05, gnorm=0.777, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36022
2023-01-05 21:58:32 - progress_bar.py[line:274] - INFO: epoch 001:   9052 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3649, wps=101.5, ups=0.47, wpb=108.5, bsz=40, num_updates=9040, lr=4.80186e-05, gnorm=0.559, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36044
2023-01-05 21:58:54 - progress_bar.py[line:274] - INFO: epoch 001:   9062 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3791, wps=103.2, ups=0.47, wpb=109.3, bsz=40, num_updates=9050, lr=4.80142e-05, gnorm=0.578, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36066
2023-01-05 21:59:17 - progress_bar.py[line:274] - INFO: epoch 001:   9072 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2736, wps=99.9, ups=0.46, wpb=109, bsz=40, num_updates=9060, lr=4.80097e-05, gnorm=0.421, clip=0, loss_scale=256, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=36089
2023-01-05 21:59:38 - progress_bar.py[line:274] - INFO: epoch 001:   9082 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.402, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=9070, lr=4.80052e-05, gnorm=0.507, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=36111
2023-01-05 22:00:01 - progress_bar.py[line:274] - INFO: epoch 001:   9092 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3448, wps=100.1, ups=0.46, wpb=108, bsz=40, num_updates=9080, lr=4.80007e-05, gnorm=0.461, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=36133
2023-01-05 22:00:05 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-01-05 22:00:25 - progress_bar.py[line:274] - INFO: epoch 001:   9103 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.333, nsentences=40, sample_size=109.333, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3521, wps=98.3, ups=0.43, wpb=109.3, bsz=40, num_updates=9090, lr=4.79962e-05, gnorm=0.561, clip=10, loss_scale=128, train_wall=23, gb_free=10.4, ema_decay=0.9999, wall=36157
2023-01-05 22:00:47 - progress_bar.py[line:274] - INFO: epoch 001:   9113 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3351, wps=101.5, ups=0.46, wpb=110.3, bsz=40, num_updates=9100, lr=4.79917e-05, gnorm=0.505, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36179
2023-01-05 22:01:09 - progress_bar.py[line:274] - INFO: epoch 001:   9123 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.377, wps=103.4, ups=0.47, wpb=110.4, bsz=40, num_updates=9110, lr=4.79872e-05, gnorm=0.601, clip=10, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36201
2023-01-05 22:01:31 - progress_bar.py[line:274] - INFO: epoch 001:   9133 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3212, wps=101.8, ups=0.46, wpb=109.6, bsz=40, num_updates=9120, lr=4.79827e-05, gnorm=0.516, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36223
2023-01-05 22:01:54 - progress_bar.py[line:274] - INFO: epoch 001:   9143 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3333, wps=99.4, ups=0.45, wpb=109.2, bsz=40, num_updates=9130, lr=4.79782e-05, gnorm=0.42, clip=0, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=36246
2023-01-05 22:02:16 - progress_bar.py[line:274] - INFO: epoch 001:   9153 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2938, wps=98.5, ups=0.46, wpb=108.2, bsz=40, num_updates=9140, lr=4.79737e-05, gnorm=1.253, clip=10, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36269
2023-01-05 22:02:38 - progress_bar.py[line:274] - INFO: epoch 001:   9163 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3797, wps=102.1, ups=0.47, wpb=108.5, bsz=40, num_updates=9150, lr=4.79692e-05, gnorm=1.166, clip=10, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=36290
2023-01-05 22:03:01 - progress_bar.py[line:274] - INFO: epoch 001:   9173 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.7, nsentences=40, sample_size=106.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3318, wps=98.4, ups=0.46, wpb=106.7, bsz=40, num_updates=9160, lr=4.79647e-05, gnorm=0.528, clip=10, loss_scale=128, train_wall=22, gb_free=10, ema_decay=0.9999, wall=36313
2023-01-05 22:03:22 - progress_bar.py[line:274] - INFO: epoch 001:   9183 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3382, wps=103.6, ups=0.47, wpb=109.3, bsz=40, num_updates=9170, lr=4.79602e-05, gnorm=0.545, clip=10, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36335
2023-01-05 22:03:45 - progress_bar.py[line:274] - INFO: epoch 001:   9193 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.343, wps=99.5, ups=0.46, wpb=108.4, bsz=40, num_updates=9180, lr=4.79557e-05, gnorm=0.495, clip=0, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=36357
2023-01-05 22:04:07 - progress_bar.py[line:274] - INFO: epoch 001:   9203 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.359, wps=102.9, ups=0.47, wpb=109.5, bsz=40, num_updates=9190, lr=4.79512e-05, gnorm=0.659, clip=10, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=36379
2023-01-05 22:04:29 - progress_bar.py[line:274] - INFO: epoch 001:   9213 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3263, wps=102.1, ups=0.46, wpb=110, bsz=40, num_updates=9200, lr=4.79467e-05, gnorm=0.582, clip=10, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36401
2023-01-05 22:04:52 - progress_bar.py[line:274] - INFO: epoch 001:   9223 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2717, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=9210, lr=4.79422e-05, gnorm=0.51, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36424
2023-01-05 22:05:15 - progress_bar.py[line:274] - INFO: epoch 001:   9233 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3286, wps=98.3, ups=0.45, wpb=109.5, bsz=40, num_updates=9220, lr=4.79377e-05, gnorm=0.571, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36447
2023-01-05 22:05:37 - progress_bar.py[line:274] - INFO: epoch 001:   9243 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3333, wps=101.7, ups=0.46, wpb=109.6, bsz=40, num_updates=9230, lr=4.79332e-05, gnorm=0.537, clip=10, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=36469
2023-01-05 22:06:00 - progress_bar.py[line:274] - INFO: epoch 001:   9253 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3744, wps=100.2, ups=0.46, wpb=109, bsz=40, num_updates=9240, lr=4.79287e-05, gnorm=0.549, clip=10, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=36492
2023-01-05 22:06:22 - progress_bar.py[line:274] - INFO: epoch 001:   9263 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3333, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=9250, lr=4.79242e-05, gnorm=0.634, clip=20, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36514
2023-01-05 22:06:44 - progress_bar.py[line:274] - INFO: epoch 001:   9273 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4192, wps=101.6, ups=0.47, wpb=108.6, bsz=40, num_updates=9260, lr=4.79197e-05, gnorm=0.541, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36536
2023-01-05 22:07:05 - progress_bar.py[line:274] - INFO: epoch 001:   9283 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3046, wps=102.4, ups=0.47, wpb=109.1, bsz=40, num_updates=9270, lr=4.79152e-05, gnorm=1.25, clip=20, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36558
2023-01-05 22:07:27 - progress_bar.py[line:274] - INFO: epoch 001:   9293 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3565, wps=102.3, ups=0.47, wpb=108.1, bsz=40, num_updates=9280, lr=4.79107e-05, gnorm=0.559, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36580
2023-01-05 22:07:48 - progress_bar.py[line:274] - INFO: epoch 001:   9303 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.2872, wps=102.9, ups=0.47, wpb=109.6, bsz=40, num_updates=9290, lr=4.79063e-05, gnorm=0.731, clip=20, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36601
2023-01-05 22:08:10 - progress_bar.py[line:274] - INFO: epoch 001:   9313 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.407, wps=101.9, ups=0.47, wpb=108.8, bsz=40, num_updates=9300, lr=4.79018e-05, gnorm=0.446, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36623
2023-01-05 22:08:32 - progress_bar.py[line:274] - INFO: epoch 001:   9323 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3624, wps=99.6, ups=0.46, wpb=107.5, bsz=40, num_updates=9310, lr=4.78973e-05, gnorm=0.579, clip=10, loss_scale=128, train_wall=22, gb_free=10, ema_decay=0.9999, wall=36645
2023-01-05 22:08:54 - progress_bar.py[line:274] - INFO: epoch 001:   9333 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3744, wps=101.6, ups=0.47, wpb=108.3, bsz=40, num_updates=9320, lr=4.78928e-05, gnorm=0.442, clip=0, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=36666
2023-01-05 22:09:15 - progress_bar.py[line:274] - INFO: epoch 001:   9343 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3382, wps=100.4, ups=0.46, wpb=108, bsz=40, num_updates=9330, lr=4.78883e-05, gnorm=0.653, clip=20, loss_scale=128, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=36688
2023-01-05 22:09:37 - progress_bar.py[line:274] - INFO: epoch 001:   9353 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.302, wps=100.4, ups=0.46, wpb=108.5, bsz=40, num_updates=9340, lr=4.78838e-05, gnorm=0.443, clip=0, loss_scale=128, train_wall=22, gb_free=10, ema_decay=0.9999, wall=36710
2023-01-05 22:09:59 - progress_bar.py[line:274] - INFO: epoch 001:   9363 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3665, wps=99.9, ups=0.46, wpb=108.9, bsz=40, num_updates=9350, lr=4.78793e-05, gnorm=0.588, clip=20, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36732
2023-01-05 22:10:21 - progress_bar.py[line:274] - INFO: epoch 001:   9373 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3854, wps=99.9, ups=0.46, wpb=109.4, bsz=40, num_updates=9360, lr=4.78748e-05, gnorm=0.604, clip=10, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36754
2023-01-05 22:10:43 - progress_bar.py[line:274] - INFO: epoch 001:   9383 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3553, wps=102.5, ups=0.47, wpb=108.4, bsz=40, num_updates=9370, lr=4.78703e-05, gnorm=0.412, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36775
2023-01-05 22:11:05 - progress_bar.py[line:274] - INFO: epoch 001:   9393 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.342, wps=102.8, ups=0.47, wpb=109.5, bsz=40, num_updates=9380, lr=4.78658e-05, gnorm=0.542, clip=10, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36797
2023-01-05 22:11:27 - progress_bar.py[line:274] - INFO: epoch 001:   9403 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3645, wps=99.6, ups=0.46, wpb=109, bsz=40, num_updates=9390, lr=4.78613e-05, gnorm=0.579, clip=10, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36819
2023-01-05 22:11:49 - progress_bar.py[line:274] - INFO: epoch 001:   9413 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3816, wps=100.3, ups=0.46, wpb=109.4, bsz=40, num_updates=9400, lr=4.78568e-05, gnorm=0.527, clip=10, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36841
2023-01-05 22:12:10 - progress_bar.py[line:274] - INFO: epoch 001:   9423 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3194, wps=104, ups=0.47, wpb=110.5, bsz=40, num_updates=9410, lr=4.78523e-05, gnorm=0.512, clip=10, loss_scale=128, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=36863
2023-01-05 22:12:32 - progress_bar.py[line:274] - INFO: epoch 001:   9433 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3411, wps=101.9, ups=0.47, wpb=108.8, bsz=40, num_updates=9420, lr=4.78478e-05, gnorm=0.505, clip=10, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36885
2023-01-05 22:12:53 - progress_bar.py[line:274] - INFO: epoch 001:   9443 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3725, wps=104, ups=0.47, wpb=109.8, bsz=40, num_updates=9430, lr=4.78433e-05, gnorm=0.461, clip=0, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36906
2023-01-05 22:13:15 - progress_bar.py[line:274] - INFO: epoch 001:   9453 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3131, wps=104, ups=0.47, wpb=109.8, bsz=40, num_updates=9440, lr=4.78388e-05, gnorm=0.668, clip=10, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36927
2023-01-05 22:13:36 - progress_bar.py[line:274] - INFO: epoch 001:   9463 / 115845 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.301, wps=102.9, ups=0.48, wpb=108, bsz=40, num_updates=9450, lr=4.78343e-05, gnorm=0.756, clip=30, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36949
2023-01-05 22:13:58 - progress_bar.py[line:274] - INFO: epoch 001:   9473 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3659, wps=98.5, ups=0.46, wpb=108, bsz=40, num_updates=9460, lr=4.78298e-05, gnorm=0.494, clip=10, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36971
2023-01-05 22:14:20 - progress_bar.py[line:274] - INFO: epoch 001:   9483 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4069, wps=101.9, ups=0.47, wpb=109.5, bsz=40, num_updates=9470, lr=4.78253e-05, gnorm=0.432, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36993
2023-01-05 22:14:41 - progress_bar.py[line:274] - INFO: epoch 001:   9493 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.343, wps=100.8, ups=0.47, wpb=107.6, bsz=40, num_updates=9480, lr=4.78208e-05, gnorm=0.375, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37014
2023-01-05 22:15:03 - progress_bar.py[line:274] - INFO: epoch 001:   9503 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3668, wps=104.1, ups=0.48, wpb=108.8, bsz=40, num_updates=9490, lr=4.78163e-05, gnorm=0.438, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37035
2023-01-05 22:15:24 - progress_bar.py[line:274] - INFO: epoch 001:   9513 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3839, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=9500, lr=4.78118e-05, gnorm=0.369, clip=0, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37057
2023-01-05 22:15:47 - progress_bar.py[line:274] - INFO: epoch 001:   9523 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3873, wps=102.3, ups=0.47, wpb=109.4, bsz=40, num_updates=9510, lr=4.78073e-05, gnorm=0.526, clip=10, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37079
2023-01-05 22:16:08 - progress_bar.py[line:274] - INFO: epoch 001:   9533 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3586, wps=102.6, ups=0.47, wpb=108.8, bsz=40, num_updates=9520, lr=4.78028e-05, gnorm=0.483, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37101
2023-01-05 22:16:30 - progress_bar.py[line:274] - INFO: epoch 001:   9543 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3632, wps=103.3, ups=0.48, wpb=108.6, bsz=40, num_updates=9530, lr=4.77983e-05, gnorm=0.617, clip=30, loss_scale=128, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=37122
2023-01-05 22:16:52 - progress_bar.py[line:274] - INFO: epoch 001:   9553 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3763, wps=99.8, ups=0.46, wpb=109.2, bsz=40, num_updates=9540, lr=4.77939e-05, gnorm=0.433, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37144
2023-01-05 22:17:14 - progress_bar.py[line:274] - INFO: epoch 001:   9563 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3316, wps=102.3, ups=0.46, wpb=110.2, bsz=40, num_updates=9550, lr=4.77894e-05, gnorm=0.478, clip=0, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37166
2023-01-05 22:17:35 - progress_bar.py[line:274] - INFO: epoch 001:   9573 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.401, wps=101.4, ups=0.47, wpb=109, bsz=40, num_updates=9560, lr=4.77849e-05, gnorm=0.577, clip=20, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37188
2023-01-05 22:17:57 - progress_bar.py[line:274] - INFO: epoch 001:   9583 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3247, wps=100.4, ups=0.47, wpb=107.9, bsz=40, num_updates=9570, lr=4.77804e-05, gnorm=0.38, clip=0, loss_scale=128, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=37210
2023-01-05 22:18:19 - progress_bar.py[line:274] - INFO: epoch 001:   9593 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3719, wps=102.6, ups=0.47, wpb=109.5, bsz=40, num_updates=9580, lr=4.77759e-05, gnorm=0.453, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37231
2023-01-05 22:18:40 - progress_bar.py[line:274] - INFO: epoch 001:   9603 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3556, wps=101.9, ups=0.46, wpb=109.8, bsz=40, num_updates=9590, lr=4.77714e-05, gnorm=0.351, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37253
2023-01-05 22:19:02 - progress_bar.py[line:274] - INFO: epoch 001:   9613 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3641, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=9600, lr=4.77669e-05, gnorm=0.482, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37275
2023-01-05 22:19:24 - progress_bar.py[line:274] - INFO: epoch 001:   9623 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3333, wps=102.1, ups=0.47, wpb=108, bsz=40, num_updates=9610, lr=4.77624e-05, gnorm=0.521, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=37296
2023-01-05 22:19:45 - progress_bar.py[line:274] - INFO: epoch 001:   9633 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3861, wps=101.5, ups=0.47, wpb=108.3, bsz=40, num_updates=9620, lr=4.77579e-05, gnorm=0.582, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=37318
2023-01-05 22:20:07 - progress_bar.py[line:274] - INFO: epoch 001:   9643 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3271, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=9630, lr=4.77534e-05, gnorm=0.549, clip=10, loss_scale=256, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=37340
2023-01-05 22:20:29 - progress_bar.py[line:274] - INFO: epoch 001:   9653 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4115, wps=102.9, ups=0.47, wpb=109.8, bsz=40, num_updates=9640, lr=4.77489e-05, gnorm=0.396, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37361
2023-01-05 22:20:50 - progress_bar.py[line:274] - INFO: epoch 001:   9663 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3578, wps=101.3, ups=0.46, wpb=109.7, bsz=40, num_updates=9650, lr=4.77444e-05, gnorm=0.414, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37383
2023-01-05 22:21:12 - progress_bar.py[line:274] - INFO: epoch 001:   9673 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3466, wps=103, ups=0.47, wpb=110.1, bsz=40, num_updates=9660, lr=4.77399e-05, gnorm=0.531, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37405
2023-01-05 22:21:34 - progress_bar.py[line:274] - INFO: epoch 001:   9683 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3299, wps=100.2, ups=0.46, wpb=108.8, bsz=40, num_updates=9670, lr=4.77354e-05, gnorm=0.495, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=37427
2023-01-05 22:21:56 - progress_bar.py[line:274] - INFO: epoch 001:   9693 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3081, wps=102.7, ups=0.47, wpb=109.7, bsz=40, num_updates=9680, lr=4.77309e-05, gnorm=0.65, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37448
2023-01-05 22:22:17 - progress_bar.py[line:274] - INFO: epoch 001:   9703 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4101, wps=104.3, ups=0.48, wpb=109.4, bsz=40, num_updates=9690, lr=4.77264e-05, gnorm=0.637, clip=20, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37470
2023-01-05 22:22:39 - progress_bar.py[line:274] - INFO: epoch 001:   9713 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4293, wps=102.2, ups=0.46, wpb=110.3, bsz=40, num_updates=9700, lr=4.77219e-05, gnorm=0.506, clip=10, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=37492
2023-01-05 22:23:01 - progress_bar.py[line:274] - INFO: epoch 001:   9723 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4187, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=9710, lr=4.77174e-05, gnorm=0.541, clip=0, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=37514
2023-01-05 22:23:23 - progress_bar.py[line:274] - INFO: epoch 001:   9733 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3208, wps=100.9, ups=0.47, wpb=108.2, bsz=40, num_updates=9720, lr=4.77129e-05, gnorm=0.373, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=37536
2023-01-05 22:23:44 - progress_bar.py[line:274] - INFO: epoch 001:   9743 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3441, wps=103.6, ups=0.47, wpb=109.4, bsz=40, num_updates=9730, lr=4.77084e-05, gnorm=0.489, clip=10, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=37557
2023-01-05 22:24:06 - progress_bar.py[line:274] - INFO: epoch 001:   9753 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.372, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=9740, lr=4.77039e-05, gnorm=0.437, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37579
2023-01-05 22:24:28 - progress_bar.py[line:274] - INFO: epoch 001:   9763 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3978, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=9750, lr=4.76994e-05, gnorm=0.454, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37600
2023-01-05 22:24:49 - progress_bar.py[line:274] - INFO: epoch 001:   9773 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4121, wps=101.6, ups=0.47, wpb=108.1, bsz=40, num_updates=9760, lr=4.76949e-05, gnorm=0.399, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37622
2023-01-05 22:25:11 - progress_bar.py[line:274] - INFO: epoch 001:   9783 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3641, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=9770, lr=4.76904e-05, gnorm=0.464, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37644
2023-01-05 22:25:33 - progress_bar.py[line:274] - INFO: epoch 001:   9793 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3255, wps=102.1, ups=0.47, wpb=108.2, bsz=40, num_updates=9780, lr=4.7686e-05, gnorm=0.585, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37665
2023-01-05 22:25:55 - progress_bar.py[line:274] - INFO: epoch 001:   9803 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.325, wps=99.4, ups=0.46, wpb=108.7, bsz=40, num_updates=9790, lr=4.76815e-05, gnorm=0.475, clip=10, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=37687
2023-01-05 22:26:16 - progress_bar.py[line:274] - INFO: epoch 001:   9813 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4674, wps=102.1, ups=0.46, wpb=110, bsz=40, num_updates=9800, lr=4.7677e-05, gnorm=0.496, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=37709
2023-01-05 22:26:38 - progress_bar.py[line:274] - INFO: epoch 001:   9823 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3873, wps=102.2, ups=0.46, wpb=110, bsz=40, num_updates=9810, lr=4.76725e-05, gnorm=0.383, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37731
2023-01-05 22:27:01 - progress_bar.py[line:274] - INFO: epoch 001:   9833 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3282, wps=98, ups=0.45, wpb=110, bsz=40, num_updates=9820, lr=4.7668e-05, gnorm=0.443, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37754
2023-01-05 22:27:22 - progress_bar.py[line:274] - INFO: epoch 001:   9843 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3631, wps=104.6, ups=0.47, wpb=110.3, bsz=40, num_updates=9830, lr=4.76635e-05, gnorm=0.528, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37775
2023-01-05 22:27:44 - progress_bar.py[line:274] - INFO: epoch 001:   9853 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3737, wps=101, ups=0.46, wpb=109.9, bsz=40, num_updates=9840, lr=4.7659e-05, gnorm=0.445, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37797
2023-01-05 22:28:06 - progress_bar.py[line:274] - INFO: epoch 001:   9863 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3944, wps=102.2, ups=0.47, wpb=108.2, bsz=40, num_updates=9850, lr=4.76545e-05, gnorm=0.484, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37819
2023-01-05 22:28:28 - progress_bar.py[line:274] - INFO: epoch 001:   9873 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4354, wps=101.4, ups=0.47, wpb=108.2, bsz=40, num_updates=9860, lr=4.765e-05, gnorm=0.453, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37840
2023-01-05 22:28:49 - progress_bar.py[line:274] - INFO: epoch 001:   9883 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3412, wps=104.5, ups=0.48, wpb=108.7, bsz=40, num_updates=9870, lr=4.76455e-05, gnorm=0.35, clip=0, loss_scale=256, train_wall=21, gb_free=9.5, ema_decay=0.9999, wall=37861
2023-01-05 22:29:10 - progress_bar.py[line:274] - INFO: epoch 001:   9893 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.349, wps=104.3, ups=0.47, wpb=110.6, bsz=40, num_updates=9880, lr=4.7641e-05, gnorm=0.384, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=37883
2023-01-05 22:29:32 - progress_bar.py[line:274] - INFO: epoch 001:   9903 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3645, wps=100.5, ups=0.46, wpb=108.9, bsz=40, num_updates=9890, lr=4.76365e-05, gnorm=0.454, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=37905
2023-01-05 22:29:54 - progress_bar.py[line:274] - INFO: epoch 001:   9913 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4028, wps=101.5, ups=0.47, wpb=108.4, bsz=40, num_updates=9900, lr=4.7632e-05, gnorm=0.471, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37926
2023-01-05 22:30:15 - progress_bar.py[line:274] - INFO: epoch 001:   9923 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3349, wps=101.3, ups=0.47, wpb=107.8, bsz=40, num_updates=9910, lr=4.76275e-05, gnorm=0.448, clip=0, loss_scale=256, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=37948
2023-01-05 22:30:37 - progress_bar.py[line:274] - INFO: epoch 001:   9933 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3941, wps=100.3, ups=0.46, wpb=109.4, bsz=40, num_updates=9920, lr=4.7623e-05, gnorm=0.432, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=37970
2023-01-05 22:30:59 - progress_bar.py[line:274] - INFO: epoch 001:   9943 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3442, wps=99.8, ups=0.46, wpb=108.5, bsz=40, num_updates=9930, lr=4.76185e-05, gnorm=0.776, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=37992
2023-01-05 22:31:21 - progress_bar.py[line:274] - INFO: epoch 001:   9953 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3832, wps=99.3, ups=0.46, wpb=108, bsz=40, num_updates=9940, lr=4.7614e-05, gnorm=0.484, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=38014
2023-01-05 22:31:43 - progress_bar.py[line:274] - INFO: epoch 001:   9963 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3716, wps=101.1, ups=0.46, wpb=110.2, bsz=40, num_updates=9950, lr=4.76095e-05, gnorm=0.433, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=38036
2023-01-05 22:32:06 - progress_bar.py[line:274] - INFO: epoch 001:   9973 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4087, wps=101.3, ups=0.47, wpb=108.5, bsz=40, num_updates=9960, lr=4.7605e-05, gnorm=0.455, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=38058
2023-01-05 22:32:27 - progress_bar.py[line:274] - INFO: epoch 001:   9983 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3737, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=9970, lr=4.76005e-05, gnorm=0.429, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=38080
2023-01-05 22:32:49 - progress_bar.py[line:274] - INFO: epoch 001:   9993 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3925, wps=102.3, ups=0.47, wpb=109.1, bsz=40, num_updates=9980, lr=4.7596e-05, gnorm=0.406, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=38102
2023-01-05 22:33:11 - progress_bar.py[line:274] - INFO: epoch 001:  10003 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3492, wps=100.7, ups=0.46, wpb=110.5, bsz=40, num_updates=9990, lr=4.75915e-05, gnorm=0.629, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=38124
2023-01-05 22:33:33 - progress_bar.py[line:274] - INFO: epoch 001:  10013 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4554, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=10000, lr=4.7587e-05, gnorm=0.443, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=38146
2023-01-05 22:33:33 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-05 22:33:34 - train.py[line:549] - INFO: 0 / 4988
2023-01-05 22:33:35 - train.py[line:551] - INFO: load:0.89 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-05 22:33:36 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 9.26 GiB already allocated; 5.73 GiB free; 31.36 GiB reserved in total by PyTorch)
2023-01-05 22:33:36 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-05 22:33:36 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 16        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9486 MB |   10711 MB |    5374 TB |    5374 TB |
|       from large pool |    9312 MB |   10536 MB |    5371 TB |    5371 TB |
|       from small pool |     174 MB |     175 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9486 MB |   10711 MB |    5374 TB |    5374 TB |
|       from large pool |    9312 MB |   10536 MB |    5371 TB |    5371 TB |
|       from small pool |     174 MB |     175 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32116 MB |   32118 MB |  218464 MB |  186348 MB |
|       from large pool |   31940 MB |   31940 MB |  218062 MB |  186122 MB |
|       from small pool |     176 MB |     178 MB |     402 MB |     226 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22629 MB |   27159 MB |    5775 TB |    5774 TB |
|       from large pool |   22627 MB |   27157 MB |    5772 TB |    5772 TB |
|       from small pool |       1 MB |       3 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  252703 K  |  252698 K  |
|       from large pool |     698    |     710    |   78176 K  |   78175 K  |
|       from small pool |    3925    |    3943    |  174526 K  |  174522 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  252703 K  |  252698 K  |
|       from large pool |     698    |     710    |   78176 K  |   78175 K  |
|       from small pool |    3925    |    3943    |  174526 K  |  174522 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     171    |     172    |     641    |     470    |
|       from large pool |      83    |      83    |     440    |     357    |
|       from small pool |      88    |      89    |     201    |     113    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     113    |     117    |  191154 K  |  191154 K  |
|       from large pool |      46    |      47    |   40656 K  |   40656 K  |
|       from small pool |      67    |      75    |  150497 K  |  150497 K  |
|===========================================================================|

2023-01-05 22:33:36 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-05 22:36:08 - train.py[line:549] - INFO: 200 / 4988
2023-01-05 22:36:08 - train.py[line:551] - INFO: load:0.91 valid_run:153.71 task_valid:148.82 collect_output:3.82
2023-01-05 22:38:38 - train.py[line:549] - INFO: 400 / 4988
2023-01-05 22:38:38 - train.py[line:551] - INFO: load:0.94 valid_run:303.17 task_valid:292.78 collect_output:8.28
2023-01-05 22:41:11 - train.py[line:549] - INFO: 600 / 4988
2023-01-05 22:41:11 - train.py[line:551] - INFO: load:0.96 valid_run:456.44 task_valid:436.57 collect_output:16.75
2023-01-05 22:43:41 - train.py[line:549] - INFO: 800 / 4988
2023-01-05 22:43:41 - train.py[line:551] - INFO: load:0.98 valid_run:606.44 task_valid:582.19 collect_output:20.10
2023-01-05 22:46:15 - train.py[line:549] - INFO: 1000 / 4988
2023-01-05 22:46:15 - train.py[line:551] - INFO: load:1.01 valid_run:759.88 task_valid:730.32 collect_output:24.38
2023-01-05 22:48:48 - train.py[line:549] - INFO: 1200 / 4988
2023-01-05 22:48:48 - train.py[line:551] - INFO: load:1.04 valid_run:912.92 task_valid:876.72 collect_output:29.97
2023-01-05 22:51:23 - train.py[line:549] - INFO: 1400 / 4988
2023-01-05 22:51:23 - train.py[line:551] - INFO: load:1.06 valid_run:1067.35 task_valid:1023.35 collect_output:36.73
2023-01-05 22:53:55 - train.py[line:549] - INFO: 1600 / 4988
2023-01-05 22:53:55 - train.py[line:551] - INFO: load:1.09 valid_run:1219.59 task_valid:1164.99 collect_output:46.29
2023-01-05 22:56:26 - train.py[line:549] - INFO: 1800 / 4988
2023-01-05 22:56:26 - train.py[line:551] - INFO: load:1.11 valid_run:1370.20 task_valid:1310.33 collect_output:50.51
2023-01-05 22:58:56 - train.py[line:549] - INFO: 2000 / 4988
2023-01-05 22:58:56 - train.py[line:551] - INFO: load:1.14 valid_run:1519.92 task_valid:1454.25 collect_output:55.29
2023-01-05 23:01:26 - train.py[line:549] - INFO: 2200 / 4988
2023-01-05 23:01:26 - train.py[line:551] - INFO: load:1.16 valid_run:1670.59 task_valid:1599.86 collect_output:59.31
2023-01-05 23:03:58 - train.py[line:549] - INFO: 2400 / 4988
2023-01-05 23:03:58 - train.py[line:551] - INFO: load:1.19 valid_run:1821.60 task_valid:1745.41 collect_output:63.69
2023-01-05 23:06:29 - train.py[line:549] - INFO: 2600 / 4988
2023-01-05 23:06:29 - train.py[line:551] - INFO: load:1.22 valid_run:1972.52 task_valid:1887.73 collect_output:71.25
2023-01-05 23:09:01 - train.py[line:549] - INFO: 2800 / 4988
2023-01-05 23:09:01 - train.py[line:551] - INFO: load:1.24 valid_run:2124.41 task_valid:2033.98 collect_output:75.82
2023-01-05 23:11:32 - train.py[line:549] - INFO: 3000 / 4988
2023-01-05 23:11:32 - train.py[line:551] - INFO: load:1.27 valid_run:2275.39 task_valid:2181.04 collect_output:78.69
2023-01-05 23:14:03 - train.py[line:549] - INFO: 3200 / 4988
2023-01-05 23:14:03 - train.py[line:551] - INFO: load:1.29 valid_run:2426.49 task_valid:2325.82 collect_output:83.95
2023-01-05 23:16:36 - train.py[line:549] - INFO: 3400 / 4988
2023-01-05 23:16:36 - train.py[line:551] - INFO: load:1.32 valid_run:2579.16 task_valid:2471.79 collect_output:89.62
2023-01-05 23:19:07 - train.py[line:549] - INFO: 3600 / 4988
2023-01-05 23:19:07 - train.py[line:551] - INFO: load:1.34 valid_run:2730.84 task_valid:2619.45 collect_output:92.59
2023-01-05 23:21:37 - train.py[line:549] - INFO: 3800 / 4988
2023-01-05 23:21:37 - train.py[line:551] - INFO: load:1.37 valid_run:2880.31 task_valid:2761.61 collect_output:98.85
2023-01-05 23:24:08 - train.py[line:549] - INFO: 4000 / 4988
2023-01-05 23:24:08 - train.py[line:551] - INFO: load:1.40 valid_run:3031.63 task_valid:2907.34 collect_output:103.40
2023-01-05 23:26:41 - train.py[line:549] - INFO: 4200 / 4988
2023-01-05 23:26:41 - train.py[line:551] - INFO: load:1.42 valid_run:3184.64 task_valid:3052.47 collect_output:110.24
2023-01-05 23:29:12 - train.py[line:549] - INFO: 4400 / 4988
2023-01-05 23:29:12 - train.py[line:551] - INFO: load:1.45 valid_run:3335.19 task_valid:3197.87 collect_output:114.33
2023-01-05 23:31:44 - train.py[line:549] - INFO: 4600 / 4988
2023-01-05 23:31:44 - train.py[line:551] - INFO: load:1.48 valid_run:3487.51 task_valid:3344.81 collect_output:118.65
2023-01-05 23:34:17 - train.py[line:549] - INFO: 4800 / 4988
2023-01-05 23:34:17 - train.py[line:551] - INFO: load:1.50 valid_run:3639.63 task_valid:3491.86 collect_output:122.67

====================================================================================================
SGG eval:     R @ 50: 0.4900;     R @ 100: 0.5794;     R @ 500: 0.6439;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2925;    mR @ 100: 0.3771;    mR @ 500: 0.4316;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7415) (covered in:0.6875) (covering:0.3429) (eating:0.6765) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.8203) (says:0.0000) (sitting on:0.6825) (standing on:0.1983) (using:0.6500) (walking in:0.0000) (walking on:0.6847) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4900;     R @ 100: 0.5794;     R @ 500: 0.6439;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2925;    mR @ 100: 0.3771;    mR @ 500: 0.4316;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7415) (covered in:0.6875) (covering:0.3429) (eating:0.6765) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.8203) (says:0.0000) (sitting on:0.6825) (standing on:0.1983) (using:0.6500) (walking in:0.0000) (walking on:0.6847) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-05 23:36:48 - train.py[line:487] - INFO: 0.5793761904761905
2023-01-05 23:36:48 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-05 23:36:49 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.375 | loss_v1 0 | loss_v2 0 | nll_loss 0.221 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.579376 | ppl 1.17 | vqa_score 0.5507 | wps 118.3 | wpb 89.9 | bsz 30 | num_updates 10000 | best_R@100 0.642554
2023-01-05 23:36:49 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 10000 updates
2023-01-05 23:36:49 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_10000.pt
2023-01-05 23:37:27 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_10000.pt
2023-01-05 23:38:53 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum1.0_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 0.5793761904761905) (writing took 123.95055025443435 seconds)
2023-01-05 23:39:14 - progress_bar.py[line:274] - INFO: epoch 001:  10023 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4118, wps=0.5, ups=0, wpb=108.1, bsz=40, num_updates=10010, lr=4.75825e-05, gnorm=0.346, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42086
2023-01-05 23:39:35 - progress_bar.py[line:274] - INFO: epoch 001:  10033 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3646, wps=102.3, ups=0.47, wpb=109.2, bsz=40, num_updates=10020, lr=4.7578e-05, gnorm=0.375, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42108
2023-01-05 23:39:57 - progress_bar.py[line:274] - INFO: epoch 001:  10043 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3719, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=10030, lr=4.75736e-05, gnorm=0.477, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=42129
2023-01-05 23:40:18 - progress_bar.py[line:274] - INFO: epoch 001:  10053 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4372, wps=102.9, ups=0.47, wpb=108.6, bsz=40, num_updates=10040, lr=4.75691e-05, gnorm=0.484, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42151
2023-01-05 23:40:40 - progress_bar.py[line:274] - INFO: epoch 001:  10063 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3902, wps=101.1, ups=0.47, wpb=107.1, bsz=40, num_updates=10050, lr=4.75646e-05, gnorm=0.615, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42172
2023-01-05 23:41:02 - progress_bar.py[line:274] - INFO: epoch 001:  10073 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3935, wps=98.9, ups=0.46, wpb=107.9, bsz=40, num_updates=10060, lr=4.75601e-05, gnorm=0.459, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42194
2023-01-05 23:41:24 - progress_bar.py[line:274] - INFO: epoch 001:  10083 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3474, wps=99.6, ups=0.46, wpb=107.3, bsz=40, num_updates=10070, lr=4.75556e-05, gnorm=0.539, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=42216
2023-01-05 23:41:45 - progress_bar.py[line:274] - INFO: epoch 001:  10093 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3764, wps=102.1, ups=0.46, wpb=110.9, bsz=40, num_updates=10080, lr=4.75511e-05, gnorm=0.389, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42238
2023-01-05 23:42:07 - progress_bar.py[line:274] - INFO: epoch 001:  10103 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.399, wps=102.4, ups=0.47, wpb=108.2, bsz=40, num_updates=10090, lr=4.75466e-05, gnorm=0.504, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42260
2023-01-05 23:42:29 - progress_bar.py[line:274] - INFO: epoch 001:  10113 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.379, wps=100.7, ups=0.46, wpb=108.7, bsz=40, num_updates=10100, lr=4.75421e-05, gnorm=0.573, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42281
2023-01-05 23:42:50 - progress_bar.py[line:274] - INFO: epoch 001:  10123 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4087, wps=102.2, ups=0.47, wpb=109.8, bsz=40, num_updates=10110, lr=4.75376e-05, gnorm=0.402, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42303
2023-01-05 23:43:12 - progress_bar.py[line:274] - INFO: epoch 001:  10133 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3706, wps=103.1, ups=0.47, wpb=109, bsz=40, num_updates=10120, lr=4.75331e-05, gnorm=0.474, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42324
2023-01-05 23:43:33 - progress_bar.py[line:274] - INFO: epoch 001:  10143 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.36, wps=103, ups=0.47, wpb=109, bsz=40, num_updates=10130, lr=4.75286e-05, gnorm=0.489, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42346
2023-01-05 23:43:55 - progress_bar.py[line:274] - INFO: epoch 001:  10153 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4396, wps=100.6, ups=0.47, wpb=108, bsz=40, num_updates=10140, lr=4.75241e-05, gnorm=0.405, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=42368
2023-01-05 23:44:17 - progress_bar.py[line:274] - INFO: epoch 001:  10163 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4076, wps=101.3, ups=0.46, wpb=110.4, bsz=40, num_updates=10150, lr=4.75196e-05, gnorm=0.466, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=42390
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 2173934
Killing subprocess 2173935
Main process received SIGINT, exiting
