2023-01-06 14:50:45 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2023-01-06 14:50:45 - utils.py[line:261] - INFO: Start init
2023-01-06 14:50:45 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2023-01-06 14:50:46 - utils.py[line:261] - INFO: Start init
2023-01-06 14:50:46 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-01-06 14:50:46 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-01-06 14:50:46 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.2023-01-06 14:50:46 - utils.py[line:274] - INFO: initialized host node4 as rank 0

single-machine distributed training is initialized.
2023-01-06 14:50:51 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_visualDS_momentum0.99_alpha1.0', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 2000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 2000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=1, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480', save_interval=10, save_interval_updates=2000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_visualDS_momentum0.99_alpha1.0', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=2000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-01-06 14:50:51 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-01-06 14:50:51 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2023-01-06 14:50:56 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-01-06 14:50:56 - train.py[line:118] - INFO: task: VqaGenTask
2023-01-06 14:50:56 - train.py[line:119] - INFO: model: OFAModel
2023-01-06 14:50:56 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-01-06 14:50:56 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-01-06 14:50:56 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2023-01-06 14:50:56 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-01-06 14:50:56 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-01-06 14:50:56 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-01-06 14:50:56 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-01-06 14:50:56 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-01-06 14:50:56 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-01-06 14:50:56 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-01-06 14:50:56 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-01-06 14:50:56 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-01-06 14:50:56 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-01-06 14:50:57 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-01-06 14:50:58 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-01-06 14:50:59 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-01-06 14:50:59 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-01-06 14:50:59 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-01-06 14:50:59 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-01-06 14:50:59 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-01-06 14:50:59 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-01-06 14:51:00 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-01-06 14:51:00 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-01-06 14:51:00 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
Done 0.99 cuda cpu, cpu
2023-01-06 14:51:01 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2023-01-06 14:51:01 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2023-01-06 14:51:01 - trainer.py[line:499] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
Done 0.99 cuda cpu, cpu
2023-01-06 14:51:04 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-01-06 14:51:04 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-01-06 14:51:04 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-01-06 14:51:05 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-01-06 14:51:05 - trainer.py[line:314] - INFO: Exponential Moving Average Shadow Model is initialized.
2023-01-06 14:51:05 - trainer.py[line:674] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2023-01-06 14:51:05 - trainer.py[line:694] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv slice_id 1 row count 2316893 total row count 4633786file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv slice_id 0 row count 2316893 total row count 4633786

2023-01-06 14:51:09 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 115845, warmup steps 4633, warmup_factor 0.0002158428663932657
Total steps 115845, warmup steps 4633, warmup_factor 0.0002158428663932657
2023-01-06 14:51:09 - trainer.py[line:758] - INFO: begin training epoch 1
2023-01-06 14:51:09 - train.py[line:312] - INFO: Start iterating over samples
From cpu to cuda:0
From cpu to cuda:1
2023-01-06 14:51:39 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 115845 loss=0.977, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, vqa_score=0.0363, wps=93.5, ups=0.43, wpb=109.9, bsz=40, num_updates=10, lr=1.07921e-07, gnorm=7.485, clip=100, loss_scale=128, train_wall=27, gb_free=10.4, ema_decay=0.9999, wall=39
2023-01-06 14:52:01 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 115845 loss=1.01, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, vqa_score=0.0308, wps=99.6, ups=0.45, wpb=109.6, bsz=40, num_updates=20, lr=2.15843e-07, gnorm=8.028, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61
2023-01-06 14:52:23 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0245, wps=102.2, ups=0.47, wpb=109, bsz=40, num_updates=30, lr=3.23764e-07, gnorm=9.005, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=83
2023-01-06 14:52:45 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 115845 loss=1.005, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, vqa_score=0.0263, wps=101.2, ups=0.47, wpb=108.7, bsz=40, num_updates=40, lr=4.31686e-07, gnorm=7.742, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=105
2023-01-06 14:53:06 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0297, wps=102.1, ups=0.47, wpb=108.8, bsz=40, num_updates=50, lr=5.39607e-07, gnorm=7.299, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=126
2023-01-06 14:53:28 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 115845 loss=1.084, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, vqa_score=0.0332, wps=101.4, ups=0.47, wpb=108.3, bsz=40, num_updates=60, lr=6.47529e-07, gnorm=8.534, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=148
2023-01-06 14:53:51 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 115845 loss=1.034, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, vqa_score=0.0283, wps=98.2, ups=0.45, wpb=109.6, bsz=40, num_updates=70, lr=7.5545e-07, gnorm=7.193, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=171
2023-01-06 14:54:14 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 115845 loss=0.99, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, vqa_score=0.0287, wps=97.6, ups=0.45, wpb=108.3, bsz=40, num_updates=80, lr=8.63371e-07, gnorm=6.811, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=194
2023-01-06 14:54:36 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 115845 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.7, vqa_score=0.0291, wps=100.7, ups=0.46, wpb=109.4, bsz=40, num_updates=90, lr=9.71293e-07, gnorm=5.63, clip=100, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=216
2023-01-06 14:54:57 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 115845 loss=0.867, loss_v1=0, loss_v2=0, nll_loss=0.75, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.68, vqa_score=0.0205, wps=103.5, ups=0.47, wpb=109, bsz=40, num_updates=100, lr=1.07921e-06, gnorm=5.199, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=237
2023-01-06 14:55:21 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 115845 loss=0.883, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, vqa_score=0.0321, wps=92.7, ups=0.43, wpb=108.4, bsz=40, num_updates=110, lr=1.18714e-06, gnorm=5.272, clip=100, loss_scale=128, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=261
2023-01-06 14:55:43 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 115845 loss=0.797, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, vqa_score=0.0361, wps=103.6, ups=0.47, wpb=109.9, bsz=40, num_updates=120, lr=1.29506e-06, gnorm=4.536, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=283
2023-01-06 14:56:05 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 115845 loss=0.751, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, vqa_score=0.0217, wps=101.5, ups=0.46, wpb=109.7, bsz=40, num_updates=130, lr=1.40298e-06, gnorm=3.782, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=305
2023-01-06 14:56:27 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0457, wps=100.4, ups=0.46, wpb=108.1, bsz=40, num_updates=140, lr=1.5109e-06, gnorm=3.881, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=327
2023-01-06 14:56:49 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0337, wps=101.2, ups=0.47, wpb=108.7, bsz=40, num_updates=150, lr=1.61882e-06, gnorm=3.65, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=349
2023-01-06 14:57:11 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 115845 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.56, vqa_score=0.0195, wps=102.3, ups=0.46, wpb=110, bsz=40, num_updates=160, lr=1.72674e-06, gnorm=3.268, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=371
2023-01-06 14:57:32 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0263, wps=103.8, ups=0.47, wpb=110.4, bsz=40, num_updates=170, lr=1.83466e-06, gnorm=2.663, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=392
2023-01-06 14:57:54 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 115845 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, vqa_score=0.0048, wps=99.1, ups=0.46, wpb=107.2, bsz=40, num_updates=180, lr=1.94259e-06, gnorm=3.207, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=414
2023-01-06 14:58:16 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 115845 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, vqa_score=0.0243, wps=102.8, ups=0.47, wpb=109.6, bsz=40, num_updates=190, lr=2.05051e-06, gnorm=2.933, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=436
2023-01-06 14:58:38 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 115845 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, vqa_score=0.0187, wps=100, ups=0.46, wpb=108.6, bsz=40, num_updates=200, lr=2.15843e-06, gnorm=2.631, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=458
2023-01-06 14:59:00 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 115845 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.615, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, vqa_score=0.0147, wps=102.6, ups=0.47, wpb=109.9, bsz=40, num_updates=210, lr=2.26635e-06, gnorm=2.613, clip=100, loss_scale=128, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=480
2023-01-06 14:59:23 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 115845 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, vqa_score=0.0194, wps=98.8, ups=0.45, wpb=110.1, bsz=40, num_updates=220, lr=2.37427e-06, gnorm=2.407, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=503
2023-01-06 14:59:45 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 115845 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, vqa_score=0.0303, wps=98.8, ups=0.45, wpb=109.2, bsz=40, num_updates=230, lr=2.48219e-06, gnorm=2.241, clip=100, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=525
2023-01-06 15:00:07 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0156, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=240, lr=2.59011e-06, gnorm=2.123, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=547
2023-01-06 15:00:29 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.8, nsentences=40, sample_size=106.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0431, wps=99, ups=0.46, wpb=106.8, bsz=40, num_updates=250, lr=2.69804e-06, gnorm=2.062, clip=100, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=569
2023-01-06 15:00:51 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.04, wps=101.1, ups=0.47, wpb=108.1, bsz=40, num_updates=260, lr=2.80596e-06, gnorm=2.182, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=591
2023-01-06 15:01:12 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 115845 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, vqa_score=0.011, wps=106.3, ups=0.48, wpb=110.3, bsz=40, num_updates=270, lr=2.91388e-06, gnorm=2.061, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=612
2023-01-06 15:01:34 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 115845 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, vqa_score=0.0047, wps=101, ups=0.47, wpb=107.1, bsz=40, num_updates=280, lr=3.0218e-06, gnorm=1.935, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=634
2023-01-06 15:01:56 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 115845 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0269, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=290, lr=3.12972e-06, gnorm=1.643, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=656
2023-01-06 15:02:18 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0052, wps=103, ups=0.47, wpb=109.2, bsz=40, num_updates=300, lr=3.23764e-06, gnorm=1.808, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=678
2023-01-06 15:02:40 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 115845 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, vqa_score=0.0398, wps=101.2, ups=0.46, wpb=110.3, bsz=40, num_updates=310, lr=3.34556e-06, gnorm=1.689, clip=100, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=700
2023-01-06 15:03:02 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0146, wps=99.3, ups=0.46, wpb=107.3, bsz=40, num_updates=320, lr=3.45349e-06, gnorm=1.711, clip=100, loss_scale=128, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=722
2023-01-06 15:03:24 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0047, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=330, lr=3.56141e-06, gnorm=1.704, clip=100, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=744
2023-01-06 15:03:46 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 115845 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, vqa_score=0.0204, wps=100.8, ups=0.46, wpb=109.1, bsz=40, num_updates=340, lr=3.66933e-06, gnorm=1.619, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=766
2023-01-06 15:04:08 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 115845 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, vqa_score=0.0317, wps=99.2, ups=0.45, wpb=109.1, bsz=40, num_updates=350, lr=3.77725e-06, gnorm=1.409, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=788
2023-01-06 15:04:33 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 115845 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, vqa_score=0.024, wps=102.8, ups=0.47, wpb=108.9, bsz=40, num_updates=360, lr=3.88517e-06, gnorm=1.51, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=810
2023-01-06 15:04:58 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 115845 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0156, wps=100, ups=0.46, wpb=108.3, bsz=40, num_updates=370, lr=3.99309e-06, gnorm=1.589, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=835
2023-01-06 15:05:23 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 115845 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0452, wps=100.1, ups=0.46, wpb=108.5, bsz=40, num_updates=380, lr=4.10101e-06, gnorm=1.417, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=860
2023-01-06 15:05:49 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 115845 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, vqa_score=0.0376, wps=100.3, ups=0.46, wpb=108.6, bsz=40, num_updates=390, lr=4.20894e-06, gnorm=1.681, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=886
2023-01-06 15:06:14 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 115845 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, vqa_score=0.0281, wps=102.6, ups=0.46, wpb=110.6, bsz=40, num_updates=400, lr=4.31686e-06, gnorm=1.619, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=911
2023-01-06 15:06:39 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0296, wps=99.3, ups=0.46, wpb=108.1, bsz=40, num_updates=410, lr=4.42478e-06, gnorm=1.552, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=936
2023-01-06 15:07:04 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 115845 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0323, wps=99.7, ups=0.46, wpb=108.4, bsz=40, num_updates=420, lr=4.5327e-06, gnorm=1.504, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=961
2023-01-06 15:07:29 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 115845 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, vqa_score=0.0309, wps=102.9, ups=0.47, wpb=109.4, bsz=40, num_updates=430, lr=4.64062e-06, gnorm=1.756, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=986
2023-01-06 15:07:55 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 115845 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0051, wps=99.8, ups=0.46, wpb=108.8, bsz=40, num_updates=440, lr=4.74854e-06, gnorm=1.515, clip=100, loss_scale=128, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=1011
2023-01-06 15:08:20 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 115845 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0472, wps=100.2, ups=0.46, wpb=109, bsz=40, num_updates=450, lr=4.85646e-06, gnorm=1.335, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1037
2023-01-06 15:08:45 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 115845 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, vqa_score=0.0329, wps=101.2, ups=0.47, wpb=108.3, bsz=40, num_updates=460, lr=4.96439e-06, gnorm=1.469, clip=100, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1061
2023-01-06 15:09:08 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 115845 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, vqa_score=0.0096, wps=101.1, ups=0.46, wpb=109.5, bsz=40, num_updates=470, lr=5.07231e-06, gnorm=1.254, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1087
2023-01-06 15:09:31 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 115845 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0538, wps=104.3, ups=0.47, wpb=110.5, bsz=40, num_updates=480, lr=5.18023e-06, gnorm=1.513, clip=100, loss_scale=128, train_wall=21, gb_free=10, ema_decay=0.9999, wall=1110
2023-01-06 15:09:54 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 115845 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, vqa_score=0.0242, wps=99.7, ups=0.46, wpb=108.7, bsz=40, num_updates=490, lr=5.28815e-06, gnorm=1.427, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1133
2023-01-06 15:10:17 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0266, wps=102.9, ups=0.47, wpb=109.9, bsz=40, num_updates=500, lr=5.39607e-06, gnorm=1.57, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1156
2023-01-06 15:10:40 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.058, wps=103.9, ups=0.47, wpb=109.7, bsz=40, num_updates=510, lr=5.50399e-06, gnorm=1.455, clip=90, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1179
2023-01-06 15:11:03 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 115845 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0286, wps=99, ups=0.46, wpb=107.9, bsz=40, num_updates=520, lr=5.61191e-06, gnorm=1.451, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1202
2023-01-06 15:11:26 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 115845 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0199, wps=101.7, ups=0.47, wpb=108.5, bsz=40, num_updates=530, lr=5.71984e-06, gnorm=1.411, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1224
2023-01-06 15:11:49 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 115845 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0273, wps=103.3, ups=0.47, wpb=109.5, bsz=40, num_updates=540, lr=5.82776e-06, gnorm=1.363, clip=80, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1248
2023-01-06 15:12:12 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 115845 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0294, wps=100.1, ups=0.45, wpb=110.6, bsz=40, num_updates=550, lr=5.93568e-06, gnorm=1.391, clip=90, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=1271
2023-01-06 15:12:36 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 115845 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.051, wps=100.4, ups=0.46, wpb=109.3, bsz=40, num_updates=560, lr=6.0436e-06, gnorm=1.573, clip=100, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=1294
2023-01-06 15:12:58 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 115845 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0299, wps=103, ups=0.47, wpb=109.5, bsz=40, num_updates=570, lr=6.15152e-06, gnorm=1.295, clip=100, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1317
2023-01-06 15:13:21 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 115845 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0469, wps=101.6, ups=0.47, wpb=108.7, bsz=40, num_updates=580, lr=6.25944e-06, gnorm=1.294, clip=80, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=1340
2023-01-06 15:13:45 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 115845 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0198, wps=102.5, ups=0.47, wpb=109.4, bsz=40, num_updates=590, lr=6.36736e-06, gnorm=1.392, clip=100, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1363
2023-01-06 15:14:08 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0153, wps=100, ups=0.46, wpb=109.6, bsz=40, num_updates=600, lr=6.47529e-06, gnorm=1.32, clip=100, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=1387
2023-01-06 15:14:31 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 115845 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0493, wps=101.3, ups=0.47, wpb=108.7, bsz=40, num_updates=610, lr=6.58321e-06, gnorm=1.435, clip=100, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1410
2023-01-06 15:14:53 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 115845 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, vqa_score=0.0202, wps=103.5, ups=0.47, wpb=109.6, bsz=40, num_updates=620, lr=6.69113e-06, gnorm=1.312, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1432
2023-01-06 15:15:17 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0253, wps=101.4, ups=0.46, wpb=109.9, bsz=40, num_updates=630, lr=6.79905e-06, gnorm=1.388, clip=90, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1455
2023-01-06 15:15:40 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0514, wps=103.3, ups=0.47, wpb=111, bsz=40, num_updates=640, lr=6.90697e-06, gnorm=1.453, clip=100, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1479
2023-01-06 15:16:03 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0326, wps=98.4, ups=0.46, wpb=107.6, bsz=40, num_updates=650, lr=7.01489e-06, gnorm=1.467, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1502
2023-01-06 15:16:27 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 115845 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0254, wps=100, ups=0.46, wpb=109, bsz=40, num_updates=660, lr=7.12281e-06, gnorm=1.541, clip=100, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=1526
2023-01-06 15:16:49 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 115845 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0294, wps=103.7, ups=0.47, wpb=109.9, bsz=40, num_updates=670, lr=7.23074e-06, gnorm=1.242, clip=60, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1548
2023-01-06 15:17:12 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 115845 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0202, wps=102.4, ups=0.47, wpb=109.6, bsz=40, num_updates=680, lr=7.33866e-06, gnorm=1.322, clip=90, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1571
2023-01-06 15:17:35 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0394, wps=102.1, ups=0.47, wpb=109.4, bsz=40, num_updates=690, lr=7.44658e-06, gnorm=1.379, clip=100, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1594
2023-01-06 15:17:58 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 115845 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0205, wps=101.5, ups=0.46, wpb=109.2, bsz=40, num_updates=700, lr=7.5545e-06, gnorm=1.487, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1617
2023-01-06 15:18:20 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0107, wps=103.6, ups=0.47, wpb=110.3, bsz=40, num_updates=710, lr=7.66242e-06, gnorm=1.267, clip=90, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1640
2023-01-06 15:18:43 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0306, wps=103.3, ups=0.47, wpb=109.2, bsz=40, num_updates=720, lr=7.77034e-06, gnorm=1.286, clip=100, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1662
2023-01-06 15:19:06 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 115845 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0324, wps=101.8, ups=0.46, wpb=110.5, bsz=40, num_updates=730, lr=7.87826e-06, gnorm=1.302, clip=80, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=1685
2023-01-06 15:19:29 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 115845 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, vqa_score=0.0151, wps=102.4, ups=0.47, wpb=109.5, bsz=40, num_updates=740, lr=7.98619e-06, gnorm=1.309, clip=90, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1708
2023-01-06 15:19:52 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 115845 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.044, wps=103.2, ups=0.47, wpb=110.4, bsz=40, num_updates=750, lr=8.09411e-06, gnorm=1.418, clip=100, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1731
2023-01-06 15:20:15 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0107, wps=100.5, ups=0.46, wpb=109.3, bsz=40, num_updates=760, lr=8.20203e-06, gnorm=1.144, clip=80, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=1754
2023-01-06 15:20:38 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 115845 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0259, wps=105, ups=0.47, wpb=111.5, bsz=40, num_updates=770, lr=8.30995e-06, gnorm=1.243, clip=90, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1777
2023-01-06 15:21:01 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0203, wps=99.8, ups=0.46, wpb=108.6, bsz=40, num_updates=780, lr=8.41787e-06, gnorm=1.364, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1800
2023-01-06 15:21:25 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 115845 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0359, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=790, lr=8.52579e-06, gnorm=1.261, clip=80, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1823
2023-01-06 15:21:47 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0294, wps=101.1, ups=0.47, wpb=108, bsz=40, num_updates=800, lr=8.63371e-06, gnorm=1.523, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1847
2023-01-06 15:22:10 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 115845 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0248, wps=102, ups=0.47, wpb=108.6, bsz=40, num_updates=810, lr=8.74164e-06, gnorm=1.545, clip=100, loss_scale=256, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=1869
2023-01-06 15:22:32 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 115845 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0201, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=820, lr=8.84956e-06, gnorm=1.343, clip=100, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=1892
2023-01-06 15:22:54 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 115845 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0153, wps=101.6, ups=0.47, wpb=107.8, bsz=40, num_updates=830, lr=8.95748e-06, gnorm=1.331, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1914
2023-01-06 15:23:15 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 115845 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.035, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=840, lr=9.0654e-06, gnorm=1.174, clip=70, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1936
2023-01-06 15:23:37 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0239, wps=102.9, ups=0.47, wpb=109.3, bsz=40, num_updates=850, lr=9.17332e-06, gnorm=1.23, clip=80, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1957
2023-01-06 15:23:59 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 115845 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0385, wps=101.9, ups=0.46, wpb=109.9, bsz=40, num_updates=860, lr=9.28124e-06, gnorm=1.294, clip=70, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=1979
2023-01-06 15:24:21 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 115845 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0246, wps=100, ups=0.46, wpb=108.2, bsz=40, num_updates=870, lr=9.38916e-06, gnorm=1.299, clip=80, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2001
2023-01-06 15:24:43 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0287, wps=100.9, ups=0.46, wpb=110.8, bsz=40, num_updates=880, lr=9.49709e-06, gnorm=1.263, clip=90, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=2023
2023-01-06 15:25:04 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0153, wps=104.6, ups=0.47, wpb=111.1, bsz=40, num_updates=890, lr=9.60501e-06, gnorm=1.274, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2044
2023-01-06 15:25:26 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 115845 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0154, wps=101.6, ups=0.47, wpb=108.3, bsz=40, num_updates=900, lr=9.71293e-06, gnorm=1.374, clip=100, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2066
2023-01-06 15:25:48 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 115845 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0381, wps=101.1, ups=0.46, wpb=108.9, bsz=40, num_updates=910, lr=9.82085e-06, gnorm=1.328, clip=90, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=2088
2023-01-06 15:26:10 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 115845 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0192, wps=98.2, ups=0.46, wpb=107.9, bsz=40, num_updates=920, lr=9.92877e-06, gnorm=1.601, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2110
2023-01-06 15:26:32 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 115845 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0265, wps=99, ups=0.46, wpb=107.7, bsz=40, num_updates=930, lr=1.00367e-05, gnorm=1.433, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2132
2023-01-06 15:26:54 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 115845 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0253, wps=99.7, ups=0.46, wpb=108.5, bsz=40, num_updates=940, lr=1.01446e-05, gnorm=1.436, clip=100, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=2154
2023-01-06 15:27:15 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 115845 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0343, wps=103.1, ups=0.47, wpb=108.8, bsz=40, num_updates=950, lr=1.02525e-05, gnorm=1.375, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2175
2023-01-06 15:27:37 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0197, wps=102.9, ups=0.47, wpb=109.3, bsz=40, num_updates=960, lr=1.03605e-05, gnorm=1.253, clip=90, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2197
2023-01-06 15:27:59 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0243, wps=98.9, ups=0.46, wpb=107.9, bsz=40, num_updates=970, lr=1.04684e-05, gnorm=1.134, clip=60, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=2219
2023-01-06 15:28:20 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0146, wps=101.6, ups=0.47, wpb=108.9, bsz=40, num_updates=980, lr=1.05763e-05, gnorm=1.297, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2241
2023-01-06 15:28:42 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 115845 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0377, wps=102.4, ups=0.47, wpb=109.5, bsz=40, num_updates=990, lr=1.06842e-05, gnorm=1.416, clip=90, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2262
2023-01-06 15:29:04 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 115845 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0296, wps=101.4, ups=0.47, wpb=107.8, bsz=40, num_updates=1000, lr=1.07921e-05, gnorm=1.403, clip=100, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=2284
2023-01-06 15:29:25 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 115845 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0242, wps=100.8, ups=0.46, wpb=108.4, bsz=40, num_updates=1010, lr=1.09001e-05, gnorm=1.4, clip=90, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=2305
2023-01-06 15:29:47 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 115845 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0201, wps=102.3, ups=0.46, wpb=110.2, bsz=40, num_updates=1020, lr=1.1008e-05, gnorm=1.322, clip=90, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2327
2023-01-06 15:30:09 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 115845 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0383, wps=101.5, ups=0.46, wpb=109.3, bsz=40, num_updates=1030, lr=1.11159e-05, gnorm=1.291, clip=90, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2349
2023-01-06 15:30:31 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 115845 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0195, wps=99.8, ups=0.46, wpb=108.9, bsz=40, num_updates=1040, lr=1.12238e-05, gnorm=1.369, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2371
2023-01-06 15:30:53 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0202, wps=101.1, ups=0.46, wpb=109.4, bsz=40, num_updates=1050, lr=1.13318e-05, gnorm=1.322, clip=90, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=2393
2023-01-06 15:31:15 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0321, wps=102.6, ups=0.46, wpb=110.4, bsz=40, num_updates=1060, lr=1.14397e-05, gnorm=1.044, clip=60, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2415
2023-01-06 15:31:36 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 115845 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0388, wps=101.9, ups=0.47, wpb=108.7, bsz=40, num_updates=1070, lr=1.15476e-05, gnorm=1.343, clip=100, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2436
2023-01-06 15:31:58 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0421, wps=102.7, ups=0.47, wpb=110.1, bsz=40, num_updates=1080, lr=1.16555e-05, gnorm=1.293, clip=90, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=2458
2023-01-06 15:32:19 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 115845 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0258, wps=102.6, ups=0.47, wpb=109.8, bsz=40, num_updates=1090, lr=1.17634e-05, gnorm=1.303, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2480
2023-01-06 15:32:41 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0335, wps=103.4, ups=0.47, wpb=110.1, bsz=40, num_updates=1100, lr=1.18714e-05, gnorm=1.26, clip=70, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2501
2023-01-06 15:33:03 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 115845 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0154, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=1110, lr=1.19793e-05, gnorm=1.309, clip=100, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=2523
2023-01-06 15:33:24 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0048, wps=101.8, ups=0.47, wpb=108.2, bsz=40, num_updates=1120, lr=1.20872e-05, gnorm=1.373, clip=100, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2544
2023-01-06 15:33:46 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 115845 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.03, wps=100.3, ups=0.46, wpb=108.8, bsz=40, num_updates=1130, lr=1.21951e-05, gnorm=1.366, clip=100, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=2566
2023-01-06 15:34:08 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 115845 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0049, wps=101.4, ups=0.46, wpb=109.4, bsz=40, num_updates=1140, lr=1.2303e-05, gnorm=1.162, clip=80, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=2588
2023-01-06 15:34:30 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 115845 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0426, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=1150, lr=1.2411e-05, gnorm=1.275, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2610
2023-01-06 15:34:51 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 115845 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0327, wps=101.1, ups=0.47, wpb=108.3, bsz=40, num_updates=1160, lr=1.25189e-05, gnorm=1.302, clip=100, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2631
2023-01-06 15:35:13 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 115845 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0308, wps=100.9, ups=0.46, wpb=109.9, bsz=40, num_updates=1170, lr=1.26268e-05, gnorm=1.291, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2654
2023-01-06 15:35:36 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0333, wps=98.5, ups=0.45, wpb=108.8, bsz=40, num_updates=1180, lr=1.27347e-05, gnorm=1.376, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2676
2023-01-06 15:35:58 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 115845 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0242, wps=99.8, ups=0.46, wpb=109.1, bsz=40, num_updates=1190, lr=1.28427e-05, gnorm=1.174, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2698
2023-01-06 15:36:19 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 115845 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0234, wps=102.2, ups=0.47, wpb=107.9, bsz=40, num_updates=1200, lr=1.29506e-05, gnorm=1.223, clip=100, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=2719
2023-01-06 15:36:41 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 115845 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0431, wps=97.8, ups=0.45, wpb=108.4, bsz=40, num_updates=1210, lr=1.30585e-05, gnorm=1.403, clip=100, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=2742
2023-01-06 15:37:03 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0254, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=1220, lr=1.31664e-05, gnorm=1.231, clip=80, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=2763
2023-01-06 15:37:25 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 115845 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0481, wps=99.4, ups=0.46, wpb=108.2, bsz=40, num_updates=1230, lr=1.32743e-05, gnorm=1.432, clip=90, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=2785
2023-01-06 15:37:46 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0103, wps=102.3, ups=0.47, wpb=108.5, bsz=40, num_updates=1240, lr=1.33823e-05, gnorm=1.238, clip=80, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=2807
2023-01-06 15:38:08 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 115845 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0156, wps=100.4, ups=0.46, wpb=109.3, bsz=40, num_updates=1250, lr=1.34902e-05, gnorm=1.231, clip=70, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2829
2023-01-06 15:38:30 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0106, wps=101.7, ups=0.47, wpb=108.8, bsz=40, num_updates=1260, lr=1.35981e-05, gnorm=1.125, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2850
2023-01-06 15:38:52 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0051, wps=101.9, ups=0.47, wpb=108.3, bsz=40, num_updates=1270, lr=1.3706e-05, gnorm=1.166, clip=80, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=2872
2023-01-06 15:39:13 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 115845 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0207, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=1280, lr=1.38139e-05, gnorm=1.165, clip=70, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=2894
2023-01-06 15:39:35 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 115845 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0316, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=1290, lr=1.39219e-05, gnorm=1.445, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2916
2023-01-06 15:39:56 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.01, wps=105.2, ups=0.48, wpb=109.3, bsz=40, num_updates=1300, lr=1.40298e-05, gnorm=1.209, clip=80, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2937
2023-01-06 15:40:18 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 115845 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0345, wps=103.4, ups=0.47, wpb=109.4, bsz=40, num_updates=1310, lr=1.41377e-05, gnorm=1.281, clip=90, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2958
2023-01-06 15:40:40 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0303, wps=101.4, ups=0.46, wpb=110.2, bsz=40, num_updates=1320, lr=1.42456e-05, gnorm=1.2, clip=90, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=2980
2023-01-06 15:41:01 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0183, wps=103.9, ups=0.48, wpb=108.3, bsz=40, num_updates=1330, lr=1.43536e-05, gnorm=1.288, clip=80, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=3001
2023-01-06 15:41:22 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 115845 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0237, wps=100.9, ups=0.47, wpb=108.1, bsz=40, num_updates=1340, lr=1.44615e-05, gnorm=1.134, clip=70, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3023
2023-01-06 15:41:44 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 115845 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0145, wps=99.1, ups=0.46, wpb=107.3, bsz=40, num_updates=1350, lr=1.45694e-05, gnorm=1.261, clip=90, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=3045
2023-01-06 15:42:06 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 115845 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.025, wps=101.4, ups=0.47, wpb=108, bsz=40, num_updates=1360, lr=1.46773e-05, gnorm=1.426, clip=100, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3066
2023-01-06 15:42:27 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0206, wps=102.3, ups=0.47, wpb=109.1, bsz=40, num_updates=1370, lr=1.47852e-05, gnorm=1.357, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3088
2023-01-06 15:42:50 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 115845 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0097, wps=98.7, ups=0.45, wpb=108.7, bsz=40, num_updates=1380, lr=1.48932e-05, gnorm=1.142, clip=70, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3110
2023-01-06 15:43:11 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0273, wps=102.6, ups=0.47, wpb=109.4, bsz=40, num_updates=1390, lr=1.50011e-05, gnorm=1.258, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3131
2023-01-06 15:43:33 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 115845 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0185, wps=101.9, ups=0.47, wpb=108.8, bsz=40, num_updates=1400, lr=1.5109e-05, gnorm=1.136, clip=90, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3153
2023-01-06 15:43:55 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0093, wps=100.5, ups=0.46, wpb=108.6, bsz=40, num_updates=1410, lr=1.52169e-05, gnorm=1.253, clip=80, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3175
2023-01-06 15:44:17 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 115845 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0291, wps=99.6, ups=0.46, wpb=108.5, bsz=40, num_updates=1420, lr=1.53248e-05, gnorm=1.359, clip=90, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3197
2023-01-06 15:44:38 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0155, wps=100.9, ups=0.47, wpb=108.4, bsz=40, num_updates=1430, lr=1.54328e-05, gnorm=1.352, clip=90, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=3219
2023-01-06 15:45:00 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 115845 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0366, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=1440, lr=1.55407e-05, gnorm=1.127, clip=80, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3240
2023-01-06 15:45:21 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0211, wps=104.9, ups=0.48, wpb=109.1, bsz=40, num_updates=1450, lr=1.56486e-05, gnorm=1.175, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3261
2023-01-06 15:45:43 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 115845 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0317, wps=102.9, ups=0.47, wpb=109.9, bsz=40, num_updates=1460, lr=1.57565e-05, gnorm=1.094, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=3283
2023-01-06 15:46:05 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 115845 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0347, wps=103.5, ups=0.47, wpb=110.7, bsz=40, num_updates=1470, lr=1.58645e-05, gnorm=1.123, clip=80, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=3305
2023-01-06 15:46:26 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 115845 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0293, wps=102.6, ups=0.47, wpb=109.8, bsz=40, num_updates=1480, lr=1.59724e-05, gnorm=1.298, clip=80, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=3326
2023-01-06 15:46:48 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 115845 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0187, wps=101.8, ups=0.47, wpb=109.4, bsz=40, num_updates=1490, lr=1.60803e-05, gnorm=1.263, clip=90, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=3348
2023-01-06 15:47:10 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0235, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=1500, lr=1.61882e-05, gnorm=1.23, clip=70, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3370
2023-01-06 15:47:32 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 115845 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.033, wps=98.6, ups=0.46, wpb=107.7, bsz=40, num_updates=1510, lr=1.62961e-05, gnorm=1.306, clip=80, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3392
2023-01-06 15:47:53 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0193, wps=101.2, ups=0.47, wpb=107.9, bsz=40, num_updates=1520, lr=1.64041e-05, gnorm=1.179, clip=80, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3414
2023-01-06 15:48:15 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0251, wps=102.5, ups=0.47, wpb=109.7, bsz=40, num_updates=1530, lr=1.6512e-05, gnorm=1.078, clip=60, loss_scale=512, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=3435
2023-01-06 15:48:37 - progress_bar.py[line:274] - INFO: epoch 001:   1540 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.033, wps=100.7, ups=0.46, wpb=109.9, bsz=40, num_updates=1540, lr=1.66199e-05, gnorm=1.213, clip=90, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3457
2023-01-06 15:48:59 - progress_bar.py[line:274] - INFO: epoch 001:   1550 / 115845 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0209, wps=102.1, ups=0.47, wpb=109, bsz=40, num_updates=1550, lr=1.67278e-05, gnorm=1.155, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3479
2023-01-06 15:49:21 - progress_bar.py[line:274] - INFO: epoch 001:   1560 / 115845 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0097, wps=100.7, ups=0.46, wpb=108.8, bsz=40, num_updates=1560, lr=1.68357e-05, gnorm=1.197, clip=70, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3501
2023-01-06 15:49:42 - progress_bar.py[line:274] - INFO: epoch 001:   1570 / 115845 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.05, wps=101.4, ups=0.47, wpb=108.5, bsz=40, num_updates=1570, lr=1.69437e-05, gnorm=1.123, clip=80, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3522
2023-01-06 15:50:04 - progress_bar.py[line:274] - INFO: epoch 001:   1580 / 115845 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0207, wps=104, ups=0.47, wpb=110.1, bsz=40, num_updates=1580, lr=1.70516e-05, gnorm=1.139, clip=60, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3544
2023-01-06 15:50:26 - progress_bar.py[line:274] - INFO: epoch 001:   1590 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0105, wps=99.7, ups=0.46, wpb=108.7, bsz=40, num_updates=1590, lr=1.71595e-05, gnorm=0.998, clip=60, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3566
2023-01-06 15:50:48 - progress_bar.py[line:274] - INFO: epoch 001:   1600 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0335, wps=99, ups=0.46, wpb=107, bsz=40, num_updates=1600, lr=1.72674e-05, gnorm=1.405, clip=100, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3588
2023-01-06 15:51:09 - progress_bar.py[line:274] - INFO: epoch 001:   1610 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0095, wps=100.6, ups=0.47, wpb=107.3, bsz=40, num_updates=1610, lr=1.73754e-05, gnorm=1.241, clip=90, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3609
2023-01-06 15:51:31 - progress_bar.py[line:274] - INFO: epoch 001:   1620 / 115845 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0306, wps=101.6, ups=0.46, wpb=109.4, bsz=40, num_updates=1620, lr=1.74833e-05, gnorm=1.111, clip=80, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3631
2023-01-06 15:51:52 - progress_bar.py[line:274] - INFO: epoch 001:   1630 / 115845 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0363, wps=104, ups=0.48, wpb=108.1, bsz=40, num_updates=1630, lr=1.75912e-05, gnorm=1.142, clip=80, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3652
2023-01-06 15:52:14 - progress_bar.py[line:274] - INFO: epoch 001:   1640 / 115845 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0149, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=1640, lr=1.76991e-05, gnorm=1.153, clip=70, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3674
2023-01-06 15:52:36 - progress_bar.py[line:274] - INFO: epoch 001:   1650 / 115845 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0441, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=1650, lr=1.7807e-05, gnorm=1.13, clip=60, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=3696
2023-01-06 15:52:57 - progress_bar.py[line:274] - INFO: epoch 001:   1660 / 115845 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0251, wps=101.9, ups=0.47, wpb=109.3, bsz=40, num_updates=1660, lr=1.7915e-05, gnorm=1.137, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3718
2023-01-06 15:53:06 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 15:53:21 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=109.476, nsentences=40, sample_size=109.476, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0327, wps=98.8, ups=0.43, wpb=109.5, bsz=40, num_updates=1670, lr=1.80229e-05, gnorm=1.208, clip=90, loss_scale=512, train_wall=23, gb_free=9.7, ema_decay=0.9999, wall=3741
2023-01-06 15:53:42 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 115845 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0404, wps=103.9, ups=0.47, wpb=110.1, bsz=40, num_updates=1680, lr=1.81308e-05, gnorm=1.058, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3762
2023-01-06 15:54:03 - progress_bar.py[line:274] - INFO: epoch 001:   1691 / 115845 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0291, wps=104.7, ups=0.48, wpb=109.7, bsz=40, num_updates=1690, lr=1.82387e-05, gnorm=1.107, clip=70, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=3784
2023-01-06 15:54:25 - progress_bar.py[line:274] - INFO: epoch 001:   1701 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0113, wps=102.1, ups=0.47, wpb=108.9, bsz=40, num_updates=1700, lr=1.83466e-05, gnorm=1.085, clip=70, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3805
2023-01-06 15:54:47 - progress_bar.py[line:274] - INFO: epoch 001:   1711 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0256, wps=100.5, ups=0.46, wpb=109, bsz=40, num_updates=1710, lr=1.84546e-05, gnorm=1.244, clip=90, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3827
2023-01-06 15:55:09 - progress_bar.py[line:274] - INFO: epoch 001:   1721 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0567, wps=101.4, ups=0.46, wpb=110, bsz=40, num_updates=1720, lr=1.85625e-05, gnorm=1.02, clip=50, loss_scale=512, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=3849
2023-01-06 15:55:31 - progress_bar.py[line:274] - INFO: epoch 001:   1731 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0273, wps=100.3, ups=0.46, wpb=109.4, bsz=40, num_updates=1730, lr=1.86704e-05, gnorm=1.071, clip=50, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=3871
2023-01-06 15:55:53 - progress_bar.py[line:274] - INFO: epoch 001:   1741 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0201, wps=100.5, ups=0.46, wpb=108.6, bsz=40, num_updates=1740, lr=1.87783e-05, gnorm=1.294, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3893
2023-01-06 15:56:15 - progress_bar.py[line:274] - INFO: epoch 001:   1751 / 115845 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.026, wps=98.9, ups=0.45, wpb=109.1, bsz=40, num_updates=1750, lr=1.88863e-05, gnorm=1.067, clip=40, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3915
2023-01-06 15:56:37 - progress_bar.py[line:274] - INFO: epoch 001:   1761 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0192, wps=98.5, ups=0.45, wpb=108.9, bsz=40, num_updates=1760, lr=1.89942e-05, gnorm=1.05, clip=60, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=3938
2023-01-06 15:56:59 - progress_bar.py[line:274] - INFO: epoch 001:   1771 / 115845 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0148, wps=103.6, ups=0.48, wpb=108.7, bsz=40, num_updates=1770, lr=1.91021e-05, gnorm=1.206, clip=80, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3959
2023-01-06 15:57:21 - progress_bar.py[line:274] - INFO: epoch 001:   1781 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0155, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=1780, lr=1.921e-05, gnorm=1.136, clip=70, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=3981
2023-01-06 15:57:42 - progress_bar.py[line:274] - INFO: epoch 001:   1791 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0326, wps=102.6, ups=0.46, wpb=110.5, bsz=40, num_updates=1790, lr=1.93179e-05, gnorm=1.088, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4003
2023-01-06 15:58:04 - progress_bar.py[line:274] - INFO: epoch 001:   1801 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.035, wps=101.2, ups=0.47, wpb=108.8, bsz=40, num_updates=1800, lr=1.94259e-05, gnorm=1.113, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4024
2023-01-06 15:58:26 - progress_bar.py[line:274] - INFO: epoch 001:   1811 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0196, wps=102.6, ups=0.47, wpb=108.7, bsz=40, num_updates=1810, lr=1.95338e-05, gnorm=1.086, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4046
2023-01-06 15:58:47 - progress_bar.py[line:274] - INFO: epoch 001:   1821 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0433, wps=102.7, ups=0.47, wpb=110, bsz=40, num_updates=1820, lr=1.96417e-05, gnorm=1.089, clip=70, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=4067
2023-01-06 15:59:10 - progress_bar.py[line:274] - INFO: epoch 001:   1831 / 115845 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0243, wps=97.4, ups=0.45, wpb=107.8, bsz=40, num_updates=1830, lr=1.97496e-05, gnorm=1.093, clip=60, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=4090
2023-01-06 15:59:32 - progress_bar.py[line:274] - INFO: epoch 001:   1841 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0242, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=1840, lr=1.98575e-05, gnorm=1.26, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4112
2023-01-06 15:59:54 - progress_bar.py[line:274] - INFO: epoch 001:   1851 / 115845 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0249, wps=98.6, ups=0.45, wpb=108.6, bsz=40, num_updates=1850, lr=1.99655e-05, gnorm=1.149, clip=80, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4134
2023-01-06 16:00:15 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 115845 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.041, wps=101.1, ups=0.47, wpb=108.6, bsz=40, num_updates=1860, lr=2.00734e-05, gnorm=1.18, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4156
2023-01-06 16:00:37 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0145, wps=99.7, ups=0.46, wpb=107.3, bsz=40, num_updates=1870, lr=2.01813e-05, gnorm=1.113, clip=70, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=4177
2023-01-06 16:00:59 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 115845 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0291, wps=100.2, ups=0.46, wpb=108.2, bsz=40, num_updates=1880, lr=2.02892e-05, gnorm=1.141, clip=70, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=4199
2023-01-06 16:01:21 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 115845 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.034, wps=103.5, ups=0.47, wpb=109.9, bsz=40, num_updates=1890, lr=2.03972e-05, gnorm=1.15, clip=80, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4221
2023-01-06 16:01:42 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 115845 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0243, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=1900, lr=2.05051e-05, gnorm=1.164, clip=80, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4243
2023-01-06 16:02:04 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0226, wps=102.7, ups=0.46, wpb=111.5, bsz=40, num_updates=1910, lr=2.0613e-05, gnorm=1.174, clip=70, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=4264
2023-01-06 16:02:25 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 115845 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0151, wps=104.9, ups=0.48, wpb=109.2, bsz=40, num_updates=1920, lr=2.07209e-05, gnorm=1.05, clip=60, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=4285
2023-01-06 16:02:47 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0191, wps=99.7, ups=0.46, wpb=108.2, bsz=40, num_updates=1930, lr=2.08288e-05, gnorm=1.231, clip=90, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=4307
2023-01-06 16:03:09 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 115845 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0102, wps=101.9, ups=0.46, wpb=109.6, bsz=40, num_updates=1940, lr=2.09368e-05, gnorm=1.126, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4329
2023-01-06 16:03:31 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0237, wps=99.8, ups=0.46, wpb=109.5, bsz=40, num_updates=1950, lr=2.10447e-05, gnorm=1.027, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4351
2023-01-06 16:03:53 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 115845 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0191, wps=103, ups=0.47, wpb=109.1, bsz=40, num_updates=1960, lr=2.11526e-05, gnorm=1.182, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4373
2023-01-06 16:04:15 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 115845 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0243, wps=97.1, ups=0.45, wpb=108.1, bsz=40, num_updates=1970, lr=2.12605e-05, gnorm=1.117, clip=80, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=4396
2023-01-06 16:04:38 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 115845 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0208, wps=99.6, ups=0.46, wpb=108.4, bsz=40, num_updates=1980, lr=2.13684e-05, gnorm=1.056, clip=60, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4418
2023-01-06 16:04:59 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0185, wps=100.4, ups=0.47, wpb=107.9, bsz=40, num_updates=1990, lr=2.14764e-05, gnorm=1.143, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4439
2023-01-06 16:05:21 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 115845 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0198, wps=101.3, ups=0.47, wpb=108.7, bsz=40, num_updates=2000, lr=2.15843e-05, gnorm=1.098, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4461
2023-01-06 16:05:21 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-06 16:05:21 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-01-06 16:05:22 - train.py[line:549] - INFO: 0 / 4988
2023-01-06 16:05:22 - train.py[line:551] - INFO: load:0.91 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-06 16:07:55 - train.py[line:549] - INFO: 200 / 4988
2023-01-06 16:07:55 - train.py[line:551] - INFO: load:0.93 valid_run:152.71 task_valid:148.19 collect_output:3.35
2023-01-06 16:10:24 - train.py[line:549] - INFO: 400 / 4988
2023-01-06 16:10:24 - train.py[line:551] - INFO: load:0.96 valid_run:301.85 task_valid:289.90 collect_output:9.70
2023-01-06 16:12:58 - train.py[line:549] - INFO: 600 / 4988
2023-01-06 16:12:58 - train.py[line:551] - INFO: load:0.98 valid_run:455.02 task_valid:432.08 collect_output:19.59
2023-01-06 16:15:26 - train.py[line:549] - INFO: 800 / 4988
2023-01-06 16:15:26 - train.py[line:551] - INFO: load:1.01 valid_run:603.76 task_valid:576.04 collect_output:23.27
2023-01-06 16:17:59 - train.py[line:549] - INFO: 1000 / 4988
2023-01-06 16:17:59 - train.py[line:551] - INFO: load:1.03 valid_run:755.88 task_valid:722.51 collect_output:27.83
2023-01-06 16:20:31 - train.py[line:549] - INFO: 1200 / 4988
2023-01-06 16:20:31 - train.py[line:551] - INFO: load:1.06 valid_run:907.71 task_valid:866.88 collect_output:34.17
2023-01-06 16:23:05 - train.py[line:549] - INFO: 1400 / 4988
2023-01-06 16:23:05 - train.py[line:551] - INFO: load:1.09 valid_run:1061.72 task_valid:1012.04 collect_output:41.90
2023-01-06 16:25:36 - train.py[line:549] - INFO: 1600 / 4988
2023-01-06 16:25:36 - train.py[line:551] - INFO: load:1.11 valid_run:1213.39 task_valid:1152.06 collect_output:52.47
2023-01-06 16:28:06 - train.py[line:549] - INFO: 1800 / 4988
2023-01-06 16:28:06 - train.py[line:551] - INFO: load:1.13 valid_run:1362.93 task_valid:1295.49 collect_output:57.53
2023-01-06 16:30:35 - train.py[line:549] - INFO: 2000 / 4988
2023-01-06 16:30:35 - train.py[line:551] - INFO: load:1.16 valid_run:1511.61 task_valid:1437.54 collect_output:63.09
2023-01-06 16:33:05 - train.py[line:549] - INFO: 2200 / 4988
2023-01-06 16:33:05 - train.py[line:551] - INFO: load:1.19 valid_run:1661.45 task_valid:1581.47 collect_output:67.93
2023-01-06 16:35:35 - train.py[line:549] - INFO: 2400 / 4988
2023-01-06 16:35:35 - train.py[line:551] - INFO: load:1.21 valid_run:1811.33 task_valid:1725.12 collect_output:73.10
2023-01-06 16:38:05 - train.py[line:549] - INFO: 2600 / 4988
2023-01-06 16:38:05 - train.py[line:551] - INFO: load:1.24 valid_run:1961.34 task_valid:1865.80 collect_output:81.34
2023-01-06 16:40:35 - train.py[line:549] - INFO: 2800 / 4988
2023-01-06 16:40:35 - train.py[line:551] - INFO: load:1.26 valid_run:2111.56 task_valid:2010.05 collect_output:86.23
2023-01-06 16:43:05 - train.py[line:549] - INFO: 3000 / 4988
2023-01-06 16:43:05 - train.py[line:551] - INFO: load:1.29 valid_run:2261.16 task_valid:2155.22 collect_output:89.61
2023-01-06 16:45:35 - train.py[line:549] - INFO: 3200 / 4988
2023-01-06 16:45:35 - train.py[line:551] - INFO: load:1.31 valid_run:2410.97 task_valid:2298.07 collect_output:95.53
2023-01-06 16:48:06 - train.py[line:549] - INFO: 3400 / 4988
2023-01-06 16:48:06 - train.py[line:551] - INFO: load:1.34 valid_run:2562.42 task_valid:2442.15 collect_output:101.83
2023-01-06 16:50:36 - train.py[line:549] - INFO: 3600 / 4988
2023-01-06 16:50:36 - train.py[line:551] - INFO: load:1.37 valid_run:2712.70 task_valid:2587.67 collect_output:105.53
2023-01-06 16:53:05 - train.py[line:549] - INFO: 3800 / 4988
2023-01-06 16:53:05 - train.py[line:551] - INFO: load:1.39 valid_run:2861.46 task_valid:2727.58 collect_output:113.34
2023-01-06 16:55:36 - train.py[line:549] - INFO: 4000 / 4988
2023-01-06 16:55:36 - train.py[line:551] - INFO: load:1.42 valid_run:3012.35 task_valid:2871.66 collect_output:119.08
2023-01-06 16:58:09 - train.py[line:549] - INFO: 4200 / 4988
2023-01-06 16:58:09 - train.py[line:551] - INFO: load:1.45 valid_run:3165.27 task_valid:3014.95 collect_output:127.61
2023-01-06 17:00:39 - train.py[line:549] - INFO: 4400 / 4988
2023-01-06 17:00:39 - train.py[line:551] - INFO: load:1.48 valid_run:3314.34 task_valid:3158.04 collect_output:132.56
2023-01-06 17:03:10 - train.py[line:549] - INFO: 4600 / 4988
2023-01-06 17:03:10 - train.py[line:551] - INFO: load:1.50 valid_run:3465.16 task_valid:3302.66 collect_output:137.72
2023-01-06 17:05:41 - train.py[line:549] - INFO: 4800 / 4988
2023-01-06 17:05:41 - train.py[line:551] - INFO: load:1.53 valid_run:3616.19 task_valid:3447.90 collect_output:142.45

====================================================================================================
SGG eval:     R @ 50: 0.2813;     R @ 100: 0.3496;     R @ 500: 0.4105;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1267;    mR @ 100: 0.1834;    mR @ 500: 0.2226;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0439) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.3931) (says:0.0000) (sitting on:0.4238) (standing on:0.5183) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-01-06 17:08:10 - train.py[line:487] - INFO: 0.34956666666666664

====================================================================================================
SGG eval:     R @ 50: 0.2813;     R @ 100: 0.3496;     R @ 500: 0.4105;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1267;    mR @ 100: 0.1834;    mR @ 500: 0.2226;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0439) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.3931) (says:0.0000) (sitting on:0.4238) (standing on:0.5183) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-01-06 17:08:10 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-06 17:08:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.317 | loss_v1 0 | loss_v2 0 | nll_loss 0.16 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.349567 | ppl 1.12 | vqa_score 0.1745 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 2000
2023-01-06 17:08:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2023-01-06 17:08:11 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_2000.pt
2023-01-06 17:08:56 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_2000.pt
2023-01-06 17:11:56 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.34956666666666664) (writing took 225.27363085374236 seconds)
2023-01-06 17:12:19 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0099, wps=0.5, ups=0, wpb=108.2, bsz=40, num_updates=2010, lr=2.16922e-05, gnorm=1.015, clip=40, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=8478
2023-01-06 17:12:41 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0267, wps=100.9, ups=0.46, wpb=110, bsz=40, num_updates=2020, lr=2.18001e-05, gnorm=1.059, clip=60, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8501
2023-01-06 17:13:03 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 115845 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0193, wps=101.7, ups=0.47, wpb=108.4, bsz=40, num_updates=2030, lr=2.19081e-05, gnorm=1.018, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8523
2023-01-06 17:13:24 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0169, wps=102.5, ups=0.47, wpb=110.2, bsz=40, num_updates=2040, lr=2.2016e-05, gnorm=1.164, clip=80, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=8545
2023-01-06 17:13:46 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0222, wps=103.4, ups=0.47, wpb=111, bsz=40, num_updates=2050, lr=2.21239e-05, gnorm=1.054, clip=60, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=8566
2023-01-06 17:14:08 - progress_bar.py[line:274] - INFO: epoch 001:   2061 / 115845 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0244, wps=103.3, ups=0.47, wpb=110, bsz=40, num_updates=2060, lr=2.22318e-05, gnorm=1.084, clip=60, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=8588
2023-01-06 17:14:30 - progress_bar.py[line:274] - INFO: epoch 001:   2071 / 115845 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0287, wps=96.3, ups=0.44, wpb=108.8, bsz=40, num_updates=2070, lr=2.23397e-05, gnorm=1.072, clip=70, loss_scale=512, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=8611
2023-01-06 17:14:52 - progress_bar.py[line:274] - INFO: epoch 001:   2081 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0376, wps=101.4, ups=0.46, wpb=109.8, bsz=40, num_updates=2080, lr=2.24477e-05, gnorm=1.058, clip=50, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8633
2023-01-06 17:15:14 - progress_bar.py[line:274] - INFO: epoch 001:   2091 / 115845 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0425, wps=101, ups=0.46, wpb=109.2, bsz=40, num_updates=2090, lr=2.25556e-05, gnorm=1.037, clip=60, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8654
2023-01-06 17:15:35 - progress_bar.py[line:274] - INFO: epoch 001:   2101 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0093, wps=103.5, ups=0.48, wpb=108, bsz=40, num_updates=2100, lr=2.26635e-05, gnorm=1.156, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8675
2023-01-06 17:15:57 - progress_bar.py[line:274] - INFO: epoch 001:   2111 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0366, wps=102.5, ups=0.47, wpb=108.9, bsz=40, num_updates=2110, lr=2.27714e-05, gnorm=0.978, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=8697
2023-01-06 17:16:18 - progress_bar.py[line:274] - INFO: epoch 001:   2121 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0253, wps=102.5, ups=0.47, wpb=108.4, bsz=40, num_updates=2120, lr=2.28793e-05, gnorm=1.024, clip=70, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=8718
2023-01-06 17:16:40 - progress_bar.py[line:274] - INFO: epoch 001:   2131 / 115845 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0214, wps=101, ups=0.46, wpb=110.1, bsz=40, num_updates=2130, lr=2.29873e-05, gnorm=1.007, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8740
2023-01-06 17:17:02 - progress_bar.py[line:274] - INFO: epoch 001:   2141 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0215, wps=100.9, ups=0.46, wpb=109, bsz=40, num_updates=2140, lr=2.30952e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8762
2023-01-06 17:17:24 - progress_bar.py[line:274] - INFO: epoch 001:   2151 / 115845 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=106.7, nsentences=40, sample_size=106.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0185, wps=99.8, ups=0.47, wpb=106.7, bsz=40, num_updates=2150, lr=2.32031e-05, gnorm=1.067, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8784
2023-01-06 17:17:45 - progress_bar.py[line:274] - INFO: epoch 001:   2161 / 115845 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0248, wps=102.3, ups=0.47, wpb=108.6, bsz=40, num_updates=2160, lr=2.3311e-05, gnorm=1.028, clip=50, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=8805
2023-01-06 17:18:07 - progress_bar.py[line:274] - INFO: epoch 001:   2171 / 115845 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0191, wps=101.6, ups=0.47, wpb=108.4, bsz=40, num_updates=2170, lr=2.3419e-05, gnorm=0.973, clip=40, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=8827
2023-01-06 17:18:28 - progress_bar.py[line:274] - INFO: epoch 001:   2181 / 115845 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0144, wps=100.2, ups=0.46, wpb=108.6, bsz=40, num_updates=2180, lr=2.35269e-05, gnorm=1.113, clip=40, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8849
2023-01-06 17:18:50 - progress_bar.py[line:274] - INFO: epoch 001:   2191 / 115845 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0239, wps=99.9, ups=0.46, wpb=107.8, bsz=40, num_updates=2190, lr=2.36348e-05, gnorm=1.151, clip=80, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8870
2023-01-06 17:18:54 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 17:19:14 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 115845 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=110.048, nsentences=40, sample_size=110.048, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0271, wps=96.3, ups=0.42, wpb=110, bsz=40, num_updates=2200, lr=2.37427e-05, gnorm=1.114, clip=60, loss_scale=512, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=8895
2023-01-06 17:19:36 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0246, wps=101.6, ups=0.46, wpb=109.7, bsz=40, num_updates=2210, lr=2.38506e-05, gnorm=0.944, clip=30, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8917
2023-01-06 17:19:58 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0226, wps=101.9, ups=0.47, wpb=107.6, bsz=40, num_updates=2220, lr=2.39586e-05, gnorm=0.939, clip=40, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=8938
2023-01-06 17:20:19 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 115845 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0205, wps=101.7, ups=0.47, wpb=109, bsz=40, num_updates=2230, lr=2.40665e-05, gnorm=1.303, clip=100, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=8960
2023-01-06 17:20:41 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 115845 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0297, wps=100.8, ups=0.46, wpb=110, bsz=40, num_updates=2240, lr=2.41744e-05, gnorm=1, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8982
2023-01-06 17:21:03 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0049, wps=100.1, ups=0.47, wpb=107.6, bsz=40, num_updates=2250, lr=2.42823e-05, gnorm=1.074, clip=60, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=9003
2023-01-06 17:21:25 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0343, wps=100.3, ups=0.46, wpb=108.1, bsz=40, num_updates=2260, lr=2.43902e-05, gnorm=1.2, clip=50, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=9025
2023-01-06 17:21:47 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.005, wps=98.6, ups=0.45, wpb=108.5, bsz=40, num_updates=2270, lr=2.44982e-05, gnorm=1.141, clip=60, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9047
2023-01-06 17:22:09 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 115845 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0203, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=2280, lr=2.46061e-05, gnorm=0.965, clip=40, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9069
2023-01-06 17:22:31 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0314, wps=100.8, ups=0.46, wpb=109.3, bsz=40, num_updates=2290, lr=2.4714e-05, gnorm=0.95, clip=40, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9091
2023-01-06 17:22:53 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0196, wps=99.1, ups=0.46, wpb=108, bsz=40, num_updates=2300, lr=2.48219e-05, gnorm=1.046, clip=50, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9113
2023-01-06 17:23:15 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0508, wps=98.3, ups=0.45, wpb=108.7, bsz=40, num_updates=2310, lr=2.49299e-05, gnorm=1.052, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9136
2023-01-06 17:23:37 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 115845 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0335, wps=101.6, ups=0.47, wpb=109, bsz=40, num_updates=2320, lr=2.50378e-05, gnorm=1.09, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=9157
2023-01-06 17:23:59 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0096, wps=100.1, ups=0.46, wpb=107.9, bsz=40, num_updates=2330, lr=2.51457e-05, gnorm=1.018, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9179
2023-01-06 17:24:21 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 115845 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0242, wps=101, ups=0.47, wpb=108.3, bsz=40, num_updates=2340, lr=2.52536e-05, gnorm=1.029, clip=50, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=9201
2023-01-06 17:24:42 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 115845 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0242, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=2350, lr=2.53615e-05, gnorm=1.105, clip=60, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9223
2023-01-06 17:25:04 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0219, wps=105.4, ups=0.47, wpb=111.2, bsz=40, num_updates=2360, lr=2.54695e-05, gnorm=0.936, clip=40, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=9244
2023-01-06 17:25:26 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 115845 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0273, wps=100.4, ups=0.46, wpb=109.5, bsz=40, num_updates=2370, lr=2.55774e-05, gnorm=1.033, clip=60, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9266
2023-01-06 17:25:47 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0345, wps=102.6, ups=0.47, wpb=108.5, bsz=40, num_updates=2380, lr=2.56853e-05, gnorm=0.98, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9287
2023-01-06 17:26:09 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0198, wps=99.8, ups=0.46, wpb=108.7, bsz=40, num_updates=2390, lr=2.57932e-05, gnorm=0.882, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=9309
2023-01-06 17:26:31 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0153, wps=102.3, ups=0.47, wpb=108.4, bsz=40, num_updates=2400, lr=2.59011e-05, gnorm=0.994, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9331
2023-01-06 17:26:52 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0508, wps=101, ups=0.47, wpb=108.6, bsz=40, num_updates=2410, lr=2.60091e-05, gnorm=0.998, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9353
2023-01-06 17:27:14 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0299, wps=102.9, ups=0.47, wpb=109.7, bsz=40, num_updates=2420, lr=2.6117e-05, gnorm=0.993, clip=40, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=9374
2023-01-06 17:27:36 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 115845 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0139, wps=99.7, ups=0.47, wpb=106.5, bsz=40, num_updates=2430, lr=2.62249e-05, gnorm=0.905, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9396
2023-01-06 17:27:57 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 115845 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0338, wps=102, ups=0.47, wpb=109.3, bsz=40, num_updates=2440, lr=2.63328e-05, gnorm=1.107, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9417
2023-01-06 17:28:19 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0471, wps=102.9, ups=0.47, wpb=110.4, bsz=40, num_updates=2450, lr=2.64408e-05, gnorm=1.038, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9439
2023-01-06 17:28:41 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 115845 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0312, wps=101.7, ups=0.46, wpb=109.4, bsz=40, num_updates=2460, lr=2.65487e-05, gnorm=1.06, clip=70, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=9461
2023-01-06 17:29:02 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0284, wps=102.3, ups=0.47, wpb=109.2, bsz=40, num_updates=2470, lr=2.66566e-05, gnorm=0.945, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9483
2023-01-06 17:29:24 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0333, wps=102, ups=0.47, wpb=109.6, bsz=40, num_updates=2480, lr=2.67645e-05, gnorm=0.937, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9504
2023-01-06 17:29:46 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 115845 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0478, wps=100.7, ups=0.46, wpb=108.4, bsz=40, num_updates=2490, lr=2.68724e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9526
2023-01-06 17:30:08 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 115845 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0245, wps=100.6, ups=0.46, wpb=108.5, bsz=40, num_updates=2500, lr=2.69804e-05, gnorm=0.848, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9548
2023-01-06 17:30:29 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 115845 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0248, wps=103.4, ups=0.47, wpb=109.4, bsz=40, num_updates=2510, lr=2.70883e-05, gnorm=0.958, clip=40, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=9569
2023-01-06 17:30:51 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.019, wps=100.9, ups=0.46, wpb=109.4, bsz=40, num_updates=2520, lr=2.71962e-05, gnorm=0.967, clip=40, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=9591
2023-01-06 17:31:12 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0262, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=2530, lr=2.73041e-05, gnorm=0.932, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9613
2023-01-06 17:31:34 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 115845 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0296, wps=102.4, ups=0.47, wpb=109.2, bsz=40, num_updates=2540, lr=2.7412e-05, gnorm=0.942, clip=20, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=9634
2023-01-06 17:31:56 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0321, wps=102.9, ups=0.47, wpb=109.8, bsz=40, num_updates=2550, lr=2.752e-05, gnorm=0.835, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9656
2023-01-06 17:32:17 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 115845 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0303, wps=101.1, ups=0.46, wpb=108.9, bsz=40, num_updates=2560, lr=2.76279e-05, gnorm=0.859, clip=30, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9678
2023-01-06 17:32:39 - progress_bar.py[line:274] - INFO: epoch 001:   2572 / 115845 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0326, wps=101.2, ups=0.47, wpb=108.2, bsz=40, num_updates=2570, lr=2.77358e-05, gnorm=0.835, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=9699
2023-01-06 17:33:01 - progress_bar.py[line:274] - INFO: epoch 001:   2582 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0419, wps=100.8, ups=0.46, wpb=109.9, bsz=40, num_updates=2580, lr=2.78437e-05, gnorm=1.012, clip=50, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=9721
2023-01-06 17:33:23 - progress_bar.py[line:274] - INFO: epoch 001:   2592 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0233, wps=98.2, ups=0.46, wpb=107.9, bsz=40, num_updates=2590, lr=2.79517e-05, gnorm=0.975, clip=40, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9743
2023-01-06 17:33:45 - progress_bar.py[line:274] - INFO: epoch 001:   2602 / 115845 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.03, wps=102, ups=0.47, wpb=109.1, bsz=40, num_updates=2600, lr=2.80596e-05, gnorm=0.904, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9765
2023-01-06 17:34:06 - progress_bar.py[line:274] - INFO: epoch 001:   2612 / 115845 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0291, wps=102.4, ups=0.47, wpb=110.1, bsz=40, num_updates=2610, lr=2.81675e-05, gnorm=1.063, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9787
2023-01-06 17:34:28 - progress_bar.py[line:274] - INFO: epoch 001:   2622 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0404, wps=100.6, ups=0.46, wpb=109.5, bsz=40, num_updates=2620, lr=2.82754e-05, gnorm=1.029, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9809
2023-01-06 17:34:50 - progress_bar.py[line:274] - INFO: epoch 001:   2632 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0337, wps=102.7, ups=0.47, wpb=109.7, bsz=40, num_updates=2630, lr=2.83833e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9830
2023-01-06 17:35:12 - progress_bar.py[line:274] - INFO: epoch 001:   2642 / 115845 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0205, wps=100.8, ups=0.47, wpb=108, bsz=40, num_updates=2640, lr=2.84913e-05, gnorm=0.966, clip=50, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9852
2023-01-06 17:35:33 - progress_bar.py[line:274] - INFO: epoch 001:   2652 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.019, wps=101.7, ups=0.47, wpb=107.5, bsz=40, num_updates=2650, lr=2.85992e-05, gnorm=1.008, clip=70, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=9873
2023-01-06 17:35:55 - progress_bar.py[line:274] - INFO: epoch 001:   2662 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0328, wps=102.4, ups=0.46, wpb=110.4, bsz=40, num_updates=2660, lr=2.87071e-05, gnorm=0.859, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=9895
2023-01-06 17:36:17 - progress_bar.py[line:274] - INFO: epoch 001:   2672 / 115845 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0237, wps=101.5, ups=0.46, wpb=109.9, bsz=40, num_updates=2670, lr=2.8815e-05, gnorm=0.825, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9917
2023-01-06 17:36:39 - progress_bar.py[line:274] - INFO: epoch 001:   2682 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0326, wps=100, ups=0.46, wpb=108.6, bsz=40, num_updates=2680, lr=2.89229e-05, gnorm=0.979, clip=30, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9939
2023-01-06 17:37:01 - progress_bar.py[line:274] - INFO: epoch 001:   2692 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0311, wps=100.5, ups=0.46, wpb=108.5, bsz=40, num_updates=2690, lr=2.90309e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9961
2023-01-06 17:37:22 - progress_bar.py[line:274] - INFO: epoch 001:   2702 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0352, wps=102.6, ups=0.47, wpb=109.7, bsz=40, num_updates=2700, lr=2.91388e-05, gnorm=1.001, clip=40, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=9983
2023-01-06 17:37:44 - progress_bar.py[line:274] - INFO: epoch 001:   2712 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0219, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=2710, lr=2.92467e-05, gnorm=0.793, clip=10, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=10004
2023-01-06 17:38:06 - progress_bar.py[line:274] - INFO: epoch 001:   2722 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.02, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=2720, lr=2.93546e-05, gnorm=0.867, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10026
2023-01-06 17:38:27 - progress_bar.py[line:274] - INFO: epoch 001:   2732 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.037, wps=101.6, ups=0.47, wpb=107.8, bsz=40, num_updates=2730, lr=2.94626e-05, gnorm=0.937, clip=30, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10048
2023-01-06 17:38:49 - progress_bar.py[line:274] - INFO: epoch 001:   2742 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0152, wps=103.2, ups=0.47, wpb=110, bsz=40, num_updates=2740, lr=2.95705e-05, gnorm=0.98, clip=50, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10069
2023-01-06 17:39:11 - progress_bar.py[line:274] - INFO: epoch 001:   2752 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0266, wps=101, ups=0.47, wpb=108, bsz=40, num_updates=2750, lr=2.96784e-05, gnorm=0.952, clip=50, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10091
2023-01-06 17:39:32 - progress_bar.py[line:274] - INFO: epoch 001:   2762 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0253, wps=105.3, ups=0.48, wpb=110.4, bsz=40, num_updates=2760, lr=2.97863e-05, gnorm=0.997, clip=40, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=10112
2023-01-06 17:39:54 - progress_bar.py[line:274] - INFO: epoch 001:   2772 / 115845 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0338, wps=99, ups=0.46, wpb=107.9, bsz=40, num_updates=2770, lr=2.98942e-05, gnorm=1.003, clip=40, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10134
2023-01-06 17:40:16 - progress_bar.py[line:274] - INFO: epoch 001:   2782 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0476, wps=99.3, ups=0.46, wpb=108.8, bsz=40, num_updates=2780, lr=3.00022e-05, gnorm=0.931, clip=40, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10156
2023-01-06 17:40:37 - progress_bar.py[line:274] - INFO: epoch 001:   2792 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0521, wps=102.5, ups=0.47, wpb=108.9, bsz=40, num_updates=2790, lr=3.01101e-05, gnorm=0.968, clip=60, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10178
2023-01-06 17:40:59 - progress_bar.py[line:274] - INFO: epoch 001:   2802 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0481, wps=101.2, ups=0.46, wpb=109.2, bsz=40, num_updates=2800, lr=3.0218e-05, gnorm=0.884, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=10199
2023-01-06 17:41:21 - progress_bar.py[line:274] - INFO: epoch 001:   2812 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0405, wps=104.4, ups=0.47, wpb=111.3, bsz=40, num_updates=2810, lr=3.03259e-05, gnorm=0.851, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10221
2023-01-06 17:41:42 - progress_bar.py[line:274] - INFO: epoch 001:   2822 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0406, wps=102.5, ups=0.47, wpb=108.7, bsz=40, num_updates=2820, lr=3.04338e-05, gnorm=1.008, clip=60, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10242
2023-01-06 17:42:04 - progress_bar.py[line:274] - INFO: epoch 001:   2832 / 115845 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0051, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=2830, lr=3.05418e-05, gnorm=1.007, clip=30, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10264
2023-01-06 17:42:26 - progress_bar.py[line:274] - INFO: epoch 001:   2842 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0166, wps=102.6, ups=0.47, wpb=109.3, bsz=40, num_updates=2840, lr=3.06497e-05, gnorm=0.894, clip=30, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10286
2023-01-06 17:42:47 - progress_bar.py[line:274] - INFO: epoch 001:   2852 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.015, wps=103.4, ups=0.47, wpb=109.3, bsz=40, num_updates=2850, lr=3.07576e-05, gnorm=0.893, clip=40, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10307
2023-01-06 17:43:09 - progress_bar.py[line:274] - INFO: epoch 001:   2862 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.029, wps=98.7, ups=0.45, wpb=108.6, bsz=40, num_updates=2860, lr=3.08655e-05, gnorm=0.77, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10330
2023-01-06 17:43:31 - progress_bar.py[line:274] - INFO: epoch 001:   2872 / 115845 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0386, wps=101, ups=0.46, wpb=109.3, bsz=40, num_updates=2870, lr=3.09735e-05, gnorm=0.882, clip=30, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=10351
2023-01-06 17:43:53 - progress_bar.py[line:274] - INFO: epoch 001:   2882 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0152, wps=101.8, ups=0.47, wpb=109.1, bsz=40, num_updates=2880, lr=3.10814e-05, gnorm=0.878, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10373
2023-01-06 17:44:14 - progress_bar.py[line:274] - INFO: epoch 001:   2892 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.025, wps=103.2, ups=0.47, wpb=109.3, bsz=40, num_updates=2890, lr=3.11893e-05, gnorm=0.836, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10394
2023-01-06 17:44:36 - progress_bar.py[line:274] - INFO: epoch 001:   2902 / 115845 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0244, wps=102, ups=0.47, wpb=109.3, bsz=40, num_updates=2900, lr=3.12972e-05, gnorm=0.805, clip=20, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10416
2023-01-06 17:44:57 - progress_bar.py[line:274] - INFO: epoch 001:   2912 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0303, wps=103.4, ups=0.48, wpb=108.8, bsz=40, num_updates=2910, lr=3.14051e-05, gnorm=0.817, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10437
2023-01-06 17:45:19 - progress_bar.py[line:274] - INFO: epoch 001:   2922 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0048, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=2920, lr=3.15131e-05, gnorm=0.865, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10459
2023-01-06 17:45:41 - progress_bar.py[line:274] - INFO: epoch 001:   2932 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0306, wps=101.9, ups=0.47, wpb=109.1, bsz=40, num_updates=2930, lr=3.1621e-05, gnorm=0.937, clip=40, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10481
2023-01-06 17:46:02 - progress_bar.py[line:274] - INFO: epoch 001:   2942 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0243, wps=100.9, ups=0.47, wpb=108.1, bsz=40, num_updates=2940, lr=3.17289e-05, gnorm=0.762, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10502
2023-01-06 17:46:24 - progress_bar.py[line:274] - INFO: epoch 001:   2952 / 115845 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0309, wps=100.4, ups=0.46, wpb=109.7, bsz=40, num_updates=2950, lr=3.18368e-05, gnorm=0.888, clip=20, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=10525
2023-01-06 17:46:46 - progress_bar.py[line:274] - INFO: epoch 001:   2962 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.045, wps=102, ups=0.46, wpb=109.8, bsz=40, num_updates=2960, lr=3.19447e-05, gnorm=0.84, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10546
2023-01-06 17:47:08 - progress_bar.py[line:274] - INFO: epoch 001:   2972 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0374, wps=102.8, ups=0.47, wpb=109.4, bsz=40, num_updates=2970, lr=3.20527e-05, gnorm=1.004, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10568
2023-01-06 17:47:30 - progress_bar.py[line:274] - INFO: epoch 001:   2982 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0248, wps=99.7, ups=0.46, wpb=108.8, bsz=40, num_updates=2980, lr=3.21606e-05, gnorm=0.888, clip=30, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10590
2023-01-06 17:47:51 - progress_bar.py[line:274] - INFO: epoch 001:   2992 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0149, wps=102, ups=0.47, wpb=108.7, bsz=40, num_updates=2990, lr=3.22685e-05, gnorm=0.86, clip=30, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=10611
2023-01-06 17:48:13 - progress_bar.py[line:274] - INFO: epoch 001:   3002 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0, wps=102.4, ups=0.47, wpb=109.4, bsz=40, num_updates=3000, lr=3.23764e-05, gnorm=0.754, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=10633
2023-01-06 17:48:35 - progress_bar.py[line:274] - INFO: epoch 001:   3012 / 115845 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0149, wps=101.5, ups=0.46, wpb=109.4, bsz=40, num_updates=3010, lr=3.24844e-05, gnorm=0.794, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10655
2023-01-06 17:48:56 - progress_bar.py[line:274] - INFO: epoch 001:   3022 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0202, wps=100.9, ups=0.46, wpb=109, bsz=40, num_updates=3020, lr=3.25923e-05, gnorm=0.914, clip=30, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=10677
2023-01-06 17:49:18 - progress_bar.py[line:274] - INFO: epoch 001:   3032 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0196, wps=102.6, ups=0.47, wpb=109.9, bsz=40, num_updates=3030, lr=3.27002e-05, gnorm=0.804, clip=20, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10698
2023-01-06 17:49:40 - progress_bar.py[line:274] - INFO: epoch 001:   3042 / 115845 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0296, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=3040, lr=3.28081e-05, gnorm=0.892, clip=20, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=10720
2023-01-06 17:50:01 - progress_bar.py[line:274] - INFO: epoch 001:   3052 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0242, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=3050, lr=3.2916e-05, gnorm=0.961, clip=50, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10741
2023-01-06 17:50:23 - progress_bar.py[line:274] - INFO: epoch 001:   3062 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0148, wps=102.8, ups=0.47, wpb=108.9, bsz=40, num_updates=3060, lr=3.3024e-05, gnorm=0.915, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10763
2023-01-06 17:50:44 - progress_bar.py[line:274] - INFO: epoch 001:   3072 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0163, wps=102, ups=0.46, wpb=109.9, bsz=40, num_updates=3070, lr=3.31319e-05, gnorm=0.876, clip=30, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=10785
2023-01-06 17:51:07 - progress_bar.py[line:274] - INFO: epoch 001:   3082 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0051, wps=99, ups=0.46, wpb=108.2, bsz=40, num_updates=3080, lr=3.32398e-05, gnorm=0.902, clip=30, loss_scale=1024, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=10807
2023-01-06 17:51:28 - progress_bar.py[line:274] - INFO: epoch 001:   3092 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0236, wps=103.4, ups=0.48, wpb=108.8, bsz=40, num_updates=3090, lr=3.33477e-05, gnorm=0.742, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=10828
2023-01-06 17:51:49 - progress_bar.py[line:274] - INFO: epoch 001:   3102 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0094, wps=104.9, ups=0.48, wpb=109.6, bsz=40, num_updates=3100, lr=3.34556e-05, gnorm=0.865, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10849
2023-01-06 17:52:11 - progress_bar.py[line:274] - INFO: epoch 001:   3112 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0323, wps=101, ups=0.46, wpb=110.5, bsz=40, num_updates=3110, lr=3.35636e-05, gnorm=0.873, clip=30, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=10871
2023-01-06 17:52:33 - progress_bar.py[line:274] - INFO: epoch 001:   3122 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0591, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=3120, lr=3.36715e-05, gnorm=0.822, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10893
2023-01-06 17:52:55 - progress_bar.py[line:274] - INFO: epoch 001:   3132 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0236, wps=100.2, ups=0.47, wpb=107.5, bsz=40, num_updates=3130, lr=3.37794e-05, gnorm=0.792, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10915
2023-01-06 17:53:16 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 17:53:19 - progress_bar.py[line:274] - INFO: epoch 001:   3143 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.476, nsentences=40, sample_size=109.476, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0411, wps=96.5, ups=0.42, wpb=109.5, bsz=40, num_updates=3140, lr=3.38873e-05, gnorm=0.915, clip=50, loss_scale=512, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=10939
2023-01-06 17:53:41 - progress_bar.py[line:274] - INFO: epoch 001:   3153 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0053, wps=100.4, ups=0.45, wpb=110.3, bsz=40, num_updates=3150, lr=3.39953e-05, gnorm=0.896, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10961
2023-01-06 17:54:03 - progress_bar.py[line:274] - INFO: epoch 001:   3163 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0311, wps=101.9, ups=0.47, wpb=109.4, bsz=40, num_updates=3160, lr=3.41032e-05, gnorm=0.751, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10983
2023-01-06 17:54:24 - progress_bar.py[line:274] - INFO: epoch 001:   3173 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0186, wps=101.1, ups=0.46, wpb=108.7, bsz=40, num_updates=3170, lr=3.42111e-05, gnorm=0.791, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=11005
2023-01-06 17:54:46 - progress_bar.py[line:274] - INFO: epoch 001:   3183 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.015, wps=100.4, ups=0.46, wpb=109.6, bsz=40, num_updates=3180, lr=3.4319e-05, gnorm=0.99, clip=40, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11027
2023-01-06 17:55:08 - progress_bar.py[line:274] - INFO: epoch 001:   3193 / 115845 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0227, wps=101.5, ups=0.47, wpb=107.6, bsz=40, num_updates=3190, lr=3.44269e-05, gnorm=0.892, clip=30, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=11048
2023-01-06 17:55:29 - progress_bar.py[line:274] - INFO: epoch 001:   3203 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0159, wps=103.6, ups=0.47, wpb=109.5, bsz=40, num_updates=3200, lr=3.45349e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11069
2023-01-06 17:55:51 - progress_bar.py[line:274] - INFO: epoch 001:   3213 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0152, wps=100, ups=0.46, wpb=108.7, bsz=40, num_updates=3210, lr=3.46428e-05, gnorm=0.791, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11091
2023-01-06 17:56:13 - progress_bar.py[line:274] - INFO: epoch 001:   3223 / 115845 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0303, wps=99.5, ups=0.46, wpb=108.4, bsz=40, num_updates=3220, lr=3.47507e-05, gnorm=0.902, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11113
2023-01-06 17:56:35 - progress_bar.py[line:274] - INFO: epoch 001:   3233 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0267, wps=101.7, ups=0.47, wpb=108.9, bsz=40, num_updates=3230, lr=3.48586e-05, gnorm=0.753, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11135
2023-01-06 17:56:56 - progress_bar.py[line:274] - INFO: epoch 001:   3243 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.024, wps=101.6, ups=0.47, wpb=109.2, bsz=40, num_updates=3240, lr=3.49665e-05, gnorm=0.792, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11157
2023-01-06 17:57:18 - progress_bar.py[line:274] - INFO: epoch 001:   3253 / 115845 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0448, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=3250, lr=3.50745e-05, gnorm=0.809, clip=30, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11179
2023-01-06 17:57:40 - progress_bar.py[line:274] - INFO: epoch 001:   3263 / 115845 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0146, wps=102.5, ups=0.47, wpb=108.5, bsz=40, num_updates=3260, lr=3.51824e-05, gnorm=0.722, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11200
2023-01-06 17:58:01 - progress_bar.py[line:274] - INFO: epoch 001:   3273 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0448, wps=102.6, ups=0.47, wpb=108.9, bsz=40, num_updates=3270, lr=3.52903e-05, gnorm=0.769, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11221
2023-01-06 17:58:22 - progress_bar.py[line:274] - INFO: epoch 001:   3283 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0383, wps=104.4, ups=0.48, wpb=109.2, bsz=40, num_updates=3280, lr=3.53982e-05, gnorm=0.92, clip=30, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=11243
2023-01-06 17:58:44 - progress_bar.py[line:274] - INFO: epoch 001:   3293 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.005, wps=101.5, ups=0.46, wpb=109.2, bsz=40, num_updates=3290, lr=3.55062e-05, gnorm=0.834, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11264
2023-01-06 17:59:06 - progress_bar.py[line:274] - INFO: epoch 001:   3303 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.043, wps=103.2, ups=0.47, wpb=109.5, bsz=40, num_updates=3300, lr=3.56141e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11286
2023-01-06 17:59:28 - progress_bar.py[line:274] - INFO: epoch 001:   3313 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.039, wps=98.4, ups=0.45, wpb=108.8, bsz=40, num_updates=3310, lr=3.5722e-05, gnorm=0.776, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=11308
2023-01-06 17:59:50 - progress_bar.py[line:274] - INFO: epoch 001:   3323 / 115845 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=106.6, nsentences=40, sample_size=106.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0429, wps=95.4, ups=0.45, wpb=106.6, bsz=40, num_updates=3320, lr=3.58299e-05, gnorm=0.871, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11331
2023-01-06 18:00:13 - progress_bar.py[line:274] - INFO: epoch 001:   3333 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0526, wps=98.6, ups=0.46, wpb=107.7, bsz=40, num_updates=3330, lr=3.59378e-05, gnorm=0.856, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11353
2023-01-06 18:00:34 - progress_bar.py[line:274] - INFO: epoch 001:   3343 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0337, wps=104.5, ups=0.47, wpb=110.9, bsz=40, num_updates=3340, lr=3.60458e-05, gnorm=0.817, clip=30, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11374
2023-01-06 18:00:56 - progress_bar.py[line:274] - INFO: epoch 001:   3353 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0196, wps=100.4, ups=0.46, wpb=108.9, bsz=40, num_updates=3350, lr=3.61537e-05, gnorm=0.9, clip=20, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=11396
2023-01-06 18:01:17 - progress_bar.py[line:274] - INFO: epoch 001:   3363 / 115845 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0193, wps=104.6, ups=0.48, wpb=109.1, bsz=40, num_updates=3360, lr=3.62616e-05, gnorm=0.904, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=11417
2023-01-06 18:01:38 - progress_bar.py[line:274] - INFO: epoch 001:   3373 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0387, wps=105.5, ups=0.48, wpb=109.3, bsz=40, num_updates=3370, lr=3.63695e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11438
2023-01-06 18:02:00 - progress_bar.py[line:274] - INFO: epoch 001:   3383 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0688, wps=103.1, ups=0.47, wpb=110.3, bsz=40, num_updates=3380, lr=3.64774e-05, gnorm=0.748, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11460
2023-01-06 18:02:21 - progress_bar.py[line:274] - INFO: epoch 001:   3393 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0153, wps=102.3, ups=0.47, wpb=109.4, bsz=40, num_updates=3390, lr=3.65854e-05, gnorm=0.783, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11481
2023-01-06 18:02:43 - progress_bar.py[line:274] - INFO: epoch 001:   3403 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0282, wps=101.2, ups=0.47, wpb=108.6, bsz=40, num_updates=3400, lr=3.66933e-05, gnorm=0.801, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11503
2023-01-06 18:03:04 - progress_bar.py[line:274] - INFO: epoch 001:   3413 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0296, wps=101.5, ups=0.47, wpb=108.2, bsz=40, num_updates=3410, lr=3.68012e-05, gnorm=0.822, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11525
2023-01-06 18:03:26 - progress_bar.py[line:274] - INFO: epoch 001:   3423 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.029, wps=100.8, ups=0.47, wpb=108.3, bsz=40, num_updates=3420, lr=3.69091e-05, gnorm=0.899, clip=50, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=11546
2023-01-06 18:03:47 - progress_bar.py[line:274] - INFO: epoch 001:   3433 / 115845 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0329, wps=102.6, ups=0.47, wpb=108.8, bsz=40, num_updates=3430, lr=3.70171e-05, gnorm=0.845, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11568
2023-01-06 18:04:09 - progress_bar.py[line:274] - INFO: epoch 001:   3443 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0253, wps=102.2, ups=0.47, wpb=109.6, bsz=40, num_updates=3440, lr=3.7125e-05, gnorm=0.793, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11589
2023-01-06 18:04:31 - progress_bar.py[line:274] - INFO: epoch 001:   3453 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0249, wps=101.1, ups=0.46, wpb=109.9, bsz=40, num_updates=3450, lr=3.72329e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11611
2023-01-06 18:04:53 - progress_bar.py[line:274] - INFO: epoch 001:   3463 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0479, wps=104.7, ups=0.47, wpb=110.7, bsz=40, num_updates=3460, lr=3.73408e-05, gnorm=0.699, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11633
2023-01-06 18:05:14 - progress_bar.py[line:274] - INFO: epoch 001:   3473 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0338, wps=103.3, ups=0.47, wpb=110, bsz=40, num_updates=3470, lr=3.74487e-05, gnorm=0.744, clip=20, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=11654
2023-01-06 18:05:35 - progress_bar.py[line:274] - INFO: epoch 001:   3483 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0479, wps=103.6, ups=0.47, wpb=109.4, bsz=40, num_updates=3480, lr=3.75567e-05, gnorm=0.717, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11676
2023-01-06 18:05:57 - progress_bar.py[line:274] - INFO: epoch 001:   3493 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.033, wps=103.7, ups=0.48, wpb=109.1, bsz=40, num_updates=3490, lr=3.76646e-05, gnorm=0.706, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11697
2023-01-06 18:06:18 - progress_bar.py[line:274] - INFO: epoch 001:   3503 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0419, wps=101.5, ups=0.47, wpb=108.4, bsz=40, num_updates=3500, lr=3.77725e-05, gnorm=0.796, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11718
2023-01-06 18:06:41 - progress_bar.py[line:274] - INFO: epoch 001:   3513 / 115845 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0308, wps=100.3, ups=0.47, wpb=107.2, bsz=40, num_updates=3510, lr=3.78804e-05, gnorm=0.839, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=11740
2023-01-06 18:07:03 - progress_bar.py[line:274] - INFO: epoch 001:   3523 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.02, wps=101, ups=0.46, wpb=110.2, bsz=40, num_updates=3520, lr=3.79883e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11764
2023-01-06 18:07:25 - progress_bar.py[line:274] - INFO: epoch 001:   3533 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0329, wps=101.6, ups=0.47, wpb=107.7, bsz=40, num_updates=3530, lr=3.80963e-05, gnorm=0.833, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11785
2023-01-06 18:07:47 - progress_bar.py[line:274] - INFO: epoch 001:   3543 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0237, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=3540, lr=3.82042e-05, gnorm=0.743, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11807
2023-01-06 18:08:09 - progress_bar.py[line:274] - INFO: epoch 001:   3553 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0259, wps=101.1, ups=0.46, wpb=110.5, bsz=40, num_updates=3550, lr=3.83121e-05, gnorm=0.78, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=11829
2023-01-06 18:08:30 - progress_bar.py[line:274] - INFO: epoch 001:   3563 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0309, wps=102.5, ups=0.47, wpb=109.8, bsz=40, num_updates=3560, lr=3.842e-05, gnorm=0.742, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11851
2023-01-06 18:08:52 - progress_bar.py[line:274] - INFO: epoch 001:   3573 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0419, wps=99.6, ups=0.46, wpb=108.2, bsz=40, num_updates=3570, lr=3.8528e-05, gnorm=0.767, clip=10, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=11873
2023-01-06 18:09:14 - progress_bar.py[line:274] - INFO: epoch 001:   3583 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.024, wps=100.7, ups=0.47, wpb=107.7, bsz=40, num_updates=3580, lr=3.86359e-05, gnorm=0.842, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11894
2023-01-06 18:09:36 - progress_bar.py[line:274] - INFO: epoch 001:   3593 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0489, wps=103, ups=0.47, wpb=109.9, bsz=40, num_updates=3590, lr=3.87438e-05, gnorm=0.781, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11916
2023-01-06 18:09:57 - progress_bar.py[line:274] - INFO: epoch 001:   3603 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0448, wps=100.8, ups=0.46, wpb=109.6, bsz=40, num_updates=3600, lr=3.88517e-05, gnorm=0.86, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11938
2023-01-06 18:10:19 - progress_bar.py[line:274] - INFO: epoch 001:   3613 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0198, wps=102.5, ups=0.47, wpb=109.1, bsz=40, num_updates=3610, lr=3.89596e-05, gnorm=0.859, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11959
2023-01-06 18:10:41 - progress_bar.py[line:274] - INFO: epoch 001:   3623 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0415, wps=101.3, ups=0.46, wpb=110.3, bsz=40, num_updates=3620, lr=3.90676e-05, gnorm=0.783, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11981
2023-01-06 18:11:03 - progress_bar.py[line:274] - INFO: epoch 001:   3633 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0345, wps=98.9, ups=0.46, wpb=107.8, bsz=40, num_updates=3630, lr=3.91755e-05, gnorm=0.676, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=12003
2023-01-06 18:11:25 - progress_bar.py[line:274] - INFO: epoch 001:   3643 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0404, wps=99.9, ups=0.46, wpb=108.5, bsz=40, num_updates=3640, lr=3.92834e-05, gnorm=0.726, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=12025
2023-01-06 18:11:47 - progress_bar.py[line:274] - INFO: epoch 001:   3653 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0321, wps=99.4, ups=0.46, wpb=108.2, bsz=40, num_updates=3650, lr=3.93913e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=12047
2023-01-06 18:12:09 - progress_bar.py[line:274] - INFO: epoch 001:   3663 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0197, wps=101.5, ups=0.46, wpb=109.6, bsz=40, num_updates=3660, lr=3.94992e-05, gnorm=0.755, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=12069
2023-01-06 18:12:31 - progress_bar.py[line:274] - INFO: epoch 001:   3673 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0439, wps=103.4, ups=0.47, wpb=109.5, bsz=40, num_updates=3670, lr=3.96072e-05, gnorm=0.728, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12090
2023-01-06 18:12:53 - progress_bar.py[line:274] - INFO: epoch 001:   3683 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0104, wps=101.4, ups=0.46, wpb=110, bsz=40, num_updates=3680, lr=3.97151e-05, gnorm=0.785, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12113
2023-01-06 18:13:15 - progress_bar.py[line:274] - INFO: epoch 001:   3693 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0215, wps=104.1, ups=0.47, wpb=110, bsz=40, num_updates=3690, lr=3.9823e-05, gnorm=0.807, clip=10, loss_scale=1024, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=12135
2023-01-06 18:13:36 - progress_bar.py[line:274] - INFO: epoch 001:   3703 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0284, wps=103.5, ups=0.47, wpb=109.6, bsz=40, num_updates=3700, lr=3.99309e-05, gnorm=0.727, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12156
2023-01-06 18:13:58 - progress_bar.py[line:274] - INFO: epoch 001:   3713 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0299, wps=104.6, ups=0.48, wpb=109.8, bsz=40, num_updates=3710, lr=4.00389e-05, gnorm=0.697, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12178
2023-01-06 18:14:20 - progress_bar.py[line:274] - INFO: epoch 001:   3723 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0209, wps=103.7, ups=0.47, wpb=109.7, bsz=40, num_updates=3720, lr=4.01468e-05, gnorm=0.717, clip=10, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=12200
2023-01-06 18:14:43 - progress_bar.py[line:274] - INFO: epoch 001:   3733 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0354, wps=100.8, ups=0.46, wpb=109.9, bsz=40, num_updates=3730, lr=4.02547e-05, gnorm=0.617, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=12222
2023-01-06 18:15:05 - progress_bar.py[line:274] - INFO: epoch 001:   3743 / 115845 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0512, wps=98.9, ups=0.46, wpb=107.5, bsz=40, num_updates=3740, lr=4.03626e-05, gnorm=0.886, clip=20, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=12245
2023-01-06 18:15:20 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 18:15:29 - progress_bar.py[line:274] - INFO: epoch 001:   3754 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0299, wps=97.3, ups=0.43, wpb=109, bsz=40, num_updates=3750, lr=4.04705e-05, gnorm=0.687, clip=10, loss_scale=512, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=12269
2023-01-06 18:15:51 - progress_bar.py[line:274] - INFO: epoch 001:   3764 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.051, wps=102.2, ups=0.47, wpb=109.3, bsz=40, num_updates=3760, lr=4.05785e-05, gnorm=0.756, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=12291
2023-01-06 18:16:13 - progress_bar.py[line:274] - INFO: epoch 001:   3774 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0337, wps=101.6, ups=0.47, wpb=108.6, bsz=40, num_updates=3770, lr=4.06864e-05, gnorm=0.832, clip=20, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=12313
2023-01-06 18:16:35 - progress_bar.py[line:274] - INFO: epoch 001:   3784 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0479, wps=101.6, ups=0.46, wpb=110.4, bsz=40, num_updates=3780, lr=4.07943e-05, gnorm=0.746, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12335
2023-01-06 18:16:58 - progress_bar.py[line:274] - INFO: epoch 001:   3794 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0191, wps=99.3, ups=0.46, wpb=108.3, bsz=40, num_updates=3790, lr=4.09022e-05, gnorm=0.743, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=12357
2023-01-06 18:17:20 - progress_bar.py[line:274] - INFO: epoch 001:   3804 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0305, wps=101.5, ups=0.47, wpb=108.7, bsz=40, num_updates=3800, lr=4.10101e-05, gnorm=0.779, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12379
2023-01-06 18:17:42 - progress_bar.py[line:274] - INFO: epoch 001:   3814 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0152, wps=101, ups=0.47, wpb=108.4, bsz=40, num_updates=3810, lr=4.11181e-05, gnorm=0.836, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12401
2023-01-06 18:18:04 - progress_bar.py[line:274] - INFO: epoch 001:   3824 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0464, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=3820, lr=4.1226e-05, gnorm=0.6, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=12424
2023-01-06 18:18:26 - progress_bar.py[line:274] - INFO: epoch 001:   3834 / 115845 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0362, wps=100, ups=0.46, wpb=107.7, bsz=40, num_updates=3830, lr=4.13339e-05, gnorm=0.823, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12446
2023-01-06 18:18:48 - progress_bar.py[line:274] - INFO: epoch 001:   3844 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0404, wps=100.8, ups=0.46, wpb=108.9, bsz=40, num_updates=3840, lr=4.14418e-05, gnorm=0.775, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12468
2023-01-06 18:19:10 - progress_bar.py[line:274] - INFO: epoch 001:   3854 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0415, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=3850, lr=4.15498e-05, gnorm=0.614, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=12490
2023-01-06 18:19:32 - progress_bar.py[line:274] - INFO: epoch 001:   3864 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0309, wps=101.7, ups=0.47, wpb=108.9, bsz=40, num_updates=3860, lr=4.16577e-05, gnorm=0.59, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=12512
2023-01-06 18:19:54 - progress_bar.py[line:274] - INFO: epoch 001:   3874 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0376, wps=101.1, ups=0.47, wpb=108.2, bsz=40, num_updates=3870, lr=4.17656e-05, gnorm=0.765, clip=10, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=12534
2023-01-06 18:20:16 - progress_bar.py[line:274] - INFO: epoch 001:   3884 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.051, wps=103.1, ups=0.47, wpb=108.8, bsz=40, num_updates=3880, lr=4.18735e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=12556
2023-01-06 18:20:38 - progress_bar.py[line:274] - INFO: epoch 001:   3894 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0346, wps=100, ups=0.47, wpb=106.9, bsz=40, num_updates=3890, lr=4.19814e-05, gnorm=0.823, clip=30, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12578
2023-01-06 18:21:00 - progress_bar.py[line:274] - INFO: epoch 001:   3904 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0053, wps=101.1, ups=0.46, wpb=109.8, bsz=40, num_updates=3900, lr=4.20894e-05, gnorm=0.887, clip=30, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=12600
2023-01-06 18:21:22 - progress_bar.py[line:274] - INFO: epoch 001:   3914 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0282, wps=102.9, ups=0.47, wpb=108.7, bsz=40, num_updates=3910, lr=4.21973e-05, gnorm=0.643, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12622
2023-01-06 18:21:44 - progress_bar.py[line:274] - INFO: epoch 001:   3924 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0253, wps=101.9, ups=0.47, wpb=108.9, bsz=40, num_updates=3920, lr=4.23052e-05, gnorm=0.675, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12644
2023-01-06 18:22:06 - progress_bar.py[line:274] - INFO: epoch 001:   3934 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0051, wps=102, ups=0.47, wpb=109.1, bsz=40, num_updates=3930, lr=4.24131e-05, gnorm=0.714, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=12666
2023-01-06 18:22:28 - progress_bar.py[line:274] - INFO: epoch 001:   3944 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0376, wps=99.8, ups=0.46, wpb=109, bsz=40, num_updates=3940, lr=4.2521e-05, gnorm=0.734, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=12688
2023-01-06 18:22:51 - progress_bar.py[line:274] - INFO: epoch 001:   3954 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0251, wps=100.5, ups=0.45, wpb=110.6, bsz=40, num_updates=3950, lr=4.2629e-05, gnorm=0.598, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=12711
2023-01-06 18:23:13 - progress_bar.py[line:274] - INFO: epoch 001:   3964 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0357, wps=102.9, ups=0.46, wpb=110.9, bsz=40, num_updates=3960, lr=4.27369e-05, gnorm=0.737, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12733
2023-01-06 18:23:35 - progress_bar.py[line:274] - INFO: epoch 001:   3974 / 115845 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0653, wps=99.7, ups=0.46, wpb=108.7, bsz=40, num_updates=3970, lr=4.28448e-05, gnorm=0.762, clip=20, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=12755
2023-01-06 18:23:57 - progress_bar.py[line:274] - INFO: epoch 001:   3984 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0365, wps=103, ups=0.47, wpb=109.7, bsz=40, num_updates=3980, lr=4.29527e-05, gnorm=0.613, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12777
2023-01-06 18:24:20 - progress_bar.py[line:274] - INFO: epoch 001:   3994 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0466, wps=101.1, ups=0.46, wpb=109.8, bsz=40, num_updates=3990, lr=4.30607e-05, gnorm=0.69, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12799
2023-01-06 18:24:42 - progress_bar.py[line:274] - INFO: epoch 001:   4004 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0553, wps=100.6, ups=0.46, wpb=109.5, bsz=40, num_updates=4000, lr=4.31686e-05, gnorm=0.678, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=12822
2023-01-06 18:24:42 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-06 18:24:43 - train.py[line:549] - INFO: 0 / 4988
2023-01-06 18:24:43 - train.py[line:551] - INFO: load:0.99 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-06 18:27:16 - train.py[line:549] - INFO: 200 / 4988
2023-01-06 18:27:16 - train.py[line:551] - INFO: load:1.01 valid_run:152.36 task_valid:148.18 collect_output:3.05
2023-01-06 18:29:45 - train.py[line:549] - INFO: 400 / 4988
2023-01-06 18:29:45 - train.py[line:551] - INFO: load:1.04 valid_run:301.03 task_valid:290.04 collect_output:8.82
2023-01-06 18:32:18 - train.py[line:549] - INFO: 600 / 4988
2023-01-06 18:32:18 - train.py[line:551] - INFO: load:1.06 valid_run:454.48 task_valid:431.87 collect_output:19.34
2023-01-06 18:34:47 - train.py[line:549] - INFO: 800 / 4988
2023-01-06 18:34:47 - train.py[line:551] - INFO: load:1.09 valid_run:603.52 task_valid:575.79 collect_output:23.41
2023-01-06 18:37:19 - train.py[line:549] - INFO: 1000 / 4988
2023-01-06 18:37:19 - train.py[line:551] - INFO: load:1.12 valid_run:755.58 task_valid:721.96 collect_output:28.22
2023-01-06 18:39:51 - train.py[line:549] - INFO: 1200 / 4988
2023-01-06 18:39:51 - train.py[line:551] - INFO: load:1.14 valid_run:907.39 task_valid:866.11 collect_output:34.86
2023-01-06 18:42:25 - train.py[line:549] - INFO: 1400 / 4988
2023-01-06 18:42:25 - train.py[line:551] - INFO: load:1.17 valid_run:1061.18 task_valid:1010.64 collect_output:43.07
2023-01-06 18:44:57 - train.py[line:549] - INFO: 1600 / 4988
2023-01-06 18:44:57 - train.py[line:551] - INFO: load:1.19 valid_run:1213.05 task_valid:1150.54 collect_output:53.99
2023-01-06 18:47:27 - train.py[line:549] - INFO: 1800 / 4988
2023-01-06 18:47:27 - train.py[line:551] - INFO: load:1.22 valid_run:1362.74 task_valid:1293.92 collect_output:59.21
2023-01-06 18:49:55 - train.py[line:549] - INFO: 2000 / 4988
2023-01-06 18:49:55 - train.py[line:551] - INFO: load:1.24 valid_run:1511.09 task_valid:1435.51 collect_output:64.91
2023-01-06 18:52:25 - train.py[line:549] - INFO: 2200 / 4988
2023-01-06 18:52:25 - train.py[line:551] - INFO: load:1.27 valid_run:1660.61 task_valid:1578.95 collect_output:69.91
2023-01-06 18:54:54 - train.py[line:549] - INFO: 2400 / 4988
2023-01-06 18:54:54 - train.py[line:551] - INFO: load:1.29 valid_run:1810.13 task_valid:1722.54 collect_output:74.77
2023-01-06 18:57:25 - train.py[line:549] - INFO: 2600 / 4988
2023-01-06 18:57:25 - train.py[line:551] - INFO: load:1.32 valid_run:1960.11 task_valid:1862.91 collect_output:83.34
2023-01-06 18:59:55 - train.py[line:549] - INFO: 2800 / 4988
2023-01-06 18:59:55 - train.py[line:551] - INFO: load:1.34 valid_run:2110.23 task_valid:2006.91 collect_output:88.39
2023-01-06 19:02:24 - train.py[line:549] - INFO: 3000 / 4988
2023-01-06 19:02:24 - train.py[line:551] - INFO: load:1.37 valid_run:2259.71 task_valid:2151.87 collect_output:91.87
2023-01-06 19:04:54 - train.py[line:549] - INFO: 3200 / 4988
2023-01-06 19:04:54 - train.py[line:551] - INFO: load:1.40 valid_run:2409.54 task_valid:2294.78 collect_output:97.71
2023-01-06 19:07:26 - train.py[line:549] - INFO: 3400 / 4988
2023-01-06 19:07:26 - train.py[line:551] - INFO: load:1.42 valid_run:2561.08 task_valid:2438.87 collect_output:104.09
2023-01-06 19:09:56 - train.py[line:549] - INFO: 3600 / 4988
2023-01-06 19:09:56 - train.py[line:551] - INFO: load:1.45 valid_run:2710.83 task_valid:2584.21 collect_output:107.42
2023-01-06 19:12:24 - train.py[line:549] - INFO: 3800 / 4988
2023-01-06 19:12:24 - train.py[line:551] - INFO: load:1.47 valid_run:2859.28 task_valid:2724.41 collect_output:114.56
2023-01-06 19:14:54 - train.py[line:549] - INFO: 4000 / 4988
2023-01-06 19:14:54 - train.py[line:551] - INFO: load:1.50 valid_run:3009.33 task_valid:2868.17 collect_output:119.79
2023-01-06 19:17:26 - train.py[line:549] - INFO: 4200 / 4988
2023-01-06 19:17:26 - train.py[line:551] - INFO: load:1.52 valid_run:3161.37 task_valid:3011.31 collect_output:127.58
2023-01-06 19:19:55 - train.py[line:549] - INFO: 4400 / 4988
2023-01-06 19:19:55 - train.py[line:551] - INFO: load:1.55 valid_run:3310.27 task_valid:3154.58 collect_output:132.12
2023-01-06 19:22:27 - train.py[line:549] - INFO: 4600 / 4988
2023-01-06 19:22:27 - train.py[line:551] - INFO: load:1.58 valid_run:3462.13 task_valid:3300.03 collect_output:137.43
2023-01-06 19:24:58 - train.py[line:549] - INFO: 4800 / 4988
2023-01-06 19:24:58 - train.py[line:551] - INFO: load:1.60 valid_run:3613.16 task_valid:3445.33 collect_output:142.08

====================================================================================================
SGG eval:     R @ 50: 0.5193;     R @ 100: 0.5708;     R @ 500: 0.6231;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3044;    mR @ 100: 0.3810;    mR @ 500: 0.4282;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.1875) (covering:0.5429) (eating:0.7647) (flying in:0.7273) (growing on:0.5000) (hanging from:0.4194) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7083) (playing:0.0000) (riding:0.7752) (says:0.0000) (sitting on:0.6735) (standing on:0.4050) (using:0.4000) (walking in:0.0000) (walking on:0.5811) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================

2023-01-06 19:27:28 - train.py[line:487] - INFO: 0.5708186147186147
2023-01-06 19:27:29 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-06 19:27:29 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.358 | loss_v1 0 | loss_v2 0 | nll_loss 0.209 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.570819 | ppl 1.16 | vqa_score 0.3074 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 4000 | best_R@100 0.570819
2023-01-06 19:27:29 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2023-01-06 19:27:29 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_4000.pt

====================================================================================================
SGG eval:     R @ 50: 0.5193;     R @ 100: 0.5708;     R @ 500: 0.6231;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3044;    mR @ 100: 0.3810;    mR @ 500: 0.4282;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.1875) (covering:0.5429) (eating:0.7647) (flying in:0.7273) (growing on:0.5000) (hanging from:0.4194) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7083) (playing:0.0000) (riding:0.7752) (says:0.0000) (sitting on:0.6735) (standing on:0.4050) (using:0.4000) (walking in:0.0000) (walking on:0.5811) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================

2023-01-06 19:28:11 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_4000.pt
2023-01-06 19:31:10 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.5708186147186147) (writing took 221.4837304893881 seconds)
2023-01-06 19:31:33 - progress_bar.py[line:274] - INFO: epoch 001:   4014 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0372, wps=0.5, ups=0, wpb=109.1, bsz=40, num_updates=4010, lr=4.32765e-05, gnorm=0.659, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=16833
2023-01-06 19:31:55 - progress_bar.py[line:274] - INFO: epoch 001:   4024 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0199, wps=102.6, ups=0.47, wpb=109.2, bsz=40, num_updates=4020, lr=4.33844e-05, gnorm=0.766, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=16855
2023-01-06 19:32:16 - progress_bar.py[line:274] - INFO: epoch 001:   4034 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0521, wps=103.5, ups=0.48, wpb=108.3, bsz=40, num_updates=4030, lr=4.34923e-05, gnorm=0.644, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=16876
2023-01-06 19:32:39 - progress_bar.py[line:274] - INFO: epoch 001:   4044 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0539, wps=99.5, ups=0.46, wpb=109.3, bsz=40, num_updates=4040, lr=4.36003e-05, gnorm=0.675, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=16899
2023-01-06 19:33:01 - progress_bar.py[line:274] - INFO: epoch 001:   4054 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0392, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=4050, lr=4.37082e-05, gnorm=0.687, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=16921
2023-01-06 19:33:23 - progress_bar.py[line:274] - INFO: epoch 001:   4064 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0433, wps=99.6, ups=0.46, wpb=108.9, bsz=40, num_updates=4060, lr=4.38161e-05, gnorm=0.688, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=16943
2023-01-06 19:33:46 - progress_bar.py[line:274] - INFO: epoch 001:   4074 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0363, wps=101.2, ups=0.46, wpb=110.3, bsz=40, num_updates=4070, lr=4.3924e-05, gnorm=0.701, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=16966
2023-01-06 19:34:08 - progress_bar.py[line:274] - INFO: epoch 001:   4084 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0513, wps=100.4, ups=0.46, wpb=109.3, bsz=40, num_updates=4080, lr=4.40319e-05, gnorm=0.795, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=16988
2023-01-06 19:34:30 - progress_bar.py[line:274] - INFO: epoch 001:   4094 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0415, wps=101.3, ups=0.46, wpb=109, bsz=40, num_updates=4090, lr=4.41399e-05, gnorm=0.754, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17010
2023-01-06 19:34:52 - progress_bar.py[line:274] - INFO: epoch 001:   4104 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0212, wps=103.2, ups=0.47, wpb=109, bsz=40, num_updates=4100, lr=4.42478e-05, gnorm=0.752, clip=30, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17032
2023-01-06 19:35:14 - progress_bar.py[line:274] - INFO: epoch 001:   4114 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0447, wps=103.7, ups=0.47, wpb=110.4, bsz=40, num_updates=4110, lr=4.43557e-05, gnorm=0.704, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17054
2023-01-06 19:35:36 - progress_bar.py[line:274] - INFO: epoch 001:   4124 / 115845 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0457, wps=98.3, ups=0.46, wpb=107.5, bsz=40, num_updates=4120, lr=4.44636e-05, gnorm=0.693, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=17076
2023-01-06 19:35:58 - progress_bar.py[line:274] - INFO: epoch 001:   4134 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0303, wps=103.4, ups=0.47, wpb=109.7, bsz=40, num_updates=4130, lr=4.45716e-05, gnorm=0.749, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17098
2023-01-06 19:36:21 - progress_bar.py[line:274] - INFO: epoch 001:   4144 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0377, wps=100.8, ups=0.46, wpb=109.3, bsz=40, num_updates=4140, lr=4.46795e-05, gnorm=0.733, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17120
2023-01-06 19:36:43 - progress_bar.py[line:274] - INFO: epoch 001:   4154 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0609, wps=99.4, ups=0.45, wpb=109.4, bsz=40, num_updates=4150, lr=4.47874e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17143
2023-01-06 19:37:05 - progress_bar.py[line:274] - INFO: epoch 001:   4164 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.028, wps=101.2, ups=0.47, wpb=108.3, bsz=40, num_updates=4160, lr=4.48953e-05, gnorm=0.812, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17165
2023-01-06 19:37:27 - progress_bar.py[line:274] - INFO: epoch 001:   4174 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0152, wps=105, ups=0.48, wpb=110, bsz=40, num_updates=4170, lr=4.50032e-05, gnorm=0.864, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17187
2023-01-06 19:37:49 - progress_bar.py[line:274] - INFO: epoch 001:   4184 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0372, wps=100.9, ups=0.46, wpb=109.2, bsz=40, num_updates=4180, lr=4.51112e-05, gnorm=0.653, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=17209
2023-01-06 19:38:11 - progress_bar.py[line:274] - INFO: epoch 001:   4194 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0561, wps=100.1, ups=0.46, wpb=108.3, bsz=40, num_updates=4190, lr=4.52191e-05, gnorm=0.728, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17231
2023-01-06 19:38:33 - progress_bar.py[line:274] - INFO: epoch 001:   4204 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0558, wps=103, ups=0.47, wpb=108.9, bsz=40, num_updates=4200, lr=4.5327e-05, gnorm=0.71, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17253
2023-01-06 19:38:55 - progress_bar.py[line:274] - INFO: epoch 001:   4214 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0545, wps=101.7, ups=0.47, wpb=108.5, bsz=40, num_updates=4210, lr=4.54349e-05, gnorm=0.625, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17275
2023-01-06 19:39:17 - progress_bar.py[line:274] - INFO: epoch 001:   4224 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0664, wps=102.4, ups=0.47, wpb=107.9, bsz=40, num_updates=4220, lr=4.55428e-05, gnorm=0.68, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17297
2023-01-06 19:39:39 - progress_bar.py[line:274] - INFO: epoch 001:   4234 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0441, wps=103.2, ups=0.47, wpb=109.2, bsz=40, num_updates=4230, lr=4.56508e-05, gnorm=0.735, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17318
2023-01-06 19:40:01 - progress_bar.py[line:274] - INFO: epoch 001:   4244 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0335, wps=101.2, ups=0.47, wpb=107.5, bsz=40, num_updates=4240, lr=4.57587e-05, gnorm=0.751, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17340
2023-01-06 19:40:22 - progress_bar.py[line:274] - INFO: epoch 001:   4254 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0542, wps=103.6, ups=0.47, wpb=109.3, bsz=40, num_updates=4250, lr=4.58666e-05, gnorm=0.814, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17362
2023-01-06 19:40:44 - progress_bar.py[line:274] - INFO: epoch 001:   4264 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0463, wps=102.1, ups=0.47, wpb=108, bsz=40, num_updates=4260, lr=4.59745e-05, gnorm=0.784, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17384
2023-01-06 19:41:06 - progress_bar.py[line:274] - INFO: epoch 001:   4274 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.029, wps=100.4, ups=0.46, wpb=108.1, bsz=40, num_updates=4270, lr=4.60825e-05, gnorm=0.794, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17406
2023-01-06 19:41:29 - progress_bar.py[line:274] - INFO: epoch 001:   4284 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0498, wps=101.7, ups=0.46, wpb=109.6, bsz=40, num_updates=4280, lr=4.61904e-05, gnorm=0.82, clip=20, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=17428
2023-01-06 19:41:51 - progress_bar.py[line:274] - INFO: epoch 001:   4294 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0664, wps=100.6, ups=0.46, wpb=108.3, bsz=40, num_updates=4290, lr=4.62983e-05, gnorm=0.722, clip=10, loss_scale=1024, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=17451
2023-01-06 19:42:13 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 19:42:15 - progress_bar.py[line:274] - INFO: epoch 001:   4305 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.19, nsentences=40, sample_size=109.19, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0369, wps=96.2, ups=0.42, wpb=109.2, bsz=40, num_updates=4300, lr=4.64062e-05, gnorm=0.645, clip=10, loss_scale=512, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=17475
2023-01-06 19:42:38 - progress_bar.py[line:274] - INFO: epoch 001:   4315 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.041, wps=100.4, ups=0.46, wpb=109.3, bsz=40, num_updates=4310, lr=4.65141e-05, gnorm=0.707, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17498
2023-01-06 19:42:59 - progress_bar.py[line:274] - INFO: epoch 001:   4325 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0455, wps=103.2, ups=0.47, wpb=108.6, bsz=40, num_updates=4320, lr=4.66221e-05, gnorm=0.606, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17519
2023-01-06 19:43:22 - progress_bar.py[line:274] - INFO: epoch 001:   4335 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.026, wps=102.3, ups=0.46, wpb=110.2, bsz=40, num_updates=4330, lr=4.673e-05, gnorm=0.618, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17541
2023-01-06 19:43:44 - progress_bar.py[line:274] - INFO: epoch 001:   4345 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0455, wps=99.4, ups=0.46, wpb=108.2, bsz=40, num_updates=4340, lr=4.68379e-05, gnorm=0.683, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17564
2023-01-06 19:44:06 - progress_bar.py[line:274] - INFO: epoch 001:   4355 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0357, wps=101.6, ups=0.46, wpb=109.7, bsz=40, num_updates=4350, lr=4.69458e-05, gnorm=0.701, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=17586
2023-01-06 19:44:28 - progress_bar.py[line:274] - INFO: epoch 001:   4365 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0545, wps=101.4, ups=0.47, wpb=108.1, bsz=40, num_updates=4360, lr=4.70537e-05, gnorm=0.711, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=17608
2023-01-06 19:44:49 - progress_bar.py[line:274] - INFO: epoch 001:   4375 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0328, wps=106.9, ups=0.48, wpb=110.6, bsz=40, num_updates=4370, lr=4.71617e-05, gnorm=0.849, clip=30, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=17629
2023-01-06 19:45:11 - progress_bar.py[line:274] - INFO: epoch 001:   4385 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0306, wps=105.5, ups=0.48, wpb=109.6, bsz=40, num_updates=4380, lr=4.72696e-05, gnorm=0.646, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17651
2023-01-06 19:45:33 - progress_bar.py[line:274] - INFO: epoch 001:   4395 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0153, wps=102.8, ups=0.47, wpb=109.1, bsz=40, num_updates=4390, lr=4.73775e-05, gnorm=0.64, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17673
2023-01-06 19:45:55 - progress_bar.py[line:274] - INFO: epoch 001:   4405 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0683, wps=99.9, ups=0.46, wpb=107.8, bsz=40, num_updates=4400, lr=4.74854e-05, gnorm=0.636, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17695
2023-01-06 19:46:18 - progress_bar.py[line:274] - INFO: epoch 001:   4415 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0193, wps=99.3, ups=0.46, wpb=108.2, bsz=40, num_updates=4410, lr=4.75934e-05, gnorm=0.692, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=17717
2023-01-06 19:46:40 - progress_bar.py[line:274] - INFO: epoch 001:   4425 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0348, wps=100.6, ups=0.46, wpb=108.5, bsz=40, num_updates=4420, lr=4.77013e-05, gnorm=0.656, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17740
2023-01-06 19:47:02 - progress_bar.py[line:274] - INFO: epoch 001:   4435 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0488, wps=99.8, ups=0.46, wpb=108, bsz=40, num_updates=4430, lr=4.78092e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17762
2023-01-06 19:47:24 - progress_bar.py[line:274] - INFO: epoch 001:   4445 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0205, wps=100.6, ups=0.46, wpb=108.7, bsz=40, num_updates=4440, lr=4.79171e-05, gnorm=0.754, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17784
2023-01-06 19:47:46 - progress_bar.py[line:274] - INFO: epoch 001:   4455 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0376, wps=100, ups=0.46, wpb=109.3, bsz=40, num_updates=4450, lr=4.8025e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17806
2023-01-06 19:48:08 - progress_bar.py[line:274] - INFO: epoch 001:   4465 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0379, wps=99.9, ups=0.46, wpb=108.5, bsz=40, num_updates=4460, lr=4.8133e-05, gnorm=0.624, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=17828
2023-01-06 19:48:30 - progress_bar.py[line:274] - INFO: epoch 001:   4475 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0408, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=4470, lr=4.82409e-05, gnorm=0.63, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=17850
2023-01-06 19:48:51 - progress_bar.py[line:274] - INFO: epoch 001:   4485 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0653, wps=101.9, ups=0.47, wpb=108.4, bsz=40, num_updates=4480, lr=4.83488e-05, gnorm=0.753, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17871
2023-01-06 19:49:13 - progress_bar.py[line:274] - INFO: epoch 001:   4495 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0704, wps=103.5, ups=0.47, wpb=110.5, bsz=40, num_updates=4490, lr=4.84567e-05, gnorm=0.674, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17893
2023-01-06 19:49:34 - progress_bar.py[line:274] - INFO: epoch 001:   4505 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0352, wps=103.2, ups=0.48, wpb=108.4, bsz=40, num_updates=4500, lr=4.85646e-05, gnorm=0.671, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17914
2023-01-06 19:49:56 - progress_bar.py[line:274] - INFO: epoch 001:   4515 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0585, wps=99.3, ups=0.46, wpb=108, bsz=40, num_updates=4510, lr=4.86726e-05, gnorm=0.669, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17936
2023-01-06 19:50:18 - progress_bar.py[line:274] - INFO: epoch 001:   4525 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0392, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=4520, lr=4.87805e-05, gnorm=0.661, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=17958
2023-01-06 19:50:39 - progress_bar.py[line:274] - INFO: epoch 001:   4535 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.04, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=4530, lr=4.88884e-05, gnorm=0.617, clip=0, loss_scale=512, train_wall=21, gb_free=9.4, ema_decay=0.9999, wall=17979
2023-01-06 19:51:01 - progress_bar.py[line:274] - INFO: epoch 001:   4545 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0291, wps=100.4, ups=0.46, wpb=108.2, bsz=40, num_updates=4540, lr=4.89963e-05, gnorm=0.667, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18001
2023-01-06 19:51:23 - progress_bar.py[line:274] - INFO: epoch 001:   4555 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0201, wps=99.1, ups=0.46, wpb=108.2, bsz=40, num_updates=4550, lr=4.91043e-05, gnorm=0.69, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18023
2023-01-06 19:51:45 - progress_bar.py[line:274] - INFO: epoch 001:   4565 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0529, wps=100.4, ups=0.46, wpb=108.6, bsz=40, num_updates=4560, lr=4.92122e-05, gnorm=0.584, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18045
2023-01-06 19:52:07 - progress_bar.py[line:274] - INFO: epoch 001:   4575 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.041, wps=100.5, ups=0.46, wpb=109.2, bsz=40, num_updates=4570, lr=4.93201e-05, gnorm=0.675, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=18067
2023-01-06 19:52:29 - progress_bar.py[line:274] - INFO: epoch 001:   4585 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0488, wps=102.8, ups=0.47, wpb=110.3, bsz=40, num_updates=4580, lr=4.9428e-05, gnorm=0.678, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=18089
2023-01-06 19:52:51 - progress_bar.py[line:274] - INFO: epoch 001:   4595 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0291, wps=101, ups=0.47, wpb=108.5, bsz=40, num_updates=4590, lr=4.95359e-05, gnorm=0.633, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18111
2023-01-06 19:53:12 - progress_bar.py[line:274] - INFO: epoch 001:   4605 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0505, wps=100.9, ups=0.46, wpb=109.2, bsz=40, num_updates=4600, lr=4.96439e-05, gnorm=0.624, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18133
2023-01-06 19:53:34 - progress_bar.py[line:274] - INFO: epoch 001:   4615 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0563, wps=100.1, ups=0.47, wpb=106.5, bsz=40, num_updates=4610, lr=4.97518e-05, gnorm=0.635, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18154
2023-01-06 19:53:55 - progress_bar.py[line:274] - INFO: epoch 001:   4625 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0343, wps=103.3, ups=0.47, wpb=108.8, bsz=40, num_updates=4620, lr=4.98597e-05, gnorm=0.631, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18175
2023-01-06 19:54:17 - progress_bar.py[line:274] - INFO: epoch 001:   4635 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0203, wps=102.7, ups=0.47, wpb=109.8, bsz=40, num_updates=4630, lr=4.99676e-05, gnorm=0.572, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18197
2023-01-06 19:54:39 - progress_bar.py[line:274] - INFO: epoch 001:   4645 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0631, wps=101.1, ups=0.46, wpb=109.2, bsz=40, num_updates=4640, lr=4.99969e-05, gnorm=0.552, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18219
2023-01-06 19:55:00 - progress_bar.py[line:274] - INFO: epoch 001:   4655 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0657, wps=102.7, ups=0.47, wpb=108.6, bsz=40, num_updates=4650, lr=4.99924e-05, gnorm=0.73, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18240
2023-01-06 19:55:22 - progress_bar.py[line:274] - INFO: epoch 001:   4665 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0359, wps=103, ups=0.47, wpb=109.9, bsz=40, num_updates=4660, lr=4.99879e-05, gnorm=0.67, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18262
2023-01-06 19:55:44 - progress_bar.py[line:274] - INFO: epoch 001:   4675 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0585, wps=102, ups=0.46, wpb=109.8, bsz=40, num_updates=4670, lr=4.99834e-05, gnorm=0.616, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=18284
2023-01-06 19:56:05 - progress_bar.py[line:274] - INFO: epoch 001:   4685 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0374, wps=100.8, ups=0.47, wpb=107.8, bsz=40, num_updates=4680, lr=4.99789e-05, gnorm=0.627, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18305
2023-01-06 19:56:27 - progress_bar.py[line:274] - INFO: epoch 001:   4695 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0314, wps=102.3, ups=0.46, wpb=110.1, bsz=40, num_updates=4690, lr=4.99744e-05, gnorm=0.725, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18327
2023-01-06 19:56:49 - progress_bar.py[line:274] - INFO: epoch 001:   4705 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0312, wps=99.6, ups=0.46, wpb=108, bsz=40, num_updates=4700, lr=4.99699e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18349
2023-01-06 19:57:11 - progress_bar.py[line:274] - INFO: epoch 001:   4715 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0785, wps=101.4, ups=0.46, wpb=109.5, bsz=40, num_updates=4710, lr=4.99654e-05, gnorm=0.567, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18371
2023-01-06 19:57:32 - progress_bar.py[line:274] - INFO: epoch 001:   4725 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0452, wps=100.7, ups=0.46, wpb=109, bsz=40, num_updates=4720, lr=4.99609e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18393
2023-01-06 19:57:54 - progress_bar.py[line:274] - INFO: epoch 001:   4735 / 115845 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0588, wps=100.7, ups=0.47, wpb=107.7, bsz=40, num_updates=4730, lr=4.99564e-05, gnorm=0.761, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=18414
2023-01-06 19:58:16 - progress_bar.py[line:274] - INFO: epoch 001:   4745 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0556, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=4740, lr=4.99519e-05, gnorm=0.661, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18436
2023-01-06 19:58:38 - progress_bar.py[line:274] - INFO: epoch 001:   4755 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0348, wps=103.4, ups=0.47, wpb=110, bsz=40, num_updates=4750, lr=4.99474e-05, gnorm=0.666, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18458
2023-01-06 19:58:59 - progress_bar.py[line:274] - INFO: epoch 001:   4765 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0576, wps=103.3, ups=0.47, wpb=110.2, bsz=40, num_updates=4760, lr=4.99429e-05, gnorm=0.539, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18480
2023-01-06 19:59:21 - progress_bar.py[line:274] - INFO: epoch 001:   4775 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0538, wps=101.3, ups=0.46, wpb=109.4, bsz=40, num_updates=4770, lr=4.99384e-05, gnorm=0.528, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18501
2023-01-06 19:59:43 - progress_bar.py[line:274] - INFO: epoch 001:   4785 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0435, wps=101.2, ups=0.47, wpb=107.8, bsz=40, num_updates=4780, lr=4.99339e-05, gnorm=0.592, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18523
2023-01-06 20:00:05 - progress_bar.py[line:274] - INFO: epoch 001:   4795 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0271, wps=98.2, ups=0.46, wpb=107.6, bsz=40, num_updates=4790, lr=4.99294e-05, gnorm=0.546, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18545
2023-01-06 20:00:27 - progress_bar.py[line:274] - INFO: epoch 001:   4805 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0753, wps=101.2, ups=0.46, wpb=110.4, bsz=40, num_updates=4800, lr=4.99249e-05, gnorm=0.587, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18567
2023-01-06 20:00:49 - progress_bar.py[line:274] - INFO: epoch 001:   4815 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0714, wps=100.5, ups=0.46, wpb=109.4, bsz=40, num_updates=4810, lr=4.99204e-05, gnorm=0.671, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18589
2023-01-06 20:01:11 - progress_bar.py[line:274] - INFO: epoch 001:   4825 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0591, wps=101.1, ups=0.47, wpb=108.5, bsz=40, num_updates=4820, lr=4.99159e-05, gnorm=0.665, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18611
2023-01-06 20:01:33 - progress_bar.py[line:274] - INFO: epoch 001:   4835 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0647, wps=100.5, ups=0.46, wpb=109.9, bsz=40, num_updates=4830, lr=4.99114e-05, gnorm=0.594, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18633
2023-01-06 20:01:54 - progress_bar.py[line:274] - INFO: epoch 001:   4845 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0622, wps=101.6, ups=0.47, wpb=108.3, bsz=40, num_updates=4840, lr=4.99069e-05, gnorm=0.746, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18655
2023-01-06 20:02:16 - progress_bar.py[line:274] - INFO: epoch 001:   4855 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0563, wps=99.1, ups=0.46, wpb=107.5, bsz=40, num_updates=4850, lr=4.99024e-05, gnorm=0.647, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18676
2023-01-06 20:02:38 - progress_bar.py[line:274] - INFO: epoch 001:   4865 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0674, wps=98.8, ups=0.46, wpb=108.3, bsz=40, num_updates=4860, lr=4.98979e-05, gnorm=0.65, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18699
2023-01-06 20:03:00 - progress_bar.py[line:274] - INFO: epoch 001:   4875 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0415, wps=99.8, ups=0.46, wpb=107.6, bsz=40, num_updates=4870, lr=4.98934e-05, gnorm=0.715, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18720
2023-01-06 20:03:21 - progress_bar.py[line:274] - INFO: epoch 001:   4885 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.05, wps=104.7, ups=0.48, wpb=109.5, bsz=40, num_updates=4880, lr=4.9889e-05, gnorm=0.633, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=18742
2023-01-06 20:03:43 - progress_bar.py[line:274] - INFO: epoch 001:   4895 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.075, wps=101.4, ups=0.46, wpb=109.3, bsz=40, num_updates=4890, lr=4.98845e-05, gnorm=0.641, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18763
2023-01-06 20:04:05 - progress_bar.py[line:274] - INFO: epoch 001:   4905 / 115845 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0564, wps=100.8, ups=0.46, wpb=109.6, bsz=40, num_updates=4900, lr=4.988e-05, gnorm=0.477, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=18785
2023-01-06 20:04:27 - progress_bar.py[line:274] - INFO: epoch 001:   4915 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0383, wps=103.1, ups=0.47, wpb=109, bsz=40, num_updates=4910, lr=4.98755e-05, gnorm=0.73, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18807
2023-01-06 20:04:48 - progress_bar.py[line:274] - INFO: epoch 001:   4925 / 115845 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0443, wps=104.9, ups=0.48, wpb=109.4, bsz=40, num_updates=4920, lr=4.9871e-05, gnorm=0.736, clip=30, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=18828
2023-01-06 20:05:09 - progress_bar.py[line:274] - INFO: epoch 001:   4935 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0777, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=4930, lr=4.98665e-05, gnorm=0.527, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18850
2023-01-06 20:05:31 - progress_bar.py[line:274] - INFO: epoch 001:   4945 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0606, wps=101.1, ups=0.46, wpb=108.8, bsz=40, num_updates=4940, lr=4.9862e-05, gnorm=0.556, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18871
2023-01-06 20:05:54 - progress_bar.py[line:274] - INFO: epoch 001:   4955 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0426, wps=95.6, ups=0.44, wpb=108.9, bsz=40, num_updates=4950, lr=4.98575e-05, gnorm=0.599, clip=0, loss_scale=1024, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=18894
2023-01-06 20:06:16 - progress_bar.py[line:274] - INFO: epoch 001:   4965 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0483, wps=98.8, ups=0.46, wpb=108.5, bsz=40, num_updates=4960, lr=4.9853e-05, gnorm=0.651, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=18917
2023-01-06 20:06:38 - progress_bar.py[line:274] - INFO: epoch 001:   4975 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0591, wps=103.8, ups=0.48, wpb=108.7, bsz=40, num_updates=4970, lr=4.98485e-05, gnorm=0.646, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=18938
2023-01-06 20:06:59 - progress_bar.py[line:274] - INFO: epoch 001:   4985 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0657, wps=100, ups=0.46, wpb=108.2, bsz=40, num_updates=4980, lr=4.9844e-05, gnorm=0.673, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=18960
2023-01-06 20:07:21 - progress_bar.py[line:274] - INFO: epoch 001:   4995 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0639, wps=100.3, ups=0.47, wpb=107.7, bsz=40, num_updates=4990, lr=4.98395e-05, gnorm=0.58, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18981
2023-01-06 20:07:43 - progress_bar.py[line:274] - INFO: epoch 001:   5005 / 115845 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0435, wps=101.4, ups=0.47, wpb=107.3, bsz=40, num_updates=5000, lr=4.9835e-05, gnorm=0.616, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19003
2023-01-06 20:08:04 - progress_bar.py[line:274] - INFO: epoch 001:   5015 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0443, wps=100.3, ups=0.46, wpb=108.5, bsz=40, num_updates=5010, lr=4.98305e-05, gnorm=0.611, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19025
2023-01-06 20:08:26 - progress_bar.py[line:274] - INFO: epoch 001:   5025 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0628, wps=100.7, ups=0.46, wpb=108.6, bsz=40, num_updates=5020, lr=4.9826e-05, gnorm=0.551, clip=0, loss_scale=1024, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=19046
2023-01-06 20:08:47 - progress_bar.py[line:274] - INFO: epoch 001:   5035 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0366, wps=105, ups=0.48, wpb=108.9, bsz=40, num_updates=5030, lr=4.98215e-05, gnorm=0.563, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=19067
2023-01-06 20:09:09 - progress_bar.py[line:274] - INFO: epoch 001:   5045 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.05, wps=103.6, ups=0.47, wpb=109.6, bsz=40, num_updates=5040, lr=4.9817e-05, gnorm=0.591, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19089
2023-01-06 20:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   5055 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0576, wps=104.5, ups=0.47, wpb=110.6, bsz=40, num_updates=5050, lr=4.98125e-05, gnorm=0.554, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19110
2023-01-06 20:09:52 - progress_bar.py[line:274] - INFO: epoch 001:   5065 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0558, wps=101, ups=0.46, wpb=109.4, bsz=40, num_updates=5060, lr=4.9808e-05, gnorm=0.655, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=19132
2023-01-06 20:10:14 - progress_bar.py[line:274] - INFO: epoch 001:   5075 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0505, wps=98.5, ups=0.45, wpb=108.9, bsz=40, num_updates=5070, lr=4.98035e-05, gnorm=0.619, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19155
2023-01-06 20:10:36 - progress_bar.py[line:274] - INFO: epoch 001:   5085 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0638, wps=101, ups=0.46, wpb=109.3, bsz=40, num_updates=5080, lr=4.9799e-05, gnorm=0.508, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19177
2023-01-06 20:10:58 - progress_bar.py[line:274] - INFO: epoch 001:   5095 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0861, wps=98.4, ups=0.45, wpb=108.2, bsz=40, num_updates=5090, lr=4.97945e-05, gnorm=0.564, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19199
2023-01-06 20:11:21 - progress_bar.py[line:274] - INFO: epoch 001:   5105 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0628, wps=99.6, ups=0.46, wpb=109.2, bsz=40, num_updates=5100, lr=4.979e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19221
2023-01-06 20:11:42 - progress_bar.py[line:274] - INFO: epoch 001:   5115 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0588, wps=103.5, ups=0.47, wpb=110.2, bsz=40, num_updates=5110, lr=4.97855e-05, gnorm=0.606, clip=10, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=19242
2023-01-06 20:12:04 - progress_bar.py[line:274] - INFO: epoch 001:   5125 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0553, wps=100.4, ups=0.46, wpb=108.9, bsz=40, num_updates=5120, lr=4.9781e-05, gnorm=0.697, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19264
2023-01-06 20:12:06 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 20:12:28 - progress_bar.py[line:274] - INFO: epoch 001:   5136 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108.429, nsentences=40, sample_size=108.429, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0398, wps=96.8, ups=0.43, wpb=108.4, bsz=40, num_updates=5130, lr=4.97766e-05, gnorm=0.66, clip=10, loss_scale=512, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=19288
2023-01-06 20:12:50 - progress_bar.py[line:274] - INFO: epoch 001:   5146 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0481, wps=103.5, ups=0.46, wpb=111.8, bsz=40, num_updates=5140, lr=4.97721e-05, gnorm=0.652, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19310
2023-01-06 20:13:11 - progress_bar.py[line:274] - INFO: epoch 001:   5156 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0616, wps=102.9, ups=0.48, wpb=107.8, bsz=40, num_updates=5150, lr=4.97676e-05, gnorm=0.658, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19331
2023-01-06 20:13:33 - progress_bar.py[line:274] - INFO: epoch 001:   5166 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0649, wps=100, ups=0.46, wpb=108.8, bsz=40, num_updates=5160, lr=4.97631e-05, gnorm=0.608, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=19353
2023-01-06 20:13:55 - progress_bar.py[line:274] - INFO: epoch 001:   5176 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0619, wps=101.7, ups=0.47, wpb=108.9, bsz=40, num_updates=5170, lr=4.97586e-05, gnorm=0.609, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19375
2023-01-06 20:14:17 - progress_bar.py[line:274] - INFO: epoch 001:   5186 / 115845 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0635, wps=99.6, ups=0.46, wpb=109.2, bsz=40, num_updates=5180, lr=4.97541e-05, gnorm=0.536, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19397
2023-01-06 20:14:39 - progress_bar.py[line:274] - INFO: epoch 001:   5196 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0374, wps=101.4, ups=0.46, wpb=110.4, bsz=40, num_updates=5190, lr=4.97496e-05, gnorm=0.629, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19419
2023-01-06 20:15:01 - progress_bar.py[line:274] - INFO: epoch 001:   5206 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0691, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=5200, lr=4.97451e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=19441
2023-01-06 20:15:22 - progress_bar.py[line:274] - INFO: epoch 001:   5216 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0571, wps=100, ups=0.46, wpb=108, bsz=40, num_updates=5210, lr=4.97406e-05, gnorm=0.618, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19463
2023-01-06 20:15:45 - progress_bar.py[line:274] - INFO: epoch 001:   5226 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0519, wps=99.3, ups=0.46, wpb=108.2, bsz=40, num_updates=5220, lr=4.97361e-05, gnorm=0.652, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19485
2023-01-06 20:16:06 - progress_bar.py[line:274] - INFO: epoch 001:   5236 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0588, wps=101.5, ups=0.47, wpb=108.2, bsz=40, num_updates=5230, lr=4.97316e-05, gnorm=0.658, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=19506
2023-01-06 20:16:28 - progress_bar.py[line:274] - INFO: epoch 001:   5246 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0606, wps=102.3, ups=0.47, wpb=108.5, bsz=40, num_updates=5240, lr=4.97271e-05, gnorm=0.724, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19528
2023-01-06 20:16:50 - progress_bar.py[line:274] - INFO: epoch 001:   5256 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0616, wps=100.1, ups=0.46, wpb=108.3, bsz=40, num_updates=5250, lr=4.97226e-05, gnorm=0.552, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19550
2023-01-06 20:17:11 - progress_bar.py[line:274] - INFO: epoch 001:   5266 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.099, wps=103.1, ups=0.47, wpb=110, bsz=40, num_updates=5260, lr=4.97181e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=19571
2023-01-06 20:17:34 - progress_bar.py[line:274] - INFO: epoch 001:   5276 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0539, wps=99.9, ups=0.46, wpb=109.2, bsz=40, num_updates=5270, lr=4.97136e-05, gnorm=0.513, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19594
2023-01-06 20:17:56 - progress_bar.py[line:274] - INFO: epoch 001:   5286 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0419, wps=99.9, ups=0.46, wpb=108.5, bsz=40, num_updates=5280, lr=4.97091e-05, gnorm=0.638, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19616
2023-01-06 20:18:18 - progress_bar.py[line:274] - INFO: epoch 001:   5296 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0524, wps=99.4, ups=0.46, wpb=108.9, bsz=40, num_updates=5290, lr=4.97046e-05, gnorm=0.643, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19638
2023-01-06 20:18:40 - progress_bar.py[line:274] - INFO: epoch 001:   5306 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0936, wps=98.5, ups=0.45, wpb=108.3, bsz=40, num_updates=5300, lr=4.97001e-05, gnorm=0.786, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=19660
2023-01-06 20:19:01 - progress_bar.py[line:274] - INFO: epoch 001:   5316 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0947, wps=103.9, ups=0.48, wpb=108.8, bsz=40, num_updates=5310, lr=4.96956e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=19681
2023-01-06 20:19:23 - progress_bar.py[line:274] - INFO: epoch 001:   5326 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0547, wps=101.9, ups=0.47, wpb=108.7, bsz=40, num_updates=5320, lr=4.96911e-05, gnorm=0.631, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19703
2023-01-06 20:19:44 - progress_bar.py[line:274] - INFO: epoch 001:   5336 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0744, wps=100.9, ups=0.47, wpb=107.5, bsz=40, num_updates=5330, lr=4.96866e-05, gnorm=0.63, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19724
2023-01-06 20:20:06 - progress_bar.py[line:274] - INFO: epoch 001:   5346 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0945, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=5340, lr=4.96821e-05, gnorm=0.673, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19746
2023-01-06 20:20:27 - progress_bar.py[line:274] - INFO: epoch 001:   5356 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0885, wps=102.3, ups=0.47, wpb=109.2, bsz=40, num_updates=5350, lr=4.96776e-05, gnorm=0.589, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19768
2023-01-06 20:20:49 - progress_bar.py[line:274] - INFO: epoch 001:   5366 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.05, wps=101, ups=0.47, wpb=108.3, bsz=40, num_updates=5360, lr=4.96731e-05, gnorm=0.561, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19789
2023-01-06 20:21:11 - progress_bar.py[line:274] - INFO: epoch 001:   5376 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0638, wps=102.7, ups=0.47, wpb=110, bsz=40, num_updates=5370, lr=4.96687e-05, gnorm=0.785, clip=30, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19811
2023-01-06 20:21:32 - progress_bar.py[line:274] - INFO: epoch 001:   5386 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0691, wps=102.9, ups=0.47, wpb=110.2, bsz=40, num_updates=5380, lr=4.96642e-05, gnorm=0.616, clip=10, loss_scale=512, train_wall=21, gb_free=9.4, ema_decay=0.9999, wall=19833
2023-01-06 20:21:54 - progress_bar.py[line:274] - INFO: epoch 001:   5396 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1171, wps=102, ups=0.46, wpb=109.8, bsz=40, num_updates=5390, lr=4.96597e-05, gnorm=0.51, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=19854
2023-01-06 20:22:16 - progress_bar.py[line:274] - INFO: epoch 001:   5406 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0773, wps=98.5, ups=0.46, wpb=107.8, bsz=40, num_updates=5400, lr=4.96552e-05, gnorm=0.786, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19877
2023-01-06 20:22:38 - progress_bar.py[line:274] - INFO: epoch 001:   5416 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0663, wps=100.2, ups=0.46, wpb=108.8, bsz=40, num_updates=5410, lr=4.96507e-05, gnorm=0.729, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19898
2023-01-06 20:22:59 - progress_bar.py[line:274] - INFO: epoch 001:   5426 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0372, wps=103.3, ups=0.48, wpb=108.6, bsz=40, num_updates=5420, lr=4.96462e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=19920
2023-01-06 20:23:21 - progress_bar.py[line:274] - INFO: epoch 001:   5436 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0591, wps=104.2, ups=0.47, wpb=110.2, bsz=40, num_updates=5430, lr=4.96417e-05, gnorm=0.541, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19941
2023-01-06 20:23:43 - progress_bar.py[line:274] - INFO: epoch 001:   5446 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0854, wps=99.7, ups=0.46, wpb=108.2, bsz=40, num_updates=5440, lr=4.96372e-05, gnorm=0.562, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19963
2023-01-06 20:24:05 - progress_bar.py[line:274] - INFO: epoch 001:   5456 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0874, wps=103.5, ups=0.47, wpb=109.7, bsz=40, num_updates=5450, lr=4.96327e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19985
2023-01-06 20:24:26 - progress_bar.py[line:274] - INFO: epoch 001:   5466 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0428, wps=104.5, ups=0.48, wpb=108.9, bsz=40, num_updates=5460, lr=4.96282e-05, gnorm=0.774, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20006
2023-01-06 20:24:48 - progress_bar.py[line:274] - INFO: epoch 001:   5476 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0769, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=5470, lr=4.96237e-05, gnorm=0.822, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20028
2023-01-06 20:25:09 - progress_bar.py[line:274] - INFO: epoch 001:   5486 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0511, wps=104.1, ups=0.47, wpb=111.5, bsz=40, num_updates=5480, lr=4.96192e-05, gnorm=0.648, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20050
2023-01-06 20:25:32 - progress_bar.py[line:274] - INFO: epoch 001:   5496 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0667, wps=99, ups=0.46, wpb=108, bsz=40, num_updates=5490, lr=4.96147e-05, gnorm=0.651, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=20072
2023-01-06 20:25:53 - progress_bar.py[line:274] - INFO: epoch 001:   5506 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0868, wps=102.4, ups=0.47, wpb=108.7, bsz=40, num_updates=5500, lr=4.96102e-05, gnorm=0.706, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20093
2023-01-06 20:26:14 - progress_bar.py[line:274] - INFO: epoch 001:   5516 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0785, wps=103.9, ups=0.47, wpb=110.1, bsz=40, num_updates=5510, lr=4.96057e-05, gnorm=0.6, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20115
2023-01-06 20:26:37 - progress_bar.py[line:274] - INFO: epoch 001:   5526 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0601, wps=101, ups=0.46, wpb=110.9, bsz=40, num_updates=5520, lr=4.96012e-05, gnorm=0.571, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20137
2023-01-06 20:26:59 - progress_bar.py[line:274] - INFO: epoch 001:   5536 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0446, wps=101.2, ups=0.46, wpb=110.1, bsz=40, num_updates=5530, lr=4.95967e-05, gnorm=0.752, clip=20, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=20159
2023-01-06 20:27:21 - progress_bar.py[line:274] - INFO: epoch 001:   5546 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1053, wps=98.8, ups=0.46, wpb=107.5, bsz=40, num_updates=5540, lr=4.95922e-05, gnorm=0.576, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=20181
2023-01-06 20:27:42 - progress_bar.py[line:274] - INFO: epoch 001:   5556 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0448, wps=103.9, ups=0.47, wpb=110, bsz=40, num_updates=5550, lr=4.95877e-05, gnorm=0.62, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20202
2023-01-06 20:28:04 - progress_bar.py[line:274] - INFO: epoch 001:   5566 / 115845 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0498, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=5560, lr=4.95832e-05, gnorm=0.504, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20224
2023-01-06 20:28:26 - progress_bar.py[line:274] - INFO: epoch 001:   5576 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0905, wps=101.1, ups=0.46, wpb=110.3, bsz=40, num_updates=5570, lr=4.95787e-05, gnorm=0.775, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20246
2023-01-06 20:28:48 - progress_bar.py[line:274] - INFO: epoch 001:   5586 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.085, wps=100.6, ups=0.46, wpb=110, bsz=40, num_updates=5580, lr=4.95742e-05, gnorm=0.592, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20268
2023-01-06 20:29:09 - progress_bar.py[line:274] - INFO: epoch 001:   5596 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0837, wps=100.9, ups=0.47, wpb=107.5, bsz=40, num_updates=5590, lr=4.95697e-05, gnorm=0.603, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20290
2023-01-06 20:29:31 - progress_bar.py[line:274] - INFO: epoch 001:   5606 / 115845 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1176, wps=102.5, ups=0.46, wpb=110.6, bsz=40, num_updates=5600, lr=4.95652e-05, gnorm=0.659, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20311
2023-01-06 20:29:33 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-06 20:29:55 - progress_bar.py[line:274] - INFO: epoch 001:   5617 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.381, nsentences=40, sample_size=109.381, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0429, wps=98, ups=0.43, wpb=109.4, bsz=40, num_updates=5610, lr=4.95607e-05, gnorm=0.619, clip=0, loss_scale=256, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=20335
2023-01-06 20:30:16 - progress_bar.py[line:274] - INFO: epoch 001:   5627 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1068, wps=102.6, ups=0.47, wpb=108.8, bsz=40, num_updates=5620, lr=4.95563e-05, gnorm=0.601, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20356
2023-01-06 20:30:38 - progress_bar.py[line:274] - INFO: epoch 001:   5637 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0585, wps=101.2, ups=0.46, wpb=109.2, bsz=40, num_updates=5630, lr=4.95518e-05, gnorm=1.018, clip=30, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=20378
2023-01-06 20:31:00 - progress_bar.py[line:274] - INFO: epoch 001:   5647 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0725, wps=102.8, ups=0.47, wpb=109.5, bsz=40, num_updates=5640, lr=4.95473e-05, gnorm=0.669, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20400
2023-01-06 20:31:22 - progress_bar.py[line:274] - INFO: epoch 001:   5657 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1198, wps=99.9, ups=0.46, wpb=109.5, bsz=40, num_updates=5650, lr=4.95428e-05, gnorm=0.778, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20422
2023-01-06 20:31:44 - progress_bar.py[line:274] - INFO: epoch 001:   5667 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0749, wps=100.8, ups=0.46, wpb=109.1, bsz=40, num_updates=5660, lr=4.95383e-05, gnorm=0.612, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20444
2023-01-06 20:32:05 - progress_bar.py[line:274] - INFO: epoch 001:   5677 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0865, wps=103.6, ups=0.47, wpb=110.3, bsz=40, num_updates=5670, lr=4.95338e-05, gnorm=0.724, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20465
2023-01-06 20:32:27 - progress_bar.py[line:274] - INFO: epoch 001:   5687 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0815, wps=101.1, ups=0.46, wpb=110.1, bsz=40, num_updates=5680, lr=4.95293e-05, gnorm=0.647, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20488
2023-01-06 20:32:49 - progress_bar.py[line:274] - INFO: epoch 001:   5697 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0734, wps=101.8, ups=0.46, wpb=109.9, bsz=40, num_updates=5690, lr=4.95248e-05, gnorm=0.587, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20509
2023-01-06 20:33:10 - progress_bar.py[line:274] - INFO: epoch 001:   5707 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0637, wps=103.9, ups=0.48, wpb=109.1, bsz=40, num_updates=5700, lr=4.95203e-05, gnorm=0.557, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20531
2023-01-06 20:33:32 - progress_bar.py[line:274] - INFO: epoch 001:   5717 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0729, wps=102.3, ups=0.46, wpb=110.6, bsz=40, num_updates=5710, lr=4.95158e-05, gnorm=0.531, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20552
2023-01-06 20:33:53 - progress_bar.py[line:274] - INFO: epoch 001:   5727 / 115845 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0955, wps=105.3, ups=0.48, wpb=109.1, bsz=40, num_updates=5720, lr=4.95113e-05, gnorm=0.517, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20573
2023-01-06 20:34:15 - progress_bar.py[line:274] - INFO: epoch 001:   5737 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0691, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=5730, lr=4.95068e-05, gnorm=0.649, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20595
2023-01-06 20:34:37 - progress_bar.py[line:274] - INFO: epoch 001:   5747 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0663, wps=101.3, ups=0.47, wpb=108.4, bsz=40, num_updates=5740, lr=4.95023e-05, gnorm=0.622, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20617
2023-01-06 20:34:58 - progress_bar.py[line:274] - INFO: epoch 001:   5757 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0711, wps=100.3, ups=0.46, wpb=108, bsz=40, num_updates=5750, lr=4.94978e-05, gnorm=0.678, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=20639
2023-01-06 20:35:20 - progress_bar.py[line:274] - INFO: epoch 001:   5767 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1174, wps=101.6, ups=0.47, wpb=108.3, bsz=40, num_updates=5760, lr=4.94933e-05, gnorm=0.627, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20660
2023-01-06 20:35:41 - progress_bar.py[line:274] - INFO: epoch 001:   5777 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0984, wps=103, ups=0.47, wpb=108.9, bsz=40, num_updates=5770, lr=4.94888e-05, gnorm=0.619, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20681
2023-01-06 20:36:03 - progress_bar.py[line:274] - INFO: epoch 001:   5787 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0914, wps=99.7, ups=0.46, wpb=109.2, bsz=40, num_updates=5780, lr=4.94843e-05, gnorm=0.739, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20704
2023-01-06 20:36:25 - progress_bar.py[line:274] - INFO: epoch 001:   5797 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1026, wps=99.4, ups=0.46, wpb=108.7, bsz=40, num_updates=5790, lr=4.94798e-05, gnorm=0.579, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20726
2023-01-06 20:36:47 - progress_bar.py[line:274] - INFO: epoch 001:   5807 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0609, wps=101.1, ups=0.47, wpb=107.8, bsz=40, num_updates=5800, lr=4.94753e-05, gnorm=0.723, clip=10, loss_scale=256, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=20747
2023-01-06 20:37:08 - progress_bar.py[line:274] - INFO: epoch 001:   5817 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0612, wps=102.7, ups=0.47, wpb=108.9, bsz=40, num_updates=5810, lr=4.94708e-05, gnorm=0.742, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20769
2023-01-06 20:37:31 - progress_bar.py[line:274] - INFO: epoch 001:   5827 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0913, wps=98.5, ups=0.46, wpb=107.9, bsz=40, num_updates=5820, lr=4.94663e-05, gnorm=0.652, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20791
2023-01-06 20:37:52 - progress_bar.py[line:274] - INFO: epoch 001:   5837 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1094, wps=101, ups=0.47, wpb=107.8, bsz=40, num_updates=5830, lr=4.94618e-05, gnorm=0.559, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20812
2023-01-06 20:38:14 - progress_bar.py[line:274] - INFO: epoch 001:   5847 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0785, wps=103.1, ups=0.47, wpb=109.9, bsz=40, num_updates=5840, lr=4.94573e-05, gnorm=0.57, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20834
2023-01-06 20:38:36 - progress_bar.py[line:274] - INFO: epoch 001:   5857 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0924, wps=101.6, ups=0.46, wpb=110, bsz=40, num_updates=5850, lr=4.94528e-05, gnorm=0.563, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20856
2023-01-06 20:38:57 - progress_bar.py[line:274] - INFO: epoch 001:   5867 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0553, wps=102.2, ups=0.47, wpb=108.2, bsz=40, num_updates=5860, lr=4.94484e-05, gnorm=0.463, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20877
2023-01-06 20:39:19 - progress_bar.py[line:274] - INFO: epoch 001:   5877 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.06, wps=102.6, ups=0.47, wpb=109.8, bsz=40, num_updates=5870, lr=4.94439e-05, gnorm=0.517, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20899
2023-01-06 20:39:40 - progress_bar.py[line:274] - INFO: epoch 001:   5887 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0769, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=5880, lr=4.94394e-05, gnorm=0.536, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20920
2023-01-06 20:40:02 - progress_bar.py[line:274] - INFO: epoch 001:   5897 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0588, wps=103.6, ups=0.47, wpb=109.6, bsz=40, num_updates=5890, lr=4.94349e-05, gnorm=0.565, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20942
2023-01-06 20:40:25 - progress_bar.py[line:274] - INFO: epoch 001:   5907 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0773, wps=100.7, ups=0.47, wpb=108, bsz=40, num_updates=5900, lr=4.94304e-05, gnorm=0.854, clip=20, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=20964
2023-01-06 20:40:47 - progress_bar.py[line:274] - INFO: epoch 001:   5917 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0653, wps=102.6, ups=0.47, wpb=110, bsz=40, num_updates=5910, lr=4.94259e-05, gnorm=0.639, clip=0, loss_scale=256, train_wall=21, gb_free=9.5, ema_decay=0.9999, wall=20986
2023-01-06 20:41:10 - progress_bar.py[line:274] - INFO: epoch 001:   5927 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0952, wps=100.9, ups=0.46, wpb=110, bsz=40, num_updates=5920, lr=4.94214e-05, gnorm=0.712, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=21009
2023-01-06 20:41:33 - progress_bar.py[line:274] - INFO: epoch 001:   5937 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.07, wps=101.5, ups=0.47, wpb=108.5, bsz=40, num_updates=5930, lr=4.94169e-05, gnorm=0.739, clip=20, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=21032
2023-01-06 20:41:56 - progress_bar.py[line:274] - INFO: epoch 001:   5947 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0628, wps=102.2, ups=0.47, wpb=109.8, bsz=40, num_updates=5940, lr=4.94124e-05, gnorm=0.565, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=21055
2023-01-06 20:42:19 - progress_bar.py[line:274] - INFO: epoch 001:   5957 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1263, wps=99.5, ups=0.46, wpb=109, bsz=40, num_updates=5950, lr=4.94079e-05, gnorm=0.692, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=21078
2023-01-06 20:42:42 - progress_bar.py[line:274] - INFO: epoch 001:   5967 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0806, wps=103.5, ups=0.48, wpb=108.7, bsz=40, num_updates=5960, lr=4.94034e-05, gnorm=0.638, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=21101
2023-01-06 20:43:05 - progress_bar.py[line:274] - INFO: epoch 001:   5977 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1078, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=5970, lr=4.93989e-05, gnorm=0.518, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=21124
2023-01-06 20:43:28 - progress_bar.py[line:274] - INFO: epoch 001:   5987 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0933, wps=104, ups=0.47, wpb=110.5, bsz=40, num_updates=5980, lr=4.93944e-05, gnorm=0.566, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=21147
2023-01-06 20:43:51 - progress_bar.py[line:274] - INFO: epoch 001:   5997 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1043, wps=101, ups=0.47, wpb=108.3, bsz=40, num_updates=5990, lr=4.93899e-05, gnorm=0.567, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=21170
2023-01-06 20:44:14 - progress_bar.py[line:274] - INFO: epoch 001:   6007 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0667, wps=103.1, ups=0.47, wpb=109.1, bsz=40, num_updates=6000, lr=4.93854e-05, gnorm=0.543, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=21193
2023-01-06 20:44:14 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-06 20:44:15 - train.py[line:549] - INFO: 0 / 4988
2023-01-06 20:44:15 - train.py[line:551] - INFO: load:1.05 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-06 20:46:46 - train.py[line:549] - INFO: 200 / 4988
2023-01-06 20:46:46 - train.py[line:551] - INFO: load:1.08 valid_run:151.00 task_valid:146.99 collect_output:2.96
2023-01-06 20:49:15 - train.py[line:549] - INFO: 400 / 4988
2023-01-06 20:49:15 - train.py[line:551] - INFO: load:1.10 valid_run:299.46 task_valid:288.91 collect_output:8.45
2023-01-06 20:51:48 - train.py[line:549] - INFO: 600 / 4988
2023-01-06 20:51:48 - train.py[line:551] - INFO: load:1.13 valid_run:452.38 task_valid:430.81 collect_output:18.44
2023-01-06 20:54:17 - train.py[line:549] - INFO: 800 / 4988
2023-01-06 20:54:17 - train.py[line:551] - INFO: load:1.15 valid_run:601.19 task_valid:574.77 collect_output:22.25
2023-01-06 20:56:48 - train.py[line:549] - INFO: 1000 / 4988
2023-01-06 20:56:48 - train.py[line:551] - INFO: load:1.18 valid_run:752.89 task_valid:720.96 collect_output:26.72
2023-01-06 20:59:20 - train.py[line:549] - INFO: 1200 / 4988
2023-01-06 20:59:20 - train.py[line:551] - INFO: load:1.21 valid_run:904.41 task_valid:865.14 collect_output:33.03
2023-01-06 21:01:54 - train.py[line:549] - INFO: 1400 / 4988
2023-01-06 21:01:54 - train.py[line:551] - INFO: load:1.23 valid_run:1057.82 task_valid:1009.77 collect_output:40.77
2023-01-06 21:04:25 - train.py[line:549] - INFO: 1600 / 4988
2023-01-06 21:04:25 - train.py[line:551] - INFO: load:1.26 valid_run:1209.26 task_valid:1149.80 collect_output:51.12
2023-01-06 21:06:55 - train.py[line:549] - INFO: 1800 / 4988
2023-01-06 21:06:55 - train.py[line:551] - INFO: load:1.28 valid_run:1358.57 task_valid:1293.37 collect_output:55.80
2023-01-06 21:09:23 - train.py[line:549] - INFO: 2000 / 4988
2023-01-06 21:09:23 - train.py[line:551] - INFO: load:1.31 valid_run:1506.96 task_valid:1435.42 collect_output:61.09
2023-01-06 21:11:52 - train.py[line:549] - INFO: 2200 / 4988
2023-01-06 21:11:52 - train.py[line:551] - INFO: load:1.34 valid_run:1656.21 task_valid:1579.04 collect_output:65.66
2023-01-06 21:14:22 - train.py[line:549] - INFO: 2400 / 4988
2023-01-06 21:14:22 - train.py[line:551] - INFO: load:1.36 valid_run:1805.92 task_valid:1722.97 collect_output:70.38
2023-01-06 21:16:52 - train.py[line:549] - INFO: 2600 / 4988
2023-01-06 21:16:52 - train.py[line:551] - INFO: load:1.39 valid_run:1955.80 task_valid:1863.55 collect_output:78.63
2023-01-06 21:19:25 - train.py[line:549] - INFO: 2800 / 4988
2023-01-06 21:19:25 - train.py[line:551] - INFO: load:1.42 valid_run:2108.07 task_valid:2009.44 collect_output:83.88
2023-01-06 21:21:54 - train.py[line:549] - INFO: 3000 / 4988
2023-01-06 21:21:54 - train.py[line:551] - INFO: load:1.44 valid_run:2257.70 task_valid:2154.84 collect_output:87.03
2023-01-06 21:24:25 - train.py[line:549] - INFO: 3200 / 4988
2023-01-06 21:24:25 - train.py[line:551] - INFO: load:1.47 valid_run:2407.84 task_valid:2298.39 collect_output:92.56
2023-01-06 21:26:56 - train.py[line:549] - INFO: 3400 / 4988
2023-01-06 21:26:56 - train.py[line:551] - INFO: load:1.50 valid_run:2559.62 task_valid:2442.90 collect_output:98.71
2023-01-06 21:29:27 - train.py[line:549] - INFO: 3600 / 4988
2023-01-06 21:29:27 - train.py[line:551] - INFO: load:1.52 valid_run:2709.67 task_valid:2588.75 collect_output:101.85
2023-01-06 21:31:55 - train.py[line:549] - INFO: 3800 / 4988
2023-01-06 21:31:55 - train.py[line:551] - INFO: load:1.55 valid_run:2858.54 task_valid:2729.34 collect_output:109.06
2023-01-06 21:34:26 - train.py[line:549] - INFO: 4000 / 4988
2023-01-06 21:34:26 - train.py[line:551] - INFO: load:1.57 valid_run:3008.86 task_valid:2873.69 collect_output:113.98
2023-01-06 21:36:58 - train.py[line:549] - INFO: 4200 / 4988
2023-01-06 21:36:58 - train.py[line:551] - INFO: load:1.60 valid_run:3160.89 task_valid:3017.29 collect_output:121.31
2023-01-06 21:39:27 - train.py[line:549] - INFO: 4400 / 4988
2023-01-06 21:39:27 - train.py[line:551] - INFO: load:1.62 valid_run:3310.09 task_valid:3160.84 collect_output:125.90
2023-01-06 21:41:58 - train.py[line:549] - INFO: 4600 / 4988
2023-01-06 21:41:58 - train.py[line:551] - INFO: load:1.65 valid_run:3461.19 task_valid:3305.99 collect_output:130.81
2023-01-06 21:44:30 - train.py[line:549] - INFO: 4800 / 4988
2023-01-06 21:44:30 - train.py[line:551] - INFO: load:1.68 valid_run:3612.46 task_valid:3451.88 collect_output:135.09

====================================================================================================
SGG eval:     R @ 50: 0.5856;     R @ 100: 0.6372;     R @ 500: 0.6722;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3539;    mR @ 100: 0.4520;    mR @ 500: 0.4997;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.8125) (covering:0.3714) (eating:0.7647) (flying in:0.7273) (growing on:0.3750) (hanging from:0.4194) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9183) (says:0.0000) (sitting on:0.7347) (standing on:0.2583) (using:0.6000) (walking in:0.0000) (walking on:0.8108) (watching:0.3750) 
--------------------------------------------------------
====================================================================================================

2023-01-06 21:47:00 - train.py[line:487] - INFO: 0.6372205755029284
2023-01-06 21:47:00 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.5856;     R @ 100: 0.6372;     R @ 500: 0.6722;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3539;    mR @ 100: 0.4520;    mR @ 500: 0.4997;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.8125) (covering:0.3714) (eating:0.7647) (flying in:0.7273) (growing on:0.3750) (hanging from:0.4194) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9183) (says:0.0000) (sitting on:0.7347) (standing on:0.2583) (using:0.6000) (walking in:0.0000) (walking on:0.8108) (watching:0.3750) 
--------------------------------------------------------
====================================================================================================

2023-01-06 21:47:01 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.362 | loss_v1 0 | loss_v2 0 | nll_loss 0.209 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.637221 | ppl 1.16 | vqa_score 0.4561 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 6000 | best_R@100 0.637221
2023-01-06 21:47:01 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2023-01-06 21:47:01 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_6000.pt
2023-01-06 21:48:00 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_6000.pt
2023-01-06 21:51:33 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.6372205755029284) (writing took 272.5012739505619 seconds)
2023-01-06 21:51:54 - progress_bar.py[line:274] - INFO: epoch 001:   6017 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1156, wps=0.5, ups=0, wpb=108.3, bsz=40, num_updates=6010, lr=4.93809e-05, gnorm=0.637, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=25255
2023-01-06 21:52:16 - progress_bar.py[line:274] - INFO: epoch 001:   6027 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0885, wps=102.2, ups=0.47, wpb=109.1, bsz=40, num_updates=6020, lr=4.93764e-05, gnorm=0.512, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25276
2023-01-06 21:52:38 - progress_bar.py[line:274] - INFO: epoch 001:   6037 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0952, wps=99.6, ups=0.46, wpb=107.4, bsz=40, num_updates=6030, lr=4.93719e-05, gnorm=0.538, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=25298
2023-01-06 21:53:00 - progress_bar.py[line:274] - INFO: epoch 001:   6047 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0754, wps=99.8, ups=0.46, wpb=108.9, bsz=40, num_updates=6040, lr=4.93674e-05, gnorm=0.587, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25320
2023-01-06 21:53:22 - progress_bar.py[line:274] - INFO: epoch 001:   6057 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0632, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=6050, lr=4.93629e-05, gnorm=0.634, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=25342
2023-01-06 21:53:43 - progress_bar.py[line:274] - INFO: epoch 001:   6067 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0579, wps=102, ups=0.47, wpb=109, bsz=40, num_updates=6060, lr=4.93584e-05, gnorm=0.65, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25363
2023-01-06 21:54:05 - progress_bar.py[line:274] - INFO: epoch 001:   6077 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1019, wps=100.9, ups=0.47, wpb=108, bsz=40, num_updates=6070, lr=4.93539e-05, gnorm=0.502, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25385
2023-01-06 21:54:27 - progress_bar.py[line:274] - INFO: epoch 001:   6087 / 115845 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0791, wps=101.5, ups=0.46, wpb=110.2, bsz=40, num_updates=6080, lr=4.93494e-05, gnorm=0.574, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=25407
2023-01-06 21:54:49 - progress_bar.py[line:274] - INFO: epoch 001:   6097 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0991, wps=99.3, ups=0.46, wpb=108.1, bsz=40, num_updates=6090, lr=4.93449e-05, gnorm=0.673, clip=20, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=25429
2023-01-06 21:55:11 - progress_bar.py[line:274] - INFO: epoch 001:   6107 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0825, wps=102.4, ups=0.47, wpb=109.9, bsz=40, num_updates=6100, lr=4.93404e-05, gnorm=0.546, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25451
2023-01-06 21:55:32 - progress_bar.py[line:274] - INFO: epoch 001:   6117 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0704, wps=104, ups=0.47, wpb=109.8, bsz=40, num_updates=6110, lr=4.9336e-05, gnorm=0.591, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=25472
2023-01-06 21:55:54 - progress_bar.py[line:274] - INFO: epoch 001:   6127 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0933, wps=99.3, ups=0.46, wpb=108.3, bsz=40, num_updates=6120, lr=4.93315e-05, gnorm=0.612, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=25494
2023-01-06 21:56:15 - progress_bar.py[line:274] - INFO: epoch 001:   6137 / 115845 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1385, wps=104.5, ups=0.47, wpb=111, bsz=40, num_updates=6130, lr=4.9327e-05, gnorm=0.54, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=25516
2023-01-06 21:56:37 - progress_bar.py[line:274] - INFO: epoch 001:   6147 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0789, wps=101.5, ups=0.47, wpb=108.9, bsz=40, num_updates=6140, lr=4.93225e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=25537
2023-01-06 21:56:59 - progress_bar.py[line:274] - INFO: epoch 001:   6157 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0863, wps=102.5, ups=0.47, wpb=109.7, bsz=40, num_updates=6150, lr=4.9318e-05, gnorm=0.526, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25559
2023-01-06 21:57:21 - progress_bar.py[line:274] - INFO: epoch 001:   6167 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0647, wps=102.3, ups=0.47, wpb=109.8, bsz=40, num_updates=6160, lr=4.93135e-05, gnorm=0.517, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25581
2023-01-06 21:57:42 - progress_bar.py[line:274] - INFO: epoch 001:   6177 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0922, wps=101, ups=0.46, wpb=108.6, bsz=40, num_updates=6170, lr=4.9309e-05, gnorm=0.653, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25602
2023-01-06 21:58:04 - progress_bar.py[line:274] - INFO: epoch 001:   6187 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0778, wps=104.9, ups=0.47, wpb=111.1, bsz=40, num_updates=6180, lr=4.93045e-05, gnorm=0.571, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25624
2023-01-06 21:58:25 - progress_bar.py[line:274] - INFO: epoch 001:   6197 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0567, wps=102.4, ups=0.47, wpb=109.9, bsz=40, num_updates=6190, lr=4.93e-05, gnorm=0.535, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=25646
2023-01-06 21:58:47 - progress_bar.py[line:274] - INFO: epoch 001:   6207 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1019, wps=101.6, ups=0.47, wpb=109, bsz=40, num_updates=6200, lr=4.92955e-05, gnorm=0.625, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25667
2023-01-06 21:59:09 - progress_bar.py[line:274] - INFO: epoch 001:   6217 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0928, wps=102.1, ups=0.47, wpb=109.8, bsz=40, num_updates=6210, lr=4.9291e-05, gnorm=0.522, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25689
2023-01-06 21:59:31 - progress_bar.py[line:274] - INFO: epoch 001:   6227 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1366, wps=100.9, ups=0.47, wpb=108.5, bsz=40, num_updates=6220, lr=4.92865e-05, gnorm=0.547, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25711
2023-01-06 21:59:52 - progress_bar.py[line:274] - INFO: epoch 001:   6237 / 115845 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1429, wps=104, ups=0.47, wpb=109.7, bsz=40, num_updates=6230, lr=4.9282e-05, gnorm=0.713, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25732
2023-01-06 22:00:13 - progress_bar.py[line:274] - INFO: epoch 001:   6247 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.099, wps=104.6, ups=0.48, wpb=108.7, bsz=40, num_updates=6240, lr=4.92775e-05, gnorm=0.477, clip=0, loss_scale=512, train_wall=21, gb_free=9.5, ema_decay=0.9999, wall=25753
2023-01-06 22:00:34 - progress_bar.py[line:274] - INFO: epoch 001:   6257 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1042, wps=102.7, ups=0.47, wpb=109.4, bsz=40, num_updates=6250, lr=4.9273e-05, gnorm=0.613, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25775
2023-01-06 22:00:56 - progress_bar.py[line:274] - INFO: epoch 001:   6267 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0842, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=6260, lr=4.92685e-05, gnorm=0.463, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25797
2023-01-06 22:01:18 - progress_bar.py[line:274] - INFO: epoch 001:   6277 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1116, wps=103, ups=0.47, wpb=109.2, bsz=40, num_updates=6270, lr=4.9264e-05, gnorm=0.515, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=25818
2023-01-06 22:01:40 - progress_bar.py[line:274] - INFO: epoch 001:   6287 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1232, wps=99.7, ups=0.46, wpb=108.1, bsz=40, num_updates=6280, lr=4.92595e-05, gnorm=0.477, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=25840
2023-01-06 22:02:02 - progress_bar.py[line:274] - INFO: epoch 001:   6297 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.145, wps=99.9, ups=0.46, wpb=109.5, bsz=40, num_updates=6290, lr=4.9255e-05, gnorm=0.487, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25862
2023-01-06 22:02:23 - progress_bar.py[line:274] - INFO: epoch 001:   6307 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1408, wps=103, ups=0.47, wpb=109, bsz=40, num_updates=6300, lr=4.92505e-05, gnorm=0.595, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25883
2023-01-06 22:02:45 - progress_bar.py[line:274] - INFO: epoch 001:   6317 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1397, wps=103.1, ups=0.47, wpb=110.6, bsz=40, num_updates=6310, lr=4.9246e-05, gnorm=0.523, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25905
2023-01-06 22:03:06 - progress_bar.py[line:274] - INFO: epoch 001:   6327 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0936, wps=102.7, ups=0.47, wpb=108.4, bsz=40, num_updates=6320, lr=4.92415e-05, gnorm=0.519, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=25926
2023-01-06 22:03:27 - progress_bar.py[line:274] - INFO: epoch 001:   6337 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1554, wps=103.5, ups=0.48, wpb=108.6, bsz=40, num_updates=6330, lr=4.9237e-05, gnorm=0.739, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25948
2023-01-06 22:03:49 - progress_bar.py[line:274] - INFO: epoch 001:   6347 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1489, wps=104.2, ups=0.47, wpb=110.1, bsz=40, num_updates=6340, lr=4.92325e-05, gnorm=0.606, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=25969
2023-01-06 22:04:10 - progress_bar.py[line:274] - INFO: epoch 001:   6357 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0974, wps=102.5, ups=0.48, wpb=107.8, bsz=40, num_updates=6350, lr=4.92281e-05, gnorm=0.813, clip=20, loss_scale=512, train_wall=21, gb_free=9.5, ema_decay=0.9999, wall=25990
2023-01-06 22:04:32 - progress_bar.py[line:274] - INFO: epoch 001:   6367 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1056, wps=102.3, ups=0.47, wpb=109.9, bsz=40, num_updates=6360, lr=4.92236e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26012
2023-01-06 22:04:53 - progress_bar.py[line:274] - INFO: epoch 001:   6377 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0693, wps=102.9, ups=0.47, wpb=108.8, bsz=40, num_updates=6370, lr=4.92191e-05, gnorm=0.577, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=26033
2023-01-06 22:05:15 - progress_bar.py[line:274] - INFO: epoch 001:   6387 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.128, wps=99.9, ups=0.46, wpb=107.6, bsz=40, num_updates=6380, lr=4.92146e-05, gnorm=0.57, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26055
2023-01-06 22:05:37 - progress_bar.py[line:274] - INFO: epoch 001:   6397 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.122, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=6390, lr=4.92101e-05, gnorm=0.701, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26077
2023-01-06 22:05:58 - progress_bar.py[line:274] - INFO: epoch 001:   6407 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1455, wps=100, ups=0.46, wpb=107.9, bsz=40, num_updates=6400, lr=4.92056e-05, gnorm=0.558, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26099
2023-01-06 22:06:20 - progress_bar.py[line:274] - INFO: epoch 001:   6417 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1031, wps=101, ups=0.46, wpb=110, bsz=40, num_updates=6410, lr=4.92011e-05, gnorm=0.523, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26121
2023-01-06 22:06:42 - progress_bar.py[line:274] - INFO: epoch 001:   6427 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0714, wps=103.7, ups=0.47, wpb=110.2, bsz=40, num_updates=6420, lr=4.91966e-05, gnorm=0.52, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26142
2023-01-06 22:07:03 - progress_bar.py[line:274] - INFO: epoch 001:   6437 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1684, wps=102.5, ups=0.47, wpb=109.3, bsz=40, num_updates=6430, lr=4.91921e-05, gnorm=0.599, clip=10, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=26164
2023-01-06 22:07:25 - progress_bar.py[line:274] - INFO: epoch 001:   6447 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1045, wps=101.3, ups=0.47, wpb=108.4, bsz=40, num_updates=6440, lr=4.91876e-05, gnorm=0.572, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26185
2023-01-06 22:07:47 - progress_bar.py[line:274] - INFO: epoch 001:   6457 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1366, wps=102.9, ups=0.47, wpb=108.5, bsz=40, num_updates=6450, lr=4.91831e-05, gnorm=0.564, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=26207
2023-01-06 22:08:08 - progress_bar.py[line:274] - INFO: epoch 001:   6467 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1469, wps=101.5, ups=0.47, wpb=108.7, bsz=40, num_updates=6460, lr=4.91786e-05, gnorm=0.509, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=26228
2023-01-06 22:08:30 - progress_bar.py[line:274] - INFO: epoch 001:   6477 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1117, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=6470, lr=4.91741e-05, gnorm=0.577, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=26250
2023-01-06 22:08:51 - progress_bar.py[line:274] - INFO: epoch 001:   6487 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1382, wps=103, ups=0.48, wpb=107.7, bsz=40, num_updates=6480, lr=4.91696e-05, gnorm=0.553, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=26271
2023-01-06 22:09:13 - progress_bar.py[line:274] - INFO: epoch 001:   6497 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1152, wps=99.6, ups=0.46, wpb=107.9, bsz=40, num_updates=6490, lr=4.91651e-05, gnorm=0.541, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26293
2023-01-06 22:09:35 - progress_bar.py[line:274] - INFO: epoch 001:   6507 / 115845 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1111, wps=101, ups=0.46, wpb=109.7, bsz=40, num_updates=6500, lr=4.91606e-05, gnorm=0.437, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26315
2023-01-06 22:09:57 - progress_bar.py[line:274] - INFO: epoch 001:   6517 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1163, wps=100.9, ups=0.47, wpb=108.3, bsz=40, num_updates=6510, lr=4.91561e-05, gnorm=0.658, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=26337
2023-01-06 22:10:18 - progress_bar.py[line:274] - INFO: epoch 001:   6527 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1042, wps=102.1, ups=0.47, wpb=109.7, bsz=40, num_updates=6520, lr=4.91516e-05, gnorm=0.544, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26358
2023-01-06 22:10:40 - progress_bar.py[line:274] - INFO: epoch 001:   6537 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1393, wps=102.5, ups=0.47, wpb=108.7, bsz=40, num_updates=6530, lr=4.91471e-05, gnorm=0.499, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26380
2023-01-06 22:11:01 - progress_bar.py[line:274] - INFO: epoch 001:   6547 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1733, wps=101.7, ups=0.47, wpb=108.7, bsz=40, num_updates=6540, lr=4.91426e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26402
2023-01-06 22:11:22 - progress_bar.py[line:274] - INFO: epoch 001:   6557 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1407, wps=105.9, ups=0.48, wpb=109.3, bsz=40, num_updates=6550, lr=4.91381e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=26422
2023-01-06 22:11:44 - progress_bar.py[line:274] - INFO: epoch 001:   6567 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1773, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=6560, lr=4.91336e-05, gnorm=0.451, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26444
2023-01-06 22:12:06 - progress_bar.py[line:274] - INFO: epoch 001:   6577 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1498, wps=101.6, ups=0.47, wpb=108.4, bsz=40, num_updates=6570, lr=4.91291e-05, gnorm=0.537, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=26466
2023-01-06 22:12:27 - progress_bar.py[line:274] - INFO: epoch 001:   6587 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1144, wps=102.4, ups=0.47, wpb=109.2, bsz=40, num_updates=6580, lr=4.91246e-05, gnorm=0.655, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26488
2023-01-06 22:12:49 - progress_bar.py[line:274] - INFO: epoch 001:   6597 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1429, wps=102.1, ups=0.47, wpb=108.7, bsz=40, num_updates=6590, lr=4.91201e-05, gnorm=0.532, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=26509
2023-01-06 22:13:11 - progress_bar.py[line:274] - INFO: epoch 001:   6607 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1231, wps=102.9, ups=0.47, wpb=110.6, bsz=40, num_updates=6600, lr=4.91157e-05, gnorm=0.566, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26531
2023-01-06 22:13:33 - progress_bar.py[line:274] - INFO: epoch 001:   6617 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1615, wps=100.5, ups=0.46, wpb=108.9, bsz=40, num_updates=6610, lr=4.91112e-05, gnorm=0.515, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=26553
2023-01-06 22:13:54 - progress_bar.py[line:274] - INFO: epoch 001:   6627 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0833, wps=101.9, ups=0.47, wpb=108.6, bsz=40, num_updates=6620, lr=4.91067e-05, gnorm=0.527, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26574
2023-01-06 22:14:15 - progress_bar.py[line:274] - INFO: epoch 001:   6637 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1302, wps=105.8, ups=0.48, wpb=109.8, bsz=40, num_updates=6630, lr=4.91022e-05, gnorm=0.641, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26595
2023-01-06 22:14:37 - progress_bar.py[line:274] - INFO: epoch 001:   6647 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1395, wps=100.3, ups=0.46, wpb=108.7, bsz=40, num_updates=6640, lr=4.90977e-05, gnorm=0.531, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26617
2023-01-06 22:14:58 - progress_bar.py[line:274] - INFO: epoch 001:   6657 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1192, wps=105, ups=0.48, wpb=110.3, bsz=40, num_updates=6650, lr=4.90932e-05, gnorm=0.503, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26638
2023-01-06 22:15:07 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 22:15:23 - progress_bar.py[line:274] - INFO: epoch 001:   6668 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=109.19, nsentences=40, sample_size=109.19, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1217, wps=94.9, ups=0.41, wpb=109.2, bsz=40, num_updates=6660, lr=4.90887e-05, gnorm=0.642, clip=10, loss_scale=512, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=26663
2023-01-06 22:15:44 - progress_bar.py[line:274] - INFO: epoch 001:   6678 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1256, wps=102.6, ups=0.47, wpb=108.7, bsz=40, num_updates=6670, lr=4.90842e-05, gnorm=0.589, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26684
2023-01-06 22:16:06 - progress_bar.py[line:274] - INFO: epoch 001:   6688 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1649, wps=102.3, ups=0.47, wpb=109.6, bsz=40, num_updates=6680, lr=4.90797e-05, gnorm=0.618, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26706
2023-01-06 22:16:27 - progress_bar.py[line:274] - INFO: epoch 001:   6698 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1095, wps=102.9, ups=0.47, wpb=109.8, bsz=40, num_updates=6690, lr=4.90752e-05, gnorm=0.551, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26727
2023-01-06 22:16:49 - progress_bar.py[line:274] - INFO: epoch 001:   6708 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1702, wps=103.6, ups=0.47, wpb=110.4, bsz=40, num_updates=6700, lr=4.90707e-05, gnorm=0.454, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26749
2023-01-06 22:17:10 - progress_bar.py[line:274] - INFO: epoch 001:   6718 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1106, wps=101, ups=0.47, wpb=107.5, bsz=40, num_updates=6710, lr=4.90662e-05, gnorm=0.678, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=26771
2023-01-06 22:17:31 - progress_bar.py[line:274] - INFO: epoch 001:   6728 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.134, wps=104.8, ups=0.48, wpb=109.8, bsz=40, num_updates=6720, lr=4.90617e-05, gnorm=0.557, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=26792
2023-01-06 22:17:53 - progress_bar.py[line:274] - INFO: epoch 001:   6738 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1667, wps=103.4, ups=0.47, wpb=109.7, bsz=40, num_updates=6730, lr=4.90572e-05, gnorm=0.633, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26813
2023-01-06 22:18:15 - progress_bar.py[line:274] - INFO: epoch 001:   6748 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1576, wps=102, ups=0.47, wpb=108.8, bsz=40, num_updates=6740, lr=4.90527e-05, gnorm=0.519, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26835
2023-01-06 22:18:36 - progress_bar.py[line:274] - INFO: epoch 001:   6758 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.087, wps=102.2, ups=0.47, wpb=109.1, bsz=40, num_updates=6750, lr=4.90482e-05, gnorm=0.572, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26856
2023-01-06 22:18:58 - progress_bar.py[line:274] - INFO: epoch 001:   6768 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1392, wps=102.5, ups=0.46, wpb=110.7, bsz=40, num_updates=6760, lr=4.90437e-05, gnorm=0.592, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=26878
2023-01-06 22:19:20 - progress_bar.py[line:274] - INFO: epoch 001:   6778 / 115845 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1337, wps=101.7, ups=0.46, wpb=109.8, bsz=40, num_updates=6770, lr=4.90392e-05, gnorm=0.584, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26900
2023-01-06 22:19:42 - progress_bar.py[line:274] - INFO: epoch 001:   6788 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1675, wps=100.6, ups=0.46, wpb=108.7, bsz=40, num_updates=6780, lr=4.90347e-05, gnorm=0.554, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26922
2023-01-06 22:20:04 - progress_bar.py[line:274] - INFO: epoch 001:   6798 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0876, wps=99.4, ups=0.46, wpb=109.1, bsz=40, num_updates=6790, lr=4.90302e-05, gnorm=0.624, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=26944
2023-01-06 22:20:26 - progress_bar.py[line:274] - INFO: epoch 001:   6808 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1512, wps=101, ups=0.47, wpb=108.4, bsz=40, num_updates=6800, lr=4.90257e-05, gnorm=0.55, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26966
2023-01-06 22:20:48 - progress_bar.py[line:274] - INFO: epoch 001:   6818 / 115845 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1268, wps=101.7, ups=0.46, wpb=110.3, bsz=40, num_updates=6810, lr=4.90212e-05, gnorm=0.523, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26988
2023-01-06 22:21:09 - progress_bar.py[line:274] - INFO: epoch 001:   6828 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1401, wps=102, ups=0.46, wpb=109.7, bsz=40, num_updates=6820, lr=4.90167e-05, gnorm=0.449, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27010
2023-01-06 22:21:31 - progress_bar.py[line:274] - INFO: epoch 001:   6838 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1193, wps=98.6, ups=0.46, wpb=107.2, bsz=40, num_updates=6830, lr=4.90122e-05, gnorm=0.51, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=27032
2023-01-06 22:21:53 - progress_bar.py[line:274] - INFO: epoch 001:   6848 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1088, wps=101.5, ups=0.47, wpb=108.2, bsz=40, num_updates=6840, lr=4.90078e-05, gnorm=0.564, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=27053
2023-01-06 22:22:14 - progress_bar.py[line:274] - INFO: epoch 001:   6858 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1574, wps=103.4, ups=0.47, wpb=109.4, bsz=40, num_updates=6850, lr=4.90033e-05, gnorm=0.466, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27074
2023-01-06 22:22:36 - progress_bar.py[line:274] - INFO: epoch 001:   6868 / 115845 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1379, wps=102.9, ups=0.47, wpb=108.5, bsz=40, num_updates=6860, lr=4.89988e-05, gnorm=0.53, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=27096
2023-01-06 22:22:58 - progress_bar.py[line:274] - INFO: epoch 001:   6878 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1554, wps=101.3, ups=0.46, wpb=110, bsz=40, num_updates=6870, lr=4.89943e-05, gnorm=0.499, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27118
2023-01-06 22:23:20 - progress_bar.py[line:274] - INFO: epoch 001:   6888 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1643, wps=100.1, ups=0.47, wpb=107.1, bsz=40, num_updates=6880, lr=4.89898e-05, gnorm=0.447, clip=0, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=27140
2023-01-06 22:23:41 - progress_bar.py[line:274] - INFO: epoch 001:   6898 / 115845 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1598, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=6890, lr=4.89853e-05, gnorm=0.568, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27161
2023-01-06 22:24:03 - progress_bar.py[line:274] - INFO: epoch 001:   6908 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1347, wps=104.6, ups=0.47, wpb=110.3, bsz=40, num_updates=6900, lr=4.89808e-05, gnorm=0.569, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27183
2023-01-06 22:24:24 - progress_bar.py[line:274] - INFO: epoch 001:   6918 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1337, wps=101.9, ups=0.47, wpb=109.5, bsz=40, num_updates=6910, lr=4.89763e-05, gnorm=0.561, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=27205
2023-01-06 22:24:46 - progress_bar.py[line:274] - INFO: epoch 001:   6928 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1517, wps=102.3, ups=0.47, wpb=108.9, bsz=40, num_updates=6920, lr=4.89718e-05, gnorm=0.541, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=27226
2023-01-06 22:25:07 - progress_bar.py[line:274] - INFO: epoch 001:   6938 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1275, wps=103.4, ups=0.48, wpb=108.5, bsz=40, num_updates=6930, lr=4.89673e-05, gnorm=0.584, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=27247
2023-01-06 22:25:29 - progress_bar.py[line:274] - INFO: epoch 001:   6948 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1386, wps=101.6, ups=0.46, wpb=109.9, bsz=40, num_updates=6940, lr=4.89628e-05, gnorm=0.85, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=27269
2023-01-06 22:25:51 - progress_bar.py[line:274] - INFO: epoch 001:   6958 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1414, wps=99.7, ups=0.45, wpb=110, bsz=40, num_updates=6950, lr=4.89583e-05, gnorm=0.622, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27291
2023-01-06 22:26:13 - progress_bar.py[line:274] - INFO: epoch 001:   6968 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1643, wps=101.8, ups=0.47, wpb=109.3, bsz=40, num_updates=6960, lr=4.89538e-05, gnorm=0.784, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27313
2023-01-06 22:26:35 - progress_bar.py[line:274] - INFO: epoch 001:   6978 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1524, wps=100.1, ups=0.46, wpb=108.5, bsz=40, num_updates=6970, lr=4.89493e-05, gnorm=0.565, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=27335
2023-01-06 22:26:57 - progress_bar.py[line:274] - INFO: epoch 001:   6988 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1449, wps=101.9, ups=0.47, wpb=108.8, bsz=40, num_updates=6980, lr=4.89448e-05, gnorm=0.522, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27357
2023-01-06 22:27:19 - progress_bar.py[line:274] - INFO: epoch 001:   6998 / 115845 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1297, wps=100.9, ups=0.46, wpb=109.5, bsz=40, num_updates=6990, lr=4.89403e-05, gnorm=0.459, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27379
2023-01-06 22:27:41 - progress_bar.py[line:274] - INFO: epoch 001:   7008 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1594, wps=99, ups=0.46, wpb=108.5, bsz=40, num_updates=7000, lr=4.89358e-05, gnorm=0.58, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=27401
2023-01-06 22:28:03 - progress_bar.py[line:274] - INFO: epoch 001:   7018 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1224, wps=101.2, ups=0.47, wpb=108.7, bsz=40, num_updates=7010, lr=4.89313e-05, gnorm=0.571, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27423
2023-01-06 22:28:25 - progress_bar.py[line:274] - INFO: epoch 001:   7028 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1319, wps=103.4, ups=0.47, wpb=109.8, bsz=40, num_updates=7020, lr=4.89268e-05, gnorm=0.517, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27445
2023-01-06 22:28:46 - progress_bar.py[line:274] - INFO: epoch 001:   7038 / 115845 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1765, wps=102.9, ups=0.47, wpb=109.8, bsz=40, num_updates=7030, lr=4.89223e-05, gnorm=0.56, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27466
2023-01-06 22:29:08 - progress_bar.py[line:274] - INFO: epoch 001:   7048 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1397, wps=102.4, ups=0.47, wpb=109.3, bsz=40, num_updates=7040, lr=4.89178e-05, gnorm=0.66, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27488
2023-01-06 22:29:30 - progress_bar.py[line:274] - INFO: epoch 001:   7058 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1554, wps=102.3, ups=0.46, wpb=110, bsz=40, num_updates=7050, lr=4.89133e-05, gnorm=0.613, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27510
2023-01-06 22:29:51 - progress_bar.py[line:274] - INFO: epoch 001:   7068 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.163, wps=105.3, ups=0.48, wpb=110.2, bsz=40, num_updates=7060, lr=4.89088e-05, gnorm=0.6, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27531
2023-01-06 22:30:14 - progress_bar.py[line:274] - INFO: epoch 001:   7078 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1641, wps=101.2, ups=0.46, wpb=110, bsz=40, num_updates=7070, lr=4.89043e-05, gnorm=0.52, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27553
2023-01-06 22:30:35 - progress_bar.py[line:274] - INFO: epoch 001:   7088 / 115845 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1618, wps=100.8, ups=0.46, wpb=108.4, bsz=40, num_updates=7080, lr=4.88998e-05, gnorm=0.745, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27576
2023-01-06 22:30:58 - progress_bar.py[line:274] - INFO: epoch 001:   7098 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.125, wps=99.2, ups=0.46, wpb=107.5, bsz=40, num_updates=7090, lr=4.88954e-05, gnorm=0.758, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=27597
2023-01-06 22:31:19 - progress_bar.py[line:274] - INFO: epoch 001:   7108 / 115845 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.19, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=7100, lr=4.88909e-05, gnorm=0.574, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27619
2023-01-06 22:31:41 - progress_bar.py[line:274] - INFO: epoch 001:   7118 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1789, wps=103.2, ups=0.47, wpb=110, bsz=40, num_updates=7110, lr=4.88864e-05, gnorm=0.493, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27641
2023-01-06 22:31:53 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-06 22:32:04 - progress_bar.py[line:274] - INFO: epoch 001:   7129 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.762, nsentences=40, sample_size=107.762, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.15, wps=97.1, ups=0.43, wpb=107.8, bsz=40, num_updates=7120, lr=4.88819e-05, gnorm=0.752, clip=10, loss_scale=256, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=27665
2023-01-06 22:32:26 - progress_bar.py[line:274] - INFO: epoch 001:   7139 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1353, wps=102.9, ups=0.48, wpb=107.6, bsz=40, num_updates=7130, lr=4.88774e-05, gnorm=0.448, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27686
2023-01-06 22:32:47 - progress_bar.py[line:274] - INFO: epoch 001:   7149 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1859, wps=101.4, ups=0.47, wpb=108.7, bsz=40, num_updates=7140, lr=4.88729e-05, gnorm=0.696, clip=10, loss_scale=256, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=27707
2023-01-06 22:33:09 - progress_bar.py[line:274] - INFO: epoch 001:   7159 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1925, wps=102.2, ups=0.46, wpb=110.8, bsz=40, num_updates=7150, lr=4.88684e-05, gnorm=0.581, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27729
2023-01-06 22:33:31 - progress_bar.py[line:274] - INFO: epoch 001:   7169 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.164, wps=101, ups=0.46, wpb=109.7, bsz=40, num_updates=7160, lr=4.88639e-05, gnorm=0.664, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27751
2023-01-06 22:33:53 - progress_bar.py[line:274] - INFO: epoch 001:   7179 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1746, wps=102.6, ups=0.46, wpb=110.4, bsz=40, num_updates=7170, lr=4.88594e-05, gnorm=0.607, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27773
2023-01-06 22:34:15 - progress_bar.py[line:274] - INFO: epoch 001:   7189 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1472, wps=100.2, ups=0.46, wpb=109.5, bsz=40, num_updates=7180, lr=4.88549e-05, gnorm=0.569, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27795
2023-01-06 22:34:36 - progress_bar.py[line:274] - INFO: epoch 001:   7199 / 115845 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1979, wps=104.4, ups=0.48, wpb=109.2, bsz=40, num_updates=7190, lr=4.88504e-05, gnorm=0.606, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27816
2023-01-06 22:34:58 - progress_bar.py[line:274] - INFO: epoch 001:   7209 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1658, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=7200, lr=4.88459e-05, gnorm=0.663, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27838
2023-01-06 22:35:20 - progress_bar.py[line:274] - INFO: epoch 001:   7219 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1735, wps=99.7, ups=0.46, wpb=108.5, bsz=40, num_updates=7210, lr=4.88414e-05, gnorm=0.664, clip=20, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27860
2023-01-06 22:35:41 - progress_bar.py[line:274] - INFO: epoch 001:   7229 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1755, wps=105, ups=0.48, wpb=110.5, bsz=40, num_updates=7220, lr=4.88369e-05, gnorm=0.609, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=27881
2023-01-06 22:36:03 - progress_bar.py[line:274] - INFO: epoch 001:   7239 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1556, wps=101.8, ups=0.46, wpb=109.7, bsz=40, num_updates=7230, lr=4.88324e-05, gnorm=0.483, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27903
2023-01-06 22:36:24 - progress_bar.py[line:274] - INFO: epoch 001:   7249 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1932, wps=104.5, ups=0.48, wpb=108.3, bsz=40, num_updates=7240, lr=4.88279e-05, gnorm=0.563, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=27924
2023-01-06 22:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   7259 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1707, wps=100.7, ups=0.47, wpb=107.3, bsz=40, num_updates=7250, lr=4.88234e-05, gnorm=0.521, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=27946
2023-01-06 22:37:07 - progress_bar.py[line:274] - INFO: epoch 001:   7269 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2277, wps=99.2, ups=0.46, wpb=108.9, bsz=40, num_updates=7260, lr=4.88189e-05, gnorm=0.802, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27968
2023-01-06 22:37:29 - progress_bar.py[line:274] - INFO: epoch 001:   7279 / 115845 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1959, wps=101.5, ups=0.46, wpb=109.3, bsz=40, num_updates=7270, lr=4.88144e-05, gnorm=0.623, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27989
2023-01-06 22:37:51 - progress_bar.py[line:274] - INFO: epoch 001:   7289 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2069, wps=101.2, ups=0.46, wpb=110.2, bsz=40, num_updates=7280, lr=4.88099e-05, gnorm=0.745, clip=30, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28011
2023-01-06 22:38:13 - progress_bar.py[line:274] - INFO: epoch 001:   7299 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.201, wps=101.5, ups=0.47, wpb=109.1, bsz=40, num_updates=7290, lr=4.88054e-05, gnorm=0.609, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=28033
2023-01-06 22:38:35 - progress_bar.py[line:274] - INFO: epoch 001:   7309 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1717, wps=99.7, ups=0.46, wpb=109.5, bsz=40, num_updates=7300, lr=4.88009e-05, gnorm=0.501, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28055
2023-01-06 22:38:57 - progress_bar.py[line:274] - INFO: epoch 001:   7319 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1475, wps=100.2, ups=0.46, wpb=109.6, bsz=40, num_updates=7310, lr=4.87964e-05, gnorm=0.502, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28077
2023-01-06 22:39:19 - progress_bar.py[line:274] - INFO: epoch 001:   7329 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1912, wps=101, ups=0.46, wpb=109, bsz=40, num_updates=7320, lr=4.87919e-05, gnorm=0.749, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28099
2023-01-06 22:39:41 - progress_bar.py[line:274] - INFO: epoch 001:   7339 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2322, wps=99, ups=0.46, wpb=107.5, bsz=40, num_updates=7330, lr=4.87875e-05, gnorm=0.682, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28121
2023-01-06 22:40:03 - progress_bar.py[line:274] - INFO: epoch 001:   7349 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.195, wps=100.9, ups=0.47, wpb=108.4, bsz=40, num_updates=7340, lr=4.8783e-05, gnorm=1.033, clip=20, loss_scale=256, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=28143
2023-01-06 22:40:24 - progress_bar.py[line:274] - INFO: epoch 001:   7359 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2362, wps=103.9, ups=0.48, wpb=109.1, bsz=40, num_updates=7350, lr=4.87785e-05, gnorm=0.519, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=28164
2023-01-06 22:40:46 - progress_bar.py[line:274] - INFO: epoch 001:   7369 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1951, wps=100.2, ups=0.46, wpb=108.7, bsz=40, num_updates=7360, lr=4.8774e-05, gnorm=0.432, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28186
2023-01-06 22:41:07 - progress_bar.py[line:274] - INFO: epoch 001:   7379 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2448, wps=105.5, ups=0.48, wpb=109.7, bsz=40, num_updates=7370, lr=4.87695e-05, gnorm=0.454, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28207
2023-01-06 22:41:28 - progress_bar.py[line:274] - INFO: epoch 001:   7389 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.199, wps=103.9, ups=0.47, wpb=110.1, bsz=40, num_updates=7380, lr=4.8765e-05, gnorm=0.723, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=28229
2023-01-06 22:41:50 - progress_bar.py[line:274] - INFO: epoch 001:   7399 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.229, wps=102.8, ups=0.48, wpb=107.9, bsz=40, num_updates=7390, lr=4.87605e-05, gnorm=0.719, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=28250
2023-01-06 22:42:11 - progress_bar.py[line:274] - INFO: epoch 001:   7409 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1606, wps=102.6, ups=0.47, wpb=109.5, bsz=40, num_updates=7400, lr=4.8756e-05, gnorm=0.531, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28271
2023-01-06 22:42:33 - progress_bar.py[line:274] - INFO: epoch 001:   7419 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2338, wps=101.7, ups=0.47, wpb=109.3, bsz=40, num_updates=7410, lr=4.87515e-05, gnorm=0.517, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28293
2023-01-06 22:42:55 - progress_bar.py[line:274] - INFO: epoch 001:   7429 / 115845 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1842, wps=101.4, ups=0.46, wpb=109.3, bsz=40, num_updates=7420, lr=4.8747e-05, gnorm=0.726, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28315
2023-01-06 22:43:17 - progress_bar.py[line:274] - INFO: epoch 001:   7439 / 115845 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1602, wps=100.7, ups=0.47, wpb=107.9, bsz=40, num_updates=7430, lr=4.87425e-05, gnorm=0.579, clip=10, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=28337
2023-01-06 22:43:38 - progress_bar.py[line:274] - INFO: epoch 001:   7449 / 115845 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.201, wps=101.4, ups=0.47, wpb=109, bsz=40, num_updates=7440, lr=4.8738e-05, gnorm=0.565, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28359
2023-01-06 22:44:00 - progress_bar.py[line:274] - INFO: epoch 001:   7459 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1957, wps=104.5, ups=0.47, wpb=111.7, bsz=40, num_updates=7450, lr=4.87335e-05, gnorm=0.471, clip=0, loss_scale=256, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=28380
2023-01-06 22:44:22 - progress_bar.py[line:274] - INFO: epoch 001:   7469 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1768, wps=101.5, ups=0.46, wpb=110.3, bsz=40, num_updates=7460, lr=4.8729e-05, gnorm=0.507, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=28402
2023-01-06 22:44:43 - progress_bar.py[line:274] - INFO: epoch 001:   7479 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2, wps=102.4, ups=0.47, wpb=108.1, bsz=40, num_updates=7470, lr=4.87245e-05, gnorm=0.649, clip=10, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=28424
2023-01-06 22:45:05 - progress_bar.py[line:274] - INFO: epoch 001:   7489 / 115845 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.233, wps=102.2, ups=0.47, wpb=109.1, bsz=40, num_updates=7480, lr=4.872e-05, gnorm=0.658, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28445
2023-01-06 22:45:26 - progress_bar.py[line:274] - INFO: epoch 001:   7499 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1932, wps=102.4, ups=0.47, wpb=109, bsz=40, num_updates=7490, lr=4.87155e-05, gnorm=0.578, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28467
2023-01-06 22:45:49 - progress_bar.py[line:274] - INFO: epoch 001:   7509 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.165, wps=100.4, ups=0.46, wpb=110.1, bsz=40, num_updates=7500, lr=4.8711e-05, gnorm=0.569, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28489
2023-01-06 22:46:10 - progress_bar.py[line:274] - INFO: epoch 001:   7519 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1902, wps=101.4, ups=0.47, wpb=108.7, bsz=40, num_updates=7510, lr=4.87065e-05, gnorm=0.505, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28510
2023-01-06 22:46:33 - progress_bar.py[line:274] - INFO: epoch 001:   7529 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2289, wps=101.6, ups=0.47, wpb=109, bsz=40, num_updates=7520, lr=4.8702e-05, gnorm=0.551, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=28532
2023-01-06 22:46:55 - progress_bar.py[line:274] - INFO: epoch 001:   7539 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2174, wps=100.1, ups=0.46, wpb=108.9, bsz=40, num_updates=7530, lr=4.86975e-05, gnorm=0.653, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=28555
2023-01-06 22:47:17 - progress_bar.py[line:274] - INFO: epoch 001:   7549 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1915, wps=102.9, ups=0.46, wpb=110.8, bsz=40, num_updates=7540, lr=4.8693e-05, gnorm=0.556, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=28577
2023-01-06 22:47:38 - progress_bar.py[line:274] - INFO: epoch 001:   7559 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1683, wps=101.2, ups=0.47, wpb=108.2, bsz=40, num_updates=7550, lr=4.86885e-05, gnorm=0.608, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=28599
2023-01-06 22:48:00 - progress_bar.py[line:274] - INFO: epoch 001:   7569 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2273, wps=102.5, ups=0.47, wpb=109.2, bsz=40, num_updates=7560, lr=4.8684e-05, gnorm=0.539, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28620
2023-01-06 22:48:22 - progress_bar.py[line:274] - INFO: epoch 001:   7579 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1852, wps=100.4, ups=0.46, wpb=109.2, bsz=40, num_updates=7570, lr=4.86795e-05, gnorm=0.603, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28642
2023-01-06 22:48:43 - progress_bar.py[line:274] - INFO: epoch 001:   7589 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2136, wps=104.3, ups=0.48, wpb=107.9, bsz=40, num_updates=7580, lr=4.86751e-05, gnorm=0.569, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28663
2023-01-06 22:49:05 - progress_bar.py[line:274] - INFO: epoch 001:   7599 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2487, wps=102.3, ups=0.46, wpb=110.7, bsz=40, num_updates=7590, lr=4.86706e-05, gnorm=0.658, clip=20, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28685
2023-01-06 22:49:27 - progress_bar.py[line:274] - INFO: epoch 001:   7609 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2244, wps=99, ups=0.46, wpb=108.5, bsz=40, num_updates=7600, lr=4.86661e-05, gnorm=0.505, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=28707
2023-01-06 22:49:48 - progress_bar.py[line:274] - INFO: epoch 001:   7619 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2488, wps=103.7, ups=0.48, wpb=108.1, bsz=40, num_updates=7610, lr=4.86616e-05, gnorm=0.568, clip=0, loss_scale=256, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=28728
2023-01-06 22:50:09 - progress_bar.py[line:274] - INFO: epoch 001:   7629 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.198, wps=104.4, ups=0.48, wpb=109.8, bsz=40, num_updates=7620, lr=4.86571e-05, gnorm=0.644, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=28750
2023-01-06 22:50:31 - progress_bar.py[line:274] - INFO: epoch 001:   7639 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2315, wps=101.7, ups=0.47, wpb=109.1, bsz=40, num_updates=7630, lr=4.86526e-05, gnorm=0.508, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=28771
2023-01-06 22:50:55 - progress_bar.py[line:274] - INFO: epoch 001:   7649 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1667, wps=89.8, ups=0.41, wpb=108.8, bsz=40, num_updates=7640, lr=4.86481e-05, gnorm=0.613, clip=0, loss_scale=512, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=28796
2023-01-06 22:51:17 - progress_bar.py[line:274] - INFO: epoch 001:   7659 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1616, wps=103.1, ups=0.47, wpb=109.4, bsz=40, num_updates=7650, lr=4.86436e-05, gnorm=0.602, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28817
2023-01-06 22:51:39 - progress_bar.py[line:274] - INFO: epoch 001:   7669 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2174, wps=100.6, ups=0.46, wpb=108.7, bsz=40, num_updates=7660, lr=4.86391e-05, gnorm=0.579, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28839
2023-01-06 22:52:00 - progress_bar.py[line:274] - INFO: epoch 001:   7679 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1707, wps=102.4, ups=0.47, wpb=108.7, bsz=40, num_updates=7670, lr=4.86346e-05, gnorm=0.677, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28860
2023-01-06 22:52:22 - progress_bar.py[line:274] - INFO: epoch 001:   7689 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.1832, wps=101.9, ups=0.46, wpb=109.9, bsz=40, num_updates=7680, lr=4.86301e-05, gnorm=0.519, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=28882
2023-01-06 22:52:43 - progress_bar.py[line:274] - INFO: epoch 001:   7699 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.229, wps=102.5, ups=0.47, wpb=108.4, bsz=40, num_updates=7690, lr=4.86256e-05, gnorm=0.494, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28904
2023-01-06 22:53:05 - progress_bar.py[line:274] - INFO: epoch 001:   7709 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2, wps=100.9, ups=0.47, wpb=108.4, bsz=40, num_updates=7700, lr=4.86211e-05, gnorm=0.5, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28925
2023-01-06 22:53:27 - progress_bar.py[line:274] - INFO: epoch 001:   7719 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.23, wps=99.8, ups=0.46, wpb=109.2, bsz=40, num_updates=7710, lr=4.86166e-05, gnorm=0.564, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28947
2023-01-06 22:53:49 - progress_bar.py[line:274] - INFO: epoch 001:   7729 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2201, wps=99.2, ups=0.46, wpb=107.9, bsz=40, num_updates=7720, lr=4.86121e-05, gnorm=0.534, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28969
2023-01-06 22:54:11 - progress_bar.py[line:274] - INFO: epoch 001:   7739 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2255, wps=100.3, ups=0.46, wpb=109, bsz=40, num_updates=7730, lr=4.86076e-05, gnorm=0.778, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28991
2023-01-06 22:54:33 - progress_bar.py[line:274] - INFO: epoch 001:   7749 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2374, wps=102.2, ups=0.47, wpb=108.6, bsz=40, num_updates=7740, lr=4.86031e-05, gnorm=0.639, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29013
2023-01-06 22:54:55 - progress_bar.py[line:274] - INFO: epoch 001:   7759 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1981, wps=99.3, ups=0.46, wpb=108.7, bsz=40, num_updates=7750, lr=4.85986e-05, gnorm=0.593, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29035
2023-01-06 22:55:16 - progress_bar.py[line:274] - INFO: epoch 001:   7769 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1919, wps=103.3, ups=0.47, wpb=108.9, bsz=40, num_updates=7760, lr=4.85941e-05, gnorm=0.608, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29056
2023-01-06 22:55:38 - progress_bar.py[line:274] - INFO: epoch 001:   7779 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1551, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=7770, lr=4.85896e-05, gnorm=0.481, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29078
2023-01-06 22:56:00 - progress_bar.py[line:274] - INFO: epoch 001:   7789 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.25, wps=100.6, ups=0.46, wpb=108.7, bsz=40, num_updates=7780, lr=4.85851e-05, gnorm=0.616, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29100
2023-01-06 22:56:22 - progress_bar.py[line:274] - INFO: epoch 001:   7799 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.199, wps=98.6, ups=0.45, wpb=108.4, bsz=40, num_updates=7790, lr=4.85806e-05, gnorm=0.458, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29123
2023-01-06 22:56:44 - progress_bar.py[line:274] - INFO: epoch 001:   7809 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.1737, wps=102.7, ups=0.47, wpb=108.3, bsz=40, num_updates=7800, lr=4.85761e-05, gnorm=0.442, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29144
2023-01-06 22:57:05 - progress_bar.py[line:274] - INFO: epoch 001:   7819 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2103, wps=103.6, ups=0.47, wpb=109.5, bsz=40, num_updates=7810, lr=4.85716e-05, gnorm=0.447, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29165
2023-01-06 22:57:27 - progress_bar.py[line:274] - INFO: epoch 001:   7829 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2871, wps=102.2, ups=0.46, wpb=110.1, bsz=40, num_updates=7820, lr=4.85672e-05, gnorm=0.506, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29187
2023-01-06 22:57:48 - progress_bar.py[line:274] - INFO: epoch 001:   7839 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2718, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=7830, lr=4.85627e-05, gnorm=0.733, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29209
2023-01-06 22:58:11 - progress_bar.py[line:274] - INFO: epoch 001:   7849 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.209, wps=97.6, ups=0.45, wpb=108.3, bsz=40, num_updates=7840, lr=4.85582e-05, gnorm=0.45, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29231
2023-01-06 22:58:33 - progress_bar.py[line:274] - INFO: epoch 001:   7859 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3032, wps=100.3, ups=0.46, wpb=109.5, bsz=40, num_updates=7850, lr=4.85537e-05, gnorm=0.736, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29253
2023-01-06 22:58:54 - progress_bar.py[line:274] - INFO: epoch 001:   7869 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1981, wps=102.5, ups=0.48, wpb=107.6, bsz=40, num_updates=7860, lr=4.85492e-05, gnorm=0.77, clip=30, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=29274
2023-01-06 22:59:16 - progress_bar.py[line:274] - INFO: epoch 001:   7879 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2551, wps=100.5, ups=0.46, wpb=108.1, bsz=40, num_updates=7870, lr=4.85447e-05, gnorm=0.449, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29296
2023-01-06 22:59:38 - progress_bar.py[line:274] - INFO: epoch 001:   7889 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2286, wps=97.9, ups=0.46, wpb=107.5, bsz=40, num_updates=7880, lr=4.85402e-05, gnorm=0.61, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29318
2023-01-06 23:00:00 - progress_bar.py[line:274] - INFO: epoch 001:   7899 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.215, wps=99.5, ups=0.46, wpb=107.9, bsz=40, num_updates=7890, lr=4.85357e-05, gnorm=0.649, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=29340
2023-01-06 23:00:22 - progress_bar.py[line:274] - INFO: epoch 001:   7909 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1689, wps=99.4, ups=0.46, wpb=107.2, bsz=40, num_updates=7900, lr=4.85312e-05, gnorm=0.616, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=29362
2023-01-06 23:00:44 - progress_bar.py[line:274] - INFO: epoch 001:   7919 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1828, wps=105.4, ups=0.47, wpb=111.1, bsz=40, num_updates=7910, lr=4.85267e-05, gnorm=0.565, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29384
2023-01-06 23:01:06 - progress_bar.py[line:274] - INFO: epoch 001:   7929 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2251, wps=100.9, ups=0.46, wpb=110.2, bsz=40, num_updates=7920, lr=4.85222e-05, gnorm=0.673, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=29406
2023-01-06 23:01:27 - progress_bar.py[line:274] - INFO: epoch 001:   7939 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2473, wps=103.9, ups=0.47, wpb=110, bsz=40, num_updates=7930, lr=4.85177e-05, gnorm=0.471, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=29427
2023-01-06 23:01:49 - progress_bar.py[line:274] - INFO: epoch 001:   7949 / 115845 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2057, wps=101, ups=0.47, wpb=108.5, bsz=40, num_updates=7940, lr=4.85132e-05, gnorm=0.51, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29449
2023-01-06 23:02:10 - progress_bar.py[line:274] - INFO: epoch 001:   7959 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2798, wps=102, ups=0.47, wpb=109.6, bsz=40, num_updates=7950, lr=4.85087e-05, gnorm=0.823, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29471
2023-01-06 23:02:32 - progress_bar.py[line:274] - INFO: epoch 001:   7969 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2365, wps=103.4, ups=0.48, wpb=108.8, bsz=40, num_updates=7960, lr=4.85042e-05, gnorm=0.681, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=29492
2023-01-06 23:02:53 - progress_bar.py[line:274] - INFO: epoch 001:   7979 / 115845 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2194, wps=102.3, ups=0.46, wpb=110.2, bsz=40, num_updates=7970, lr=4.84997e-05, gnorm=0.546, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29514
2023-01-06 23:03:15 - progress_bar.py[line:274] - INFO: epoch 001:   7989 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2186, wps=102.2, ups=0.46, wpb=109.9, bsz=40, num_updates=7980, lr=4.84952e-05, gnorm=0.486, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29535
2023-01-06 23:03:37 - progress_bar.py[line:274] - INFO: epoch 001:   7999 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2714, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=7990, lr=4.84907e-05, gnorm=0.443, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29557
2023-01-06 23:03:59 - progress_bar.py[line:274] - INFO: epoch 001:   8009 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.22, wps=99.9, ups=0.46, wpb=108.9, bsz=40, num_updates=8000, lr=4.84862e-05, gnorm=0.534, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29579
2023-01-06 23:03:59 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-06 23:04:00 - train.py[line:549] - INFO: 0 / 4988
2023-01-06 23:04:00 - train.py[line:551] - INFO: load:1.04 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-06 23:06:31 - train.py[line:549] - INFO: 200 / 4988
2023-01-06 23:06:31 - train.py[line:551] - INFO: load:1.06 valid_run:150.89 task_valid:146.30 collect_output:3.49
2023-01-06 23:08:59 - train.py[line:549] - INFO: 400 / 4988
2023-01-06 23:08:59 - train.py[line:551] - INFO: load:1.09 valid_run:298.71 task_valid:287.58 collect_output:9.00
2023-01-06 23:11:31 - train.py[line:549] - INFO: 600 / 4988
2023-01-06 23:11:31 - train.py[line:551] - INFO: load:1.11 valid_run:450.69 task_valid:429.01 collect_output:18.50
2023-01-06 23:14:00 - train.py[line:549] - INFO: 800 / 4988
2023-01-06 23:14:00 - train.py[line:551] - INFO: load:1.14 valid_run:599.20 task_valid:572.60 collect_output:22.38
2023-01-06 23:16:32 - train.py[line:549] - INFO: 1000 / 4988
2023-01-06 23:16:32 - train.py[line:551] - INFO: load:1.16 valid_run:751.09 task_valid:718.55 collect_output:27.27
2023-01-06 23:19:03 - train.py[line:549] - INFO: 1200 / 4988
2023-01-06 23:19:03 - train.py[line:551] - INFO: load:1.19 valid_run:902.41 task_valid:862.55 collect_output:33.48
2023-01-06 23:21:37 - train.py[line:549] - INFO: 1400 / 4988
2023-01-06 23:21:37 - train.py[line:551] - INFO: load:1.22 valid_run:1055.75 task_valid:1007.05 collect_output:41.24
2023-01-06 23:24:08 - train.py[line:549] - INFO: 1600 / 4988
2023-01-06 23:24:08 - train.py[line:551] - INFO: load:1.24 valid_run:1207.20 task_valid:1146.83 collect_output:51.86
2023-01-06 23:26:38 - train.py[line:549] - INFO: 1800 / 4988
2023-01-06 23:26:38 - train.py[line:551] - INFO: load:1.27 valid_run:1356.48 task_valid:1289.92 collect_output:56.97
2023-01-06 23:29:06 - train.py[line:549] - INFO: 2000 / 4988
2023-01-06 23:29:06 - train.py[line:551] - INFO: load:1.30 valid_run:1504.48 task_valid:1431.50 collect_output:62.36
2023-01-06 23:31:35 - train.py[line:549] - INFO: 2200 / 4988
2023-01-06 23:31:35 - train.py[line:551] - INFO: load:1.32 valid_run:1653.49 task_valid:1574.82 collect_output:66.99
2023-01-06 23:34:05 - train.py[line:549] - INFO: 2400 / 4988
2023-01-06 23:34:05 - train.py[line:551] - INFO: load:1.35 valid_run:1803.28 task_valid:1718.39 collect_output:72.12
2023-01-06 23:36:35 - train.py[line:549] - INFO: 2600 / 4988
2023-01-06 23:36:35 - train.py[line:551] - INFO: load:1.38 valid_run:1953.50 task_valid:1858.79 collect_output:80.83
2023-01-06 23:39:05 - train.py[line:549] - INFO: 2800 / 4988
2023-01-06 23:39:05 - train.py[line:551] - INFO: load:1.40 valid_run:2103.37 task_valid:2002.67 collect_output:85.74
2023-01-06 23:41:34 - train.py[line:549] - INFO: 3000 / 4988
2023-01-06 23:41:35 - train.py[line:551] - INFO: load:1.43 valid_run:2252.64 task_valid:2147.69 collect_output:88.92
2023-01-06 23:44:04 - train.py[line:549] - INFO: 3200 / 4988
2023-01-06 23:44:04 - train.py[line:551] - INFO: load:1.46 valid_run:2402.35 task_valid:2290.52 collect_output:94.69
2023-01-06 23:46:36 - train.py[line:549] - INFO: 3400 / 4988
2023-01-06 23:46:36 - train.py[line:551] - INFO: load:1.48 valid_run:2554.12 task_valid:2434.67 collect_output:101.21
2023-01-06 23:49:06 - train.py[line:549] - INFO: 3600 / 4988
2023-01-06 23:49:06 - train.py[line:551] - INFO: load:1.51 valid_run:2703.98 task_valid:2580.21 collect_output:104.47
2023-01-06 23:51:34 - train.py[line:549] - INFO: 3800 / 4988
2023-01-06 23:51:34 - train.py[line:551] - INFO: load:1.54 valid_run:2852.21 task_valid:2720.18 collect_output:111.68
2023-01-06 23:54:05 - train.py[line:549] - INFO: 4000 / 4988
2023-01-06 23:54:05 - train.py[line:551] - INFO: load:1.56 valid_run:3002.35 task_valid:2863.92 collect_output:117.02
2023-01-06 23:56:37 - train.py[line:549] - INFO: 4200 / 4988
2023-01-06 23:56:37 - train.py[line:551] - INFO: load:1.59 valid_run:3154.34 task_valid:3007.02 collect_output:124.83
2023-01-06 23:59:06 - train.py[line:549] - INFO: 4400 / 4988
2023-01-06 23:59:06 - train.py[line:551] - INFO: load:1.62 valid_run:3303.15 task_valid:3150.20 collect_output:129.37
2023-01-07 00:01:36 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 00:01:36 - train.py[line:551] - INFO: load:1.65 valid_run:3453.86 task_valid:3294.89 collect_output:134.32
2023-01-07 00:04:10 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 00:04:10 - train.py[line:551] - INFO: load:1.68 valid_run:3607.20 task_valid:3441.89 collect_output:139.48

====================================================================================================
SGG eval:     R @ 50: 0.5563;     R @ 100: 0.6160;     R @ 500: 0.6614;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3453;    mR @ 100: 0.4026;    mR @ 500: 0.4959;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4516) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9232) (says:0.0000) (sitting on:0.7080) (standing on:0.2083) (using:0.6000) (walking in:0.0000) (walking on:0.8108) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5563;     R @ 100: 0.6160;     R @ 500: 0.6614;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3453;    mR @ 100: 0.4026;    mR @ 500: 0.4959;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4516) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9232) (says:0.0000) (sitting on:0.7080) (standing on:0.2083) (using:0.6000) (walking in:0.0000) (walking on:0.8108) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================
2023-01-07 00:06:40 - train.py[line:487] - INFO: 0.615978151260504

2023-01-07 00:06:40 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-07 00:06:41 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.343 | loss_v1 0 | loss_v2 0 | nll_loss 0.186 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.615978 | ppl 1.14 | vqa_score 0.5225 | wps 119.3 | wpb 89.9 | bsz 30 | num_updates 8000 | best_R@100 0.637221
2023-01-07 00:06:41 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2023-01-07 00:06:41 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_8000.pt
2023-01-07 00:07:18 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_8000.pt
2023-01-07 00:08:47 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.615978151260504) (writing took 126.68710165843368 seconds)
2023-01-07 00:09:09 - progress_bar.py[line:274] - INFO: epoch 001:   8019 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2356, wps=0.6, ups=0, wpb=109.4, bsz=40, num_updates=8010, lr=4.84817e-05, gnorm=0.653, clip=10, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=33489
2023-01-07 00:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   8029 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.255, wps=105.3, ups=0.48, wpb=110.2, bsz=40, num_updates=8020, lr=4.84772e-05, gnorm=0.476, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=33511
2023-01-07 00:09:52 - progress_bar.py[line:274] - INFO: epoch 001:   8039 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2157, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=8030, lr=4.84727e-05, gnorm=0.853, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=33533
2023-01-07 00:10:14 - progress_bar.py[line:274] - INFO: epoch 001:   8049 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2611, wps=102.5, ups=0.47, wpb=109.2, bsz=40, num_updates=8040, lr=4.84682e-05, gnorm=0.563, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33554
2023-01-07 00:10:35 - progress_bar.py[line:274] - INFO: epoch 001:   8059 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2917, wps=103.6, ups=0.47, wpb=109.5, bsz=40, num_updates=8050, lr=4.84637e-05, gnorm=0.475, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33576
2023-01-07 00:10:57 - progress_bar.py[line:274] - INFO: epoch 001:   8069 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2487, wps=103.5, ups=0.47, wpb=109.7, bsz=40, num_updates=8060, lr=4.84592e-05, gnorm=0.482, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=33597
2023-01-07 00:11:18 - progress_bar.py[line:274] - INFO: epoch 001:   8079 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2435, wps=102.5, ups=0.47, wpb=109.2, bsz=40, num_updates=8070, lr=4.84548e-05, gnorm=0.615, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=33618
2023-01-07 00:11:40 - progress_bar.py[line:274] - INFO: epoch 001:   8089 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2692, wps=101.2, ups=0.47, wpb=108.7, bsz=40, num_updates=8080, lr=4.84503e-05, gnorm=0.406, clip=0, loss_scale=512, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=33640
2023-01-07 00:12:02 - progress_bar.py[line:274] - INFO: epoch 001:   8099 / 115845 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2277, wps=99.5, ups=0.46, wpb=107.5, bsz=40, num_updates=8090, lr=4.84458e-05, gnorm=0.516, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=33662
2023-01-07 00:12:23 - progress_bar.py[line:274] - INFO: epoch 001:   8109 / 115845 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2111, wps=104, ups=0.47, wpb=110, bsz=40, num_updates=8100, lr=4.84413e-05, gnorm=0.53, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=33683
2023-01-07 00:12:45 - progress_bar.py[line:274] - INFO: epoch 001:   8119 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.267, wps=100.9, ups=0.46, wpb=109.3, bsz=40, num_updates=8110, lr=4.84368e-05, gnorm=0.569, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=33705
2023-01-07 00:13:07 - progress_bar.py[line:274] - INFO: epoch 001:   8129 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1902, wps=102, ups=0.46, wpb=109.8, bsz=40, num_updates=8120, lr=4.84323e-05, gnorm=0.464, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=33727
2023-01-07 00:13:29 - progress_bar.py[line:274] - INFO: epoch 001:   8139 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.25, wps=101.7, ups=0.46, wpb=109.4, bsz=40, num_updates=8130, lr=4.84278e-05, gnorm=0.582, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=33749
2023-01-07 00:13:51 - progress_bar.py[line:274] - INFO: epoch 001:   8149 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2842, wps=99.5, ups=0.45, wpb=109.5, bsz=40, num_updates=8140, lr=4.84233e-05, gnorm=0.493, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=33771
2023-01-07 00:13:53 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 00:14:15 - progress_bar.py[line:274] - INFO: epoch 001:   8160 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.81, nsentences=40, sample_size=108.81, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3034, wps=96.9, ups=0.42, wpb=108.8, bsz=40, num_updates=8150, lr=4.84188e-05, gnorm=0.422, clip=0, loss_scale=512, train_wall=24, gb_free=10.4, ema_decay=0.9999, wall=33795
2023-01-07 00:14:36 - progress_bar.py[line:274] - INFO: epoch 001:   8170 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2296, wps=102.9, ups=0.47, wpb=109.7, bsz=40, num_updates=8160, lr=4.84143e-05, gnorm=0.728, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=33816
2023-01-07 00:14:57 - progress_bar.py[line:274] - INFO: epoch 001:   8180 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2951, wps=105.3, ups=0.47, wpb=111, bsz=40, num_updates=8170, lr=4.84098e-05, gnorm=0.583, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33838
2023-01-07 00:15:19 - progress_bar.py[line:274] - INFO: epoch 001:   8190 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.245, wps=101.3, ups=0.46, wpb=109.8, bsz=40, num_updates=8180, lr=4.84053e-05, gnorm=0.803, clip=20, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=33860
2023-01-07 00:15:41 - progress_bar.py[line:274] - INFO: epoch 001:   8200 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2714, wps=102.3, ups=0.47, wpb=109.7, bsz=40, num_updates=8190, lr=4.84008e-05, gnorm=0.478, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=33881
2023-01-07 00:16:03 - progress_bar.py[line:274] - INFO: epoch 001:   8210 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2727, wps=101.9, ups=0.47, wpb=108.5, bsz=40, num_updates=8200, lr=4.83963e-05, gnorm=0.525, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=33903
2023-01-07 00:16:24 - progress_bar.py[line:274] - INFO: epoch 001:   8220 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2487, wps=101.1, ups=0.46, wpb=108.8, bsz=40, num_updates=8210, lr=4.83918e-05, gnorm=0.499, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=33925
2023-01-07 00:16:46 - progress_bar.py[line:274] - INFO: epoch 001:   8230 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2512, wps=100, ups=0.46, wpb=109.1, bsz=40, num_updates=8220, lr=4.83873e-05, gnorm=0.535, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=33947
2023-01-07 00:17:08 - progress_bar.py[line:274] - INFO: epoch 001:   8240 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2598, wps=101.9, ups=0.47, wpb=108.5, bsz=40, num_updates=8230, lr=4.83828e-05, gnorm=0.55, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33968
2023-01-07 00:17:30 - progress_bar.py[line:274] - INFO: epoch 001:   8250 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2463, wps=100.3, ups=0.46, wpb=108.2, bsz=40, num_updates=8240, lr=4.83783e-05, gnorm=0.504, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=33990
2023-01-07 00:17:52 - progress_bar.py[line:274] - INFO: epoch 001:   8260 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3394, wps=99.9, ups=0.46, wpb=109.2, bsz=40, num_updates=8250, lr=4.83738e-05, gnorm=0.558, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34012
2023-01-07 00:18:14 - progress_bar.py[line:274] - INFO: epoch 001:   8270 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2537, wps=99.2, ups=0.46, wpb=108.2, bsz=40, num_updates=8260, lr=4.83693e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34034
2023-01-07 00:18:36 - progress_bar.py[line:274] - INFO: epoch 001:   8280 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2947, wps=101, ups=0.46, wpb=109, bsz=40, num_updates=8270, lr=4.83648e-05, gnorm=0.596, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=34056
2023-01-07 00:18:58 - progress_bar.py[line:274] - INFO: epoch 001:   8290 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2391, wps=100.9, ups=0.46, wpb=109.9, bsz=40, num_updates=8280, lr=4.83603e-05, gnorm=0.478, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34078
2023-01-07 00:19:20 - progress_bar.py[line:274] - INFO: epoch 001:   8300 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2207, wps=100, ups=0.46, wpb=108, bsz=40, num_updates=8290, lr=4.83558e-05, gnorm=0.413, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=34100
2023-01-07 00:19:42 - progress_bar.py[line:274] - INFO: epoch 001:   8310 / 115845 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3015, wps=98.7, ups=0.45, wpb=109.3, bsz=40, num_updates=8300, lr=4.83513e-05, gnorm=0.626, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=34122
2023-01-07 00:20:04 - progress_bar.py[line:274] - INFO: epoch 001:   8320 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2747, wps=102.7, ups=0.47, wpb=109.8, bsz=40, num_updates=8310, lr=4.83469e-05, gnorm=0.781, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34144
2023-01-07 00:20:25 - progress_bar.py[line:274] - INFO: epoch 001:   8330 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2899, wps=103.1, ups=0.48, wpb=108.1, bsz=40, num_updates=8320, lr=4.83424e-05, gnorm=0.476, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34165
2023-01-07 00:20:46 - progress_bar.py[line:274] - INFO: epoch 001:   8340 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2663, wps=102.3, ups=0.47, wpb=109.5, bsz=40, num_updates=8330, lr=4.83379e-05, gnorm=0.616, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34187
2023-01-07 00:21:08 - progress_bar.py[line:274] - INFO: epoch 001:   8350 / 115845 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2551, wps=101.6, ups=0.47, wpb=109.1, bsz=40, num_updates=8340, lr=4.83334e-05, gnorm=0.481, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34208
2023-01-07 00:21:30 - progress_bar.py[line:274] - INFO: epoch 001:   8360 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3058, wps=102.4, ups=0.47, wpb=109.5, bsz=40, num_updates=8350, lr=4.83289e-05, gnorm=0.404, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34230
2023-01-07 00:21:52 - progress_bar.py[line:274] - INFO: epoch 001:   8370 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2606, wps=100.7, ups=0.46, wpb=109.3, bsz=40, num_updates=8360, lr=4.83244e-05, gnorm=0.518, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=34252
2023-01-07 00:22:13 - progress_bar.py[line:274] - INFO: epoch 001:   8380 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2642, wps=101.3, ups=0.47, wpb=108.4, bsz=40, num_updates=8370, lr=4.83199e-05, gnorm=0.895, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34274
2023-01-07 00:22:36 - progress_bar.py[line:274] - INFO: epoch 001:   8390 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.25, wps=99.4, ups=0.46, wpb=108.7, bsz=40, num_updates=8380, lr=4.83154e-05, gnorm=0.429, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34296
2023-01-07 00:22:57 - progress_bar.py[line:274] - INFO: epoch 001:   8400 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2746, wps=101.9, ups=0.46, wpb=110, bsz=40, num_updates=8390, lr=4.83109e-05, gnorm=0.589, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34318
2023-01-07 00:23:19 - progress_bar.py[line:274] - INFO: epoch 001:   8410 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2412, wps=100, ups=0.46, wpb=109.1, bsz=40, num_updates=8400, lr=4.83064e-05, gnorm=0.612, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=34340
2023-01-07 00:23:41 - progress_bar.py[line:274] - INFO: epoch 001:   8420 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3, wps=101.5, ups=0.47, wpb=108, bsz=40, num_updates=8410, lr=4.83019e-05, gnorm=0.676, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34361
2023-01-07 00:24:03 - progress_bar.py[line:274] - INFO: epoch 001:   8430 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3155, wps=102, ups=0.47, wpb=109, bsz=40, num_updates=8420, lr=4.82974e-05, gnorm=0.659, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34383
2023-01-07 00:24:24 - progress_bar.py[line:274] - INFO: epoch 001:   8440 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2429, wps=102.9, ups=0.47, wpb=108.8, bsz=40, num_updates=8430, lr=4.82929e-05, gnorm=0.546, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34404
2023-01-07 00:24:45 - progress_bar.py[line:274] - INFO: epoch 001:   8450 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2513, wps=105.4, ups=0.48, wpb=110.7, bsz=40, num_updates=8440, lr=4.82884e-05, gnorm=0.503, clip=0, loss_scale=512, train_wall=21, gb_free=10.9, ema_decay=0.9999, wall=34425
2023-01-07 00:25:07 - progress_bar.py[line:274] - INFO: epoch 001:   8460 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2602, wps=103.4, ups=0.47, wpb=110, bsz=40, num_updates=8450, lr=4.82839e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34447
2023-01-07 00:25:28 - progress_bar.py[line:274] - INFO: epoch 001:   8470 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2751, wps=102.5, ups=0.47, wpb=108.9, bsz=40, num_updates=8460, lr=4.82794e-05, gnorm=0.452, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34468
2023-01-07 00:25:49 - progress_bar.py[line:274] - INFO: epoch 001:   8480 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2602, wps=103.4, ups=0.48, wpb=108.6, bsz=40, num_updates=8470, lr=4.82749e-05, gnorm=0.548, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34490
2023-01-07 00:26:11 - progress_bar.py[line:274] - INFO: epoch 001:   8490 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.25, wps=98.9, ups=0.46, wpb=107.6, bsz=40, num_updates=8480, lr=4.82704e-05, gnorm=0.554, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=34512
2023-01-07 00:26:33 - progress_bar.py[line:274] - INFO: epoch 001:   8500 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3212, wps=104.3, ups=0.47, wpb=110.1, bsz=40, num_updates=8490, lr=4.82659e-05, gnorm=0.554, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34533
2023-01-07 00:26:54 - progress_bar.py[line:274] - INFO: epoch 001:   8510 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.301, wps=102.5, ups=0.47, wpb=109, bsz=40, num_updates=8500, lr=4.82614e-05, gnorm=0.6, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34554
2023-01-07 00:27:16 - progress_bar.py[line:274] - INFO: epoch 001:   8520 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2732, wps=101.3, ups=0.46, wpb=110.2, bsz=40, num_updates=8510, lr=4.82569e-05, gnorm=0.644, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=34576
2023-01-07 00:27:38 - progress_bar.py[line:274] - INFO: epoch 001:   8530 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.25, wps=100.6, ups=0.46, wpb=108.5, bsz=40, num_updates=8520, lr=4.82524e-05, gnorm=0.508, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=34598
2023-01-07 00:28:00 - progress_bar.py[line:274] - INFO: epoch 001:   8540 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3062, wps=102, ups=0.47, wpb=109.4, bsz=40, num_updates=8530, lr=4.82479e-05, gnorm=0.618, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=34620
2023-01-07 00:28:21 - progress_bar.py[line:274] - INFO: epoch 001:   8550 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3109, wps=105, ups=0.48, wpb=109.8, bsz=40, num_updates=8540, lr=4.82434e-05, gnorm=0.439, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34641
2023-01-07 00:28:43 - progress_bar.py[line:274] - INFO: epoch 001:   8560 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2991, wps=102.3, ups=0.47, wpb=109.7, bsz=40, num_updates=8550, lr=4.82389e-05, gnorm=0.484, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34663
2023-01-07 00:29:05 - progress_bar.py[line:274] - INFO: epoch 001:   8570 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2842, wps=99.5, ups=0.46, wpb=109.3, bsz=40, num_updates=8560, lr=4.82345e-05, gnorm=0.458, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34685
2023-01-07 00:29:26 - progress_bar.py[line:274] - INFO: epoch 001:   8580 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3107, wps=101.4, ups=0.47, wpb=108.5, bsz=40, num_updates=8570, lr=4.823e-05, gnorm=0.495, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34707
2023-01-07 00:29:48 - progress_bar.py[line:274] - INFO: epoch 001:   8590 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.275, wps=99.7, ups=0.46, wpb=108.2, bsz=40, num_updates=8580, lr=4.82255e-05, gnorm=0.749, clip=30, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34729
2023-01-07 00:30:10 - progress_bar.py[line:274] - INFO: epoch 001:   8600 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2587, wps=101.8, ups=0.47, wpb=109.2, bsz=40, num_updates=8590, lr=4.8221e-05, gnorm=0.452, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34750
2023-01-07 00:30:31 - progress_bar.py[line:274] - INFO: epoch 001:   8610 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2629, wps=104.3, ups=0.48, wpb=109.2, bsz=40, num_updates=8600, lr=4.82165e-05, gnorm=0.424, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34771
2023-01-07 00:30:53 - progress_bar.py[line:274] - INFO: epoch 001:   8620 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2956, wps=100, ups=0.46, wpb=108.6, bsz=40, num_updates=8610, lr=4.8212e-05, gnorm=0.474, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=34793
2023-01-07 00:31:14 - progress_bar.py[line:274] - INFO: epoch 001:   8630 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3066, wps=102.2, ups=0.48, wpb=107.5, bsz=40, num_updates=8620, lr=4.82075e-05, gnorm=0.561, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34815
2023-01-07 00:31:36 - progress_bar.py[line:274] - INFO: epoch 001:   8640 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.277, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=8630, lr=4.8203e-05, gnorm=0.593, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34836
2023-01-07 00:31:58 - progress_bar.py[line:274] - INFO: epoch 001:   8650 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2747, wps=102, ups=0.46, wpb=109.9, bsz=40, num_updates=8640, lr=4.81985e-05, gnorm=0.553, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34858
2023-01-07 00:32:20 - progress_bar.py[line:274] - INFO: epoch 001:   8660 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2985, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=8650, lr=4.8194e-05, gnorm=0.675, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=34880
2023-01-07 00:32:42 - progress_bar.py[line:274] - INFO: epoch 001:   8670 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2653, wps=101.7, ups=0.46, wpb=110, bsz=40, num_updates=8660, lr=4.81895e-05, gnorm=0.509, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34902
2023-01-07 00:33:03 - progress_bar.py[line:274] - INFO: epoch 001:   8680 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3641, wps=101.4, ups=0.47, wpb=108.2, bsz=40, num_updates=8670, lr=4.8185e-05, gnorm=0.574, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=34923
2023-01-07 00:33:26 - progress_bar.py[line:274] - INFO: epoch 001:   8690 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2708, wps=98.9, ups=0.45, wpb=109.5, bsz=40, num_updates=8680, lr=4.81805e-05, gnorm=0.654, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34946
2023-01-07 00:33:47 - progress_bar.py[line:274] - INFO: epoch 001:   8700 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3109, wps=102.2, ups=0.47, wpb=108.9, bsz=40, num_updates=8690, lr=4.8176e-05, gnorm=0.717, clip=10, loss_scale=1024, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=34967
2023-01-07 00:34:09 - progress_bar.py[line:274] - INFO: epoch 001:   8710 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3069, wps=102.4, ups=0.47, wpb=110.1, bsz=40, num_updates=8700, lr=4.81715e-05, gnorm=0.804, clip=20, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=34989
2023-01-07 00:34:30 - progress_bar.py[line:274] - INFO: epoch 001:   8720 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2732, wps=102.9, ups=0.47, wpb=109.4, bsz=40, num_updates=8710, lr=4.8167e-05, gnorm=0.612, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35011
2023-01-07 00:34:52 - progress_bar.py[line:274] - INFO: epoch 001:   8730 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.255, wps=101.3, ups=0.46, wpb=109.7, bsz=40, num_updates=8720, lr=4.81625e-05, gnorm=0.416, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35032
2023-01-07 00:35:14 - progress_bar.py[line:274] - INFO: epoch 001:   8740 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3077, wps=100.9, ups=0.46, wpb=109.8, bsz=40, num_updates=8730, lr=4.8158e-05, gnorm=0.509, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=35054
2023-01-07 00:35:36 - progress_bar.py[line:274] - INFO: epoch 001:   8750 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3352, wps=101.7, ups=0.46, wpb=109.8, bsz=40, num_updates=8740, lr=4.81535e-05, gnorm=0.535, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35076
2023-01-07 00:35:57 - progress_bar.py[line:274] - INFO: epoch 001:   8760 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2808, wps=105.9, ups=0.48, wpb=110.4, bsz=40, num_updates=8750, lr=4.8149e-05, gnorm=0.419, clip=0, loss_scale=1024, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=35097
2023-01-07 00:36:19 - progress_bar.py[line:274] - INFO: epoch 001:   8770 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3208, wps=99, ups=0.46, wpb=107.6, bsz=40, num_updates=8760, lr=4.81445e-05, gnorm=0.701, clip=20, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=35119
2023-01-07 00:36:40 - progress_bar.py[line:274] - INFO: epoch 001:   8780 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=106.6, nsentences=40, sample_size=106.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2691, wps=102, ups=0.48, wpb=106.6, bsz=40, num_updates=8770, lr=4.814e-05, gnorm=0.523, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35140
2023-01-07 00:36:55 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 00:37:04 - progress_bar.py[line:274] - INFO: epoch 001:   8791 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.81, nsentences=40, sample_size=108.81, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3113, wps=95.9, ups=0.42, wpb=108.8, bsz=40, num_updates=8780, lr=4.81355e-05, gnorm=0.485, clip=0, loss_scale=512, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=35165
2023-01-07 00:37:26 - progress_bar.py[line:274] - INFO: epoch 001:   8801 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2629, wps=101.5, ups=0.46, wpb=109.9, bsz=40, num_updates=8790, lr=4.8131e-05, gnorm=0.562, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=35186
2023-01-07 00:37:47 - progress_bar.py[line:274] - INFO: epoch 001:   8811 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3089, wps=104.5, ups=0.48, wpb=109.2, bsz=40, num_updates=8800, lr=4.81266e-05, gnorm=0.567, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35208
2023-01-07 00:38:09 - progress_bar.py[line:274] - INFO: epoch 001:   8821 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3421, wps=104.4, ups=0.47, wpb=110.3, bsz=40, num_updates=8810, lr=4.81221e-05, gnorm=0.419, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35229
2023-01-07 00:38:30 - progress_bar.py[line:274] - INFO: epoch 001:   8831 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3175, wps=101.2, ups=0.46, wpb=109.2, bsz=40, num_updates=8820, lr=4.81176e-05, gnorm=0.555, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35251
2023-01-07 00:38:52 - progress_bar.py[line:274] - INFO: epoch 001:   8841 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3096, wps=103.9, ups=0.48, wpb=109.1, bsz=40, num_updates=8830, lr=4.81131e-05, gnorm=0.636, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=35272
2023-01-07 00:39:09 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-07 00:39:16 - progress_bar.py[line:274] - INFO: epoch 001:   8852 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.381, nsentences=40, sample_size=110.381, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3062, wps=97.4, ups=0.42, wpb=110.4, bsz=40, num_updates=8840, lr=4.81086e-05, gnorm=0.546, clip=0, loss_scale=256, train_wall=24, gb_free=10.5, ema_decay=0.9999, wall=35296
2023-01-07 00:39:37 - progress_bar.py[line:274] - INFO: epoch 001:   8862 / 115845 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=106.4, nsentences=40, sample_size=106.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2969, wps=100.1, ups=0.47, wpb=106.4, bsz=40, num_updates=8850, lr=4.81041e-05, gnorm=0.562, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35317
2023-01-07 00:39:59 - progress_bar.py[line:274] - INFO: epoch 001:   8872 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3722, wps=103.5, ups=0.47, wpb=109.7, bsz=40, num_updates=8860, lr=4.80996e-05, gnorm=0.437, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=35339
2023-01-07 00:40:20 - progress_bar.py[line:274] - INFO: epoch 001:   8882 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3713, wps=101, ups=0.47, wpb=108.3, bsz=40, num_updates=8870, lr=4.80951e-05, gnorm=0.491, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=35361
2023-01-07 00:40:42 - progress_bar.py[line:274] - INFO: epoch 001:   8892 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3398, wps=102.5, ups=0.47, wpb=108.9, bsz=40, num_updates=8880, lr=4.80906e-05, gnorm=0.485, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35382
2023-01-07 00:41:03 - progress_bar.py[line:274] - INFO: epoch 001:   8902 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3153, wps=105, ups=0.48, wpb=108.8, bsz=40, num_updates=8890, lr=4.80861e-05, gnorm=0.728, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35403
2023-01-07 00:41:25 - progress_bar.py[line:274] - INFO: epoch 001:   8912 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2183, wps=101.1, ups=0.46, wpb=109.6, bsz=40, num_updates=8900, lr=4.80816e-05, gnorm=0.425, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35425
2023-01-07 00:41:46 - progress_bar.py[line:274] - INFO: epoch 001:   8922 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3168, wps=102.9, ups=0.48, wpb=108.3, bsz=40, num_updates=8910, lr=4.80771e-05, gnorm=0.793, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35446
2023-01-07 00:42:08 - progress_bar.py[line:274] - INFO: epoch 001:   8932 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3146, wps=100.5, ups=0.47, wpb=108, bsz=40, num_updates=8920, lr=4.80726e-05, gnorm=0.562, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35468
2023-01-07 00:42:30 - progress_bar.py[line:274] - INFO: epoch 001:   8942 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3301, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=8930, lr=4.80681e-05, gnorm=0.468, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=35490
2023-01-07 00:42:51 - progress_bar.py[line:274] - INFO: epoch 001:   8952 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2873, wps=101.8, ups=0.46, wpb=110.6, bsz=40, num_updates=8940, lr=4.80636e-05, gnorm=0.519, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35512
2023-01-07 00:43:13 - progress_bar.py[line:274] - INFO: epoch 001:   8962 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3382, wps=100.7, ups=0.46, wpb=109, bsz=40, num_updates=8950, lr=4.80591e-05, gnorm=0.645, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35534
2023-01-07 00:43:35 - progress_bar.py[line:274] - INFO: epoch 001:   8972 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.348, wps=102.1, ups=0.47, wpb=108.6, bsz=40, num_updates=8960, lr=4.80546e-05, gnorm=0.378, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35555
2023-01-07 00:43:57 - progress_bar.py[line:274] - INFO: epoch 001:   8982 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3189, wps=104.2, ups=0.47, wpb=111.1, bsz=40, num_updates=8970, lr=4.80501e-05, gnorm=0.411, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35577
2023-01-07 00:44:18 - progress_bar.py[line:274] - INFO: epoch 001:   8992 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2944, wps=101.2, ups=0.47, wpb=107.9, bsz=40, num_updates=8980, lr=4.80456e-05, gnorm=0.531, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35598
2023-01-07 00:44:40 - progress_bar.py[line:274] - INFO: epoch 001:   9002 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3138, wps=102.6, ups=0.47, wpb=110.2, bsz=40, num_updates=8990, lr=4.80411e-05, gnorm=0.429, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35620
2023-01-07 00:45:01 - progress_bar.py[line:274] - INFO: epoch 001:   9012 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3196, wps=104.8, ups=0.47, wpb=110.7, bsz=40, num_updates=9000, lr=4.80366e-05, gnorm=0.44, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35641
2023-01-07 00:45:23 - progress_bar.py[line:274] - INFO: epoch 001:   9022 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.299, wps=100.4, ups=0.46, wpb=108.8, bsz=40, num_updates=9010, lr=4.80321e-05, gnorm=0.533, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=35663
2023-01-07 00:45:45 - progress_bar.py[line:274] - INFO: epoch 001:   9032 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3594, wps=103.1, ups=0.47, wpb=110.4, bsz=40, num_updates=9020, lr=4.80276e-05, gnorm=0.411, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35685
2023-01-07 00:46:07 - progress_bar.py[line:274] - INFO: epoch 001:   9042 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3221, wps=100.4, ups=0.46, wpb=108.2, bsz=40, num_updates=9030, lr=4.80231e-05, gnorm=0.55, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35707
2023-01-07 00:46:28 - progress_bar.py[line:274] - INFO: epoch 001:   9052 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3507, wps=101.5, ups=0.47, wpb=108.5, bsz=40, num_updates=9040, lr=4.80186e-05, gnorm=0.545, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35728
2023-01-07 00:46:50 - progress_bar.py[line:274] - INFO: epoch 001:   9062 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3571, wps=103.3, ups=0.47, wpb=109.3, bsz=40, num_updates=9050, lr=4.80142e-05, gnorm=0.625, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35750
2023-01-07 00:47:11 - progress_bar.py[line:274] - INFO: epoch 001:   9072 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2637, wps=100.2, ups=0.46, wpb=109, bsz=40, num_updates=9060, lr=4.80097e-05, gnorm=0.57, clip=0, loss_scale=256, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=35772
2023-01-07 00:47:33 - progress_bar.py[line:274] - INFO: epoch 001:   9082 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.392, wps=102, ups=0.47, wpb=109.6, bsz=40, num_updates=9070, lr=4.80052e-05, gnorm=0.563, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=35793
2023-01-07 00:47:55 - progress_bar.py[line:274] - INFO: epoch 001:   9092 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.335, wps=100.4, ups=0.46, wpb=108, bsz=40, num_updates=9080, lr=4.80007e-05, gnorm=0.565, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35815
2023-01-07 00:48:16 - progress_bar.py[line:274] - INFO: epoch 001:   9102 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3231, wps=103.3, ups=0.47, wpb=109.1, bsz=40, num_updates=9090, lr=4.79962e-05, gnorm=0.77, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35837
2023-01-07 00:48:38 - progress_bar.py[line:274] - INFO: epoch 001:   9112 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3194, wps=101.7, ups=0.46, wpb=110.5, bsz=40, num_updates=9100, lr=4.79917e-05, gnorm=0.732, clip=30, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=35859
2023-01-07 00:49:00 - progress_bar.py[line:274] - INFO: epoch 001:   9122 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3575, wps=103.4, ups=0.47, wpb=110.1, bsz=40, num_updates=9110, lr=4.79872e-05, gnorm=0.438, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35880
2023-01-07 00:49:22 - progress_bar.py[line:274] - INFO: epoch 001:   9132 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3281, wps=102.5, ups=0.47, wpb=109.5, bsz=40, num_updates=9120, lr=4.79827e-05, gnorm=0.711, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35902
2023-01-07 00:49:44 - progress_bar.py[line:274] - INFO: epoch 001:   9142 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2984, wps=99.3, ups=0.45, wpb=109.8, bsz=40, num_updates=9130, lr=4.79782e-05, gnorm=0.456, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35924
2023-01-07 00:50:06 - progress_bar.py[line:274] - INFO: epoch 001:   9152 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3146, wps=98.7, ups=0.46, wpb=107.9, bsz=40, num_updates=9140, lr=4.79737e-05, gnorm=0.686, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35946
2023-01-07 00:50:28 - progress_bar.py[line:274] - INFO: epoch 001:   9162 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3351, wps=101.3, ups=0.47, wpb=108.4, bsz=40, num_updates=9150, lr=4.79692e-05, gnorm=0.834, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35968
2023-01-07 00:50:50 - progress_bar.py[line:274] - INFO: epoch 001:   9172 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3333, wps=99.5, ups=0.46, wpb=107.6, bsz=40, num_updates=9160, lr=4.79647e-05, gnorm=0.407, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35990
2023-01-07 00:51:11 - progress_bar.py[line:274] - INFO: epoch 001:   9182 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3486, wps=102.6, ups=0.47, wpb=108.3, bsz=40, num_updates=9170, lr=4.79602e-05, gnorm=0.562, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36011
2023-01-07 00:51:33 - progress_bar.py[line:274] - INFO: epoch 001:   9192 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3235, wps=99.9, ups=0.46, wpb=108.5, bsz=40, num_updates=9180, lr=4.79557e-05, gnorm=0.58, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=36033
2023-01-07 00:51:55 - progress_bar.py[line:274] - INFO: epoch 001:   9202 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3351, wps=103.2, ups=0.47, wpb=109.6, bsz=40, num_updates=9190, lr=4.79512e-05, gnorm=0.698, clip=20, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36055
2023-01-07 00:52:17 - progress_bar.py[line:274] - INFO: epoch 001:   9212 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.301, wps=102.3, ups=0.47, wpb=109.7, bsz=40, num_updates=9200, lr=4.79467e-05, gnorm=0.533, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36077
2023-01-07 00:52:39 - progress_bar.py[line:274] - INFO: epoch 001:   9222 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2527, wps=100.7, ups=0.46, wpb=109.2, bsz=40, num_updates=9210, lr=4.79422e-05, gnorm=0.621, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36099
2023-01-07 00:53:02 - progress_bar.py[line:274] - INFO: epoch 001:   9232 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2829, wps=100.1, ups=0.46, wpb=109.5, bsz=40, num_updates=9220, lr=4.79377e-05, gnorm=0.636, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36122
2023-01-07 00:53:24 - progress_bar.py[line:274] - INFO: epoch 001:   9242 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.325, wps=102.1, ups=0.46, wpb=109.9, bsz=40, num_updates=9230, lr=4.79332e-05, gnorm=0.494, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36144
2023-01-07 00:53:46 - progress_bar.py[line:274] - INFO: epoch 001:   9252 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3762, wps=100.6, ups=0.46, wpb=108.9, bsz=40, num_updates=9240, lr=4.79287e-05, gnorm=0.523, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=36166
2023-01-07 00:54:08 - progress_bar.py[line:274] - INFO: epoch 001:   9262 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2798, wps=100.5, ups=0.46, wpb=109.1, bsz=40, num_updates=9250, lr=4.79242e-05, gnorm=0.394, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=36188
2023-01-07 00:54:30 - progress_bar.py[line:274] - INFO: epoch 001:   9272 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4227, wps=101.8, ups=0.47, wpb=108.5, bsz=40, num_updates=9260, lr=4.79197e-05, gnorm=0.543, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36210
2023-01-07 00:54:52 - progress_bar.py[line:274] - INFO: epoch 001:   9282 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3218, wps=101.7, ups=0.47, wpb=108.6, bsz=40, num_updates=9270, lr=4.79152e-05, gnorm=0.573, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36232
2023-01-07 00:55:13 - progress_bar.py[line:274] - INFO: epoch 001:   9292 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3333, wps=102.4, ups=0.47, wpb=109.2, bsz=40, num_updates=9280, lr=4.79107e-05, gnorm=0.548, clip=10, loss_scale=256, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=36253
2023-01-07 00:55:35 - progress_bar.py[line:274] - INFO: epoch 001:   9302 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3085, wps=103.2, ups=0.47, wpb=108.9, bsz=40, num_updates=9290, lr=4.79063e-05, gnorm=0.557, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36275
2023-01-07 00:55:57 - progress_bar.py[line:274] - INFO: epoch 001:   9312 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3687, wps=102.2, ups=0.47, wpb=109, bsz=40, num_updates=9300, lr=4.79018e-05, gnorm=0.492, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=36297
2023-01-07 00:56:18 - progress_bar.py[line:274] - INFO: epoch 001:   9322 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3581, wps=100.5, ups=0.47, wpb=107.9, bsz=40, num_updates=9310, lr=4.78973e-05, gnorm=0.569, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=36318
2023-01-07 00:56:40 - progress_bar.py[line:274] - INFO: epoch 001:   9332 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3744, wps=99.6, ups=0.46, wpb=107.9, bsz=40, num_updates=9320, lr=4.78928e-05, gnorm=0.409, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36341
2023-01-07 00:57:02 - progress_bar.py[line:274] - INFO: epoch 001:   9342 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3235, wps=101.4, ups=0.47, wpb=108, bsz=40, num_updates=9330, lr=4.78883e-05, gnorm=0.586, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36362
2023-01-07 00:57:24 - progress_bar.py[line:274] - INFO: epoch 001:   9352 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3179, wps=100.5, ups=0.46, wpb=108.9, bsz=40, num_updates=9340, lr=4.78838e-05, gnorm=0.435, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36384
2023-01-07 00:57:47 - progress_bar.py[line:274] - INFO: epoch 001:   9362 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3316, wps=99.4, ups=0.46, wpb=108.4, bsz=40, num_updates=9350, lr=4.78793e-05, gnorm=0.511, clip=0, loss_scale=512, train_wall=22, gb_free=9.5, ema_decay=0.9999, wall=36407
2023-01-07 00:58:09 - progress_bar.py[line:274] - INFO: epoch 001:   9372 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3768, wps=100.1, ups=0.46, wpb=109.5, bsz=40, num_updates=9360, lr=4.78748e-05, gnorm=0.557, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36429
2023-01-07 00:58:31 - progress_bar.py[line:274] - INFO: epoch 001:   9382 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3503, wps=102.8, ups=0.47, wpb=108.5, bsz=40, num_updates=9370, lr=4.78703e-05, gnorm=0.598, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36451
2023-01-07 00:58:52 - progress_bar.py[line:274] - INFO: epoch 001:   9392 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3122, wps=102.8, ups=0.47, wpb=109.5, bsz=40, num_updates=9380, lr=4.78658e-05, gnorm=0.599, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36472
2023-01-07 00:59:15 - progress_bar.py[line:274] - INFO: epoch 001:   9402 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3632, wps=99.6, ups=0.46, wpb=108.6, bsz=40, num_updates=9390, lr=4.78613e-05, gnorm=0.435, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=36495
2023-01-07 00:59:37 - progress_bar.py[line:274] - INFO: epoch 001:   9412 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3507, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=9400, lr=4.78568e-05, gnorm=0.511, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36517
2023-01-07 00:59:59 - progress_bar.py[line:274] - INFO: epoch 001:   9422 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3053, wps=103.5, ups=0.47, wpb=110.4, bsz=40, num_updates=9410, lr=4.78523e-05, gnorm=0.677, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36539
2023-01-07 01:00:20 - progress_bar.py[line:274] - INFO: epoch 001:   9432 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3224, wps=102.3, ups=0.47, wpb=108.9, bsz=40, num_updates=9420, lr=4.78478e-05, gnorm=0.565, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36560
2023-01-07 01:00:42 - progress_bar.py[line:274] - INFO: epoch 001:   9442 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3483, wps=103, ups=0.47, wpb=109.8, bsz=40, num_updates=9430, lr=4.78433e-05, gnorm=0.681, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36582
2023-01-07 01:01:04 - progress_bar.py[line:274] - INFO: epoch 001:   9452 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3095, wps=102.9, ups=0.47, wpb=109.2, bsz=40, num_updates=9440, lr=4.78388e-05, gnorm=0.437, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=36604
2023-01-07 01:01:25 - progress_bar.py[line:274] - INFO: epoch 001:   9462 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2843, wps=104.7, ups=0.48, wpb=108.8, bsz=40, num_updates=9450, lr=4.78343e-05, gnorm=0.468, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36625
2023-01-07 01:01:48 - progress_bar.py[line:274] - INFO: epoch 001:   9472 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.33, wps=98.5, ups=0.46, wpb=108.1, bsz=40, num_updates=9460, lr=4.78298e-05, gnorm=0.637, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36648
2023-01-07 01:02:10 - progress_bar.py[line:274] - INFO: epoch 001:   9482 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3774, wps=101.4, ups=0.47, wpb=109, bsz=40, num_updates=9470, lr=4.78253e-05, gnorm=0.635, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36670
2023-01-07 01:02:31 - progress_bar.py[line:274] - INFO: epoch 001:   9492 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3429, wps=101, ups=0.47, wpb=107.7, bsz=40, num_updates=9480, lr=4.78208e-05, gnorm=0.464, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36691
2023-01-07 01:02:53 - progress_bar.py[line:274] - INFO: epoch 001:   9502 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3827, wps=102.6, ups=0.47, wpb=108.7, bsz=40, num_updates=9490, lr=4.78163e-05, gnorm=0.403, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36713
2023-01-07 01:03:15 - progress_bar.py[line:274] - INFO: epoch 001:   9512 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3548, wps=101.6, ups=0.47, wpb=108.9, bsz=40, num_updates=9500, lr=4.78118e-05, gnorm=0.723, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36735
2023-01-07 01:03:37 - progress_bar.py[line:274] - INFO: epoch 001:   9522 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3697, wps=102.5, ups=0.47, wpb=109.1, bsz=40, num_updates=9510, lr=4.78073e-05, gnorm=0.416, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=36757
2023-01-07 01:03:58 - progress_bar.py[line:274] - INFO: epoch 001:   9532 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3568, wps=103.1, ups=0.47, wpb=109.1, bsz=40, num_updates=9520, lr=4.78028e-05, gnorm=0.35, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36778
2023-01-07 01:04:20 - progress_bar.py[line:274] - INFO: epoch 001:   9542 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3493, wps=103.6, ups=0.48, wpb=108, bsz=40, num_updates=9530, lr=4.77983e-05, gnorm=0.453, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36800
2023-01-07 01:04:42 - progress_bar.py[line:274] - INFO: epoch 001:   9552 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3604, wps=101.1, ups=0.46, wpb=109.3, bsz=40, num_updates=9540, lr=4.77939e-05, gnorm=0.43, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=36822
2023-01-07 01:05:04 - progress_bar.py[line:274] - INFO: epoch 001:   9562 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2979, wps=101.7, ups=0.46, wpb=110.3, bsz=40, num_updates=9550, lr=4.77894e-05, gnorm=0.428, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=36844
2023-01-07 01:05:26 - progress_bar.py[line:274] - INFO: epoch 001:   9572 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3762, wps=101.6, ups=0.47, wpb=109, bsz=40, num_updates=9560, lr=4.77849e-05, gnorm=0.501, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36866
2023-01-07 01:05:47 - progress_bar.py[line:274] - INFO: epoch 001:   9582 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3262, wps=101.1, ups=0.47, wpb=108.5, bsz=40, num_updates=9570, lr=4.77804e-05, gnorm=0.548, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36888
2023-01-07 01:05:52 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-07 01:06:11 - progress_bar.py[line:274] - INFO: epoch 001:   9593 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.381, nsentences=40, sample_size=109.381, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.36, wps=98.2, ups=0.43, wpb=109.4, bsz=40, num_updates=9580, lr=4.77759e-05, gnorm=0.487, clip=0, loss_scale=256, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=36911
2023-01-07 01:06:33 - progress_bar.py[line:274] - INFO: epoch 001:   9603 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3278, wps=102.1, ups=0.46, wpb=109.8, bsz=40, num_updates=9590, lr=4.77714e-05, gnorm=0.254, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36933
2023-01-07 01:06:56 - progress_bar.py[line:274] - INFO: epoch 001:   9613 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3641, wps=101.4, ups=0.46, wpb=109, bsz=40, num_updates=9600, lr=4.77669e-05, gnorm=0.445, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36955
2023-01-07 01:07:17 - progress_bar.py[line:274] - INFO: epoch 001:   9623 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3179, wps=102.5, ups=0.47, wpb=108, bsz=40, num_updates=9610, lr=4.77624e-05, gnorm=0.623, clip=20, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36977
2023-01-07 01:07:39 - progress_bar.py[line:274] - INFO: epoch 001:   9633 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3861, wps=102.7, ups=0.47, wpb=108.3, bsz=40, num_updates=9620, lr=4.77579e-05, gnorm=0.482, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36999
2023-01-07 01:08:01 - progress_bar.py[line:274] - INFO: epoch 001:   9643 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3271, wps=101.3, ups=0.47, wpb=108.1, bsz=40, num_updates=9630, lr=4.77534e-05, gnorm=0.535, clip=10, loss_scale=256, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=37021
2023-01-07 01:08:23 - progress_bar.py[line:274] - INFO: epoch 001:   9653 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.401, wps=103.1, ups=0.47, wpb=109.8, bsz=40, num_updates=9640, lr=4.77489e-05, gnorm=0.566, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37043
2023-01-07 01:08:45 - progress_bar.py[line:274] - INFO: epoch 001:   9663 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.348, wps=101.3, ups=0.46, wpb=109.7, bsz=40, num_updates=9650, lr=4.77444e-05, gnorm=0.344, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37065
2023-01-07 01:09:06 - progress_bar.py[line:274] - INFO: epoch 001:   9673 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3409, wps=103.2, ups=0.47, wpb=110.1, bsz=40, num_updates=9660, lr=4.77399e-05, gnorm=0.556, clip=10, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=37086
2023-01-07 01:09:29 - progress_bar.py[line:274] - INFO: epoch 001:   9683 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3198, wps=100.1, ups=0.46, wpb=108.8, bsz=40, num_updates=9670, lr=4.77354e-05, gnorm=0.409, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=37109
2023-01-07 01:09:50 - progress_bar.py[line:274] - INFO: epoch 001:   9693 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3135, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=9680, lr=4.77309e-05, gnorm=0.577, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37130
2023-01-07 01:10:12 - progress_bar.py[line:274] - INFO: epoch 001:   9703 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3825, wps=104.4, ups=0.48, wpb=109.4, bsz=40, num_updates=9690, lr=4.77264e-05, gnorm=0.39, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37152
2023-01-07 01:10:34 - progress_bar.py[line:274] - INFO: epoch 001:   9713 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.404, wps=102.6, ups=0.47, wpb=110.3, bsz=40, num_updates=9700, lr=4.77219e-05, gnorm=0.577, clip=10, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=37174
2023-01-07 01:10:56 - progress_bar.py[line:274] - INFO: epoch 001:   9723 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4039, wps=100.2, ups=0.46, wpb=108.7, bsz=40, num_updates=9710, lr=4.77174e-05, gnorm=0.503, clip=0, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=37196
2023-01-07 01:11:18 - progress_bar.py[line:274] - INFO: epoch 001:   9733 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3396, wps=100.9, ups=0.47, wpb=108.2, bsz=40, num_updates=9720, lr=4.77129e-05, gnorm=0.429, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37218
2023-01-07 01:11:39 - progress_bar.py[line:274] - INFO: epoch 001:   9743 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3387, wps=103.7, ups=0.47, wpb=109.4, bsz=40, num_updates=9730, lr=4.77084e-05, gnorm=0.479, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=37239
2023-01-07 01:12:01 - progress_bar.py[line:274] - INFO: epoch 001:   9753 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3575, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=9740, lr=4.77039e-05, gnorm=0.479, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37261
2023-01-07 01:12:23 - progress_bar.py[line:274] - INFO: epoch 001:   9763 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3812, wps=102.9, ups=0.47, wpb=109.9, bsz=40, num_updates=9750, lr=4.76994e-05, gnorm=0.474, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37283
2023-01-07 01:12:44 - progress_bar.py[line:274] - INFO: epoch 001:   9773 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3769, wps=103.1, ups=0.48, wpb=108.1, bsz=40, num_updates=9760, lr=4.76949e-05, gnorm=0.543, clip=20, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=37304
2023-01-07 01:13:06 - progress_bar.py[line:274] - INFO: epoch 001:   9783 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3641, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=9770, lr=4.76904e-05, gnorm=0.575, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37326
2023-01-07 01:13:28 - progress_bar.py[line:274] - INFO: epoch 001:   9793 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3255, wps=102.2, ups=0.47, wpb=108.2, bsz=40, num_updates=9780, lr=4.7686e-05, gnorm=0.469, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37348
2023-01-07 01:13:50 - progress_bar.py[line:274] - INFO: epoch 001:   9803 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.31, wps=99.7, ups=0.46, wpb=108.7, bsz=40, num_updates=9790, lr=4.76815e-05, gnorm=0.524, clip=10, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=37370
2023-01-07 01:14:12 - progress_bar.py[line:274] - INFO: epoch 001:   9813 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4565, wps=101.4, ups=0.46, wpb=110, bsz=40, num_updates=9800, lr=4.7677e-05, gnorm=0.497, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=37392
2023-01-07 01:14:34 - progress_bar.py[line:274] - INFO: epoch 001:   9823 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3824, wps=102.4, ups=0.47, wpb=110, bsz=40, num_updates=9810, lr=4.76725e-05, gnorm=0.452, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37414
2023-01-07 01:14:56 - progress_bar.py[line:274] - INFO: epoch 001:   9833 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3077, wps=102.3, ups=0.46, wpb=110, bsz=40, num_updates=9820, lr=4.7668e-05, gnorm=0.505, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37436
2023-01-07 01:15:18 - progress_bar.py[line:274] - INFO: epoch 001:   9843 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3575, wps=104.7, ups=0.47, wpb=110.3, bsz=40, num_updates=9830, lr=4.76635e-05, gnorm=0.48, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37458
2023-01-07 01:15:40 - progress_bar.py[line:274] - INFO: epoch 001:   9853 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3632, wps=101.2, ups=0.46, wpb=109.9, bsz=40, num_updates=9840, lr=4.7659e-05, gnorm=0.439, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37480
2023-01-07 01:16:02 - progress_bar.py[line:274] - INFO: epoch 001:   9863 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.385, wps=102.3, ups=0.47, wpb=108.2, bsz=40, num_updates=9850, lr=4.76545e-05, gnorm=0.401, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37502
2023-01-07 01:16:23 - progress_bar.py[line:274] - INFO: epoch 001:   9873 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4067, wps=101.5, ups=0.47, wpb=108.2, bsz=40, num_updates=9860, lr=4.765e-05, gnorm=0.447, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37523
2023-01-07 01:16:45 - progress_bar.py[line:274] - INFO: epoch 001:   9883 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3365, wps=104.4, ups=0.48, wpb=108.7, bsz=40, num_updates=9870, lr=4.76455e-05, gnorm=0.589, clip=10, loss_scale=256, train_wall=21, gb_free=9.5, ema_decay=0.9999, wall=37545
2023-01-07 01:17:06 - progress_bar.py[line:274] - INFO: epoch 001:   9893 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.349, wps=104.4, ups=0.47, wpb=110.6, bsz=40, num_updates=9880, lr=4.7641e-05, gnorm=0.397, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=37566
2023-01-07 01:17:28 - progress_bar.py[line:274] - INFO: epoch 001:   9903 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.335, wps=101.3, ups=0.46, wpb=108.9, bsz=40, num_updates=9890, lr=4.76365e-05, gnorm=0.572, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37588
2023-01-07 01:17:50 - progress_bar.py[line:274] - INFO: epoch 001:   9913 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3697, wps=101.6, ups=0.47, wpb=108.4, bsz=40, num_updates=9900, lr=4.7632e-05, gnorm=0.49, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37610
2023-01-07 01:18:12 - progress_bar.py[line:274] - INFO: epoch 001:   9923 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3206, wps=101.3, ups=0.47, wpb=107.8, bsz=40, num_updates=9910, lr=4.76275e-05, gnorm=0.347, clip=0, loss_scale=256, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=37632
2023-01-07 01:18:34 - progress_bar.py[line:274] - INFO: epoch 001:   9933 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3793, wps=101, ups=0.46, wpb=109.4, bsz=40, num_updates=9920, lr=4.7623e-05, gnorm=0.357, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=37654
2023-01-07 01:18:56 - progress_bar.py[line:274] - INFO: epoch 001:   9943 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3395, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=9930, lr=4.76185e-05, gnorm=0.626, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37676
2023-01-07 01:19:18 - progress_bar.py[line:274] - INFO: epoch 001:   9953 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3832, wps=98.5, ups=0.46, wpb=108, bsz=40, num_updates=9940, lr=4.7614e-05, gnorm=0.511, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=37698
2023-01-07 01:19:40 - progress_bar.py[line:274] - INFO: epoch 001:   9963 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3716, wps=101.4, ups=0.46, wpb=110.2, bsz=40, num_updates=9950, lr=4.76095e-05, gnorm=0.419, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=37720
2023-01-07 01:20:02 - progress_bar.py[line:274] - INFO: epoch 001:   9973 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3942, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=9960, lr=4.7605e-05, gnorm=0.614, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37742
2023-01-07 01:20:24 - progress_bar.py[line:274] - INFO: epoch 001:   9983 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3687, wps=101.5, ups=0.46, wpb=109.7, bsz=40, num_updates=9970, lr=4.76005e-05, gnorm=0.538, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37764
2023-01-07 01:20:46 - progress_bar.py[line:274] - INFO: epoch 001:   9993 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3871, wps=102.4, ups=0.47, wpb=109.1, bsz=40, num_updates=9980, lr=4.7596e-05, gnorm=0.489, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37786
2023-01-07 01:21:08 - progress_bar.py[line:274] - INFO: epoch 001:  10003 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3545, wps=100.7, ups=0.46, wpb=110.5, bsz=40, num_updates=9990, lr=4.75915e-05, gnorm=0.471, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37808
2023-01-07 01:21:29 - progress_bar.py[line:274] - INFO: epoch 001:  10013 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4455, wps=101.9, ups=0.47, wpb=109.3, bsz=40, num_updates=10000, lr=4.7587e-05, gnorm=0.531, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=37830
2023-01-07 01:21:29 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 01:21:31 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 01:21:31 - train.py[line:551] - INFO: load:0.94 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 01:24:02 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 01:24:02 - train.py[line:551] - INFO: load:0.96 valid_run:151.26 task_valid:146.79 collect_output:3.35
2023-01-07 01:26:30 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 01:26:30 - train.py[line:551] - INFO: load:0.99 valid_run:299.47 task_valid:288.19 collect_output:9.12
2023-01-07 01:29:03 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 01:29:03 - train.py[line:551] - INFO: load:1.01 valid_run:451.78 task_valid:429.65 collect_output:18.92
2023-01-07 01:31:31 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 01:31:31 - train.py[line:551] - INFO: load:1.04 valid_run:600.25 task_valid:573.06 collect_output:22.94
2023-01-07 01:34:03 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 01:34:03 - train.py[line:551] - INFO: load:1.06 valid_run:751.94 task_valid:718.85 collect_output:27.78
2023-01-07 01:36:35 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 01:36:35 - train.py[line:551] - INFO: load:1.09 valid_run:903.52 task_valid:862.69 collect_output:34.48
2023-01-07 01:39:08 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 01:39:08 - train.py[line:551] - INFO: load:1.12 valid_run:1056.99 task_valid:1007.13 collect_output:42.48
2023-01-07 01:41:40 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 01:41:40 - train.py[line:551] - INFO: load:1.14 valid_run:1208.27 task_valid:1146.40 collect_output:53.47
2023-01-07 01:44:09 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 01:44:09 - train.py[line:551] - INFO: load:1.17 valid_run:1357.57 task_valid:1289.38 collect_output:58.74
2023-01-07 01:46:37 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 01:46:37 - train.py[line:551] - INFO: load:1.19 valid_run:1505.84 task_valid:1430.81 collect_output:64.56
2023-01-07 01:49:07 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 01:49:07 - train.py[line:551] - INFO: load:1.22 valid_run:1655.24 task_valid:1574.10 collect_output:69.65
2023-01-07 01:51:37 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 01:51:37 - train.py[line:551] - INFO: load:1.24 valid_run:1805.15 task_valid:1717.93 collect_output:74.68
2023-01-07 01:54:07 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 01:54:07 - train.py[line:551] - INFO: load:1.27 valid_run:1954.83 task_valid:1858.06 collect_output:83.18
2023-01-07 01:56:37 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 01:56:37 - train.py[line:551] - INFO: load:1.29 valid_run:2104.88 task_valid:2001.85 collect_output:88.41
2023-01-07 01:59:06 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 01:59:06 - train.py[line:551] - INFO: load:1.32 valid_run:2254.18 task_valid:2146.77 collect_output:91.76
2023-01-07 02:01:36 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 02:01:36 - train.py[line:551] - INFO: load:1.35 valid_run:2403.87 task_valid:2289.42 collect_output:97.75
2023-01-07 02:04:08 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 02:04:08 - train.py[line:551] - INFO: load:1.39 valid_run:2556.25 task_valid:2433.90 collect_output:104.57
2023-01-07 02:06:38 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 02:06:38 - train.py[line:551] - INFO: load:1.41 valid_run:2706.28 task_valid:2579.29 collect_output:108.16
2023-01-07 02:09:07 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 02:09:07 - train.py[line:551] - INFO: load:1.44 valid_run:2855.02 task_valid:2719.83 collect_output:115.29
2023-01-07 02:11:38 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 02:11:38 - train.py[line:551] - INFO: load:1.46 valid_run:3005.23 task_valid:2863.38 collect_output:120.89
2023-01-07 02:14:10 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 02:14:10 - train.py[line:551] - INFO: load:1.49 valid_run:3157.56 task_valid:3006.62 collect_output:128.88
2023-01-07 02:16:39 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 02:16:39 - train.py[line:551] - INFO: load:1.52 valid_run:3306.67 task_valid:3149.81 collect_output:133.76
2023-01-07 02:19:10 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 02:19:10 - train.py[line:551] - INFO: load:1.55 valid_run:3457.77 task_valid:3294.65 collect_output:138.97
2023-01-07 02:21:41 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 02:21:41 - train.py[line:551] - INFO: load:1.57 valid_run:3608.65 task_valid:3439.72 collect_output:143.72

====================================================================================================
SGG eval:     R @ 50: 0.5105;     R @ 100: 0.5940;     R @ 500: 0.6487;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3120;    mR @ 100: 0.3929;    mR @ 500: 0.4451;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7707) (covered in:0.8750) (covering:0.2857) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.8497) (says:0.0000) (sitting on:0.6848) (standing on:0.2108) (using:0.6500) (walking in:0.0000) (walking on:0.6847) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-07 02:24:12 - train.py[line:487] - INFO: 0.5940380952380953
2023-01-07 02:24:12 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.5105;     R @ 100: 0.5940;     R @ 500: 0.6487;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3120;    mR @ 100: 0.3929;    mR @ 500: 0.4451;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7707) (covered in:0.8750) (covering:0.2857) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.8497) (says:0.0000) (sitting on:0.6848) (standing on:0.2108) (using:0.6500) (walking in:0.0000) (walking on:0.6847) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-07 02:24:12 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.367 | loss_v1 0 | loss_v2 0 | nll_loss 0.213 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.594038 | ppl 1.16 | vqa_score 0.5484 | wps 119.3 | wpb 89.9 | bsz 30 | num_updates 10000 | best_R@100 0.637221
2023-01-07 02:24:12 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 10000 updates
2023-01-07 02:24:12 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_10000.pt
2023-01-07 02:24:51 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_10000.pt
2023-01-07 02:26:17 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 0.5940380952380953) (writing took 125.43094970472157 seconds)
2023-01-07 02:26:38 - progress_bar.py[line:274] - INFO: epoch 001:  10023 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.402, wps=0.6, ups=0, wpb=108.1, bsz=40, num_updates=10010, lr=4.75825e-05, gnorm=0.341, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=41739
2023-01-07 02:27:00 - progress_bar.py[line:274] - INFO: epoch 001:  10033 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3646, wps=102.2, ups=0.47, wpb=109.2, bsz=40, num_updates=10020, lr=4.7578e-05, gnorm=0.398, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=41760
2023-01-07 02:27:21 - progress_bar.py[line:274] - INFO: epoch 001:  10043 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3467, wps=102.2, ups=0.47, wpb=108.8, bsz=40, num_updates=10030, lr=4.75736e-05, gnorm=0.496, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=41782
2023-01-07 02:27:43 - progress_bar.py[line:274] - INFO: epoch 001:  10053 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4271, wps=103.3, ups=0.48, wpb=108.6, bsz=40, num_updates=10040, lr=4.75691e-05, gnorm=0.59, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=41803
2023-01-07 02:28:04 - progress_bar.py[line:274] - INFO: epoch 001:  10063 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3854, wps=101.5, ups=0.47, wpb=107.1, bsz=40, num_updates=10050, lr=4.75646e-05, gnorm=0.52, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=41824
2023-01-07 02:28:26 - progress_bar.py[line:274] - INFO: epoch 001:  10073 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3704, wps=99.2, ups=0.46, wpb=107.9, bsz=40, num_updates=10060, lr=4.75601e-05, gnorm=0.489, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=41846
2023-01-07 02:28:48 - progress_bar.py[line:274] - INFO: epoch 001:  10083 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3333, wps=99.9, ups=0.47, wpb=107.3, bsz=40, num_updates=10070, lr=4.75556e-05, gnorm=0.704, clip=20, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=41868
2023-01-07 02:29:10 - progress_bar.py[line:274] - INFO: epoch 001:  10093 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3652, wps=102.2, ups=0.46, wpb=110.9, bsz=40, num_updates=10080, lr=4.75511e-05, gnorm=0.502, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=41890
2023-01-07 02:29:31 - progress_bar.py[line:274] - INFO: epoch 001:  10103 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3788, wps=102.7, ups=0.47, wpb=108.2, bsz=40, num_updates=10090, lr=4.75466e-05, gnorm=0.531, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=41911
2023-01-07 02:29:53 - progress_bar.py[line:274] - INFO: epoch 001:  10113 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3699, wps=101.1, ups=0.47, wpb=108.7, bsz=40, num_updates=10100, lr=4.75421e-05, gnorm=0.625, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=41933
2023-01-07 02:30:14 - progress_bar.py[line:274] - INFO: epoch 001:  10123 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4087, wps=102.5, ups=0.47, wpb=109.8, bsz=40, num_updates=10110, lr=4.75376e-05, gnorm=0.544, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=41955
2023-01-07 02:30:23 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-07 02:30:38 - progress_bar.py[line:274] - INFO: epoch 001:  10134 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.571, nsentences=40, sample_size=109.571, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3915, wps=100.3, ups=0.44, wpb=109.6, bsz=40, num_updates=10120, lr=4.75331e-05, gnorm=0.806, clip=20, loss_scale=256, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=41978
2023-01-07 02:30:59 - progress_bar.py[line:274] - INFO: epoch 001:  10144 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3171, wps=101.4, ups=0.47, wpb=108.5, bsz=40, num_updates=10130, lr=4.75286e-05, gnorm=0.384, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=41999
2023-01-07 02:31:21 - progress_bar.py[line:274] - INFO: epoch 001:  10154 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4375, wps=100.3, ups=0.47, wpb=107.8, bsz=40, num_updates=10140, lr=4.75241e-05, gnorm=0.398, clip=10, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=42021
2023-01-07 02:31:43 - progress_bar.py[line:274] - INFO: epoch 001:  10164 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3989, wps=102.3, ups=0.46, wpb=110.3, bsz=40, num_updates=10150, lr=4.75196e-05, gnorm=0.765, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42043
2023-01-07 02:32:05 - progress_bar.py[line:274] - INFO: epoch 001:  10174 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.381, wps=100.6, ups=0.46, wpb=108.3, bsz=40, num_updates=10160, lr=4.75151e-05, gnorm=0.441, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=42065
2023-01-07 02:32:27 - progress_bar.py[line:274] - INFO: epoch 001:  10184 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4205, wps=99.8, ups=0.45, wpb=109.8, bsz=40, num_updates=10170, lr=4.75106e-05, gnorm=0.454, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=42087
2023-01-07 02:32:49 - progress_bar.py[line:274] - INFO: epoch 001:  10194 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.404, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=10180, lr=4.75061e-05, gnorm=0.516, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=42109
2023-01-07 02:33:10 - progress_bar.py[line:274] - INFO: epoch 001:  10204 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3909, wps=102, ups=0.47, wpb=109.5, bsz=40, num_updates=10190, lr=4.75016e-05, gnorm=0.566, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42131
2023-01-07 02:33:32 - progress_bar.py[line:274] - INFO: epoch 001:  10214 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3679, wps=104.5, ups=0.48, wpb=109.3, bsz=40, num_updates=10200, lr=4.74971e-05, gnorm=0.459, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=42152
2023-01-07 02:33:53 - progress_bar.py[line:274] - INFO: epoch 001:  10224 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.335, wps=99.8, ups=0.46, wpb=108.2, bsz=40, num_updates=10210, lr=4.74926e-05, gnorm=0.555, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42174
2023-01-07 02:34:15 - progress_bar.py[line:274] - INFO: epoch 001:  10234 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4639, wps=102.3, ups=0.47, wpb=109.6, bsz=40, num_updates=10220, lr=4.74881e-05, gnorm=0.477, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=42195
2023-01-07 02:34:37 - progress_bar.py[line:274] - INFO: epoch 001:  10244 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4028, wps=101.1, ups=0.47, wpb=108.1, bsz=40, num_updates=10230, lr=4.74836e-05, gnorm=0.419, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42217
2023-01-07 02:34:59 - progress_bar.py[line:274] - INFO: epoch 001:  10254 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4118, wps=99.5, ups=0.46, wpb=107.2, bsz=40, num_updates=10240, lr=4.74791e-05, gnorm=0.537, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=42239
2023-01-07 02:35:20 - progress_bar.py[line:274] - INFO: epoch 001:  10264 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3842, wps=100.8, ups=0.46, wpb=108.4, bsz=40, num_updates=10250, lr=4.74746e-05, gnorm=0.346, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42261
2023-01-07 02:35:42 - progress_bar.py[line:274] - INFO: epoch 001:  10274 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3782, wps=102.9, ups=0.47, wpb=110, bsz=40, num_updates=10260, lr=4.74701e-05, gnorm=0.4, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42282
2023-01-07 02:36:03 - progress_bar.py[line:274] - INFO: epoch 001:  10284 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3598, wps=102.2, ups=0.47, wpb=108.1, bsz=40, num_updates=10270, lr=4.74657e-05, gnorm=0.346, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42303
2023-01-07 02:36:25 - progress_bar.py[line:274] - INFO: epoch 001:  10294 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.419, wps=101.5, ups=0.47, wpb=109.1, bsz=40, num_updates=10280, lr=4.74612e-05, gnorm=0.512, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=42325
2023-01-07 02:36:46 - progress_bar.py[line:274] - INFO: epoch 001:  10304 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4049, wps=102.6, ups=0.47, wpb=109.4, bsz=40, num_updates=10290, lr=4.74567e-05, gnorm=0.487, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42347
2023-01-07 02:37:08 - progress_bar.py[line:274] - INFO: epoch 001:  10314 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.375, wps=100.4, ups=0.46, wpb=108.8, bsz=40, num_updates=10300, lr=4.74522e-05, gnorm=0.474, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=42369
2023-01-07 02:37:30 - progress_bar.py[line:274] - INFO: epoch 001:  10324 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3816, wps=102.6, ups=0.48, wpb=107.7, bsz=40, num_updates=10310, lr=4.74477e-05, gnorm=0.415, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=42390
2023-01-07 02:37:51 - progress_bar.py[line:274] - INFO: epoch 001:  10334 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4213, wps=102.3, ups=0.47, wpb=109.5, bsz=40, num_updates=10320, lr=4.74432e-05, gnorm=0.527, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42411
2023-01-07 02:38:13 - progress_bar.py[line:274] - INFO: epoch 001:  10344 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3874, wps=103, ups=0.47, wpb=109.8, bsz=40, num_updates=10330, lr=4.74387e-05, gnorm=0.432, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=42433
2023-01-07 02:38:34 - progress_bar.py[line:274] - INFO: epoch 001:  10354 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4124, wps=103.3, ups=0.47, wpb=109.4, bsz=40, num_updates=10340, lr=4.74342e-05, gnorm=0.59, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42454
2023-01-07 02:38:56 - progress_bar.py[line:274] - INFO: epoch 001:  10364 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3366, wps=102.8, ups=0.47, wpb=110.4, bsz=40, num_updates=10350, lr=4.74297e-05, gnorm=0.39, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=42476
2023-01-07 02:39:19 - progress_bar.py[line:274] - INFO: epoch 001:  10374 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3905, wps=99.7, ups=0.46, wpb=108.2, bsz=40, num_updates=10360, lr=4.74252e-05, gnorm=0.364, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42499
2023-01-07 02:39:41 - progress_bar.py[line:274] - INFO: epoch 001:  10384 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.41, wps=101.6, ups=0.47, wpb=109, bsz=40, num_updates=10370, lr=4.74207e-05, gnorm=0.4, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42520
2023-01-07 02:40:03 - progress_bar.py[line:274] - INFO: epoch 001:  10394 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3874, wps=102.2, ups=0.47, wpb=109.9, bsz=40, num_updates=10380, lr=4.74162e-05, gnorm=0.521, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42543
2023-01-07 02:40:24 - progress_bar.py[line:274] - INFO: epoch 001:  10404 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4752, wps=103.8, ups=0.47, wpb=109.9, bsz=40, num_updates=10390, lr=4.74117e-05, gnorm=0.504, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42564
2023-01-07 02:40:46 - progress_bar.py[line:274] - INFO: epoch 001:  10414 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.35, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=10400, lr=4.74072e-05, gnorm=0.452, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42586
2023-01-07 02:41:08 - progress_bar.py[line:274] - INFO: epoch 001:  10424 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3723, wps=103.9, ups=0.48, wpb=109, bsz=40, num_updates=10410, lr=4.74027e-05, gnorm=0.6, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42608
2023-01-07 02:41:30 - progress_bar.py[line:274] - INFO: epoch 001:  10434 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4109, wps=102.3, ups=0.47, wpb=109.3, bsz=40, num_updates=10420, lr=4.73982e-05, gnorm=0.523, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42630
2023-01-07 02:41:52 - progress_bar.py[line:274] - INFO: epoch 001:  10444 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3731, wps=101, ups=0.47, wpb=108, bsz=40, num_updates=10430, lr=4.73937e-05, gnorm=0.48, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42652
2023-01-07 02:42:14 - progress_bar.py[line:274] - INFO: epoch 001:  10454 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3923, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=10440, lr=4.73892e-05, gnorm=0.471, clip=10, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=42674
2023-01-07 02:42:37 - progress_bar.py[line:274] - INFO: epoch 001:  10464 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4301, wps=101.2, ups=0.46, wpb=110.1, bsz=40, num_updates=10450, lr=4.73847e-05, gnorm=0.449, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=42696
2023-01-07 02:42:59 - progress_bar.py[line:274] - INFO: epoch 001:  10474 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.397, wps=100.3, ups=0.46, wpb=108.5, bsz=40, num_updates=10460, lr=4.73802e-05, gnorm=0.354, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=42719
2023-01-07 02:43:21 - progress_bar.py[line:274] - INFO: epoch 001:  10484 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3918, wps=101.8, ups=0.46, wpb=109.9, bsz=40, num_updates=10470, lr=4.73757e-05, gnorm=0.327, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=42741
2023-01-07 02:43:43 - progress_bar.py[line:274] - INFO: epoch 001:  10494 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3894, wps=99.8, ups=0.46, wpb=109, bsz=40, num_updates=10480, lr=4.73712e-05, gnorm=0.367, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=42763
2023-01-07 02:44:05 - progress_bar.py[line:274] - INFO: epoch 001:  10504 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3455, wps=105.7, ups=0.48, wpb=110.6, bsz=40, num_updates=10490, lr=4.73667e-05, gnorm=0.38, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42785
2023-01-07 02:44:27 - progress_bar.py[line:274] - INFO: epoch 001:  10514 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3641, wps=104.3, ups=0.47, wpb=110.5, bsz=40, num_updates=10500, lr=4.73622e-05, gnorm=0.359, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42807
2023-01-07 02:44:49 - progress_bar.py[line:274] - INFO: epoch 001:  10524 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4038, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=10510, lr=4.73577e-05, gnorm=0.836, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=42829
2023-01-07 02:45:11 - progress_bar.py[line:274] - INFO: epoch 001:  10534 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.436, wps=99.8, ups=0.46, wpb=108.2, bsz=40, num_updates=10520, lr=4.73533e-05, gnorm=0.575, clip=20, loss_scale=256, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=42851
2023-01-07 02:45:33 - progress_bar.py[line:274] - INFO: epoch 001:  10544 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3814, wps=101.1, ups=0.47, wpb=108.5, bsz=40, num_updates=10530, lr=4.73488e-05, gnorm=0.435, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=42873
2023-01-07 02:45:55 - progress_bar.py[line:274] - INFO: epoch 001:  10554 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3687, wps=100.1, ups=0.47, wpb=107.4, bsz=40, num_updates=10540, lr=4.73443e-05, gnorm=0.416, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42895
2023-01-07 02:46:18 - progress_bar.py[line:274] - INFO: epoch 001:  10564 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4265, wps=100, ups=0.46, wpb=108.7, bsz=40, num_updates=10550, lr=4.73398e-05, gnorm=0.378, clip=0, loss_scale=256, train_wall=22, gb_free=9.4, ema_decay=0.9999, wall=42918
2023-01-07 02:46:39 - progress_bar.py[line:274] - INFO: epoch 001:  10574 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3447, wps=101.8, ups=0.47, wpb=107.6, bsz=40, num_updates=10560, lr=4.73353e-05, gnorm=0.388, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42939
2023-01-07 02:47:01 - progress_bar.py[line:274] - INFO: epoch 001:  10584 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4141, wps=102.2, ups=0.47, wpb=109.2, bsz=40, num_updates=10570, lr=4.73308e-05, gnorm=0.474, clip=0, loss_scale=256, train_wall=21, gb_free=9.5, ema_decay=0.9999, wall=42961
2023-01-07 02:47:23 - progress_bar.py[line:274] - INFO: epoch 001:  10594 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3721, wps=104, ups=0.48, wpb=109.4, bsz=40, num_updates=10580, lr=4.73263e-05, gnorm=0.38, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42983
2023-01-07 02:47:45 - progress_bar.py[line:274] - INFO: epoch 001:  10604 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3846, wps=101.9, ups=0.47, wpb=109.4, bsz=40, num_updates=10590, lr=4.73218e-05, gnorm=0.737, clip=10, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=43005
2023-01-07 02:48:07 - progress_bar.py[line:274] - INFO: epoch 001:  10614 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3179, wps=101.1, ups=0.47, wpb=108.5, bsz=40, num_updates=10600, lr=4.73173e-05, gnorm=0.713, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43027
2023-01-07 02:48:29 - progress_bar.py[line:274] - INFO: epoch 001:  10624 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3892, wps=103.1, ups=0.47, wpb=109.7, bsz=40, num_updates=10610, lr=4.73128e-05, gnorm=0.585, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43049
2023-01-07 02:48:51 - progress_bar.py[line:274] - INFO: epoch 001:  10634 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3671, wps=101.4, ups=0.47, wpb=108.4, bsz=40, num_updates=10620, lr=4.73083e-05, gnorm=0.464, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43071
2023-01-07 02:49:12 - progress_bar.py[line:274] - INFO: epoch 001:  10644 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4486, wps=103.8, ups=0.47, wpb=109.7, bsz=40, num_updates=10630, lr=4.73038e-05, gnorm=0.449, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=43092
2023-01-07 02:49:34 - progress_bar.py[line:274] - INFO: epoch 001:  10654 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3557, wps=102.5, ups=0.46, wpb=110.3, bsz=40, num_updates=10640, lr=4.72993e-05, gnorm=0.417, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43114
2023-01-07 02:49:56 - progress_bar.py[line:274] - INFO: epoch 001:  10664 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3589, wps=102.8, ups=0.47, wpb=108.7, bsz=40, num_updates=10650, lr=4.72948e-05, gnorm=0.422, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43136
2023-01-07 02:50:18 - progress_bar.py[line:274] - INFO: epoch 001:  10674 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3557, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=10660, lr=4.72903e-05, gnorm=0.482, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=43158
2023-01-07 02:50:40 - progress_bar.py[line:274] - INFO: epoch 001:  10684 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3796, wps=101.9, ups=0.47, wpb=107.6, bsz=40, num_updates=10670, lr=4.72858e-05, gnorm=0.437, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=43180
2023-01-07 02:51:02 - progress_bar.py[line:274] - INFO: epoch 001:  10694 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3897, wps=101.9, ups=0.46, wpb=109.6, bsz=40, num_updates=10680, lr=4.72813e-05, gnorm=0.463, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43202
2023-01-07 02:51:24 - progress_bar.py[line:274] - INFO: epoch 001:  10704 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.401, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=10690, lr=4.72768e-05, gnorm=0.523, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=43224
2023-01-07 02:51:46 - progress_bar.py[line:274] - INFO: epoch 001:  10714 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3795, wps=100.9, ups=0.47, wpb=108.3, bsz=40, num_updates=10700, lr=4.72723e-05, gnorm=0.345, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43246
2023-01-07 02:52:09 - progress_bar.py[line:274] - INFO: epoch 001:  10724 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3351, wps=99.7, ups=0.45, wpb=109.8, bsz=40, num_updates=10710, lr=4.72678e-05, gnorm=0.418, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=43269
2023-01-07 02:52:31 - progress_bar.py[line:274] - INFO: epoch 001:  10734 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3774, wps=99, ups=0.46, wpb=108.7, bsz=40, num_updates=10720, lr=4.72633e-05, gnorm=0.446, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=43291
2023-01-07 02:52:54 - progress_bar.py[line:274] - INFO: epoch 001:  10744 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4202, wps=101.6, ups=0.46, wpb=110, bsz=40, num_updates=10730, lr=4.72588e-05, gnorm=0.445, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=43314
2023-01-07 02:53:15 - progress_bar.py[line:274] - INFO: epoch 001:  10754 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.402, wps=101.6, ups=0.46, wpb=109.3, bsz=40, num_updates=10740, lr=4.72543e-05, gnorm=0.45, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43336
2023-01-07 02:53:37 - progress_bar.py[line:274] - INFO: epoch 001:  10764 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3892, wps=103.3, ups=0.47, wpb=108.9, bsz=40, num_updates=10750, lr=4.72498e-05, gnorm=0.57, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43357
2023-01-07 02:53:59 - progress_bar.py[line:274] - INFO: epoch 001:  10774 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3781, wps=99.1, ups=0.46, wpb=108, bsz=40, num_updates=10760, lr=4.72454e-05, gnorm=0.461, clip=0, loss_scale=512, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=43379
2023-01-07 02:54:20 - progress_bar.py[line:274] - INFO: epoch 001:  10784 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3876, wps=102.6, ups=0.47, wpb=108.5, bsz=40, num_updates=10770, lr=4.72409e-05, gnorm=0.534, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43400
2023-01-07 02:54:42 - progress_bar.py[line:274] - INFO: epoch 001:  10794 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.393, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=10780, lr=4.72364e-05, gnorm=0.364, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=43422
2023-01-07 02:55:03 - progress_bar.py[line:274] - INFO: epoch 001:  10804 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4239, wps=104.5, ups=0.47, wpb=110.3, bsz=40, num_updates=10790, lr=4.72319e-05, gnorm=0.471, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43443
2023-01-07 02:55:24 - progress_bar.py[line:274] - INFO: epoch 001:  10814 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4162, wps=104.4, ups=0.48, wpb=109.4, bsz=40, num_updates=10800, lr=4.72274e-05, gnorm=0.412, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=43464
2023-01-07 02:55:46 - progress_bar.py[line:274] - INFO: epoch 001:  10824 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3951, wps=100.6, ups=0.46, wpb=108.3, bsz=40, num_updates=10810, lr=4.72229e-05, gnorm=0.343, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=43486
2023-01-07 02:56:08 - progress_bar.py[line:274] - INFO: epoch 001:  10834 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4089, wps=98.1, ups=0.46, wpb=107.5, bsz=40, num_updates=10820, lr=4.72184e-05, gnorm=0.39, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=43508
2023-01-07 02:56:29 - progress_bar.py[line:274] - INFO: epoch 001:  10844 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3807, wps=105.5, ups=0.48, wpb=110.4, bsz=40, num_updates=10830, lr=4.72139e-05, gnorm=0.478, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43530
2023-01-07 02:56:51 - progress_bar.py[line:274] - INFO: epoch 001:  10854 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4045, wps=102.2, ups=0.47, wpb=108.1, bsz=40, num_updates=10840, lr=4.72094e-05, gnorm=0.497, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43551
2023-01-07 02:57:13 - progress_bar.py[line:274] - INFO: epoch 001:  10864 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4115, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=10850, lr=4.72049e-05, gnorm=0.479, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=43573
2023-01-07 02:57:34 - progress_bar.py[line:274] - INFO: epoch 001:  10874 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.415, wps=101.4, ups=0.46, wpb=109.3, bsz=40, num_updates=10860, lr=4.72004e-05, gnorm=0.391, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=43595
2023-01-07 02:57:56 - progress_bar.py[line:274] - INFO: epoch 001:  10884 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3578, wps=98.9, ups=0.46, wpb=108.3, bsz=40, num_updates=10870, lr=4.71959e-05, gnorm=0.418, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=43617
2023-01-07 02:58:18 - progress_bar.py[line:274] - INFO: epoch 001:  10894 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4011, wps=103.9, ups=0.47, wpb=110.8, bsz=40, num_updates=10880, lr=4.71914e-05, gnorm=0.416, clip=10, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=43638
2023-01-07 02:58:40 - progress_bar.py[line:274] - INFO: epoch 001:  10904 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3776, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=10890, lr=4.71869e-05, gnorm=0.477, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43660
2023-01-07 02:59:01 - progress_bar.py[line:274] - INFO: epoch 001:  10914 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4286, wps=101.4, ups=0.46, wpb=109.4, bsz=40, num_updates=10900, lr=4.71824e-05, gnorm=0.426, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=43682
2023-01-07 02:59:23 - progress_bar.py[line:274] - INFO: epoch 001:  10924 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3901, wps=103.7, ups=0.47, wpb=109.9, bsz=40, num_updates=10910, lr=4.71779e-05, gnorm=0.522, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=43703
2023-01-07 02:59:45 - progress_bar.py[line:274] - INFO: epoch 001:  10934 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4278, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=10920, lr=4.71734e-05, gnorm=0.451, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=43725
2023-01-07 03:00:06 - progress_bar.py[line:274] - INFO: epoch 001:  10944 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4314, wps=101.3, ups=0.46, wpb=109.6, bsz=40, num_updates=10930, lr=4.71689e-05, gnorm=0.39, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=43747
2023-01-07 03:00:28 - progress_bar.py[line:274] - INFO: epoch 001:  10954 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3136, wps=98.5, ups=0.46, wpb=107, bsz=40, num_updates=10940, lr=4.71644e-05, gnorm=0.385, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=43769
2023-01-07 03:00:50 - progress_bar.py[line:274] - INFO: epoch 001:  10964 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3673, wps=99.6, ups=0.46, wpb=108.2, bsz=40, num_updates=10950, lr=4.71599e-05, gnorm=0.33, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=43791
2023-01-07 03:01:12 - progress_bar.py[line:274] - INFO: epoch 001:  10974 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4126, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=10960, lr=4.71554e-05, gnorm=0.328, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=43812
2023-01-07 03:01:34 - progress_bar.py[line:274] - INFO: epoch 001:  10984 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4155, wps=101.6, ups=0.47, wpb=109, bsz=40, num_updates=10970, lr=4.71509e-05, gnorm=0.624, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43834
2023-01-07 03:01:55 - progress_bar.py[line:274] - INFO: epoch 001:  10994 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3673, wps=105.3, ups=0.48, wpb=110.2, bsz=40, num_updates=10980, lr=4.71464e-05, gnorm=0.425, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43855
2023-01-07 03:02:17 - progress_bar.py[line:274] - INFO: epoch 001:  11004 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.385, wps=101, ups=0.46, wpb=109.3, bsz=40, num_updates=10990, lr=4.71419e-05, gnorm=0.43, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=43877
2023-01-07 03:02:39 - progress_bar.py[line:274] - INFO: epoch 001:  11014 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4072, wps=100.8, ups=0.46, wpb=108.8, bsz=40, num_updates=11000, lr=4.71374e-05, gnorm=0.36, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=43899
2023-01-07 03:03:00 - progress_bar.py[line:274] - INFO: epoch 001:  11024 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4317, wps=103.4, ups=0.47, wpb=110.2, bsz=40, num_updates=11010, lr=4.7133e-05, gnorm=0.675, clip=30, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43920
2023-01-07 03:03:22 - progress_bar.py[line:274] - INFO: epoch 001:  11034 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4149, wps=100.4, ups=0.46, wpb=109.7, bsz=40, num_updates=11020, lr=4.71285e-05, gnorm=0.517, clip=10, loss_scale=512, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=43942
2023-01-07 03:03:44 - progress_bar.py[line:274] - INFO: epoch 001:  11044 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4279, wps=103.6, ups=0.47, wpb=110.5, bsz=40, num_updates=11030, lr=4.7124e-05, gnorm=0.416, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=43964
2023-01-07 03:04:05 - progress_bar.py[line:274] - INFO: epoch 001:  11054 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4146, wps=101.4, ups=0.47, wpb=108, bsz=40, num_updates=11040, lr=4.71195e-05, gnorm=0.413, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=43986
2023-01-07 03:04:27 - progress_bar.py[line:274] - INFO: epoch 001:  11064 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3892, wps=102.1, ups=0.47, wpb=109.7, bsz=40, num_updates=11050, lr=4.7115e-05, gnorm=0.317, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44007
2023-01-07 03:04:49 - progress_bar.py[line:274] - INFO: epoch 001:  11074 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3866, wps=101.1, ups=0.46, wpb=110, bsz=40, num_updates=11060, lr=4.71105e-05, gnorm=0.316, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44029
2023-01-07 03:05:11 - progress_bar.py[line:274] - INFO: epoch 001:  11084 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.405, wps=99.1, ups=0.45, wpb=109, bsz=40, num_updates=11070, lr=4.7106e-05, gnorm=0.425, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=44051
2023-01-07 03:05:33 - progress_bar.py[line:274] - INFO: epoch 001:  11094 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4407, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=11080, lr=4.71015e-05, gnorm=0.386, clip=0, loss_scale=512, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=44073
2023-01-07 03:05:55 - progress_bar.py[line:274] - INFO: epoch 001:  11104 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3673, wps=101.2, ups=0.47, wpb=108.6, bsz=40, num_updates=11090, lr=4.7097e-05, gnorm=0.435, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44095
2023-01-07 03:06:17 - progress_bar.py[line:274] - INFO: epoch 001:  11114 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3911, wps=100.4, ups=0.46, wpb=108.8, bsz=40, num_updates=11100, lr=4.70925e-05, gnorm=0.487, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=44117
2023-01-07 03:06:39 - progress_bar.py[line:274] - INFO: epoch 001:  11124 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.375, wps=100.8, ups=0.46, wpb=109.7, bsz=40, num_updates=11110, lr=4.7088e-05, gnorm=0.512, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44139
2023-01-07 03:07:00 - progress_bar.py[line:274] - INFO: epoch 001:  11134 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3333, wps=100.2, ups=0.46, wpb=108.7, bsz=40, num_updates=11120, lr=4.70835e-05, gnorm=0.431, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44161
2023-01-07 03:07:22 - progress_bar.py[line:274] - INFO: epoch 001:  11144 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4423, wps=102.3, ups=0.47, wpb=109, bsz=40, num_updates=11130, lr=4.7079e-05, gnorm=0.555, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=44182
2023-01-07 03:07:43 - progress_bar.py[line:274] - INFO: epoch 001:  11154 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4188, wps=103.2, ups=0.47, wpb=110, bsz=40, num_updates=11140, lr=4.70745e-05, gnorm=0.462, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44204
2023-01-07 03:08:05 - progress_bar.py[line:274] - INFO: epoch 001:  11164 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4301, wps=102.3, ups=0.47, wpb=109, bsz=40, num_updates=11150, lr=4.707e-05, gnorm=0.389, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44225
2023-01-07 03:08:27 - progress_bar.py[line:274] - INFO: epoch 001:  11174 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3889, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=11160, lr=4.70655e-05, gnorm=0.448, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44247
2023-01-07 03:08:49 - progress_bar.py[line:274] - INFO: epoch 001:  11184 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.445, wps=101.5, ups=0.47, wpb=109, bsz=40, num_updates=11170, lr=4.7061e-05, gnorm=0.344, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44269
2023-01-07 03:09:11 - progress_bar.py[line:274] - INFO: epoch 001:  11194 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4066, wps=101.7, ups=0.46, wpb=110.3, bsz=40, num_updates=11180, lr=4.70565e-05, gnorm=0.488, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=44291
2023-01-07 03:09:32 - progress_bar.py[line:274] - INFO: epoch 001:  11204 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4356, wps=102, ups=0.46, wpb=110.1, bsz=40, num_updates=11190, lr=4.7052e-05, gnorm=0.376, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44313
2023-01-07 03:09:54 - progress_bar.py[line:274] - INFO: epoch 001:  11214 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4677, wps=102.1, ups=0.47, wpb=109.5, bsz=40, num_updates=11200, lr=4.70475e-05, gnorm=0.426, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=44334
2023-01-07 03:10:16 - progress_bar.py[line:274] - INFO: epoch 001:  11224 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4, wps=98.5, ups=0.46, wpb=107.8, bsz=40, num_updates=11210, lr=4.7043e-05, gnorm=0.774, clip=40, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44356
2023-01-07 03:10:38 - progress_bar.py[line:274] - INFO: epoch 001:  11234 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4021, wps=101.7, ups=0.46, wpb=110.2, bsz=40, num_updates=11220, lr=4.70385e-05, gnorm=0.562, clip=20, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=44378
2023-01-07 03:11:00 - progress_bar.py[line:274] - INFO: epoch 001:  11244 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3553, wps=102, ups=0.47, wpb=109.5, bsz=40, num_updates=11230, lr=4.7034e-05, gnorm=0.468, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44400
2023-01-07 03:11:22 - progress_bar.py[line:274] - INFO: epoch 001:  11254 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4507, wps=99.1, ups=0.46, wpb=107.8, bsz=40, num_updates=11240, lr=4.70295e-05, gnorm=0.345, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44422
2023-01-07 03:11:43 - progress_bar.py[line:274] - INFO: epoch 001:  11264 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4451, wps=102.9, ups=0.46, wpb=110.9, bsz=40, num_updates=11250, lr=4.70251e-05, gnorm=0.34, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=44444
2023-01-07 03:12:05 - progress_bar.py[line:274] - INFO: epoch 001:  11274 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4062, wps=103.7, ups=0.47, wpb=110.2, bsz=40, num_updates=11260, lr=4.70206e-05, gnorm=0.514, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44465
2023-01-07 03:12:20 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 03:12:29 - progress_bar.py[line:274] - INFO: epoch 001:  11285 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.762, nsentences=40, sample_size=109.762, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4231, wps=96.2, ups=0.42, wpb=109.8, bsz=40, num_updates=11270, lr=4.70161e-05, gnorm=0.417, clip=0, loss_scale=512, train_wall=24, gb_free=10, ema_decay=0.9999, wall=44489
2023-01-07 03:12:51 - progress_bar.py[line:274] - INFO: epoch 001:  11295 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4118, wps=100.8, ups=0.46, wpb=109.1, bsz=40, num_updates=11280, lr=4.70116e-05, gnorm=0.454, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=44511
2023-01-07 03:13:13 - progress_bar.py[line:274] - INFO: epoch 001:  11305 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3623, wps=99, ups=0.46, wpb=108.7, bsz=40, num_updates=11290, lr=4.70071e-05, gnorm=0.637, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44533
2023-01-07 03:13:34 - progress_bar.py[line:274] - INFO: epoch 001:  11315 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3641, wps=103.5, ups=0.48, wpb=108.2, bsz=40, num_updates=11300, lr=4.70026e-05, gnorm=0.352, clip=0, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=44555
2023-01-07 03:13:56 - progress_bar.py[line:274] - INFO: epoch 001:  11325 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3802, wps=104.2, ups=0.47, wpb=110.2, bsz=40, num_updates=11310, lr=4.69981e-05, gnorm=0.43, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44576
2023-01-07 03:14:18 - progress_bar.py[line:274] - INFO: epoch 001:  11335 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.378, wps=98.3, ups=0.46, wpb=107.7, bsz=40, num_updates=11320, lr=4.69936e-05, gnorm=0.494, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=44598
2023-01-07 03:14:40 - progress_bar.py[line:274] - INFO: epoch 001:  11345 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4586, wps=102, ups=0.46, wpb=110.4, bsz=40, num_updates=11330, lr=4.69891e-05, gnorm=0.453, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=44620
2023-01-07 03:15:02 - progress_bar.py[line:274] - INFO: epoch 001:  11355 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4512, wps=100.1, ups=0.47, wpb=107.4, bsz=40, num_updates=11340, lr=4.69846e-05, gnorm=0.486, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=44642
2023-01-07 03:15:23 - progress_bar.py[line:274] - INFO: epoch 001:  11365 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3902, wps=103.1, ups=0.47, wpb=109, bsz=40, num_updates=11350, lr=4.69801e-05, gnorm=0.595, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=44663
2023-01-07 03:15:44 - progress_bar.py[line:274] - INFO: epoch 001:  11375 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3762, wps=103.3, ups=0.48, wpb=108.6, bsz=40, num_updates=11360, lr=4.69756e-05, gnorm=1.005, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44684
2023-01-07 03:16:06 - progress_bar.py[line:274] - INFO: epoch 001:  11385 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=106.6, nsentences=40, sample_size=106.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4143, wps=98.3, ups=0.46, wpb=106.6, bsz=40, num_updates=11370, lr=4.69711e-05, gnorm=0.468, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=44706
2023-01-07 03:16:28 - progress_bar.py[line:274] - INFO: epoch 001:  11395 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4408, wps=100.3, ups=0.46, wpb=107.9, bsz=40, num_updates=11380, lr=4.69666e-05, gnorm=0.485, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44728
2023-01-07 03:16:49 - progress_bar.py[line:274] - INFO: epoch 001:  11405 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.457, wps=101.7, ups=0.47, wpb=108.8, bsz=40, num_updates=11390, lr=4.69621e-05, gnorm=0.448, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44750
2023-01-07 03:17:11 - progress_bar.py[line:274] - INFO: epoch 001:  11415 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4879, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=11400, lr=4.69576e-05, gnorm=0.389, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=44771
2023-01-07 03:17:33 - progress_bar.py[line:274] - INFO: epoch 001:  11425 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3854, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=11410, lr=4.69531e-05, gnorm=0.359, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44793
2023-01-07 03:17:55 - progress_bar.py[line:274] - INFO: epoch 001:  11435 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4167, wps=100.6, ups=0.46, wpb=109.2, bsz=40, num_updates=11420, lr=4.69486e-05, gnorm=0.343, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44815
2023-01-07 03:18:17 - progress_bar.py[line:274] - INFO: epoch 001:  11445 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.33, wps=101.5, ups=0.47, wpb=109, bsz=40, num_updates=11430, lr=4.69441e-05, gnorm=0.45, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=44837
2023-01-07 03:18:38 - progress_bar.py[line:274] - INFO: epoch 001:  11455 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4255, wps=103.5, ups=0.47, wpb=109.1, bsz=40, num_updates=11440, lr=4.69396e-05, gnorm=0.641, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44858
2023-01-07 03:18:59 - progress_bar.py[line:274] - INFO: epoch 001:  11465 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.47, wps=104, ups=0.48, wpb=109, bsz=40, num_updates=11450, lr=4.69351e-05, gnorm=0.49, clip=0, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=44879
2023-01-07 03:19:21 - progress_bar.py[line:274] - INFO: epoch 001:  11475 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4612, wps=100.7, ups=0.46, wpb=108.6, bsz=40, num_updates=11460, lr=4.69306e-05, gnorm=0.518, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44901
2023-01-07 03:19:43 - progress_bar.py[line:274] - INFO: epoch 001:  11485 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4195, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=11470, lr=4.69261e-05, gnorm=0.592, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44923
2023-01-07 03:20:04 - progress_bar.py[line:274] - INFO: epoch 001:  11495 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3819, wps=100.6, ups=0.46, wpb=108.4, bsz=40, num_updates=11480, lr=4.69216e-05, gnorm=0.485, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=44944
2023-01-07 03:20:26 - progress_bar.py[line:274] - INFO: epoch 001:  11505 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3851, wps=105.3, ups=0.48, wpb=110.8, bsz=40, num_updates=11490, lr=4.69171e-05, gnorm=0.458, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44966
2023-01-07 03:20:47 - progress_bar.py[line:274] - INFO: epoch 001:  11515 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4045, wps=103.8, ups=0.46, wpb=112, bsz=40, num_updates=11500, lr=4.69127e-05, gnorm=0.491, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44988
2023-01-07 03:21:09 - progress_bar.py[line:274] - INFO: epoch 001:  11525 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3918, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=11510, lr=4.69082e-05, gnorm=0.278, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=45009
2023-01-07 03:21:31 - progress_bar.py[line:274] - INFO: epoch 001:  11535 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=103.1, ups=0.47, wpb=109.8, bsz=40, num_updates=11520, lr=4.69037e-05, gnorm=0.365, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=45031
2023-01-07 03:21:52 - progress_bar.py[line:274] - INFO: epoch 001:  11545 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4101, wps=100.5, ups=0.47, wpb=107.1, bsz=40, num_updates=11530, lr=4.68992e-05, gnorm=0.341, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45052
2023-01-07 03:22:14 - progress_bar.py[line:274] - INFO: epoch 001:  11555 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4093, wps=100.2, ups=0.46, wpb=109, bsz=40, num_updates=11540, lr=4.68947e-05, gnorm=0.532, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45074
2023-01-07 03:22:36 - progress_bar.py[line:274] - INFO: epoch 001:  11565 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4545, wps=104, ups=0.47, wpb=111.1, bsz=40, num_updates=11550, lr=4.68902e-05, gnorm=0.363, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45096
2023-01-07 03:22:57 - progress_bar.py[line:274] - INFO: epoch 001:  11575 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4231, wps=102.4, ups=0.47, wpb=108.4, bsz=40, num_updates=11560, lr=4.68857e-05, gnorm=0.577, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=45117
2023-01-07 03:23:19 - progress_bar.py[line:274] - INFO: epoch 001:  11585 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4255, wps=103, ups=0.47, wpb=110.3, bsz=40, num_updates=11570, lr=4.68812e-05, gnorm=0.45, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=45139
2023-01-07 03:23:40 - progress_bar.py[line:274] - INFO: epoch 001:  11595 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3582, wps=102.1, ups=0.47, wpb=108.1, bsz=40, num_updates=11580, lr=4.68767e-05, gnorm=0.451, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=45161
2023-01-07 03:24:02 - progress_bar.py[line:274] - INFO: epoch 001:  11605 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3455, wps=99.3, ups=0.46, wpb=107.1, bsz=40, num_updates=11590, lr=4.68722e-05, gnorm=0.461, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=45182
2023-01-07 03:24:24 - progress_bar.py[line:274] - INFO: epoch 001:  11615 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3861, wps=99.4, ups=0.46, wpb=108.9, bsz=40, num_updates=11600, lr=4.68677e-05, gnorm=0.551, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=45204
2023-01-07 03:24:46 - progress_bar.py[line:274] - INFO: epoch 001:  11625 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4513, wps=98.8, ups=0.46, wpb=108.2, bsz=40, num_updates=11610, lr=4.68632e-05, gnorm=0.612, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45227
2023-01-07 03:25:08 - progress_bar.py[line:274] - INFO: epoch 001:  11635 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3651, wps=103.2, ups=0.47, wpb=109.7, bsz=40, num_updates=11620, lr=4.68587e-05, gnorm=0.446, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=45248
2023-01-07 03:25:29 - progress_bar.py[line:274] - INFO: epoch 001:  11645 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4192, wps=101.6, ups=0.47, wpb=108.2, bsz=40, num_updates=11630, lr=4.68542e-05, gnorm=0.339, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=45270
2023-01-07 03:25:51 - progress_bar.py[line:274] - INFO: epoch 001:  11655 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.414, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=11640, lr=4.68497e-05, gnorm=0.393, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45291
2023-01-07 03:26:13 - progress_bar.py[line:274] - INFO: epoch 001:  11665 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.402, wps=101.5, ups=0.47, wpb=109, bsz=40, num_updates=11650, lr=4.68452e-05, gnorm=0.603, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=45313
2023-01-07 03:26:35 - progress_bar.py[line:274] - INFO: epoch 001:  11675 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3641, wps=102.3, ups=0.46, wpb=110.1, bsz=40, num_updates=11660, lr=4.68407e-05, gnorm=0.327, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45335
2023-01-07 03:26:57 - progress_bar.py[line:274] - INFO: epoch 001:  11685 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3697, wps=101.3, ups=0.46, wpb=110, bsz=40, num_updates=11670, lr=4.68362e-05, gnorm=0.516, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45357
2023-01-07 03:27:18 - progress_bar.py[line:274] - INFO: epoch 001:  11695 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4308, wps=101.4, ups=0.46, wpb=109.3, bsz=40, num_updates=11680, lr=4.68317e-05, gnorm=0.383, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=45379
2023-01-07 03:27:40 - progress_bar.py[line:274] - INFO: epoch 001:  11705 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4278, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=11690, lr=4.68272e-05, gnorm=0.592, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=45400
2023-01-07 03:28:02 - progress_bar.py[line:274] - INFO: epoch 001:  11715 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=106.4, nsentences=40, sample_size=106.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.379, wps=99, ups=0.47, wpb=106.4, bsz=40, num_updates=11700, lr=4.68227e-05, gnorm=0.394, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=45422
2023-01-07 03:28:23 - progress_bar.py[line:274] - INFO: epoch 001:  11725 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3857, wps=102.1, ups=0.47, wpb=108.7, bsz=40, num_updates=11710, lr=4.68182e-05, gnorm=0.496, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=45444
2023-01-07 03:28:44 - progress_bar.py[line:274] - INFO: epoch 001:  11735 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4461, wps=104.8, ups=0.48, wpb=108.4, bsz=40, num_updates=11720, lr=4.68137e-05, gnorm=0.339, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=45464
2023-01-07 03:29:06 - progress_bar.py[line:274] - INFO: epoch 001:  11745 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3699, wps=104, ups=0.47, wpb=109.8, bsz=40, num_updates=11730, lr=4.68092e-05, gnorm=0.312, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45486
2023-01-07 03:29:27 - progress_bar.py[line:274] - INFO: epoch 001:  11755 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3711, wps=103.7, ups=0.47, wpb=111.1, bsz=40, num_updates=11740, lr=4.68048e-05, gnorm=0.381, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=45507
2023-01-07 03:29:49 - progress_bar.py[line:274] - INFO: epoch 001:  11765 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=101, ups=0.47, wpb=108.5, bsz=40, num_updates=11750, lr=4.68003e-05, gnorm=0.358, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45529
2023-01-07 03:30:11 - progress_bar.py[line:274] - INFO: epoch 001:  11775 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3913, wps=99.8, ups=0.46, wpb=109.7, bsz=40, num_updates=11760, lr=4.67958e-05, gnorm=0.372, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45551
2023-01-07 03:30:32 - progress_bar.py[line:274] - INFO: epoch 001:  11785 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4252, wps=103.2, ups=0.48, wpb=108.6, bsz=40, num_updates=11770, lr=4.67913e-05, gnorm=0.41, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=45573
2023-01-07 03:30:54 - progress_bar.py[line:274] - INFO: epoch 001:  11795 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4118, wps=99.5, ups=0.46, wpb=107.6, bsz=40, num_updates=11780, lr=4.67868e-05, gnorm=0.452, clip=20, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=45595
2023-01-07 03:31:16 - progress_bar.py[line:274] - INFO: epoch 001:  11805 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4586, wps=102.3, ups=0.46, wpb=111.2, bsz=40, num_updates=11790, lr=4.67823e-05, gnorm=0.347, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=45616
2023-01-07 03:31:38 - progress_bar.py[line:274] - INFO: epoch 001:  11815 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3744, wps=102.6, ups=0.47, wpb=108.4, bsz=40, num_updates=11800, lr=4.67778e-05, gnorm=0.47, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45638
2023-01-07 03:31:59 - progress_bar.py[line:274] - INFO: epoch 001:  11825 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4069, wps=101.3, ups=0.47, wpb=108.6, bsz=40, num_updates=11810, lr=4.67733e-05, gnorm=0.403, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=45660
2023-01-07 03:32:20 - progress_bar.py[line:274] - INFO: epoch 001:  11835 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.399, wps=104.1, ups=0.48, wpb=108.8, bsz=40, num_updates=11820, lr=4.67688e-05, gnorm=0.378, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45681
2023-01-07 03:32:42 - progress_bar.py[line:274] - INFO: epoch 001:  11845 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3538, wps=102.3, ups=0.47, wpb=109.1, bsz=40, num_updates=11830, lr=4.67643e-05, gnorm=0.357, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=45702
2023-01-07 03:33:04 - progress_bar.py[line:274] - INFO: epoch 001:  11855 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3555, wps=99.6, ups=0.46, wpb=108.9, bsz=40, num_updates=11840, lr=4.67598e-05, gnorm=0.503, clip=10, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=45724
2023-01-07 03:33:26 - progress_bar.py[line:274] - INFO: epoch 001:  11865 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3687, wps=101.2, ups=0.47, wpb=108.2, bsz=40, num_updates=11850, lr=4.67553e-05, gnorm=0.329, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45746
2023-01-07 03:33:47 - progress_bar.py[line:274] - INFO: epoch 001:  11875 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4029, wps=101.5, ups=0.47, wpb=108.5, bsz=40, num_updates=11860, lr=4.67508e-05, gnorm=0.476, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=45767
2023-01-07 03:34:09 - progress_bar.py[line:274] - INFO: epoch 001:  11885 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3897, wps=100.8, ups=0.46, wpb=109.7, bsz=40, num_updates=11870, lr=4.67463e-05, gnorm=0.497, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=45789
2023-01-07 03:34:31 - progress_bar.py[line:274] - INFO: epoch 001:  11895 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3575, wps=102.1, ups=0.47, wpb=109.6, bsz=40, num_updates=11880, lr=4.67418e-05, gnorm=0.459, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45811
2023-01-07 03:34:52 - progress_bar.py[line:274] - INFO: epoch 001:  11905 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3838, wps=103.9, ups=0.47, wpb=110.8, bsz=40, num_updates=11890, lr=4.67373e-05, gnorm=0.465, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45833
2023-01-07 03:35:15 - progress_bar.py[line:274] - INFO: epoch 001:  11915 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4439, wps=100.9, ups=0.46, wpb=110.3, bsz=40, num_updates=11900, lr=4.67328e-05, gnorm=0.32, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=45855
2023-01-07 03:35:36 - progress_bar.py[line:274] - INFO: epoch 001:  11925 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4084, wps=102.3, ups=0.47, wpb=109.6, bsz=40, num_updates=11910, lr=4.67283e-05, gnorm=0.313, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=45876
2023-01-07 03:35:58 - progress_bar.py[line:274] - INFO: epoch 001:  11935 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4316, wps=101.8, ups=0.46, wpb=109.6, bsz=40, num_updates=11920, lr=4.67238e-05, gnorm=0.46, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45898
2023-01-07 03:36:19 - progress_bar.py[line:274] - INFO: epoch 001:  11945 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4205, wps=103.8, ups=0.47, wpb=109.7, bsz=40, num_updates=11930, lr=4.67193e-05, gnorm=0.587, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=45920
2023-01-07 03:36:41 - progress_bar.py[line:274] - INFO: epoch 001:  11955 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4127, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=11940, lr=4.67148e-05, gnorm=0.323, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=45941
2023-01-07 03:37:03 - progress_bar.py[line:274] - INFO: epoch 001:  11965 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3795, wps=100.6, ups=0.46, wpb=109.1, bsz=40, num_updates=11950, lr=4.67103e-05, gnorm=0.347, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45963
2023-01-07 03:37:25 - progress_bar.py[line:274] - INFO: epoch 001:  11975 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3957, wps=98.7, ups=0.46, wpb=107.1, bsz=40, num_updates=11960, lr=4.67058e-05, gnorm=0.396, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45985
2023-01-07 03:37:46 - progress_bar.py[line:274] - INFO: epoch 001:  11985 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.418, wps=105.1, ups=0.47, wpb=110.8, bsz=40, num_updates=11970, lr=4.67013e-05, gnorm=0.501, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=46007
2023-01-07 03:38:09 - progress_bar.py[line:274] - INFO: epoch 001:  11995 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4478, wps=100.1, ups=0.46, wpb=109.4, bsz=40, num_updates=11980, lr=4.66968e-05, gnorm=0.372, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=46029
2023-01-07 03:38:30 - progress_bar.py[line:274] - INFO: epoch 001:  12005 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4315, wps=101.3, ups=0.46, wpb=109, bsz=40, num_updates=11990, lr=4.66924e-05, gnorm=0.449, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=46050
2023-01-07 03:38:52 - progress_bar.py[line:274] - INFO: epoch 001:  12015 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4337, wps=103, ups=0.48, wpb=108.1, bsz=40, num_updates=12000, lr=4.66879e-05, gnorm=0.393, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=46072
2023-01-07 03:38:52 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 03:38:53 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 03:38:53 - train.py[line:551] - INFO: load:1.31 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 03:41:25 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 03:41:25 - train.py[line:551] - INFO: load:1.34 valid_run:151.28 task_valid:147.31 collect_output:2.79
2023-01-07 03:43:53 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 03:43:53 - train.py[line:551] - INFO: load:1.36 valid_run:299.32 task_valid:289.24 collect_output:7.81
2023-01-07 03:46:25 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 03:46:25 - train.py[line:551] - INFO: load:1.39 valid_run:451.52 task_valid:431.37 collect_output:16.81
2023-01-07 03:48:54 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 03:48:54 - train.py[line:551] - INFO: load:1.41 valid_run:600.39 task_valid:575.27 collect_output:20.74
2023-01-07 03:51:26 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 03:51:26 - train.py[line:551] - INFO: load:1.44 valid_run:752.43 task_valid:721.66 collect_output:25.32
2023-01-07 03:53:58 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 03:53:58 - train.py[line:551] - INFO: load:1.47 valid_run:904.14 task_valid:866.29 collect_output:31.32
2023-01-07 03:56:31 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 03:56:31 - train.py[line:551] - INFO: load:1.49 valid_run:1057.66 task_valid:1010.98 collect_output:39.10
2023-01-07 03:59:03 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 03:59:03 - train.py[line:551] - INFO: load:1.52 valid_run:1209.34 task_valid:1151.10 collect_output:49.58
2023-01-07 04:01:33 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 04:01:33 - train.py[line:551] - INFO: load:1.55 valid_run:1358.72 task_valid:1294.57 collect_output:54.43
2023-01-07 04:04:01 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 04:04:01 - train.py[line:551] - INFO: load:1.57 valid_run:1507.06 task_valid:1436.64 collect_output:59.64
2023-01-07 04:06:31 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 04:06:31 - train.py[line:551] - INFO: load:1.60 valid_run:1656.52 task_valid:1580.19 collect_output:64.51
2023-01-07 04:09:01 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 04:09:01 - train.py[line:551] - INFO: load:1.63 valid_run:1806.68 task_valid:1724.34 collect_output:69.45
2023-01-07 04:11:31 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 04:11:31 - train.py[line:551] - INFO: load:1.65 valid_run:1956.62 task_valid:1864.84 collect_output:77.81
2023-01-07 04:14:01 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 04:14:01 - train.py[line:551] - INFO: load:1.68 valid_run:2106.67 task_valid:2009.20 collect_output:82.45
2023-01-07 04:16:31 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 04:16:31 - train.py[line:551] - INFO: load:1.71 valid_run:2256.21 task_valid:2154.62 collect_output:85.53
2023-01-07 04:19:01 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 04:19:01 - train.py[line:551] - INFO: load:1.73 valid_run:2406.02 task_valid:2297.64 collect_output:91.24
2023-01-07 04:21:33 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 04:21:33 - train.py[line:551] - INFO: load:1.76 valid_run:2558.05 task_valid:2442.20 collect_output:97.66
2023-01-07 04:24:03 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 04:24:03 - train.py[line:551] - INFO: load:1.79 valid_run:2707.96 task_valid:2587.87 collect_output:100.84
2023-01-07 04:26:31 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 04:26:31 - train.py[line:551] - INFO: load:1.81 valid_run:2856.29 task_valid:2728.12 collect_output:107.87
2023-01-07 04:29:01 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 04:29:01 - train.py[line:551] - INFO: load:1.84 valid_run:3006.37 task_valid:2871.94 collect_output:113.07
2023-01-07 04:31:34 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 04:31:34 - train.py[line:551] - INFO: load:1.87 valid_run:3158.81 task_valid:3015.70 collect_output:120.68
2023-01-07 04:34:03 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 04:34:03 - train.py[line:551] - INFO: load:1.89 valid_run:3307.89 task_valid:3159.25 collect_output:125.14
2023-01-07 04:36:34 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 04:36:34 - train.py[line:551] - INFO: load:1.92 valid_run:3458.77 task_valid:3304.19 collect_output:130.03
2023-01-07 04:39:05 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 04:39:05 - train.py[line:551] - INFO: load:1.95 valid_run:3609.76 task_valid:3449.65 collect_output:134.51

====================================================================================================
SGG eval:     R @ 50: 0.4739;     R @ 100: 0.5708;     R @ 500: 0.6299;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2870;    mR @ 100: 0.3734;    mR @ 500: 0.4405;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7634) (covered in:0.5625) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.8448) (says:0.0000) (sitting on:0.6488) (standing on:0.1858) (using:0.6500) (walking in:0.0000) (walking on:0.5946) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4739;     R @ 100: 0.5708;     R @ 500: 0.6299;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2870;    mR @ 100: 0.3734;    mR @ 500: 0.4405;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7634) (covered in:0.5625) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.8448) (says:0.0000) (sitting on:0.6488) (standing on:0.1858) (using:0.6500) (walking in:0.0000) (walking on:0.5946) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-07 04:41:36 - train.py[line:487] - INFO: 0.5707619047619048
2023-01-07 04:41:36 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-07 04:41:36 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.376 | loss_v1 0 | loss_v2 0 | nll_loss 0.227 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.570762 | ppl 1.17 | vqa_score 0.5394 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 12000 | best_R@100 0.637221
2023-01-07 04:41:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 12000 updates
2023-01-07 04:41:36 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_12000.pt
2023-01-07 04:42:19 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_12000.pt
2023-01-07 04:43:50 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 0.5707619047619048) (writing took 134.1724454537034 seconds)
2023-01-07 04:44:12 - progress_bar.py[line:274] - INFO: epoch 001:  12025 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4813, wps=0.6, ups=0, wpb=110.1, bsz=40, num_updates=12010, lr=4.66834e-05, gnorm=0.494, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=49993
2023-01-07 04:44:35 - progress_bar.py[line:274] - INFO: epoch 001:  12035 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4133, wps=99.3, ups=0.46, wpb=108.5, bsz=40, num_updates=12020, lr=4.66789e-05, gnorm=0.415, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=50015
2023-01-07 04:44:56 - progress_bar.py[line:274] - INFO: epoch 001:  12045 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.396, wps=102, ups=0.47, wpb=108.5, bsz=40, num_updates=12030, lr=4.66744e-05, gnorm=0.676, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50036
2023-01-07 04:45:18 - progress_bar.py[line:274] - INFO: epoch 001:  12055 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4433, wps=99.5, ups=0.46, wpb=109, bsz=40, num_updates=12040, lr=4.66699e-05, gnorm=0.304, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=50058
2023-01-07 04:45:40 - progress_bar.py[line:274] - INFO: epoch 001:  12065 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4203, wps=101.3, ups=0.47, wpb=108.7, bsz=40, num_updates=12050, lr=4.66654e-05, gnorm=0.434, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50080
2023-01-07 04:46:02 - progress_bar.py[line:274] - INFO: epoch 001:  12075 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4278, wps=99.8, ups=0.46, wpb=109.3, bsz=40, num_updates=12060, lr=4.66609e-05, gnorm=0.379, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50102
2023-01-07 04:46:24 - progress_bar.py[line:274] - INFO: epoch 001:  12085 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4096, wps=102.6, ups=0.47, wpb=109.4, bsz=40, num_updates=12070, lr=4.66564e-05, gnorm=0.347, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=50124
2023-01-07 04:46:45 - progress_bar.py[line:274] - INFO: epoch 001:  12095 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4105, wps=102, ups=0.47, wpb=109, bsz=40, num_updates=12080, lr=4.66519e-05, gnorm=0.543, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50145
2023-01-07 04:47:07 - progress_bar.py[line:274] - INFO: epoch 001:  12105 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3907, wps=102, ups=0.47, wpb=108.6, bsz=40, num_updates=12090, lr=4.66474e-05, gnorm=0.523, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=50167
2023-01-07 04:47:28 - progress_bar.py[line:274] - INFO: epoch 001:  12115 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4183, wps=103.2, ups=0.47, wpb=109, bsz=40, num_updates=12100, lr=4.66429e-05, gnorm=0.37, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=50188
2023-01-07 04:47:50 - progress_bar.py[line:274] - INFO: epoch 001:  12125 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4163, wps=101, ups=0.46, wpb=108.7, bsz=40, num_updates=12110, lr=4.66384e-05, gnorm=0.418, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50210
2023-01-07 04:48:11 - progress_bar.py[line:274] - INFO: epoch 001:  12135 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4256, wps=101.7, ups=0.47, wpb=109.3, bsz=40, num_updates=12120, lr=4.66339e-05, gnorm=0.44, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=50232
2023-01-07 04:48:33 - progress_bar.py[line:274] - INFO: epoch 001:  12145 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4264, wps=100.4, ups=0.46, wpb=109.3, bsz=40, num_updates=12130, lr=4.66294e-05, gnorm=0.327, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=50254
2023-01-07 04:48:55 - progress_bar.py[line:274] - INFO: epoch 001:  12155 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4171, wps=102, ups=0.47, wpb=109.6, bsz=40, num_updates=12140, lr=4.66249e-05, gnorm=0.454, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50275
2023-01-07 04:49:17 - progress_bar.py[line:274] - INFO: epoch 001:  12165 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4185, wps=102.3, ups=0.47, wpb=108.9, bsz=40, num_updates=12150, lr=4.66204e-05, gnorm=0.333, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50297
2023-01-07 04:49:39 - progress_bar.py[line:274] - INFO: epoch 001:  12175 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4138, wps=97.9, ups=0.45, wpb=108.1, bsz=40, num_updates=12160, lr=4.66159e-05, gnorm=0.573, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=50319
2023-01-07 04:50:01 - progress_bar.py[line:274] - INFO: epoch 001:  12185 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4385, wps=100.8, ups=0.46, wpb=109.6, bsz=40, num_updates=12170, lr=4.66114e-05, gnorm=0.454, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=50341
2023-01-07 04:50:22 - progress_bar.py[line:274] - INFO: epoch 001:  12195 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4516, wps=103.8, ups=0.47, wpb=109.4, bsz=40, num_updates=12180, lr=4.66069e-05, gnorm=0.466, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=50362
2023-01-07 04:50:44 - progress_bar.py[line:274] - INFO: epoch 001:  12205 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4197, wps=103.2, ups=0.47, wpb=110, bsz=40, num_updates=12190, lr=4.66024e-05, gnorm=0.312, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50384
2023-01-07 04:51:06 - progress_bar.py[line:274] - INFO: epoch 001:  12215 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4466, wps=100, ups=0.46, wpb=108.6, bsz=40, num_updates=12200, lr=4.65979e-05, gnorm=0.442, clip=10, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=50406
2023-01-07 04:51:28 - progress_bar.py[line:274] - INFO: epoch 001:  12225 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3596, wps=100.4, ups=0.46, wpb=108.7, bsz=40, num_updates=12210, lr=4.65934e-05, gnorm=0.255, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=50428
2023-01-07 04:51:49 - progress_bar.py[line:274] - INFO: epoch 001:  12235 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4375, wps=101.1, ups=0.46, wpb=109.7, bsz=40, num_updates=12220, lr=4.65889e-05, gnorm=0.284, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=50450
2023-01-07 04:52:11 - progress_bar.py[line:274] - INFO: epoch 001:  12245 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4286, wps=104.3, ups=0.47, wpb=110, bsz=40, num_updates=12230, lr=4.65845e-05, gnorm=0.329, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=50471
2023-01-07 04:52:33 - progress_bar.py[line:274] - INFO: epoch 001:  12255 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4398, wps=101.4, ups=0.46, wpb=109, bsz=40, num_updates=12240, lr=4.658e-05, gnorm=0.347, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50493
2023-01-07 04:52:54 - progress_bar.py[line:274] - INFO: epoch 001:  12265 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4087, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=12250, lr=4.65755e-05, gnorm=0.446, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=50514
2023-01-07 04:53:16 - progress_bar.py[line:274] - INFO: epoch 001:  12275 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4495, wps=101.2, ups=0.46, wpb=110.1, bsz=40, num_updates=12260, lr=4.6571e-05, gnorm=0.63, clip=10, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=50536
2023-01-07 04:53:38 - progress_bar.py[line:274] - INFO: epoch 001:  12285 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4053, wps=101.5, ups=0.47, wpb=109.1, bsz=40, num_updates=12270, lr=4.65665e-05, gnorm=0.339, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=50558
2023-01-07 04:53:59 - progress_bar.py[line:274] - INFO: epoch 001:  12295 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4089, wps=101.8, ups=0.47, wpb=108.4, bsz=40, num_updates=12280, lr=4.6562e-05, gnorm=0.301, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=50580
2023-01-07 04:54:21 - progress_bar.py[line:274] - INFO: epoch 001:  12305 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3743, wps=102.4, ups=0.47, wpb=109.7, bsz=40, num_updates=12290, lr=4.65575e-05, gnorm=0.573, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50601
2023-01-07 04:54:43 - progress_bar.py[line:274] - INFO: epoch 001:  12315 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4486, wps=100.6, ups=0.46, wpb=109.1, bsz=40, num_updates=12300, lr=4.6553e-05, gnorm=0.272, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50623
2023-01-07 04:55:04 - progress_bar.py[line:274] - INFO: epoch 001:  12325 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3922, wps=102.9, ups=0.47, wpb=109.9, bsz=40, num_updates=12310, lr=4.65485e-05, gnorm=0.354, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50645
2023-01-07 04:55:26 - progress_bar.py[line:274] - INFO: epoch 001:  12335 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4724, wps=101.4, ups=0.47, wpb=108.7, bsz=40, num_updates=12320, lr=4.6544e-05, gnorm=0.533, clip=10, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50666
2023-01-07 04:55:47 - progress_bar.py[line:274] - INFO: epoch 001:  12345 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4439, wps=104.9, ups=0.47, wpb=110.9, bsz=40, num_updates=12330, lr=4.65395e-05, gnorm=0.35, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50688
2023-01-07 04:56:05 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-07 04:56:12 - progress_bar.py[line:274] - INFO: epoch 001:  12356 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.333, nsentences=40, sample_size=109.333, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4701, wps=96.5, ups=0.42, wpb=109.3, bsz=40, num_updates=12340, lr=4.6535e-05, gnorm=0.34, clip=0, loss_scale=1024, train_wall=24, gb_free=10.4, ema_decay=0.9999, wall=50712
2023-01-07 04:56:34 - progress_bar.py[line:274] - INFO: epoch 001:  12366 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3781, wps=97.5, ups=0.46, wpb=107.1, bsz=40, num_updates=12350, lr=4.65305e-05, gnorm=0.425, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=50734
2023-01-07 04:56:54 - progress_bar.py[line:274] - INFO: epoch 001:  12376 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4187, wps=106.5, ups=0.49, wpb=109.3, bsz=40, num_updates=12360, lr=4.6526e-05, gnorm=0.37, clip=0, loss_scale=1024, train_wall=20, gb_free=10.2, ema_decay=0.9999, wall=50755
2023-01-07 04:57:16 - progress_bar.py[line:274] - INFO: epoch 001:  12386 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4348, wps=102, ups=0.46, wpb=110.5, bsz=40, num_updates=12370, lr=4.65215e-05, gnorm=0.346, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=50777
2023-01-07 04:57:38 - progress_bar.py[line:274] - INFO: epoch 001:  12396 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4265, wps=101.4, ups=0.46, wpb=109.3, bsz=40, num_updates=12380, lr=4.6517e-05, gnorm=0.396, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=50798
2023-01-07 04:58:00 - progress_bar.py[line:274] - INFO: epoch 001:  12406 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.403, wps=102.2, ups=0.47, wpb=109.6, bsz=40, num_updates=12390, lr=4.65125e-05, gnorm=0.612, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50820
2023-01-07 04:58:21 - progress_bar.py[line:274] - INFO: epoch 001:  12416 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4263, wps=102.2, ups=0.47, wpb=109.4, bsz=40, num_updates=12400, lr=4.6508e-05, gnorm=0.361, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=50842
2023-01-07 04:58:43 - progress_bar.py[line:274] - INFO: epoch 001:  12426 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.455, wps=102.8, ups=0.47, wpb=108.9, bsz=40, num_updates=12410, lr=4.65035e-05, gnorm=0.324, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=50863
2023-01-07 04:59:05 - progress_bar.py[line:274] - INFO: epoch 001:  12436 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3831, wps=100.4, ups=0.46, wpb=109.7, bsz=40, num_updates=12420, lr=4.6499e-05, gnorm=0.326, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50885
2023-01-07 04:59:26 - progress_bar.py[line:274] - INFO: epoch 001:  12446 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.401, wps=103.8, ups=0.47, wpb=110.7, bsz=40, num_updates=12430, lr=4.64945e-05, gnorm=0.31, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=50907
2023-01-07 04:59:48 - progress_bar.py[line:274] - INFO: epoch 001:  12456 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3803, wps=100.1, ups=0.47, wpb=107.3, bsz=40, num_updates=12440, lr=4.649e-05, gnorm=0.494, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50928
2023-01-07 05:00:10 - progress_bar.py[line:274] - INFO: epoch 001:  12466 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4227, wps=101, ups=0.47, wpb=108.3, bsz=40, num_updates=12450, lr=4.64855e-05, gnorm=0.326, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50950
2023-01-07 05:00:20 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 05:00:33 - progress_bar.py[line:274] - INFO: epoch 001:  12477 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.476, nsentences=40, sample_size=109.476, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4344, wps=98.9, ups=0.43, wpb=109.5, bsz=40, num_updates=12460, lr=4.6481e-05, gnorm=0.429, clip=0, loss_scale=512, train_wall=23, gb_free=10.6, ema_decay=0.9999, wall=50973
2023-01-07 05:00:55 - progress_bar.py[line:274] - INFO: epoch 001:  12487 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4271, wps=101.7, ups=0.47, wpb=108.4, bsz=40, num_updates=12470, lr=4.64765e-05, gnorm=0.257, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50995
2023-01-07 05:01:16 - progress_bar.py[line:274] - INFO: epoch 001:  12497 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3632, wps=101, ups=0.46, wpb=108.7, bsz=40, num_updates=12480, lr=4.64721e-05, gnorm=0.347, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=51017
2023-01-07 05:01:38 - progress_bar.py[line:274] - INFO: epoch 001:  12507 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4043, wps=102.3, ups=0.46, wpb=110, bsz=40, num_updates=12490, lr=4.64676e-05, gnorm=0.513, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51038
2023-01-07 05:02:00 - progress_bar.py[line:274] - INFO: epoch 001:  12517 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4235, wps=103.5, ups=0.47, wpb=109.2, bsz=40, num_updates=12500, lr=4.64631e-05, gnorm=0.4, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=51060
2023-01-07 05:02:21 - progress_bar.py[line:274] - INFO: epoch 001:  12527 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3951, wps=101.9, ups=0.47, wpb=109.5, bsz=40, num_updates=12510, lr=4.64586e-05, gnorm=0.269, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51081
2023-01-07 05:02:43 - progress_bar.py[line:274] - INFO: epoch 001:  12537 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4696, wps=101.3, ups=0.46, wpb=110.1, bsz=40, num_updates=12520, lr=4.64541e-05, gnorm=0.341, clip=0, loss_scale=512, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=51103
2023-01-07 05:03:05 - progress_bar.py[line:274] - INFO: epoch 001:  12547 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4416, wps=100.8, ups=0.46, wpb=109.2, bsz=40, num_updates=12530, lr=4.64496e-05, gnorm=0.309, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=51125
2023-01-07 05:03:09 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-07 05:03:29 - progress_bar.py[line:274] - INFO: epoch 001:  12558 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.333, nsentences=40, sample_size=107.333, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4574, wps=97, ups=0.43, wpb=107.3, bsz=40, num_updates=12540, lr=4.64451e-05, gnorm=0.666, clip=20, loss_scale=256, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=51149
2023-01-07 05:03:50 - progress_bar.py[line:274] - INFO: epoch 001:  12568 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4306, wps=101.4, ups=0.47, wpb=108.5, bsz=40, num_updates=12550, lr=4.64406e-05, gnorm=0.299, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51170
2023-01-07 05:04:12 - progress_bar.py[line:274] - INFO: epoch 001:  12578 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3825, wps=101.1, ups=0.46, wpb=110.5, bsz=40, num_updates=12560, lr=4.64361e-05, gnorm=0.547, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=51192
2023-01-07 05:04:34 - progress_bar.py[line:274] - INFO: epoch 001:  12588 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3738, wps=100.1, ups=0.46, wpb=109.6, bsz=40, num_updates=12570, lr=4.64316e-05, gnorm=0.369, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=51215
2023-01-07 05:04:56 - progress_bar.py[line:274] - INFO: epoch 001:  12598 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4408, wps=100, ups=0.46, wpb=108.3, bsz=40, num_updates=12580, lr=4.64271e-05, gnorm=0.416, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=51236
2023-01-07 05:05:18 - progress_bar.py[line:274] - INFO: epoch 001:  12608 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3627, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=12590, lr=4.64226e-05, gnorm=0.385, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51258
2023-01-07 05:05:40 - progress_bar.py[line:274] - INFO: epoch 001:  12618 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3782, wps=99.8, ups=0.46, wpb=108.3, bsz=40, num_updates=12600, lr=4.64181e-05, gnorm=0.438, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51280
2023-01-07 05:06:02 - progress_bar.py[line:274] - INFO: epoch 001:  12628 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3698, wps=101, ups=0.46, wpb=109.5, bsz=40, num_updates=12610, lr=4.64136e-05, gnorm=0.621, clip=20, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=51302
2023-01-07 05:06:23 - progress_bar.py[line:274] - INFO: epoch 001:  12638 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4381, wps=103.7, ups=0.47, wpb=109.5, bsz=40, num_updates=12620, lr=4.64091e-05, gnorm=0.447, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51323
2023-01-07 05:06:45 - progress_bar.py[line:274] - INFO: epoch 001:  12648 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.407, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=12630, lr=4.64046e-05, gnorm=0.439, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51345
2023-01-07 05:07:07 - progress_bar.py[line:274] - INFO: epoch 001:  12658 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3981, wps=100.4, ups=0.46, wpb=108.1, bsz=40, num_updates=12640, lr=4.64001e-05, gnorm=0.572, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51367
2023-01-07 05:07:29 - progress_bar.py[line:274] - INFO: epoch 001:  12668 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3469, wps=101.2, ups=0.47, wpb=108.6, bsz=40, num_updates=12650, lr=4.63956e-05, gnorm=0.423, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51389
2023-01-07 05:07:51 - progress_bar.py[line:274] - INFO: epoch 001:  12678 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4167, wps=101.4, ups=0.46, wpb=110, bsz=40, num_updates=12660, lr=4.63911e-05, gnorm=0.58, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=51411
2023-01-07 05:08:12 - progress_bar.py[line:274] - INFO: epoch 001:  12688 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.392, wps=101.7, ups=0.46, wpb=110.2, bsz=40, num_updates=12670, lr=4.63866e-05, gnorm=0.382, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51433
2023-01-07 05:08:34 - progress_bar.py[line:274] - INFO: epoch 001:  12698 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4278, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=12680, lr=4.63821e-05, gnorm=0.652, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51454
2023-01-07 05:08:56 - progress_bar.py[line:274] - INFO: epoch 001:  12708 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3889, wps=102, ups=0.47, wpb=108.7, bsz=40, num_updates=12690, lr=4.63776e-05, gnorm=0.407, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51476
2023-01-07 05:09:18 - progress_bar.py[line:274] - INFO: epoch 001:  12718 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4346, wps=99.4, ups=0.46, wpb=109.1, bsz=40, num_updates=12700, lr=4.63731e-05, gnorm=0.331, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=51498
2023-01-07 05:09:39 - progress_bar.py[line:274] - INFO: epoch 001:  12728 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3653, wps=103, ups=0.47, wpb=108.7, bsz=40, num_updates=12710, lr=4.63686e-05, gnorm=0.501, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51519
2023-01-07 05:10:01 - progress_bar.py[line:274] - INFO: epoch 001:  12738 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4126, wps=100.2, ups=0.47, wpb=107.7, bsz=40, num_updates=12720, lr=4.63642e-05, gnorm=0.5, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=51541
2023-01-07 05:10:22 - progress_bar.py[line:274] - INFO: epoch 001:  12748 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4368, wps=104.9, ups=0.48, wpb=110.2, bsz=40, num_updates=12730, lr=4.63597e-05, gnorm=0.451, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51562
2023-01-07 05:10:44 - progress_bar.py[line:274] - INFO: epoch 001:  12758 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4093, wps=101.5, ups=0.47, wpb=109.1, bsz=40, num_updates=12740, lr=4.63552e-05, gnorm=0.442, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51584
2023-01-07 05:11:06 - progress_bar.py[line:274] - INFO: epoch 001:  12768 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4475, wps=101.7, ups=0.46, wpb=110.3, bsz=40, num_updates=12750, lr=4.63507e-05, gnorm=0.537, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=51606
2023-01-07 05:11:27 - progress_bar.py[line:274] - INFO: epoch 001:  12778 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4406, wps=101.9, ups=0.47, wpb=109.4, bsz=40, num_updates=12760, lr=4.63462e-05, gnorm=0.269, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=51628
2023-01-07 05:11:49 - progress_bar.py[line:274] - INFO: epoch 001:  12788 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4031, wps=102.4, ups=0.47, wpb=108.7, bsz=40, num_updates=12770, lr=4.63417e-05, gnorm=0.41, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=51649
2023-01-07 05:12:11 - progress_bar.py[line:274] - INFO: epoch 001:  12798 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4372, wps=99.2, ups=0.46, wpb=107.6, bsz=40, num_updates=12780, lr=4.63372e-05, gnorm=0.295, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=51671
2023-01-07 05:12:32 - progress_bar.py[line:274] - INFO: epoch 001:  12808 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.2, nsentences=40, sample_size=106.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3716, wps=99.2, ups=0.47, wpb=106.2, bsz=40, num_updates=12790, lr=4.63327e-05, gnorm=0.443, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51693
2023-01-07 05:12:54 - progress_bar.py[line:274] - INFO: epoch 001:  12818 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4352, wps=103.3, ups=0.47, wpb=109.1, bsz=40, num_updates=12800, lr=4.63282e-05, gnorm=0.406, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51714
2023-01-07 05:13:15 - progress_bar.py[line:274] - INFO: epoch 001:  12828 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4271, wps=102.9, ups=0.47, wpb=110.1, bsz=40, num_updates=12810, lr=4.63237e-05, gnorm=0.417, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51736
2023-01-07 05:13:38 - progress_bar.py[line:274] - INFO: epoch 001:  12838 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3768, wps=98.9, ups=0.46, wpb=108.3, bsz=40, num_updates=12820, lr=4.63192e-05, gnorm=0.579, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=51758
2023-01-07 05:13:59 - progress_bar.py[line:274] - INFO: epoch 001:  12848 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3838, wps=101.8, ups=0.47, wpb=109.4, bsz=40, num_updates=12830, lr=4.63147e-05, gnorm=0.376, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51779
2023-01-07 05:14:20 - progress_bar.py[line:274] - INFO: epoch 001:  12858 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4471, wps=103.9, ups=0.48, wpb=108.8, bsz=40, num_updates=12840, lr=4.63102e-05, gnorm=0.395, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51801
2023-01-07 05:14:42 - progress_bar.py[line:274] - INFO: epoch 001:  12868 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4688, wps=103.4, ups=0.47, wpb=110.1, bsz=40, num_updates=12850, lr=4.63057e-05, gnorm=0.424, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51822
2023-01-07 05:15:04 - progress_bar.py[line:274] - INFO: epoch 001:  12878 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4346, wps=100.9, ups=0.46, wpb=110, bsz=40, num_updates=12860, lr=4.63012e-05, gnorm=0.347, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=51844
2023-01-07 05:15:26 - progress_bar.py[line:274] - INFO: epoch 001:  12888 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4456, wps=100.6, ups=0.46, wpb=109.1, bsz=40, num_updates=12870, lr=4.62967e-05, gnorm=0.441, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51866
2023-01-07 05:15:47 - progress_bar.py[line:274] - INFO: epoch 001:  12898 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3874, wps=105, ups=0.48, wpb=110.4, bsz=40, num_updates=12880, lr=4.62922e-05, gnorm=0.202, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51887
2023-01-07 05:16:08 - progress_bar.py[line:274] - INFO: epoch 001:  12908 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4098, wps=103.9, ups=0.47, wpb=110.3, bsz=40, num_updates=12890, lr=4.62877e-05, gnorm=0.321, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51909
2023-01-07 05:16:30 - progress_bar.py[line:274] - INFO: epoch 001:  12918 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4236, wps=102.2, ups=0.47, wpb=108.9, bsz=40, num_updates=12900, lr=4.62832e-05, gnorm=0.384, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51930
2023-01-07 05:16:51 - progress_bar.py[line:274] - INFO: epoch 001:  12928 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.402, wps=102.9, ups=0.47, wpb=108.8, bsz=40, num_updates=12910, lr=4.62787e-05, gnorm=0.3, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51952
2023-01-07 05:17:13 - progress_bar.py[line:274] - INFO: epoch 001:  12938 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3838, wps=100.9, ups=0.46, wpb=109.4, bsz=40, num_updates=12920, lr=4.62742e-05, gnorm=0.435, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51974
2023-01-07 05:17:35 - progress_bar.py[line:274] - INFO: epoch 001:  12948 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4129, wps=100.4, ups=0.46, wpb=109.2, bsz=40, num_updates=12930, lr=4.62697e-05, gnorm=0.468, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51995
2023-01-07 05:17:57 - progress_bar.py[line:274] - INFO: epoch 001:  12958 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.401, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=12940, lr=4.62652e-05, gnorm=0.459, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=52017
2023-01-07 05:18:19 - progress_bar.py[line:274] - INFO: epoch 001:  12968 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.401, wps=101.2, ups=0.47, wpb=108.5, bsz=40, num_updates=12950, lr=4.62607e-05, gnorm=0.522, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52039
2023-01-07 05:18:40 - progress_bar.py[line:274] - INFO: epoch 001:  12978 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=102.2, ups=0.47, wpb=108.2, bsz=40, num_updates=12960, lr=4.62562e-05, gnorm=0.447, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52060
2023-01-07 05:19:02 - progress_bar.py[line:274] - INFO: epoch 001:  12988 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4053, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=12970, lr=4.62518e-05, gnorm=0.582, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52082
2023-01-07 05:19:23 - progress_bar.py[line:274] - INFO: epoch 001:  12998 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4581, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=12980, lr=4.62473e-05, gnorm=0.38, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52104
2023-01-07 05:19:46 - progress_bar.py[line:274] - INFO: epoch 001:  13008 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4197, wps=98.9, ups=0.46, wpb=108.5, bsz=40, num_updates=12990, lr=4.62428e-05, gnorm=0.588, clip=10, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=52126
2023-01-07 05:20:07 - progress_bar.py[line:274] - INFO: epoch 001:  13018 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4087, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=13000, lr=4.62383e-05, gnorm=0.417, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52148
2023-01-07 05:20:28 - progress_bar.py[line:274] - INFO: epoch 001:  13028 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4409, wps=105.9, ups=0.48, wpb=110, bsz=40, num_updates=13010, lr=4.62338e-05, gnorm=0.381, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52169
2023-01-07 05:20:50 - progress_bar.py[line:274] - INFO: epoch 001:  13038 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3578, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=13020, lr=4.62293e-05, gnorm=0.433, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52191
2023-01-07 05:20:52 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-01-07 05:21:14 - progress_bar.py[line:274] - INFO: epoch 001:  13049 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.143, nsentences=40, sample_size=109.143, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5049, wps=97.9, ups=0.43, wpb=109.1, bsz=40, num_updates=13030, lr=4.62248e-05, gnorm=0.423, clip=10, loss_scale=128, train_wall=23, gb_free=10.4, ema_decay=0.9999, wall=52214
2023-01-07 05:21:35 - progress_bar.py[line:274] - INFO: epoch 001:  13059 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3831, wps=102.4, ups=0.47, wpb=108.7, bsz=40, num_updates=13040, lr=4.62203e-05, gnorm=0.406, clip=10, loss_scale=128, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=52236
2023-01-07 05:21:57 - progress_bar.py[line:274] - INFO: epoch 001:  13069 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4434, wps=99.4, ups=0.46, wpb=107.7, bsz=40, num_updates=13050, lr=4.62158e-05, gnorm=0.358, clip=0, loss_scale=128, train_wall=22, gb_free=10, ema_decay=0.9999, wall=52257
2023-01-07 05:22:19 - progress_bar.py[line:274] - INFO: epoch 001:  13079 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4337, wps=102.2, ups=0.47, wpb=108.2, bsz=40, num_updates=13060, lr=4.62113e-05, gnorm=0.506, clip=10, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52279
2023-01-07 05:22:41 - progress_bar.py[line:274] - INFO: epoch 001:  13089 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4195, wps=98.2, ups=0.46, wpb=107.6, bsz=40, num_updates=13070, lr=4.62068e-05, gnorm=0.312, clip=10, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52301
2023-01-07 05:23:03 - progress_bar.py[line:274] - INFO: epoch 001:  13099 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3978, wps=103, ups=0.47, wpb=110.2, bsz=40, num_updates=13080, lr=4.62023e-05, gnorm=0.325, clip=0, loss_scale=128, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=52323
2023-01-07 05:23:25 - progress_bar.py[line:274] - INFO: epoch 001:  13109 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4029, wps=99.3, ups=0.46, wpb=107.9, bsz=40, num_updates=13090, lr=4.61978e-05, gnorm=0.357, clip=0, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=52345
2023-01-07 05:23:47 - progress_bar.py[line:274] - INFO: epoch 001:  13119 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4924, wps=100, ups=0.46, wpb=108.7, bsz=40, num_updates=13100, lr=4.61933e-05, gnorm=0.361, clip=0, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=52367
2023-01-07 05:24:09 - progress_bar.py[line:274] - INFO: epoch 001:  13129 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4567, wps=99.9, ups=0.46, wpb=108.1, bsz=40, num_updates=13110, lr=4.61888e-05, gnorm=0.458, clip=10, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=52389
2023-01-07 05:24:30 - progress_bar.py[line:274] - INFO: epoch 001:  13139 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4485, wps=102.4, ups=0.47, wpb=109.3, bsz=40, num_updates=13120, lr=4.61843e-05, gnorm=0.4, clip=0, loss_scale=128, train_wall=21, gb_free=10, ema_decay=0.9999, wall=52410
2023-01-07 05:24:52 - progress_bar.py[line:274] - INFO: epoch 001:  13149 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4135, wps=101.8, ups=0.47, wpb=108.4, bsz=40, num_updates=13130, lr=4.61798e-05, gnorm=0.606, clip=10, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52432
2023-01-07 05:25:13 - progress_bar.py[line:274] - INFO: epoch 001:  13159 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4332, wps=103, ups=0.47, wpb=110.2, bsz=40, num_updates=13140, lr=4.61753e-05, gnorm=0.381, clip=10, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52453
2023-01-07 05:25:34 - progress_bar.py[line:274] - INFO: epoch 001:  13169 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3966, wps=105.8, ups=0.48, wpb=111.1, bsz=40, num_updates=13150, lr=4.61708e-05, gnorm=0.394, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52475
2023-01-07 05:25:56 - progress_bar.py[line:274] - INFO: epoch 001:  13179 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3804, wps=102.1, ups=0.46, wpb=109.9, bsz=40, num_updates=13160, lr=4.61663e-05, gnorm=0.317, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52496
2023-01-07 05:26:18 - progress_bar.py[line:274] - INFO: epoch 001:  13189 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.355, wps=100.1, ups=0.45, wpb=110.1, bsz=40, num_updates=13170, lr=4.61618e-05, gnorm=0.308, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52519
2023-01-07 05:26:40 - progress_bar.py[line:274] - INFO: epoch 001:  13199 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.388, wps=102.5, ups=0.47, wpb=109.2, bsz=40, num_updates=13180, lr=4.61573e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52540
2023-01-07 05:27:02 - progress_bar.py[line:274] - INFO: epoch 001:  13209 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3958, wps=101.6, ups=0.47, wpb=109.1, bsz=40, num_updates=13190, lr=4.61528e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=52562
2023-01-07 05:27:23 - progress_bar.py[line:274] - INFO: epoch 001:  13219 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.403, wps=103.2, ups=0.47, wpb=110.6, bsz=40, num_updates=13200, lr=4.61483e-05, gnorm=0.289, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52583
2023-01-07 05:27:45 - progress_bar.py[line:274] - INFO: epoch 001:  13229 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3854, wps=99.9, ups=0.46, wpb=108.5, bsz=40, num_updates=13210, lr=4.61439e-05, gnorm=0.355, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52605
2023-01-07 05:28:07 - progress_bar.py[line:274] - INFO: epoch 001:  13239 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=106.6, nsentences=40, sample_size=106.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.448, wps=99.4, ups=0.47, wpb=106.6, bsz=40, num_updates=13220, lr=4.61394e-05, gnorm=0.318, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52627
2023-01-07 05:28:28 - progress_bar.py[line:274] - INFO: epoch 001:  13249 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4747, wps=102.6, ups=0.47, wpb=109.3, bsz=40, num_updates=13230, lr=4.61349e-05, gnorm=0.355, clip=0, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=52649
2023-01-07 05:28:50 - progress_bar.py[line:274] - INFO: epoch 001:  13259 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4293, wps=101.9, ups=0.46, wpb=110.6, bsz=40, num_updates=13240, lr=4.61304e-05, gnorm=0.684, clip=10, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=52671
2023-01-07 05:29:12 - progress_bar.py[line:274] - INFO: epoch 001:  13269 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3456, wps=102.3, ups=0.47, wpb=108, bsz=40, num_updates=13250, lr=4.61259e-05, gnorm=0.347, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52692
2023-01-07 05:29:33 - progress_bar.py[line:274] - INFO: epoch 001:  13279 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4197, wps=104.2, ups=0.47, wpb=110.2, bsz=40, num_updates=13260, lr=4.61214e-05, gnorm=0.301, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52713
2023-01-07 05:29:55 - progress_bar.py[line:274] - INFO: epoch 001:  13289 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4785, wps=101.9, ups=0.47, wpb=108.4, bsz=40, num_updates=13270, lr=4.61169e-05, gnorm=0.26, clip=0, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=52735
2023-01-07 05:30:16 - progress_bar.py[line:274] - INFO: epoch 001:  13299 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3838, wps=105.5, ups=0.48, wpb=109.5, bsz=40, num_updates=13280, lr=4.61124e-05, gnorm=0.294, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52756
2023-01-07 05:30:37 - progress_bar.py[line:274] - INFO: epoch 001:  13309 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4734, wps=101.2, ups=0.47, wpb=107.8, bsz=40, num_updates=13290, lr=4.61079e-05, gnorm=0.467, clip=10, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=52777
2023-01-07 05:30:59 - progress_bar.py[line:274] - INFO: epoch 001:  13319 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3918, wps=100.3, ups=0.46, wpb=108.3, bsz=40, num_updates=13300, lr=4.61034e-05, gnorm=0.386, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52799
2023-01-07 05:31:20 - progress_bar.py[line:274] - INFO: epoch 001:  13329 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3846, wps=103.3, ups=0.47, wpb=109.8, bsz=40, num_updates=13310, lr=4.60989e-05, gnorm=0.363, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52821
2023-01-07 05:31:42 - progress_bar.py[line:274] - INFO: epoch 001:  13339 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4462, wps=100.1, ups=0.46, wpb=109.1, bsz=40, num_updates=13320, lr=4.60944e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=22, gb_free=9.6, ema_decay=0.9999, wall=52843
2023-01-07 05:32:04 - progress_bar.py[line:274] - INFO: epoch 001:  13349 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3744, wps=100.1, ups=0.46, wpb=107.7, bsz=40, num_updates=13330, lr=4.60899e-05, gnorm=0.48, clip=10, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52864
2023-01-07 05:32:26 - progress_bar.py[line:274] - INFO: epoch 001:  13359 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4019, wps=99.2, ups=0.46, wpb=107.4, bsz=40, num_updates=13340, lr=4.60854e-05, gnorm=0.274, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52886
2023-01-07 05:32:47 - progress_bar.py[line:274] - INFO: epoch 001:  13369 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4623, wps=102, ups=0.47, wpb=108.1, bsz=40, num_updates=13350, lr=4.60809e-05, gnorm=0.26, clip=0, loss_scale=128, train_wall=21, gb_free=10, ema_decay=0.9999, wall=52908
2023-01-07 05:33:09 - progress_bar.py[line:274] - INFO: epoch 001:  13379 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4709, wps=104.4, ups=0.47, wpb=110.3, bsz=40, num_updates=13360, lr=4.60764e-05, gnorm=0.305, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52929
2023-01-07 05:33:30 - progress_bar.py[line:274] - INFO: epoch 001:  13389 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4531, wps=102, ups=0.47, wpb=109, bsz=40, num_updates=13370, lr=4.60719e-05, gnorm=0.412, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52950
2023-01-07 05:33:52 - progress_bar.py[line:274] - INFO: epoch 001:  13399 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.404, wps=102.1, ups=0.47, wpb=108.7, bsz=40, num_updates=13380, lr=4.60674e-05, gnorm=0.288, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52972
2023-01-07 05:34:14 - progress_bar.py[line:274] - INFO: epoch 001:  13409 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4315, wps=100.3, ups=0.46, wpb=108, bsz=40, num_updates=13390, lr=4.60629e-05, gnorm=0.401, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52994
2023-01-07 05:34:35 - progress_bar.py[line:274] - INFO: epoch 001:  13419 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4299, wps=100.2, ups=0.46, wpb=107.8, bsz=40, num_updates=13400, lr=4.60584e-05, gnorm=0.409, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53015
2023-01-07 05:34:56 - progress_bar.py[line:274] - INFO: epoch 001:  13429 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4171, wps=105.3, ups=0.48, wpb=110.6, bsz=40, num_updates=13410, lr=4.60539e-05, gnorm=0.206, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53037
2023-01-07 05:35:18 - progress_bar.py[line:274] - INFO: epoch 001:  13439 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4286, wps=101, ups=0.47, wpb=108.2, bsz=40, num_updates=13420, lr=4.60494e-05, gnorm=0.402, clip=10, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53058
2023-01-07 05:35:40 - progress_bar.py[line:274] - INFO: epoch 001:  13449 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4163, wps=102.2, ups=0.47, wpb=108.3, bsz=40, num_updates=13430, lr=4.60449e-05, gnorm=0.366, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53080
2023-01-07 05:36:01 - progress_bar.py[line:274] - INFO: epoch 001:  13459 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4439, wps=101.2, ups=0.47, wpb=107.8, bsz=40, num_updates=13440, lr=4.60404e-05, gnorm=0.553, clip=30, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=53101
2023-01-07 05:36:23 - progress_bar.py[line:274] - INFO: epoch 001:  13469 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.401, wps=102.3, ups=0.47, wpb=109.3, bsz=40, num_updates=13450, lr=4.60359e-05, gnorm=0.479, clip=10, loss_scale=128, train_wall=21, gb_free=10, ema_decay=0.9999, wall=53123
2023-01-07 05:36:44 - progress_bar.py[line:274] - INFO: epoch 001:  13479 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.402, wps=101.6, ups=0.46, wpb=109.5, bsz=40, num_updates=13460, lr=4.60315e-05, gnorm=0.281, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53145
2023-01-07 05:37:06 - progress_bar.py[line:274] - INFO: epoch 001:  13489 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3744, wps=99, ups=0.46, wpb=107, bsz=40, num_updates=13470, lr=4.6027e-05, gnorm=0.337, clip=0, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=53166
2023-01-07 05:37:28 - progress_bar.py[line:274] - INFO: epoch 001:  13499 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4136, wps=102.3, ups=0.46, wpb=110, bsz=40, num_updates=13480, lr=4.60225e-05, gnorm=0.324, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53188
2023-01-07 05:37:50 - progress_bar.py[line:274] - INFO: epoch 001:  13509 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4121, wps=100.6, ups=0.46, wpb=110.3, bsz=40, num_updates=13490, lr=4.6018e-05, gnorm=0.375, clip=0, loss_scale=128, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=53210
2023-01-07 05:38:12 - progress_bar.py[line:274] - INFO: epoch 001:  13519 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4615, wps=101.5, ups=0.46, wpb=109.2, bsz=40, num_updates=13500, lr=4.60135e-05, gnorm=0.442, clip=0, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=53232
2023-01-07 05:38:34 - progress_bar.py[line:274] - INFO: epoch 001:  13529 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3889, wps=102.7, ups=0.46, wpb=110.6, bsz=40, num_updates=13510, lr=4.6009e-05, gnorm=0.447, clip=10, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53254
2023-01-07 05:38:55 - progress_bar.py[line:274] - INFO: epoch 001:  13539 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4772, wps=102.2, ups=0.47, wpb=109.2, bsz=40, num_updates=13520, lr=4.60045e-05, gnorm=0.518, clip=10, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53275
2023-01-07 05:39:17 - progress_bar.py[line:274] - INFO: epoch 001:  13549 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.392, wps=103.6, ups=0.47, wpb=110.3, bsz=40, num_updates=13530, lr=4.6e-05, gnorm=0.319, clip=0, loss_scale=128, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=53297
2023-01-07 05:39:38 - progress_bar.py[line:274] - INFO: epoch 001:  13559 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4488, wps=101.5, ups=0.47, wpb=108, bsz=40, num_updates=13540, lr=4.59955e-05, gnorm=0.455, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53318
2023-01-07 05:40:00 - progress_bar.py[line:274] - INFO: epoch 001:  13569 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4885, wps=101.7, ups=0.47, wpb=108.7, bsz=40, num_updates=13550, lr=4.5991e-05, gnorm=0.26, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53340
2023-01-07 05:40:21 - progress_bar.py[line:274] - INFO: epoch 001:  13579 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4225, wps=100.3, ups=0.47, wpb=107.5, bsz=40, num_updates=13560, lr=4.59865e-05, gnorm=0.354, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53362
2023-01-07 05:40:43 - progress_bar.py[line:274] - INFO: epoch 001:  13589 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4973, wps=103.4, ups=0.47, wpb=110.3, bsz=40, num_updates=13570, lr=4.5982e-05, gnorm=0.465, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53383
2023-01-07 05:41:05 - progress_bar.py[line:274] - INFO: epoch 001:  13599 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.41, wps=102.3, ups=0.47, wpb=108.9, bsz=40, num_updates=13580, lr=4.59775e-05, gnorm=0.459, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53405
2023-01-07 05:41:26 - progress_bar.py[line:274] - INFO: epoch 001:  13609 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3897, wps=101, ups=0.46, wpb=109.7, bsz=40, num_updates=13590, lr=4.5973e-05, gnorm=0.429, clip=0, loss_scale=256, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=53427
2023-01-07 05:41:48 - progress_bar.py[line:274] - INFO: epoch 001:  13619 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3897, wps=100.9, ups=0.46, wpb=109.3, bsz=40, num_updates=13600, lr=4.59685e-05, gnorm=0.299, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=53449
2023-01-07 05:42:10 - progress_bar.py[line:274] - INFO: epoch 001:  13629 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3943, wps=104.7, ups=0.48, wpb=109.9, bsz=40, num_updates=13610, lr=4.5964e-05, gnorm=0.428, clip=20, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=53470
2023-01-07 05:42:31 - progress_bar.py[line:274] - INFO: epoch 001:  13639 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4533, wps=101.2, ups=0.47, wpb=107.3, bsz=40, num_updates=13620, lr=4.59595e-05, gnorm=0.335, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53491
2023-01-07 05:42:53 - progress_bar.py[line:274] - INFO: epoch 001:  13649 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.398, wps=101.4, ups=0.46, wpb=109.7, bsz=40, num_updates=13630, lr=4.5955e-05, gnorm=0.407, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=53513
2023-01-07 05:43:15 - progress_bar.py[line:274] - INFO: epoch 001:  13659 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4922, wps=100.9, ups=0.46, wpb=109.8, bsz=40, num_updates=13640, lr=4.59505e-05, gnorm=0.283, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=53535
2023-01-07 05:43:36 - progress_bar.py[line:274] - INFO: epoch 001:  13669 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4216, wps=105.5, ups=0.47, wpb=112.2, bsz=40, num_updates=13650, lr=4.5946e-05, gnorm=0.31, clip=0, loss_scale=256, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=53557
2023-01-07 05:43:58 - progress_bar.py[line:274] - INFO: epoch 001:  13679 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4764, wps=100.1, ups=0.46, wpb=109.4, bsz=40, num_updates=13660, lr=4.59415e-05, gnorm=0.363, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=53579
2023-01-07 05:44:20 - progress_bar.py[line:274] - INFO: epoch 001:  13689 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3949, wps=102.9, ups=0.47, wpb=109.6, bsz=40, num_updates=13670, lr=4.5937e-05, gnorm=0.336, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=53600
2023-01-07 05:44:42 - progress_bar.py[line:274] - INFO: epoch 001:  13699 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3756, wps=100.7, ups=0.46, wpb=108.9, bsz=40, num_updates=13680, lr=4.59325e-05, gnorm=0.461, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=53622
2023-01-07 05:45:03 - progress_bar.py[line:274] - INFO: epoch 001:  13709 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4044, wps=103.7, ups=0.47, wpb=109.5, bsz=40, num_updates=13690, lr=4.5928e-05, gnorm=0.362, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53643
2023-01-07 05:45:25 - progress_bar.py[line:274] - INFO: epoch 001:  13719 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4492, wps=101.6, ups=0.46, wpb=110.8, bsz=40, num_updates=13700, lr=4.59236e-05, gnorm=0.452, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=53665
2023-01-07 05:45:47 - progress_bar.py[line:274] - INFO: epoch 001:  13729 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4279, wps=102.1, ups=0.46, wpb=109.9, bsz=40, num_updates=13710, lr=4.59191e-05, gnorm=0.386, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=53687
2023-01-07 05:46:08 - progress_bar.py[line:274] - INFO: epoch 001:  13739 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3661, wps=103.7, ups=0.47, wpb=110.8, bsz=40, num_updates=13720, lr=4.59146e-05, gnorm=0.394, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=53709
2023-01-07 05:46:30 - progress_bar.py[line:274] - INFO: epoch 001:  13749 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3485, wps=102.7, ups=0.47, wpb=109.9, bsz=40, num_updates=13730, lr=4.59101e-05, gnorm=0.376, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53730
2023-01-07 05:46:52 - progress_bar.py[line:274] - INFO: epoch 001:  13759 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4272, wps=99.3, ups=0.46, wpb=108.8, bsz=40, num_updates=13740, lr=4.59056e-05, gnorm=0.358, clip=0, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=53752
2023-01-07 05:47:14 - progress_bar.py[line:274] - INFO: epoch 001:  13769 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.484, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=13750, lr=4.59011e-05, gnorm=0.267, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53774
2023-01-07 05:47:36 - progress_bar.py[line:274] - INFO: epoch 001:  13779 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3702, wps=99.8, ups=0.46, wpb=109.2, bsz=40, num_updates=13760, lr=4.58966e-05, gnorm=0.485, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=53796
2023-01-07 05:47:57 - progress_bar.py[line:274] - INFO: epoch 001:  13789 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4444, wps=104, ups=0.47, wpb=109.5, bsz=40, num_updates=13770, lr=4.58921e-05, gnorm=0.556, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53818
2023-01-07 05:48:19 - progress_bar.py[line:274] - INFO: epoch 001:  13799 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4412, wps=101.5, ups=0.47, wpb=108.1, bsz=40, num_updates=13780, lr=4.58876e-05, gnorm=0.303, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53839
2023-01-07 05:48:41 - progress_bar.py[line:274] - INFO: epoch 001:  13809 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4366, wps=98.5, ups=0.46, wpb=107.1, bsz=40, num_updates=13790, lr=4.58831e-05, gnorm=0.288, clip=0, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=53861
2023-01-07 05:49:02 - progress_bar.py[line:274] - INFO: epoch 001:  13819 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4316, wps=104.8, ups=0.48, wpb=109.3, bsz=40, num_updates=13800, lr=4.58786e-05, gnorm=0.444, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53882
2023-01-07 05:49:24 - progress_bar.py[line:274] - INFO: epoch 001:  13829 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4444, wps=99.3, ups=0.46, wpb=108.9, bsz=40, num_updates=13810, lr=4.58741e-05, gnorm=0.427, clip=0, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=53904
2023-01-07 05:49:46 - progress_bar.py[line:274] - INFO: epoch 001:  13839 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4265, wps=100.6, ups=0.47, wpb=107.8, bsz=40, num_updates=13820, lr=4.58696e-05, gnorm=0.417, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53926
2023-01-07 05:50:07 - progress_bar.py[line:274] - INFO: epoch 001:  13849 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4631, wps=101.3, ups=0.46, wpb=109.1, bsz=40, num_updates=13830, lr=4.58651e-05, gnorm=0.289, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53948
2023-01-07 05:50:29 - progress_bar.py[line:274] - INFO: epoch 001:  13859 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4084, wps=102.3, ups=0.46, wpb=110, bsz=40, num_updates=13840, lr=4.58606e-05, gnorm=0.264, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53969
2023-01-07 05:50:51 - progress_bar.py[line:274] - INFO: epoch 001:  13869 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4167, wps=100.9, ups=0.47, wpb=107.7, bsz=40, num_updates=13850, lr=4.58561e-05, gnorm=0.332, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53991
2023-01-07 05:51:12 - progress_bar.py[line:274] - INFO: epoch 001:  13879 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4433, wps=104.8, ups=0.48, wpb=108.5, bsz=40, num_updates=13860, lr=4.58516e-05, gnorm=0.496, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54012
2023-01-07 05:51:33 - progress_bar.py[line:274] - INFO: epoch 001:  13889 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4009, wps=100.5, ups=0.47, wpb=107.8, bsz=40, num_updates=13870, lr=4.58471e-05, gnorm=0.658, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54034
2023-01-07 05:51:55 - progress_bar.py[line:274] - INFO: epoch 001:  13899 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4545, wps=102.4, ups=0.47, wpb=109.7, bsz=40, num_updates=13880, lr=4.58426e-05, gnorm=0.336, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=54055
2023-01-07 05:52:17 - progress_bar.py[line:274] - INFO: epoch 001:  13909 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4518, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=13890, lr=4.58381e-05, gnorm=0.337, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54077
2023-01-07 05:52:38 - progress_bar.py[line:274] - INFO: epoch 001:  13919 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5048, wps=101.7, ups=0.47, wpb=108.6, bsz=40, num_updates=13900, lr=4.58336e-05, gnorm=0.402, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54099
2023-01-07 05:53:00 - progress_bar.py[line:274] - INFO: epoch 001:  13929 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3831, wps=102.3, ups=0.46, wpb=110, bsz=40, num_updates=13910, lr=4.58291e-05, gnorm=0.452, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54120
2023-01-07 05:53:22 - progress_bar.py[line:274] - INFO: epoch 001:  13939 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4573, wps=102.4, ups=0.47, wpb=109.4, bsz=40, num_updates=13920, lr=4.58246e-05, gnorm=0.454, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=54142
2023-01-07 05:53:44 - progress_bar.py[line:274] - INFO: epoch 001:  13949 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3869, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=13930, lr=4.58201e-05, gnorm=0.255, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=54164
2023-01-07 05:54:05 - progress_bar.py[line:274] - INFO: epoch 001:  13959 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3807, wps=103.7, ups=0.47, wpb=109.6, bsz=40, num_updates=13940, lr=4.58156e-05, gnorm=0.325, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=54185
2023-01-07 05:54:26 - progress_bar.py[line:274] - INFO: epoch 001:  13969 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4764, wps=102.2, ups=0.47, wpb=108.2, bsz=40, num_updates=13950, lr=4.58112e-05, gnorm=0.323, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=54207
2023-01-07 05:54:48 - progress_bar.py[line:274] - INFO: epoch 001:  13979 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4577, wps=104, ups=0.47, wpb=109.9, bsz=40, num_updates=13960, lr=4.58067e-05, gnorm=0.45, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=54228
2023-01-07 05:55:09 - progress_bar.py[line:274] - INFO: epoch 001:  13989 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4286, wps=102.2, ups=0.47, wpb=108.9, bsz=40, num_updates=13970, lr=4.58022e-05, gnorm=0.269, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=54250
2023-01-07 05:55:31 - progress_bar.py[line:274] - INFO: epoch 001:  13999 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.465, wps=102.1, ups=0.47, wpb=109.1, bsz=40, num_updates=13980, lr=4.57977e-05, gnorm=0.395, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54271
2023-01-07 05:55:52 - progress_bar.py[line:274] - INFO: epoch 001:  14009 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4921, wps=103.3, ups=0.47, wpb=110, bsz=40, num_updates=13990, lr=4.57932e-05, gnorm=0.377, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=54293
2023-01-07 05:56:14 - progress_bar.py[line:274] - INFO: epoch 001:  14019 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3906, wps=101, ups=0.46, wpb=108.8, bsz=40, num_updates=14000, lr=4.57887e-05, gnorm=0.415, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=54314
2023-01-07 05:56:14 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 05:56:16 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 05:56:16 - train.py[line:551] - INFO: load:1.15 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 05:56:17 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 9.26 GiB already allocated; 5.87 GiB free; 31.23 GiB reserved in total by PyTorch)
2023-01-07 05:56:17 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-07 05:56:17 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 27        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9484 MB |   10709 MB |    7739 TB |    7739 TB |
|       from large pool |    9310 MB |   10535 MB |    7736 TB |    7736 TB |
|       from small pool |     174 MB |     175 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9484 MB |   10709 MB |    7739 TB |    7739 TB |
|       from large pool |    9310 MB |   10535 MB |    7736 TB |    7736 TB |
|       from small pool |     174 MB |     175 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   31980 MB |   33262 MB |  298216 MB |  266236 MB |
|       from large pool |   31804 MB |   33080 MB |  297806 MB |  266002 MB |
|       from small pool |     176 MB |     182 MB |     410 MB |     234 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22495 MB |   26771 MB |    7090 TB |    7090 TB |
|       from large pool |   22493 MB |   26769 MB |    7087 TB |    7087 TB |
|       from small pool |       1 MB |       2 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  364922 K  |  364918 K  |
|       from large pool |     698    |     710    |  112589 K  |  112588 K  |
|       from small pool |    3925    |    3943    |  252332 K  |  252329 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  364922 K  |  364918 K  |
|       from large pool |     698    |     710    |  112589 K  |  112588 K  |
|       from small pool |    3925    |    3943    |  252332 K  |  252329 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     201    |     213    |     661    |     460    |
|       from large pool |     113    |     122    |     456    |     343    |
|       from small pool |      88    |      91    |     205    |     117    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     127    |     129    |  269335 K  |  269335 K  |
|       from large pool |      68    |      70    |   53052 K  |   53052 K  |
|       from small pool |      59    |      68    |  216283 K  |  216283 K  |
|===========================================================================|

2023-01-07 05:56:17 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-07 05:58:48 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 05:58:48 - train.py[line:551] - INFO: load:1.18 valid_run:152.11 task_valid:146.75 collect_output:4.22
2023-01-07 06:01:16 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 06:01:16 - train.py[line:551] - INFO: load:1.20 valid_run:300.13 task_valid:288.29 collect_output:9.61
2023-01-07 06:03:48 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 06:03:48 - train.py[line:551] - INFO: load:1.23 valid_run:452.24 task_valid:429.73 collect_output:19.22
2023-01-07 06:06:17 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 06:06:17 - train.py[line:551] - INFO: load:1.25 valid_run:600.75 task_valid:573.02 collect_output:23.36
2023-01-07 06:08:49 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 06:08:49 - train.py[line:551] - INFO: load:1.28 valid_run:752.66 task_valid:719.08 collect_output:28.13
2023-01-07 06:11:20 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 06:11:20 - train.py[line:551] - INFO: load:1.30 valid_run:903.95 task_valid:863.00 collect_output:34.45
2023-01-07 06:13:54 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 06:13:54 - train.py[line:551] - INFO: load:1.33 valid_run:1057.38 task_valid:1007.26 collect_output:42.57
2023-01-07 06:16:25 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 06:16:25 - train.py[line:551] - INFO: load:1.36 valid_run:1208.65 task_valid:1146.76 collect_output:53.28
2023-01-07 06:18:55 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 06:18:55 - train.py[line:551] - INFO: load:1.38 valid_run:1358.12 task_valid:1290.16 collect_output:58.29
2023-01-07 06:21:23 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 06:21:23 - train.py[line:551] - INFO: load:1.41 valid_run:1506.21 task_valid:1431.80 collect_output:63.69
2023-01-07 06:23:52 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 06:23:52 - train.py[line:551] - INFO: load:1.43 valid_run:1655.46 task_valid:1575.09 collect_output:68.60
2023-01-07 06:26:21 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 06:26:21 - train.py[line:551] - INFO: load:1.46 valid_run:1804.81 task_valid:1718.26 collect_output:73.76
2023-01-07 06:28:51 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 06:28:51 - train.py[line:551] - INFO: load:1.49 valid_run:1954.67 task_valid:1858.54 collect_output:82.28
2023-01-07 06:31:22 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 06:31:22 - train.py[line:551] - INFO: load:1.51 valid_run:2104.75 task_valid:2002.49 collect_output:87.36
2023-01-07 06:33:51 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 06:33:51 - train.py[line:551] - INFO: load:1.54 valid_run:2253.72 task_valid:2147.18 collect_output:90.57
2023-01-07 06:36:20 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 06:36:20 - train.py[line:551] - INFO: load:1.56 valid_run:2403.16 task_valid:2289.62 collect_output:96.51
2023-01-07 06:38:52 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 06:38:52 - train.py[line:551] - INFO: load:1.59 valid_run:2554.46 task_valid:2433.62 collect_output:102.77
2023-01-07 06:41:21 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 06:41:21 - train.py[line:551] - INFO: load:1.62 valid_run:2704.31 task_valid:2578.87 collect_output:106.32
2023-01-07 06:43:50 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 06:43:50 - train.py[line:551] - INFO: load:1.64 valid_run:2852.76 task_valid:2718.60 collect_output:114.00
2023-01-07 06:46:20 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 06:46:20 - train.py[line:551] - INFO: load:1.67 valid_run:3002.87 task_valid:2861.97 collect_output:119.69
2023-01-07 06:48:52 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 06:48:52 - train.py[line:551] - INFO: load:1.69 valid_run:3154.88 task_valid:3004.76 collect_output:127.88
2023-01-07 06:51:22 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 06:51:22 - train.py[line:551] - INFO: load:1.72 valid_run:3304.10 task_valid:3148.15 collect_output:132.62
2023-01-07 06:53:53 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 06:53:53 - train.py[line:551] - INFO: load:1.74 valid_run:3454.99 task_valid:3292.64 collect_output:137.97
2023-01-07 06:56:24 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 06:56:24 - train.py[line:551] - INFO: load:1.77 valid_run:3605.76 task_valid:3437.64 collect_output:142.68

====================================================================================================
SGG eval:     R @ 50: 0.4739;     R @ 100: 0.5674;     R @ 500: 0.6099;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2841;    mR @ 100: 0.3722;    mR @ 500: 0.4166;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7268) (covered in:0.6875) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.3871) (lying on:0.0000) (mounted on:0.0000) (painted on:0.5000) (parked on:0.8750) (playing:0.0000) (riding:0.8343) (says:0.0000) (sitting on:0.6800) (standing on:0.1958) (using:0.6500) (walking in:0.0000) (walking on:0.4820) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4739;     R @ 100: 0.5674;     R @ 500: 0.6099;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2841;    mR @ 100: 0.3722;    mR @ 500: 0.4166;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7268) (covered in:0.6875) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.3871) (lying on:0.0000) (mounted on:0.0000) (painted on:0.5000) (parked on:0.8750) (playing:0.0000) (riding:0.8343) (says:0.0000) (sitting on:0.6800) (standing on:0.1958) (using:0.6500) (walking in:0.0000) (walking on:0.4820) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-01-07 06:58:54 - train.py[line:487] - INFO: 0.5673952380952381
2023-01-07 06:58:54 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-07 06:58:54 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.411 | loss_v1 0 | loss_v2 0 | nll_loss 0.261 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.567395 | ppl 1.2 | vqa_score 0.5034 | wps 119.4 | wpb 89.9 | bsz 30 | num_updates 14000 | best_R@100 0.637221
2023-01-07 06:58:54 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 14000 updates
2023-01-07 06:58:54 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_14000.pt
2023-01-07 06:59:39 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_14000.pt
2023-01-07 07:01:12 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_14000.pt (epoch 1 @ 14000 updates, score 0.5673952380952381) (writing took 137.47188848815858 seconds)
2023-01-07 07:01:34 - progress_bar.py[line:274] - INFO: epoch 001:  14029 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4238, wps=0.6, ups=0, wpb=108, bsz=40, num_updates=14010, lr=4.57842e-05, gnorm=0.426, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=58234
2023-01-07 07:01:55 - progress_bar.py[line:274] - INFO: epoch 001:  14039 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4247, wps=103.4, ups=0.47, wpb=109.1, bsz=40, num_updates=14020, lr=4.57797e-05, gnorm=0.295, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=58255
2023-01-07 07:02:17 - progress_bar.py[line:274] - INFO: epoch 001:  14049 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4153, wps=101.6, ups=0.47, wpb=109.2, bsz=40, num_updates=14030, lr=4.57752e-05, gnorm=0.358, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58277
2023-01-07 07:02:39 - progress_bar.py[line:274] - INFO: epoch 001:  14059 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4682, wps=103.5, ups=0.46, wpb=111.3, bsz=40, num_updates=14040, lr=4.57707e-05, gnorm=0.554, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58299
2023-01-07 07:03:00 - progress_bar.py[line:274] - INFO: epoch 001:  14069 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4049, wps=104.4, ups=0.48, wpb=109, bsz=40, num_updates=14050, lr=4.57662e-05, gnorm=0.422, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58320
2023-01-07 07:03:21 - progress_bar.py[line:274] - INFO: epoch 001:  14079 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4333, wps=102.5, ups=0.47, wpb=108.5, bsz=40, num_updates=14060, lr=4.57617e-05, gnorm=0.394, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58341
2023-01-07 07:03:42 - progress_bar.py[line:274] - INFO: epoch 001:  14089 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3687, wps=102.3, ups=0.48, wpb=107.1, bsz=40, num_updates=14070, lr=4.57572e-05, gnorm=0.369, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58363
2023-01-07 07:04:04 - progress_bar.py[line:274] - INFO: epoch 001:  14099 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4359, wps=103.8, ups=0.47, wpb=109.4, bsz=40, num_updates=14080, lr=4.57527e-05, gnorm=0.263, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=58384
2023-01-07 07:04:25 - progress_bar.py[line:274] - INFO: epoch 001:  14109 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3835, wps=102.8, ups=0.47, wpb=109.3, bsz=40, num_updates=14090, lr=4.57482e-05, gnorm=0.459, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=58405
2023-01-07 07:04:47 - progress_bar.py[line:274] - INFO: epoch 001:  14119 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4415, wps=104.1, ups=0.47, wpb=111.6, bsz=40, num_updates=14100, lr=4.57437e-05, gnorm=0.414, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58427
2023-01-07 07:05:09 - progress_bar.py[line:274] - INFO: epoch 001:  14129 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4573, wps=98.6, ups=0.45, wpb=108.6, bsz=40, num_updates=14110, lr=4.57392e-05, gnorm=0.463, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58449
2023-01-07 07:05:31 - progress_bar.py[line:274] - INFO: epoch 001:  14139 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4053, wps=101, ups=0.46, wpb=109.5, bsz=40, num_updates=14120, lr=4.57347e-05, gnorm=0.422, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58471
2023-01-07 07:05:53 - progress_bar.py[line:274] - INFO: epoch 001:  14149 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4581, wps=102.6, ups=0.46, wpb=111.1, bsz=40, num_updates=14130, lr=4.57302e-05, gnorm=0.373, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=58493
2023-01-07 07:06:15 - progress_bar.py[line:274] - INFO: epoch 001:  14159 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4046, wps=102.6, ups=0.46, wpb=111.6, bsz=40, num_updates=14140, lr=4.57257e-05, gnorm=0.308, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58515
2023-01-07 07:06:36 - progress_bar.py[line:274] - INFO: epoch 001:  14169 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4466, wps=101.3, ups=0.47, wpb=108, bsz=40, num_updates=14150, lr=4.57212e-05, gnorm=0.413, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58537
2023-01-07 07:06:58 - progress_bar.py[line:274] - INFO: epoch 001:  14179 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3508, wps=102.8, ups=0.47, wpb=109.3, bsz=40, num_updates=14160, lr=4.57167e-05, gnorm=0.328, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=58558
2023-01-07 07:07:19 - progress_bar.py[line:274] - INFO: epoch 001:  14189 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.396, wps=106, ups=0.48, wpb=110.2, bsz=40, num_updates=14170, lr=4.57122e-05, gnorm=0.357, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=58579
2023-01-07 07:07:41 - progress_bar.py[line:274] - INFO: epoch 001:  14199 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4348, wps=101.8, ups=0.46, wpb=110.6, bsz=40, num_updates=14180, lr=4.57077e-05, gnorm=0.338, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58601
2023-01-07 07:08:02 - progress_bar.py[line:274] - INFO: epoch 001:  14209 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3941, wps=104.1, ups=0.48, wpb=109.5, bsz=40, num_updates=14190, lr=4.57033e-05, gnorm=0.42, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58622
2023-01-07 07:08:24 - progress_bar.py[line:274] - INFO: epoch 001:  14219 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4451, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=14200, lr=4.56988e-05, gnorm=0.358, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58644
2023-01-07 07:08:46 - progress_bar.py[line:274] - INFO: epoch 001:  14229 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3266, wps=100.6, ups=0.46, wpb=109.1, bsz=40, num_updates=14210, lr=4.56943e-05, gnorm=0.318, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58666
2023-01-07 07:09:08 - progress_bar.py[line:274] - INFO: epoch 001:  14239 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4201, wps=97.7, ups=0.46, wpb=106.5, bsz=40, num_updates=14220, lr=4.56898e-05, gnorm=0.401, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=58688
2023-01-07 07:09:30 - progress_bar.py[line:274] - INFO: epoch 001:  14249 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4178, wps=99.8, ups=0.46, wpb=108.2, bsz=40, num_updates=14230, lr=4.56853e-05, gnorm=0.391, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58710
2023-01-07 07:09:51 - progress_bar.py[line:274] - INFO: epoch 001:  14259 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3618, wps=102.8, ups=0.47, wpb=108.7, bsz=40, num_updates=14240, lr=4.56808e-05, gnorm=0.459, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58731
2023-01-07 07:10:13 - progress_bar.py[line:274] - INFO: epoch 001:  14269 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4162, wps=101.4, ups=0.47, wpb=108.9, bsz=40, num_updates=14250, lr=4.56763e-05, gnorm=0.297, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58753
2023-01-07 07:10:35 - progress_bar.py[line:274] - INFO: epoch 001:  14279 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3889, wps=100.7, ups=0.46, wpb=109, bsz=40, num_updates=14260, lr=4.56718e-05, gnorm=0.299, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=58775
2023-01-07 07:10:56 - progress_bar.py[line:274] - INFO: epoch 001:  14289 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4384, wps=102.4, ups=0.47, wpb=108.2, bsz=40, num_updates=14270, lr=4.56673e-05, gnorm=0.427, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58796
2023-01-07 07:11:18 - progress_bar.py[line:274] - INFO: epoch 001:  14299 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4623, wps=101.7, ups=0.47, wpb=108.7, bsz=40, num_updates=14280, lr=4.56628e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=58818
2023-01-07 07:11:39 - progress_bar.py[line:274] - INFO: epoch 001:  14309 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4064, wps=100.8, ups=0.47, wpb=108.2, bsz=40, num_updates=14290, lr=4.56583e-05, gnorm=0.339, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58839
2023-01-07 07:12:01 - progress_bar.py[line:274] - INFO: epoch 001:  14319 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4309, wps=103.9, ups=0.47, wpb=110, bsz=40, num_updates=14300, lr=4.56538e-05, gnorm=0.253, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58861
2023-01-07 07:12:22 - progress_bar.py[line:274] - INFO: epoch 001:  14329 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3807, wps=103.7, ups=0.47, wpb=109.5, bsz=40, num_updates=14310, lr=4.56493e-05, gnorm=0.367, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58882
2023-01-07 07:12:44 - progress_bar.py[line:274] - INFO: epoch 001:  14339 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4049, wps=99.4, ups=0.46, wpb=108.2, bsz=40, num_updates=14320, lr=4.56448e-05, gnorm=0.27, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58904
2023-01-07 07:13:05 - progress_bar.py[line:274] - INFO: epoch 001:  14349 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3807, wps=103.1, ups=0.47, wpb=109.2, bsz=40, num_updates=14330, lr=4.56403e-05, gnorm=0.272, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58926
2023-01-07 07:13:28 - progress_bar.py[line:274] - INFO: epoch 001:  14359 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.445, wps=99.1, ups=0.46, wpb=108.6, bsz=40, num_updates=14340, lr=4.56358e-05, gnorm=0.309, clip=0, loss_scale=512, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=58948
2023-01-07 07:13:49 - progress_bar.py[line:274] - INFO: epoch 001:  14369 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4187, wps=103.5, ups=0.48, wpb=108.4, bsz=40, num_updates=14350, lr=4.56313e-05, gnorm=0.303, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=58969
2023-01-07 07:14:11 - progress_bar.py[line:274] - INFO: epoch 001:  14379 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.445, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=14360, lr=4.56268e-05, gnorm=0.192, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=58991
2023-01-07 07:14:32 - progress_bar.py[line:274] - INFO: epoch 001:  14389 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4604, wps=105.5, ups=0.48, wpb=109.5, bsz=40, num_updates=14370, lr=4.56223e-05, gnorm=0.425, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=59012
2023-01-07 07:14:53 - progress_bar.py[line:274] - INFO: epoch 001:  14399 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4271, wps=103.1, ups=0.47, wpb=108.9, bsz=40, num_updates=14380, lr=4.56178e-05, gnorm=0.392, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=59033
2023-01-07 07:15:14 - progress_bar.py[line:274] - INFO: epoch 001:  14409 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4307, wps=102.8, ups=0.47, wpb=108.3, bsz=40, num_updates=14390, lr=4.56133e-05, gnorm=0.318, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59055
2023-01-07 07:15:36 - progress_bar.py[line:274] - INFO: epoch 001:  14419 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4475, wps=101.2, ups=0.46, wpb=110.5, bsz=40, num_updates=14400, lr=4.56088e-05, gnorm=0.491, clip=10, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=59077
2023-01-07 07:15:58 - progress_bar.py[line:274] - INFO: epoch 001:  14429 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4135, wps=98.9, ups=0.46, wpb=107.6, bsz=40, num_updates=14410, lr=4.56043e-05, gnorm=0.418, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=59099
2023-01-07 07:16:20 - progress_bar.py[line:274] - INFO: epoch 001:  14439 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3788, wps=101.7, ups=0.47, wpb=108.3, bsz=40, num_updates=14420, lr=4.55998e-05, gnorm=0.339, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=59120
2023-01-07 07:16:42 - progress_bar.py[line:274] - INFO: epoch 001:  14449 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3738, wps=101.4, ups=0.46, wpb=109.6, bsz=40, num_updates=14430, lr=4.55953e-05, gnorm=0.309, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59142
2023-01-07 07:17:03 - progress_bar.py[line:274] - INFO: epoch 001:  14459 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3964, wps=100.9, ups=0.47, wpb=108.2, bsz=40, num_updates=14440, lr=4.55909e-05, gnorm=0.325, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=59164
2023-01-07 07:17:25 - progress_bar.py[line:274] - INFO: epoch 001:  14469 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4686, wps=100.1, ups=0.46, wpb=108.3, bsz=40, num_updates=14450, lr=4.55864e-05, gnorm=0.372, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59185
2023-01-07 07:17:47 - progress_bar.py[line:274] - INFO: epoch 001:  14479 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4742, wps=100.7, ups=0.46, wpb=109.9, bsz=40, num_updates=14460, lr=4.55819e-05, gnorm=0.466, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=59208
2023-01-07 07:18:09 - progress_bar.py[line:274] - INFO: epoch 001:  14489 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4639, wps=102, ups=0.47, wpb=109.5, bsz=40, num_updates=14470, lr=4.55774e-05, gnorm=0.486, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59229
2023-01-07 07:18:31 - progress_bar.py[line:274] - INFO: epoch 001:  14499 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4421, wps=102.7, ups=0.47, wpb=110.3, bsz=40, num_updates=14480, lr=4.55729e-05, gnorm=0.411, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59251
2023-01-07 07:18:52 - progress_bar.py[line:274] - INFO: epoch 001:  14509 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4754, wps=104.7, ups=0.48, wpb=110, bsz=40, num_updates=14490, lr=4.55684e-05, gnorm=0.288, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59272
2023-01-07 07:19:14 - progress_bar.py[line:274] - INFO: epoch 001:  14519 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4258, wps=101.2, ups=0.47, wpb=108, bsz=40, num_updates=14500, lr=4.55639e-05, gnorm=0.38, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=59294
2023-01-07 07:19:35 - progress_bar.py[line:274] - INFO: epoch 001:  14529 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4688, wps=101.1, ups=0.46, wpb=109.6, bsz=40, num_updates=14510, lr=4.55594e-05, gnorm=0.4, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59316
2023-01-07 07:19:57 - progress_bar.py[line:274] - INFO: epoch 001:  14539 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4346, wps=101.7, ups=0.47, wpb=108.8, bsz=40, num_updates=14520, lr=4.55549e-05, gnorm=0.886, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=59337
2023-01-07 07:20:19 - progress_bar.py[line:274] - INFO: epoch 001:  14549 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3667, wps=101.4, ups=0.47, wpb=108.7, bsz=40, num_updates=14530, lr=4.55504e-05, gnorm=0.388, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59359
2023-01-07 07:20:40 - progress_bar.py[line:274] - INFO: epoch 001:  14559 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4381, wps=103.8, ups=0.47, wpb=109.3, bsz=40, num_updates=14540, lr=4.55459e-05, gnorm=0.426, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59380
2023-01-07 07:21:02 - progress_bar.py[line:274] - INFO: epoch 001:  14569 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4313, wps=102.6, ups=0.47, wpb=110, bsz=40, num_updates=14550, lr=4.55414e-05, gnorm=0.279, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=59402
2023-01-07 07:21:23 - progress_bar.py[line:274] - INFO: epoch 001:  14579 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4363, wps=103.3, ups=0.47, wpb=109.1, bsz=40, num_updates=14560, lr=4.55369e-05, gnorm=0.284, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=59423
2023-01-07 07:21:36 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 07:21:47 - progress_bar.py[line:274] - INFO: epoch 001:  14590 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.571, nsentences=40, sample_size=108.571, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4299, wps=96.7, ups=0.42, wpb=108.6, bsz=40, num_updates=14570, lr=4.55324e-05, gnorm=0.462, clip=10, loss_scale=512, train_wall=24, gb_free=10.1, ema_decay=0.9999, wall=59447
2023-01-07 07:22:08 - progress_bar.py[line:274] - INFO: epoch 001:  14600 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4974, wps=103.5, ups=0.47, wpb=109.4, bsz=40, num_updates=14580, lr=4.55279e-05, gnorm=0.43, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=59468
2023-01-07 07:22:30 - progress_bar.py[line:274] - INFO: epoch 001:  14610 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4564, wps=100.6, ups=0.46, wpb=108.9, bsz=40, num_updates=14590, lr=4.55234e-05, gnorm=0.391, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59490
2023-01-07 07:22:51 - progress_bar.py[line:274] - INFO: epoch 001:  14620 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3956, wps=106.4, ups=0.48, wpb=110.3, bsz=40, num_updates=14600, lr=4.55189e-05, gnorm=0.435, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59511
2023-01-07 07:23:12 - progress_bar.py[line:274] - INFO: epoch 001:  14630 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4745, wps=102.5, ups=0.47, wpb=108.8, bsz=40, num_updates=14610, lr=4.55144e-05, gnorm=0.352, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59533
2023-01-07 07:23:35 - progress_bar.py[line:274] - INFO: epoch 001:  14640 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.413, wps=100.6, ups=0.46, wpb=110.5, bsz=40, num_updates=14620, lr=4.55099e-05, gnorm=0.29, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59555
2023-01-07 07:23:57 - progress_bar.py[line:274] - INFO: epoch 001:  14650 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4316, wps=100.2, ups=0.46, wpb=109.1, bsz=40, num_updates=14630, lr=4.55054e-05, gnorm=0.405, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=59577
2023-01-07 07:24:18 - progress_bar.py[line:274] - INFO: epoch 001:  14660 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.401, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=14640, lr=4.55009e-05, gnorm=0.222, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=59599
2023-01-07 07:24:40 - progress_bar.py[line:274] - INFO: epoch 001:  14670 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.554, wps=103.8, ups=0.48, wpb=109.2, bsz=40, num_updates=14650, lr=4.54964e-05, gnorm=0.319, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59620
2023-01-07 07:25:01 - progress_bar.py[line:274] - INFO: epoch 001:  14680 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.459, wps=103.1, ups=0.47, wpb=109.8, bsz=40, num_updates=14660, lr=4.54919e-05, gnorm=0.331, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=59641
2023-01-07 07:25:22 - progress_bar.py[line:274] - INFO: epoch 001:  14690 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4236, wps=103.6, ups=0.47, wpb=109.4, bsz=40, num_updates=14670, lr=4.54874e-05, gnorm=0.291, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59663
2023-01-07 07:25:45 - progress_bar.py[line:274] - INFO: epoch 001:  14700 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3839, wps=99.8, ups=0.46, wpb=109.5, bsz=40, num_updates=14680, lr=4.5483e-05, gnorm=0.28, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=59685
2023-01-07 07:26:06 - progress_bar.py[line:274] - INFO: epoch 001:  14710 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.398, wps=100.4, ups=0.46, wpb=108.1, bsz=40, num_updates=14690, lr=4.54785e-05, gnorm=0.435, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59707
2023-01-07 07:26:28 - progress_bar.py[line:274] - INFO: epoch 001:  14720 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4091, wps=101.8, ups=0.47, wpb=108.4, bsz=40, num_updates=14700, lr=4.5474e-05, gnorm=0.589, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59728
2023-01-07 07:26:50 - progress_bar.py[line:274] - INFO: epoch 001:  14730 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4573, wps=103, ups=0.47, wpb=110.7, bsz=40, num_updates=14710, lr=4.54695e-05, gnorm=0.296, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=59750
2023-01-07 07:27:11 - progress_bar.py[line:274] - INFO: epoch 001:  14740 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4265, wps=102.2, ups=0.46, wpb=110.9, bsz=40, num_updates=14720, lr=4.5465e-05, gnorm=0.27, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59772
2023-01-07 07:27:33 - progress_bar.py[line:274] - INFO: epoch 001:  14750 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4876, wps=100.6, ups=0.46, wpb=109.3, bsz=40, num_updates=14730, lr=4.54605e-05, gnorm=0.406, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=59794
2023-01-07 07:27:55 - progress_bar.py[line:274] - INFO: epoch 001:  14760 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.401, wps=101.1, ups=0.47, wpb=108.6, bsz=40, num_updates=14740, lr=4.5456e-05, gnorm=0.342, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59815
2023-01-07 07:28:17 - progress_bar.py[line:274] - INFO: epoch 001:  14770 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4162, wps=105.9, ups=0.48, wpb=111.5, bsz=40, num_updates=14750, lr=4.54515e-05, gnorm=0.3, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=59837
2023-01-07 07:28:38 - progress_bar.py[line:274] - INFO: epoch 001:  14780 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4253, wps=103.8, ups=0.47, wpb=110.1, bsz=40, num_updates=14760, lr=4.5447e-05, gnorm=0.317, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59859
2023-01-07 07:29:00 - progress_bar.py[line:274] - INFO: epoch 001:  14790 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4586, wps=101.4, ups=0.46, wpb=110.3, bsz=40, num_updates=14770, lr=4.54425e-05, gnorm=0.203, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=59881
2023-01-07 07:29:22 - progress_bar.py[line:274] - INFO: epoch 001:  14800 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3959, wps=103.6, ups=0.47, wpb=109.6, bsz=40, num_updates=14780, lr=4.5438e-05, gnorm=0.388, clip=10, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=59902
2023-01-07 07:29:44 - progress_bar.py[line:274] - INFO: epoch 001:  14810 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4323, wps=99.9, ups=0.46, wpb=108.9, bsz=40, num_updates=14790, lr=4.54335e-05, gnorm=0.282, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=59924
2023-01-07 07:30:05 - progress_bar.py[line:274] - INFO: epoch 001:  14820 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4646, wps=102.1, ups=0.47, wpb=109.6, bsz=40, num_updates=14800, lr=4.5429e-05, gnorm=0.388, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=59946
2023-01-07 07:30:27 - progress_bar.py[line:274] - INFO: epoch 001:  14830 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4439, wps=104.3, ups=0.47, wpb=110.1, bsz=40, num_updates=14810, lr=4.54245e-05, gnorm=0.426, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=59967
2023-01-07 07:30:49 - progress_bar.py[line:274] - INFO: epoch 001:  14840 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4322, wps=100.7, ups=0.46, wpb=108.8, bsz=40, num_updates=14820, lr=4.542e-05, gnorm=0.339, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=59989
2023-01-07 07:31:10 - progress_bar.py[line:274] - INFO: epoch 001:  14850 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4047, wps=102.2, ups=0.47, wpb=108.7, bsz=40, num_updates=14830, lr=4.54155e-05, gnorm=0.331, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=60010
2023-01-07 07:31:31 - progress_bar.py[line:274] - INFO: epoch 001:  14860 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4236, wps=103.4, ups=0.48, wpb=108.2, bsz=40, num_updates=14840, lr=4.5411e-05, gnorm=0.444, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60032
2023-01-07 07:31:53 - progress_bar.py[line:274] - INFO: epoch 001:  14870 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4028, wps=100.8, ups=0.46, wpb=109.2, bsz=40, num_updates=14850, lr=4.54065e-05, gnorm=0.406, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60053
2023-01-07 07:32:14 - progress_bar.py[line:274] - INFO: epoch 001:  14880 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4341, wps=103.8, ups=0.48, wpb=108.9, bsz=40, num_updates=14860, lr=4.5402e-05, gnorm=0.533, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60075
2023-01-07 07:32:36 - progress_bar.py[line:274] - INFO: epoch 001:  14890 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.411, wps=100, ups=0.46, wpb=107.7, bsz=40, num_updates=14870, lr=4.53975e-05, gnorm=0.569, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60096
2023-01-07 07:32:58 - progress_bar.py[line:274] - INFO: epoch 001:  14900 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5027, wps=103.2, ups=0.47, wpb=109.5, bsz=40, num_updates=14880, lr=4.5393e-05, gnorm=0.253, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60118
2023-01-07 07:33:20 - progress_bar.py[line:274] - INFO: epoch 001:  14910 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4236, wps=100.3, ups=0.46, wpb=108.5, bsz=40, num_updates=14890, lr=4.53885e-05, gnorm=0.467, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=60140
2023-01-07 07:33:41 - progress_bar.py[line:274] - INFO: epoch 001:  14920 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4082, wps=100.6, ups=0.46, wpb=109.2, bsz=40, num_updates=14900, lr=4.5384e-05, gnorm=0.292, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=60162
2023-01-07 07:34:03 - progress_bar.py[line:274] - INFO: epoch 001:  14930 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4486, wps=99.4, ups=0.46, wpb=107.8, bsz=40, num_updates=14910, lr=4.53795e-05, gnorm=0.313, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60184
2023-01-07 07:34:25 - progress_bar.py[line:274] - INFO: epoch 001:  14940 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4888, wps=103.6, ups=0.47, wpb=110.4, bsz=40, num_updates=14920, lr=4.5375e-05, gnorm=0.314, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60205
2023-01-07 07:34:47 - progress_bar.py[line:274] - INFO: epoch 001:  14950 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4972, wps=102.5, ups=0.47, wpb=110.1, bsz=40, num_updates=14930, lr=4.53706e-05, gnorm=0.331, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60227
2023-01-07 07:35:09 - progress_bar.py[line:274] - INFO: epoch 001:  14960 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4398, wps=100.2, ups=0.46, wpb=109.7, bsz=40, num_updates=14940, lr=4.53661e-05, gnorm=0.286, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60249
2023-01-07 07:35:30 - progress_bar.py[line:274] - INFO: epoch 001:  14970 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4428, wps=102.2, ups=0.47, wpb=108.7, bsz=40, num_updates=14950, lr=4.53616e-05, gnorm=0.254, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60271
2023-01-07 07:35:52 - progress_bar.py[line:274] - INFO: epoch 001:  14980 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3676, wps=101, ups=0.46, wpb=109.6, bsz=40, num_updates=14960, lr=4.53571e-05, gnorm=0.541, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60292
2023-01-07 07:36:14 - progress_bar.py[line:274] - INFO: epoch 001:  14990 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4237, wps=103.4, ups=0.47, wpb=110.1, bsz=40, num_updates=14970, lr=4.53526e-05, gnorm=0.186, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60314
2023-01-07 07:36:35 - progress_bar.py[line:274] - INFO: epoch 001:  15000 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.365, wps=102.1, ups=0.47, wpb=108.7, bsz=40, num_updates=14980, lr=4.53481e-05, gnorm=0.418, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=60335
2023-01-07 07:36:57 - progress_bar.py[line:274] - INFO: epoch 001:  15010 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3828, wps=100.8, ups=0.47, wpb=107.8, bsz=40, num_updates=14990, lr=4.53436e-05, gnorm=0.36, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60357
2023-01-07 07:37:18 - progress_bar.py[line:274] - INFO: epoch 001:  15020 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4416, wps=102.1, ups=0.47, wpb=108.9, bsz=40, num_updates=15000, lr=4.53391e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60379
2023-01-07 07:37:40 - progress_bar.py[line:274] - INFO: epoch 001:  15030 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5172, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=15010, lr=4.53346e-05, gnorm=0.364, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60400
2023-01-07 07:38:02 - progress_bar.py[line:274] - INFO: epoch 001:  15040 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4694, wps=100.9, ups=0.46, wpb=109.4, bsz=40, num_updates=15020, lr=4.53301e-05, gnorm=0.271, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=60422
2023-01-07 07:38:24 - progress_bar.py[line:274] - INFO: epoch 001:  15050 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4384, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=15030, lr=4.53256e-05, gnorm=0.409, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60444
2023-01-07 07:38:45 - progress_bar.py[line:274] - INFO: epoch 001:  15060 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4796, wps=103.5, ups=0.47, wpb=110.1, bsz=40, num_updates=15040, lr=4.53211e-05, gnorm=0.283, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=60466
2023-01-07 07:39:07 - progress_bar.py[line:274] - INFO: epoch 001:  15070 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3861, wps=102.3, ups=0.46, wpb=110.1, bsz=40, num_updates=15050, lr=4.53166e-05, gnorm=0.272, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60487
2023-01-07 07:39:29 - progress_bar.py[line:274] - INFO: epoch 001:  15080 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.408, wps=99.7, ups=0.46, wpb=108.3, bsz=40, num_updates=15060, lr=4.53121e-05, gnorm=0.24, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=60509
2023-01-07 07:39:50 - progress_bar.py[line:274] - INFO: epoch 001:  15090 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4341, wps=102.5, ups=0.47, wpb=108.9, bsz=40, num_updates=15070, lr=4.53076e-05, gnorm=0.299, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60531
2023-01-07 07:40:12 - progress_bar.py[line:274] - INFO: epoch 001:  15100 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.396, wps=102.7, ups=0.47, wpb=108.2, bsz=40, num_updates=15080, lr=4.53031e-05, gnorm=0.348, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60552
2023-01-07 07:40:33 - progress_bar.py[line:274] - INFO: epoch 001:  15110 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4091, wps=102.2, ups=0.47, wpb=108.8, bsz=40, num_updates=15090, lr=4.52986e-05, gnorm=0.414, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=60573
2023-01-07 07:40:55 - progress_bar.py[line:274] - INFO: epoch 001:  15120 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5082, wps=103.6, ups=0.47, wpb=109.2, bsz=40, num_updates=15100, lr=4.52941e-05, gnorm=0.483, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60595
2023-01-07 07:41:16 - progress_bar.py[line:274] - INFO: epoch 001:  15130 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4359, wps=102.5, ups=0.47, wpb=109.2, bsz=40, num_updates=15110, lr=4.52896e-05, gnorm=0.347, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60616
2023-01-07 07:41:20 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 07:41:40 - progress_bar.py[line:274] - INFO: epoch 001:  15141 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.333, nsentences=40, sample_size=109.333, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5096, wps=98.8, ups=0.43, wpb=109.3, bsz=40, num_updates=15120, lr=4.52851e-05, gnorm=0.477, clip=10, loss_scale=512, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=60640
2023-01-07 07:42:01 - progress_bar.py[line:274] - INFO: epoch 001:  15151 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3692, wps=100.3, ups=0.46, wpb=108, bsz=40, num_updates=15130, lr=4.52806e-05, gnorm=0.319, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60662
2023-01-07 07:42:23 - progress_bar.py[line:274] - INFO: epoch 001:  15161 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4697, wps=101.1, ups=0.46, wpb=109.8, bsz=40, num_updates=15140, lr=4.52761e-05, gnorm=0.301, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=60683
2023-01-07 07:42:45 - progress_bar.py[line:274] - INFO: epoch 001:  15171 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4381, wps=102, ups=0.46, wpb=109.8, bsz=40, num_updates=15150, lr=4.52716e-05, gnorm=0.239, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60705
2023-01-07 07:43:07 - progress_bar.py[line:274] - INFO: epoch 001:  15181 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4886, wps=102.8, ups=0.47, wpb=109.5, bsz=40, num_updates=15160, lr=4.52671e-05, gnorm=0.211, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60727
2023-01-07 07:43:29 - progress_bar.py[line:274] - INFO: epoch 001:  15191 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4346, wps=97.9, ups=0.46, wpb=106.5, bsz=40, num_updates=15170, lr=4.52627e-05, gnorm=0.272, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60749
2023-01-07 07:43:50 - progress_bar.py[line:274] - INFO: epoch 001:  15201 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.484, wps=102.1, ups=0.46, wpb=110.7, bsz=40, num_updates=15180, lr=4.52582e-05, gnorm=0.352, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=60771
2023-01-07 07:44:12 - progress_bar.py[line:274] - INFO: epoch 001:  15211 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4272, wps=101.5, ups=0.46, wpb=109.3, bsz=40, num_updates=15190, lr=4.52537e-05, gnorm=0.271, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=60792
2023-01-07 07:44:34 - progress_bar.py[line:274] - INFO: epoch 001:  15221 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4313, wps=102.1, ups=0.47, wpb=108.9, bsz=40, num_updates=15200, lr=4.52492e-05, gnorm=0.372, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60814
2023-01-07 07:44:55 - progress_bar.py[line:274] - INFO: epoch 001:  15231 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4185, wps=102.5, ups=0.47, wpb=109.5, bsz=40, num_updates=15210, lr=4.52447e-05, gnorm=0.256, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60836
2023-01-07 07:45:17 - progress_bar.py[line:274] - INFO: epoch 001:  15241 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.455, wps=101.3, ups=0.46, wpb=108.9, bsz=40, num_updates=15220, lr=4.52402e-05, gnorm=0.294, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=60857
2023-01-07 07:45:39 - progress_bar.py[line:274] - INFO: epoch 001:  15251 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5079, wps=101.1, ups=0.46, wpb=109.8, bsz=40, num_updates=15230, lr=4.52357e-05, gnorm=0.176, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60879
2023-01-07 07:46:01 - progress_bar.py[line:274] - INFO: epoch 001:  15261 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5132, wps=102.7, ups=0.47, wpb=109.8, bsz=40, num_updates=15240, lr=4.52312e-05, gnorm=0.349, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60901
2023-01-07 07:46:22 - progress_bar.py[line:274] - INFO: epoch 001:  15271 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4466, wps=102.9, ups=0.47, wpb=108.5, bsz=40, num_updates=15250, lr=4.52267e-05, gnorm=0.349, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60922
2023-01-07 07:46:44 - progress_bar.py[line:274] - INFO: epoch 001:  15281 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4272, wps=102.3, ups=0.47, wpb=109.1, bsz=40, num_updates=15260, lr=4.52222e-05, gnorm=0.263, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60944
2023-01-07 07:47:05 - progress_bar.py[line:274] - INFO: epoch 001:  15291 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4508, wps=103.7, ups=0.47, wpb=109.9, bsz=40, num_updates=15270, lr=4.52177e-05, gnorm=0.237, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60965
2023-01-07 07:47:27 - progress_bar.py[line:274] - INFO: epoch 001:  15301 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4667, wps=98.9, ups=0.46, wpb=108.4, bsz=40, num_updates=15280, lr=4.52132e-05, gnorm=0.309, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60987
2023-01-07 07:47:49 - progress_bar.py[line:274] - INFO: epoch 001:  15311 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4802, wps=100.8, ups=0.46, wpb=109.4, bsz=40, num_updates=15290, lr=4.52087e-05, gnorm=0.193, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61009
2023-01-07 07:48:11 - progress_bar.py[line:274] - INFO: epoch 001:  15321 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.375, wps=100.3, ups=0.46, wpb=108.8, bsz=40, num_updates=15300, lr=4.52042e-05, gnorm=0.372, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61031
2023-01-07 07:48:33 - progress_bar.py[line:274] - INFO: epoch 001:  15331 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4101, wps=100.9, ups=0.46, wpb=109.2, bsz=40, num_updates=15310, lr=4.51997e-05, gnorm=0.532, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=61053
2023-01-07 07:48:55 - progress_bar.py[line:274] - INFO: epoch 001:  15341 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4136, wps=100.5, ups=0.46, wpb=109.5, bsz=40, num_updates=15320, lr=4.51952e-05, gnorm=0.381, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61075
2023-01-07 07:49:16 - progress_bar.py[line:274] - INFO: epoch 001:  15351 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4227, wps=103.4, ups=0.47, wpb=110.1, bsz=40, num_updates=15330, lr=4.51907e-05, gnorm=0.386, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=61097
2023-01-07 07:49:38 - progress_bar.py[line:274] - INFO: epoch 001:  15361 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4588, wps=100.3, ups=0.46, wpb=109.5, bsz=40, num_updates=15340, lr=4.51862e-05, gnorm=0.358, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=61119
2023-01-07 07:50:01 - progress_bar.py[line:274] - INFO: epoch 001:  15371 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.396, wps=98.3, ups=0.45, wpb=108.1, bsz=40, num_updates=15350, lr=4.51817e-05, gnorm=0.45, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61141
2023-01-07 07:50:22 - progress_bar.py[line:274] - INFO: epoch 001:  15381 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4263, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=15360, lr=4.51772e-05, gnorm=0.257, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61162
2023-01-07 07:50:44 - progress_bar.py[line:274] - INFO: epoch 001:  15391 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4124, wps=104.1, ups=0.47, wpb=110.7, bsz=40, num_updates=15370, lr=4.51727e-05, gnorm=0.293, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=61184
2023-01-07 07:51:05 - progress_bar.py[line:274] - INFO: epoch 001:  15401 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4585, wps=103.6, ups=0.48, wpb=108.2, bsz=40, num_updates=15380, lr=4.51682e-05, gnorm=0.413, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=61205
2023-01-07 07:51:26 - progress_bar.py[line:274] - INFO: epoch 001:  15411 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4009, wps=103.3, ups=0.47, wpb=109, bsz=40, num_updates=15390, lr=4.51637e-05, gnorm=0.392, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61226
2023-01-07 07:51:48 - progress_bar.py[line:274] - INFO: epoch 001:  15421 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3821, wps=102.3, ups=0.47, wpb=107.8, bsz=40, num_updates=15400, lr=4.51592e-05, gnorm=0.312, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=61248
2023-01-07 07:52:09 - progress_bar.py[line:274] - INFO: epoch 001:  15431 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3671, wps=100.3, ups=0.46, wpb=108, bsz=40, num_updates=15410, lr=4.51547e-05, gnorm=0.266, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61270
2023-01-07 07:52:31 - progress_bar.py[line:274] - INFO: epoch 001:  15441 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4474, wps=100.9, ups=0.46, wpb=109.6, bsz=40, num_updates=15420, lr=4.51503e-05, gnorm=0.349, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61292
2023-01-07 07:52:53 - progress_bar.py[line:274] - INFO: epoch 001:  15451 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4545, wps=101.6, ups=0.46, wpb=110.3, bsz=40, num_updates=15430, lr=4.51458e-05, gnorm=0.328, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=61314
2023-01-07 07:53:14 - progress_bar.py[line:274] - INFO: epoch 001:  15461 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4009, wps=102.6, ups=0.48, wpb=107.2, bsz=40, num_updates=15440, lr=4.51413e-05, gnorm=0.484, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61335
2023-01-07 07:53:36 - progress_bar.py[line:274] - INFO: epoch 001:  15471 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4422, wps=99.7, ups=0.46, wpb=108.2, bsz=40, num_updates=15450, lr=4.51368e-05, gnorm=0.369, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61357
2023-01-07 07:53:58 - progress_bar.py[line:274] - INFO: epoch 001:  15481 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5172, wps=101.5, ups=0.47, wpb=108.4, bsz=40, num_updates=15460, lr=4.51323e-05, gnorm=0.323, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61378
2023-01-07 07:54:19 - progress_bar.py[line:274] - INFO: epoch 001:  15491 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4462, wps=103.3, ups=0.48, wpb=108.7, bsz=40, num_updates=15470, lr=4.51278e-05, gnorm=0.463, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61400
2023-01-07 07:54:41 - progress_bar.py[line:274] - INFO: epoch 001:  15501 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4241, wps=102.7, ups=0.47, wpb=110, bsz=40, num_updates=15480, lr=4.51233e-05, gnorm=0.386, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=61421
2023-01-07 07:55:03 - progress_bar.py[line:274] - INFO: epoch 001:  15511 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4245, wps=100.3, ups=0.46, wpb=109.3, bsz=40, num_updates=15490, lr=4.51188e-05, gnorm=0.386, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61443
2023-01-07 07:55:25 - progress_bar.py[line:274] - INFO: epoch 001:  15521 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4187, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=15500, lr=4.51143e-05, gnorm=0.388, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=61465
2023-01-07 07:55:47 - progress_bar.py[line:274] - INFO: epoch 001:  15531 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.435, wps=102.5, ups=0.47, wpb=110.1, bsz=40, num_updates=15510, lr=4.51098e-05, gnorm=0.219, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=61487
2023-01-07 07:56:08 - progress_bar.py[line:274] - INFO: epoch 001:  15541 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4222, wps=102.6, ups=0.47, wpb=110.3, bsz=40, num_updates=15520, lr=4.51053e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=61509
2023-01-07 07:56:30 - progress_bar.py[line:274] - INFO: epoch 001:  15551 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4422, wps=101.8, ups=0.47, wpb=109.4, bsz=40, num_updates=15530, lr=4.51008e-05, gnorm=0.424, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61530
2023-01-07 07:56:52 - progress_bar.py[line:274] - INFO: epoch 001:  15561 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4502, wps=99.7, ups=0.46, wpb=108.3, bsz=40, num_updates=15540, lr=4.50963e-05, gnorm=0.408, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=61552
2023-01-07 07:57:14 - progress_bar.py[line:274] - INFO: epoch 001:  15571 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4398, wps=102.4, ups=0.46, wpb=110.1, bsz=40, num_updates=15550, lr=4.50918e-05, gnorm=0.39, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61574
2023-01-07 07:57:35 - progress_bar.py[line:274] - INFO: epoch 001:  15581 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4554, wps=102.3, ups=0.47, wpb=108.1, bsz=40, num_updates=15560, lr=4.50873e-05, gnorm=0.237, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61595
2023-01-07 07:57:57 - progress_bar.py[line:274] - INFO: epoch 001:  15591 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4527, wps=102, ups=0.47, wpb=109.6, bsz=40, num_updates=15570, lr=4.50828e-05, gnorm=0.298, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=61617
2023-01-07 07:58:19 - progress_bar.py[line:274] - INFO: epoch 001:  15601 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4475, wps=99.5, ups=0.46, wpb=109.2, bsz=40, num_updates=15580, lr=4.50783e-05, gnorm=0.282, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61639
2023-01-07 07:58:41 - progress_bar.py[line:274] - INFO: epoch 001:  15611 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3491, wps=99.3, ups=0.46, wpb=108.1, bsz=40, num_updates=15590, lr=4.50738e-05, gnorm=0.522, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=61661
2023-01-07 07:59:02 - progress_bar.py[line:274] - INFO: epoch 001:  15621 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4976, wps=102.7, ups=0.47, wpb=108.6, bsz=40, num_updates=15600, lr=4.50693e-05, gnorm=0.316, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61683
2023-01-07 07:59:25 - progress_bar.py[line:274] - INFO: epoch 001:  15631 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3737, wps=100, ups=0.46, wpb=109.1, bsz=40, num_updates=15610, lr=4.50648e-05, gnorm=0.347, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61705
2023-01-07 07:59:46 - progress_bar.py[line:274] - INFO: epoch 001:  15641 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.455, wps=102, ups=0.47, wpb=108.9, bsz=40, num_updates=15620, lr=4.50603e-05, gnorm=0.547, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61726
2023-01-07 08:00:08 - progress_bar.py[line:274] - INFO: epoch 001:  15651 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4362, wps=102.5, ups=0.46, wpb=110.7, bsz=40, num_updates=15630, lr=4.50558e-05, gnorm=0.361, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61748
2023-01-07 08:00:30 - progress_bar.py[line:274] - INFO: epoch 001:  15661 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4844, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=15640, lr=4.50513e-05, gnorm=0.373, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61770
2023-01-07 08:00:51 - progress_bar.py[line:274] - INFO: epoch 001:  15671 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4623, wps=102.9, ups=0.47, wpb=109.1, bsz=40, num_updates=15650, lr=4.50468e-05, gnorm=0.358, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61791
2023-01-07 08:01:13 - progress_bar.py[line:274] - INFO: epoch 001:  15681 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4721, wps=102.5, ups=0.47, wpb=110, bsz=40, num_updates=15660, lr=4.50424e-05, gnorm=0.216, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61813
2023-01-07 08:01:35 - progress_bar.py[line:274] - INFO: epoch 001:  15691 / 115845 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4598, wps=103.3, ups=0.46, wpb=111.1, bsz=40, num_updates=15670, lr=4.50379e-05, gnorm=0.267, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61835
2023-01-07 08:01:57 - progress_bar.py[line:274] - INFO: epoch 001:  15701 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.445, wps=101.9, ups=0.46, wpb=110.4, bsz=40, num_updates=15680, lr=4.50334e-05, gnorm=0.251, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=61857
2023-01-07 08:02:18 - progress_bar.py[line:274] - INFO: epoch 001:  15711 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.465, wps=102, ups=0.46, wpb=109.8, bsz=40, num_updates=15690, lr=4.50289e-05, gnorm=0.374, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=61878
2023-01-07 08:02:40 - progress_bar.py[line:274] - INFO: epoch 001:  15721 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4466, wps=100.3, ups=0.46, wpb=108.1, bsz=40, num_updates=15700, lr=4.50244e-05, gnorm=0.286, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=61900
2023-01-07 08:02:42 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 08:03:04 - progress_bar.py[line:274] - INFO: epoch 001:  15732 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4167, wps=94.8, ups=0.42, wpb=108, bsz=40, num_updates=15710, lr=4.50199e-05, gnorm=0.304, clip=0, loss_scale=512, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=61924
2023-01-07 08:03:26 - progress_bar.py[line:274] - INFO: epoch 001:  15742 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4607, wps=102.8, ups=0.47, wpb=109.4, bsz=40, num_updates=15720, lr=4.50154e-05, gnorm=0.224, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=61946
2023-01-07 08:03:48 - progress_bar.py[line:274] - INFO: epoch 001:  15752 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4607, wps=100.3, ups=0.46, wpb=108.7, bsz=40, num_updates=15730, lr=4.50109e-05, gnorm=0.311, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=61968
2023-01-07 08:04:09 - progress_bar.py[line:274] - INFO: epoch 001:  15762 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4709, wps=101.5, ups=0.47, wpb=108.6, bsz=40, num_updates=15740, lr=4.50064e-05, gnorm=0.481, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=61989
2023-01-07 08:04:31 - progress_bar.py[line:274] - INFO: epoch 001:  15772 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.403, wps=102.2, ups=0.47, wpb=108.9, bsz=40, num_updates=15750, lr=4.50019e-05, gnorm=0.277, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=62011
2023-01-07 08:04:52 - progress_bar.py[line:274] - INFO: epoch 001:  15782 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4667, wps=103, ups=0.47, wpb=109.6, bsz=40, num_updates=15760, lr=4.49974e-05, gnorm=0.407, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62032
2023-01-07 08:05:14 - progress_bar.py[line:274] - INFO: epoch 001:  15792 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4712, wps=99.8, ups=0.46, wpb=108.9, bsz=40, num_updates=15770, lr=4.49929e-05, gnorm=0.288, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=62055
2023-01-07 08:05:36 - progress_bar.py[line:274] - INFO: epoch 001:  15802 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4216, wps=99.8, ups=0.46, wpb=108.7, bsz=40, num_updates=15780, lr=4.49884e-05, gnorm=0.572, clip=30, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=62077
2023-01-07 08:05:58 - progress_bar.py[line:274] - INFO: epoch 001:  15812 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4872, wps=103.1, ups=0.47, wpb=110.1, bsz=40, num_updates=15790, lr=4.49839e-05, gnorm=0.3, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=62098
2023-01-07 08:06:20 - progress_bar.py[line:274] - INFO: epoch 001:  15822 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4545, wps=101.6, ups=0.47, wpb=109.1, bsz=40, num_updates=15800, lr=4.49794e-05, gnorm=0.392, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62120
2023-01-07 08:06:41 - progress_bar.py[line:274] - INFO: epoch 001:  15832 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4396, wps=103, ups=0.47, wpb=109.7, bsz=40, num_updates=15810, lr=4.49749e-05, gnorm=0.433, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=62141
2023-01-07 08:07:03 - progress_bar.py[line:274] - INFO: epoch 001:  15842 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3782, wps=99.7, ups=0.46, wpb=108.1, bsz=40, num_updates=15820, lr=4.49704e-05, gnorm=0.275, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=62163
2023-01-07 08:07:25 - progress_bar.py[line:274] - INFO: epoch 001:  15852 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4171, wps=102.8, ups=0.47, wpb=110.1, bsz=40, num_updates=15830, lr=4.49659e-05, gnorm=0.222, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62185
2023-01-07 08:07:46 - progress_bar.py[line:274] - INFO: epoch 001:  15862 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4241, wps=105.6, ups=0.48, wpb=110.4, bsz=40, num_updates=15840, lr=4.49614e-05, gnorm=0.296, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=62206
2023-01-07 08:08:07 - progress_bar.py[line:274] - INFO: epoch 001:  15872 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.46, wps=101.9, ups=0.47, wpb=108.8, bsz=40, num_updates=15850, lr=4.49569e-05, gnorm=0.274, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62228
2023-01-07 08:08:29 - progress_bar.py[line:274] - INFO: epoch 001:  15882 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.402, wps=102.5, ups=0.47, wpb=109.3, bsz=40, num_updates=15860, lr=4.49524e-05, gnorm=0.254, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=62249
2023-01-07 08:08:51 - progress_bar.py[line:274] - INFO: epoch 001:  15892 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4375, wps=102.8, ups=0.47, wpb=109.8, bsz=40, num_updates=15870, lr=4.49479e-05, gnorm=0.304, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=62271
2023-01-07 08:09:12 - progress_bar.py[line:274] - INFO: epoch 001:  15902 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4769, wps=100.2, ups=0.46, wpb=107.9, bsz=40, num_updates=15880, lr=4.49434e-05, gnorm=0.348, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62293
2023-01-07 08:09:34 - progress_bar.py[line:274] - INFO: epoch 001:  15912 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4413, wps=99.2, ups=0.46, wpb=107.7, bsz=40, num_updates=15890, lr=4.49389e-05, gnorm=0.556, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62315
2023-01-07 08:09:56 - progress_bar.py[line:274] - INFO: epoch 001:  15922 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4019, wps=102.1, ups=0.47, wpb=108, bsz=40, num_updates=15900, lr=4.49344e-05, gnorm=0.51, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62336
2023-01-07 08:10:18 - progress_bar.py[line:274] - INFO: epoch 001:  15932 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4272, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=15910, lr=4.493e-05, gnorm=0.272, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=62358
2023-01-07 08:10:40 - progress_bar.py[line:274] - INFO: epoch 001:  15942 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=101, ups=0.46, wpb=110.9, bsz=40, num_updates=15920, lr=4.49255e-05, gnorm=0.229, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=62380
2023-01-07 08:11:02 - progress_bar.py[line:274] - INFO: epoch 001:  15952 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3834, wps=101.3, ups=0.47, wpb=108.7, bsz=40, num_updates=15930, lr=4.4921e-05, gnorm=0.454, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=62402
2023-01-07 08:11:23 - progress_bar.py[line:274] - INFO: epoch 001:  15962 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4141, wps=101.9, ups=0.47, wpb=108.9, bsz=40, num_updates=15940, lr=4.49165e-05, gnorm=0.307, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62423
2023-01-07 08:11:44 - progress_bar.py[line:274] - INFO: epoch 001:  15972 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4009, wps=102.1, ups=0.47, wpb=107.9, bsz=40, num_updates=15950, lr=4.4912e-05, gnorm=0.411, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=62445
2023-01-07 08:12:06 - progress_bar.py[line:274] - INFO: epoch 001:  15982 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4627, wps=103, ups=0.48, wpb=107.6, bsz=40, num_updates=15960, lr=4.49075e-05, gnorm=0.249, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62466
2023-01-07 08:12:28 - progress_bar.py[line:274] - INFO: epoch 001:  15992 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4257, wps=102.2, ups=0.46, wpb=110.9, bsz=40, num_updates=15970, lr=4.4903e-05, gnorm=0.331, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62488
2023-01-07 08:12:49 - progress_bar.py[line:274] - INFO: epoch 001:  16002 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4062, wps=102.2, ups=0.47, wpb=109.4, bsz=40, num_updates=15980, lr=4.48985e-05, gnorm=0.351, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62509
2023-01-07 08:13:11 - progress_bar.py[line:274] - INFO: epoch 001:  16012 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.393, wps=101.9, ups=0.47, wpb=109.3, bsz=40, num_updates=15990, lr=4.4894e-05, gnorm=0.22, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=62531
2023-01-07 08:13:33 - progress_bar.py[line:274] - INFO: epoch 001:  16022 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4162, wps=102, ups=0.46, wpb=109.9, bsz=40, num_updates=16000, lr=4.48895e-05, gnorm=0.563, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62553
2023-01-07 08:13:33 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 08:13:34 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 08:13:34 - train.py[line:551] - INFO: load:1.17 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 08:16:05 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 08:16:05 - train.py[line:551] - INFO: load:1.20 valid_run:150.95 task_valid:146.24 collect_output:3.64
2023-01-07 08:18:34 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 08:18:34 - train.py[line:551] - INFO: load:1.22 valid_run:299.43 task_valid:287.93 collect_output:9.38
2023-01-07 08:21:07 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 08:21:07 - train.py[line:551] - INFO: load:1.25 valid_run:452.51 task_valid:429.38 collect_output:19.96
2023-01-07 08:23:35 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 08:23:35 - train.py[line:551] - INFO: load:1.27 valid_run:600.93 task_valid:572.73 collect_output:24.00
2023-01-07 08:26:07 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 08:26:07 - train.py[line:551] - INFO: load:1.30 valid_run:752.63 task_valid:718.58 collect_output:28.81
2023-01-07 08:28:39 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 08:28:39 - train.py[line:551] - INFO: load:1.32 valid_run:904.16 task_valid:862.71 collect_output:35.16
2023-01-07 08:31:12 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 08:31:12 - train.py[line:551] - INFO: load:1.35 valid_run:1057.50 task_valid:1007.01 collect_output:43.14
2023-01-07 08:33:44 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 08:33:44 - train.py[line:551] - INFO: load:1.37 valid_run:1208.74 task_valid:1146.52 collect_output:53.81
2023-01-07 08:36:13 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 08:36:13 - train.py[line:551] - INFO: load:1.40 valid_run:1357.84 task_valid:1289.57 collect_output:58.81
2023-01-07 08:38:41 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 08:38:41 - train.py[line:551] - INFO: load:1.42 valid_run:1506.23 task_valid:1431.48 collect_output:64.24
2023-01-07 08:41:11 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 08:41:11 - train.py[line:551] - INFO: load:1.45 valid_run:1655.50 task_valid:1574.86 collect_output:69.09
2023-01-07 08:43:40 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 08:43:40 - train.py[line:551] - INFO: load:1.47 valid_run:1805.03 task_valid:1718.22 collect_output:74.22
2023-01-07 08:46:10 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 08:46:10 - train.py[line:551] - INFO: load:1.50 valid_run:1954.87 task_valid:1858.50 collect_output:82.74
2023-01-07 08:48:40 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 08:48:40 - train.py[line:551] - INFO: load:1.52 valid_run:2104.89 task_valid:2002.64 collect_output:87.56
2023-01-07 08:51:10 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 08:51:10 - train.py[line:551] - INFO: load:1.55 valid_run:2254.03 task_valid:2147.59 collect_output:90.70
2023-01-07 08:53:40 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 08:53:40 - train.py[line:551] - INFO: load:1.58 valid_run:2403.90 task_valid:2290.35 collect_output:96.75
2023-01-07 08:56:11 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 08:56:11 - train.py[line:551] - INFO: load:1.60 valid_run:2555.33 task_valid:2434.31 collect_output:103.16
2023-01-07 08:58:41 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 08:58:41 - train.py[line:551] - INFO: load:1.63 valid_run:2704.95 task_valid:2579.63 collect_output:106.40
2023-01-07 09:01:09 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 09:01:09 - train.py[line:551] - INFO: load:1.65 valid_run:2853.31 task_valid:2719.94 collect_output:113.41
2023-01-07 09:03:39 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 09:03:39 - train.py[line:551] - INFO: load:1.68 valid_run:3003.34 task_valid:2863.48 collect_output:118.84
2023-01-07 09:06:11 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 09:06:11 - train.py[line:551] - INFO: load:1.71 valid_run:3155.10 task_valid:3006.50 collect_output:126.51
2023-01-07 09:08:40 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 09:08:40 - train.py[line:551] - INFO: load:1.73 valid_run:3303.66 task_valid:3149.32 collect_output:131.20
2023-01-07 09:11:11 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 09:11:11 - train.py[line:551] - INFO: load:1.76 valid_run:3454.53 task_valid:3293.99 collect_output:136.35
2023-01-07 09:13:42 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 09:13:42 - train.py[line:551] - INFO: load:1.79 valid_run:3605.24 task_valid:3439.02 collect_output:140.99

====================================================================================================
SGG eval:     R @ 50: 0.4586;     R @ 100: 0.5339;     R @ 500: 0.5765;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2923;    mR @ 100: 0.3626;    mR @ 500: 0.4022;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7024) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.5000) (parked on:0.9062) (playing:0.0000) (riding:0.7190) (says:0.0000) (sitting on:0.6786) (standing on:0.1958) (using:0.6000) (walking in:0.0000) (walking on:0.3514) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-07 09:16:12 - train.py[line:487] - INFO: 0.5339285714285714

====================================================================================================
SGG eval:     R @ 50: 0.4586;     R @ 100: 0.5339;     R @ 500: 0.5765;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2923;    mR @ 100: 0.3626;    mR @ 500: 0.4022;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7024) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.5000) (parked on:0.9062) (playing:0.0000) (riding:0.7190) (says:0.0000) (sitting on:0.6786) (standing on:0.1958) (using:0.6000) (walking in:0.0000) (walking on:0.3514) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-07 09:16:12 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-07 09:16:12 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.396 | loss_v1 0 | loss_v2 0 | nll_loss 0.247 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.533929 | ppl 1.19 | vqa_score 0.4561 | wps 119.4 | wpb 89.9 | bsz 30 | num_updates 16000 | best_R@100 0.637221
2023-01-07 09:16:12 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 16000 updates
2023-01-07 09:16:12 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_16000.pt
2023-01-07 09:16:59 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_16000.pt
2023-01-07 09:18:30 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_16000.pt (epoch 1 @ 16000 updates, score 0.5339285714285714) (writing took 137.162626799196 seconds)
2023-01-07 09:18:52 - progress_bar.py[line:274] - INFO: epoch 001:  16032 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4607, wps=0.6, ups=0, wpb=108.8, bsz=40, num_updates=16010, lr=4.4885e-05, gnorm=0.382, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66472
2023-01-07 09:19:14 - progress_bar.py[line:274] - INFO: epoch 001:  16042 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.442, wps=100.9, ups=0.46, wpb=110.5, bsz=40, num_updates=16020, lr=4.48805e-05, gnorm=0.472, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=66494
2023-01-07 09:19:37 - progress_bar.py[line:274] - INFO: epoch 001:  16052 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4776, wps=101.2, ups=0.46, wpb=109.7, bsz=40, num_updates=16030, lr=4.4876e-05, gnorm=0.294, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66516
2023-01-07 09:19:59 - progress_bar.py[line:274] - INFO: epoch 001:  16062 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4352, wps=101.6, ups=0.46, wpb=109.5, bsz=40, num_updates=16040, lr=4.48715e-05, gnorm=0.342, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=66539
2023-01-07 09:20:21 - progress_bar.py[line:274] - INFO: epoch 001:  16072 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4356, wps=99.1, ups=0.46, wpb=108.3, bsz=40, num_updates=16050, lr=4.4867e-05, gnorm=0.405, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66561
2023-01-07 09:20:43 - progress_bar.py[line:274] - INFO: epoch 001:  16082 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4124, wps=104.5, ups=0.47, wpb=110.2, bsz=40, num_updates=16060, lr=4.48625e-05, gnorm=0.403, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=66583
2023-01-07 09:21:05 - progress_bar.py[line:274] - INFO: epoch 001:  16092 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4128, wps=100, ups=0.46, wpb=107.5, bsz=40, num_updates=16070, lr=4.4858e-05, gnorm=0.273, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=66605
2023-01-07 09:21:27 - progress_bar.py[line:274] - INFO: epoch 001:  16102 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4569, wps=102.8, ups=0.47, wpb=108.8, bsz=40, num_updates=16080, lr=4.48535e-05, gnorm=0.354, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=66627
2023-01-07 09:21:50 - progress_bar.py[line:274] - INFO: epoch 001:  16112 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4262, wps=100.1, ups=0.46, wpb=109.9, bsz=40, num_updates=16090, lr=4.4849e-05, gnorm=0.251, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66650
2023-01-07 09:22:11 - progress_bar.py[line:274] - INFO: epoch 001:  16122 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.436, wps=102.9, ups=0.48, wpb=107.6, bsz=40, num_updates=16100, lr=4.48445e-05, gnorm=0.349, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=66671
2023-01-07 09:22:34 - progress_bar.py[line:274] - INFO: epoch 001:  16132 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3874, wps=101.2, ups=0.46, wpb=110.6, bsz=40, num_updates=16110, lr=4.484e-05, gnorm=0.341, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66694
2023-01-07 09:22:56 - progress_bar.py[line:274] - INFO: epoch 001:  16142 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.424, wps=100.4, ups=0.47, wpb=107.2, bsz=40, num_updates=16120, lr=4.48355e-05, gnorm=0.436, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=66716
2023-01-07 09:23:17 - progress_bar.py[line:274] - INFO: epoch 001:  16152 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4072, wps=105.3, ups=0.48, wpb=109.1, bsz=40, num_updates=16130, lr=4.4831e-05, gnorm=0.276, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=66737
2023-01-07 09:23:39 - progress_bar.py[line:274] - INFO: epoch 001:  16162 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3807, wps=103, ups=0.47, wpb=108.9, bsz=40, num_updates=16140, lr=4.48265e-05, gnorm=0.421, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=66759
2023-01-07 09:24:01 - progress_bar.py[line:274] - INFO: epoch 001:  16172 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4627, wps=99, ups=0.46, wpb=108.3, bsz=40, num_updates=16150, lr=4.48221e-05, gnorm=0.347, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66781
2023-01-07 09:24:23 - progress_bar.py[line:274] - INFO: epoch 001:  16182 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4372, wps=104, ups=0.47, wpb=110.3, bsz=40, num_updates=16160, lr=4.48176e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=66803
2023-01-07 09:24:45 - progress_bar.py[line:274] - INFO: epoch 001:  16192 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4082, wps=100.4, ups=0.46, wpb=108.8, bsz=40, num_updates=16170, lr=4.48131e-05, gnorm=0.281, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=66825
2023-01-07 09:25:07 - progress_bar.py[line:274] - INFO: epoch 001:  16202 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.402, wps=103.9, ups=0.48, wpb=108.9, bsz=40, num_updates=16180, lr=4.48086e-05, gnorm=0.365, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=66847
2023-01-07 09:25:29 - progress_bar.py[line:274] - INFO: epoch 001:  16212 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4512, wps=98.8, ups=0.46, wpb=107.4, bsz=40, num_updates=16190, lr=4.48041e-05, gnorm=0.346, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66869
2023-01-07 09:25:51 - progress_bar.py[line:274] - INFO: epoch 001:  16222 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4734, wps=101.8, ups=0.47, wpb=108.3, bsz=40, num_updates=16200, lr=4.47996e-05, gnorm=0.335, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=66891
2023-01-07 09:26:14 - progress_bar.py[line:274] - INFO: epoch 001:  16232 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4171, wps=101.2, ups=0.46, wpb=110.2, bsz=40, num_updates=16210, lr=4.47951e-05, gnorm=0.481, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66913
2023-01-07 09:26:35 - progress_bar.py[line:274] - INFO: epoch 001:  16242 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4879, wps=102, ups=0.47, wpb=107.8, bsz=40, num_updates=16220, lr=4.47906e-05, gnorm=0.381, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=66935
2023-01-07 09:26:57 - progress_bar.py[line:274] - INFO: epoch 001:  16252 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4265, wps=101.5, ups=0.47, wpb=107.3, bsz=40, num_updates=16230, lr=4.47861e-05, gnorm=0.476, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=66957
2023-01-07 09:27:18 - progress_bar.py[line:274] - INFO: epoch 001:  16262 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4439, wps=102, ups=0.47, wpb=108.8, bsz=40, num_updates=16240, lr=4.47816e-05, gnorm=0.322, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=66979
2023-01-07 09:27:40 - progress_bar.py[line:274] - INFO: epoch 001:  16272 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4154, wps=101.3, ups=0.46, wpb=109.4, bsz=40, num_updates=16250, lr=4.47771e-05, gnorm=0.29, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=67000
2023-01-07 09:28:02 - progress_bar.py[line:274] - INFO: epoch 001:  16282 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.535, wps=100.1, ups=0.46, wpb=108.5, bsz=40, num_updates=16260, lr=4.47726e-05, gnorm=0.416, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67022
2023-01-07 09:28:24 - progress_bar.py[line:274] - INFO: epoch 001:  16292 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4129, wps=101.5, ups=0.47, wpb=109.1, bsz=40, num_updates=16270, lr=4.47681e-05, gnorm=0.388, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67044
2023-01-07 09:28:45 - progress_bar.py[line:274] - INFO: epoch 001:  16302 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4179, wps=103.8, ups=0.48, wpb=108.5, bsz=40, num_updates=16280, lr=4.47636e-05, gnorm=0.249, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67065
2023-01-07 09:29:07 - progress_bar.py[line:274] - INFO: epoch 001:  16312 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4691, wps=100.7, ups=0.46, wpb=109.8, bsz=40, num_updates=16290, lr=4.47591e-05, gnorm=0.405, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=67087
2023-01-07 09:29:29 - progress_bar.py[line:274] - INFO: epoch 001:  16322 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4739, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=16300, lr=4.47546e-05, gnorm=0.272, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=67109
2023-01-07 09:29:50 - progress_bar.py[line:274] - INFO: epoch 001:  16332 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4402, wps=98.9, ups=0.46, wpb=107.1, bsz=40, num_updates=16310, lr=4.47501e-05, gnorm=0.335, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=67131
2023-01-07 09:30:13 - progress_bar.py[line:274] - INFO: epoch 001:  16342 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4428, wps=98.4, ups=0.46, wpb=107.5, bsz=40, num_updates=16320, lr=4.47456e-05, gnorm=0.353, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67153
2023-01-07 09:30:34 - progress_bar.py[line:274] - INFO: epoch 001:  16352 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4432, wps=103, ups=0.46, wpb=110.8, bsz=40, num_updates=16330, lr=4.47411e-05, gnorm=0.375, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=67174
2023-01-07 09:30:56 - progress_bar.py[line:274] - INFO: epoch 001:  16362 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.455, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=16340, lr=4.47366e-05, gnorm=0.324, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67196
2023-01-07 09:31:18 - progress_bar.py[line:274] - INFO: epoch 001:  16372 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4545, wps=101.3, ups=0.47, wpb=108.9, bsz=40, num_updates=16350, lr=4.47321e-05, gnorm=0.296, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67218
2023-01-07 09:31:39 - progress_bar.py[line:274] - INFO: epoch 001:  16382 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4335, wps=102.2, ups=0.47, wpb=109.3, bsz=40, num_updates=16360, lr=4.47276e-05, gnorm=0.263, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67239
2023-01-07 09:32:01 - progress_bar.py[line:274] - INFO: epoch 001:  16392 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4402, wps=101.9, ups=0.46, wpb=109.8, bsz=40, num_updates=16370, lr=4.47231e-05, gnorm=0.248, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=67261
2023-01-07 09:32:23 - progress_bar.py[line:274] - INFO: epoch 001:  16402 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4626, wps=101.1, ups=0.47, wpb=108.1, bsz=40, num_updates=16380, lr=4.47186e-05, gnorm=0.245, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67283
2023-01-07 09:32:45 - progress_bar.py[line:274] - INFO: epoch 001:  16412 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4471, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=16390, lr=4.47141e-05, gnorm=0.33, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=67305
2023-01-07 09:33:06 - progress_bar.py[line:274] - INFO: epoch 001:  16422 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4083, wps=102.6, ups=0.47, wpb=108.8, bsz=40, num_updates=16400, lr=4.47097e-05, gnorm=0.181, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67326
2023-01-07 09:33:28 - progress_bar.py[line:274] - INFO: epoch 001:  16432 / 115845 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.465, wps=104.4, ups=0.47, wpb=111.6, bsz=40, num_updates=16410, lr=4.47052e-05, gnorm=0.307, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67348
2023-01-07 09:33:49 - progress_bar.py[line:274] - INFO: epoch 001:  16442 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4417, wps=103.6, ups=0.47, wpb=110.1, bsz=40, num_updates=16420, lr=4.47007e-05, gnorm=0.38, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67369
2023-01-07 09:34:11 - progress_bar.py[line:274] - INFO: epoch 001:  16452 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4975, wps=101, ups=0.47, wpb=108.5, bsz=40, num_updates=16430, lr=4.46962e-05, gnorm=0.274, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67391
2023-01-07 09:34:32 - progress_bar.py[line:274] - INFO: epoch 001:  16462 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4153, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=16440, lr=4.46917e-05, gnorm=0.41, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67413
2023-01-07 09:34:54 - progress_bar.py[line:274] - INFO: epoch 001:  16472 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4541, wps=103.7, ups=0.47, wpb=110.2, bsz=40, num_updates=16450, lr=4.46872e-05, gnorm=0.529, clip=20, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67434
2023-01-07 09:35:15 - progress_bar.py[line:274] - INFO: epoch 001:  16482 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4415, wps=103.1, ups=0.47, wpb=109.1, bsz=40, num_updates=16460, lr=4.46827e-05, gnorm=0.306, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67455
2023-01-07 09:35:37 - progress_bar.py[line:274] - INFO: epoch 001:  16492 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4706, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=16470, lr=4.46782e-05, gnorm=0.236, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67477
2023-01-07 09:35:58 - progress_bar.py[line:274] - INFO: epoch 001:  16502 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4108, wps=105.3, ups=0.48, wpb=110.2, bsz=40, num_updates=16480, lr=4.46737e-05, gnorm=0.38, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67498
2023-01-07 09:36:19 - progress_bar.py[line:274] - INFO: epoch 001:  16512 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3958, wps=105.2, ups=0.48, wpb=110.2, bsz=40, num_updates=16490, lr=4.46692e-05, gnorm=0.234, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=67519
2023-01-07 09:36:42 - progress_bar.py[line:274] - INFO: epoch 001:  16522 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4897, wps=99.4, ups=0.45, wpb=110.2, bsz=40, num_updates=16500, lr=4.46647e-05, gnorm=0.38, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=67542
2023-01-07 09:37:04 - progress_bar.py[line:274] - INFO: epoch 001:  16532 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4462, wps=100, ups=0.46, wpb=108.4, bsz=40, num_updates=16510, lr=4.46602e-05, gnorm=0.347, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67564
2023-01-07 09:37:25 - progress_bar.py[line:274] - INFO: epoch 001:  16542 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4663, wps=101.9, ups=0.47, wpb=109.4, bsz=40, num_updates=16520, lr=4.46557e-05, gnorm=0.299, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67585
2023-01-07 09:37:47 - progress_bar.py[line:274] - INFO: epoch 001:  16552 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4314, wps=103.4, ups=0.47, wpb=109.5, bsz=40, num_updates=16530, lr=4.46512e-05, gnorm=0.296, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67607
2023-01-07 09:38:09 - progress_bar.py[line:274] - INFO: epoch 001:  16562 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.47, wps=101.1, ups=0.46, wpb=109.9, bsz=40, num_updates=16540, lr=4.46467e-05, gnorm=0.307, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=67629
2023-01-07 09:38:31 - progress_bar.py[line:274] - INFO: epoch 001:  16572 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4861, wps=100.2, ups=0.46, wpb=109.1, bsz=40, num_updates=16550, lr=4.46422e-05, gnorm=0.294, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=67651
2023-01-07 09:38:52 - progress_bar.py[line:274] - INFO: epoch 001:  16582 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4372, wps=103.1, ups=0.47, wpb=108.9, bsz=40, num_updates=16560, lr=4.46377e-05, gnorm=0.27, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67672
2023-01-07 09:39:13 - progress_bar.py[line:274] - INFO: epoch 001:  16592 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4271, wps=103.2, ups=0.47, wpb=108.8, bsz=40, num_updates=16570, lr=4.46332e-05, gnorm=0.384, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67694
2023-01-07 09:39:35 - progress_bar.py[line:274] - INFO: epoch 001:  16602 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4337, wps=101.7, ups=0.46, wpb=109.9, bsz=40, num_updates=16580, lr=4.46287e-05, gnorm=0.29, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=67715
2023-01-07 09:39:57 - progress_bar.py[line:274] - INFO: epoch 001:  16612 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4271, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=16590, lr=4.46242e-05, gnorm=0.4, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=67737
2023-01-07 09:40:18 - progress_bar.py[line:274] - INFO: epoch 001:  16622 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4595, wps=103.5, ups=0.47, wpb=109.8, bsz=40, num_updates=16600, lr=4.46197e-05, gnorm=0.24, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=67759
2023-01-07 09:40:40 - progress_bar.py[line:274] - INFO: epoch 001:  16632 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4293, wps=101.6, ups=0.47, wpb=108.4, bsz=40, num_updates=16610, lr=4.46152e-05, gnorm=0.239, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67780
2023-01-07 09:41:02 - progress_bar.py[line:274] - INFO: epoch 001:  16642 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4492, wps=99.5, ups=0.45, wpb=109.7, bsz=40, num_updates=16620, lr=4.46107e-05, gnorm=0.266, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=67802
2023-01-07 09:41:24 - progress_bar.py[line:274] - INFO: epoch 001:  16652 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.484, wps=102.5, ups=0.47, wpb=109.5, bsz=40, num_updates=16630, lr=4.46062e-05, gnorm=0.415, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=67824
2023-01-07 09:41:46 - progress_bar.py[line:274] - INFO: epoch 001:  16662 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4244, wps=100.2, ups=0.46, wpb=108.8, bsz=40, num_updates=16640, lr=4.46018e-05, gnorm=0.341, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=67846
2023-01-07 09:42:07 - progress_bar.py[line:274] - INFO: epoch 001:  16672 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.42, wps=103.2, ups=0.47, wpb=109.2, bsz=40, num_updates=16650, lr=4.45973e-05, gnorm=0.292, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67867
2023-01-07 09:42:29 - progress_bar.py[line:274] - INFO: epoch 001:  16682 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4306, wps=100.4, ups=0.47, wpb=107.3, bsz=40, num_updates=16660, lr=4.45928e-05, gnorm=0.302, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67889
2023-01-07 09:42:51 - progress_bar.py[line:274] - INFO: epoch 001:  16692 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4028, wps=99.7, ups=0.46, wpb=108.2, bsz=40, num_updates=16670, lr=4.45883e-05, gnorm=0.236, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=67911
2023-01-07 09:43:12 - progress_bar.py[line:274] - INFO: epoch 001:  16702 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4745, wps=104, ups=0.47, wpb=110, bsz=40, num_updates=16680, lr=4.45838e-05, gnorm=0.514, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67932
2023-01-07 09:43:34 - progress_bar.py[line:274] - INFO: epoch 001:  16712 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.452, wps=104.3, ups=0.47, wpb=110.8, bsz=40, num_updates=16690, lr=4.45793e-05, gnorm=0.277, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=67954
2023-01-07 09:43:55 - progress_bar.py[line:274] - INFO: epoch 001:  16722 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4031, wps=100.4, ups=0.47, wpb=107.8, bsz=40, num_updates=16700, lr=4.45748e-05, gnorm=0.337, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=67976
2023-01-07 09:44:17 - progress_bar.py[line:274] - INFO: epoch 001:  16732 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.487, wps=103.7, ups=0.47, wpb=110.2, bsz=40, num_updates=16710, lr=4.45703e-05, gnorm=0.23, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=67997
2023-01-07 09:44:39 - progress_bar.py[line:274] - INFO: epoch 001:  16742 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4626, wps=99.5, ups=0.46, wpb=108.5, bsz=40, num_updates=16720, lr=4.45658e-05, gnorm=0.361, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68019
2023-01-07 09:45:01 - progress_bar.py[line:274] - INFO: epoch 001:  16752 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5052, wps=100.5, ups=0.46, wpb=109.1, bsz=40, num_updates=16730, lr=4.45613e-05, gnorm=0.299, clip=0, loss_scale=2048, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=68041
2023-01-07 09:45:23 - progress_bar.py[line:274] - INFO: epoch 001:  16762 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4249, wps=100.5, ups=0.46, wpb=109.1, bsz=40, num_updates=16740, lr=4.45568e-05, gnorm=0.302, clip=0, loss_scale=2048, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=68063
2023-01-07 09:45:44 - progress_bar.py[line:274] - INFO: epoch 001:  16772 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4271, wps=102.9, ups=0.47, wpb=109.7, bsz=40, num_updates=16750, lr=4.45523e-05, gnorm=0.365, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68084
2023-01-07 09:46:06 - progress_bar.py[line:274] - INFO: epoch 001:  16782 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4365, wps=102.5, ups=0.47, wpb=109.9, bsz=40, num_updates=16760, lr=4.45478e-05, gnorm=0.313, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68106
2023-01-07 09:46:28 - progress_bar.py[line:274] - INFO: epoch 001:  16792 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.42, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=16770, lr=4.45433e-05, gnorm=0.361, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68128
2023-01-07 09:46:49 - progress_bar.py[line:274] - INFO: epoch 001:  16802 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3902, wps=102.3, ups=0.47, wpb=109.4, bsz=40, num_updates=16780, lr=4.45388e-05, gnorm=0.326, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68150
2023-01-07 09:47:04 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-07 09:47:13 - progress_bar.py[line:274] - INFO: epoch 001:  16813 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.333, nsentences=40, sample_size=109.333, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4796, wps=98.2, ups=0.43, wpb=109.3, bsz=40, num_updates=16790, lr=4.45343e-05, gnorm=0.323, clip=0, loss_scale=1024, train_wall=23, gb_free=10, ema_decay=0.9999, wall=68173
2023-01-07 09:47:35 - progress_bar.py[line:274] - INFO: epoch 001:  16823 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4899, wps=102.3, ups=0.46, wpb=110.2, bsz=40, num_updates=16800, lr=4.45298e-05, gnorm=0.287, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68195
2023-01-07 09:47:57 - progress_bar.py[line:274] - INFO: epoch 001:  16833 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3915, wps=102.3, ups=0.46, wpb=110.8, bsz=40, num_updates=16810, lr=4.45253e-05, gnorm=0.276, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68217
2023-01-07 09:48:18 - progress_bar.py[line:274] - INFO: epoch 001:  16843 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4978, wps=99.8, ups=0.47, wpb=107.3, bsz=40, num_updates=16820, lr=4.45208e-05, gnorm=0.337, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68239
2023-01-07 09:48:40 - progress_bar.py[line:274] - INFO: epoch 001:  16853 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4428, wps=103.2, ups=0.48, wpb=108.6, bsz=40, num_updates=16830, lr=4.45163e-05, gnorm=0.378, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=68260
2023-01-07 09:49:01 - progress_bar.py[line:274] - INFO: epoch 001:  16863 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4162, wps=100.8, ups=0.47, wpb=108.3, bsz=40, num_updates=16840, lr=4.45118e-05, gnorm=0.214, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=68282
2023-01-07 09:49:23 - progress_bar.py[line:274] - INFO: epoch 001:  16873 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4923, wps=105.9, ups=0.48, wpb=110.3, bsz=40, num_updates=16850, lr=4.45073e-05, gnorm=0.335, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68303
2023-01-07 09:49:44 - progress_bar.py[line:274] - INFO: epoch 001:  16883 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3947, wps=103.6, ups=0.47, wpb=109.5, bsz=40, num_updates=16860, lr=4.45028e-05, gnorm=0.425, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68324
2023-01-07 09:50:05 - progress_bar.py[line:274] - INFO: epoch 001:  16893 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4627, wps=104.4, ups=0.47, wpb=110.6, bsz=40, num_updates=16870, lr=4.44983e-05, gnorm=0.341, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68346
2023-01-07 09:50:27 - progress_bar.py[line:274] - INFO: epoch 001:  16903 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4519, wps=102, ups=0.47, wpb=108.8, bsz=40, num_updates=16880, lr=4.44938e-05, gnorm=0.185, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=68367
2023-01-07 09:50:48 - progress_bar.py[line:274] - INFO: epoch 001:  16913 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4022, wps=103.7, ups=0.47, wpb=110.2, bsz=40, num_updates=16890, lr=4.44894e-05, gnorm=0.33, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68389
2023-01-07 09:51:10 - progress_bar.py[line:274] - INFO: epoch 001:  16923 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4463, wps=105, ups=0.48, wpb=109.9, bsz=40, num_updates=16900, lr=4.44849e-05, gnorm=0.454, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68410
2023-01-07 09:51:31 - progress_bar.py[line:274] - INFO: epoch 001:  16933 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4293, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=16910, lr=4.44804e-05, gnorm=0.25, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68432
2023-01-07 09:51:53 - progress_bar.py[line:274] - INFO: epoch 001:  16943 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4413, wps=103, ups=0.47, wpb=109, bsz=40, num_updates=16920, lr=4.44759e-05, gnorm=0.375, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68453
2023-01-07 09:52:14 - progress_bar.py[line:274] - INFO: epoch 001:  16953 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4536, wps=103.9, ups=0.47, wpb=110, bsz=40, num_updates=16930, lr=4.44714e-05, gnorm=0.305, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68474
2023-01-07 09:52:35 - progress_bar.py[line:274] - INFO: epoch 001:  16963 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4537, wps=104.1, ups=0.48, wpb=108.7, bsz=40, num_updates=16940, lr=4.44669e-05, gnorm=0.307, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=68496
2023-01-07 09:52:57 - progress_bar.py[line:274] - INFO: epoch 001:  16973 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4483, wps=100.6, ups=0.47, wpb=108.1, bsz=40, num_updates=16950, lr=4.44624e-05, gnorm=0.256, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=68517
2023-01-07 09:53:19 - progress_bar.py[line:274] - INFO: epoch 001:  16983 / 115845 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.48, wps=103.2, ups=0.46, wpb=111.1, bsz=40, num_updates=16960, lr=4.44579e-05, gnorm=0.182, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68539
2023-01-07 09:53:40 - progress_bar.py[line:274] - INFO: epoch 001:  16993 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4433, wps=101.3, ups=0.47, wpb=108, bsz=40, num_updates=16970, lr=4.44534e-05, gnorm=0.294, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=68561
2023-01-07 09:54:03 - progress_bar.py[line:274] - INFO: epoch 001:  17003 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.485, wps=100.6, ups=0.46, wpb=110, bsz=40, num_updates=16980, lr=4.44489e-05, gnorm=0.456, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=68583
2023-01-07 09:54:24 - progress_bar.py[line:274] - INFO: epoch 001:  17013 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.439, wps=104.3, ups=0.48, wpb=109.1, bsz=40, num_updates=16990, lr=4.44444e-05, gnorm=0.379, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68604
2023-01-07 09:54:46 - progress_bar.py[line:274] - INFO: epoch 001:  17023 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4365, wps=100.8, ups=0.46, wpb=109.3, bsz=40, num_updates=17000, lr=4.44399e-05, gnorm=0.224, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68626
2023-01-07 09:55:07 - progress_bar.py[line:274] - INFO: epoch 001:  17033 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4394, wps=104.3, ups=0.48, wpb=108.8, bsz=40, num_updates=17010, lr=4.44354e-05, gnorm=0.227, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=68647
2023-01-07 09:55:28 - progress_bar.py[line:274] - INFO: epoch 001:  17043 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.402, wps=101, ups=0.47, wpb=107.8, bsz=40, num_updates=17020, lr=4.44309e-05, gnorm=0.181, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=68668
2023-01-07 09:55:50 - progress_bar.py[line:274] - INFO: epoch 001:  17053 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4691, wps=100.7, ups=0.46, wpb=109.1, bsz=40, num_updates=17030, lr=4.44264e-05, gnorm=0.399, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=68690
2023-01-07 09:56:12 - progress_bar.py[line:274] - INFO: epoch 001:  17063 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4813, wps=99.8, ups=0.46, wpb=107.4, bsz=40, num_updates=17040, lr=4.44219e-05, gnorm=0.302, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68712
2023-01-07 09:56:33 - progress_bar.py[line:274] - INFO: epoch 001:  17073 / 115845 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.5225, wps=104.5, ups=0.47, wpb=111.3, bsz=40, num_updates=17050, lr=4.44174e-05, gnorm=0.247, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=68734
2023-01-07 09:56:55 - progress_bar.py[line:274] - INFO: epoch 001:  17083 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4118, wps=100.9, ups=0.47, wpb=108.2, bsz=40, num_updates=17060, lr=4.44129e-05, gnorm=0.393, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68755
2023-01-07 09:57:17 - progress_bar.py[line:274] - INFO: epoch 001:  17093 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4769, wps=99, ups=0.46, wpb=108.3, bsz=40, num_updates=17070, lr=4.44084e-05, gnorm=0.234, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=68777
2023-01-07 09:57:38 - progress_bar.py[line:274] - INFO: epoch 001:  17103 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4444, wps=104.8, ups=0.48, wpb=109.2, bsz=40, num_updates=17080, lr=4.44039e-05, gnorm=0.258, clip=0, loss_scale=1024, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=68798
2023-01-07 09:58:00 - progress_bar.py[line:274] - INFO: epoch 001:  17113 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4657, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=17090, lr=4.43994e-05, gnorm=0.316, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=68820
2023-01-07 09:58:22 - progress_bar.py[line:274] - INFO: epoch 001:  17123 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.48, wps=100.4, ups=0.46, wpb=109.9, bsz=40, num_updates=17100, lr=4.43949e-05, gnorm=0.278, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=68842
2023-01-07 09:58:43 - progress_bar.py[line:274] - INFO: epoch 001:  17133 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4478, wps=103.5, ups=0.47, wpb=109.5, bsz=40, num_updates=17110, lr=4.43904e-05, gnorm=0.271, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=68864
2023-01-07 09:59:05 - progress_bar.py[line:274] - INFO: epoch 001:  17143 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5053, wps=100.9, ups=0.46, wpb=109.2, bsz=40, num_updates=17120, lr=4.43859e-05, gnorm=0.435, clip=10, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=68885
2023-01-07 09:59:27 - progress_bar.py[line:274] - INFO: epoch 001:  17153 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.456, wps=104.5, ups=0.47, wpb=110.4, bsz=40, num_updates=17130, lr=4.43815e-05, gnorm=0.249, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=68907
2023-01-07 09:59:48 - progress_bar.py[line:274] - INFO: epoch 001:  17163 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3895, wps=103.2, ups=0.47, wpb=110.3, bsz=40, num_updates=17140, lr=4.4377e-05, gnorm=0.268, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68928
2023-01-07 10:00:10 - progress_bar.py[line:274] - INFO: epoch 001:  17173 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4596, wps=101.9, ups=0.46, wpb=110.4, bsz=40, num_updates=17150, lr=4.43725e-05, gnorm=0.197, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=68950
2023-01-07 10:00:32 - progress_bar.py[line:274] - INFO: epoch 001:  17183 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5147, wps=102.4, ups=0.47, wpb=109.4, bsz=40, num_updates=17160, lr=4.4368e-05, gnorm=0.255, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=68972
2023-01-07 10:00:53 - progress_bar.py[line:274] - INFO: epoch 001:  17193 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4623, wps=103.6, ups=0.47, wpb=109.9, bsz=40, num_updates=17170, lr=4.43635e-05, gnorm=0.425, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=68993
2023-01-07 10:01:14 - progress_bar.py[line:274] - INFO: epoch 001:  17203 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=102, ups=0.47, wpb=107.8, bsz=40, num_updates=17180, lr=4.4359e-05, gnorm=0.251, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69015
2023-01-07 10:01:16 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 10:01:38 - progress_bar.py[line:274] - INFO: epoch 001:  17214 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.619, nsentences=40, sample_size=110.619, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4976, wps=100.7, ups=0.43, wpb=110.6, bsz=40, num_updates=17190, lr=4.43545e-05, gnorm=0.263, clip=0, loss_scale=512, train_wall=23, gb_free=10, ema_decay=0.9999, wall=69038
2023-01-07 10:01:59 - progress_bar.py[line:274] - INFO: epoch 001:  17224 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4847, wps=102, ups=0.47, wpb=109.3, bsz=40, num_updates=17200, lr=4.435e-05, gnorm=0.246, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69060
2023-01-07 10:02:21 - progress_bar.py[line:274] - INFO: epoch 001:  17234 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.446, wps=99.8, ups=0.46, wpb=108.7, bsz=40, num_updates=17210, lr=4.43455e-05, gnorm=0.32, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=69082
2023-01-07 10:02:43 - progress_bar.py[line:274] - INFO: epoch 001:  17244 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=100.1, ups=0.46, wpb=107.8, bsz=40, num_updates=17220, lr=4.4341e-05, gnorm=0.276, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69103
2023-01-07 10:03:05 - progress_bar.py[line:274] - INFO: epoch 001:  17254 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4467, wps=100.9, ups=0.46, wpb=108.5, bsz=40, num_updates=17230, lr=4.43365e-05, gnorm=0.318, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=69125
2023-01-07 10:03:27 - progress_bar.py[line:274] - INFO: epoch 001:  17264 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4069, wps=100.1, ups=0.46, wpb=108.8, bsz=40, num_updates=17240, lr=4.4332e-05, gnorm=0.344, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=69147
2023-01-07 10:03:49 - progress_bar.py[line:274] - INFO: epoch 001:  17274 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.435, wps=101.5, ups=0.46, wpb=109.3, bsz=40, num_updates=17250, lr=4.43275e-05, gnorm=0.27, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69169
2023-01-07 10:04:10 - progress_bar.py[line:274] - INFO: epoch 001:  17284 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.449, wps=103.8, ups=0.47, wpb=110.4, bsz=40, num_updates=17260, lr=4.4323e-05, gnorm=0.183, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69190
2023-01-07 10:04:32 - progress_bar.py[line:274] - INFO: epoch 001:  17294 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4236, wps=101.3, ups=0.47, wpb=108.8, bsz=40, num_updates=17270, lr=4.43185e-05, gnorm=0.472, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69212
2023-01-07 10:04:53 - progress_bar.py[line:274] - INFO: epoch 001:  17304 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.446, wps=102.7, ups=0.48, wpb=107.3, bsz=40, num_updates=17280, lr=4.4314e-05, gnorm=0.375, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=69233
2023-01-07 10:05:14 - progress_bar.py[line:274] - INFO: epoch 001:  17314 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4978, wps=102.3, ups=0.47, wpb=107.9, bsz=40, num_updates=17290, lr=4.43095e-05, gnorm=0.444, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=69254
2023-01-07 10:05:36 - progress_bar.py[line:274] - INFO: epoch 001:  17324 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4495, wps=100.9, ups=0.47, wpb=108.4, bsz=40, num_updates=17300, lr=4.4305e-05, gnorm=0.257, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69276
2023-01-07 10:05:58 - progress_bar.py[line:274] - INFO: epoch 001:  17334 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4483, wps=102.4, ups=0.47, wpb=109.4, bsz=40, num_updates=17310, lr=4.43005e-05, gnorm=0.322, clip=0, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=69298
2023-01-07 10:06:19 - progress_bar.py[line:274] - INFO: epoch 001:  17344 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.467, wps=102.9, ups=0.47, wpb=110.4, bsz=40, num_updates=17320, lr=4.4296e-05, gnorm=0.21, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69319
2023-01-07 10:06:41 - progress_bar.py[line:274] - INFO: epoch 001:  17354 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4734, wps=98.7, ups=0.46, wpb=107.9, bsz=40, num_updates=17330, lr=4.42915e-05, gnorm=0.348, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=69342
2023-01-07 10:07:03 - progress_bar.py[line:274] - INFO: epoch 001:  17364 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4545, wps=100, ups=0.46, wpb=108.7, bsz=40, num_updates=17340, lr=4.4287e-05, gnorm=0.288, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=69364
2023-01-07 10:07:25 - progress_bar.py[line:274] - INFO: epoch 001:  17374 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4639, wps=101.5, ups=0.47, wpb=108.9, bsz=40, num_updates=17350, lr=4.42825e-05, gnorm=0.251, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69385
2023-01-07 10:07:47 - progress_bar.py[line:274] - INFO: epoch 001:  17384 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4129, wps=102.8, ups=0.47, wpb=110, bsz=40, num_updates=17360, lr=4.4278e-05, gnorm=0.22, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=69407
2023-01-07 10:08:09 - progress_bar.py[line:274] - INFO: epoch 001:  17394 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4279, wps=101.7, ups=0.46, wpb=110.6, bsz=40, num_updates=17370, lr=4.42735e-05, gnorm=0.321, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=69429
2023-01-07 10:08:31 - progress_bar.py[line:274] - INFO: epoch 001:  17404 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4394, wps=100.5, ups=0.46, wpb=108.2, bsz=40, num_updates=17380, lr=4.42691e-05, gnorm=0.196, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69451
2023-01-07 10:08:53 - progress_bar.py[line:274] - INFO: epoch 001:  17414 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4494, wps=100.9, ups=0.46, wpb=110.2, bsz=40, num_updates=17390, lr=4.42646e-05, gnorm=0.385, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=69473
2023-01-07 10:09:14 - progress_bar.py[line:274] - INFO: epoch 001:  17424 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4742, wps=101.3, ups=0.47, wpb=108.8, bsz=40, num_updates=17400, lr=4.42601e-05, gnorm=0.252, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69495
2023-01-07 10:09:36 - progress_bar.py[line:274] - INFO: epoch 001:  17434 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4127, wps=105.3, ups=0.48, wpb=110.1, bsz=40, num_updates=17410, lr=4.42556e-05, gnorm=0.414, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69516
2023-01-07 10:09:57 - progress_bar.py[line:274] - INFO: epoch 001:  17444 / 115845 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4451, wps=104.9, ups=0.47, wpb=111.5, bsz=40, num_updates=17420, lr=4.42511e-05, gnorm=0.27, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69537
2023-01-07 10:10:19 - progress_bar.py[line:274] - INFO: epoch 001:  17454 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4485, wps=101.3, ups=0.46, wpb=110.1, bsz=40, num_updates=17430, lr=4.42466e-05, gnorm=0.207, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=69559
2023-01-07 10:10:41 - progress_bar.py[line:274] - INFO: epoch 001:  17464 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4146, wps=102.4, ups=0.47, wpb=109.1, bsz=40, num_updates=17440, lr=4.42421e-05, gnorm=0.196, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69581
2023-01-07 10:11:02 - progress_bar.py[line:274] - INFO: epoch 001:  17474 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3842, wps=101.7, ups=0.47, wpb=107.9, bsz=40, num_updates=17450, lr=4.42376e-05, gnorm=0.296, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=69602
2023-01-07 10:11:23 - progress_bar.py[line:274] - INFO: epoch 001:  17484 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4476, wps=100.6, ups=0.47, wpb=107.1, bsz=40, num_updates=17460, lr=4.42331e-05, gnorm=0.27, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69624
2023-01-07 10:11:45 - progress_bar.py[line:274] - INFO: epoch 001:  17494 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4326, wps=101, ups=0.47, wpb=108, bsz=40, num_updates=17470, lr=4.42286e-05, gnorm=0.276, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69645
2023-01-07 10:12:06 - progress_bar.py[line:274] - INFO: epoch 001:  17504 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.442, wps=103.8, ups=0.47, wpb=110.1, bsz=40, num_updates=17480, lr=4.42241e-05, gnorm=0.527, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69667
2023-01-07 10:12:28 - progress_bar.py[line:274] - INFO: epoch 001:  17514 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4569, wps=103.2, ups=0.48, wpb=108.6, bsz=40, num_updates=17490, lr=4.42196e-05, gnorm=0.306, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=69688
2023-01-07 10:12:49 - progress_bar.py[line:274] - INFO: epoch 001:  17524 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4579, wps=102.1, ups=0.47, wpb=109.6, bsz=40, num_updates=17500, lr=4.42151e-05, gnorm=0.366, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69710
2023-01-07 10:13:11 - progress_bar.py[line:274] - INFO: epoch 001:  17534 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4429, wps=102.8, ups=0.47, wpb=108.4, bsz=40, num_updates=17510, lr=4.42106e-05, gnorm=0.422, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=69731
2023-01-07 10:13:33 - progress_bar.py[line:274] - INFO: epoch 001:  17544 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4188, wps=100.9, ups=0.46, wpb=109.7, bsz=40, num_updates=17520, lr=4.42061e-05, gnorm=0.207, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=69753
2023-01-07 10:13:54 - progress_bar.py[line:274] - INFO: epoch 001:  17554 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4627, wps=101.9, ups=0.47, wpb=109.2, bsz=40, num_updates=17530, lr=4.42016e-05, gnorm=0.218, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=69775
2023-01-07 10:14:17 - progress_bar.py[line:274] - INFO: epoch 001:  17564 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4058, wps=98.2, ups=0.45, wpb=108.8, bsz=40, num_updates=17540, lr=4.41971e-05, gnorm=0.351, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=69797
2023-01-07 10:14:38 - progress_bar.py[line:274] - INFO: epoch 001:  17574 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4525, wps=104.8, ups=0.47, wpb=110.9, bsz=40, num_updates=17550, lr=4.41926e-05, gnorm=0.331, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69818
2023-01-07 10:15:00 - progress_bar.py[line:274] - INFO: epoch 001:  17584 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3711, wps=100, ups=0.46, wpb=108.3, bsz=40, num_updates=17560, lr=4.41881e-05, gnorm=0.36, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69840
2023-01-07 10:15:22 - progress_bar.py[line:274] - INFO: epoch 001:  17594 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4747, wps=100.9, ups=0.47, wpb=107.6, bsz=40, num_updates=17570, lr=4.41836e-05, gnorm=0.344, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=69862
2023-01-07 10:15:43 - progress_bar.py[line:274] - INFO: epoch 001:  17604 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4372, wps=103.2, ups=0.47, wpb=110.2, bsz=40, num_updates=17580, lr=4.41791e-05, gnorm=0.376, clip=0, loss_scale=512, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=69883
2023-01-07 10:16:05 - progress_bar.py[line:274] - INFO: epoch 001:  17614 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4785, wps=100.5, ups=0.46, wpb=108.8, bsz=40, num_updates=17590, lr=4.41746e-05, gnorm=0.437, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69905
2023-01-07 10:16:26 - progress_bar.py[line:274] - INFO: epoch 001:  17624 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4084, wps=103.2, ups=0.47, wpb=108.8, bsz=40, num_updates=17600, lr=4.41701e-05, gnorm=0.418, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=69927
2023-01-07 10:16:48 - progress_bar.py[line:274] - INFO: epoch 001:  17634 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4901, wps=101.2, ups=0.46, wpb=109.9, bsz=40, num_updates=17610, lr=4.41656e-05, gnorm=0.315, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=69949
2023-01-07 10:17:10 - progress_bar.py[line:274] - INFO: epoch 001:  17644 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4378, wps=99.1, ups=0.46, wpb=107.6, bsz=40, num_updates=17620, lr=4.41612e-05, gnorm=0.301, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=69970
2023-01-07 10:17:32 - progress_bar.py[line:274] - INFO: epoch 001:  17654 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4363, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=17630, lr=4.41567e-05, gnorm=0.222, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69992
2023-01-07 10:17:54 - progress_bar.py[line:274] - INFO: epoch 001:  17664 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.526, wps=98.9, ups=0.46, wpb=107.4, bsz=40, num_updates=17640, lr=4.41522e-05, gnorm=0.305, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=70014
2023-01-07 10:18:15 - progress_bar.py[line:274] - INFO: epoch 001:  17674 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.405, wps=102.3, ups=0.47, wpb=108.1, bsz=40, num_updates=17650, lr=4.41477e-05, gnorm=0.315, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=70036
2023-01-07 10:18:37 - progress_bar.py[line:274] - INFO: epoch 001:  17684 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4819, wps=103, ups=0.47, wpb=109.9, bsz=40, num_updates=17660, lr=4.41432e-05, gnorm=0.478, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70057
2023-01-07 10:18:59 - progress_bar.py[line:274] - INFO: epoch 001:  17694 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4318, wps=99.3, ups=0.46, wpb=107, bsz=40, num_updates=17670, lr=4.41387e-05, gnorm=0.297, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=70079
2023-01-07 10:19:21 - progress_bar.py[line:274] - INFO: epoch 001:  17704 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4712, wps=101.4, ups=0.46, wpb=110.5, bsz=40, num_updates=17680, lr=4.41342e-05, gnorm=0.5, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70101
2023-01-07 10:19:42 - progress_bar.py[line:274] - INFO: epoch 001:  17714 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.465, wps=104.5, ups=0.47, wpb=110.2, bsz=40, num_updates=17690, lr=4.41297e-05, gnorm=0.25, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70122
2023-01-07 10:20:03 - progress_bar.py[line:274] - INFO: epoch 001:  17724 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4601, wps=102.7, ups=0.48, wpb=106.5, bsz=40, num_updates=17700, lr=4.41252e-05, gnorm=0.425, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70143
2023-01-07 10:20:25 - progress_bar.py[line:274] - INFO: epoch 001:  17734 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4179, wps=102.1, ups=0.47, wpb=108.3, bsz=40, num_updates=17710, lr=4.41207e-05, gnorm=0.261, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70165
2023-01-07 10:20:46 - progress_bar.py[line:274] - INFO: epoch 001:  17744 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3938, wps=104.1, ups=0.47, wpb=110.3, bsz=40, num_updates=17720, lr=4.41162e-05, gnorm=0.444, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70186
2023-01-07 10:21:07 - progress_bar.py[line:274] - INFO: epoch 001:  17754 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4427, wps=104.4, ups=0.48, wpb=109.4, bsz=40, num_updates=17730, lr=4.41117e-05, gnorm=0.334, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70207
2023-01-07 10:21:29 - progress_bar.py[line:274] - INFO: epoch 001:  17764 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5136, wps=100, ups=0.47, wpb=107.4, bsz=40, num_updates=17740, lr=4.41072e-05, gnorm=0.252, clip=0, loss_scale=1024, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=70229
2023-01-07 10:21:51 - progress_bar.py[line:274] - INFO: epoch 001:  17774 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4115, wps=102.9, ups=0.46, wpb=111.3, bsz=40, num_updates=17750, lr=4.41027e-05, gnorm=0.26, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=70251
2023-01-07 10:22:13 - progress_bar.py[line:274] - INFO: epoch 001:  17784 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4667, wps=99.9, ups=0.46, wpb=108.2, bsz=40, num_updates=17760, lr=4.40982e-05, gnorm=0.316, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70273
2023-01-07 10:22:34 - progress_bar.py[line:274] - INFO: epoch 001:  17794 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4581, wps=102.8, ups=0.47, wpb=109.5, bsz=40, num_updates=17770, lr=4.40937e-05, gnorm=0.235, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70294
2023-01-07 10:22:56 - progress_bar.py[line:274] - INFO: epoch 001:  17804 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.467, wps=103.9, ups=0.47, wpb=110.7, bsz=40, num_updates=17780, lr=4.40892e-05, gnorm=0.535, clip=10, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=70316
2023-01-07 10:23:17 - progress_bar.py[line:274] - INFO: epoch 001:  17814 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4049, wps=101.3, ups=0.46, wpb=109.1, bsz=40, num_updates=17790, lr=4.40847e-05, gnorm=0.314, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=70338
2023-01-07 10:23:39 - progress_bar.py[line:274] - INFO: epoch 001:  17824 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3939, wps=102.7, ups=0.47, wpb=110, bsz=40, num_updates=17800, lr=4.40802e-05, gnorm=0.19, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70359
2023-01-07 10:24:00 - progress_bar.py[line:274] - INFO: epoch 001:  17834 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4581, wps=102.8, ups=0.47, wpb=108.4, bsz=40, num_updates=17810, lr=4.40757e-05, gnorm=0.279, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70381
2023-01-07 10:24:22 - progress_bar.py[line:274] - INFO: epoch 001:  17844 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.474, wps=100.6, ups=0.46, wpb=109.4, bsz=40, num_updates=17820, lr=4.40712e-05, gnorm=0.35, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70403
2023-01-07 10:24:44 - progress_bar.py[line:274] - INFO: epoch 001:  17854 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4868, wps=101.8, ups=0.46, wpb=110.2, bsz=40, num_updates=17830, lr=4.40667e-05, gnorm=0.364, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=70424
2023-01-07 10:25:06 - progress_bar.py[line:274] - INFO: epoch 001:  17864 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3861, wps=99.6, ups=0.46, wpb=108.6, bsz=40, num_updates=17840, lr=4.40622e-05, gnorm=0.321, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=70446
2023-01-07 10:25:12 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 10:25:29 - progress_bar.py[line:274] - INFO: epoch 001:  17875 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107.667, nsentences=40, sample_size=107.667, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4709, wps=99, ups=0.44, wpb=107.7, bsz=40, num_updates=17850, lr=4.40577e-05, gnorm=0.198, clip=0, loss_scale=512, train_wall=23, gb_free=10.4, ema_decay=0.9999, wall=70470
2023-01-07 10:25:51 - progress_bar.py[line:274] - INFO: epoch 001:  17885 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4595, wps=102.5, ups=0.46, wpb=110.3, bsz=40, num_updates=17860, lr=4.40532e-05, gnorm=0.233, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70491
2023-01-07 10:26:13 - progress_bar.py[line:274] - INFO: epoch 001:  17895 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4976, wps=101.1, ups=0.47, wpb=108, bsz=40, num_updates=17870, lr=4.40488e-05, gnorm=0.259, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70513
2023-01-07 10:26:34 - progress_bar.py[line:274] - INFO: epoch 001:  17905 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4162, wps=103, ups=0.46, wpb=110.8, bsz=40, num_updates=17880, lr=4.40443e-05, gnorm=0.28, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70535
2023-01-07 10:26:56 - progress_bar.py[line:274] - INFO: epoch 001:  17915 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4061, wps=102.1, ups=0.47, wpb=108.6, bsz=40, num_updates=17890, lr=4.40398e-05, gnorm=0.347, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=70556
2023-01-07 10:27:18 - progress_bar.py[line:274] - INFO: epoch 001:  17925 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4612, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=17900, lr=4.40353e-05, gnorm=0.191, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=70578
2023-01-07 10:27:40 - progress_bar.py[line:274] - INFO: epoch 001:  17935 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4188, wps=101.1, ups=0.46, wpb=109.8, bsz=40, num_updates=17910, lr=4.40308e-05, gnorm=0.419, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=70600
2023-01-07 10:28:01 - progress_bar.py[line:274] - INFO: epoch 001:  17945 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5025, wps=102.8, ups=0.47, wpb=109.2, bsz=40, num_updates=17920, lr=4.40263e-05, gnorm=0.38, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70621
2023-01-07 10:28:23 - progress_bar.py[line:274] - INFO: epoch 001:  17955 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.392, wps=100.3, ups=0.46, wpb=108.8, bsz=40, num_updates=17930, lr=4.40218e-05, gnorm=0.23, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=70643
2023-01-07 10:28:45 - progress_bar.py[line:274] - INFO: epoch 001:  17965 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4, wps=100.8, ups=0.46, wpb=108.8, bsz=40, num_updates=17940, lr=4.40173e-05, gnorm=0.268, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70665
2023-01-07 10:29:07 - progress_bar.py[line:274] - INFO: epoch 001:  17975 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4469, wps=100.9, ups=0.46, wpb=110.5, bsz=40, num_updates=17950, lr=4.40128e-05, gnorm=0.21, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70687
2023-01-07 10:29:29 - progress_bar.py[line:274] - INFO: epoch 001:  17985 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4876, wps=100.9, ups=0.47, wpb=107.7, bsz=40, num_updates=17960, lr=4.40083e-05, gnorm=0.344, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=70709
2023-01-07 10:29:50 - progress_bar.py[line:274] - INFO: epoch 001:  17995 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4842, wps=104.5, ups=0.48, wpb=109.7, bsz=40, num_updates=17970, lr=4.40038e-05, gnorm=0.245, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70730
2023-01-07 10:30:12 - progress_bar.py[line:274] - INFO: epoch 001:  18005 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4098, wps=98.6, ups=0.46, wpb=108, bsz=40, num_updates=17980, lr=4.39993e-05, gnorm=0.31, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70752
2023-01-07 10:30:33 - progress_bar.py[line:274] - INFO: epoch 001:  18015 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4195, wps=105.1, ups=0.48, wpb=109.3, bsz=40, num_updates=17990, lr=4.39948e-05, gnorm=0.38, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=70773
2023-01-07 10:30:55 - progress_bar.py[line:274] - INFO: epoch 001:  18025 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4208, wps=101, ups=0.47, wpb=108.5, bsz=40, num_updates=18000, lr=4.39903e-05, gnorm=0.237, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70795
2023-01-07 10:30:55 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 10:30:56 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 10:30:56 - train.py[line:551] - INFO: load:1.20 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 10:33:28 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 10:33:28 - train.py[line:551] - INFO: load:1.22 valid_run:151.18 task_valid:146.92 collect_output:3.18
2023-01-07 10:35:56 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 10:35:56 - train.py[line:551] - INFO: load:1.25 valid_run:299.43 task_valid:288.59 collect_output:8.72
2023-01-07 10:35:57 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.35 GiB (GPU 1; 39.59 GiB total capacity; 9.38 GiB already allocated; 3.05 GiB free; 34.05 GiB reserved in total by PyTorch)
2023-01-07 10:35:57 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-07 10:35:57 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 34        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9604 MB |   15994 MB |   10148 TB |   10148 TB |
|       from large pool |    9430 MB |   15820 MB |   10144 TB |   10144 TB |
|       from small pool |     174 MB |     175 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9604 MB |   15994 MB |   10148 TB |   10148 TB |
|       from large pool |    9430 MB |   15820 MB |   10144 TB |   10144 TB |
|       from small pool |     174 MB |     175 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   34870 MB |   35108 MB |  352372 MB |  317502 MB |
|       from large pool |   34694 MB |   34926 MB |  351924 MB |  317230 MB |
|       from small pool |     176 MB |     182 MB |     448 MB |     272 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   25265 MB |   29893 MB |    9734 TB |    9734 TB |
|       from large pool |   25263 MB |   29890 MB |    9729 TB |    9729 TB |
|       from small pool |       1 MB |       3 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4634    |    4648    |  479392 K  |  479387 K  |
|       from large pool |     698    |     710    |  147639 K  |  147638 K  |
|       from small pool |    3936    |    3946    |  331752 K  |  331748 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4634    |    4648    |  479392 K  |  479387 K  |
|       from large pool |     698    |     710    |  147639 K  |  147638 K  |
|       from small pool |    3936    |    3946    |  331752 K  |  331748 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     193    |     197    |     723    |     530    |
|       from large pool |     105    |     106    |     499    |     394    |
|       from small pool |      88    |      91    |     224    |     136    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     109    |     123    |  356505 K  |  356505 K  |
|       from large pool |      57    |      64    |   70957 K  |   70957 K  |
|       from small pool |      52    |      65    |  285548 K  |  285548 K  |
|===========================================================================|

2023-01-07 10:35:57 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-07 10:38:30 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 10:38:30 - train.py[line:551] - INFO: load:1.28 valid_run:453.28 task_valid:430.30 collect_output:19.79
2023-01-07 10:40:58 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 10:40:58 - train.py[line:551] - INFO: load:1.30 valid_run:601.70 task_valid:573.86 collect_output:23.61
2023-01-07 10:43:31 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 10:43:31 - train.py[line:551] - INFO: load:1.33 valid_run:753.86 task_valid:720.11 collect_output:28.47
2023-01-07 10:46:02 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 10:46:02 - train.py[line:551] - INFO: load:1.35 valid_run:905.27 task_valid:864.21 collect_output:34.72
2023-01-07 10:48:35 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 10:48:35 - train.py[line:551] - INFO: load:1.38 valid_run:1058.51 task_valid:1008.66 collect_output:42.48
2023-01-07 10:51:07 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 10:51:07 - train.py[line:551] - INFO: load:1.41 valid_run:1209.69 task_valid:1148.33 collect_output:52.94
2023-01-07 10:56:02 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 10:56:02 - train.py[line:551] - INFO: load:1.43 valid_run:1504.38 task_valid:1292.09 collect_output:202.76
2023-01-07 11:01:20 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 11:01:20 - train.py[line:551] - INFO: load:1.46 valid_run:1822.45 task_valid:1433.76 collect_output:378.08
2023-01-07 11:06:38 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 11:06:38 - train.py[line:551] - INFO: load:1.49 valid_run:2140.49 task_valid:1577.02 collect_output:551.78
2023-01-07 11:11:57 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 11:11:57 - train.py[line:551] - INFO: load:1.52 valid_run:2459.70 task_valid:1720.61 collect_output:726.29
2023-01-07 11:17:17 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 11:17:17 - train.py[line:551] - INFO: load:1.55 valid_run:2779.89 task_valid:1861.18 collect_output:904.82
2023-01-07 11:22:34 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 11:22:34 - train.py[line:551] - INFO: load:1.58 valid_run:3096.82 task_valid:2005.06 collect_output:1076.77
2023-01-07 11:27:49 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 11:27:49 - train.py[line:551] - INFO: load:1.60 valid_run:3411.50 task_valid:2150.15 collect_output:1245.26
2023-01-07 11:33:08 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 11:33:08 - train.py[line:551] - INFO: load:1.63 valid_run:3729.82 task_valid:2292.81 collect_output:1419.83
2023-01-07 11:38:32 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 11:38:32 - train.py[line:551] - INFO: load:1.67 valid_run:4054.19 task_valid:2437.04 collect_output:1598.87
2023-01-07 11:43:53 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 11:43:53 - train.py[line:551] - INFO: load:1.69 valid_run:4374.92 task_valid:2582.50 collect_output:1773.09
2023-01-07 11:49:19 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 11:49:19 - train.py[line:551] - INFO: load:1.72 valid_run:4701.41 task_valid:2722.46 collect_output:1958.51
2023-01-07 11:54:47 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 11:54:47 - train.py[line:551] - INFO: load:1.75 valid_run:5028.45 task_valid:2866.00 collect_output:2140.94
2023-01-07 12:00:24 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 12:00:24 - train.py[line:551] - INFO: load:1.78 valid_run:5365.57 task_valid:3009.27 collect_output:2333.70
2023-01-07 12:05:50 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 12:05:50 - train.py[line:551] - INFO: load:1.81 valid_run:5691.58 task_valid:3152.41 collect_output:2515.47
2023-01-07 12:11:17 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 12:11:17 - train.py[line:551] - INFO: load:1.84 valid_run:6019.00 task_valid:3297.14 collect_output:2697.08
2023-01-07 12:16:44 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 12:16:44 - train.py[line:551] - INFO: load:1.87 valid_run:6345.12 task_valid:3442.09 collect_output:2877.16

====================================================================================================
SGG eval:     R @ 50: 0.4496;     R @ 100: 0.5157;     R @ 500: 0.5500;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2772;    mR @ 100: 0.3456;    mR @ 500: 0.3724;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6293) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.6160) (says:0.0000) (sitting on:0.7168) (standing on:0.1950) (using:0.6500) (walking in:0.0000) (walking on:0.2973) (watching:0.1389) 
--------------------------------------------------------
====================================================================================================

2023-01-07 12:21:51 - train.py[line:487] - INFO: 0.5156952380952381
2023-01-07 12:21:51 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.4496;     R @ 100: 0.5157;     R @ 500: 0.5500;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2772;    mR @ 100: 0.3456;    mR @ 500: 0.3724;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6293) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.6160) (says:0.0000) (sitting on:0.7168) (standing on:0.1950) (using:0.6500) (walking in:0.0000) (walking on:0.2973) (watching:0.1389) 
--------------------------------------------------------
====================================================================================================

2023-01-07 12:21:51 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.372 | loss_v1 0 | loss_v2 0 | nll_loss 0.223 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.515695 | ppl 1.17 | vqa_score 0.4358 | wps 67.4 | wpb 89.9 | bsz 30 | num_updates 18000 | best_R@100 0.637221
2023-01-07 12:21:51 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 18000 updates
2023-01-07 12:21:51 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_18000.pt
2023-01-07 12:22:39 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_18000.pt
2023-01-07 12:24:08 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.99_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_18000.pt (epoch 1 @ 18000 updates, score 0.5156952380952381) (writing took 136.49952042102814 seconds)
2023-01-07 12:24:09 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 42.00 MiB (GPU 1; 39.59 GiB total capacity; 27.90 GiB already allocated; 29.19 MiB free; 27.95 GiB reserved in total by PyTorch)
2023-01-07 12:24:09 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-07 12:24:09 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 38        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   28572 MB |   28572 MB |   10645 TB |   10645 TB |
|       from large pool |   28424 MB |   28424 MB |   10641 TB |   10641 TB |
|       from small pool |     148 MB |     175 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Active memory         |   28572 MB |   28572 MB |   10645 TB |   10645 TB |
|       from large pool |   28424 MB |   28424 MB |   10641 TB |   10641 TB |
|       from small pool |     148 MB |     175 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   28620 MB |   35108 MB |  394264 MB |  365644 MB |
|       from large pool |   28470 MB |   34926 MB |  393812 MB |  365342 MB |
|       from small pool |     150 MB |     182 MB |     452 MB |     302 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   48925 KB |   29893 MB |   10447 TB |   10447 TB |
|       from large pool |   47031 KB |   29890 MB |   10442 TB |   10442 TB |
|       from small pool |    1894 KB |       8 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4786    |    4786    |  505019 K  |  505014 K  |
|       from large pool |    1050    |    1050    |  154870 K  |  154869 K  |
|       from small pool |    3736    |    3946    |  350148 K  |  350144 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4786    |    4786    |  505019 K  |  505014 K  |
|       from large pool |    1050    |    1050    |  154870 K  |  154869 K  |
|       from small pool |    3736    |    3946    |  350148 K  |  350144 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     184    |     197    |     769    |     585    |
|       from large pool |     109    |     109    |     543    |     434    |
|       from small pool |      75    |      91    |     226    |     151    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      45    |     196    |  376564 K  |  376564 K  |
|       from large pool |      30    |      64    |   74070 K  |   74070 K  |
|       from small pool |      15    |     145    |  302493 K  |  302493 K  |
|===========================================================================|

2023-01-07 12:24:09 - trainer.py[line:877] - WARNING: attempting to recover from OOM in forward/backward pass
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 2728126
Killing subprocess 2728127
Main process received SIGINT, exiting
