2023-01-07 22:59:32 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2023-01-07 22:59:32 - utils.py[line:261] - INFO: Start init
2023-01-07 22:59:32 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2023-01-07 22:59:32 - utils.py[line:261] - INFO: Start init
2023-01-07 22:59:32 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-01-07 22:59:32 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-01-07 22:59:32 - utils.py[line:274] - INFO: initialized host node4 as rank 1
2023-01-07 22:59:32 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.single-machine distributed training is initialized.

2023-01-07 22:59:38 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_visualDS_momentum0.9_alpha1.0', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 2000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 12, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 2000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=16, batch_size_valid='12', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=1, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480', save_interval=10, save_interval_updates=2000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_visualDS_momentum0.9_alpha1.0', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=2000, wandb_project=None, warmup_ratio=0.032, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.032, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-01-07 22:59:38 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-01-07 22:59:38 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2023-01-07 22:59:43 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-01-07 22:59:43 - train.py[line:118] - INFO: task: VqaGenTask
2023-01-07 22:59:43 - train.py[line:119] - INFO: model: OFAModel
2023-01-07 22:59:43 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-01-07 22:59:43 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-01-07 22:59:43 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2023-01-07 22:59:43 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-01-07 22:59:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-01-07 22:59:44 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-01-07 22:59:45 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-01-07 22:59:45 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-01-07 22:59:45 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-01-07 22:59:45 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
Done 0.9 cuda cpu, cpu
Done 0.9 cuda cpu, cpu
2023-01-07 22:59:46 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2023-01-07 22:59:46 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 16
2023-01-07 22:59:46 - trainer.py[line:499] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2023-01-07 22:59:49 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-01-07 22:59:50 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-01-07 22:59:50 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-01-07 22:59:50 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-01-07 22:59:51 - trainer.py[line:314] - INFO: Exponential Moving Average Shadow Model is initialized.
2023-01-07 22:59:51 - trainer.py[line:674] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2023-01-07 22:59:51 - trainer.py[line:694] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv slice_id 1 row count 2316893 total row count 4633786
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv slice_id 0 row count 2316893 total row count 4633786
2023-01-07 22:59:55 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 144806, warmup steps 4633, warmup_factor 0.0002158428663932657
Total steps 144806, warmup steps 4633, warmup_factor 0.0002158428663932657
2023-01-07 22:59:56 - trainer.py[line:758] - INFO: begin training epoch 1
2023-01-07 22:59:56 - train.py[line:312] - INFO: Start iterating over samples
From cpu to cuda:1
From cpu to cuda:0
2023-01-07 23:00:30 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 144806 loss=1.003, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, vqa_score=0.0449, wps=61.4, ups=0.35, wpb=87.7, bsz=32, num_updates=10, lr=1.07921e-07, gnorm=8.93, clip=100, loss_scale=128, train_wall=32, gb_free=15.5, ema_decay=0.9999, wall=45
2023-01-07 23:00:56 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 144806 loss=0.997, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, vqa_score=0.0316, wps=68.7, ups=0.39, wpb=87.5, bsz=32, num_updates=20, lr=2.15843e-07, gnorm=7.791, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=71
2023-01-07 23:01:22 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 144806 loss=1.124, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=2, vqa_score=0.0121, wps=68.3, ups=0.39, wpb=87.1, bsz=32, num_updates=30, lr=3.23764e-07, gnorm=9.583, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=97
2023-01-07 23:01:48 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0408, wps=69.6, ups=0.39, wpb=88.5, bsz=32, num_updates=40, lr=4.31686e-07, gnorm=9, clip=100, loss_scale=128, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=123
2023-01-07 23:02:15 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 144806 loss=1.028, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, vqa_score=0.0192, wps=67.6, ups=0.39, wpb=86.4, bsz=32, num_updates=50, lr=5.39607e-07, gnorm=8.624, clip=100, loss_scale=128, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=149
2023-01-07 23:02:41 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0294, wps=67.4, ups=0.39, wpb=87, bsz=32, num_updates=60, lr=6.47529e-07, gnorm=8.264, clip=100, loss_scale=128, train_wall=26, gb_free=14.9, ema_decay=0.9999, wall=176
2023-01-07 23:03:07 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 144806 loss=1.028, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, vqa_score=0.0368, wps=67.6, ups=0.39, wpb=86.9, bsz=32, num_updates=70, lr=7.5545e-07, gnorm=7.971, clip=100, loss_scale=128, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=202
2023-01-07 23:03:35 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 144806 loss=0.998, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, vqa_score=0.0184, wps=65.8, ups=0.38, wpb=86.9, bsz=32, num_updates=80, lr=8.63371e-07, gnorm=8.573, clip=100, loss_scale=128, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=229
2023-01-07 23:04:01 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 144806 loss=0.961, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.8, vqa_score=0.0351, wps=69.7, ups=0.4, wpb=87.6, bsz=32, num_updates=90, lr=9.71293e-07, gnorm=7.185, clip=100, loss_scale=128, train_wall=25, gb_free=15, ema_decay=0.9999, wall=255
2023-01-07 23:04:28 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 144806 loss=0.913, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.74, vqa_score=0.0299, wps=66.5, ups=0.38, wpb=86.6, bsz=32, num_updates=100, lr=1.07921e-06, gnorm=6.738, clip=100, loss_scale=128, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=282
2023-01-07 23:04:54 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 144806 loss=0.841, loss_v1=0, loss_v2=0, nll_loss=0.728, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.66, vqa_score=0.0364, wps=68.4, ups=0.39, wpb=87.8, bsz=32, num_updates=110, lr=1.18714e-06, gnorm=5.132, clip=100, loss_scale=128, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=309
2023-01-07 23:05:20 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 144806 loss=0.801, loss_v1=0, loss_v2=0, nll_loss=0.685, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.61, vqa_score=0.0258, wps=70.1, ups=0.4, wpb=87.7, bsz=32, num_updates=120, lr=1.29506e-06, gnorm=4.622, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=335
2023-01-07 23:05:46 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 144806 loss=0.821, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.64, vqa_score=0.0182, wps=67, ups=0.39, wpb=86.4, bsz=32, num_updates=130, lr=1.40298e-06, gnorm=4.45, clip=100, loss_scale=128, train_wall=26, gb_free=15, ema_decay=0.9999, wall=361
2023-01-07 23:06:13 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 144806 loss=0.805, loss_v1=0, loss_v2=0, nll_loss=0.706, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.63, vqa_score=0.0355, wps=67.7, ups=0.39, wpb=87, bsz=32, num_updates=140, lr=1.5109e-06, gnorm=4.637, clip=100, loss_scale=128, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=387
2023-01-07 23:06:39 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 144806 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.644, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, vqa_score=0.0314, wps=68.3, ups=0.39, wpb=87.8, bsz=32, num_updates=150, lr=1.61882e-06, gnorm=4.085, clip=100, loss_scale=128, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=414
2023-01-07 23:07:05 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 144806 loss=0.71, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.52, vqa_score=0.0268, wps=69.6, ups=0.4, wpb=87.7, bsz=32, num_updates=160, lr=1.72674e-06, gnorm=3.436, clip=100, loss_scale=128, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=440
2023-01-07 23:07:31 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0417, wps=67.5, ups=0.39, wpb=87, bsz=32, num_updates=170, lr=1.83466e-06, gnorm=3.588, clip=100, loss_scale=128, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=466
2023-01-07 23:07:57 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0407, wps=68, ups=0.39, wpb=87, bsz=32, num_updates=180, lr=1.94259e-06, gnorm=3.322, clip=100, loss_scale=128, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=492
2023-01-07 23:08:23 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0252, wps=69.1, ups=0.4, wpb=87, bsz=32, num_updates=190, lr=2.05051e-06, gnorm=3.178, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=518
2023-01-07 23:08:50 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 144806 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.55, vqa_score=0.0176, wps=69.4, ups=0.4, wpb=87.8, bsz=32, num_updates=200, lr=2.15843e-06, gnorm=2.926, clip=100, loss_scale=128, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=544
2023-01-07 23:09:15 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=89, nsentences=32, sample_size=89, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0208, wps=71.1, ups=0.4, wpb=89, bsz=32, num_updates=210, lr=2.26635e-06, gnorm=2.536, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=570
2023-01-07 23:09:41 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 144806 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.654, ntokens=84.5, nsentences=32, sample_size=84.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, vqa_score=0.017, wps=66.4, ups=0.39, wpb=84.5, bsz=32, num_updates=220, lr=2.37427e-06, gnorm=2.815, clip=100, loss_scale=128, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=596
2023-01-07 23:10:07 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 144806 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.615, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.53, vqa_score=0.0233, wps=69.7, ups=0.4, wpb=88.1, bsz=32, num_updates=230, lr=2.48219e-06, gnorm=2.899, clip=100, loss_scale=128, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=622
2023-01-07 23:10:33 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 144806 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, vqa_score=0.0128, wps=68.9, ups=0.39, wpb=87.4, bsz=32, num_updates=240, lr=2.59011e-06, gnorm=2.904, clip=100, loss_scale=128, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=648
2023-01-07 23:11:00 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 144806 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.52, vqa_score=0.0176, wps=67.7, ups=0.39, wpb=86.8, bsz=32, num_updates=250, lr=2.69804e-06, gnorm=2.485, clip=100, loss_scale=128, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=674
2023-01-07 23:11:26 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 144806 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.605, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, vqa_score=0.012, wps=68.9, ups=0.39, wpb=87.5, bsz=32, num_updates=260, lr=2.80596e-06, gnorm=2.345, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=700
2023-01-07 23:11:53 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 144806 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, vqa_score=0.0248, wps=66.5, ups=0.38, wpb=88.4, bsz=32, num_updates=270, lr=2.91388e-06, gnorm=2.051, clip=100, loss_scale=128, train_wall=27, gb_free=15.2, ema_decay=0.9999, wall=728
2023-01-07 23:12:19 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 144806 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, vqa_score=0.0127, wps=68.8, ups=0.39, wpb=87.8, bsz=32, num_updates=280, lr=3.0218e-06, gnorm=2.243, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=754
2023-01-07 23:12:46 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0327, wps=68.6, ups=0.39, wpb=87.6, bsz=32, num_updates=290, lr=3.12972e-06, gnorm=2.074, clip=100, loss_scale=128, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=780
2023-01-07 23:13:12 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 144806 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, vqa_score=0.0185, wps=67.6, ups=0.39, wpb=86.7, bsz=32, num_updates=300, lr=3.23764e-06, gnorm=2.15, clip=100, loss_scale=128, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=807
2023-01-07 23:13:38 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.1, nsentences=32, sample_size=85.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0529, wps=66.8, ups=0.39, wpb=85.1, bsz=32, num_updates=310, lr=3.34556e-06, gnorm=1.907, clip=100, loss_scale=128, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=833
2023-01-07 23:14:04 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 144806 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, vqa_score=0.0437, wps=67.8, ups=0.39, wpb=86.5, bsz=32, num_updates=320, lr=3.45349e-06, gnorm=2.204, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=859
2023-01-07 23:14:30 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0135, wps=70.6, ups=0.4, wpb=88, bsz=32, num_updates=330, lr=3.56141e-06, gnorm=1.912, clip=100, loss_scale=128, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=885
2023-01-07 23:14:56 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 144806 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.49, vqa_score=0.0061, wps=67.3, ups=0.39, wpb=85.9, bsz=32, num_updates=340, lr=3.66933e-06, gnorm=2.215, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=911
2023-01-07 23:15:22 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 144806 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, vqa_score=0.0062, wps=68.5, ups=0.39, wpb=86.8, bsz=32, num_updates=350, lr=3.77725e-06, gnorm=1.813, clip=100, loss_scale=128, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=937
2023-01-07 23:15:48 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 144806 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0196, wps=68.2, ups=0.39, wpb=86.7, bsz=32, num_updates=360, lr=3.88517e-06, gnorm=1.79, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=963
2023-01-07 23:16:14 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0201, wps=69.6, ups=0.4, wpb=88, bsz=32, num_updates=370, lr=3.99309e-06, gnorm=1.648, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=989
2023-01-07 23:16:41 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 144806 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.45, vqa_score=0.0062, wps=68.4, ups=0.39, wpb=88, bsz=32, num_updates=380, lr=4.10101e-06, gnorm=1.734, clip=100, loss_scale=128, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=1015
2023-01-07 23:17:07 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 144806 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, vqa_score=0.0375, wps=69.5, ups=0.4, wpb=87.8, bsz=32, num_updates=390, lr=4.20894e-06, gnorm=1.682, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=1042
2023-01-07 23:17:33 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0184, wps=68.2, ups=0.4, wpb=85.8, bsz=32, num_updates=400, lr=4.31686e-06, gnorm=1.74, clip=100, loss_scale=128, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=1067
2023-01-07 23:17:59 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0058, wps=68.1, ups=0.39, wpb=87, bsz=32, num_updates=410, lr=4.42478e-06, gnorm=1.91, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=1093
2023-01-07 23:18:25 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 144806 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0194, wps=68.6, ups=0.39, wpb=86.9, bsz=32, num_updates=420, lr=4.5327e-06, gnorm=1.824, clip=100, loss_scale=128, train_wall=25, gb_free=15, ema_decay=0.9999, wall=1119
2023-01-07 23:18:51 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 144806 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0314, wps=67.6, ups=0.39, wpb=87.3, bsz=32, num_updates=430, lr=4.64062e-06, gnorm=1.552, clip=100, loss_scale=128, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=1146
2023-01-07 23:19:18 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 144806 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, vqa_score=0.0131, wps=67.5, ups=0.39, wpb=86.6, bsz=32, num_updates=440, lr=4.74854e-06, gnorm=1.678, clip=100, loss_scale=128, train_wall=26, gb_free=14.9, ema_decay=0.9999, wall=1172
2023-01-07 23:19:43 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 144806 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, vqa_score=0.0301, wps=69.7, ups=0.4, wpb=87.8, bsz=32, num_updates=450, lr=4.85646e-06, gnorm=1.723, clip=100, loss_scale=128, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=1198
2023-01-07 23:20:10 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 144806 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.4, vqa_score=0.02, wps=68.2, ups=0.39, wpb=87, bsz=32, num_updates=460, lr=4.96439e-06, gnorm=1.679, clip=100, loss_scale=128, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=1224
2023-01-07 23:20:35 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 144806 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0314, wps=69, ups=0.4, wpb=86.9, bsz=32, num_updates=470, lr=5.07231e-06, gnorm=1.728, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=1250
2023-01-07 23:21:01 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 144806 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.45, vqa_score=0.0351, wps=67.6, ups=0.39, wpb=86, bsz=32, num_updates=480, lr=5.18023e-06, gnorm=1.612, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=1276
2023-01-07 23:21:28 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 144806 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, vqa_score=0.0368, wps=68.5, ups=0.39, wpb=87.3, bsz=32, num_updates=490, lr=5.28815e-06, gnorm=2.07, clip=100, loss_scale=128, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=1302
2023-01-07 23:21:54 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 144806 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0432, wps=69.6, ups=0.39, wpb=88.8, bsz=32, num_updates=500, lr=5.39607e-06, gnorm=1.663, clip=100, loss_scale=128, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=1328
2023-01-07 23:22:20 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.6, nsentences=32, sample_size=85.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0294, wps=67, ups=0.39, wpb=85.6, bsz=32, num_updates=510, lr=5.50399e-06, gnorm=1.803, clip=100, loss_scale=128, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=1355
2023-01-07 23:22:46 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 144806 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0387, wps=69.3, ups=0.39, wpb=88.2, bsz=32, num_updates=520, lr=5.61191e-06, gnorm=1.534, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=1381
2023-01-07 23:23:12 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 144806 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0233, wps=68, ups=0.4, wpb=86.1, bsz=32, num_updates=530, lr=5.71984e-06, gnorm=1.712, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=1407
2023-01-07 23:23:38 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 144806 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0258, wps=69.1, ups=0.39, wpb=87.8, bsz=32, num_updates=540, lr=5.82776e-06, gnorm=1.697, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=1433
2023-01-07 23:24:04 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 144806 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0063, wps=68.2, ups=0.39, wpb=87, bsz=32, num_updates=550, lr=5.93568e-06, gnorm=1.513, clip=100, loss_scale=256, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=1459
2023-01-07 23:24:31 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 144806 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0508, wps=67.8, ups=0.39, wpb=86.8, bsz=32, num_updates=560, lr=6.0436e-06, gnorm=1.305, clip=90, loss_scale=256, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=1485
2023-01-07 23:24:57 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 144806 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0361, wps=69.1, ups=0.4, wpb=87.2, bsz=32, num_updates=570, lr=6.15152e-06, gnorm=1.66, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=1512
2023-01-07 23:25:23 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 144806 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0123, wps=68.7, ups=0.39, wpb=87, bsz=32, num_updates=580, lr=6.25944e-06, gnorm=1.386, clip=90, loss_scale=256, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=1538
2023-01-07 23:25:50 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 144806 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0186, wps=67.9, ups=0.39, wpb=87.8, bsz=32, num_updates=590, lr=6.36736e-06, gnorm=1.457, clip=90, loss_scale=256, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=1564
2023-01-07 23:26:16 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 144806 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0592, wps=69.7, ups=0.39, wpb=88.5, bsz=32, num_updates=600, lr=6.47529e-06, gnorm=1.641, clip=100, loss_scale=256, train_wall=25, gb_free=15, ema_decay=0.9999, wall=1590
2023-01-07 23:26:42 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 144806 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.44, vqa_score=0.0238, wps=68.2, ups=0.39, wpb=87, bsz=32, num_updates=610, lr=6.58321e-06, gnorm=1.525, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=1617
2023-01-07 23:27:08 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0238, wps=68.6, ups=0.4, wpb=86.4, bsz=32, num_updates=620, lr=6.69113e-06, gnorm=1.636, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=1642
2023-01-07 23:27:34 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 144806 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=89.7, nsentences=32, sample_size=89.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0845, wps=70.5, ups=0.39, wpb=89.7, bsz=32, num_updates=630, lr=6.79905e-06, gnorm=1.707, clip=100, loss_scale=256, train_wall=25, gb_free=15, ema_decay=0.9999, wall=1669
2023-01-07 23:28:00 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0245, wps=68.2, ups=0.39, wpb=86.9, bsz=32, num_updates=640, lr=6.90697e-06, gnorm=1.457, clip=100, loss_scale=256, train_wall=25, gb_free=15, ema_decay=0.9999, wall=1695
2023-01-07 23:28:26 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 144806 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, vqa_score=0.0292, wps=67.1, ups=0.39, wpb=86.2, bsz=32, num_updates=650, lr=7.01489e-06, gnorm=1.715, clip=100, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=1721
2023-01-07 23:28:52 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 144806 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0186, wps=67.4, ups=0.39, wpb=86.3, bsz=32, num_updates=660, lr=7.12281e-06, gnorm=1.51, clip=100, loss_scale=256, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=1747
2023-01-07 23:29:17 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 144806 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0136, wps=70.1, ups=0.4, wpb=88.1, bsz=32, num_updates=670, lr=7.23074e-06, gnorm=1.507, clip=100, loss_scale=256, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=1772
2023-01-07 23:29:43 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 144806 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0311, wps=68.4, ups=0.39, wpb=87.9, bsz=32, num_updates=680, lr=7.33866e-06, gnorm=1.713, clip=100, loss_scale=256, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=1798
2023-01-07 23:30:09 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 144806 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0321, wps=68.7, ups=0.39, wpb=88.3, bsz=32, num_updates=690, lr=7.44658e-06, gnorm=1.697, clip=100, loss_scale=256, train_wall=26, gb_free=15, ema_decay=0.9999, wall=1824
2023-01-07 23:30:35 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 144806 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0566, wps=69, ups=0.4, wpb=87.3, bsz=32, num_updates=700, lr=7.5545e-06, gnorm=1.885, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=1850
2023-01-07 23:31:00 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 144806 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, vqa_score=0.0368, wps=69.4, ups=0.4, wpb=87.5, bsz=32, num_updates=710, lr=7.66242e-06, gnorm=1.672, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=1875
2023-01-07 23:31:26 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 144806 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0387, wps=68.5, ups=0.39, wpb=87.1, bsz=32, num_updates=720, lr=7.77034e-06, gnorm=1.467, clip=90, loss_scale=256, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=1901
2023-01-07 23:31:51 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 144806 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.038, wps=68.2, ups=0.39, wpb=86.7, bsz=32, num_updates=730, lr=7.87826e-06, gnorm=1.586, clip=90, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=1927
2023-01-07 23:32:17 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 144806 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0131, wps=69.9, ups=0.4, wpb=88.4, bsz=32, num_updates=740, lr=7.98619e-06, gnorm=1.483, clip=90, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=1952
2023-01-07 23:32:43 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0123, wps=68.4, ups=0.39, wpb=87.5, bsz=32, num_updates=750, lr=8.09411e-06, gnorm=1.486, clip=100, loss_scale=256, train_wall=26, gb_free=15.7, ema_decay=0.9999, wall=1978
2023-01-07 23:33:08 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 144806 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0519, wps=70.7, ups=0.4, wpb=87.7, bsz=32, num_updates=760, lr=8.20203e-06, gnorm=1.79, clip=100, loss_scale=256, train_wall=25, gb_free=14.6, ema_decay=0.9999, wall=2003
2023-01-07 23:33:34 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 144806 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, vqa_score=0.017, wps=67.8, ups=0.39, wpb=86.5, bsz=32, num_updates=770, lr=8.30995e-06, gnorm=1.725, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=2029
2023-01-07 23:34:00 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0204, wps=69.8, ups=0.39, wpb=88.8, bsz=32, num_updates=780, lr=8.41787e-06, gnorm=1.534, clip=90, loss_scale=256, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=2055
2023-01-07 23:34:25 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0403, wps=69.2, ups=0.39, wpb=88.1, bsz=32, num_updates=790, lr=8.52579e-06, gnorm=1.634, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=2080
2023-01-07 23:34:51 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 144806 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0473, wps=69.1, ups=0.39, wpb=88.1, bsz=32, num_updates=800, lr=8.63371e-06, gnorm=1.52, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=2106
2023-01-07 23:35:17 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0339, wps=68.3, ups=0.4, wpb=86.3, bsz=32, num_updates=810, lr=8.74164e-06, gnorm=1.639, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=2132
2023-01-07 23:35:42 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 144806 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0329, wps=67.7, ups=0.39, wpb=86.3, bsz=32, num_updates=820, lr=8.84956e-06, gnorm=1.591, clip=100, loss_scale=256, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=2157
2023-01-07 23:36:08 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 144806 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, vqa_score=0.012, wps=69.8, ups=0.4, wpb=87.2, bsz=32, num_updates=830, lr=8.95748e-06, gnorm=1.695, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=2183
2023-01-07 23:36:33 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 144806 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0305, wps=70, ups=0.4, wpb=88.3, bsz=32, num_updates=840, lr=9.0654e-06, gnorm=1.4, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=2208
2023-01-07 23:36:59 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 144806 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.38, vqa_score=0.0195, wps=69.1, ups=0.39, wpb=88, bsz=32, num_updates=850, lr=9.17332e-06, gnorm=1.58, clip=90, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=2234
2023-01-07 23:37:25 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0427, wps=68.1, ups=0.39, wpb=87.6, bsz=32, num_updates=860, lr=9.28124e-06, gnorm=1.634, clip=100, loss_scale=256, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=2260
2023-01-07 23:37:50 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 144806 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0195, wps=69.8, ups=0.4, wpb=87.8, bsz=32, num_updates=870, lr=9.38916e-06, gnorm=1.831, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=2285
2023-01-07 23:38:16 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0132, wps=67.8, ups=0.39, wpb=86.8, bsz=32, num_updates=880, lr=9.49709e-06, gnorm=1.585, clip=100, loss_scale=256, train_wall=26, gb_free=15.5, ema_decay=0.9999, wall=2311
2023-01-07 23:38:41 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 144806 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0196, wps=70.8, ups=0.4, wpb=88.9, bsz=32, num_updates=890, lr=9.60501e-06, gnorm=1.368, clip=100, loss_scale=256, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=2337
2023-01-07 23:39:07 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0253, wps=70.2, ups=0.4, wpb=87, bsz=32, num_updates=900, lr=9.71293e-06, gnorm=1.544, clip=90, loss_scale=256, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=2362
2023-01-07 23:39:33 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 144806 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0204, wps=68.2, ups=0.39, wpb=88.2, bsz=32, num_updates=910, lr=9.82085e-06, gnorm=1.484, clip=100, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=2388
2023-01-07 23:39:59 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 144806 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0191, wps=68.9, ups=0.39, wpb=88, bsz=32, num_updates=920, lr=9.92877e-06, gnorm=1.769, clip=100, loss_scale=256, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=2414
2023-01-07 23:40:24 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 144806 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0405, wps=69.6, ups=0.39, wpb=88.1, bsz=32, num_updates=930, lr=1.00367e-05, gnorm=1.652, clip=100, loss_scale=256, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=2439
2023-01-07 23:40:50 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 144806 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0265, wps=69.3, ups=0.39, wpb=88.1, bsz=32, num_updates=940, lr=1.01446e-05, gnorm=1.805, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=2465
2023-01-07 23:41:16 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0133, wps=68.5, ups=0.39, wpb=87.3, bsz=32, num_updates=950, lr=1.02525e-05, gnorm=1.396, clip=90, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=2491
2023-01-07 23:41:41 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 144806 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0195, wps=69.4, ups=0.39, wpb=88.9, bsz=32, num_updates=960, lr=1.03605e-05, gnorm=1.507, clip=100, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=2516
2023-01-07 23:42:07 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 144806 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0256, wps=70.4, ups=0.4, wpb=88, bsz=32, num_updates=970, lr=1.04684e-05, gnorm=1.63, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=2542
2023-01-07 23:42:32 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0267, wps=68.8, ups=0.39, wpb=87.8, bsz=32, num_updates=980, lr=1.05763e-05, gnorm=1.517, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=2567
2023-01-07 23:42:58 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0294, wps=67.8, ups=0.39, wpb=86.4, bsz=32, num_updates=990, lr=1.06842e-05, gnorm=1.53, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=2593
2023-01-07 23:43:24 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0311, wps=68.2, ups=0.39, wpb=86.5, bsz=32, num_updates=1000, lr=1.07921e-05, gnorm=1.581, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=2619
2023-01-07 23:43:50 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 144806 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0318, wps=69, ups=0.4, wpb=87, bsz=32, num_updates=1010, lr=1.09001e-05, gnorm=1.647, clip=90, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=2645
2023-01-07 23:44:16 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 144806 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0123, wps=67.9, ups=0.39, wpb=87.4, bsz=32, num_updates=1020, lr=1.1008e-05, gnorm=1.534, clip=100, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=2671
2023-01-07 23:44:42 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 144806 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0189, wps=68.4, ups=0.39, wpb=86.7, bsz=32, num_updates=1030, lr=1.11159e-05, gnorm=1.418, clip=100, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=2697
2023-01-07 23:45:08 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 144806 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0192, wps=68.3, ups=0.39, wpb=86.7, bsz=32, num_updates=1040, lr=1.12238e-05, gnorm=1.369, clip=70, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=2723
2023-01-07 23:45:34 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 144806 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0368, wps=68.2, ups=0.39, wpb=86.4, bsz=32, num_updates=1050, lr=1.13318e-05, gnorm=1.314, clip=90, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=2749
2023-01-07 23:46:00 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0186, wps=70.2, ups=0.4, wpb=87.8, bsz=32, num_updates=1060, lr=1.14397e-05, gnorm=1.144, clip=60, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=2775
2023-01-07 23:46:26 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.044, wps=67.8, ups=0.39, wpb=87.2, bsz=32, num_updates=1070, lr=1.15476e-05, gnorm=1.476, clip=100, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=2801
2023-01-07 23:46:52 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 144806 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0314, wps=69.7, ups=0.4, wpb=87.8, bsz=32, num_updates=1080, lr=1.16555e-05, gnorm=1.507, clip=90, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=2826
2023-01-07 23:47:18 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 144806 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.02, wps=68.5, ups=0.4, wpb=86.7, bsz=32, num_updates=1090, lr=1.17634e-05, gnorm=1.409, clip=100, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=2852
2023-01-07 23:47:44 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0352, wps=69.1, ups=0.39, wpb=88.7, bsz=32, num_updates=1100, lr=1.18714e-05, gnorm=1.605, clip=100, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=2879
2023-01-07 23:48:09 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0185, wps=71.4, ups=0.4, wpb=88.8, bsz=32, num_updates=1110, lr=1.19793e-05, gnorm=1.359, clip=100, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=2904
2023-01-07 23:48:36 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 144806 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0137, wps=67.4, ups=0.39, wpb=86.8, bsz=32, num_updates=1120, lr=1.20872e-05, gnorm=1.456, clip=100, loss_scale=512, train_wall=26, gb_free=15.5, ema_decay=0.9999, wall=2930
2023-01-07 23:49:02 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 144806 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0185, wps=68.2, ups=0.39, wpb=87.2, bsz=32, num_updates=1130, lr=1.21951e-05, gnorm=1.624, clip=100, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=2957
2023-01-07 23:49:28 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 144806 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0465, wps=67.7, ups=0.39, wpb=86.4, bsz=32, num_updates=1140, lr=1.2303e-05, gnorm=1.442, clip=90, loss_scale=512, train_wall=25, gb_free=15.6, ema_decay=0.9999, wall=2983
2023-01-07 23:49:54 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 144806 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.018, wps=67.4, ups=0.39, wpb=87, bsz=32, num_updates=1150, lr=1.2411e-05, gnorm=1.443, clip=100, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=3009
2023-01-07 23:50:21 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 144806 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0197, wps=66.6, ups=0.39, wpb=86.2, bsz=32, num_updates=1160, lr=1.25189e-05, gnorm=1.458, clip=100, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=3035
2023-01-07 23:50:46 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 144806 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0321, wps=68.2, ups=0.39, wpb=86.3, bsz=32, num_updates=1170, lr=1.26268e-05, gnorm=1.489, clip=100, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=3061
2023-01-07 23:51:13 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 144806 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0258, wps=68, ups=0.39, wpb=87.5, bsz=32, num_updates=1180, lr=1.27347e-05, gnorm=1.338, clip=90, loss_scale=512, train_wall=26, gb_free=15, ema_decay=0.9999, wall=3088
2023-01-07 23:51:38 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0294, wps=69.3, ups=0.4, wpb=87, bsz=32, num_updates=1190, lr=1.28427e-05, gnorm=1.63, clip=100, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=3113
2023-01-07 23:52:04 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 144806 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0186, wps=69.1, ups=0.4, wpb=87.3, bsz=32, num_updates=1200, lr=1.29506e-05, gnorm=1.241, clip=80, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=3139
2023-01-07 23:52:30 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0248, wps=68.3, ups=0.39, wpb=86.9, bsz=32, num_updates=1210, lr=1.30585e-05, gnorm=1.125, clip=50, loss_scale=512, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=3165
2023-01-07 23:52:57 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0123, wps=67.9, ups=0.39, wpb=86.4, bsz=32, num_updates=1220, lr=1.31664e-05, gnorm=1.345, clip=80, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=3191
2023-01-07 23:53:22 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 144806 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0229, wps=69.2, ups=0.4, wpb=87.3, bsz=32, num_updates=1230, lr=1.32743e-05, gnorm=1.364, clip=90, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=3217
2023-01-07 23:53:48 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 144806 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0355, wps=68.6, ups=0.4, wpb=86.6, bsz=32, num_updates=1240, lr=1.33823e-05, gnorm=1.534, clip=100, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=3243
2023-01-07 23:54:14 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 144806 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0377, wps=68.8, ups=0.4, wpb=86.9, bsz=32, num_updates=1250, lr=1.34902e-05, gnorm=1.497, clip=100, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=3269
2023-01-07 23:54:40 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 144806 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0301, wps=67.3, ups=0.39, wpb=86.5, bsz=32, num_updates=1260, lr=1.35981e-05, gnorm=1.328, clip=70, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=3295
2023-01-07 23:55:06 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 144806 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0065, wps=70.7, ups=0.4, wpb=88.7, bsz=32, num_updates=1270, lr=1.3706e-05, gnorm=1.351, clip=90, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=3321
2023-01-07 23:55:32 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 144806 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0419, wps=68, ups=0.39, wpb=86.7, bsz=32, num_updates=1280, lr=1.38139e-05, gnorm=1.245, clip=80, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=3347
2023-01-07 23:55:58 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 144806 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.023, wps=68.3, ups=0.39, wpb=87.8, bsz=32, num_updates=1290, lr=1.39219e-05, gnorm=1.302, clip=90, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=3373
2023-01-07 23:56:24 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 144806 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.025, wps=68.1, ups=0.39, wpb=87.1, bsz=32, num_updates=1300, lr=1.40298e-05, gnorm=1.474, clip=90, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=3399
2023-01-07 23:56:51 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 144806 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.026, wps=68, ups=0.39, wpb=88.1, bsz=32, num_updates=1310, lr=1.41377e-05, gnorm=1.394, clip=100, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=3426
2023-01-07 23:57:17 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0192, wps=68.8, ups=0.4, wpb=87.1, bsz=32, num_updates=1320, lr=1.42456e-05, gnorm=1.218, clip=100, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=3451
2023-01-07 23:57:43 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 144806 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0387, wps=68.7, ups=0.39, wpb=88.5, bsz=32, num_updates=1330, lr=1.43536e-05, gnorm=1.173, clip=80, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=3478
2023-01-07 23:58:09 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 144806 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0424, wps=69.1, ups=0.4, wpb=86.5, bsz=32, num_updates=1340, lr=1.44615e-05, gnorm=1.366, clip=100, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=3503
2023-01-07 23:58:35 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0397, wps=68.5, ups=0.39, wpb=88.4, bsz=32, num_updates=1350, lr=1.45694e-05, gnorm=1.297, clip=100, loss_scale=512, train_wall=26, gb_free=14.8, ema_decay=0.9999, wall=3530
2023-01-07 23:59:01 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 144806 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0323, wps=69.3, ups=0.39, wpb=88.1, bsz=32, num_updates=1360, lr=1.46773e-05, gnorm=1.361, clip=100, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=3556
2023-01-07 23:59:27 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0211, wps=68.8, ups=0.39, wpb=87.3, bsz=32, num_updates=1370, lr=1.47852e-05, gnorm=1.283, clip=90, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=3582
2023-01-07 23:59:52 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 144806 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0191, wps=69.7, ups=0.39, wpb=88.3, bsz=32, num_updates=1380, lr=1.48932e-05, gnorm=1.428, clip=100, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=3607
2023-01-08 00:00:18 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 144806 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.013, wps=67.6, ups=0.39, wpb=86.9, bsz=32, num_updates=1390, lr=1.50011e-05, gnorm=1.326, clip=100, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=3633
2023-01-08 00:00:44 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.006, wps=67.8, ups=0.39, wpb=86.5, bsz=32, num_updates=1400, lr=1.5109e-05, gnorm=1.398, clip=100, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=3659
2023-01-08 00:01:09 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 144806 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0299, wps=68.6, ups=0.4, wpb=86.4, bsz=32, num_updates=1410, lr=1.52169e-05, gnorm=1.361, clip=100, loss_scale=512, train_wall=25, gb_free=15.7, ema_decay=0.9999, wall=3684
2023-01-08 00:01:35 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 144806 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0067, wps=71.4, ups=0.4, wpb=88.8, bsz=32, num_updates=1420, lr=1.53248e-05, gnorm=1.448, clip=100, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=3710
2023-01-08 00:02:01 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 144806 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0123, wps=67.4, ups=0.39, wpb=87, bsz=32, num_updates=1430, lr=1.54328e-05, gnorm=1.334, clip=90, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=3736
2023-01-08 00:02:26 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 144806 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0375, wps=68.8, ups=0.39, wpb=87.2, bsz=32, num_updates=1440, lr=1.55407e-05, gnorm=1.283, clip=80, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=3761
2023-01-08 00:02:52 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 144806 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0299, wps=67.4, ups=0.39, wpb=86.6, bsz=32, num_updates=1450, lr=1.56486e-05, gnorm=1.237, clip=90, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=3787
2023-01-08 00:03:18 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 144806 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0253, wps=68.3, ups=0.39, wpb=87.9, bsz=32, num_updates=1460, lr=1.57565e-05, gnorm=1.238, clip=90, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=3813
2023-01-08 00:03:44 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0417, wps=67.7, ups=0.39, wpb=86.8, bsz=32, num_updates=1470, lr=1.58645e-05, gnorm=1.245, clip=80, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=3839
2023-01-08 00:04:10 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 144806 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0419, wps=67.5, ups=0.39, wpb=87.4, bsz=32, num_updates=1480, lr=1.59724e-05, gnorm=1.272, clip=70, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=3865
2023-01-08 00:04:36 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 144806 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0063, wps=67.7, ups=0.39, wpb=87.6, bsz=32, num_updates=1490, lr=1.60803e-05, gnorm=1.158, clip=90, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=3891
2023-01-08 00:05:02 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 144806 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0057, wps=67.9, ups=0.4, wpb=86, bsz=32, num_updates=1500, lr=1.61882e-05, gnorm=1.332, clip=100, loss_scale=512, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=3917
2023-01-08 00:05:28 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 144806 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0482, wps=66.7, ups=0.39, wpb=86.5, bsz=32, num_updates=1510, lr=1.62961e-05, gnorm=1.491, clip=100, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=3943
2023-01-08 00:05:54 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0187, wps=67.5, ups=0.39, wpb=86.6, bsz=32, num_updates=1520, lr=1.64041e-05, gnorm=1.59, clip=90, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=3969
2023-01-08 00:06:19 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 144806 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0244, wps=69.7, ups=0.4, wpb=88.1, bsz=32, num_updates=1530, lr=1.6512e-05, gnorm=1.196, clip=80, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=3994
2023-01-08 00:06:37 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 00:06:47 - progress_bar.py[line:274] - INFO: epoch 001:   1541 / 144806 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=85.952, nsentences=32, sample_size=85.952, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0402, wps=65, ups=0.36, wpb=86, bsz=32, num_updates=1540, lr=1.66199e-05, gnorm=1.275, clip=100, loss_scale=512, train_wall=28, gb_free=15.5, ema_decay=0.9999, wall=4022
2023-01-08 00:07:13 - progress_bar.py[line:274] - INFO: epoch 001:   1551 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0125, wps=68.9, ups=0.39, wpb=87.2, bsz=32, num_updates=1550, lr=1.67278e-05, gnorm=1.158, clip=60, loss_scale=512, train_wall=25, gb_free=15.6, ema_decay=0.9999, wall=4048
2023-01-08 00:07:39 - progress_bar.py[line:274] - INFO: epoch 001:   1561 / 144806 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0203, wps=69.1, ups=0.39, wpb=87.8, bsz=32, num_updates=1560, lr=1.68357e-05, gnorm=1.27, clip=80, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=4074
2023-01-08 00:08:04 - progress_bar.py[line:274] - INFO: epoch 001:   1571 / 144806 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0127, wps=68.2, ups=0.4, wpb=86.2, bsz=32, num_updates=1570, lr=1.69437e-05, gnorm=1.029, clip=60, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=4099
2023-01-08 00:08:29 - progress_bar.py[line:274] - INFO: epoch 001:   1581 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0, wps=69.4, ups=0.4, wpb=87.6, bsz=32, num_updates=1580, lr=1.70516e-05, gnorm=1.31, clip=90, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=4125
2023-01-08 00:08:55 - progress_bar.py[line:274] - INFO: epoch 001:   1591 / 144806 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0123, wps=68.7, ups=0.4, wpb=86.9, bsz=32, num_updates=1590, lr=1.71595e-05, gnorm=1.213, clip=90, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=4150
2023-01-08 00:09:21 - progress_bar.py[line:274] - INFO: epoch 001:   1601 / 144806 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0261, wps=68.7, ups=0.39, wpb=87.9, bsz=32, num_updates=1600, lr=1.72674e-05, gnorm=1.173, clip=60, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=4176
2023-01-08 00:09:46 - progress_bar.py[line:274] - INFO: epoch 001:   1611 / 144806 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0323, wps=68.3, ups=0.39, wpb=87, bsz=32, num_updates=1610, lr=1.73754e-05, gnorm=1.471, clip=100, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=4202
2023-01-08 00:10:12 - progress_bar.py[line:274] - INFO: epoch 001:   1621 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0127, wps=68.7, ups=0.39, wpb=87.1, bsz=32, num_updates=1620, lr=1.74833e-05, gnorm=1.273, clip=80, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=4227
2023-01-08 00:10:37 - progress_bar.py[line:274] - INFO: epoch 001:   1631 / 144806 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0242, wps=70, ups=0.4, wpb=87.8, bsz=32, num_updates=1630, lr=1.75912e-05, gnorm=1.194, clip=80, loss_scale=512, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=4252
2023-01-08 00:11:03 - progress_bar.py[line:274] - INFO: epoch 001:   1641 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0323, wps=67.9, ups=0.39, wpb=87.3, bsz=32, num_updates=1640, lr=1.76991e-05, gnorm=1.143, clip=70, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=4278
2023-01-08 00:11:29 - progress_bar.py[line:274] - INFO: epoch 001:   1651 / 144806 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0187, wps=68.8, ups=0.39, wpb=87.8, bsz=32, num_updates=1650, lr=1.7807e-05, gnorm=1.21, clip=90, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=4304
2023-01-08 00:11:54 - progress_bar.py[line:274] - INFO: epoch 001:   1661 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0056, wps=69.7, ups=0.4, wpb=86.8, bsz=32, num_updates=1660, lr=1.7915e-05, gnorm=1.45, clip=90, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=4329
2023-01-08 00:12:20 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 144806 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0298, wps=69.3, ups=0.4, wpb=87.5, bsz=32, num_updates=1670, lr=1.80229e-05, gnorm=1.14, clip=70, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=4355
2023-01-08 00:12:46 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 144806 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=84.9, nsentences=32, sample_size=84.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0247, wps=65.5, ups=0.39, wpb=84.9, bsz=32, num_updates=1680, lr=1.81308e-05, gnorm=1.355, clip=100, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=4381
2023-01-08 00:13:12 - progress_bar.py[line:274] - INFO: epoch 001:   1691 / 144806 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0118, wps=67.2, ups=0.39, wpb=86.5, bsz=32, num_updates=1690, lr=1.82387e-05, gnorm=1.427, clip=100, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=4407
2023-01-08 00:13:37 - progress_bar.py[line:274] - INFO: epoch 001:   1701 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.037, wps=68, ups=0.39, wpb=86.4, bsz=32, num_updates=1700, lr=1.83466e-05, gnorm=1.482, clip=100, loss_scale=512, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=4433
2023-01-08 00:14:03 - progress_bar.py[line:274] - INFO: epoch 001:   1711 / 144806 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0127, wps=68.6, ups=0.39, wpb=87.2, bsz=32, num_updates=1710, lr=1.84546e-05, gnorm=1.281, clip=100, loss_scale=512, train_wall=25, gb_free=15.6, ema_decay=0.9999, wall=4458
2023-01-08 00:14:29 - progress_bar.py[line:274] - INFO: epoch 001:   1721 / 144806 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0183, wps=67.4, ups=0.39, wpb=86.7, bsz=32, num_updates=1720, lr=1.85625e-05, gnorm=1.217, clip=80, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=4484
2023-01-08 00:14:55 - progress_bar.py[line:274] - INFO: epoch 001:   1731 / 144806 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0137, wps=69.5, ups=0.4, wpb=87.9, bsz=32, num_updates=1730, lr=1.86704e-05, gnorm=1.33, clip=100, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=4510
2023-01-08 00:15:20 - progress_bar.py[line:274] - INFO: epoch 001:   1741 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0201, wps=71.2, ups=0.4, wpb=88.6, bsz=32, num_updates=1740, lr=1.87783e-05, gnorm=1.256, clip=100, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=4535
2023-01-08 00:15:46 - progress_bar.py[line:274] - INFO: epoch 001:   1751 / 144806 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0166, wps=66.5, ups=0.39, wpb=85.5, bsz=32, num_updates=1750, lr=1.88863e-05, gnorm=1.285, clip=80, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=4561
2023-01-08 00:16:12 - progress_bar.py[line:274] - INFO: epoch 001:   1761 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0171, wps=66.5, ups=0.38, wpb=86.7, bsz=32, num_updates=1760, lr=1.89942e-05, gnorm=1.359, clip=80, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=4587
2023-01-08 00:16:38 - progress_bar.py[line:274] - INFO: epoch 001:   1771 / 144806 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0253, wps=68.8, ups=0.39, wpb=87.8, bsz=32, num_updates=1770, lr=1.91021e-05, gnorm=1.415, clip=90, loss_scale=512, train_wall=25, gb_free=14.8, ema_decay=0.9999, wall=4613
2023-01-08 00:17:04 - progress_bar.py[line:274] - INFO: epoch 001:   1781 / 144806 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0235, wps=66.6, ups=0.39, wpb=85.5, bsz=32, num_updates=1780, lr=1.921e-05, gnorm=1.3, clip=100, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=4639
2023-01-08 00:17:29 - progress_bar.py[line:274] - INFO: epoch 001:   1791 / 144806 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0146, wps=69.3, ups=0.39, wpb=87.7, bsz=32, num_updates=1790, lr=1.93179e-05, gnorm=1.092, clip=60, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=4664
2023-01-08 00:17:56 - progress_bar.py[line:274] - INFO: epoch 001:   1801 / 144806 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0364, wps=67.4, ups=0.39, wpb=87.3, bsz=32, num_updates=1800, lr=1.94259e-05, gnorm=1.183, clip=80, loss_scale=512, train_wall=26, gb_free=15.5, ema_decay=0.9999, wall=4691
2023-01-08 00:18:21 - progress_bar.py[line:274] - INFO: epoch 001:   1811 / 144806 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0261, wps=70.2, ups=0.4, wpb=87, bsz=32, num_updates=1810, lr=1.95338e-05, gnorm=1.236, clip=100, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=4716
2023-01-08 00:18:46 - progress_bar.py[line:274] - INFO: epoch 001:   1821 / 144806 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0214, wps=70, ups=0.39, wpb=88.6, bsz=32, num_updates=1820, lr=1.96417e-05, gnorm=1.085, clip=70, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=4741
2023-01-08 00:19:12 - progress_bar.py[line:274] - INFO: epoch 001:   1831 / 144806 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0432, wps=69.3, ups=0.39, wpb=88.4, bsz=32, num_updates=1830, lr=1.97496e-05, gnorm=1.259, clip=90, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=4767
2023-01-08 00:19:38 - progress_bar.py[line:274] - INFO: epoch 001:   1841 / 144806 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0305, wps=69.2, ups=0.39, wpb=88.3, bsz=32, num_updates=1840, lr=1.98575e-05, gnorm=1.101, clip=80, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=4793
2023-01-08 00:20:03 - progress_bar.py[line:274] - INFO: epoch 001:   1851 / 144806 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0179, wps=69.2, ups=0.4, wpb=87.1, bsz=32, num_updates=1850, lr=1.99655e-05, gnorm=1.262, clip=70, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=4818
2023-01-08 00:20:29 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 144806 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0359, wps=69.3, ups=0.39, wpb=88, bsz=32, num_updates=1860, lr=2.00734e-05, gnorm=1.129, clip=80, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=4844
2023-01-08 00:20:54 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0222, wps=67.3, ups=0.39, wpb=86.5, bsz=32, num_updates=1870, lr=2.01813e-05, gnorm=1.256, clip=80, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=4870
2023-01-08 00:21:20 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 144806 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0242, wps=67.3, ups=0.39, wpb=86.7, bsz=32, num_updates=1880, lr=2.02892e-05, gnorm=1.277, clip=100, loss_scale=512, train_wall=26, gb_free=15, ema_decay=0.9999, wall=4896
2023-01-08 00:21:46 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0299, wps=68.2, ups=0.39, wpb=86.6, bsz=32, num_updates=1890, lr=2.03972e-05, gnorm=1.274, clip=80, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=4921
2023-01-08 00:22:12 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 144806 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0185, wps=68, ups=0.39, wpb=86.4, bsz=32, num_updates=1900, lr=2.05051e-05, gnorm=1.153, clip=70, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=4947
2023-01-08 00:22:37 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0417, wps=69, ups=0.39, wpb=87.7, bsz=32, num_updates=1910, lr=2.0613e-05, gnorm=1.148, clip=70, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=4972
2023-01-08 00:23:03 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 144806 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0507, wps=68.2, ups=0.39, wpb=88, bsz=32, num_updates=1920, lr=2.07209e-05, gnorm=1.158, clip=80, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=4999
2023-01-08 00:23:29 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 144806 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.021, wps=69.3, ups=0.39, wpb=88.3, bsz=32, num_updates=1930, lr=2.08288e-05, gnorm=1.187, clip=70, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=5024
2023-01-08 00:23:55 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 144806 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.012, wps=68.5, ups=0.4, wpb=86.3, bsz=32, num_updates=1940, lr=2.09368e-05, gnorm=1.19, clip=90, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=5050
2023-01-08 00:24:21 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 144806 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.012, wps=67.1, ups=0.39, wpb=86.5, bsz=32, num_updates=1950, lr=2.10447e-05, gnorm=1.241, clip=90, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=5076
2023-01-08 00:24:46 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 144806 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.057, wps=69.3, ups=0.4, wpb=87.4, bsz=32, num_updates=1960, lr=2.11526e-05, gnorm=1.205, clip=60, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=5101
2023-01-08 00:25:12 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 144806 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0199, wps=69.1, ups=0.39, wpb=87.6, bsz=32, num_updates=1970, lr=2.12605e-05, gnorm=1.171, clip=90, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=5127
2023-01-08 00:25:37 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 144806 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0305, wps=68, ups=0.39, wpb=86.9, bsz=32, num_updates=1980, lr=2.13684e-05, gnorm=1.21, clip=80, loss_scale=512, train_wall=26, gb_free=14.9, ema_decay=0.9999, wall=5152
2023-01-08 00:26:03 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0336, wps=68.2, ups=0.39, wpb=87.8, bsz=32, num_updates=1990, lr=2.14764e-05, gnorm=1.157, clip=70, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=5178
2023-01-08 00:26:29 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.2, nsentences=32, sample_size=85.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.024, wps=67.1, ups=0.39, wpb=85.2, bsz=32, num_updates=2000, lr=2.15843e-05, gnorm=1.361, clip=80, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=5204
2023-01-08 00:26:29 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 00:26:29 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-01-08 00:26:30 - train.py[line:549] - INFO: 0 / 6234
2023-01-08 00:26:30 - train.py[line:551] - INFO: load:0.86 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 00:26:32 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.91 GiB (GPU 1; 39.59 GiB total capacity; 8.38 GiB already allocated; 4.57 GiB free; 25.70 GiB reserved in total by PyTorch)
2023-01-08 00:26:32 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-08 00:26:32 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 6         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8583 MB |    9563 MB |  525673 GB |  525664 GB |
|       from large pool |    8409 MB |    9388 MB |  525234 GB |  525226 GB |
|       from small pool |     174 MB |     174 MB |     438 GB |     438 GB |
|---------------------------------------------------------------------------|
| Active memory         |    8583 MB |    9563 MB |  525673 GB |  525664 GB |
|       from large pool |    8409 MB |    9388 MB |  525234 GB |  525226 GB |
|       from small pool |     174 MB |     174 MB |     438 GB |     438 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26316 MB |   27362 MB |   98582 MB |   72266 MB |
|       from large pool |   26140 MB |   27182 MB |   98288 MB |   72148 MB |
|       from small pool |     176 MB |     180 MB |     294 MB |     118 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17732 MB |   21293 MB |  491939 GB |  491922 GB |
|       from large pool |   17730 MB |   21290 MB |  491478 GB |  491461 GB |
|       from small pool |       1 MB |       3 MB |     461 GB |     461 GB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |   26393 K  |   26388 K  |
|       from large pool |     698    |     710    |    9333 K  |    9333 K  |
|       from small pool |    3925    |    3943    |   17059 K  |   17055 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |   26393 K  |   26388 K  |
|       from large pool |     698    |     710    |    9333 K  |    9333 K  |
|       from small pool |    3925    |    3943    |   17059 K  |   17055 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     193    |     200    |     423    |     230    |
|       from large pool |     105    |     110    |     276    |     171    |
|       from small pool |      88    |      90    |     147    |      59    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     130    |     138    |   19153 K  |   19153 K  |
|       from large pool |      78    |      82    |    5705 K  |    5705 K  |
|       from small pool |      52    |      60    |   13448 K  |   13448 K  |
|===========================================================================|

2023-01-08 00:26:32 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-08 00:30:05 - train.py[line:549] - INFO: 200 / 6234
2023-01-08 00:30:05 - train.py[line:551] - INFO: load:0.88 valid_run:214.58 task_valid:208.64 collect_output:3.93
2023-01-08 00:33:33 - train.py[line:549] - INFO: 400 / 6234
2023-01-08 00:33:33 - train.py[line:551] - INFO: load:0.91 valid_run:422.83 task_valid:410.94 collect_output:7.90
2023-01-08 00:37:04 - train.py[line:549] - INFO: 600 / 6234
2023-01-08 00:37:04 - train.py[line:551] - INFO: load:0.93 valid_run:633.59 task_valid:614.03 collect_output:13.61
2023-01-08 00:40:35 - train.py[line:549] - INFO: 800 / 6234
2023-01-08 00:40:35 - train.py[line:551] - INFO: load:0.96 valid_run:844.05 task_valid:813.23 collect_output:22.94
2023-01-08 00:44:04 - train.py[line:549] - INFO: 1000 / 6234
2023-01-08 00:44:04 - train.py[line:551] - INFO: load:0.98 valid_run:1052.93 task_valid:1017.41 collect_output:25.70
2023-01-08 00:47:36 - train.py[line:549] - INFO: 1200 / 6234
2023-01-08 00:47:36 - train.py[line:551] - INFO: load:1.00 valid_run:1265.08 task_valid:1223.47 collect_output:29.86
2023-01-08 00:51:08 - train.py[line:549] - INFO: 1400 / 6234
2023-01-08 00:51:08 - train.py[line:551] - INFO: load:1.03 valid_run:1477.41 task_valid:1428.54 collect_output:35.16
2023-01-08 00:54:39 - train.py[line:549] - INFO: 1600 / 6234
2023-01-08 00:54:39 - train.py[line:551] - INFO: load:1.05 valid_run:1687.96 task_valid:1631.53 collect_output:40.79
2023-01-08 00:58:12 - train.py[line:549] - INFO: 1800 / 6234
2023-01-08 00:58:12 - train.py[line:551] - INFO: load:1.08 valid_run:1900.96 task_valid:1835.30 collect_output:48.07
2023-01-08 01:01:42 - train.py[line:549] - INFO: 2000 / 6234
2023-01-08 01:01:42 - train.py[line:551] - INFO: load:1.10 valid_run:2111.13 task_valid:2033.28 collect_output:58.32
2023-01-08 01:05:11 - train.py[line:549] - INFO: 2200 / 6234
2023-01-08 01:05:11 - train.py[line:551] - INFO: load:1.12 valid_run:2319.75 task_valid:2235.26 collect_output:62.99
2023-01-08 01:08:41 - train.py[line:549] - INFO: 2400 / 6234
2023-01-08 01:08:41 - train.py[line:551] - INFO: load:1.15 valid_run:2529.85 task_valid:2439.06 collect_output:67.32
2023-01-08 01:12:08 - train.py[line:549] - INFO: 2600 / 6234
2023-01-08 01:12:08 - train.py[line:551] - INFO: load:1.17 valid_run:2736.31 task_valid:2638.53 collect_output:72.37
2023-01-08 01:15:37 - train.py[line:549] - INFO: 2800 / 6234
2023-01-08 01:15:37 - train.py[line:551] - INFO: load:1.20 valid_run:2945.43 task_valid:2842.97 collect_output:75.09
2023-01-08 01:19:06 - train.py[line:549] - INFO: 3000 / 6234
2023-01-08 01:19:06 - train.py[line:551] - INFO: load:1.22 valid_run:3154.33 task_valid:3045.49 collect_output:79.55
2023-01-08 01:22:35 - train.py[line:549] - INFO: 3200 / 6234
2023-01-08 01:22:35 - train.py[line:551] - INFO: load:1.25 valid_run:3363.53 task_valid:3245.06 collect_output:87.23
2023-01-08 01:26:05 - train.py[line:549] - INFO: 3400 / 6234
2023-01-08 01:26:05 - train.py[line:551] - INFO: load:1.27 valid_run:3573.12 task_valid:3447.44 collect_output:92.51
2023-01-08 01:29:34 - train.py[line:549] - INFO: 3600 / 6234
2023-01-08 01:29:34 - train.py[line:551] - INFO: load:1.30 valid_run:3782.08 task_valid:3652.42 collect_output:94.57
2023-01-08 01:33:04 - train.py[line:549] - INFO: 3800 / 6234
2023-01-08 01:33:04 - train.py[line:551] - INFO: load:1.32 valid_run:3991.98 task_valid:3856.14 collect_output:98.79
2023-01-08 01:36:33 - train.py[line:549] - INFO: 4000 / 6234
2023-01-08 01:36:33 - train.py[line:551] - INFO: load:1.35 valid_run:4200.68 task_valid:4059.36 collect_output:102.32
2023-01-08 01:40:03 - train.py[line:549] - INFO: 4200 / 6234
2023-01-08 01:40:03 - train.py[line:551] - INFO: load:1.38 valid_run:4411.08 task_valid:4262.16 collect_output:107.98
2023-01-08 01:43:34 - train.py[line:549] - INFO: 4400 / 6234
2023-01-08 01:43:34 - train.py[line:551] - INFO: load:1.40 valid_run:4621.91 task_valid:4468.51 collect_output:110.49
2023-01-08 01:47:02 - train.py[line:549] - INFO: 4600 / 6234
2023-01-08 01:47:02 - train.py[line:551] - INFO: load:1.43 valid_run:4830.16 task_valid:4668.57 collect_output:116.75
2023-01-08 01:50:30 - train.py[line:549] - INFO: 4800 / 6234
2023-01-08 01:50:30 - train.py[line:551] - INFO: load:1.45 valid_run:5038.13 task_valid:4871.39 collect_output:119.93
2023-01-08 01:54:01 - train.py[line:549] - INFO: 5000 / 6234
2023-01-08 01:54:01 - train.py[line:551] - INFO: load:1.48 valid_run:5248.15 task_valid:5074.00 collect_output:125.37
2023-01-08 01:57:32 - train.py[line:549] - INFO: 5200 / 6234
2023-01-08 01:57:32 - train.py[line:551] - INFO: load:1.50 valid_run:5459.70 task_valid:5276.49 collect_output:132.47
2023-01-08 02:01:00 - train.py[line:549] - INFO: 5400 / 6234
2023-01-08 02:01:00 - train.py[line:551] - INFO: load:1.53 valid_run:5666.94 task_valid:5476.06 collect_output:138.21
2023-01-08 02:04:31 - train.py[line:549] - INFO: 5600 / 6234
2023-01-08 02:04:31 - train.py[line:551] - INFO: load:1.55 valid_run:5877.87 task_valid:5683.08 collect_output:140.17
2023-01-08 02:08:01 - train.py[line:549] - INFO: 5800 / 6234
2023-01-08 02:08:01 - train.py[line:551] - INFO: load:1.58 valid_run:6087.74 task_valid:5884.79 collect_output:146.38
2023-01-08 02:11:31 - train.py[line:549] - INFO: 6000 / 6234
2023-01-08 02:11:31 - train.py[line:551] - INFO: load:1.60 valid_run:6298.16 task_valid:6090.03 collect_output:149.64
2023-01-08 02:15:01 - train.py[line:549] - INFO: 6200 / 6234
2023-01-08 02:15:01 - train.py[line:551] - INFO: load:1.63 valid_run:6507.72 task_valid:6295.60 collect_output:151.70

====================================================================================================
SGG eval:     R @ 50: 0.2792;     R @ 100: 0.3391;     R @ 500: 0.4048;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1245;    mR @ 100: 0.1775;    mR @ 500: 0.2138;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0488) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1667) (playing:0.0000) (riding:0.3500) (says:0.0000) (sitting on:0.4118) (standing on:0.5383) (using:0.1500) (walking in:0.0000) (walking on:0.1622) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2792;     R @ 100: 0.3391;     R @ 500: 0.4048;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1245;    mR @ 100: 0.1775;    mR @ 500: 0.2138;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0488) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1667) (playing:0.0000) (riding:0.3500) (says:0.0000) (sitting on:0.4118) (standing on:0.5383) (using:0.1500) (walking in:0.0000) (walking on:0.1622) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-01-08 02:15:46 - train.py[line:487] - INFO: 0.33909999999999996
2023-01-08 02:15:46 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 02:15:46 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.362 | loss_v1 0 | loss_v2 0 | nll_loss 0.219 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.3391 | ppl 1.16 | vqa_score 0.1757 | wps 68.4 | wpb 72 | bsz 24 | num_updates 2000
2023-01-08 02:15:46 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2023-01-08 02:15:46 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_2000.pt
2023-01-08 02:16:37 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_2000.pt
2023-01-08 02:19:42 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.33909999999999996) (writing took 236.04717760533094 seconds)
2023-01-08 02:20:08 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 144806 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=85.6, nsentences=32, sample_size=85.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.006, wps=0.3, ups=0, wpb=85.6, bsz=32, num_updates=2010, lr=2.16922e-05, gnorm=1.276, clip=80, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=12023
2023-01-08 02:20:34 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.038, wps=67.7, ups=0.39, wpb=87, bsz=32, num_updates=2020, lr=2.18001e-05, gnorm=1.081, clip=40, loss_scale=512, train_wall=26, gb_free=14.8, ema_decay=0.9999, wall=12049
2023-01-08 02:20:59 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 144806 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0063, wps=69.5, ups=0.4, wpb=87, bsz=32, num_updates=2030, lr=2.19081e-05, gnorm=1.073, clip=60, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=12074
2023-01-08 02:21:25 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 144806 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0411, wps=69.3, ups=0.4, wpb=87.6, bsz=32, num_updates=2040, lr=2.2016e-05, gnorm=1.206, clip=70, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=12100
2023-01-08 02:21:51 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 144806 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0173, wps=67.8, ups=0.39, wpb=85.9, bsz=32, num_updates=2050, lr=2.21239e-05, gnorm=1.151, clip=60, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=12126
2023-01-08 02:22:16 - progress_bar.py[line:274] - INFO: epoch 001:   2061 / 144806 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0432, wps=68.8, ups=0.39, wpb=87.2, bsz=32, num_updates=2060, lr=2.22318e-05, gnorm=1.277, clip=90, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=12151
2023-01-08 02:22:42 - progress_bar.py[line:274] - INFO: epoch 001:   2071 / 144806 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0123, wps=67.5, ups=0.38, wpb=87.8, bsz=32, num_updates=2070, lr=2.23397e-05, gnorm=1.201, clip=70, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=12177
2023-01-08 02:23:08 - progress_bar.py[line:274] - INFO: epoch 001:   2081 / 144806 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0382, wps=69.7, ups=0.4, wpb=87.2, bsz=32, num_updates=2080, lr=2.24477e-05, gnorm=1.223, clip=70, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=12203
2023-01-08 02:23:33 - progress_bar.py[line:274] - INFO: epoch 001:   2091 / 144806 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0323, wps=70.3, ups=0.4, wpb=87.8, bsz=32, num_updates=2090, lr=2.25556e-05, gnorm=1.111, clip=70, loss_scale=1024, train_wall=25, gb_free=15.6, ema_decay=0.9999, wall=12228
2023-01-08 02:23:58 - progress_bar.py[line:274] - INFO: epoch 001:   2101 / 144806 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.051, wps=69.4, ups=0.39, wpb=88.4, bsz=32, num_updates=2100, lr=2.26635e-05, gnorm=0.969, clip=40, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=12254
2023-01-08 02:24:24 - progress_bar.py[line:274] - INFO: epoch 001:   2111 / 144806 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0309, wps=69.8, ups=0.39, wpb=88.5, bsz=32, num_updates=2110, lr=2.27714e-05, gnorm=1.169, clip=70, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=12279
2023-01-08 02:24:49 - progress_bar.py[line:274] - INFO: epoch 001:   2121 / 144806 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0132, wps=68.8, ups=0.4, wpb=86.4, bsz=32, num_updates=2120, lr=2.28793e-05, gnorm=1.053, clip=40, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=12304
2023-01-08 02:25:15 - progress_bar.py[line:274] - INFO: epoch 001:   2131 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0333, wps=68.6, ups=0.39, wpb=87.4, bsz=32, num_updates=2130, lr=2.29873e-05, gnorm=1.124, clip=50, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=12330
2023-01-08 02:25:41 - progress_bar.py[line:274] - INFO: epoch 001:   2141 / 144806 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0265, wps=68.5, ups=0.39, wpb=87.7, bsz=32, num_updates=2140, lr=2.30952e-05, gnorm=1.208, clip=70, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=12356
2023-01-08 02:26:07 - progress_bar.py[line:274] - INFO: epoch 001:   2151 / 144806 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0645, wps=68.5, ups=0.39, wpb=87.6, bsz=32, num_updates=2150, lr=2.32031e-05, gnorm=0.98, clip=40, loss_scale=1024, train_wall=26, gb_free=14.7, ema_decay=0.9999, wall=12382
2023-01-08 02:26:32 - progress_bar.py[line:274] - INFO: epoch 001:   2161 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.027, wps=68.5, ups=0.39, wpb=87.4, bsz=32, num_updates=2160, lr=2.3311e-05, gnorm=1.065, clip=50, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=12408
2023-01-08 02:26:58 - progress_bar.py[line:274] - INFO: epoch 001:   2171 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0265, wps=69, ups=0.39, wpb=87.6, bsz=32, num_updates=2170, lr=2.3419e-05, gnorm=1.079, clip=60, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=12433
2023-01-08 02:27:24 - progress_bar.py[line:274] - INFO: epoch 001:   2181 / 144806 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0237, wps=67, ups=0.39, wpb=86.7, bsz=32, num_updates=2180, lr=2.35269e-05, gnorm=1.029, clip=60, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=12459
2023-01-08 02:27:50 - progress_bar.py[line:274] - INFO: epoch 001:   2191 / 144806 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0201, wps=69.3, ups=0.4, wpb=87.7, bsz=32, num_updates=2190, lr=2.36348e-05, gnorm=1.049, clip=40, loss_scale=1024, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=12485
2023-01-08 02:28:15 - progress_bar.py[line:274] - INFO: epoch 001:   2201 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0181, wps=68.5, ups=0.39, wpb=86.8, bsz=32, num_updates=2200, lr=2.37427e-05, gnorm=1.098, clip=40, loss_scale=1024, train_wall=25, gb_free=15.7, ema_decay=0.9999, wall=12510
2023-01-08 02:28:41 - progress_bar.py[line:274] - INFO: epoch 001:   2211 / 144806 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0183, wps=68.6, ups=0.4, wpb=86.8, bsz=32, num_updates=2210, lr=2.38506e-05, gnorm=1.204, clip=60, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=12536
2023-01-08 02:29:07 - progress_bar.py[line:274] - INFO: epoch 001:   2221 / 144806 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.019, wps=68.2, ups=0.39, wpb=87, bsz=32, num_updates=2220, lr=2.39586e-05, gnorm=1.256, clip=90, loss_scale=1024, train_wall=25, gb_free=14.6, ema_decay=0.9999, wall=12562
2023-01-08 02:29:32 - progress_bar.py[line:274] - INFO: epoch 001:   2231 / 144806 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0195, wps=69.2, ups=0.39, wpb=87.8, bsz=32, num_updates=2230, lr=2.40665e-05, gnorm=1.241, clip=90, loss_scale=1024, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=12587
2023-01-08 02:29:58 - progress_bar.py[line:274] - INFO: epoch 001:   2241 / 144806 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0408, wps=69, ups=0.39, wpb=87.8, bsz=32, num_updates=2240, lr=2.41744e-05, gnorm=1.01, clip=40, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=12613
2023-01-08 02:30:24 - progress_bar.py[line:274] - INFO: epoch 001:   2251 / 144806 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0318, wps=68.5, ups=0.39, wpb=87.3, bsz=32, num_updates=2250, lr=2.42823e-05, gnorm=1.235, clip=80, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=12639
2023-01-08 02:30:49 - progress_bar.py[line:274] - INFO: epoch 001:   2261 / 144806 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.019, wps=68.2, ups=0.39, wpb=87.5, bsz=32, num_updates=2260, lr=2.43902e-05, gnorm=1.09, clip=80, loss_scale=1024, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=12665
2023-01-08 02:31:15 - progress_bar.py[line:274] - INFO: epoch 001:   2271 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0417, wps=69.3, ups=0.39, wpb=88, bsz=32, num_updates=2270, lr=2.44982e-05, gnorm=1.112, clip=70, loss_scale=1024, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=12690
2023-01-08 02:31:41 - progress_bar.py[line:274] - INFO: epoch 001:   2281 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0185, wps=68.3, ups=0.39, wpb=86.9, bsz=32, num_updates=2280, lr=2.46061e-05, gnorm=1.224, clip=80, loss_scale=1024, train_wall=25, gb_free=15.7, ema_decay=0.9999, wall=12716
2023-01-08 02:32:06 - progress_bar.py[line:274] - INFO: epoch 001:   2291 / 144806 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=85.7, nsentences=32, sample_size=85.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0398, wps=67.2, ups=0.39, wpb=85.7, bsz=32, num_updates=2290, lr=2.4714e-05, gnorm=1.112, clip=60, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=12742
2023-01-08 02:32:33 - progress_bar.py[line:274] - INFO: epoch 001:   2301 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0186, wps=67.9, ups=0.39, wpb=87.7, bsz=32, num_updates=2300, lr=2.48219e-05, gnorm=1.292, clip=70, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=12768
2023-01-08 02:32:59 - progress_bar.py[line:274] - INFO: epoch 001:   2311 / 144806 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0189, wps=67.4, ups=0.39, wpb=87.3, bsz=32, num_updates=2310, lr=2.49299e-05, gnorm=1.141, clip=70, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=12794
2023-01-08 02:33:24 - progress_bar.py[line:274] - INFO: epoch 001:   2321 / 144806 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=85.7, nsentences=32, sample_size=85.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0185, wps=67, ups=0.39, wpb=85.7, bsz=32, num_updates=2320, lr=2.50378e-05, gnorm=1.136, clip=60, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=12820
2023-01-08 02:33:50 - progress_bar.py[line:274] - INFO: epoch 001:   2331 / 144806 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0327, wps=69.7, ups=0.4, wpb=87.4, bsz=32, num_updates=2330, lr=2.51457e-05, gnorm=0.975, clip=50, loss_scale=1024, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=12845
2023-01-08 02:34:16 - progress_bar.py[line:274] - INFO: epoch 001:   2341 / 144806 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.023, wps=66.6, ups=0.39, wpb=85.5, bsz=32, num_updates=2340, lr=2.52536e-05, gnorm=1.13, clip=80, loss_scale=1024, train_wall=26, gb_free=14.9, ema_decay=0.9999, wall=12871
2023-01-08 02:34:41 - progress_bar.py[line:274] - INFO: epoch 001:   2351 / 144806 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0429, wps=67.8, ups=0.39, wpb=86.7, bsz=32, num_updates=2350, lr=2.53615e-05, gnorm=1.117, clip=70, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=12896
2023-01-08 02:35:07 - progress_bar.py[line:274] - INFO: epoch 001:   2361 / 144806 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0355, wps=69.3, ups=0.4, wpb=87.3, bsz=32, num_updates=2360, lr=2.54695e-05, gnorm=1.182, clip=60, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=12922
2023-01-08 02:35:33 - progress_bar.py[line:274] - INFO: epoch 001:   2371 / 144806 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0443, wps=69, ups=0.39, wpb=88.1, bsz=32, num_updates=2370, lr=2.55774e-05, gnorm=1.214, clip=90, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=12948
2023-01-08 02:35:58 - progress_bar.py[line:274] - INFO: epoch 001:   2381 / 144806 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0124, wps=69.6, ups=0.39, wpb=88.9, bsz=32, num_updates=2380, lr=2.56853e-05, gnorm=1.26, clip=80, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=12973
2023-01-08 02:36:24 - progress_bar.py[line:274] - INFO: epoch 001:   2391 / 144806 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0282, wps=69.8, ups=0.39, wpb=88.4, bsz=32, num_updates=2390, lr=2.57932e-05, gnorm=1.01, clip=20, loss_scale=1024, train_wall=25, gb_free=15, ema_decay=0.9999, wall=12999
2023-01-08 02:36:49 - progress_bar.py[line:274] - INFO: epoch 001:   2401 / 144806 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0063, wps=69.5, ups=0.4, wpb=87.4, bsz=32, num_updates=2400, lr=2.59011e-05, gnorm=1.092, clip=50, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=13024
2023-01-08 02:37:15 - progress_bar.py[line:274] - INFO: epoch 001:   2411 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0351, wps=68.4, ups=0.39, wpb=86.7, bsz=32, num_updates=2410, lr=2.60091e-05, gnorm=1.274, clip=90, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=13050
2023-01-08 02:37:40 - progress_bar.py[line:274] - INFO: epoch 001:   2421 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0, wps=69.5, ups=0.4, wpb=87.6, bsz=32, num_updates=2420, lr=2.6117e-05, gnorm=1.285, clip=90, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=13075
2023-01-08 02:38:06 - progress_bar.py[line:274] - INFO: epoch 001:   2431 / 144806 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.018, wps=68.5, ups=0.39, wpb=88, bsz=32, num_updates=2430, lr=2.62249e-05, gnorm=1.018, clip=50, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=13101
2023-01-08 02:38:32 - progress_bar.py[line:274] - INFO: epoch 001:   2441 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0237, wps=67.8, ups=0.39, wpb=86.9, bsz=32, num_updates=2440, lr=2.63328e-05, gnorm=1.028, clip=70, loss_scale=1024, train_wall=26, gb_free=14.6, ema_decay=0.9999, wall=13127
2023-01-08 02:38:58 - progress_bar.py[line:274] - INFO: epoch 001:   2451 / 144806 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0299, wps=68.7, ups=0.39, wpb=87.5, bsz=32, num_updates=2450, lr=2.64408e-05, gnorm=1.066, clip=40, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=13153
2023-01-08 02:39:24 - progress_bar.py[line:274] - INFO: epoch 001:   2461 / 144806 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0303, wps=67.4, ups=0.39, wpb=86.2, bsz=32, num_updates=2460, lr=2.65487e-05, gnorm=1.085, clip=60, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=13179
2023-01-08 02:39:49 - progress_bar.py[line:274] - INFO: epoch 001:   2471 / 144806 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0432, wps=67, ups=0.39, wpb=85.8, bsz=32, num_updates=2470, lr=2.66566e-05, gnorm=1.072, clip=60, loss_scale=1024, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=13205
2023-01-08 02:40:16 - progress_bar.py[line:274] - INFO: epoch 001:   2481 / 144806 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0422, wps=67.2, ups=0.39, wpb=86.8, bsz=32, num_updates=2480, lr=2.67645e-05, gnorm=0.955, clip=30, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=13231
2023-01-08 02:40:41 - progress_bar.py[line:274] - INFO: epoch 001:   2491 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0253, wps=68.4, ups=0.39, wpb=87.9, bsz=32, num_updates=2490, lr=2.68724e-05, gnorm=1.051, clip=30, loss_scale=1024, train_wall=26, gb_free=15, ema_decay=0.9999, wall=13257
2023-01-08 02:41:07 - progress_bar.py[line:274] - INFO: epoch 001:   2501 / 144806 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0182, wps=67.7, ups=0.39, wpb=86.1, bsz=32, num_updates=2500, lr=2.69804e-05, gnorm=1.062, clip=50, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=13282
2023-01-08 02:41:33 - progress_bar.py[line:274] - INFO: epoch 001:   2511 / 144806 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0127, wps=67.8, ups=0.39, wpb=86.9, bsz=32, num_updates=2510, lr=2.70883e-05, gnorm=0.939, clip=20, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=13308
2023-01-08 02:41:59 - progress_bar.py[line:274] - INFO: epoch 001:   2521 / 144806 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.026, wps=68.6, ups=0.39, wpb=87.8, bsz=32, num_updates=2520, lr=2.71962e-05, gnorm=1.054, clip=60, loss_scale=1024, train_wall=26, gb_free=14.9, ema_decay=0.9999, wall=13334
2023-01-08 02:42:24 - progress_bar.py[line:274] - INFO: epoch 001:   2531 / 144806 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0256, wps=68.2, ups=0.39, wpb=86.3, bsz=32, num_updates=2530, lr=2.73041e-05, gnorm=1.213, clip=80, loss_scale=1024, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=13359
2023-01-08 02:42:50 - progress_bar.py[line:274] - INFO: epoch 001:   2541 / 144806 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.018, wps=68.1, ups=0.39, wpb=87.5, bsz=32, num_updates=2540, lr=2.7412e-05, gnorm=1.086, clip=70, loss_scale=1024, train_wall=26, gb_free=15.5, ema_decay=0.9999, wall=13385
2023-01-08 02:43:16 - progress_bar.py[line:274] - INFO: epoch 001:   2551 / 144806 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0284, wps=69.6, ups=0.39, wpb=88.2, bsz=32, num_updates=2550, lr=2.752e-05, gnorm=1.285, clip=80, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=13411
2023-01-08 02:43:42 - progress_bar.py[line:274] - INFO: epoch 001:   2561 / 144806 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=89.5, nsentences=32, sample_size=89.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0142, wps=69.9, ups=0.39, wpb=89.5, bsz=32, num_updates=2560, lr=2.76279e-05, gnorm=1.022, clip=50, loss_scale=2048, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=13437
2023-01-08 02:44:00 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-08 02:44:10 - progress_bar.py[line:274] - INFO: epoch 001:   2572 / 144806 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=88.429, nsentences=32, sample_size=88.429, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0172, wps=66.2, ups=0.36, wpb=88.4, bsz=32, num_updates=2570, lr=2.77358e-05, gnorm=0.937, clip=20, loss_scale=1024, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=13465
2023-01-08 02:44:36 - progress_bar.py[line:274] - INFO: epoch 001:   2582 / 144806 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0298, wps=65.8, ups=0.38, wpb=86, bsz=32, num_updates=2580, lr=2.78437e-05, gnorm=1.002, clip=40, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=13491
2023-01-08 02:45:02 - progress_bar.py[line:274] - INFO: epoch 001:   2592 / 144806 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0184, wps=67.8, ups=0.39, wpb=87.2, bsz=32, num_updates=2590, lr=2.79517e-05, gnorm=0.913, clip=30, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=13517
2023-01-08 02:45:28 - progress_bar.py[line:274] - INFO: epoch 001:   2602 / 144806 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0479, wps=70.1, ups=0.4, wpb=88.7, bsz=32, num_updates=2600, lr=2.80596e-05, gnorm=1.114, clip=50, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=13543
2023-01-08 02:45:54 - progress_bar.py[line:274] - INFO: epoch 001:   2612 / 144806 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0419, wps=68.2, ups=0.39, wpb=87.3, bsz=32, num_updates=2610, lr=2.81675e-05, gnorm=1.056, clip=60, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=13569
2023-01-08 02:46:14 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 02:46:22 - progress_bar.py[line:274] - INFO: epoch 001:   2623 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.286, nsentences=32, sample_size=86.286, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0153, wps=65.1, ups=0.36, wpb=86.3, bsz=32, num_updates=2620, lr=2.82754e-05, gnorm=1.081, clip=40, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=13597
2023-01-08 02:46:47 - progress_bar.py[line:274] - INFO: epoch 001:   2633 / 144806 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0307, wps=68.7, ups=0.4, wpb=86.4, bsz=32, num_updates=2630, lr=2.83833e-05, gnorm=0.913, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=13622
2023-01-08 02:47:12 - progress_bar.py[line:274] - INFO: epoch 001:   2643 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0265, wps=69.5, ups=0.4, wpb=87.2, bsz=32, num_updates=2640, lr=2.84913e-05, gnorm=1.016, clip=50, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=13647
2023-01-08 02:47:38 - progress_bar.py[line:274] - INFO: epoch 001:   2653 / 144806 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0131, wps=69.5, ups=0.4, wpb=87.5, bsz=32, num_updates=2650, lr=2.85992e-05, gnorm=0.969, clip=30, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=13673
2023-01-08 02:48:03 - progress_bar.py[line:274] - INFO: epoch 001:   2663 / 144806 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0263, wps=69.5, ups=0.4, wpb=87.5, bsz=32, num_updates=2660, lr=2.87071e-05, gnorm=1.063, clip=60, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=13698
2023-01-08 02:48:29 - progress_bar.py[line:274] - INFO: epoch 001:   2673 / 144806 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0276, wps=68.2, ups=0.39, wpb=88.3, bsz=32, num_updates=2670, lr=2.8815e-05, gnorm=0.961, clip=30, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=13724
2023-01-08 02:48:55 - progress_bar.py[line:274] - INFO: epoch 001:   2683 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.1, nsentences=32, sample_size=85.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0114, wps=66.6, ups=0.39, wpb=85.1, bsz=32, num_updates=2680, lr=2.89229e-05, gnorm=0.926, clip=40, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=13750
2023-01-08 02:49:21 - progress_bar.py[line:274] - INFO: epoch 001:   2693 / 144806 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0373, wps=67.9, ups=0.39, wpb=86.4, bsz=32, num_updates=2690, lr=2.90309e-05, gnorm=0.969, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=13776
2023-01-08 02:49:47 - progress_bar.py[line:274] - INFO: epoch 001:   2703 / 144806 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0311, wps=67.8, ups=0.39, wpb=87.1, bsz=32, num_updates=2700, lr=2.91388e-05, gnorm=0.949, clip=30, loss_scale=512, train_wall=26, gb_free=14.7, ema_decay=0.9999, wall=13802
2023-01-08 02:50:13 - progress_bar.py[line:274] - INFO: epoch 001:   2713 / 144806 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0175, wps=67.6, ups=0.39, wpb=86.3, bsz=32, num_updates=2710, lr=2.92467e-05, gnorm=0.998, clip=50, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=13828
2023-01-08 02:50:39 - progress_bar.py[line:274] - INFO: epoch 001:   2723 / 144806 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0187, wps=68, ups=0.39, wpb=86.8, bsz=32, num_updates=2720, lr=2.93546e-05, gnorm=1.043, clip=60, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=13854
2023-01-08 02:51:04 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 144806 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0364, wps=68.3, ups=0.39, wpb=87, bsz=32, num_updates=2730, lr=2.94626e-05, gnorm=1.06, clip=40, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=13879
2023-01-08 02:51:30 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 144806 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0176, wps=67, ups=0.39, wpb=86.7, bsz=32, num_updates=2740, lr=2.95705e-05, gnorm=1.026, clip=30, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=13905
2023-01-08 02:51:56 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 144806 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0366, wps=68.4, ups=0.39, wpb=87.4, bsz=32, num_updates=2750, lr=2.96784e-05, gnorm=0.984, clip=40, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=13931
2023-01-08 02:52:22 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0316, wps=69.2, ups=0.39, wpb=88.1, bsz=32, num_updates=2760, lr=2.97863e-05, gnorm=1.013, clip=50, loss_scale=512, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=13957
2023-01-08 02:52:47 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0227, wps=69.5, ups=0.4, wpb=86.8, bsz=32, num_updates=2770, lr=2.98942e-05, gnorm=0.925, clip=40, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=13982
2023-01-08 02:53:13 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 144806 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0237, wps=66.5, ups=0.39, wpb=86.3, bsz=32, num_updates=2780, lr=3.00022e-05, gnorm=1.121, clip=70, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=14008
2023-01-08 02:53:38 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 144806 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0258, wps=70.1, ups=0.4, wpb=87.8, bsz=32, num_updates=2790, lr=3.01101e-05, gnorm=1.131, clip=60, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=14033
2023-01-08 02:54:04 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 144806 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0305, wps=67.9, ups=0.39, wpb=87.4, bsz=32, num_updates=2800, lr=3.0218e-05, gnorm=1.059, clip=60, loss_scale=512, train_wall=26, gb_free=15.5, ema_decay=0.9999, wall=14059
2023-01-08 02:54:30 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 144806 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0124, wps=67.8, ups=0.39, wpb=86, bsz=32, num_updates=2810, lr=3.03259e-05, gnorm=1.016, clip=40, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=14085
2023-01-08 02:54:56 - progress_bar.py[line:274] - INFO: epoch 001:   2823 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0245, wps=68, ups=0.39, wpb=86.7, bsz=32, num_updates=2820, lr=3.04338e-05, gnorm=1.057, clip=50, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=14111
2023-01-08 02:55:22 - progress_bar.py[line:274] - INFO: epoch 001:   2833 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.046, wps=66.4, ups=0.39, wpb=85.8, bsz=32, num_updates=2830, lr=3.05418e-05, gnorm=0.962, clip=30, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=14137
2023-01-08 02:55:48 - progress_bar.py[line:274] - INFO: epoch 001:   2843 / 144806 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0067, wps=67.7, ups=0.39, wpb=87.7, bsz=32, num_updates=2840, lr=3.06497e-05, gnorm=1.131, clip=60, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=14163
2023-01-08 02:56:14 - progress_bar.py[line:274] - INFO: epoch 001:   2853 / 144806 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0327, wps=68.2, ups=0.39, wpb=87.6, bsz=32, num_updates=2850, lr=3.07576e-05, gnorm=0.922, clip=30, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=14189
2023-01-08 02:56:40 - progress_bar.py[line:274] - INFO: epoch 001:   2863 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0255, wps=67.6, ups=0.39, wpb=87, bsz=32, num_updates=2860, lr=3.08655e-05, gnorm=0.924, clip=30, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=14215
2023-01-08 02:57:06 - progress_bar.py[line:274] - INFO: epoch 001:   2873 / 144806 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0314, wps=67.4, ups=0.39, wpb=86.9, bsz=32, num_updates=2870, lr=3.09735e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=14241
2023-01-08 02:57:32 - progress_bar.py[line:274] - INFO: epoch 001:   2883 / 144806 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0241, wps=67.8, ups=0.39, wpb=86.7, bsz=32, num_updates=2880, lr=3.10814e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=26, gb_free=14.6, ema_decay=0.9999, wall=14267
2023-01-08 02:57:58 - progress_bar.py[line:274] - INFO: epoch 001:   2893 / 144806 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0654, wps=68.5, ups=0.39, wpb=87, bsz=32, num_updates=2890, lr=3.11893e-05, gnorm=1.13, clip=70, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=14293
2023-01-08 02:58:23 - progress_bar.py[line:274] - INFO: epoch 001:   2903 / 144806 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0409, wps=68.2, ups=0.39, wpb=87.1, bsz=32, num_updates=2900, lr=3.12972e-05, gnorm=0.993, clip=20, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=14318
2023-01-08 02:58:50 - progress_bar.py[line:274] - INFO: epoch 001:   2913 / 144806 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0473, wps=66.2, ups=0.38, wpb=86.1, bsz=32, num_updates=2910, lr=3.14051e-05, gnorm=0.947, clip=40, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=14345
2023-01-08 02:59:15 - progress_bar.py[line:274] - INFO: epoch 001:   2923 / 144806 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0238, wps=68.9, ups=0.4, wpb=86.9, bsz=32, num_updates=2920, lr=3.15131e-05, gnorm=0.937, clip=50, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=14370
2023-01-08 02:59:41 - progress_bar.py[line:274] - INFO: epoch 001:   2933 / 144806 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0361, wps=67.1, ups=0.39, wpb=86.8, bsz=32, num_updates=2930, lr=3.1621e-05, gnorm=1.015, clip=50, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=14396
2023-01-08 03:00:07 - progress_bar.py[line:274] - INFO: epoch 001:   2943 / 144806 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.038, wps=68.8, ups=0.39, wpb=88, bsz=32, num_updates=2940, lr=3.17289e-05, gnorm=1.027, clip=60, loss_scale=512, train_wall=26, gb_free=15, ema_decay=0.9999, wall=14422
2023-01-08 03:00:32 - progress_bar.py[line:274] - INFO: epoch 001:   2953 / 144806 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=89.2, nsentences=32, sample_size=89.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0282, wps=71.2, ups=0.4, wpb=89.2, bsz=32, num_updates=2950, lr=3.18368e-05, gnorm=0.882, clip=20, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=14447
2023-01-08 03:00:58 - progress_bar.py[line:274] - INFO: epoch 001:   2963 / 144806 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0329, wps=67.9, ups=0.39, wpb=87.4, bsz=32, num_updates=2960, lr=3.19447e-05, gnorm=0.995, clip=40, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=14473
2023-01-08 03:01:24 - progress_bar.py[line:274] - INFO: epoch 001:   2973 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0314, wps=67.6, ups=0.39, wpb=86.5, bsz=32, num_updates=2970, lr=3.20527e-05, gnorm=1.016, clip=50, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=14499
2023-01-08 03:01:49 - progress_bar.py[line:274] - INFO: epoch 001:   2983 / 144806 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0305, wps=69.4, ups=0.4, wpb=87, bsz=32, num_updates=2980, lr=3.21606e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=14524
2023-01-08 03:02:16 - progress_bar.py[line:274] - INFO: epoch 001:   2993 / 144806 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0267, wps=67.7, ups=0.38, wpb=88.1, bsz=32, num_updates=2990, lr=3.22685e-05, gnorm=0.816, clip=10, loss_scale=512, train_wall=26, gb_free=14.7, ema_decay=0.9999, wall=14551
2023-01-08 03:02:41 - progress_bar.py[line:274] - INFO: epoch 001:   3003 / 144806 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0123, wps=67.5, ups=0.39, wpb=86, bsz=32, num_updates=3000, lr=3.23764e-05, gnorm=0.991, clip=40, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=14576
2023-01-08 03:03:07 - progress_bar.py[line:274] - INFO: epoch 001:   3013 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0516, wps=68.7, ups=0.4, wpb=86.5, bsz=32, num_updates=3010, lr=3.24844e-05, gnorm=1.029, clip=60, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=14602
2023-01-08 03:03:32 - progress_bar.py[line:274] - INFO: epoch 001:   3023 / 144806 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0427, wps=69.9, ups=0.4, wpb=88.4, bsz=32, num_updates=3020, lr=3.25923e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=14627
2023-01-08 03:03:58 - progress_bar.py[line:274] - INFO: epoch 001:   3033 / 144806 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0185, wps=68.1, ups=0.39, wpb=86.5, bsz=32, num_updates=3030, lr=3.27002e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=14653
2023-01-08 03:04:23 - progress_bar.py[line:274] - INFO: epoch 001:   3043 / 144806 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0281, wps=68.2, ups=0.4, wpb=85.5, bsz=32, num_updates=3040, lr=3.28081e-05, gnorm=0.856, clip=20, loss_scale=512, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=14678
2023-01-08 03:04:49 - progress_bar.py[line:274] - INFO: epoch 001:   3053 / 144806 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0252, wps=69.3, ups=0.4, wpb=87.5, bsz=32, num_updates=3050, lr=3.2916e-05, gnorm=1.018, clip=70, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=14704
2023-01-08 03:05:14 - progress_bar.py[line:274] - INFO: epoch 001:   3063 / 144806 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0452, wps=69.8, ups=0.39, wpb=88.5, bsz=32, num_updates=3060, lr=3.3024e-05, gnorm=0.959, clip=40, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=14729
2023-01-08 03:05:40 - progress_bar.py[line:274] - INFO: epoch 001:   3073 / 144806 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0276, wps=69.3, ups=0.39, wpb=87.8, bsz=32, num_updates=3070, lr=3.31319e-05, gnorm=1.021, clip=40, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=14755
2023-01-08 03:06:05 - progress_bar.py[line:274] - INFO: epoch 001:   3083 / 144806 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0508, wps=68.7, ups=0.4, wpb=86.1, bsz=32, num_updates=3080, lr=3.32398e-05, gnorm=0.939, clip=40, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=14780
2023-01-08 03:06:31 - progress_bar.py[line:274] - INFO: epoch 001:   3093 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0327, wps=69.3, ups=0.39, wpb=88.5, bsz=32, num_updates=3090, lr=3.33477e-05, gnorm=0.907, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=14806
2023-01-08 03:06:57 - progress_bar.py[line:274] - INFO: epoch 001:   3103 / 144806 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.053, wps=68.2, ups=0.39, wpb=87.1, bsz=32, num_updates=3100, lr=3.34556e-05, gnorm=0.8, clip=10, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=14832
2023-01-08 03:07:22 - progress_bar.py[line:274] - INFO: epoch 001:   3113 / 144806 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0549, wps=68.2, ups=0.39, wpb=86.6, bsz=32, num_updates=3110, lr=3.35636e-05, gnorm=0.994, clip=40, loss_scale=512, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=14857
2023-01-08 03:07:48 - progress_bar.py[line:274] - INFO: epoch 001:   3123 / 144806 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0307, wps=68.2, ups=0.39, wpb=87, bsz=32, num_updates=3120, lr=3.36715e-05, gnorm=0.847, clip=20, loss_scale=512, train_wall=25, gb_free=15.6, ema_decay=0.9999, wall=14883
2023-01-08 03:08:13 - progress_bar.py[line:274] - INFO: epoch 001:   3133 / 144806 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0435, wps=69.4, ups=0.4, wpb=87.3, bsz=32, num_updates=3130, lr=3.37794e-05, gnorm=0.908, clip=40, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=14908
2023-01-08 03:08:39 - progress_bar.py[line:274] - INFO: epoch 001:   3143 / 144806 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0312, wps=68, ups=0.39, wpb=87.5, bsz=32, num_updates=3140, lr=3.38873e-05, gnorm=0.938, clip=40, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=14934
2023-01-08 03:09:05 - progress_bar.py[line:274] - INFO: epoch 001:   3153 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0115, wps=68.5, ups=0.39, wpb=87.5, bsz=32, num_updates=3150, lr=3.39953e-05, gnorm=0.959, clip=30, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=14960
2023-01-08 03:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   3163 / 144806 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0258, wps=70.4, ups=0.4, wpb=87.7, bsz=32, num_updates=3160, lr=3.41032e-05, gnorm=0.93, clip=20, loss_scale=1024, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=14985
2023-01-08 03:09:56 - progress_bar.py[line:274] - INFO: epoch 001:   3173 / 144806 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0443, wps=69, ups=0.39, wpb=87.5, bsz=32, num_updates=3170, lr=3.42111e-05, gnorm=0.918, clip=40, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=15011
2023-01-08 03:10:21 - progress_bar.py[line:274] - INFO: epoch 001:   3183 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.039, wps=69.2, ups=0.39, wpb=87.7, bsz=32, num_updates=3180, lr=3.4319e-05, gnorm=0.807, clip=20, loss_scale=1024, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=15037
2023-01-08 03:10:47 - progress_bar.py[line:274] - INFO: epoch 001:   3193 / 144806 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0195, wps=69.1, ups=0.4, wpb=87.3, bsz=32, num_updates=3190, lr=3.44269e-05, gnorm=0.82, clip=10, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=15062
2023-01-08 03:11:13 - progress_bar.py[line:274] - INFO: epoch 001:   3203 / 144806 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0375, wps=68.1, ups=0.39, wpb=87.2, bsz=32, num_updates=3200, lr=3.45349e-05, gnorm=0.807, clip=10, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=15088
2023-01-08 03:11:39 - progress_bar.py[line:274] - INFO: epoch 001:   3213 / 144806 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0359, wps=67.9, ups=0.39, wpb=86.3, bsz=32, num_updates=3210, lr=3.46428e-05, gnorm=0.769, clip=0, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=15114
2023-01-08 03:11:57 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 03:12:07 - progress_bar.py[line:274] - INFO: epoch 001:   3224 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.238, nsentences=32, sample_size=88.238, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0419, wps=66.6, ups=0.36, wpb=88.2, bsz=32, num_updates=3220, lr=3.47507e-05, gnorm=0.995, clip=50, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=15142
2023-01-08 03:12:34 - progress_bar.py[line:274] - INFO: epoch 001:   3234 / 144806 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0353, wps=66.3, ups=0.38, wpb=86.4, bsz=32, num_updates=3230, lr=3.48586e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=15168
2023-01-08 03:12:59 - progress_bar.py[line:274] - INFO: epoch 001:   3244 / 144806 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0231, wps=68.2, ups=0.39, wpb=87.3, bsz=32, num_updates=3240, lr=3.49665e-05, gnorm=0.956, clip=30, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=15194
2023-01-08 03:13:25 - progress_bar.py[line:274] - INFO: epoch 001:   3254 / 144806 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0395, wps=68.4, ups=0.39, wpb=87.1, bsz=32, num_updates=3250, lr=3.50745e-05, gnorm=0.795, clip=10, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=15220
2023-01-08 03:13:51 - progress_bar.py[line:274] - INFO: epoch 001:   3264 / 144806 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0237, wps=69.9, ups=0.39, wpb=88.9, bsz=32, num_updates=3260, lr=3.51824e-05, gnorm=0.962, clip=40, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=15246
2023-01-08 03:14:17 - progress_bar.py[line:274] - INFO: epoch 001:   3274 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0336, wps=69.4, ups=0.4, wpb=87.8, bsz=32, num_updates=3270, lr=3.52903e-05, gnorm=0.945, clip=30, loss_scale=512, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=15272
2023-01-08 03:14:42 - progress_bar.py[line:274] - INFO: epoch 001:   3284 / 144806 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.051, wps=68.2, ups=0.39, wpb=87, bsz=32, num_updates=3280, lr=3.53982e-05, gnorm=0.859, clip=10, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=15297
2023-01-08 03:15:07 - progress_bar.py[line:274] - INFO: epoch 001:   3294 / 144806 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0265, wps=69.9, ups=0.4, wpb=87.2, bsz=32, num_updates=3290, lr=3.55062e-05, gnorm=0.985, clip=50, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=15323
2023-01-08 03:15:33 - progress_bar.py[line:274] - INFO: epoch 001:   3304 / 144806 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0331, wps=67.8, ups=0.39, wpb=86.7, bsz=32, num_updates=3300, lr=3.56141e-05, gnorm=0.826, clip=40, loss_scale=512, train_wall=26, gb_free=15.5, ema_decay=0.9999, wall=15348
2023-01-08 03:15:59 - progress_bar.py[line:274] - INFO: epoch 001:   3314 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0231, wps=68.8, ups=0.4, wpb=85.5, bsz=32, num_updates=3310, lr=3.5722e-05, gnorm=1.064, clip=50, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=15373
2023-01-08 03:16:25 - progress_bar.py[line:274] - INFO: epoch 001:   3324 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0544, wps=68.1, ups=0.39, wpb=87.9, bsz=32, num_updates=3320, lr=3.58299e-05, gnorm=0.775, clip=0, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=15400
2023-01-08 03:16:51 - progress_bar.py[line:274] - INFO: epoch 001:   3334 / 144806 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0536, wps=69.6, ups=0.39, wpb=88.2, bsz=32, num_updates=3330, lr=3.59378e-05, gnorm=0.769, clip=20, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=15425
2023-01-08 03:17:16 - progress_bar.py[line:274] - INFO: epoch 001:   3344 / 144806 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0301, wps=69.2, ups=0.4, wpb=87.5, bsz=32, num_updates=3340, lr=3.60458e-05, gnorm=0.837, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=15451
2023-01-08 03:17:42 - progress_bar.py[line:274] - INFO: epoch 001:   3354 / 144806 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0536, wps=68, ups=0.39, wpb=86.9, bsz=32, num_updates=3350, lr=3.61537e-05, gnorm=1.025, clip=20, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=15477
2023-01-08 03:18:08 - progress_bar.py[line:274] - INFO: epoch 001:   3364 / 144806 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0323, wps=68.4, ups=0.39, wpb=87, bsz=32, num_updates=3360, lr=3.62616e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=15503
2023-01-08 03:18:34 - progress_bar.py[line:274] - INFO: epoch 001:   3374 / 144806 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0424, wps=68.1, ups=0.39, wpb=87.1, bsz=32, num_updates=3370, lr=3.63695e-05, gnorm=0.843, clip=40, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=15529
2023-01-08 03:19:00 - progress_bar.py[line:274] - INFO: epoch 001:   3384 / 144806 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.021, wps=69, ups=0.39, wpb=87.7, bsz=32, num_updates=3380, lr=3.64774e-05, gnorm=0.76, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=15555
2023-01-08 03:19:26 - progress_bar.py[line:274] - INFO: epoch 001:   3394 / 144806 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0263, wps=68.7, ups=0.39, wpb=88.4, bsz=32, num_updates=3390, lr=3.65854e-05, gnorm=0.797, clip=0, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=15581
2023-01-08 03:19:51 - progress_bar.py[line:274] - INFO: epoch 001:   3404 / 144806 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0485, wps=69.3, ups=0.4, wpb=86.8, bsz=32, num_updates=3400, lr=3.66933e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=15606
2023-01-08 03:20:17 - progress_bar.py[line:274] - INFO: epoch 001:   3414 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0468, wps=69.6, ups=0.4, wpb=86.5, bsz=32, num_updates=3410, lr=3.68012e-05, gnorm=0.798, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=15632
2023-01-08 03:20:42 - progress_bar.py[line:274] - INFO: epoch 001:   3424 / 144806 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0062, wps=69, ups=0.39, wpb=87.3, bsz=32, num_updates=3420, lr=3.69091e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=15657
2023-01-08 03:21:08 - progress_bar.py[line:274] - INFO: epoch 001:   3434 / 144806 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0203, wps=69.1, ups=0.39, wpb=87.8, bsz=32, num_updates=3430, lr=3.70171e-05, gnorm=1.016, clip=40, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=15683
2023-01-08 03:21:34 - progress_bar.py[line:274] - INFO: epoch 001:   3444 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0129, wps=68.5, ups=0.39, wpb=87.1, bsz=32, num_updates=3440, lr=3.7125e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=15709
2023-01-08 03:22:00 - progress_bar.py[line:274] - INFO: epoch 001:   3454 / 144806 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0671, wps=69.9, ups=0.4, wpb=87.4, bsz=32, num_updates=3450, lr=3.72329e-05, gnorm=0.839, clip=40, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=15734
2023-01-08 03:22:26 - progress_bar.py[line:274] - INFO: epoch 001:   3464 / 144806 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0298, wps=66.9, ups=0.39, wpb=86.4, bsz=32, num_updates=3460, lr=3.73408e-05, gnorm=0.821, clip=20, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=15761
2023-01-08 03:22:52 - progress_bar.py[line:274] - INFO: epoch 001:   3474 / 144806 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0643, wps=67.3, ups=0.39, wpb=87.2, bsz=32, num_updates=3470, lr=3.74487e-05, gnorm=0.854, clip=10, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=15787
2023-01-08 03:23:18 - progress_bar.py[line:274] - INFO: epoch 001:   3484 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0592, wps=68, ups=0.39, wpb=86.6, bsz=32, num_updates=3480, lr=3.75567e-05, gnorm=0.988, clip=30, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=15813
2023-01-08 03:23:44 - progress_bar.py[line:274] - INFO: epoch 001:   3494 / 144806 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0519, wps=68.2, ups=0.39, wpb=87.1, bsz=32, num_updates=3490, lr=3.76646e-05, gnorm=0.921, clip=40, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=15839
2023-01-08 03:24:10 - progress_bar.py[line:274] - INFO: epoch 001:   3504 / 144806 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0338, wps=69.2, ups=0.39, wpb=88.1, bsz=32, num_updates=3500, lr=3.77725e-05, gnorm=0.924, clip=30, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=15865
2023-01-08 03:24:36 - progress_bar.py[line:274] - INFO: epoch 001:   3514 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=89, nsentences=32, sample_size=89, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0365, wps=70.2, ups=0.39, wpb=89, bsz=32, num_updates=3510, lr=3.78804e-05, gnorm=0.808, clip=20, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=15891
2023-01-08 03:25:01 - progress_bar.py[line:274] - INFO: epoch 001:   3524 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0927, wps=70.6, ups=0.4, wpb=88, bsz=32, num_updates=3520, lr=3.79883e-05, gnorm=1.008, clip=50, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=15916
2023-01-08 03:25:27 - progress_bar.py[line:274] - INFO: epoch 001:   3534 / 144806 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0364, wps=68.8, ups=0.4, wpb=86.5, bsz=32, num_updates=3530, lr=3.80963e-05, gnorm=0.854, clip=10, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=15942
2023-01-08 03:25:53 - progress_bar.py[line:274] - INFO: epoch 001:   3544 / 144806 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0135, wps=67.2, ups=0.39, wpb=86.2, bsz=32, num_updates=3540, lr=3.82042e-05, gnorm=0.866, clip=10, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=15968
2023-01-08 03:26:19 - progress_bar.py[line:274] - INFO: epoch 001:   3554 / 144806 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0276, wps=69, ups=0.39, wpb=88, bsz=32, num_updates=3550, lr=3.83121e-05, gnorm=0.897, clip=20, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=15994
2023-01-08 03:26:44 - progress_bar.py[line:274] - INFO: epoch 001:   3564 / 144806 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0513, wps=69.9, ups=0.4, wpb=87.7, bsz=32, num_updates=3560, lr=3.842e-05, gnorm=0.736, clip=10, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=16019
2023-01-08 03:27:10 - progress_bar.py[line:274] - INFO: epoch 001:   3574 / 144806 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0234, wps=67.8, ups=0.39, wpb=86.7, bsz=32, num_updates=3570, lr=3.8528e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=26, gb_free=15, ema_decay=0.9999, wall=16045
2023-01-08 03:27:36 - progress_bar.py[line:274] - INFO: epoch 001:   3584 / 144806 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0432, wps=68.6, ups=0.39, wpb=87.6, bsz=32, num_updates=3580, lr=3.86359e-05, gnorm=0.728, clip=0, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=16071
2023-01-08 03:28:02 - progress_bar.py[line:274] - INFO: epoch 001:   3594 / 144806 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.024, wps=67.6, ups=0.39, wpb=86.7, bsz=32, num_updates=3590, lr=3.87438e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=16097
2023-01-08 03:28:28 - progress_bar.py[line:274] - INFO: epoch 001:   3604 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0312, wps=68.7, ups=0.39, wpb=87.2, bsz=32, num_updates=3600, lr=3.88517e-05, gnorm=0.859, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=16123
2023-01-08 03:28:53 - progress_bar.py[line:274] - INFO: epoch 001:   3614 / 144806 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0327, wps=71.2, ups=0.41, wpb=87.7, bsz=32, num_updates=3610, lr=3.89596e-05, gnorm=0.78, clip=10, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=16148
2023-01-08 03:29:19 - progress_bar.py[line:274] - INFO: epoch 001:   3624 / 144806 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0465, wps=69.3, ups=0.4, wpb=87.3, bsz=32, num_updates=3620, lr=3.90676e-05, gnorm=0.745, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=16174
2023-01-08 03:29:45 - progress_bar.py[line:274] - INFO: epoch 001:   3634 / 144806 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0307, wps=69.2, ups=0.4, wpb=86.8, bsz=32, num_updates=3630, lr=3.91755e-05, gnorm=0.781, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=16199
2023-01-08 03:30:10 - progress_bar.py[line:274] - INFO: epoch 001:   3644 / 144806 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0192, wps=70, ups=0.4, wpb=87.4, bsz=32, num_updates=3640, lr=3.92834e-05, gnorm=0.912, clip=20, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=16225
2023-01-08 03:30:36 - progress_bar.py[line:274] - INFO: epoch 001:   3654 / 144806 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0435, wps=68.8, ups=0.39, wpb=88, bsz=32, num_updates=3650, lr=3.93913e-05, gnorm=0.841, clip=30, loss_scale=512, train_wall=26, gb_free=15, ema_decay=0.9999, wall=16251
2023-01-08 03:31:02 - progress_bar.py[line:274] - INFO: epoch 001:   3664 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0253, wps=67.9, ups=0.39, wpb=87.2, bsz=32, num_updates=3660, lr=3.94992e-05, gnorm=0.808, clip=20, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=16277
2023-01-08 03:31:28 - progress_bar.py[line:274] - INFO: epoch 001:   3674 / 144806 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0237, wps=69.5, ups=0.4, wpb=86.8, bsz=32, num_updates=3670, lr=3.96072e-05, gnorm=0.822, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=16302
2023-01-08 03:31:54 - progress_bar.py[line:274] - INFO: epoch 001:   3684 / 144806 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0604, wps=67.9, ups=0.39, wpb=87.4, bsz=32, num_updates=3680, lr=3.97151e-05, gnorm=0.736, clip=0, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=16329
2023-01-08 03:32:20 - progress_bar.py[line:274] - INFO: epoch 001:   3694 / 144806 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0629, wps=68.3, ups=0.39, wpb=87.9, bsz=32, num_updates=3690, lr=3.9823e-05, gnorm=0.903, clip=30, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=16355
2023-01-08 03:32:46 - progress_bar.py[line:274] - INFO: epoch 001:   3704 / 144806 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0854, wps=67.9, ups=0.39, wpb=87.6, bsz=32, num_updates=3700, lr=3.99309e-05, gnorm=0.851, clip=10, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=16381
2023-01-08 03:33:12 - progress_bar.py[line:274] - INFO: epoch 001:   3714 / 144806 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0342, wps=69.8, ups=0.4, wpb=87.5, bsz=32, num_updates=3710, lr=4.00389e-05, gnorm=0.836, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=16407
2023-01-08 03:33:38 - progress_bar.py[line:274] - INFO: epoch 001:   3724 / 144806 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0417, wps=67.2, ups=0.39, wpb=86.2, bsz=32, num_updates=3720, lr=4.01468e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=16433
2023-01-08 03:34:03 - progress_bar.py[line:274] - INFO: epoch 001:   3734 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0256, wps=70.3, ups=0.4, wpb=88.3, bsz=32, num_updates=3730, lr=4.02547e-05, gnorm=0.806, clip=30, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=16458
2023-01-08 03:34:29 - progress_bar.py[line:274] - INFO: epoch 001:   3744 / 144806 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0129, wps=69.6, ups=0.4, wpb=86.6, bsz=32, num_updates=3740, lr=4.03626e-05, gnorm=0.705, clip=0, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=16484
2023-01-08 03:34:56 - progress_bar.py[line:274] - INFO: epoch 001:   3754 / 144806 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0, wps=67.9, ups=0.39, wpb=87.8, bsz=32, num_updates=3750, lr=4.04705e-05, gnorm=0.747, clip=20, loss_scale=1024, train_wall=26, gb_free=15.6, ema_decay=0.9999, wall=16510
2023-01-08 03:35:22 - progress_bar.py[line:274] - INFO: epoch 001:   3764 / 144806 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0238, wps=68.7, ups=0.39, wpb=87, bsz=32, num_updates=3760, lr=4.05785e-05, gnorm=0.791, clip=20, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=16536
2023-01-08 03:35:48 - progress_bar.py[line:274] - INFO: epoch 001:   3774 / 144806 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0321, wps=68.5, ups=0.39, wpb=87.9, bsz=32, num_updates=3770, lr=4.06864e-05, gnorm=0.847, clip=20, loss_scale=1024, train_wall=26, gb_free=15, ema_decay=0.9999, wall=16563
2023-01-08 03:36:14 - progress_bar.py[line:274] - INFO: epoch 001:   3784 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0373, wps=69.7, ups=0.4, wpb=87.4, bsz=32, num_updates=3780, lr=4.07943e-05, gnorm=0.672, clip=0, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=16589
2023-01-08 03:36:41 - progress_bar.py[line:274] - INFO: epoch 001:   3794 / 144806 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.012, wps=68.3, ups=0.39, wpb=87.3, bsz=32, num_updates=3790, lr=4.09022e-05, gnorm=0.864, clip=20, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=16615
2023-01-08 03:37:07 - progress_bar.py[line:274] - INFO: epoch 001:   3804 / 144806 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0683, wps=69.5, ups=0.4, wpb=87.7, bsz=32, num_updates=3800, lr=4.10101e-05, gnorm=0.815, clip=10, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=16642
2023-01-08 03:37:33 - progress_bar.py[line:274] - INFO: epoch 001:   3814 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0542, wps=68.4, ups=0.39, wpb=87.3, bsz=32, num_updates=3810, lr=4.11181e-05, gnorm=0.833, clip=30, loss_scale=1024, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=16668
2023-01-08 03:38:00 - progress_bar.py[line:274] - INFO: epoch 001:   3824 / 144806 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0307, wps=69, ups=0.4, wpb=87, bsz=32, num_updates=3820, lr=4.1226e-05, gnorm=0.719, clip=10, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=16694
2023-01-08 03:38:26 - progress_bar.py[line:274] - INFO: epoch 001:   3834 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0395, wps=69.8, ups=0.4, wpb=87.5, bsz=32, num_updates=3830, lr=4.13339e-05, gnorm=0.792, clip=20, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=16720
2023-01-08 03:38:52 - progress_bar.py[line:274] - INFO: epoch 001:   3844 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0135, wps=68.6, ups=0.39, wpb=87.6, bsz=32, num_updates=3840, lr=4.14418e-05, gnorm=0.79, clip=10, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=16746
2023-01-08 03:39:19 - progress_bar.py[line:274] - INFO: epoch 001:   3854 / 144806 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0241, wps=66.6, ups=0.39, wpb=85.8, bsz=32, num_updates=3850, lr=4.15498e-05, gnorm=0.77, clip=10, loss_scale=1024, train_wall=26, gb_free=15, ema_decay=0.9999, wall=16773
2023-01-08 03:39:45 - progress_bar.py[line:274] - INFO: epoch 001:   3864 / 144806 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0299, wps=70, ups=0.4, wpb=87.7, bsz=32, num_updates=3860, lr=4.16577e-05, gnorm=0.727, clip=10, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=16799
2023-01-08 03:40:11 - progress_bar.py[line:274] - INFO: epoch 001:   3874 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0301, wps=68.8, ups=0.39, wpb=88.1, bsz=32, num_updates=3870, lr=4.17656e-05, gnorm=0.918, clip=30, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=16826
2023-01-08 03:40:37 - progress_bar.py[line:274] - INFO: epoch 001:   3884 / 144806 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0382, wps=69.4, ups=0.39, wpb=88.1, bsz=32, num_updates=3880, lr=4.18735e-05, gnorm=0.818, clip=10, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=16852
2023-01-08 03:41:04 - progress_bar.py[line:274] - INFO: epoch 001:   3894 / 144806 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0654, wps=67.4, ups=0.38, wpb=87.6, bsz=32, num_updates=3890, lr=4.19814e-05, gnorm=0.731, clip=0, loss_scale=1024, train_wall=26, gb_free=14.7, ema_decay=0.9999, wall=16879
2023-01-08 03:41:31 - progress_bar.py[line:274] - INFO: epoch 001:   3904 / 144806 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0714, wps=68.3, ups=0.39, wpb=87.7, bsz=32, num_updates=3900, lr=4.20894e-05, gnorm=0.879, clip=40, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=16905
2023-01-08 03:41:57 - progress_bar.py[line:274] - INFO: epoch 001:   3914 / 144806 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0479, wps=67.7, ups=0.39, wpb=86.2, bsz=32, num_updates=3910, lr=4.21973e-05, gnorm=0.7, clip=10, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=16932
2023-01-08 03:42:24 - progress_bar.py[line:274] - INFO: epoch 001:   3924 / 144806 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0385, wps=68.8, ups=0.39, wpb=87.2, bsz=32, num_updates=3920, lr=4.23052e-05, gnorm=0.903, clip=40, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=16958
2023-01-08 03:42:34 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 03:42:53 - progress_bar.py[line:274] - INFO: epoch 001:   3935 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.524, nsentences=32, sample_size=88.524, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0339, wps=65.9, ups=0.35, wpb=88.5, bsz=32, num_updates=3930, lr=4.24131e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=28, gb_free=15, ema_decay=0.9999, wall=16987
2023-01-08 03:43:19 - progress_bar.py[line:274] - INFO: epoch 001:   3945 / 144806 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0464, wps=69.9, ups=0.4, wpb=87.9, bsz=32, num_updates=3940, lr=4.2521e-05, gnorm=0.808, clip=20, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=17013
2023-01-08 03:43:45 - progress_bar.py[line:274] - INFO: epoch 001:   3955 / 144806 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0195, wps=69.1, ups=0.4, wpb=87.4, bsz=32, num_updates=3950, lr=4.2629e-05, gnorm=0.73, clip=0, loss_scale=512, train_wall=25, gb_free=15.6, ema_decay=0.9999, wall=17039
2023-01-08 03:44:12 - progress_bar.py[line:274] - INFO: epoch 001:   3965 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0341, wps=67.9, ups=0.39, wpb=87.2, bsz=32, num_updates=3960, lr=4.27369e-05, gnorm=0.797, clip=20, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=17066
2023-01-08 03:44:39 - progress_bar.py[line:274] - INFO: epoch 001:   3975 / 144806 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0375, wps=67.8, ups=0.39, wpb=87.4, bsz=32, num_updates=3970, lr=4.28448e-05, gnorm=0.862, clip=30, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=17093
2023-01-08 03:45:05 - progress_bar.py[line:274] - INFO: epoch 001:   3985 / 144806 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=85.2, nsentences=32, sample_size=85.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0169, wps=66.8, ups=0.39, wpb=85.2, bsz=32, num_updates=3980, lr=4.29527e-05, gnorm=0.924, clip=30, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=17119
2023-01-08 03:45:32 - progress_bar.py[line:274] - INFO: epoch 001:   3995 / 144806 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0368, wps=68.7, ups=0.39, wpb=87.3, bsz=32, num_updates=3990, lr=4.30607e-05, gnorm=0.904, clip=40, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=17146
2023-01-08 03:45:58 - progress_bar.py[line:274] - INFO: epoch 001:   4005 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0403, wps=69.2, ups=0.39, wpb=88.1, bsz=32, num_updates=4000, lr=4.31686e-05, gnorm=0.757, clip=0, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=17172
2023-01-08 03:45:58 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 03:45:59 - train.py[line:549] - INFO: 0 / 6234
2023-01-08 03:45:59 - train.py[line:551] - INFO: load:0.88 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 03:46:03 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.97 GiB (GPU 1; 39.59 GiB total capacity; 8.42 GiB already allocated; 4.96 GiB free; 25.31 GiB reserved in total by PyTorch)
2023-01-08 03:46:03 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-08 03:46:03 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 9         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8626 MB |   13622 MB |    1567 TB |    1567 TB |
|       from large pool |    8452 MB |   13447 MB |    1566 TB |    1566 TB |
|       from small pool |     174 MB |     174 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8626 MB |   13622 MB |    1567 TB |    1567 TB |
|       from large pool |    8452 MB |   13447 MB |    1566 TB |    1566 TB |
|       from small pool |     174 MB |     174 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   25916 MB |   30946 MB |  131578 MB |  105662 MB |
|       from large pool |   25740 MB |   30770 MB |  131230 MB |  105490 MB |
|       from small pool |     176 MB |     180 MB |     348 MB |     172 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17289 MB |   20865 MB |    1919 TB |    1919 TB |
|       from large pool |   17287 MB |   20862 MB |    1918 TB |    1918 TB |
|       from small pool |       1 MB |       2 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4634    |    4648    |   83323 K  |   83319 K  |
|       from large pool |     698    |     710    |   28508 K  |   28508 K  |
|       from small pool |    3936    |    3946    |   54814 K  |   54810 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4634    |    4648    |   83323 K  |   83319 K  |
|       from large pool |     698    |     710    |   28508 K  |   28508 K  |
|       from small pool |    3936    |    3946    |   54814 K  |   54810 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     197    |     202    |     525    |     328    |
|       from large pool |     109    |     112    |     351    |     242    |
|       from small pool |      88    |      90    |     174    |      86    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     124    |     140    |   63538 K  |   63538 K  |
|       from large pool |      68    |      74    |   17525 K  |   17525 K  |
|       from small pool |      56    |      71    |   46012 K  |   46012 K  |
|===========================================================================|

2023-01-08 03:46:03 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-08 03:49:32 - train.py[line:549] - INFO: 200 / 6234
2023-01-08 03:49:32 - train.py[line:551] - INFO: load:0.90 valid_run:212.41 task_valid:206.44 collect_output:3.96
2023-01-08 03:53:00 - train.py[line:549] - INFO: 400 / 6234
2023-01-08 03:53:00 - train.py[line:551] - INFO: load:0.93 valid_run:420.83 task_valid:409.00 collect_output:7.85
2023-01-08 03:56:31 - train.py[line:549] - INFO: 600 / 6234
2023-01-08 03:56:31 - train.py[line:551] - INFO: load:0.96 valid_run:631.53 task_valid:612.21 collect_output:13.40
2023-01-08 04:00:02 - train.py[line:549] - INFO: 800 / 6234
2023-01-08 04:00:02 - train.py[line:551] - INFO: load:0.98 valid_run:841.91 task_valid:811.73 collect_output:22.31
2023-01-08 04:03:31 - train.py[line:549] - INFO: 1000 / 6234
2023-01-08 04:03:31 - train.py[line:551] - INFO: load:1.01 valid_run:1050.89 task_valid:1016.12 collect_output:24.93
2023-01-08 04:07:03 - train.py[line:549] - INFO: 1200 / 6234
2023-01-08 04:07:03 - train.py[line:551] - INFO: load:1.04 valid_run:1262.90 task_valid:1222.24 collect_output:28.86
2023-01-08 04:10:35 - train.py[line:549] - INFO: 1400 / 6234
2023-01-08 04:10:35 - train.py[line:551] - INFO: load:1.06 valid_run:1475.23 task_valid:1427.52 collect_output:33.94
2023-01-08 04:14:06 - train.py[line:549] - INFO: 1600 / 6234
2023-01-08 04:14:06 - train.py[line:551] - INFO: load:1.09 valid_run:1685.62 task_valid:1630.56 collect_output:39.34
2023-01-08 04:17:39 - train.py[line:549] - INFO: 1800 / 6234
2023-01-08 04:17:39 - train.py[line:551] - INFO: load:1.12 valid_run:1898.65 task_valid:1834.64 collect_output:46.34
2023-01-08 04:21:09 - train.py[line:549] - INFO: 2000 / 6234
2023-01-08 04:21:09 - train.py[line:551] - INFO: load:1.14 valid_run:2108.47 task_valid:2032.75 collect_output:56.08
2023-01-08 04:24:37 - train.py[line:549] - INFO: 2200 / 6234
2023-01-08 04:24:37 - train.py[line:551] - INFO: load:1.17 valid_run:2316.76 task_valid:2234.80 collect_output:60.35
2023-01-08 04:28:07 - train.py[line:549] - INFO: 2400 / 6234
2023-01-08 04:28:07 - train.py[line:551] - INFO: load:1.20 valid_run:2526.74 task_valid:2438.43 collect_output:64.75
2023-01-08 04:31:33 - train.py[line:549] - INFO: 2600 / 6234
2023-01-08 04:31:33 - train.py[line:551] - INFO: load:1.23 valid_run:2732.84 task_valid:2637.58 collect_output:69.75
2023-01-08 04:35:03 - train.py[line:549] - INFO: 2800 / 6234
2023-01-08 04:35:03 - train.py[line:551] - INFO: load:1.25 valid_run:2942.25 task_valid:2842.36 collect_output:72.40
2023-01-08 04:38:32 - train.py[line:549] - INFO: 3000 / 6234
2023-01-08 04:38:32 - train.py[line:551] - INFO: load:1.28 valid_run:3151.12 task_valid:3044.83 collect_output:76.86
2023-01-08 04:42:01 - train.py[line:549] - INFO: 3200 / 6234
2023-01-08 04:42:01 - train.py[line:551] - INFO: load:1.31 valid_run:3360.21 task_valid:3244.48 collect_output:84.32
2023-01-08 04:45:31 - train.py[line:549] - INFO: 3400 / 6234
2023-01-08 04:45:31 - train.py[line:551] - INFO: load:1.34 valid_run:3569.91 task_valid:3446.89 collect_output:89.67
2023-01-08 04:49:00 - train.py[line:549] - INFO: 3600 / 6234
2023-01-08 04:49:00 - train.py[line:551] - INFO: load:1.36 valid_run:3778.75 task_valid:3651.54 collect_output:91.91
2023-01-08 04:52:30 - train.py[line:549] - INFO: 3800 / 6234
2023-01-08 04:52:30 - train.py[line:551] - INFO: load:1.39 valid_run:3988.58 task_valid:3855.05 collect_output:96.29
2023-01-08 04:55:59 - train.py[line:549] - INFO: 4000 / 6234
2023-01-08 04:55:59 - train.py[line:551] - INFO: load:1.42 valid_run:4197.50 task_valid:4058.34 collect_output:99.96
2023-01-08 04:59:29 - train.py[line:549] - INFO: 4200 / 6234
2023-01-08 04:59:29 - train.py[line:551] - INFO: load:1.44 valid_run:4408.05 task_valid:4261.41 collect_output:105.49
2023-01-08 05:03:00 - train.py[line:549] - INFO: 4400 / 6234
2023-01-08 05:03:00 - train.py[line:551] - INFO: load:1.47 valid_run:4618.88 task_valid:4467.78 collect_output:108.01
2023-01-08 05:06:29 - train.py[line:549] - INFO: 4600 / 6234
2023-01-08 05:06:29 - train.py[line:551] - INFO: load:1.50 valid_run:4827.82 task_valid:4668.38 collect_output:114.37
2023-01-08 05:09:58 - train.py[line:549] - INFO: 4800 / 6234
2023-01-08 05:09:58 - train.py[line:551] - INFO: load:1.52 valid_run:5036.06 task_valid:4871.39 collect_output:117.62
2023-01-08 05:13:28 - train.py[line:549] - INFO: 5000 / 6234
2023-01-08 05:13:28 - train.py[line:551] - INFO: load:1.55 valid_run:5246.38 task_valid:5074.08 collect_output:123.27
2023-01-08 05:17:00 - train.py[line:549] - INFO: 5200 / 6234
2023-01-08 05:17:00 - train.py[line:551] - INFO: load:1.58 valid_run:5458.22 task_valid:5276.92 collect_output:130.28
2023-01-08 05:20:28 - train.py[line:549] - INFO: 5400 / 6234
2023-01-08 05:20:28 - train.py[line:551] - INFO: load:1.61 valid_run:5665.91 task_valid:5476.99 collect_output:135.96
2023-01-08 05:23:59 - train.py[line:549] - INFO: 5600 / 6234
2023-01-08 05:23:59 - train.py[line:551] - INFO: load:1.63 valid_run:5877.10 task_valid:5684.15 collect_output:138.03
2023-01-08 05:27:29 - train.py[line:549] - INFO: 5800 / 6234
2023-01-08 05:27:29 - train.py[line:551] - INFO: load:1.66 valid_run:6087.52 task_valid:5886.36 collect_output:144.26
2023-01-08 05:31:01 - train.py[line:549] - INFO: 6000 / 6234
2023-01-08 05:31:01 - train.py[line:551] - INFO: load:1.69 valid_run:6298.60 task_valid:6092.05 collect_output:147.73
2023-01-08 05:34:30 - train.py[line:549] - INFO: 6200 / 6234
2023-01-08 05:34:30 - train.py[line:551] - INFO: load:1.71 valid_run:6508.29 task_valid:6297.69 collect_output:149.82

====================================================================================================
SGG eval:     R @ 50: 0.5151;     R @ 100: 0.5680;     R @ 500: 0.6209;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3006;    mR @ 100: 0.3749;    mR @ 500: 0.4263;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6415) (covered in:0.1875) (covering:0.5714) (eating:0.7059) (flying in:0.7273) (growing on:0.5000) (hanging from:0.4355) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6250) (playing:0.0000) (riding:0.7467) (says:0.0000) (sitting on:0.6939) (standing on:0.4050) (using:0.3500) (walking in:0.0000) (walking on:0.5676) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================

2023-01-08 05:35:16 - train.py[line:487] - INFO: 0.5679709956709956
2023-01-08 05:35:16 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.5151;     R @ 100: 0.5680;     R @ 500: 0.6209;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3006;    mR @ 100: 0.3749;    mR @ 500: 0.4263;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6415) (covered in:0.1875) (covering:0.5714) (eating:0.7059) (flying in:0.7273) (growing on:0.5000) (hanging from:0.4355) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6250) (playing:0.0000) (riding:0.7467) (says:0.0000) (sitting on:0.6939) (standing on:0.4050) (using:0.3500) (walking in:0.0000) (walking on:0.5676) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================

2023-01-08 05:35:16 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.317 | loss_v1 0 | loss_v2 0 | nll_loss 0.158 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.567971 | ppl 1.12 | vqa_score 0.3164 | wps 68.4 | wpb 72 | bsz 24 | num_updates 4000 | best_R@100 0.567971
2023-01-08 05:35:16 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2023-01-08 05:35:16 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_4000.pt
2023-01-08 05:35:55 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_4000.pt
2023-01-08 05:38:44 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.5679709956709956) (writing took 207.34079043380916 seconds)
2023-01-08 05:39:10 - progress_bar.py[line:274] - INFO: epoch 001:   4015 / 144806 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0318, wps=0.3, ups=0, wpb=87.1, bsz=32, num_updates=4010, lr=4.32765e-05, gnorm=0.855, clip=40, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=23965
2023-01-08 05:39:36 - progress_bar.py[line:274] - INFO: epoch 001:   4025 / 144806 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0311, wps=67.4, ups=0.39, wpb=86.8, bsz=32, num_updates=4020, lr=4.33844e-05, gnorm=0.839, clip=30, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=23991
2023-01-08 05:40:02 - progress_bar.py[line:274] - INFO: epoch 001:   4035 / 144806 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0385, wps=67.1, ups=0.39, wpb=86.1, bsz=32, num_updates=4030, lr=4.34923e-05, gnorm=0.816, clip=20, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=24017
2023-01-08 05:40:27 - progress_bar.py[line:274] - INFO: epoch 001:   4045 / 144806 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0137, wps=70.9, ups=0.4, wpb=88.1, bsz=32, num_updates=4040, lr=4.36003e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=24042
2023-01-08 05:40:53 - progress_bar.py[line:274] - INFO: epoch 001:   4055 / 144806 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0482, wps=68, ups=0.39, wpb=87.5, bsz=32, num_updates=4050, lr=4.37082e-05, gnorm=0.773, clip=10, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=24068
2023-01-08 05:41:18 - progress_bar.py[line:274] - INFO: epoch 001:   4065 / 144806 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0488, wps=68.2, ups=0.39, wpb=86.6, bsz=32, num_updates=4060, lr=4.38161e-05, gnorm=0.783, clip=20, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=24093
2023-01-08 05:41:44 - progress_bar.py[line:274] - INFO: epoch 001:   4075 / 144806 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.044, wps=69.3, ups=0.4, wpb=87.1, bsz=32, num_updates=4070, lr=4.3924e-05, gnorm=0.786, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=24119
2023-01-08 05:42:09 - progress_bar.py[line:274] - INFO: epoch 001:   4085 / 144806 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0613, wps=69.3, ups=0.4, wpb=87.5, bsz=32, num_updates=4080, lr=4.40319e-05, gnorm=0.765, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=24144
2023-01-08 05:42:34 - progress_bar.py[line:274] - INFO: epoch 001:   4095 / 144806 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0424, wps=69.9, ups=0.4, wpb=87, bsz=32, num_updates=4090, lr=4.41399e-05, gnorm=0.784, clip=30, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=24169
2023-01-08 05:43:00 - progress_bar.py[line:274] - INFO: epoch 001:   4105 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0298, wps=69.4, ups=0.4, wpb=87.4, bsz=32, num_updates=4100, lr=4.42478e-05, gnorm=0.865, clip=30, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=24195
2023-01-08 05:43:26 - progress_bar.py[line:274] - INFO: epoch 001:   4115 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0, wps=68, ups=0.39, wpb=87, bsz=32, num_updates=4110, lr=4.43557e-05, gnorm=0.793, clip=10, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=24221
2023-01-08 05:43:51 - progress_bar.py[line:274] - INFO: epoch 001:   4125 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0486, wps=70, ups=0.4, wpb=88.5, bsz=32, num_updates=4120, lr=4.44636e-05, gnorm=0.845, clip=30, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=24246
2023-01-08 05:44:18 - progress_bar.py[line:274] - INFO: epoch 001:   4135 / 144806 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0536, wps=65.7, ups=0.38, wpb=86, bsz=32, num_updates=4130, lr=4.45716e-05, gnorm=0.736, clip=10, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=24273
2023-01-08 05:44:44 - progress_bar.py[line:274] - INFO: epoch 001:   4145 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0327, wps=67.8, ups=0.39, wpb=87.1, bsz=32, num_updates=4140, lr=4.46795e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=24299
2023-01-08 05:45:09 - progress_bar.py[line:274] - INFO: epoch 001:   4155 / 144806 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=85.2, nsentences=32, sample_size=85.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0636, wps=66.5, ups=0.39, wpb=85.2, bsz=32, num_updates=4150, lr=4.47874e-05, gnorm=0.742, clip=10, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=24324
2023-01-08 05:45:35 - progress_bar.py[line:274] - INFO: epoch 001:   4165 / 144806 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=85.6, nsentences=32, sample_size=85.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0585, wps=66.6, ups=0.39, wpb=85.6, bsz=32, num_updates=4160, lr=4.48953e-05, gnorm=0.791, clip=20, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=24350
2023-01-08 05:46:01 - progress_bar.py[line:274] - INFO: epoch 001:   4175 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0411, wps=70.4, ups=0.4, wpb=88.6, bsz=32, num_updates=4170, lr=4.50032e-05, gnorm=0.861, clip=30, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=24376
2023-01-08 05:46:27 - progress_bar.py[line:274] - INFO: epoch 001:   4185 / 144806 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0537, wps=68.9, ups=0.39, wpb=87.9, bsz=32, num_updates=4180, lr=4.51112e-05, gnorm=0.782, clip=20, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=24402
2023-01-08 05:46:52 - progress_bar.py[line:274] - INFO: epoch 001:   4195 / 144806 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0347, wps=68.8, ups=0.4, wpb=86.9, bsz=32, num_updates=4190, lr=4.52191e-05, gnorm=0.927, clip=30, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=24427
2023-01-08 05:47:17 - progress_bar.py[line:274] - INFO: epoch 001:   4205 / 144806 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0368, wps=71, ups=0.41, wpb=87.4, bsz=32, num_updates=4200, lr=4.5327e-05, gnorm=0.706, clip=0, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=24452
2023-01-08 05:47:42 - progress_bar.py[line:274] - INFO: epoch 001:   4215 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0352, wps=69.6, ups=0.4, wpb=87.9, bsz=32, num_updates=4210, lr=4.54349e-05, gnorm=0.775, clip=20, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=24477
2023-01-08 05:48:08 - progress_bar.py[line:274] - INFO: epoch 001:   4225 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0946, wps=69.6, ups=0.4, wpb=88, bsz=32, num_updates=4220, lr=4.55428e-05, gnorm=0.723, clip=10, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=24503
2023-01-08 05:48:33 - progress_bar.py[line:274] - INFO: epoch 001:   4235 / 144806 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0377, wps=69, ups=0.39, wpb=87.4, bsz=32, num_updates=4230, lr=4.56508e-05, gnorm=0.692, clip=0, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=24529
2023-01-08 05:48:59 - progress_bar.py[line:274] - INFO: epoch 001:   4245 / 144806 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0385, wps=68.7, ups=0.4, wpb=86.9, bsz=32, num_updates=4240, lr=4.57587e-05, gnorm=0.715, clip=10, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=24554
2023-01-08 05:49:25 - progress_bar.py[line:274] - INFO: epoch 001:   4255 / 144806 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0412, wps=69.2, ups=0.39, wpb=88, bsz=32, num_updates=4250, lr=4.58666e-05, gnorm=0.801, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=24580
2023-01-08 05:49:51 - progress_bar.py[line:274] - INFO: epoch 001:   4265 / 144806 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0602, wps=67.1, ups=0.39, wpb=86.1, bsz=32, num_updates=4260, lr=4.59745e-05, gnorm=0.905, clip=40, loss_scale=512, train_wall=26, gb_free=14.9, ema_decay=0.9999, wall=24606
2023-01-08 05:50:16 - progress_bar.py[line:274] - INFO: epoch 001:   4275 / 144806 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.076, wps=68.1, ups=0.4, wpb=86.2, bsz=32, num_updates=4270, lr=4.60825e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=24631
2023-01-08 05:50:42 - progress_bar.py[line:274] - INFO: epoch 001:   4285 / 144806 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0649, wps=69.2, ups=0.39, wpb=87.8, bsz=32, num_updates=4280, lr=4.61904e-05, gnorm=0.831, clip=20, loss_scale=512, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=24657
2023-01-08 05:51:08 - progress_bar.py[line:274] - INFO: epoch 001:   4295 / 144806 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0414, wps=68.9, ups=0.4, wpb=86.8, bsz=32, num_updates=4290, lr=4.62983e-05, gnorm=0.694, clip=10, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=24683
2023-01-08 05:51:34 - progress_bar.py[line:274] - INFO: epoch 001:   4305 / 144806 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0298, wps=69.3, ups=0.4, wpb=87.5, bsz=32, num_updates=4300, lr=4.64062e-05, gnorm=0.72, clip=30, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=24708
2023-01-08 05:52:00 - progress_bar.py[line:274] - INFO: epoch 001:   4315 / 144806 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0437, wps=69, ups=0.39, wpb=87.7, bsz=32, num_updates=4310, lr=4.65141e-05, gnorm=0.783, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=24734
2023-01-08 05:52:25 - progress_bar.py[line:274] - INFO: epoch 001:   4325 / 144806 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=89.1, nsentences=32, sample_size=89.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0544, wps=70.6, ups=0.4, wpb=89.1, bsz=32, num_updates=4320, lr=4.66221e-05, gnorm=0.669, clip=10, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=24760
2023-01-08 05:52:51 - progress_bar.py[line:274] - INFO: epoch 001:   4335 / 144806 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0629, wps=69.6, ups=0.39, wpb=88.2, bsz=32, num_updates=4330, lr=4.673e-05, gnorm=0.715, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=24786
2023-01-08 05:53:17 - progress_bar.py[line:274] - INFO: epoch 001:   4345 / 144806 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0432, wps=68.4, ups=0.39, wpb=87.2, bsz=32, num_updates=4340, lr=4.68379e-05, gnorm=0.586, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=24812
2023-01-08 05:53:43 - progress_bar.py[line:274] - INFO: epoch 001:   4355 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0556, wps=69.9, ups=0.4, wpb=88, bsz=32, num_updates=4350, lr=4.69458e-05, gnorm=0.672, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=24838
2023-01-08 05:54:09 - progress_bar.py[line:274] - INFO: epoch 001:   4365 / 144806 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0811, wps=69.6, ups=0.4, wpb=86.9, bsz=32, num_updates=4360, lr=4.70537e-05, gnorm=0.769, clip=10, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=24863
2023-01-08 05:54:35 - progress_bar.py[line:274] - INFO: epoch 001:   4375 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0529, wps=68.4, ups=0.39, wpb=87.3, bsz=32, num_updates=4370, lr=4.71617e-05, gnorm=0.805, clip=20, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=24890
2023-01-08 05:55:01 - progress_bar.py[line:274] - INFO: epoch 001:   4385 / 144806 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0449, wps=67.8, ups=0.39, wpb=86.1, bsz=32, num_updates=4380, lr=4.72696e-05, gnorm=0.822, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=24915
2023-01-08 05:55:27 - progress_bar.py[line:274] - INFO: epoch 001:   4395 / 144806 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0226, wps=68, ups=0.39, wpb=86.2, bsz=32, num_updates=4390, lr=4.73775e-05, gnorm=0.703, clip=10, loss_scale=512, train_wall=25, gb_free=14.8, ema_decay=0.9999, wall=24941
2023-01-08 05:55:53 - progress_bar.py[line:274] - INFO: epoch 001:   4405 / 144806 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.038, wps=67.3, ups=0.38, wpb=87.9, bsz=32, num_updates=4400, lr=4.74854e-05, gnorm=0.677, clip=0, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=24968
2023-01-08 05:56:19 - progress_bar.py[line:274] - INFO: epoch 001:   4415 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0595, wps=68.2, ups=0.39, wpb=86.4, bsz=32, num_updates=4410, lr=4.75934e-05, gnorm=0.77, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=24994
2023-01-08 05:56:45 - progress_bar.py[line:274] - INFO: epoch 001:   4425 / 144806 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0402, wps=67.9, ups=0.39, wpb=86.9, bsz=32, num_updates=4420, lr=4.77013e-05, gnorm=0.762, clip=0, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=25020
2023-01-08 05:57:11 - progress_bar.py[line:274] - INFO: epoch 001:   4435 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0671, wps=69.1, ups=0.39, wpb=88.1, bsz=32, num_updates=4430, lr=4.78092e-05, gnorm=0.782, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=25046
2023-01-08 05:57:38 - progress_bar.py[line:274] - INFO: epoch 001:   4445 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0458, wps=68, ups=0.39, wpb=87.5, bsz=32, num_updates=4440, lr=4.79171e-05, gnorm=0.775, clip=0, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=25072
2023-01-08 05:58:04 - progress_bar.py[line:274] - INFO: epoch 001:   4455 / 144806 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0592, wps=69.6, ups=0.39, wpb=88.4, bsz=32, num_updates=4450, lr=4.8025e-05, gnorm=0.667, clip=0, loss_scale=1024, train_wall=25, gb_free=15, ema_decay=0.9999, wall=25098
2023-01-08 05:58:30 - progress_bar.py[line:274] - INFO: epoch 001:   4465 / 144806 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0862, wps=67.8, ups=0.39, wpb=86.6, bsz=32, num_updates=4460, lr=4.8133e-05, gnorm=0.683, clip=0, loss_scale=1024, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=25124
2023-01-08 05:58:56 - progress_bar.py[line:274] - INFO: epoch 001:   4475 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0539, wps=68, ups=0.39, wpb=86.7, bsz=32, num_updates=4470, lr=4.82409e-05, gnorm=0.813, clip=30, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=25151
2023-01-08 05:59:22 - progress_bar.py[line:274] - INFO: epoch 001:   4485 / 144806 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0544, wps=68.9, ups=0.39, wpb=87.2, bsz=32, num_updates=4480, lr=4.83488e-05, gnorm=0.728, clip=0, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=25176
2023-01-08 05:59:48 - progress_bar.py[line:274] - INFO: epoch 001:   4495 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0539, wps=68, ups=0.39, wpb=87, bsz=32, num_updates=4490, lr=4.84567e-05, gnorm=0.676, clip=0, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=25202
2023-01-08 06:00:14 - progress_bar.py[line:274] - INFO: epoch 001:   4505 / 144806 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0526, wps=68.2, ups=0.39, wpb=87.6, bsz=32, num_updates=4500, lr=4.85646e-05, gnorm=0.726, clip=10, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=25229
2023-01-08 06:00:39 - progress_bar.py[line:274] - INFO: epoch 001:   4515 / 144806 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0491, wps=70.5, ups=0.4, wpb=87.8, bsz=32, num_updates=4510, lr=4.86726e-05, gnorm=0.701, clip=0, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=25254
2023-01-08 06:01:06 - progress_bar.py[line:274] - INFO: epoch 001:   4525 / 144806 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0513, wps=68.1, ups=0.39, wpb=87.8, bsz=32, num_updates=4520, lr=4.87805e-05, gnorm=0.768, clip=20, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=25280
2023-01-08 06:01:33 - progress_bar.py[line:274] - INFO: epoch 001:   4535 / 144806 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0679, wps=67.4, ups=0.39, wpb=87, bsz=32, num_updates=4530, lr=4.88884e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=25307
2023-01-08 06:01:59 - progress_bar.py[line:274] - INFO: epoch 001:   4545 / 144806 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0432, wps=67.9, ups=0.39, wpb=86.4, bsz=32, num_updates=4540, lr=4.89963e-05, gnorm=0.659, clip=0, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=25333
2023-01-08 06:02:25 - progress_bar.py[line:274] - INFO: epoch 001:   4555 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0461, wps=67.8, ups=0.39, wpb=86.7, bsz=32, num_updates=4550, lr=4.91043e-05, gnorm=0.701, clip=10, loss_scale=1024, train_wall=26, gb_free=15, ema_decay=0.9999, wall=25359
2023-01-08 06:02:51 - progress_bar.py[line:274] - INFO: epoch 001:   4565 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0667, wps=67.1, ups=0.39, wpb=86.9, bsz=32, num_updates=4560, lr=4.92122e-05, gnorm=0.661, clip=20, loss_scale=1024, train_wall=26, gb_free=14.9, ema_decay=0.9999, wall=25386
2023-01-08 06:03:17 - progress_bar.py[line:274] - INFO: epoch 001:   4575 / 144806 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0301, wps=68.7, ups=0.39, wpb=87, bsz=32, num_updates=4570, lr=4.93201e-05, gnorm=0.627, clip=10, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=25412
2023-01-08 06:03:43 - progress_bar.py[line:274] - INFO: epoch 001:   4585 / 144806 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0596, wps=69.4, ups=0.39, wpb=88.6, bsz=32, num_updates=4580, lr=4.9428e-05, gnorm=0.726, clip=10, loss_scale=1024, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=25438
2023-01-08 06:04:08 - progress_bar.py[line:274] - INFO: epoch 001:   4595 / 144806 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0375, wps=67.9, ups=0.39, wpb=87.2, bsz=32, num_updates=4590, lr=4.95359e-05, gnorm=0.746, clip=20, loss_scale=1024, train_wall=26, gb_free=15, ema_decay=0.9999, wall=25464
2023-01-08 06:04:34 - progress_bar.py[line:274] - INFO: epoch 001:   4605 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0549, wps=68.6, ups=0.39, wpb=88, bsz=32, num_updates=4600, lr=4.96439e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=25489
2023-01-08 06:04:59 - progress_bar.py[line:274] - INFO: epoch 001:   4615 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0476, wps=70.8, ups=0.4, wpb=88, bsz=32, num_updates=4610, lr=4.97518e-05, gnorm=0.676, clip=10, loss_scale=1024, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=25515
2023-01-08 06:05:25 - progress_bar.py[line:274] - INFO: epoch 001:   4625 / 144806 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0366, wps=68.7, ups=0.39, wpb=87.6, bsz=32, num_updates=4620, lr=4.98597e-05, gnorm=0.668, clip=0, loss_scale=1024, train_wall=25, gb_free=14.8, ema_decay=0.9999, wall=25540
2023-01-08 06:05:51 - progress_bar.py[line:274] - INFO: epoch 001:   4635 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0355, wps=69.3, ups=0.4, wpb=87.7, bsz=32, num_updates=4630, lr=4.99676e-05, gnorm=0.736, clip=10, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=25566
2023-01-08 06:06:16 - progress_bar.py[line:274] - INFO: epoch 001:   4645 / 144806 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0387, wps=70, ups=0.4, wpb=88, bsz=32, num_updates=4640, lr=4.99975e-05, gnorm=0.768, clip=0, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=25591
2023-01-08 06:06:42 - progress_bar.py[line:274] - INFO: epoch 001:   4655 / 144806 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0464, wps=69.2, ups=0.4, wpb=87.5, bsz=32, num_updates=4650, lr=4.99939e-05, gnorm=0.653, clip=10, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=25617
2023-01-08 06:07:08 - progress_bar.py[line:274] - INFO: epoch 001:   4665 / 144806 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0701, wps=68.6, ups=0.39, wpb=88.4, bsz=32, num_updates=4660, lr=4.99904e-05, gnorm=0.631, clip=10, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=25643
2023-01-08 06:07:33 - progress_bar.py[line:274] - INFO: epoch 001:   4675 / 144806 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=85.6, nsentences=32, sample_size=85.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0678, wps=67.8, ups=0.4, wpb=85.6, bsz=32, num_updates=4670, lr=4.99868e-05, gnorm=0.656, clip=0, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=25668
2023-01-08 06:07:59 - progress_bar.py[line:274] - INFO: epoch 001:   4685 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0584, wps=68.3, ups=0.39, wpb=87.1, bsz=32, num_updates=4680, lr=4.99832e-05, gnorm=0.532, clip=0, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=25694
2023-01-08 06:08:25 - progress_bar.py[line:274] - INFO: epoch 001:   4695 / 144806 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0423, wps=68.8, ups=0.39, wpb=87.7, bsz=32, num_updates=4690, lr=4.99797e-05, gnorm=0.872, clip=30, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=25720
2023-01-08 06:08:50 - progress_bar.py[line:274] - INFO: epoch 001:   4705 / 144806 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0675, wps=68.8, ups=0.39, wpb=87.2, bsz=32, num_updates=4700, lr=4.99761e-05, gnorm=0.588, clip=0, loss_scale=1024, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=25745
2023-01-08 06:09:15 - progress_bar.py[line:274] - INFO: epoch 001:   4715 / 144806 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0588, wps=69.1, ups=0.4, wpb=86.2, bsz=32, num_updates=4710, lr=4.99725e-05, gnorm=0.693, clip=10, loss_scale=1024, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=25770
2023-01-08 06:09:42 - progress_bar.py[line:274] - INFO: epoch 001:   4725 / 144806 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0705, wps=67.7, ups=0.38, wpb=88.3, bsz=32, num_updates=4720, lr=4.9969e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=25797
2023-01-08 06:10:07 - progress_bar.py[line:274] - INFO: epoch 001:   4735 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0467, wps=69.4, ups=0.4, wpb=87.9, bsz=32, num_updates=4730, lr=4.99654e-05, gnorm=0.648, clip=10, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=25822
2023-01-08 06:10:33 - progress_bar.py[line:274] - INFO: epoch 001:   4745 / 144806 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0476, wps=67.1, ups=0.39, wpb=86.3, bsz=32, num_updates=4740, lr=4.99618e-05, gnorm=0.631, clip=0, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=25848
2023-01-08 06:10:59 - progress_bar.py[line:274] - INFO: epoch 001:   4755 / 144806 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.038, wps=67.7, ups=0.39, wpb=87.3, bsz=32, num_updates=4750, lr=4.99583e-05, gnorm=0.776, clip=20, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=25874
2023-01-08 06:11:09 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 06:11:27 - progress_bar.py[line:274] - INFO: epoch 001:   4766 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.333, nsentences=32, sample_size=86.333, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0349, wps=65, ups=0.36, wpb=86.3, bsz=32, num_updates=4760, lr=4.99547e-05, gnorm=0.754, clip=20, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=25902
2023-01-08 06:11:53 - progress_bar.py[line:274] - INFO: epoch 001:   4776 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.04, wps=68.7, ups=0.39, wpb=88.2, bsz=32, num_updates=4770, lr=4.99511e-05, gnorm=0.595, clip=0, loss_scale=512, train_wall=26, gb_free=15, ema_decay=0.9999, wall=25928
2023-01-08 06:12:19 - progress_bar.py[line:274] - INFO: epoch 001:   4786 / 144806 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0714, wps=67.4, ups=0.39, wpb=86.2, bsz=32, num_updates=4780, lr=4.99476e-05, gnorm=0.78, clip=10, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=25954
2023-01-08 06:12:45 - progress_bar.py[line:274] - INFO: epoch 001:   4796 / 144806 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0389, wps=67.6, ups=0.39, wpb=85.9, bsz=32, num_updates=4790, lr=4.9944e-05, gnorm=0.762, clip=20, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=25980
2023-01-08 06:13:10 - progress_bar.py[line:274] - INFO: epoch 001:   4806 / 144806 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0844, wps=69, ups=0.4, wpb=87.2, bsz=32, num_updates=4800, lr=4.99404e-05, gnorm=0.681, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=26005
2023-01-08 06:13:36 - progress_bar.py[line:274] - INFO: epoch 001:   4816 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0449, wps=69.5, ups=0.4, wpb=87.2, bsz=32, num_updates=4810, lr=4.99369e-05, gnorm=0.558, clip=0, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=26031
2023-01-08 06:14:01 - progress_bar.py[line:274] - INFO: epoch 001:   4826 / 144806 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0314, wps=69.2, ups=0.4, wpb=86.7, bsz=32, num_updates=4820, lr=4.99333e-05, gnorm=0.538, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=26056
2023-01-08 06:14:27 - progress_bar.py[line:274] - INFO: epoch 001:   4836 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0552, wps=68.5, ups=0.39, wpb=86.8, bsz=32, num_updates=4830, lr=4.99297e-05, gnorm=0.63, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=26082
2023-01-08 06:14:52 - progress_bar.py[line:274] - INFO: epoch 001:   4846 / 144806 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0774, wps=68.5, ups=0.4, wpb=86.2, bsz=32, num_updates=4840, lr=4.99262e-05, gnorm=0.685, clip=10, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=26107
2023-01-08 06:15:17 - progress_bar.py[line:274] - INFO: epoch 001:   4856 / 144806 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0541, wps=69.7, ups=0.4, wpb=87.9, bsz=32, num_updates=4850, lr=4.99226e-05, gnorm=0.678, clip=0, loss_scale=512, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=26133
2023-01-08 06:15:43 - progress_bar.py[line:274] - INFO: epoch 001:   4866 / 144806 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=85.1, nsentences=32, sample_size=85.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0573, wps=67, ups=0.39, wpb=85.1, bsz=32, num_updates=4860, lr=4.9919e-05, gnorm=0.765, clip=10, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=26158
2023-01-08 06:16:09 - progress_bar.py[line:274] - INFO: epoch 001:   4876 / 144806 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0066, wps=69.1, ups=0.39, wpb=88.1, bsz=32, num_updates=4870, lr=4.99155e-05, gnorm=0.772, clip=20, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=26184
2023-01-08 06:16:34 - progress_bar.py[line:274] - INFO: epoch 001:   4886 / 144806 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0298, wps=69.2, ups=0.4, wpb=86.9, bsz=32, num_updates=4880, lr=4.99119e-05, gnorm=0.645, clip=0, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=26209
2023-01-08 06:17:00 - progress_bar.py[line:274] - INFO: epoch 001:   4896 / 144806 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0592, wps=67.2, ups=0.39, wpb=87, bsz=32, num_updates=4890, lr=4.99083e-05, gnorm=0.561, clip=0, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=26235
2023-01-08 06:17:26 - progress_bar.py[line:274] - INFO: epoch 001:   4906 / 144806 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0701, wps=69.4, ups=0.4, wpb=87.3, bsz=32, num_updates=4900, lr=4.99048e-05, gnorm=0.716, clip=10, loss_scale=512, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=26261
2023-01-08 06:17:51 - progress_bar.py[line:274] - INFO: epoch 001:   4916 / 144806 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0769, wps=69.3, ups=0.4, wpb=87.2, bsz=32, num_updates=4910, lr=4.99012e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=26286
2023-01-08 06:18:17 - progress_bar.py[line:274] - INFO: epoch 001:   4926 / 144806 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.06, wps=67.3, ups=0.39, wpb=86.3, bsz=32, num_updates=4920, lr=4.98976e-05, gnorm=0.645, clip=0, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=26312
2023-01-08 06:18:43 - progress_bar.py[line:274] - INFO: epoch 001:   4936 / 144806 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=89.6, nsentences=32, sample_size=89.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0397, wps=69.7, ups=0.39, wpb=89.6, bsz=32, num_updates=4930, lr=4.98941e-05, gnorm=0.658, clip=0, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=26338
2023-01-08 06:19:09 - progress_bar.py[line:274] - INFO: epoch 001:   4946 / 144806 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0613, wps=68.8, ups=0.39, wpb=88.4, bsz=32, num_updates=4940, lr=4.98905e-05, gnorm=0.649, clip=0, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=26364
2023-01-08 06:19:35 - progress_bar.py[line:274] - INFO: epoch 001:   4956 / 144806 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0774, wps=68.6, ups=0.39, wpb=88.1, bsz=32, num_updates=4950, lr=4.98869e-05, gnorm=0.722, clip=10, loss_scale=512, train_wall=26, gb_free=15, ema_decay=0.9999, wall=26390
2023-01-08 06:20:01 - progress_bar.py[line:274] - INFO: epoch 001:   4966 / 144806 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0886, wps=68.1, ups=0.39, wpb=86.8, bsz=32, num_updates=4960, lr=4.98834e-05, gnorm=0.664, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=26416
2023-01-08 06:20:27 - progress_bar.py[line:274] - INFO: epoch 001:   4976 / 144806 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0629, wps=67.8, ups=0.39, wpb=87.3, bsz=32, num_updates=4970, lr=4.98798e-05, gnorm=0.665, clip=0, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=26442
2023-01-08 06:20:53 - progress_bar.py[line:274] - INFO: epoch 001:   4986 / 144806 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0526, wps=68.7, ups=0.39, wpb=88.4, bsz=32, num_updates=4980, lr=4.98762e-05, gnorm=0.549, clip=0, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=26468
2023-01-08 06:21:18 - progress_bar.py[line:274] - INFO: epoch 001:   4996 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.071, wps=68.5, ups=0.39, wpb=87.3, bsz=32, num_updates=4990, lr=4.98727e-05, gnorm=0.609, clip=0, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=26493
2023-01-08 06:21:44 - progress_bar.py[line:274] - INFO: epoch 001:   5006 / 144806 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0617, wps=68.9, ups=0.39, wpb=88, bsz=32, num_updates=5000, lr=4.98691e-05, gnorm=0.685, clip=20, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=26519
2023-01-08 06:22:10 - progress_bar.py[line:274] - INFO: epoch 001:   5016 / 144806 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0517, wps=67.5, ups=0.39, wpb=86.8, bsz=32, num_updates=5010, lr=4.98655e-05, gnorm=0.728, clip=10, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=26545
2023-01-08 06:22:36 - progress_bar.py[line:274] - INFO: epoch 001:   5026 / 144806 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0355, wps=67.9, ups=0.39, wpb=87.1, bsz=32, num_updates=5020, lr=4.9862e-05, gnorm=0.693, clip=10, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=26571
2023-01-08 06:23:02 - progress_bar.py[line:274] - INFO: epoch 001:   5036 / 144806 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0187, wps=69, ups=0.4, wpb=87.3, bsz=32, num_updates=5030, lr=4.98584e-05, gnorm=0.852, clip=20, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=26597
2023-01-08 06:23:27 - progress_bar.py[line:274] - INFO: epoch 001:   5046 / 144806 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0701, wps=69.3, ups=0.39, wpb=87.8, bsz=32, num_updates=5040, lr=4.98548e-05, gnorm=0.567, clip=0, loss_scale=512, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=26622
2023-01-08 06:23:53 - progress_bar.py[line:274] - INFO: epoch 001:   5056 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0872, wps=67.9, ups=0.39, wpb=86.5, bsz=32, num_updates=5050, lr=4.98513e-05, gnorm=0.689, clip=0, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=26648
2023-01-08 06:24:19 - progress_bar.py[line:274] - INFO: epoch 001:   5066 / 144806 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.05, wps=68.2, ups=0.39, wpb=87.3, bsz=32, num_updates=5060, lr=4.98477e-05, gnorm=0.687, clip=20, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=26674
2023-01-08 06:24:45 - progress_bar.py[line:274] - INFO: epoch 001:   5076 / 144806 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0471, wps=67.6, ups=0.39, wpb=86.5, bsz=32, num_updates=5070, lr=4.98441e-05, gnorm=0.683, clip=10, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=26700
2023-01-08 06:25:10 - progress_bar.py[line:274] - INFO: epoch 001:   5086 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0662, wps=69.5, ups=0.4, wpb=87.8, bsz=32, num_updates=5080, lr=4.98406e-05, gnorm=0.645, clip=10, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=26725
2023-01-08 06:25:36 - progress_bar.py[line:274] - INFO: epoch 001:   5096 / 144806 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.1018, wps=69.2, ups=0.39, wpb=88, bsz=32, num_updates=5090, lr=4.9837e-05, gnorm=0.756, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=26751
2023-01-08 06:26:02 - progress_bar.py[line:274] - INFO: epoch 001:   5106 / 144806 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0795, wps=68.3, ups=0.39, wpb=87.2, bsz=32, num_updates=5100, lr=4.98334e-05, gnorm=0.569, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=26777
2023-01-08 06:26:28 - progress_bar.py[line:274] - INFO: epoch 001:   5116 / 144806 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0526, wps=68.1, ups=0.39, wpb=87.7, bsz=32, num_updates=5110, lr=4.98299e-05, gnorm=0.655, clip=10, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=26803
2023-01-08 06:26:53 - progress_bar.py[line:274] - INFO: epoch 001:   5126 / 144806 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0641, wps=69.3, ups=0.4, wpb=86.5, bsz=32, num_updates=5120, lr=4.98263e-05, gnorm=0.655, clip=10, loss_scale=512, train_wall=25, gb_free=14.7, ema_decay=0.9999, wall=26828
2023-01-08 06:27:19 - progress_bar.py[line:274] - INFO: epoch 001:   5136 / 144806 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0556, wps=68.4, ups=0.39, wpb=87.6, bsz=32, num_updates=5130, lr=4.98227e-05, gnorm=0.613, clip=0, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=26854
2023-01-08 06:27:45 - progress_bar.py[line:274] - INFO: epoch 001:   5146 / 144806 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0645, wps=68.8, ups=0.39, wpb=87.8, bsz=32, num_updates=5140, lr=4.98192e-05, gnorm=0.654, clip=0, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=26880
2023-01-08 06:28:10 - progress_bar.py[line:274] - INFO: epoch 001:   5156 / 144806 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.117, wps=68.6, ups=0.4, wpb=86.4, bsz=32, num_updates=5150, lr=4.98156e-05, gnorm=0.684, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=26905
2023-01-08 06:28:36 - progress_bar.py[line:274] - INFO: epoch 001:   5166 / 144806 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0323, wps=69.6, ups=0.39, wpb=88.2, bsz=32, num_updates=5160, lr=4.9812e-05, gnorm=0.722, clip=30, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=26931
2023-01-08 06:29:02 - progress_bar.py[line:274] - INFO: epoch 001:   5176 / 144806 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0936, wps=68.6, ups=0.39, wpb=87.6, bsz=32, num_updates=5170, lr=4.98085e-05, gnorm=0.636, clip=10, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=26957
2023-01-08 06:29:28 - progress_bar.py[line:274] - INFO: epoch 001:   5186 / 144806 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0584, wps=68, ups=0.39, wpb=88, bsz=32, num_updates=5180, lr=4.98049e-05, gnorm=0.643, clip=0, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=26983
2023-01-08 06:29:54 - progress_bar.py[line:274] - INFO: epoch 001:   5196 / 144806 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0977, wps=67.1, ups=0.39, wpb=86.2, bsz=32, num_updates=5190, lr=4.98013e-05, gnorm=0.588, clip=10, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=27009
2023-01-08 06:30:20 - progress_bar.py[line:274] - INFO: epoch 001:   5206 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0417, wps=67.6, ups=0.39, wpb=86.7, bsz=32, num_updates=5200, lr=4.97977e-05, gnorm=0.56, clip=0, loss_scale=512, train_wall=26, gb_free=14.8, ema_decay=0.9999, wall=27035
2023-01-08 06:30:46 - progress_bar.py[line:274] - INFO: epoch 001:   5216 / 144806 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.044, wps=68.4, ups=0.39, wpb=88.1, bsz=32, num_updates=5210, lr=4.97942e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=26, gb_free=15, ema_decay=0.9999, wall=27061
2023-01-08 06:31:12 - progress_bar.py[line:274] - INFO: epoch 001:   5226 / 144806 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0724, wps=68.2, ups=0.39, wpb=87.9, bsz=32, num_updates=5220, lr=4.97906e-05, gnorm=0.694, clip=20, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=27087
2023-01-08 06:31:37 - progress_bar.py[line:274] - INFO: epoch 001:   5236 / 144806 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0705, wps=68.8, ups=0.4, wpb=86.4, bsz=32, num_updates=5230, lr=4.9787e-05, gnorm=0.663, clip=0, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=27112
2023-01-08 06:32:03 - progress_bar.py[line:274] - INFO: epoch 001:   5246 / 144806 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0705, wps=68, ups=0.39, wpb=86.6, bsz=32, num_updates=5240, lr=4.97835e-05, gnorm=0.66, clip=0, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=27138
2023-01-08 06:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   5256 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0641, wps=69.7, ups=0.4, wpb=87.3, bsz=32, num_updates=5250, lr=4.97799e-05, gnorm=0.642, clip=0, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=27163
2023-01-08 06:32:54 - progress_bar.py[line:274] - INFO: epoch 001:   5266 / 144806 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0802, wps=69.1, ups=0.4, wpb=87, bsz=32, num_updates=5260, lr=4.97763e-05, gnorm=0.577, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=27189
2023-01-08 06:33:19 - progress_bar.py[line:274] - INFO: epoch 001:   5276 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0667, wps=68.9, ups=0.4, wpb=86.3, bsz=32, num_updates=5270, lr=4.97728e-05, gnorm=0.645, clip=10, loss_scale=1024, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=27214
2023-01-08 06:33:45 - progress_bar.py[line:274] - INFO: epoch 001:   5286 / 144806 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0943, wps=68.7, ups=0.39, wpb=87.5, bsz=32, num_updates=5280, lr=4.97692e-05, gnorm=0.662, clip=10, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=27240
2023-01-08 06:34:10 - progress_bar.py[line:274] - INFO: epoch 001:   5296 / 144806 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0526, wps=68.2, ups=0.39, wpb=86.4, bsz=32, num_updates=5290, lr=4.97656e-05, gnorm=0.64, clip=10, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=27266
2023-01-08 06:34:36 - progress_bar.py[line:274] - INFO: epoch 001:   5306 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0659, wps=67.1, ups=0.39, wpb=86.3, bsz=32, num_updates=5300, lr=4.97621e-05, gnorm=0.719, clip=0, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=27291
2023-01-08 06:35:02 - progress_bar.py[line:274] - INFO: epoch 001:   5316 / 144806 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.097, wps=69.7, ups=0.4, wpb=87.7, bsz=32, num_updates=5310, lr=4.97585e-05, gnorm=0.701, clip=0, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=27317
2023-01-08 06:35:28 - progress_bar.py[line:274] - INFO: epoch 001:   5326 / 144806 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0774, wps=67.5, ups=0.39, wpb=86.2, bsz=32, num_updates=5320, lr=4.97549e-05, gnorm=0.642, clip=0, loss_scale=1024, train_wall=26, gb_free=15.5, ema_decay=0.9999, wall=27343
2023-01-08 06:35:53 - progress_bar.py[line:274] - INFO: epoch 001:   5336 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0833, wps=68.2, ups=0.39, wpb=87.1, bsz=32, num_updates=5330, lr=4.97514e-05, gnorm=0.698, clip=10, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=27369
2023-01-08 06:36:19 - progress_bar.py[line:274] - INFO: epoch 001:   5346 / 144806 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1018, wps=68.1, ups=0.39, wpb=86.2, bsz=32, num_updates=5340, lr=4.97478e-05, gnorm=0.636, clip=0, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=27394
2023-01-08 06:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   5356 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0802, wps=68.3, ups=0.39, wpb=87.9, bsz=32, num_updates=5350, lr=4.97442e-05, gnorm=0.703, clip=10, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=27420
2023-01-08 06:37:11 - progress_bar.py[line:274] - INFO: epoch 001:   5366 / 144806 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0848, wps=68, ups=0.39, wpb=86.6, bsz=32, num_updates=5360, lr=4.97407e-05, gnorm=0.643, clip=0, loss_scale=1024, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=27446
2023-01-08 06:37:36 - progress_bar.py[line:274] - INFO: epoch 001:   5376 / 144806 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0783, wps=68.5, ups=0.39, wpb=86.9, bsz=32, num_updates=5370, lr=4.97371e-05, gnorm=0.585, clip=0, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=27471
2023-01-08 06:38:02 - progress_bar.py[line:274] - INFO: epoch 001:   5386 / 144806 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0513, wps=69.9, ups=0.4, wpb=87.6, bsz=32, num_updates=5380, lr=4.97335e-05, gnorm=0.651, clip=20, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=27497
2023-01-08 06:38:27 - progress_bar.py[line:274] - INFO: epoch 001:   5396 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0584, wps=68.2, ups=0.39, wpb=87.1, bsz=32, num_updates=5390, lr=4.973e-05, gnorm=0.665, clip=0, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=27522
2023-01-08 06:38:53 - progress_bar.py[line:274] - INFO: epoch 001:   5406 / 144806 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0962, wps=69.6, ups=0.4, wpb=87.5, bsz=32, num_updates=5400, lr=4.97264e-05, gnorm=0.586, clip=0, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=27548
2023-01-08 06:39:18 - progress_bar.py[line:274] - INFO: epoch 001:   5416 / 144806 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0748, wps=68.9, ups=0.39, wpb=87.7, bsz=32, num_updates=5410, lr=4.97228e-05, gnorm=0.627, clip=10, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=27574
2023-01-08 06:39:44 - progress_bar.py[line:274] - INFO: epoch 001:   5426 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0656, wps=67.3, ups=0.39, wpb=86.6, bsz=32, num_updates=5420, lr=4.97193e-05, gnorm=0.711, clip=10, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=27599
2023-01-08 06:40:11 - progress_bar.py[line:274] - INFO: epoch 001:   5436 / 144806 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0299, wps=67.6, ups=0.39, wpb=87.4, bsz=32, num_updates=5430, lr=4.97157e-05, gnorm=0.694, clip=0, loss_scale=1024, train_wall=26, gb_free=15.5, ema_decay=0.9999, wall=27626
2023-01-08 06:40:36 - progress_bar.py[line:274] - INFO: epoch 001:   5446 / 144806 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0839, wps=69.7, ups=0.4, wpb=87.8, bsz=32, num_updates=5440, lr=4.97121e-05, gnorm=0.575, clip=0, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=27651
2023-01-08 06:41:02 - progress_bar.py[line:274] - INFO: epoch 001:   5456 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0679, wps=68, ups=0.39, wpb=86.3, bsz=32, num_updates=5450, lr=4.97086e-05, gnorm=0.68, clip=10, loss_scale=1024, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=27677
2023-01-08 06:41:26 - progress_bar.py[line:274] - INFO: epoch 001:   5466 / 144806 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0414, wps=71.8, ups=0.41, wpb=88.3, bsz=32, num_updates=5460, lr=4.9705e-05, gnorm=0.697, clip=10, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=27701
2023-01-08 06:41:51 - progress_bar.py[line:274] - INFO: epoch 001:   5476 / 144806 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0886, wps=70.9, ups=0.4, wpb=87.5, bsz=32, num_updates=5470, lr=4.97014e-05, gnorm=0.586, clip=0, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=27726
2023-01-08 06:42:16 - progress_bar.py[line:274] - INFO: epoch 001:   5486 / 144806 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0701, wps=71.2, ups=0.41, wpb=87.8, bsz=32, num_updates=5480, lr=4.96979e-05, gnorm=0.649, clip=0, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=27751
2023-01-08 06:42:42 - progress_bar.py[line:274] - INFO: epoch 001:   5496 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0701, wps=68.3, ups=0.39, wpb=87.4, bsz=32, num_updates=5490, lr=4.96943e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=27777
2023-01-08 06:43:08 - progress_bar.py[line:274] - INFO: epoch 001:   5506 / 144806 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0875, wps=67.1, ups=0.39, wpb=86.4, bsz=32, num_updates=5500, lr=4.96907e-05, gnorm=0.588, clip=0, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=27803
2023-01-08 06:43:34 - progress_bar.py[line:274] - INFO: epoch 001:   5516 / 144806 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0482, wps=67.2, ups=0.39, wpb=86.2, bsz=32, num_updates=5510, lr=4.96872e-05, gnorm=0.678, clip=10, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=27829
2023-01-08 06:44:00 - progress_bar.py[line:274] - INFO: epoch 001:   5526 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0485, wps=67.5, ups=0.39, wpb=86, bsz=32, num_updates=5520, lr=4.96836e-05, gnorm=0.514, clip=0, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=27855
2023-01-08 06:44:25 - progress_bar.py[line:274] - INFO: epoch 001:   5536 / 144806 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0988, wps=69.3, ups=0.39, wpb=87.8, bsz=32, num_updates=5530, lr=4.968e-05, gnorm=0.618, clip=0, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=27880
2023-01-08 06:44:51 - progress_bar.py[line:274] - INFO: epoch 001:   5546 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0633, wps=68.1, ups=0.39, wpb=86.3, bsz=32, num_updates=5540, lr=4.96765e-05, gnorm=0.741, clip=10, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=27906
2023-01-08 06:45:17 - progress_bar.py[line:274] - INFO: epoch 001:   5556 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0637, wps=67, ups=0.39, wpb=86.8, bsz=32, num_updates=5550, lr=4.96729e-05, gnorm=0.715, clip=10, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=27932
2023-01-08 06:45:43 - progress_bar.py[line:274] - INFO: epoch 001:   5566 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0588, wps=67.8, ups=0.39, wpb=87.2, bsz=32, num_updates=5560, lr=4.96693e-05, gnorm=0.695, clip=10, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=27958
2023-01-08 06:46:09 - progress_bar.py[line:274] - INFO: epoch 001:   5576 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0556, wps=68.3, ups=0.39, wpb=87.3, bsz=32, num_updates=5570, lr=4.96658e-05, gnorm=0.71, clip=0, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=27984
2023-01-08 06:46:35 - progress_bar.py[line:274] - INFO: epoch 001:   5586 / 144806 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0719, wps=67.7, ups=0.39, wpb=87.8, bsz=32, num_updates=5580, lr=4.96622e-05, gnorm=0.547, clip=0, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=28010
2023-01-08 06:47:01 - progress_bar.py[line:274] - INFO: epoch 001:   5596 / 144806 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=85.4, nsentences=32, sample_size=85.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0723, wps=66.9, ups=0.39, wpb=85.4, bsz=32, num_updates=5590, lr=4.96586e-05, gnorm=0.69, clip=0, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=28036
2023-01-08 06:47:27 - progress_bar.py[line:274] - INFO: epoch 001:   5606 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0818, wps=68.1, ups=0.39, wpb=87.1, bsz=32, num_updates=5600, lr=4.96551e-05, gnorm=0.581, clip=0, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=28062
2023-01-08 06:47:52 - progress_bar.py[line:274] - INFO: epoch 001:   5616 / 144806 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0813, wps=69.6, ups=0.4, wpb=88, bsz=32, num_updates=5610, lr=4.96515e-05, gnorm=0.605, clip=0, loss_scale=1024, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=28087
2023-01-08 06:48:18 - progress_bar.py[line:274] - INFO: epoch 001:   5626 / 144806 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0588, wps=69, ups=0.39, wpb=88.1, bsz=32, num_updates=5620, lr=4.96479e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=28113
2023-01-08 06:48:44 - progress_bar.py[line:274] - INFO: epoch 001:   5636 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0798, wps=68.5, ups=0.4, wpb=86.6, bsz=32, num_updates=5630, lr=4.96444e-05, gnorm=0.596, clip=0, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=28139
2023-01-08 06:49:09 - progress_bar.py[line:274] - INFO: epoch 001:   5646 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.7, nsentences=32, sample_size=85.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1145, wps=67, ups=0.39, wpb=85.7, bsz=32, num_updates=5640, lr=4.96408e-05, gnorm=0.811, clip=30, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=28164
2023-01-08 06:49:35 - progress_bar.py[line:274] - INFO: epoch 001:   5656 / 144806 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0549, wps=68.5, ups=0.39, wpb=86.7, bsz=32, num_updates=5650, lr=4.96372e-05, gnorm=0.509, clip=0, loss_scale=1024, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=28190
2023-01-08 06:50:01 - progress_bar.py[line:274] - INFO: epoch 001:   5666 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0802, wps=67.8, ups=0.39, wpb=87.2, bsz=32, num_updates=5660, lr=4.96337e-05, gnorm=0.64, clip=0, loss_scale=1024, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=28216
2023-01-08 06:50:26 - progress_bar.py[line:274] - INFO: epoch 001:   5676 / 144806 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0311, wps=69.1, ups=0.4, wpb=86.8, bsz=32, num_updates=5670, lr=4.96301e-05, gnorm=0.689, clip=20, loss_scale=1024, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=28241
2023-01-08 06:50:52 - progress_bar.py[line:274] - INFO: epoch 001:   5686 / 144806 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1118, wps=66.8, ups=0.39, wpb=86.4, bsz=32, num_updates=5680, lr=4.96265e-05, gnorm=0.732, clip=20, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=28268
2023-01-08 06:51:19 - progress_bar.py[line:274] - INFO: epoch 001:   5696 / 144806 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0491, wps=66.9, ups=0.39, wpb=86.4, bsz=32, num_updates=5690, lr=4.9623e-05, gnorm=0.581, clip=0, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=28294
2023-01-08 06:51:45 - progress_bar.py[line:274] - INFO: epoch 001:   5706 / 144806 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0904, wps=67.3, ups=0.39, wpb=86.9, bsz=32, num_updates=5700, lr=4.96194e-05, gnorm=0.574, clip=0, loss_scale=1024, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=28320
2023-01-08 06:52:11 - progress_bar.py[line:274] - INFO: epoch 001:   5716 / 144806 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0844, wps=67.3, ups=0.39, wpb=87.2, bsz=32, num_updates=5710, lr=4.96158e-05, gnorm=0.663, clip=10, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=28346
2023-01-08 06:52:37 - progress_bar.py[line:274] - INFO: epoch 001:   5726 / 144806 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.071, wps=69.3, ups=0.39, wpb=88.8, bsz=32, num_updates=5720, lr=4.96123e-05, gnorm=0.525, clip=0, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=28372
2023-01-08 06:53:03 - progress_bar.py[line:274] - INFO: epoch 001:   5736 / 144806 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1065, wps=68, ups=0.39, wpb=87.2, bsz=32, num_updates=5730, lr=4.96087e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=28398
2023-01-08 06:53:29 - progress_bar.py[line:274] - INFO: epoch 001:   5746 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0802, wps=67.8, ups=0.39, wpb=87.4, bsz=32, num_updates=5740, lr=4.96051e-05, gnorm=0.619, clip=0, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=28424
2023-01-08 06:53:54 - progress_bar.py[line:274] - INFO: epoch 001:   5756 / 144806 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0788, wps=68.5, ups=0.39, wpb=86.8, bsz=32, num_updates=5750, lr=4.96016e-05, gnorm=0.534, clip=10, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=28449
2023-01-08 06:54:19 - progress_bar.py[line:274] - INFO: epoch 001:   5766 / 144806 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0788, wps=68.7, ups=0.4, wpb=85.5, bsz=32, num_updates=5760, lr=4.9598e-05, gnorm=0.547, clip=0, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=28474
2023-01-08 06:54:44 - progress_bar.py[line:274] - INFO: epoch 001:   5776 / 144806 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0736, wps=69.3, ups=0.4, wpb=86, bsz=32, num_updates=5770, lr=4.95944e-05, gnorm=0.601, clip=0, loss_scale=1024, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=28500
2023-01-08 06:55:10 - progress_bar.py[line:274] - INFO: epoch 001:   5786 / 144806 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0602, wps=68.6, ups=0.39, wpb=87.6, bsz=32, num_updates=5780, lr=4.95909e-05, gnorm=0.602, clip=0, loss_scale=2048, train_wall=25, gb_free=15, ema_decay=0.9999, wall=28525
2023-01-08 06:55:15 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-08 06:55:38 - progress_bar.py[line:274] - INFO: epoch 001:   5797 / 144806 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=88.048, nsentences=32, sample_size=88.048, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0838, wps=67.3, ups=0.36, wpb=88, bsz=32, num_updates=5790, lr=4.95873e-05, gnorm=0.581, clip=0, loss_scale=1024, train_wall=27, gb_free=15.4, ema_decay=0.9999, wall=28553
2023-01-08 06:56:03 - progress_bar.py[line:274] - INFO: epoch 001:   5807 / 144806 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1152, wps=68.5, ups=0.4, wpb=86.5, bsz=32, num_updates=5800, lr=4.95837e-05, gnorm=0.586, clip=0, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=28579
2023-01-08 06:56:29 - progress_bar.py[line:274] - INFO: epoch 001:   5817 / 144806 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1097, wps=69.9, ups=0.4, wpb=87.1, bsz=32, num_updates=5810, lr=4.95802e-05, gnorm=0.642, clip=20, loss_scale=1024, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=28604
2023-01-08 06:56:54 - progress_bar.py[line:274] - INFO: epoch 001:   5827 / 144806 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0818, wps=68.7, ups=0.39, wpb=87.5, bsz=32, num_updates=5820, lr=4.95766e-05, gnorm=0.815, clip=20, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=28629
2023-01-08 06:57:20 - progress_bar.py[line:274] - INFO: epoch 001:   5837 / 144806 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1161, wps=69.1, ups=0.39, wpb=88.4, bsz=32, num_updates=5830, lr=4.9573e-05, gnorm=0.682, clip=20, loss_scale=1024, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=28655
2023-01-08 06:57:46 - progress_bar.py[line:274] - INFO: epoch 001:   5847 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1018, wps=69.1, ups=0.4, wpb=87.4, bsz=32, num_updates=5840, lr=4.95695e-05, gnorm=0.638, clip=10, loss_scale=1024, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=28681
2023-01-08 06:58:11 - progress_bar.py[line:274] - INFO: epoch 001:   5857 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0867, wps=67.8, ups=0.39, wpb=86.2, bsz=32, num_updates=5850, lr=4.95659e-05, gnorm=0.68, clip=10, loss_scale=1024, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=28706
2023-01-08 06:58:37 - progress_bar.py[line:274] - INFO: epoch 001:   5867 / 144806 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0318, wps=68.5, ups=0.39, wpb=87.8, bsz=32, num_updates=5860, lr=4.95623e-05, gnorm=0.635, clip=20, loss_scale=1024, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=28732
2023-01-08 06:59:03 - progress_bar.py[line:274] - INFO: epoch 001:   5877 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0833, wps=69.2, ups=0.4, wpb=87.5, bsz=32, num_updates=5870, lr=4.95588e-05, gnorm=0.74, clip=20, loss_scale=1024, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=28758
2023-01-08 06:59:29 - progress_bar.py[line:274] - INFO: epoch 001:   5887 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1118, wps=68, ups=0.39, wpb=86.9, bsz=32, num_updates=5880, lr=4.95552e-05, gnorm=0.745, clip=10, loss_scale=1024, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=28784
2023-01-08 06:59:41 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 06:59:57 - progress_bar.py[line:274] - INFO: epoch 001:   5898 / 144806 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=86.952, nsentences=32, sample_size=86.952, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1186, wps=65.1, ups=0.36, wpb=87, bsz=32, num_updates=5890, lr=4.95516e-05, gnorm=0.694, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=28812
2023-01-08 07:00:22 - progress_bar.py[line:274] - INFO: epoch 001:   5908 / 144806 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1235, wps=68.6, ups=0.39, wpb=86.9, bsz=32, num_updates=5900, lr=4.95481e-05, gnorm=0.645, clip=10, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=28837
2023-01-08 07:00:49 - progress_bar.py[line:274] - INFO: epoch 001:   5918 / 144806 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0994, wps=67.1, ups=0.39, wpb=86.7, bsz=32, num_updates=5910, lr=4.95445e-05, gnorm=0.568, clip=0, loss_scale=512, train_wall=26, gb_free=14.9, ema_decay=0.9999, wall=28864
2023-01-08 07:01:15 - progress_bar.py[line:274] - INFO: epoch 001:   5928 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0723, wps=67.3, ups=0.39, wpb=86, bsz=32, num_updates=5920, lr=4.95409e-05, gnorm=0.768, clip=40, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=28889
2023-01-08 07:01:40 - progress_bar.py[line:274] - INFO: epoch 001:   5938 / 144806 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1118, wps=70.4, ups=0.4, wpb=88.7, bsz=32, num_updates=5930, lr=4.95374e-05, gnorm=0.606, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=28915
2023-01-08 07:02:06 - progress_bar.py[line:274] - INFO: epoch 001:   5948 / 144806 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1, wps=69.8, ups=0.4, wpb=88.2, bsz=32, num_updates=5940, lr=4.95338e-05, gnorm=0.629, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=28941
2023-01-08 07:02:31 - progress_bar.py[line:274] - INFO: epoch 001:   5958 / 144806 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1419, wps=68.7, ups=0.39, wpb=87.6, bsz=32, num_updates=5950, lr=4.95302e-05, gnorm=0.532, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=28966
2023-01-08 07:02:57 - progress_bar.py[line:274] - INFO: epoch 001:   5968 / 144806 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0811, wps=68.5, ups=0.39, wpb=87.7, bsz=32, num_updates=5960, lr=4.95267e-05, gnorm=0.512, clip=0, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=28992
2023-01-08 07:03:23 - progress_bar.py[line:274] - INFO: epoch 001:   5978 / 144806 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1131, wps=68.7, ups=0.4, wpb=86.2, bsz=32, num_updates=5970, lr=4.95231e-05, gnorm=0.535, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=29018
2023-01-08 07:03:48 - progress_bar.py[line:274] - INFO: epoch 001:   5988 / 144806 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0491, wps=68.1, ups=0.39, wpb=86.7, bsz=32, num_updates=5980, lr=4.95195e-05, gnorm=0.577, clip=10, loss_scale=512, train_wall=25, gb_free=14.8, ema_decay=0.9999, wall=29043
2023-01-08 07:04:14 - progress_bar.py[line:274] - INFO: epoch 001:   5998 / 144806 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.113, wps=66.8, ups=0.39, wpb=86.1, bsz=32, num_updates=5990, lr=4.9516e-05, gnorm=0.596, clip=10, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=29069
2023-01-08 07:04:40 - progress_bar.py[line:274] - INFO: epoch 001:   6008 / 144806 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.106, wps=68.6, ups=0.39, wpb=88, bsz=32, num_updates=6000, lr=4.95124e-05, gnorm=0.545, clip=0, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=29095
2023-01-08 07:04:40 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 07:04:41 - train.py[line:549] - INFO: 0 / 6234
2023-01-08 07:04:41 - train.py[line:551] - INFO: load:0.86 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 07:04:43 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.91 GiB (GPU 1; 39.59 GiB total capacity; 8.40 GiB already allocated; 4.09 GiB free; 26.18 GiB reserved in total by PyTorch)
2023-01-08 07:04:43 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-08 07:04:43 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 10        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8599 MB |    9580 MB |    2620 TB |    2620 TB |
|       from large pool |    8425 MB |    9405 MB |    2618 TB |    2618 TB |
|       from small pool |     174 MB |     174 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8599 MB |    9580 MB |    2620 TB |    2620 TB |
|       from large pool |    8425 MB |    9405 MB |    2618 TB |    2618 TB |
|       from small pool |     174 MB |     174 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26808 MB |   26876 MB |  144200 MB |  117392 MB |
|       from large pool |   26632 MB |   26696 MB |  143826 MB |  117194 MB |
|       from small pool |     176 MB |     180 MB |     374 MB |     198 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   18208 MB |   21634 MB |    3378 TB |    3378 TB |
|       from large pool |   18206 MB |   21632 MB |    3377 TB |    3377 TB |
|       from small pool |       1 MB |       3 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  140221 K  |  140216 K  |
|       from large pool |     698    |     710    |   47672 K  |   47671 K  |
|       from small pool |    3925    |    3943    |   92548 K  |   92544 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  140221 K  |  140216 K  |
|       from large pool |     698    |     710    |   47672 K  |   47671 K  |
|       from small pool |    3925    |    3943    |   92548 K  |   92544 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     193    |     196    |     571    |     378    |
|       from large pool |     105    |     106    |     384    |     279    |
|       from small pool |      88    |      90    |     187    |      99    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     131    |     134    |  106576 K  |  106575 K  |
|       from large pool |      66    |      69    |   28283 K  |   28283 K  |
|       from small pool |      65    |      72    |   78292 K  |   78292 K  |
|===========================================================================|

2023-01-08 07:04:43 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-08 07:08:14 - train.py[line:549] - INFO: 200 / 6234
2023-01-08 07:08:14 - train.py[line:551] - INFO: load:0.89 valid_run:212.61 task_valid:207.17 collect_output:3.47
2023-01-08 07:11:42 - train.py[line:549] - INFO: 400 / 6234
2023-01-08 07:11:42 - train.py[line:551] - INFO: load:0.91 valid_run:420.66 task_valid:409.24 collect_output:7.49
2023-01-08 07:15:13 - train.py[line:549] - INFO: 600 / 6234
2023-01-08 07:15:13 - train.py[line:551] - INFO: load:0.93 valid_run:631.61 task_valid:612.21 collect_output:13.54
2023-01-08 07:18:44 - train.py[line:549] - INFO: 800 / 6234
2023-01-08 07:18:44 - train.py[line:551] - INFO: load:0.96 valid_run:841.91 task_valid:811.45 collect_output:22.69
2023-01-08 07:22:13 - train.py[line:549] - INFO: 1000 / 6234
2023-01-08 07:22:13 - train.py[line:551] - INFO: load:0.98 valid_run:1050.81 task_valid:1015.83 collect_output:25.27
2023-01-08 07:25:45 - train.py[line:549] - INFO: 1200 / 6234
2023-01-08 07:25:45 - train.py[line:551] - INFO: load:1.00 valid_run:1263.05 task_valid:1222.11 collect_output:29.27
2023-01-08 07:29:17 - train.py[line:549] - INFO: 1400 / 6234
2023-01-08 07:29:17 - train.py[line:551] - INFO: load:1.03 valid_run:1475.42 task_valid:1427.44 collect_output:34.35
2023-01-08 07:32:48 - train.py[line:549] - INFO: 1600 / 6234
2023-01-08 07:32:48 - train.py[line:551] - INFO: load:1.05 valid_run:1685.81 task_valid:1630.49 collect_output:39.74
2023-01-08 07:36:21 - train.py[line:549] - INFO: 1800 / 6234
2023-01-08 07:36:21 - train.py[line:551] - INFO: load:1.07 valid_run:1898.66 task_valid:1834.23 collect_output:46.89
2023-01-08 07:39:51 - train.py[line:549] - INFO: 2000 / 6234
2023-01-08 07:39:51 - train.py[line:551] - INFO: load:1.10 valid_run:2108.54 task_valid:2032.28 collect_output:56.78
2023-01-08 07:43:19 - train.py[line:549] - INFO: 2200 / 6234
2023-01-08 07:43:19 - train.py[line:551] - INFO: load:1.12 valid_run:2316.70 task_valid:2234.48 collect_output:60.81
2023-01-08 07:46:49 - train.py[line:549] - INFO: 2400 / 6234
2023-01-08 07:46:49 - train.py[line:551] - INFO: load:1.14 valid_run:2526.54 task_valid:2438.00 collect_output:65.18
2023-01-08 07:50:16 - train.py[line:549] - INFO: 2600 / 6234
2023-01-08 07:50:16 - train.py[line:551] - INFO: load:1.17 valid_run:2733.14 task_valid:2637.43 collect_output:70.40
2023-01-08 07:53:45 - train.py[line:549] - INFO: 2800 / 6234
2023-01-08 07:53:45 - train.py[line:551] - INFO: load:1.19 valid_run:2942.65 task_valid:2842.31 collect_output:73.07
2023-01-08 07:57:14 - train.py[line:549] - INFO: 3000 / 6234
2023-01-08 07:57:14 - train.py[line:551] - INFO: load:1.22 valid_run:3151.69 task_valid:3044.85 collect_output:77.61
2023-01-08 08:00:44 - train.py[line:549] - INFO: 3200 / 6234
2023-01-08 08:00:44 - train.py[line:551] - INFO: load:1.24 valid_run:3361.14 task_valid:3244.51 collect_output:85.47
2023-01-08 08:04:14 - train.py[line:549] - INFO: 3400 / 6234
2023-01-08 08:04:14 - train.py[line:551] - INFO: load:1.26 valid_run:3570.82 task_valid:3447.00 collect_output:90.70
2023-01-08 08:07:43 - train.py[line:549] - INFO: 3600 / 6234
2023-01-08 08:07:43 - train.py[line:551] - INFO: load:1.29 valid_run:3780.00 task_valid:3651.87 collect_output:93.07
2023-01-08 08:11:13 - train.py[line:549] - INFO: 3800 / 6234
2023-01-08 08:11:13 - train.py[line:551] - INFO: load:1.31 valid_run:3989.98 task_valid:3855.58 collect_output:97.38
2023-01-08 08:14:42 - train.py[line:549] - INFO: 4000 / 6234
2023-01-08 08:14:42 - train.py[line:551] - INFO: load:1.33 valid_run:4198.70 task_valid:4058.78 collect_output:100.95
2023-01-08 08:18:12 - train.py[line:549] - INFO: 4200 / 6234
2023-01-08 08:18:12 - train.py[line:551] - INFO: load:1.36 valid_run:4409.06 task_valid:4261.81 collect_output:106.35
2023-01-08 08:21:43 - train.py[line:549] - INFO: 4400 / 6234
2023-01-08 08:21:43 - train.py[line:551] - INFO: load:1.38 valid_run:4619.54 task_valid:4467.92 collect_output:108.77
2023-01-08 08:25:11 - train.py[line:549] - INFO: 4600 / 6234
2023-01-08 08:25:11 - train.py[line:551] - INFO: load:1.41 valid_run:4828.07 task_valid:4668.12 collect_output:115.14
2023-01-08 08:28:39 - train.py[line:549] - INFO: 4800 / 6234
2023-01-08 08:28:39 - train.py[line:551] - INFO: load:1.43 valid_run:5036.04 task_valid:4870.88 collect_output:118.39
2023-01-08 08:32:09 - train.py[line:549] - INFO: 5000 / 6234
2023-01-08 08:32:09 - train.py[line:551] - INFO: load:1.46 valid_run:5245.67 task_valid:5072.85 collect_output:124.08
2023-01-08 08:35:41 - train.py[line:549] - INFO: 5200 / 6234
2023-01-08 08:35:41 - train.py[line:551] - INFO: load:1.48 valid_run:5457.25 task_valid:5274.99 collect_output:131.56
2023-01-08 08:39:08 - train.py[line:549] - INFO: 5400 / 6234
2023-01-08 08:39:08 - train.py[line:551] - INFO: load:1.50 valid_run:5664.78 task_valid:5474.80 collect_output:137.32
2023-01-08 08:42:39 - train.py[line:549] - INFO: 5600 / 6234
2023-01-08 08:42:39 - train.py[line:551] - INFO: load:1.53 valid_run:5875.62 task_valid:5681.72 collect_output:139.27
2023-01-08 08:46:10 - train.py[line:549] - INFO: 5800 / 6234
2023-01-08 08:46:10 - train.py[line:551] - INFO: load:1.55 valid_run:6085.76 task_valid:5883.89 collect_output:145.26
2023-01-08 08:49:40 - train.py[line:549] - INFO: 6000 / 6234
2023-01-08 08:49:40 - train.py[line:551] - INFO: load:1.58 valid_run:6296.42 task_valid:6089.37 collect_output:148.47
2023-01-08 08:53:10 - train.py[line:549] - INFO: 6200 / 6234
2023-01-08 08:53:10 - train.py[line:551] - INFO: load:1.60 valid_run:6506.16 task_valid:6295.02 collect_output:150.59

====================================================================================================
SGG eval:     R @ 50: 0.5844;     R @ 100: 0.6321;     R @ 500: 0.6729;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3696;    mR @ 100: 0.4299;    mR @ 500: 0.4806;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8049) (covered in:0.8125) (covering:0.3714) (eating:0.7647) (flying in:0.2273) (growing on:0.3750) (hanging from:0.3871) (lying on:0.1000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8889) (says:0.0000) (sitting on:0.7800) (standing on:0.2133) (using:0.5750) (walking in:0.0000) (walking on:0.7432) (watching:0.3889) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5844;     R @ 100: 0.6321;     R @ 500: 0.6729;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3696;    mR @ 100: 0.4299;    mR @ 500: 0.4806;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8049) (covered in:0.8125) (covering:0.3714) (eating:0.7647) (flying in:0.2273) (growing on:0.3750) (hanging from:0.3871) (lying on:0.1000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8889) (says:0.0000) (sitting on:0.7800) (standing on:0.2133) (using:0.5750) (walking in:0.0000) (walking on:0.7432) (watching:0.3889) 
--------------------------------------------------------
====================================================================================================

2023-01-08 08:53:56 - train.py[line:487] - INFO: 0.6321029284441049
2023-01-08 08:53:56 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 08:53:56 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.321 | loss_v1 0 | loss_v2 0 | nll_loss 0.164 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.632103 | ppl 1.12 | vqa_score 0.4628 | wps 68.4 | wpb 72 | bsz 24 | num_updates 6000 | best_R@100 0.632103
2023-01-08 08:53:56 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2023-01-08 08:53:56 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_6000.pt
2023-01-08 08:54:37 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_6000.pt
2023-01-08 08:57:31 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.6321029284441049) (writing took 214.6274292767048 seconds)
2023-01-08 08:57:59 - progress_bar.py[line:274] - INFO: epoch 001:   6018 / 144806 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.135, wps=0.3, ups=0, wpb=88, bsz=32, num_updates=6010, lr=4.95088e-05, gnorm=0.579, clip=0, loss_scale=512, train_wall=27, gb_free=15.2, ema_decay=0.9999, wall=35894
2023-01-08 08:58:26 - progress_bar.py[line:274] - INFO: epoch 001:   6028 / 144806 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.1053, wps=67.3, ups=0.39, wpb=86.1, bsz=32, num_updates=6020, lr=4.95053e-05, gnorm=0.659, clip=10, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=35920
2023-01-08 08:58:53 - progress_bar.py[line:274] - INFO: epoch 001:   6038 / 144806 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=89, nsentences=32, sample_size=89, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1548, wps=67, ups=0.38, wpb=89, bsz=32, num_updates=6030, lr=4.95017e-05, gnorm=0.554, clip=0, loss_scale=512, train_wall=27, gb_free=15.3, ema_decay=0.9999, wall=35947
2023-01-08 08:59:19 - progress_bar.py[line:274] - INFO: epoch 001:   6048 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1141, wps=68.6, ups=0.39, wpb=87.7, bsz=32, num_updates=6040, lr=4.94981e-05, gnorm=0.741, clip=20, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=35974
2023-01-08 08:59:45 - progress_bar.py[line:274] - INFO: epoch 001:   6058 / 144806 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=85.7, nsentences=32, sample_size=85.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1131, wps=68.4, ups=0.4, wpb=85.7, bsz=32, num_updates=6050, lr=4.94946e-05, gnorm=0.639, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=35999
2023-01-08 09:00:11 - progress_bar.py[line:274] - INFO: epoch 001:   6068 / 144806 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1145, wps=66.7, ups=0.39, wpb=85.8, bsz=32, num_updates=6060, lr=4.9491e-05, gnorm=0.624, clip=10, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=36026
2023-01-08 09:00:37 - progress_bar.py[line:274] - INFO: epoch 001:   6078 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1111, wps=67.6, ups=0.39, wpb=87, bsz=32, num_updates=6070, lr=4.94874e-05, gnorm=0.644, clip=10, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=36052
2023-01-08 09:01:03 - progress_bar.py[line:274] - INFO: epoch 001:   6088 / 144806 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0925, wps=67.1, ups=0.39, wpb=85.5, bsz=32, num_updates=6080, lr=4.94839e-05, gnorm=0.618, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=36078
2023-01-08 09:01:30 - progress_bar.py[line:274] - INFO: epoch 001:   6098 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.117, wps=67.9, ups=0.39, wpb=86.7, bsz=32, num_updates=6090, lr=4.94803e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=36104
2023-01-08 09:01:56 - progress_bar.py[line:274] - INFO: epoch 001:   6108 / 144806 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1342, wps=69.4, ups=0.39, wpb=88.4, bsz=32, num_updates=6100, lr=4.94767e-05, gnorm=0.529, clip=0, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=36130
2023-01-08 09:02:22 - progress_bar.py[line:274] - INFO: epoch 001:   6118 / 144806 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1145, wps=68.8, ups=0.39, wpb=87.3, bsz=32, num_updates=6110, lr=4.94732e-05, gnorm=0.676, clip=10, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=36156
2023-01-08 09:02:48 - progress_bar.py[line:274] - INFO: epoch 001:   6128 / 144806 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1195, wps=68.1, ups=0.39, wpb=87.5, bsz=32, num_updates=6120, lr=4.94696e-05, gnorm=0.54, clip=0, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=36183
2023-01-08 09:03:14 - progress_bar.py[line:274] - INFO: epoch 001:   6138 / 144806 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1029, wps=67.9, ups=0.39, wpb=86.4, bsz=32, num_updates=6130, lr=4.9466e-05, gnorm=0.622, clip=10, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=36209
2023-01-08 09:03:40 - progress_bar.py[line:274] - INFO: epoch 001:   6148 / 144806 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0479, wps=70.8, ups=0.4, wpb=88.6, bsz=32, num_updates=6140, lr=4.94624e-05, gnorm=0.588, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=36234
2023-01-08 09:04:06 - progress_bar.py[line:274] - INFO: epoch 001:   6158 / 144806 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.1105, wps=68.6, ups=0.4, wpb=86.7, bsz=32, num_updates=6150, lr=4.94589e-05, gnorm=0.552, clip=0, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=36260
2023-01-08 09:04:32 - progress_bar.py[line:274] - INFO: epoch 001:   6168 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1373, wps=68.3, ups=0.39, wpb=87, bsz=32, num_updates=6160, lr=4.94553e-05, gnorm=0.734, clip=10, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=36286
2023-01-08 09:04:57 - progress_bar.py[line:274] - INFO: epoch 001:   6178 / 144806 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1195, wps=70.4, ups=0.4, wpb=87.5, bsz=32, num_updates=6170, lr=4.94517e-05, gnorm=0.483, clip=0, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=36312
2023-01-08 09:05:23 - progress_bar.py[line:274] - INFO: epoch 001:   6188 / 144806 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1076, wps=67.9, ups=0.39, wpb=86.1, bsz=32, num_updates=6180, lr=4.94482e-05, gnorm=0.612, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=36338
2023-01-08 09:05:50 - progress_bar.py[line:274] - INFO: epoch 001:   6198 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1141, wps=66.3, ups=0.38, wpb=87.1, bsz=32, num_updates=6190, lr=4.94446e-05, gnorm=0.614, clip=20, loss_scale=512, train_wall=26, gb_free=15.6, ema_decay=0.9999, wall=36365
2023-01-08 09:06:16 - progress_bar.py[line:274] - INFO: epoch 001:   6208 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1273, wps=69.8, ups=0.4, wpb=87.6, bsz=32, num_updates=6200, lr=4.9441e-05, gnorm=0.635, clip=10, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=36390
2023-01-08 09:06:42 - progress_bar.py[line:274] - INFO: epoch 001:   6218 / 144806 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1333, wps=69.3, ups=0.4, wpb=86.6, bsz=32, num_updates=6210, lr=4.94375e-05, gnorm=0.579, clip=10, loss_scale=512, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=36416
2023-01-08 09:07:08 - progress_bar.py[line:274] - INFO: epoch 001:   6228 / 144806 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1018, wps=66.9, ups=0.39, wpb=86.2, bsz=32, num_updates=6220, lr=4.94339e-05, gnorm=0.505, clip=0, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=36443
2023-01-08 09:07:34 - progress_bar.py[line:274] - INFO: epoch 001:   6238 / 144806 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.1173, wps=66.8, ups=0.39, wpb=86.5, bsz=32, num_updates=6230, lr=4.94303e-05, gnorm=0.578, clip=0, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=36469
2023-01-08 09:08:00 - progress_bar.py[line:274] - INFO: epoch 001:   6248 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1037, wps=67.9, ups=0.39, wpb=86.3, bsz=32, num_updates=6240, lr=4.94268e-05, gnorm=0.531, clip=0, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=36495
2023-01-08 09:08:26 - progress_bar.py[line:274] - INFO: epoch 001:   6258 / 144806 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.1059, wps=67.8, ups=0.39, wpb=86, bsz=32, num_updates=6250, lr=4.94232e-05, gnorm=0.611, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=36521
2023-01-08 09:08:52 - progress_bar.py[line:274] - INFO: epoch 001:   6268 / 144806 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1146, wps=69.1, ups=0.4, wpb=86.9, bsz=32, num_updates=6260, lr=4.94196e-05, gnorm=0.499, clip=0, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=36547
2023-01-08 09:09:19 - progress_bar.py[line:274] - INFO: epoch 001:   6278 / 144806 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1304, wps=67.4, ups=0.39, wpb=87, bsz=32, num_updates=6270, lr=4.94161e-05, gnorm=0.57, clip=0, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=36573
2023-01-08 09:09:44 - progress_bar.py[line:274] - INFO: epoch 001:   6288 / 144806 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1043, wps=68.5, ups=0.4, wpb=86, bsz=32, num_updates=6280, lr=4.94125e-05, gnorm=0.536, clip=0, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=36599
2023-01-08 09:10:10 - progress_bar.py[line:274] - INFO: epoch 001:   6298 / 144806 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0745, wps=70.2, ups=0.4, wpb=87.6, bsz=32, num_updates=6290, lr=4.94089e-05, gnorm=0.59, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=36625
2023-01-08 09:10:36 - progress_bar.py[line:274] - INFO: epoch 001:   6308 / 144806 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.141, wps=70.6, ups=0.4, wpb=88.5, bsz=32, num_updates=6300, lr=4.94054e-05, gnorm=0.544, clip=10, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=36651
2023-01-08 09:11:02 - progress_bar.py[line:274] - INFO: epoch 001:   6318 / 144806 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1765, wps=69.2, ups=0.39, wpb=88.3, bsz=32, num_updates=6310, lr=4.94018e-05, gnorm=0.481, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=36677
2023-01-08 09:11:28 - progress_bar.py[line:274] - INFO: epoch 001:   6328 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0915, wps=70.3, ups=0.4, wpb=88.3, bsz=32, num_updates=6320, lr=4.93982e-05, gnorm=0.566, clip=0, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=36702
2023-01-08 09:11:54 - progress_bar.py[line:274] - INFO: epoch 001:   6338 / 144806 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1227, wps=66.4, ups=0.39, wpb=86.2, bsz=32, num_updates=6330, lr=4.93947e-05, gnorm=0.539, clip=0, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=36729
2023-01-08 09:12:21 - progress_bar.py[line:274] - INFO: epoch 001:   6348 / 144806 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0738, wps=68.3, ups=0.39, wpb=87.9, bsz=32, num_updates=6340, lr=4.93911e-05, gnorm=0.537, clip=0, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=36755
2023-01-08 09:12:48 - progress_bar.py[line:274] - INFO: epoch 001:   6358 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1419, wps=67.9, ups=0.39, wpb=87.2, bsz=32, num_updates=6350, lr=4.93875e-05, gnorm=0.711, clip=10, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=36782
2023-01-08 09:13:16 - progress_bar.py[line:274] - INFO: epoch 001:   6368 / 144806 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.1294, wps=67.2, ups=0.39, wpb=86.3, bsz=32, num_updates=6360, lr=4.9384e-05, gnorm=0.609, clip=0, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=36809
2023-01-08 09:13:43 - progress_bar.py[line:274] - INFO: epoch 001:   6378 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1161, wps=67.7, ups=0.39, wpb=87.3, bsz=32, num_updates=6370, lr=4.93804e-05, gnorm=0.655, clip=10, loss_scale=512, train_wall=26, gb_free=15.5, ema_decay=0.9999, wall=36837
2023-01-08 09:14:10 - progress_bar.py[line:274] - INFO: epoch 001:   6388 / 144806 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1258, wps=68.3, ups=0.39, wpb=88.5, bsz=32, num_updates=6380, lr=4.93768e-05, gnorm=0.744, clip=20, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=36864
2023-01-08 09:14:35 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 09:14:39 - progress_bar.py[line:274] - INFO: epoch 001:   6399 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.905, nsentences=32, sample_size=87.905, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1192, wps=66.6, ups=0.36, wpb=87.9, bsz=32, num_updates=6390, lr=4.93733e-05, gnorm=0.694, clip=20, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=36893
2023-01-08 09:15:06 - progress_bar.py[line:274] - INFO: epoch 001:   6409 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0714, wps=68.4, ups=0.4, wpb=86.3, bsz=32, num_updates=6400, lr=4.93697e-05, gnorm=0.699, clip=20, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=36920
2023-01-08 09:15:33 - progress_bar.py[line:274] - INFO: epoch 001:   6419 / 144806 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1152, wps=69.1, ups=0.4, wpb=87.1, bsz=32, num_updates=6410, lr=4.93661e-05, gnorm=0.589, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=36947
2023-01-08 09:16:00 - progress_bar.py[line:274] - INFO: epoch 001:   6429 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=89.7, nsentences=32, sample_size=89.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1208, wps=70.2, ups=0.39, wpb=89.7, bsz=32, num_updates=6420, lr=4.93626e-05, gnorm=0.562, clip=10, loss_scale=256, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=36974
2023-01-08 09:16:27 - progress_bar.py[line:274] - INFO: epoch 001:   6439 / 144806 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1304, wps=68.8, ups=0.39, wpb=87.3, bsz=32, num_updates=6430, lr=4.9359e-05, gnorm=0.501, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=37001
2023-01-08 09:16:53 - progress_bar.py[line:274] - INFO: epoch 001:   6449 / 144806 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1154, wps=68.9, ups=0.4, wpb=86.4, bsz=32, num_updates=6440, lr=4.93554e-05, gnorm=0.603, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=37027
2023-01-08 09:17:19 - progress_bar.py[line:274] - INFO: epoch 001:   6459 / 144806 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1273, wps=68.3, ups=0.4, wpb=86.4, bsz=32, num_updates=6450, lr=4.93519e-05, gnorm=0.525, clip=0, loss_scale=256, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=37054
2023-01-08 09:17:46 - progress_bar.py[line:274] - INFO: epoch 001:   6469 / 144806 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.142, wps=68.5, ups=0.39, wpb=87.4, bsz=32, num_updates=6460, lr=4.93483e-05, gnorm=0.491, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=37080
2023-01-08 09:18:13 - progress_bar.py[line:274] - INFO: epoch 001:   6479 / 144806 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1645, wps=68.5, ups=0.39, wpb=87.7, bsz=32, num_updates=6470, lr=4.93447e-05, gnorm=0.479, clip=0, loss_scale=256, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=37107
2023-01-08 09:18:40 - progress_bar.py[line:274] - INFO: epoch 001:   6489 / 144806 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1046, wps=68.5, ups=0.39, wpb=88.3, bsz=32, num_updates=6480, lr=4.93412e-05, gnorm=0.577, clip=0, loss_scale=256, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=37134
2023-01-08 09:19:07 - progress_bar.py[line:274] - INFO: epoch 001:   6499 / 144806 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0844, wps=69.7, ups=0.4, wpb=87, bsz=32, num_updates=6490, lr=4.93376e-05, gnorm=0.633, clip=0, loss_scale=256, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=37161
2023-01-08 09:19:34 - progress_bar.py[line:274] - INFO: epoch 001:   6509 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1027, wps=67.4, ups=0.39, wpb=87.2, bsz=32, num_updates=6500, lr=4.9334e-05, gnorm=0.587, clip=10, loss_scale=256, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=37188
2023-01-08 09:20:01 - progress_bar.py[line:274] - INFO: epoch 001:   6519 / 144806 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1221, wps=67.5, ups=0.39, wpb=86.9, bsz=32, num_updates=6510, lr=4.93305e-05, gnorm=0.545, clip=0, loss_scale=256, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=37215
2023-01-08 09:20:27 - progress_bar.py[line:274] - INFO: epoch 001:   6529 / 144806 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.096, wps=68.4, ups=0.4, wpb=86, bsz=32, num_updates=6520, lr=4.93269e-05, gnorm=0.562, clip=0, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=37241
2023-01-08 09:20:54 - progress_bar.py[line:274] - INFO: epoch 001:   6539 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1243, wps=68.3, ups=0.39, wpb=87.2, bsz=32, num_updates=6530, lr=4.93233e-05, gnorm=0.934, clip=30, loss_scale=256, train_wall=25, gb_free=15, ema_decay=0.9999, wall=37268
2023-01-08 09:21:21 - progress_bar.py[line:274] - INFO: epoch 001:   6549 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1369, wps=67.2, ups=0.39, wpb=85.9, bsz=32, num_updates=6540, lr=4.93198e-05, gnorm=0.759, clip=20, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=37295
2023-01-08 09:21:48 - progress_bar.py[line:274] - INFO: epoch 001:   6559 / 144806 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1154, wps=68.4, ups=0.39, wpb=87.3, bsz=32, num_updates=6550, lr=4.93162e-05, gnorm=0.641, clip=10, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=37322
2023-01-08 09:22:15 - progress_bar.py[line:274] - INFO: epoch 001:   6569 / 144806 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0824, wps=67.3, ups=0.39, wpb=86.8, bsz=32, num_updates=6560, lr=4.93126e-05, gnorm=0.484, clip=0, loss_scale=256, train_wall=26, gb_free=15.7, ema_decay=0.9999, wall=37349
2023-01-08 09:22:42 - progress_bar.py[line:274] - INFO: epoch 001:   6579 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1801, wps=69.2, ups=0.4, wpb=87.5, bsz=32, num_updates=6570, lr=4.93091e-05, gnorm=0.735, clip=20, loss_scale=256, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=37376
2023-01-08 09:23:09 - progress_bar.py[line:274] - INFO: epoch 001:   6589 / 144806 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1355, wps=68.3, ups=0.39, wpb=88.5, bsz=32, num_updates=6580, lr=4.93055e-05, gnorm=0.502, clip=0, loss_scale=256, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=37403
2023-01-08 09:23:36 - progress_bar.py[line:274] - INFO: epoch 001:   6599 / 144806 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1145, wps=67, ups=0.39, wpb=86.8, bsz=32, num_updates=6590, lr=4.93019e-05, gnorm=0.58, clip=10, loss_scale=256, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=37430
2023-01-08 09:24:03 - progress_bar.py[line:274] - INFO: epoch 001:   6609 / 144806 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1548, wps=67.2, ups=0.39, wpb=86.3, bsz=32, num_updates=6600, lr=4.92984e-05, gnorm=0.599, clip=0, loss_scale=256, train_wall=26, gb_free=15.6, ema_decay=0.9999, wall=37457
2023-01-08 09:24:30 - progress_bar.py[line:274] - INFO: epoch 001:   6619 / 144806 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1018, wps=68.3, ups=0.39, wpb=87.4, bsz=32, num_updates=6610, lr=4.92948e-05, gnorm=0.597, clip=10, loss_scale=256, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=37484
2023-01-08 09:24:57 - progress_bar.py[line:274] - INFO: epoch 001:   6629 / 144806 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1812, wps=68.3, ups=0.39, wpb=86.9, bsz=32, num_updates=6620, lr=4.92912e-05, gnorm=0.536, clip=0, loss_scale=256, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=37511
2023-01-08 09:25:24 - progress_bar.py[line:274] - INFO: epoch 001:   6639 / 144806 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1592, wps=67.7, ups=0.39, wpb=86.7, bsz=32, num_updates=6630, lr=4.92877e-05, gnorm=0.436, clip=0, loss_scale=256, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=37538
2023-01-08 09:25:51 - progress_bar.py[line:274] - INFO: epoch 001:   6649 / 144806 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1187, wps=68.1, ups=0.39, wpb=86.8, bsz=32, num_updates=6640, lr=4.92841e-05, gnorm=0.603, clip=0, loss_scale=256, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=37565
2023-01-08 09:26:18 - progress_bar.py[line:274] - INFO: epoch 001:   6659 / 144806 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1145, wps=67.8, ups=0.39, wpb=86.6, bsz=32, num_updates=6650, lr=4.92805e-05, gnorm=0.594, clip=0, loss_scale=256, train_wall=25, gb_free=15, ema_decay=0.9999, wall=37591
2023-01-08 09:26:44 - progress_bar.py[line:274] - INFO: epoch 001:   6669 / 144806 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1471, wps=69.3, ups=0.4, wpb=86.5, bsz=32, num_updates=6660, lr=4.9277e-05, gnorm=0.556, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=37618
2023-01-08 09:27:11 - progress_bar.py[line:274] - INFO: epoch 001:   6679 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1856, wps=68.7, ups=0.4, wpb=86.8, bsz=32, num_updates=6670, lr=4.92734e-05, gnorm=0.545, clip=0, loss_scale=256, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=37645
2023-01-08 09:27:38 - progress_bar.py[line:274] - INFO: epoch 001:   6689 / 144806 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1879, wps=67.6, ups=0.39, wpb=87.3, bsz=32, num_updates=6680, lr=4.92698e-05, gnorm=0.575, clip=0, loss_scale=256, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=37672
2023-01-08 09:28:05 - progress_bar.py[line:274] - INFO: epoch 001:   6699 / 144806 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1265, wps=69.4, ups=0.4, wpb=87.7, bsz=32, num_updates=6690, lr=4.92663e-05, gnorm=0.444, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=37698
2023-01-08 09:28:32 - progress_bar.py[line:274] - INFO: epoch 001:   6709 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1299, wps=67, ups=0.39, wpb=86.1, bsz=32, num_updates=6700, lr=4.92627e-05, gnorm=0.842, clip=20, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=37726
2023-01-08 09:28:58 - progress_bar.py[line:274] - INFO: epoch 001:   6719 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1319, wps=69.1, ups=0.39, wpb=88.2, bsz=32, num_updates=6710, lr=4.92591e-05, gnorm=0.783, clip=10, loss_scale=256, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=37753
2023-01-08 09:29:25 - progress_bar.py[line:274] - INFO: epoch 001:   6729 / 144806 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1712, wps=68.9, ups=0.39, wpb=88.1, bsz=32, num_updates=6720, lr=4.92556e-05, gnorm=0.494, clip=0, loss_scale=256, train_wall=26, gb_free=15.7, ema_decay=0.9999, wall=37779
2023-01-08 09:29:53 - progress_bar.py[line:274] - INFO: epoch 001:   6739 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1758, wps=68.8, ups=0.39, wpb=87.8, bsz=32, num_updates=6730, lr=4.9252e-05, gnorm=0.944, clip=10, loss_scale=256, train_wall=25, gb_free=14.8, ema_decay=0.9999, wall=37806
2023-01-08 09:30:20 - progress_bar.py[line:274] - INFO: epoch 001:   6749 / 144806 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1782, wps=68.4, ups=0.39, wpb=87.7, bsz=32, num_updates=6740, lr=4.92484e-05, gnorm=0.5, clip=0, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=37834
2023-01-08 09:30:46 - progress_bar.py[line:274] - INFO: epoch 001:   6759 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1481, wps=66.9, ups=0.39, wpb=86.5, bsz=32, num_updates=6750, lr=4.92449e-05, gnorm=0.681, clip=10, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=37861
2023-01-08 09:31:11 - progress_bar.py[line:274] - INFO: epoch 001:   6769 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1538, wps=69.4, ups=0.4, wpb=86.7, bsz=32, num_updates=6760, lr=4.92413e-05, gnorm=0.558, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=37886
2023-01-08 09:31:37 - progress_bar.py[line:274] - INFO: epoch 001:   6779 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1156, wps=68.9, ups=0.4, wpb=87, bsz=32, num_updates=6770, lr=4.92377e-05, gnorm=0.581, clip=10, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=37912
2023-01-08 09:32:03 - progress_bar.py[line:274] - INFO: epoch 001:   6789 / 144806 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1523, wps=70.2, ups=0.4, wpb=88.3, bsz=32, num_updates=6780, lr=4.92342e-05, gnorm=0.528, clip=0, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=37938
2023-01-08 09:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   6799 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1139, wps=69.4, ups=0.4, wpb=87.2, bsz=32, num_updates=6790, lr=4.92306e-05, gnorm=0.582, clip=0, loss_scale=256, train_wall=25, gb_free=15, ema_decay=0.9999, wall=37963
2023-01-08 09:32:54 - progress_bar.py[line:274] - INFO: epoch 001:   6809 / 144806 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.205, wps=67.4, ups=0.39, wpb=86.2, bsz=32, num_updates=6800, lr=4.9227e-05, gnorm=0.603, clip=0, loss_scale=256, train_wall=26, gb_free=15, ema_decay=0.9999, wall=37989
2023-01-08 09:33:19 - progress_bar.py[line:274] - INFO: epoch 001:   6819 / 144806 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.137, wps=69.3, ups=0.4, wpb=87.5, bsz=32, num_updates=6810, lr=4.92235e-05, gnorm=0.536, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=38014
2023-01-08 09:33:45 - progress_bar.py[line:274] - INFO: epoch 001:   6829 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1867, wps=69.2, ups=0.39, wpb=87.7, bsz=32, num_updates=6820, lr=4.92199e-05, gnorm=0.706, clip=10, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=38040
2023-01-08 09:34:11 - progress_bar.py[line:274] - INFO: epoch 001:   6839 / 144806 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1645, wps=68.1, ups=0.39, wpb=87.5, bsz=32, num_updates=6830, lr=4.92163e-05, gnorm=0.64, clip=10, loss_scale=256, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=38066
2023-01-08 09:34:36 - progress_bar.py[line:274] - INFO: epoch 001:   6849 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1677, wps=69, ups=0.4, wpb=87.2, bsz=32, num_updates=6840, lr=4.92128e-05, gnorm=0.651, clip=10, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=38091
2023-01-08 09:35:02 - progress_bar.py[line:274] - INFO: epoch 001:   6859 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1259, wps=68.3, ups=0.39, wpb=88.4, bsz=32, num_updates=6850, lr=4.92092e-05, gnorm=0.714, clip=10, loss_scale=256, train_wall=26, gb_free=15.5, ema_decay=0.9999, wall=38117
2023-01-08 09:35:29 - progress_bar.py[line:274] - INFO: epoch 001:   6869 / 144806 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.109, wps=66.9, ups=0.39, wpb=86.6, bsz=32, num_updates=6860, lr=4.92056e-05, gnorm=0.65, clip=10, loss_scale=256, train_wall=26, gb_free=15.6, ema_decay=0.9999, wall=38144
2023-01-08 09:35:54 - progress_bar.py[line:274] - INFO: epoch 001:   6879 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1943, wps=68.9, ups=0.4, wpb=86.8, bsz=32, num_updates=6870, lr=4.92021e-05, gnorm=0.639, clip=0, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=38169
2023-01-08 09:36:19 - progress_bar.py[line:274] - INFO: epoch 001:   6889 / 144806 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1429, wps=71.8, ups=0.41, wpb=88.1, bsz=32, num_updates=6880, lr=4.91985e-05, gnorm=0.556, clip=0, loss_scale=256, train_wall=24, gb_free=15.2, ema_decay=0.9999, wall=38194
2023-01-08 09:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   6899 / 144806 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1579, wps=68.5, ups=0.39, wpb=88.6, bsz=32, num_updates=6890, lr=4.91949e-05, gnorm=0.563, clip=0, loss_scale=256, train_wall=26, gb_free=14.8, ema_decay=0.9999, wall=38220
2023-01-08 09:37:11 - progress_bar.py[line:274] - INFO: epoch 001:   6909 / 144806 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1192, wps=68.3, ups=0.39, wpb=88.2, bsz=32, num_updates=6900, lr=4.91914e-05, gnorm=0.5, clip=0, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=38246
2023-01-08 09:37:37 - progress_bar.py[line:274] - INFO: epoch 001:   6919 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1288, wps=68.4, ups=0.39, wpb=87.8, bsz=32, num_updates=6910, lr=4.91878e-05, gnorm=0.643, clip=10, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=38272
2023-01-08 09:38:03 - progress_bar.py[line:274] - INFO: epoch 001:   6929 / 144806 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2037, wps=67.4, ups=0.39, wpb=86.9, bsz=32, num_updates=6920, lr=4.91842e-05, gnorm=0.71, clip=10, loss_scale=512, train_wall=26, gb_free=15, ema_decay=0.9999, wall=38298
2023-01-08 09:38:29 - progress_bar.py[line:274] - INFO: epoch 001:   6939 / 144806 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1059, wps=67.8, ups=0.39, wpb=86.6, bsz=32, num_updates=6930, lr=4.91807e-05, gnorm=0.557, clip=0, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=38324
2023-01-08 09:38:39 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 09:38:57 - progress_bar.py[line:274] - INFO: epoch 001:   6950 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.524, nsentences=32, sample_size=87.524, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.125, wps=66, ups=0.36, wpb=87.5, bsz=32, num_updates=6940, lr=4.91771e-05, gnorm=0.533, clip=0, loss_scale=256, train_wall=28, gb_free=15, ema_decay=0.9999, wall=38352
2023-01-08 09:39:23 - progress_bar.py[line:274] - INFO: epoch 001:   6960 / 144806 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1491, wps=68.4, ups=0.39, wpb=86.7, bsz=32, num_updates=6950, lr=4.91735e-05, gnorm=0.43, clip=0, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=38378
2023-01-08 09:39:49 - progress_bar.py[line:274] - INFO: epoch 001:   6970 / 144806 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1582, wps=68.5, ups=0.39, wpb=88.8, bsz=32, num_updates=6960, lr=4.917e-05, gnorm=0.624, clip=0, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=38404
2023-01-08 09:40:15 - progress_bar.py[line:274] - INFO: epoch 001:   6980 / 144806 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1562, wps=68.4, ups=0.39, wpb=88.1, bsz=32, num_updates=6970, lr=4.91664e-05, gnorm=0.482, clip=0, loss_scale=256, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=38430
2023-01-08 09:40:41 - progress_bar.py[line:274] - INFO: epoch 001:   6990 / 144806 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1783, wps=68.7, ups=0.4, wpb=86.5, bsz=32, num_updates=6980, lr=4.91628e-05, gnorm=0.464, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=38456
2023-01-08 09:41:06 - progress_bar.py[line:274] - INFO: epoch 001:   7000 / 144806 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1242, wps=69.2, ups=0.4, wpb=87.2, bsz=32, num_updates=6990, lr=4.91593e-05, gnorm=0.652, clip=10, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=38481
2023-01-08 09:41:32 - progress_bar.py[line:274] - INFO: epoch 001:   7010 / 144806 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.2303, wps=68.6, ups=0.39, wpb=88.1, bsz=32, num_updates=7000, lr=4.91557e-05, gnorm=0.642, clip=10, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=38507
2023-01-08 09:41:57 - progress_bar.py[line:274] - INFO: epoch 001:   7020 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1319, wps=69.4, ups=0.39, wpb=88.1, bsz=32, num_updates=7010, lr=4.91521e-05, gnorm=0.599, clip=0, loss_scale=256, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=38533
2023-01-08 09:42:23 - progress_bar.py[line:274] - INFO: epoch 001:   7030 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2182, wps=68.1, ups=0.39, wpb=87, bsz=32, num_updates=7020, lr=4.91486e-05, gnorm=0.676, clip=20, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=38558
2023-01-08 09:42:49 - progress_bar.py[line:274] - INFO: epoch 001:   7040 / 144806 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1605, wps=68.9, ups=0.4, wpb=87.1, bsz=32, num_updates=7030, lr=4.9145e-05, gnorm=0.582, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=38584
2023-01-08 09:43:15 - progress_bar.py[line:274] - INFO: epoch 001:   7050 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1212, wps=68.5, ups=0.39, wpb=87.4, bsz=32, num_updates=7040, lr=4.91414e-05, gnorm=0.655, clip=10, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=38610
2023-01-08 09:43:41 - progress_bar.py[line:274] - INFO: epoch 001:   7060 / 144806 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1667, wps=68.5, ups=0.39, wpb=87.6, bsz=32, num_updates=7050, lr=4.91379e-05, gnorm=0.503, clip=0, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=38636
2023-01-08 09:44:07 - progress_bar.py[line:274] - INFO: epoch 001:   7070 / 144806 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1753, wps=68.2, ups=0.39, wpb=87.4, bsz=32, num_updates=7060, lr=4.91343e-05, gnorm=0.482, clip=0, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=38662
2023-01-08 09:44:33 - progress_bar.py[line:274] - INFO: epoch 001:   7080 / 144806 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.2, wps=67.2, ups=0.39, wpb=86.9, bsz=32, num_updates=7070, lr=4.91307e-05, gnorm=0.5, clip=0, loss_scale=256, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=38688
2023-01-08 09:44:59 - progress_bar.py[line:274] - INFO: epoch 001:   7090 / 144806 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.24, wps=69.7, ups=0.4, wpb=88.2, bsz=32, num_updates=7080, lr=4.91272e-05, gnorm=0.494, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=38714
2023-01-08 09:45:25 - progress_bar.py[line:274] - INFO: epoch 001:   7100 / 144806 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1533, wps=68.2, ups=0.39, wpb=88.1, bsz=32, num_updates=7090, lr=4.91236e-05, gnorm=0.498, clip=0, loss_scale=256, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=38740
2023-01-08 09:45:51 - progress_bar.py[line:274] - INFO: epoch 001:   7110 / 144806 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1912, wps=68.6, ups=0.39, wpb=88.6, bsz=32, num_updates=7100, lr=4.912e-05, gnorm=0.534, clip=0, loss_scale=256, train_wall=26, gb_free=14.7, ema_decay=0.9999, wall=38766
2023-01-08 09:46:17 - progress_bar.py[line:274] - INFO: epoch 001:   7120 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1096, wps=69.1, ups=0.39, wpb=87.6, bsz=32, num_updates=7110, lr=4.91164e-05, gnorm=0.432, clip=0, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=38792
2023-01-08 09:46:43 - progress_bar.py[line:274] - INFO: epoch 001:   7130 / 144806 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1572, wps=69.6, ups=0.4, wpb=87.3, bsz=32, num_updates=7120, lr=4.91129e-05, gnorm=0.517, clip=0, loss_scale=256, train_wall=25, gb_free=15, ema_decay=0.9999, wall=38818
2023-01-08 09:47:09 - progress_bar.py[line:274] - INFO: epoch 001:   7140 / 144806 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1479, wps=69.1, ups=0.39, wpb=87.9, bsz=32, num_updates=7130, lr=4.91093e-05, gnorm=0.635, clip=10, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=38844
2023-01-08 09:47:35 - progress_bar.py[line:274] - INFO: epoch 001:   7150 / 144806 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.226, wps=69.4, ups=0.39, wpb=88, bsz=32, num_updates=7140, lr=4.91057e-05, gnorm=0.529, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=38870
2023-01-08 09:48:01 - progress_bar.py[line:274] - INFO: epoch 001:   7160 / 144806 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1465, wps=69.2, ups=0.4, wpb=87.3, bsz=32, num_updates=7150, lr=4.91022e-05, gnorm=0.466, clip=0, loss_scale=256, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=38896
2023-01-08 09:48:27 - progress_bar.py[line:274] - INFO: epoch 001:   7170 / 144806 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1316, wps=68.3, ups=0.39, wpb=87.9, bsz=32, num_updates=7160, lr=4.90986e-05, gnorm=0.64, clip=20, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=38922
2023-01-08 09:48:54 - progress_bar.py[line:274] - INFO: epoch 001:   7180 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0921, wps=67.7, ups=0.39, wpb=87.2, bsz=32, num_updates=7170, lr=4.9095e-05, gnorm=0.957, clip=10, loss_scale=256, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=38948
2023-01-08 09:49:20 - progress_bar.py[line:274] - INFO: epoch 001:   7190 / 144806 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1742, wps=67.2, ups=0.39, wpb=85.9, bsz=32, num_updates=7180, lr=4.90915e-05, gnorm=0.576, clip=10, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=38974
2023-01-08 09:49:46 - progress_bar.py[line:274] - INFO: epoch 001:   7200 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1437, wps=69.1, ups=0.4, wpb=87, bsz=32, num_updates=7190, lr=4.90879e-05, gnorm=1.048, clip=10, loss_scale=256, train_wall=25, gb_free=15, ema_decay=0.9999, wall=39000
2023-01-08 09:50:12 - progress_bar.py[line:274] - INFO: epoch 001:   7210 / 144806 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2442, wps=67.7, ups=0.39, wpb=86.7, bsz=32, num_updates=7200, lr=4.90843e-05, gnorm=0.506, clip=0, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=39027
2023-01-08 09:50:38 - progress_bar.py[line:274] - INFO: epoch 001:   7220 / 144806 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1358, wps=67.8, ups=0.39, wpb=86.5, bsz=32, num_updates=7210, lr=4.90808e-05, gnorm=0.549, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=39053
2023-01-08 09:51:04 - progress_bar.py[line:274] - INFO: epoch 001:   7230 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1569, wps=69.3, ups=0.39, wpb=88, bsz=32, num_updates=7220, lr=4.90772e-05, gnorm=0.985, clip=10, loss_scale=256, train_wall=25, gb_free=15, ema_decay=0.9999, wall=39079
2023-01-08 09:51:30 - progress_bar.py[line:274] - INFO: epoch 001:   7240 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1603, wps=67.2, ups=0.39, wpb=86.3, bsz=32, num_updates=7230, lr=4.90736e-05, gnorm=0.44, clip=0, loss_scale=256, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=39105
2023-01-08 09:51:57 - progress_bar.py[line:274] - INFO: epoch 001:   7250 / 144806 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1923, wps=68, ups=0.39, wpb=87.3, bsz=32, num_updates=7240, lr=4.90701e-05, gnorm=0.529, clip=10, loss_scale=256, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=39131
2023-01-08 09:52:23 - progress_bar.py[line:274] - INFO: epoch 001:   7260 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1582, wps=67, ups=0.39, wpb=86, bsz=32, num_updates=7250, lr=4.90665e-05, gnorm=0.698, clip=10, loss_scale=256, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=39158
2023-01-08 09:52:49 - progress_bar.py[line:274] - INFO: epoch 001:   7270 / 144806 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1481, wps=69.8, ups=0.4, wpb=87.2, bsz=32, num_updates=7260, lr=4.90629e-05, gnorm=0.6, clip=0, loss_scale=256, train_wall=25, gb_free=15, ema_decay=0.9999, wall=39183
2023-01-08 09:53:15 - progress_bar.py[line:274] - INFO: epoch 001:   7280 / 144806 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1859, wps=67.8, ups=0.39, wpb=86.9, bsz=32, num_updates=7270, lr=4.90594e-05, gnorm=0.575, clip=10, loss_scale=256, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=39210
2023-01-08 09:53:41 - progress_bar.py[line:274] - INFO: epoch 001:   7290 / 144806 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=85.2, nsentences=32, sample_size=85.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.2164, wps=66.8, ups=0.39, wpb=85.2, bsz=32, num_updates=7280, lr=4.90558e-05, gnorm=0.713, clip=10, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=39236
2023-01-08 09:54:07 - progress_bar.py[line:274] - INFO: epoch 001:   7300 / 144806 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1769, wps=69, ups=0.39, wpb=87.4, bsz=32, num_updates=7290, lr=4.90522e-05, gnorm=0.576, clip=0, loss_scale=256, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=39262
2023-01-08 09:54:33 - progress_bar.py[line:274] - INFO: epoch 001:   7310 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1689, wps=69.1, ups=0.39, wpb=88.2, bsz=32, num_updates=7300, lr=4.90487e-05, gnorm=0.481, clip=0, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=39288
2023-01-08 09:54:59 - progress_bar.py[line:274] - INFO: epoch 001:   7320 / 144806 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1655, wps=69, ups=0.39, wpb=87.6, bsz=32, num_updates=7310, lr=4.90451e-05, gnorm=0.511, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=39314
2023-01-08 09:55:25 - progress_bar.py[line:274] - INFO: epoch 001:   7330 / 144806 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1491, wps=68.2, ups=0.39, wpb=87, bsz=32, num_updates=7320, lr=4.90415e-05, gnorm=0.458, clip=0, loss_scale=256, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=39340
2023-01-08 09:55:52 - progress_bar.py[line:274] - INFO: epoch 001:   7340 / 144806 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.125, wps=69.1, ups=0.39, wpb=88, bsz=32, num_updates=7330, lr=4.9038e-05, gnorm=0.535, clip=0, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=39366
2023-01-08 09:56:17 - progress_bar.py[line:274] - INFO: epoch 001:   7350 / 144806 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1481, wps=68.8, ups=0.4, wpb=86.4, bsz=32, num_updates=7340, lr=4.90344e-05, gnorm=0.563, clip=0, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=39392
2023-01-08 09:56:43 - progress_bar.py[line:274] - INFO: epoch 001:   7360 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2026, wps=69, ups=0.39, wpb=87.5, bsz=32, num_updates=7350, lr=4.90308e-05, gnorm=0.67, clip=10, loss_scale=256, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=39418
2023-01-08 09:57:09 - progress_bar.py[line:274] - INFO: epoch 001:   7370 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1429, wps=69.5, ups=0.4, wpb=87.7, bsz=32, num_updates=7360, lr=4.90273e-05, gnorm=0.515, clip=0, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=39444
2023-01-08 09:57:35 - progress_bar.py[line:274] - INFO: epoch 001:   7380 / 144806 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.1572, wps=68.4, ups=0.39, wpb=87.2, bsz=32, num_updates=7370, lr=4.90237e-05, gnorm=0.607, clip=0, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=39470
2023-01-08 09:58:01 - progress_bar.py[line:274] - INFO: epoch 001:   7390 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1779, wps=68.6, ups=0.39, wpb=87.7, bsz=32, num_updates=7380, lr=4.90201e-05, gnorm=0.646, clip=10, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=39496
2023-01-08 09:58:28 - progress_bar.py[line:274] - INFO: epoch 001:   7400 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1627, wps=67.1, ups=0.38, wpb=87.1, bsz=32, num_updates=7390, lr=4.90166e-05, gnorm=0.569, clip=10, loss_scale=256, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=39523
2023-01-08 09:58:54 - progress_bar.py[line:274] - INFO: epoch 001:   7410 / 144806 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1711, wps=68.2, ups=0.39, wpb=87.9, bsz=32, num_updates=7400, lr=4.9013e-05, gnorm=0.594, clip=10, loss_scale=256, train_wall=26, gb_free=14.8, ema_decay=0.9999, wall=39549
2023-01-08 09:59:20 - progress_bar.py[line:274] - INFO: epoch 001:   7420 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1975, wps=68.3, ups=0.39, wpb=86.7, bsz=32, num_updates=7410, lr=4.90094e-05, gnorm=0.546, clip=10, loss_scale=256, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=39575
2023-01-08 09:59:46 - progress_bar.py[line:274] - INFO: epoch 001:   7430 / 144806 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1361, wps=69.8, ups=0.39, wpb=88.5, bsz=32, num_updates=7420, lr=4.90059e-05, gnorm=0.549, clip=0, loss_scale=256, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=39601
2023-01-08 10:00:13 - progress_bar.py[line:274] - INFO: epoch 001:   7440 / 144806 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1975, wps=67.4, ups=0.39, wpb=86.7, bsz=32, num_updates=7430, lr=4.90023e-05, gnorm=0.44, clip=0, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=39627
2023-01-08 10:00:39 - progress_bar.py[line:274] - INFO: epoch 001:   7450 / 144806 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2381, wps=67.4, ups=0.39, wpb=86.5, bsz=32, num_updates=7440, lr=4.89987e-05, gnorm=0.56, clip=20, loss_scale=256, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=39654
2023-01-08 10:01:05 - progress_bar.py[line:274] - INFO: epoch 001:   7460 / 144806 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1603, wps=69.6, ups=0.4, wpb=87.9, bsz=32, num_updates=7450, lr=4.89952e-05, gnorm=0.705, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=39680
2023-01-08 10:01:31 - progress_bar.py[line:274] - INFO: epoch 001:   7470 / 144806 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1818, wps=68.8, ups=0.4, wpb=86.9, bsz=32, num_updates=7460, lr=4.89916e-05, gnorm=0.488, clip=0, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=39706
2023-01-08 10:01:56 - progress_bar.py[line:274] - INFO: epoch 001:   7480 / 144806 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.2138, wps=71.1, ups=0.4, wpb=88.1, bsz=32, num_updates=7470, lr=4.8988e-05, gnorm=0.623, clip=10, loss_scale=512, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=39731
2023-01-08 10:02:23 - progress_bar.py[line:274] - INFO: epoch 001:   7490 / 144806 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2026, wps=68.5, ups=0.39, wpb=88, bsz=32, num_updates=7480, lr=4.89845e-05, gnorm=0.442, clip=0, loss_scale=512, train_wall=26, gb_free=15, ema_decay=0.9999, wall=39757
2023-01-08 10:02:49 - progress_bar.py[line:274] - INFO: epoch 001:   7500 / 144806 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1724, wps=67.3, ups=0.39, wpb=86.1, bsz=32, num_updates=7490, lr=4.89809e-05, gnorm=0.654, clip=10, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=39784
2023-01-08 10:03:15 - progress_bar.py[line:274] - INFO: epoch 001:   7510 / 144806 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1859, wps=69.4, ups=0.39, wpb=88, bsz=32, num_updates=7500, lr=4.89773e-05, gnorm=0.536, clip=0, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=39810
2023-01-08 10:03:41 - progress_bar.py[line:274] - INFO: epoch 001:   7520 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1899, wps=68.4, ups=0.4, wpb=85.9, bsz=32, num_updates=7510, lr=4.89738e-05, gnorm=0.633, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=39835
2023-01-08 10:04:07 - progress_bar.py[line:274] - INFO: epoch 001:   7530 / 144806 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1902, wps=69.2, ups=0.4, wpb=87.4, bsz=32, num_updates=7520, lr=4.89702e-05, gnorm=0.503, clip=0, loss_scale=512, train_wall=25, gb_free=14.8, ema_decay=0.9999, wall=39861
2023-01-08 10:04:33 - progress_bar.py[line:274] - INFO: epoch 001:   7540 / 144806 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1724, wps=68.2, ups=0.39, wpb=87.2, bsz=32, num_updates=7530, lr=4.89666e-05, gnorm=0.498, clip=0, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=39887
2023-01-08 10:04:59 - progress_bar.py[line:274] - INFO: epoch 001:   7550 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.4, nsentences=32, sample_size=85.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2273, wps=66.8, ups=0.39, wpb=85.4, bsz=32, num_updates=7540, lr=4.89631e-05, gnorm=0.767, clip=10, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=39914
2023-01-08 10:05:25 - progress_bar.py[line:274] - INFO: epoch 001:   7560 / 144806 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2166, wps=68.4, ups=0.39, wpb=87.6, bsz=32, num_updates=7550, lr=4.89595e-05, gnorm=0.656, clip=10, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=39940
2023-01-08 10:05:51 - progress_bar.py[line:274] - INFO: epoch 001:   7570 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1429, wps=68.4, ups=0.39, wpb=87.3, bsz=32, num_updates=7560, lr=4.89559e-05, gnorm=0.491, clip=0, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=39966
2023-01-08 10:06:17 - progress_bar.py[line:274] - INFO: epoch 001:   7580 / 144806 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1146, wps=68.1, ups=0.4, wpb=85.9, bsz=32, num_updates=7570, lr=4.89524e-05, gnorm=0.54, clip=0, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=39992
2023-01-08 10:06:43 - progress_bar.py[line:274] - INFO: epoch 001:   7590 / 144806 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2075, wps=68.6, ups=0.39, wpb=87.8, bsz=32, num_updates=7580, lr=4.89488e-05, gnorm=0.509, clip=0, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=40018
2023-01-08 10:07:09 - progress_bar.py[line:274] - INFO: epoch 001:   7600 / 144806 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2303, wps=68.7, ups=0.4, wpb=86.4, bsz=32, num_updates=7590, lr=4.89452e-05, gnorm=0.547, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=40044
2023-01-08 10:07:35 - progress_bar.py[line:274] - INFO: epoch 001:   7610 / 144806 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1716, wps=68.8, ups=0.39, wpb=88, bsz=32, num_updates=7600, lr=4.89417e-05, gnorm=0.698, clip=10, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=40070
2023-01-08 10:08:02 - progress_bar.py[line:274] - INFO: epoch 001:   7620 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.193, wps=66.6, ups=0.38, wpb=86.5, bsz=32, num_updates=7610, lr=4.89381e-05, gnorm=0.608, clip=10, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=40096
2023-01-08 10:08:28 - progress_bar.py[line:274] - INFO: epoch 001:   7630 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2342, wps=68.6, ups=0.39, wpb=87.7, bsz=32, num_updates=7620, lr=4.89345e-05, gnorm=0.538, clip=10, loss_scale=512, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=40122
2023-01-08 10:08:54 - progress_bar.py[line:274] - INFO: epoch 001:   7640 / 144806 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1282, wps=69.8, ups=0.39, wpb=88.5, bsz=32, num_updates=7630, lr=4.8931e-05, gnorm=0.608, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=40148
2023-01-08 10:09:20 - progress_bar.py[line:274] - INFO: epoch 001:   7650 / 144806 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.18, wps=67.9, ups=0.39, wpb=87.5, bsz=32, num_updates=7640, lr=4.89274e-05, gnorm=0.434, clip=0, loss_scale=512, train_wall=26, gb_free=15.5, ema_decay=0.9999, wall=40175
2023-01-08 10:09:47 - progress_bar.py[line:274] - INFO: epoch 001:   7660 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1976, wps=66.8, ups=0.39, wpb=86, bsz=32, num_updates=7650, lr=4.89238e-05, gnorm=0.624, clip=10, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=40201
2023-01-08 10:10:13 - progress_bar.py[line:274] - INFO: epoch 001:   7670 / 144806 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=89.2, nsentences=32, sample_size=89.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2267, wps=70, ups=0.39, wpb=89.2, bsz=32, num_updates=7660, lr=4.89203e-05, gnorm=0.67, clip=10, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=40227
2023-01-08 10:10:38 - progress_bar.py[line:274] - INFO: epoch 001:   7680 / 144806 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2466, wps=69.9, ups=0.4, wpb=88, bsz=32, num_updates=7670, lr=4.89167e-05, gnorm=0.575, clip=0, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=40253
2023-01-08 10:11:04 - progress_bar.py[line:274] - INFO: epoch 001:   7690 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1893, wps=68.8, ups=0.4, wpb=86.4, bsz=32, num_updates=7680, lr=4.89131e-05, gnorm=0.638, clip=10, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=40279
2023-01-08 10:11:30 - progress_bar.py[line:274] - INFO: epoch 001:   7700 / 144806 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2222, wps=69, ups=0.39, wpb=88.1, bsz=32, num_updates=7690, lr=4.89096e-05, gnorm=0.522, clip=0, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=40305
2023-01-08 10:11:56 - progress_bar.py[line:274] - INFO: epoch 001:   7710 / 144806 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.1726, wps=68.1, ups=0.39, wpb=87.5, bsz=32, num_updates=7700, lr=4.8906e-05, gnorm=0.567, clip=10, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=40331
2023-01-08 10:12:22 - progress_bar.py[line:274] - INFO: epoch 001:   7720 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1834, wps=68, ups=0.39, wpb=87.4, bsz=32, num_updates=7710, lr=4.89024e-05, gnorm=0.901, clip=10, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=40357
2023-01-08 10:12:48 - progress_bar.py[line:274] - INFO: epoch 001:   7730 / 144806 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1348, wps=69.6, ups=0.4, wpb=88.1, bsz=32, num_updates=7720, lr=4.88989e-05, gnorm=0.526, clip=0, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=40383
2023-01-08 10:13:14 - progress_bar.py[line:274] - INFO: epoch 001:   7740 / 144806 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1484, wps=68.9, ups=0.39, wpb=88.7, bsz=32, num_updates=7730, lr=4.88953e-05, gnorm=0.431, clip=0, loss_scale=512, train_wall=26, gb_free=15.6, ema_decay=0.9999, wall=40409
2023-01-08 10:13:40 - progress_bar.py[line:274] - INFO: epoch 001:   7750 / 144806 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1195, wps=69.3, ups=0.4, wpb=87.2, bsz=32, num_updates=7740, lr=4.88917e-05, gnorm=0.522, clip=10, loss_scale=512, train_wall=25, gb_free=14.9, ema_decay=0.9999, wall=40434
2023-01-08 10:14:06 - progress_bar.py[line:274] - INFO: epoch 001:   7760 / 144806 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2349, wps=68.9, ups=0.39, wpb=87.9, bsz=32, num_updates=7750, lr=4.88882e-05, gnorm=0.461, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=40460
2023-01-08 10:14:32 - progress_bar.py[line:274] - INFO: epoch 001:   7770 / 144806 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1935, wps=68.4, ups=0.39, wpb=87.5, bsz=32, num_updates=7760, lr=4.88846e-05, gnorm=0.44, clip=0, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=40486
2023-01-08 10:14:58 - progress_bar.py[line:274] - INFO: epoch 001:   7780 / 144806 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1951, wps=67.2, ups=0.39, wpb=87.1, bsz=32, num_updates=7770, lr=4.8881e-05, gnorm=0.503, clip=0, loss_scale=512, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=40513
2023-01-08 10:15:23 - progress_bar.py[line:274] - INFO: epoch 001:   7790 / 144806 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2561, wps=69.3, ups=0.4, wpb=87.2, bsz=32, num_updates=7780, lr=4.88775e-05, gnorm=0.497, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=40538
2023-01-08 10:15:49 - progress_bar.py[line:274] - INFO: epoch 001:   7800 / 144806 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2177, wps=70.3, ups=0.4, wpb=87.8, bsz=32, num_updates=7790, lr=4.88739e-05, gnorm=0.593, clip=20, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=40564
2023-01-08 10:16:14 - progress_bar.py[line:274] - INFO: epoch 001:   7810 / 144806 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2264, wps=69.2, ups=0.4, wpb=86.8, bsz=32, num_updates=7800, lr=4.88703e-05, gnorm=0.412, clip=0, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=40589
2023-01-08 10:16:40 - progress_bar.py[line:274] - INFO: epoch 001:   7820 / 144806 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1731, wps=68.8, ups=0.39, wpb=87.5, bsz=32, num_updates=7810, lr=4.88668e-05, gnorm=0.544, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=40615
2023-01-08 10:17:06 - progress_bar.py[line:274] - INFO: epoch 001:   7830 / 144806 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1757, wps=68.7, ups=0.39, wpb=87.2, bsz=32, num_updates=7820, lr=4.88632e-05, gnorm=0.478, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=40641
2023-01-08 10:17:32 - progress_bar.py[line:274] - INFO: epoch 001:   7840 / 144806 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1856, wps=68.5, ups=0.39, wpb=87.2, bsz=32, num_updates=7830, lr=4.88596e-05, gnorm=0.459, clip=0, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=40667
2023-01-08 10:17:58 - progress_bar.py[line:274] - INFO: epoch 001:   7850 / 144806 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.2209, wps=69.1, ups=0.4, wpb=87.1, bsz=32, num_updates=7840, lr=4.88561e-05, gnorm=0.488, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=40693
2023-01-08 10:18:24 - progress_bar.py[line:274] - INFO: epoch 001:   7860 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2195, wps=67.7, ups=0.39, wpb=86.9, bsz=32, num_updates=7850, lr=4.88525e-05, gnorm=0.416, clip=0, loss_scale=512, train_wall=26, gb_free=15.4, ema_decay=0.9999, wall=40719
2023-01-08 10:18:50 - progress_bar.py[line:274] - INFO: epoch 001:   7870 / 144806 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2338, wps=67.9, ups=0.39, wpb=87.3, bsz=32, num_updates=7860, lr=4.88489e-05, gnorm=0.504, clip=0, loss_scale=512, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=40745
2023-01-08 10:19:16 - progress_bar.py[line:274] - INFO: epoch 001:   7880 / 144806 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.2023, wps=68, ups=0.39, wpb=86.7, bsz=32, num_updates=7870, lr=4.88454e-05, gnorm=0.613, clip=0, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=40771
2023-01-08 10:19:42 - progress_bar.py[line:274] - INFO: epoch 001:   7890 / 144806 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2414, wps=70.5, ups=0.4, wpb=88.9, bsz=32, num_updates=7880, lr=4.88418e-05, gnorm=0.464, clip=0, loss_scale=512, train_wall=25, gb_free=15, ema_decay=0.9999, wall=40796
2023-01-08 10:20:07 - progress_bar.py[line:274] - INFO: epoch 001:   7900 / 144806 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2278, wps=68.9, ups=0.39, wpb=87.8, bsz=32, num_updates=7890, lr=4.88382e-05, gnorm=0.5, clip=0, loss_scale=512, train_wall=25, gb_free=15.3, ema_decay=0.9999, wall=40822
2023-01-08 10:20:33 - progress_bar.py[line:274] - INFO: epoch 001:   7910 / 144806 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2244, wps=68.2, ups=0.39, wpb=86.8, bsz=32, num_updates=7900, lr=4.88347e-05, gnorm=0.516, clip=0, loss_scale=512, train_wall=25, gb_free=15.4, ema_decay=0.9999, wall=40848
2023-01-08 10:20:59 - progress_bar.py[line:274] - INFO: epoch 001:   7920 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2368, wps=68.8, ups=0.4, wpb=86.8, bsz=32, num_updates=7910, lr=4.88311e-05, gnorm=0.554, clip=10, loss_scale=512, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=40874
2023-01-08 10:21:25 - progress_bar.py[line:274] - INFO: epoch 001:   7930 / 144806 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2, wps=68.5, ups=0.39, wpb=87.2, bsz=32, num_updates=7920, lr=4.88275e-05, gnorm=0.488, clip=0, loss_scale=512, train_wall=25, gb_free=15.2, ema_decay=0.9999, wall=40900
2023-01-08 10:21:40 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 10:21:53 - progress_bar.py[line:274] - INFO: epoch 001:   7941 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.476, nsentences=32, sample_size=88.476, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2367, wps=67.6, ups=0.36, wpb=88.5, bsz=32, num_updates=7930, lr=4.8824e-05, gnorm=0.599, clip=10, loss_scale=256, train_wall=27, gb_free=15.2, ema_decay=0.9999, wall=40928
2023-01-08 10:22:19 - progress_bar.py[line:274] - INFO: epoch 001:   7951 / 144806 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.2273, wps=67.1, ups=0.39, wpb=86, bsz=32, num_updates=7940, lr=4.88204e-05, gnorm=0.544, clip=0, loss_scale=256, train_wall=26, gb_free=15.2, ema_decay=0.9999, wall=40954
2023-01-08 10:22:45 - progress_bar.py[line:274] - INFO: epoch 001:   7961 / 144806 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1786, wps=69.2, ups=0.39, wpb=88.1, bsz=32, num_updates=7950, lr=4.88168e-05, gnorm=0.488, clip=0, loss_scale=256, train_wall=25, gb_free=15.5, ema_decay=0.9999, wall=40980
2023-01-08 10:23:11 - progress_bar.py[line:274] - INFO: epoch 001:   7971 / 144806 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1939, wps=68.1, ups=0.39, wpb=87, bsz=32, num_updates=7960, lr=4.88133e-05, gnorm=0.6, clip=0, loss_scale=256, train_wall=26, gb_free=15, ema_decay=0.9999, wall=41006
2023-01-08 10:23:37 - progress_bar.py[line:274] - INFO: epoch 001:   7981 / 144806 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.2267, wps=66.5, ups=0.39, wpb=85.5, bsz=32, num_updates=7970, lr=4.88097e-05, gnorm=0.516, clip=0, loss_scale=256, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=41032
2023-01-08 10:24:03 - progress_bar.py[line:274] - INFO: epoch 001:   7991 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2597, wps=69.7, ups=0.4, wpb=87.7, bsz=32, num_updates=7980, lr=4.88061e-05, gnorm=0.686, clip=20, loss_scale=256, train_wall=25, gb_free=15.1, ema_decay=0.9999, wall=41058
2023-01-08 10:24:29 - progress_bar.py[line:274] - INFO: epoch 001:   8001 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1957, wps=67.2, ups=0.39, wpb=85.9, bsz=32, num_updates=7990, lr=4.88026e-05, gnorm=0.529, clip=0, loss_scale=256, train_wall=26, gb_free=15.1, ema_decay=0.9999, wall=41084
2023-01-08 10:24:56 - progress_bar.py[line:274] - INFO: epoch 001:   8011 / 144806 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3052, wps=67.6, ups=0.39, wpb=87.6, bsz=32, num_updates=8000, lr=4.8799e-05, gnorm=0.444, clip=0, loss_scale=256, train_wall=26, gb_free=15.3, ema_decay=0.9999, wall=41111
2023-01-08 10:24:56 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 10:24:58 - train.py[line:549] - INFO: 0 / 6234
2023-01-08 10:24:58 - train.py[line:551] - INFO: load:1.13 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 10:25:00 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.36 GiB (GPU 0; 39.59 GiB total capacity; 8.06 GiB already allocated; 4.36 GiB free; 27.28 GiB reserved in total by PyTorch)
2023-01-08 10:25:00 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 18        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8249 MB |   12618 MB |    3668 TB |    3668 TB |
|       from large pool |    8075 MB |   12444 MB |    3666 TB |    3666 TB |
|       from small pool |     174 MB |     174 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8249 MB |   12618 MB |    3668 TB |    3668 TB |
|       from large pool |    8075 MB |   12444 MB |    3666 TB |    3666 TB |
|       from small pool |     174 MB |     174 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   27930 MB |   32356 MB |  196124 MB |  168194 MB |
|       from large pool |   27754 MB |   32176 MB |  195752 MB |  167998 MB |
|       from small pool |     176 MB |     180 MB |     372 MB |     196 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19680 MB |   22953 MB |    3410 TB |    3410 TB |
|       from large pool |   19678 MB |   22950 MB |    3408 TB |    3408 TB |
|       from small pool |       1 MB |       2 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4633    |    4647    |  197129 K  |  197124 K  |
|       from large pool |     698    |     710    |   66835 K  |   66834 K  |
|       from small pool |    3935    |    3943    |  130293 K  |  130290 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4633    |    4647    |  197129 K  |  197124 K  |
|       from large pool |     698    |     710    |   66835 K  |   66834 K  |
|       from small pool |    3935    |    3943    |  130293 K  |  130290 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     185    |     189    |     562    |     377    |
|       from large pool |      97    |      99    |     376    |     279    |
|       from small pool |      88    |      90    |     186    |      98    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     116    |     129    |  142217 K  |  142217 K  |
|       from large pool |      68    |      70    |   32613 K  |   32613 K  |
|       from small pool |      48    |      63    |  109603 K  |  109603 K  |
|===========================================================================|

2023-01-08 10:25:00 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-08 10:25:00 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-08 10:28:29 - train.py[line:549] - INFO: 200 / 6234
2023-01-08 10:28:29 - train.py[line:551] - INFO: load:1.15 valid_run:211.74 task_valid:205.67 collect_output:2.70
2023-01-08 10:31:57 - train.py[line:549] - INFO: 400 / 6234
2023-01-08 10:31:57 - train.py[line:551] - INFO: load:1.18 valid_run:419.56 task_valid:407.70 collect_output:6.51
2023-01-08 10:35:29 - train.py[line:549] - INFO: 600 / 6234
2023-01-08 10:35:29 - train.py[line:551] - INFO: load:1.20 valid_run:630.94 task_valid:610.86 collect_output:12.79
2023-01-08 10:38:59 - train.py[line:549] - INFO: 800 / 6234
2023-01-08 10:38:59 - train.py[line:551] - INFO: load:1.23 valid_run:841.08 task_valid:810.22 collect_output:21.64
2023-01-08 10:42:28 - train.py[line:549] - INFO: 1000 / 6234
2023-01-08 10:42:28 - train.py[line:551] - INFO: load:1.25 valid_run:1049.92 task_valid:1014.58 collect_output:24.17
2023-01-08 10:46:00 - train.py[line:549] - INFO: 1200 / 6234
2023-01-08 10:46:00 - train.py[line:551] - INFO: load:1.28 valid_run:1261.80 task_valid:1220.47 collect_output:28.18
2023-01-08 10:49:32 - train.py[line:549] - INFO: 1400 / 6234
2023-01-08 10:49:32 - train.py[line:551] - INFO: load:1.30 valid_run:1473.96 task_valid:1425.40 collect_output:33.42
2023-01-08 10:53:02 - train.py[line:549] - INFO: 1600 / 6234
2023-01-08 10:53:03 - train.py[line:551] - INFO: load:1.33 valid_run:1684.23 task_valid:1628.26 collect_output:38.88
2023-01-08 10:56:36 - train.py[line:549] - INFO: 1800 / 6234
2023-01-08 10:56:36 - train.py[line:551] - INFO: load:1.35 valid_run:1897.20 task_valid:1832.21 collect_output:45.96
2023-01-08 11:00:05 - train.py[line:549] - INFO: 2000 / 6234
2023-01-08 11:00:05 - train.py[line:551] - INFO: load:1.37 valid_run:2106.94 task_valid:2030.42 collect_output:55.57
2023-01-08 11:03:34 - train.py[line:549] - INFO: 2200 / 6234
2023-01-08 11:03:34 - train.py[line:551] - INFO: load:1.40 valid_run:2315.42 task_valid:2232.52 collect_output:59.95
2023-01-08 11:07:04 - train.py[line:549] - INFO: 2400 / 6234
2023-01-08 11:07:04 - train.py[line:551] - INFO: load:1.43 valid_run:2525.51 task_valid:2436.59 collect_output:63.97
2023-01-08 11:10:31 - train.py[line:549] - INFO: 2600 / 6234
2023-01-08 11:10:31 - train.py[line:551] - INFO: load:1.45 valid_run:2732.12 task_valid:2636.09 collect_output:69.14
2023-01-08 11:14:00 - train.py[line:549] - INFO: 2800 / 6234
2023-01-08 11:14:00 - train.py[line:551] - INFO: load:1.48 valid_run:2941.68 task_valid:2840.93 collect_output:71.90
2023-01-08 11:17:30 - train.py[line:549] - INFO: 3000 / 6234
2023-01-08 11:17:30 - train.py[line:551] - INFO: load:1.50 valid_run:3150.92 task_valid:3043.71 collect_output:76.40
2023-01-08 11:20:59 - train.py[line:549] - INFO: 3200 / 6234
2023-01-08 11:20:59 - train.py[line:551] - INFO: load:1.53 valid_run:3360.48 task_valid:3243.72 collect_output:83.98
2023-01-08 11:24:30 - train.py[line:549] - INFO: 3400 / 6234
2023-01-08 11:24:30 - train.py[line:551] - INFO: load:1.55 valid_run:3570.52 task_valid:3446.45 collect_output:89.32
2023-01-08 11:27:59 - train.py[line:549] - INFO: 3600 / 6234
2023-01-08 11:27:59 - train.py[line:551] - INFO: load:1.58 valid_run:3779.71 task_valid:3651.46 collect_output:91.54
2023-01-08 11:31:30 - train.py[line:549] - INFO: 3800 / 6234
2023-01-08 11:31:30 - train.py[line:551] - INFO: load:1.60 valid_run:3990.99 task_valid:3856.37 collect_output:95.85
2023-01-08 11:34:59 - train.py[line:549] - INFO: 4000 / 6234
2023-01-08 11:34:59 - train.py[line:551] - INFO: load:1.63 valid_run:4199.63 task_valid:4059.66 collect_output:99.22
2023-01-08 11:38:30 - train.py[line:549] - INFO: 4200 / 6234
2023-01-08 11:38:30 - train.py[line:551] - INFO: load:1.65 valid_run:4410.83 task_valid:4263.72 collect_output:104.38
2023-01-08 11:42:45 - train.py[line:549] - INFO: 4400 / 6234
2023-01-08 11:42:45 - train.py[line:551] - INFO: load:1.68 valid_run:4665.35 task_valid:4514.98 collect_output:105.05
2023-01-08 11:47:03 - train.py[line:549] - INFO: 4600 / 6234
2023-01-08 11:47:03 - train.py[line:551] - INFO: load:1.70 valid_run:4923.36 task_valid:4769.51 collect_output:105.78
2023-01-08 11:51:13 - train.py[line:549] - INFO: 4800 / 6234
2023-01-08 11:51:13 - train.py[line:551] - INFO: load:1.73 valid_run:5173.24 task_valid:5016.15 collect_output:106.45
2023-01-08 11:55:22 - train.py[line:549] - INFO: 5000 / 6234
2023-01-08 11:55:22 - train.py[line:551] - INFO: load:1.75 valid_run:5422.07 task_valid:5261.77 collect_output:107.11
2023-01-08 11:59:31 - train.py[line:549] - INFO: 5200 / 6234
2023-01-08 11:59:31 - train.py[line:551] - INFO: load:1.78 valid_run:5670.78 task_valid:5507.27 collect_output:107.77
2023-01-08 12:03:37 - train.py[line:549] - INFO: 5400 / 6234
2023-01-08 12:03:37 - train.py[line:551] - INFO: load:1.80 valid_run:5916.97 task_valid:5750.22 collect_output:108.44
2023-01-08 12:07:51 - train.py[line:549] - INFO: 5600 / 6234
2023-01-08 12:07:51 - train.py[line:551] - INFO: load:1.83 valid_run:6170.60 task_valid:6000.62 collect_output:109.11
2023-01-08 12:11:59 - train.py[line:549] - INFO: 5800 / 6234
2023-01-08 12:11:59 - train.py[line:551] - INFO: load:1.85 valid_run:6418.97 task_valid:6245.74 collect_output:109.79
2023-01-08 12:16:12 - train.py[line:549] - INFO: 6000 / 6234
2023-01-08 12:16:12 - train.py[line:551] - INFO: load:1.88 valid_run:6671.38 task_valid:6494.92 collect_output:110.46
2023-01-08 12:20:24 - train.py[line:549] - INFO: 6200 / 6234
2023-01-08 12:20:24 - train.py[line:551] - INFO: load:1.91 valid_run:6923.88 task_valid:6744.16 collect_output:111.13

====================================================================================================
SGG eval:     R @ 50: 0.5502;     R @ 100: 0.6171;     R @ 500: 0.6605;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3475;    mR @ 100: 0.4003;    mR @ 500: 0.4472;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.8840) (says:0.0000) (sitting on:0.7545) (standing on:0.1883) (using:0.6500) (walking in:0.0000) (walking on:0.7297) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-08 12:21:17 - train.py[line:487] - INFO: 0.6170761904761906

====================================================================================================
SGG eval:     R @ 50: 0.5502;     R @ 100: 0.6171;     R @ 500: 0.6605;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3475;    mR @ 100: 0.4003;    mR @ 500: 0.4472;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.8840) (says:0.0000) (sitting on:0.7545) (standing on:0.1883) (using:0.6500) (walking in:0.0000) (walking on:0.7297) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-08 12:21:17 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 12:21:18 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.332 | loss_v1 0 | loss_v2 0 | nll_loss 0.177 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.617076 | ppl 1.13 | vqa_score 0.5056 | wps 64.3 | wpb 72 | bsz 24 | num_updates 8000 | best_R@100 0.632103
2023-01-08 12:21:18 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2023-01-08 12:21:18 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_8000.pt
2023-01-08 12:21:58 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_8000.pt
2023-01-08 12:23:24 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.6170761904761906) (writing took 126.1816162597388 seconds)
2023-01-08 12:23:54 - progress_bar.py[line:274] - INFO: epoch 001:   8021 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2062, wps=0.2, ups=0, wpb=87.4, bsz=32, num_updates=8010, lr=4.87954e-05, gnorm=0.996, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=48248
2023-01-08 12:24:22 - progress_bar.py[line:274] - INFO: epoch 001:   8031 / 144806 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1706, wps=62.9, ups=0.36, wpb=88.3, bsz=32, num_updates=8020, lr=4.87919e-05, gnorm=0.616, clip=20, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=48277
2023-01-08 12:24:52 - progress_bar.py[line:274] - INFO: epoch 001:   8041 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2564, wps=58.8, ups=0.33, wpb=87.8, bsz=32, num_updates=8030, lr=4.87883e-05, gnorm=0.559, clip=0, loss_scale=256, train_wall=30, gb_free=14.6, ema_decay=0.9999, wall=48307
2023-01-08 12:25:21 - progress_bar.py[line:274] - INFO: epoch 001:   8051 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2645, wps=62.3, ups=0.36, wpb=87.6, bsz=32, num_updates=8040, lr=4.87847e-05, gnorm=0.666, clip=20, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=48336
2023-01-08 12:25:50 - progress_bar.py[line:274] - INFO: epoch 001:   8061 / 144806 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=85.4, nsentences=32, sample_size=85.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.2426, wps=59.7, ups=0.35, wpb=85.4, bsz=32, num_updates=8050, lr=4.87811e-05, gnorm=0.56, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=48365
2023-01-08 12:26:20 - progress_bar.py[line:274] - INFO: epoch 001:   8071 / 144806 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2761, wps=59.3, ups=0.34, wpb=87.3, bsz=32, num_updates=8060, lr=4.87776e-05, gnorm=0.532, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=48395
2023-01-08 12:26:51 - progress_bar.py[line:274] - INFO: epoch 001:   8081 / 144806 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2424, wps=57.1, ups=0.33, wpb=86.9, bsz=32, num_updates=8070, lr=4.8774e-05, gnorm=0.426, clip=0, loss_scale=256, train_wall=30, gb_free=15.2, ema_decay=0.9999, wall=48426
2023-01-08 12:27:21 - progress_bar.py[line:274] - INFO: epoch 001:   8091 / 144806 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2298, wps=60.6, ups=0.35, wpb=87.8, bsz=32, num_updates=8080, lr=4.87704e-05, gnorm=0.534, clip=0, loss_scale=256, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=48455
2023-01-08 12:27:50 - progress_bar.py[line:274] - INFO: epoch 001:   8101 / 144806 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.2036, wps=60.8, ups=0.35, wpb=87.2, bsz=32, num_updates=8090, lr=4.87669e-05, gnorm=0.45, clip=0, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=48485
2023-01-08 12:28:19 - progress_bar.py[line:274] - INFO: epoch 001:   8111 / 144806 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.2456, wps=60.3, ups=0.35, wpb=85.5, bsz=32, num_updates=8100, lr=4.87633e-05, gnorm=0.566, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=48513
2023-01-08 12:28:48 - progress_bar.py[line:274] - INFO: epoch 001:   8121 / 144806 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2237, wps=60.6, ups=0.35, wpb=86.5, bsz=32, num_updates=8110, lr=4.87597e-05, gnorm=0.511, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=48542
2023-01-08 12:29:17 - progress_bar.py[line:274] - INFO: epoch 001:   8131 / 144806 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2611, wps=60.4, ups=0.35, wpb=87.5, bsz=32, num_updates=8120, lr=4.87562e-05, gnorm=0.395, clip=0, loss_scale=256, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=48572
2023-01-08 12:29:46 - progress_bar.py[line:274] - INFO: epoch 001:   8141 / 144806 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.2061, wps=61.4, ups=0.35, wpb=87.2, bsz=32, num_updates=8130, lr=4.87526e-05, gnorm=0.576, clip=10, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=48601
2023-01-08 12:30:16 - progress_bar.py[line:274] - INFO: epoch 001:   8151 / 144806 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2176, wps=59.4, ups=0.34, wpb=87.2, bsz=32, num_updates=8140, lr=4.8749e-05, gnorm=0.531, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=48631
2023-01-08 12:30:45 - progress_bar.py[line:274] - INFO: epoch 001:   8161 / 144806 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2065, wps=62, ups=0.35, wpb=87.5, bsz=32, num_updates=8150, lr=4.87455e-05, gnorm=0.526, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=48660
2023-01-08 12:31:14 - progress_bar.py[line:274] - INFO: epoch 001:   8171 / 144806 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.2484, wps=60.6, ups=0.35, wpb=86.9, bsz=32, num_updates=8160, lr=4.87419e-05, gnorm=0.602, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=48689
2023-01-08 12:31:44 - progress_bar.py[line:274] - INFO: epoch 001:   8181 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3057, wps=59.3, ups=0.34, wpb=86.9, bsz=32, num_updates=8170, lr=4.87383e-05, gnorm=0.532, clip=0, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=48718
2023-01-08 12:32:12 - progress_bar.py[line:274] - INFO: epoch 001:   8191 / 144806 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.2364, wps=61.3, ups=0.35, wpb=87, bsz=32, num_updates=8180, lr=4.87348e-05, gnorm=0.588, clip=10, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=48747
2023-01-08 12:32:41 - progress_bar.py[line:274] - INFO: epoch 001:   8201 / 144806 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2468, wps=62.4, ups=0.35, wpb=88, bsz=32, num_updates=8190, lr=4.87312e-05, gnorm=0.491, clip=0, loss_scale=256, train_wall=28, gb_free=15, ema_decay=0.9999, wall=48776
2023-01-08 12:33:11 - progress_bar.py[line:274] - INFO: epoch 001:   8211 / 144806 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2848, wps=59.4, ups=0.34, wpb=86.5, bsz=32, num_updates=8200, lr=4.87276e-05, gnorm=0.537, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=48806
2023-01-08 12:33:40 - progress_bar.py[line:274] - INFO: epoch 001:   8221 / 144806 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.2883, wps=60.9, ups=0.35, wpb=86.8, bsz=32, num_updates=8210, lr=4.87241e-05, gnorm=0.622, clip=10, loss_scale=256, train_wall=28, gb_free=15, ema_decay=0.9999, wall=48835
2023-01-08 12:34:13 - progress_bar.py[line:274] - INFO: epoch 001:   8231 / 144806 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2821, wps=54.9, ups=0.31, wpb=87.6, bsz=32, num_updates=8220, lr=4.87205e-05, gnorm=0.501, clip=0, loss_scale=256, train_wall=32, gb_free=15.1, ema_decay=0.9999, wall=48867
2023-01-08 12:34:42 - progress_bar.py[line:274] - INFO: epoch 001:   8241 / 144806 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.226, wps=60.2, ups=0.35, wpb=86.2, bsz=32, num_updates=8230, lr=4.87169e-05, gnorm=0.533, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=48897
2023-01-08 12:35:11 - progress_bar.py[line:274] - INFO: epoch 001:   8251 / 144806 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.245, wps=61.9, ups=0.35, wpb=88.8, bsz=32, num_updates=8240, lr=4.87134e-05, gnorm=0.474, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=48926
2023-01-08 12:35:41 - progress_bar.py[line:274] - INFO: epoch 001:   8261 / 144806 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2579, wps=60.3, ups=0.34, wpb=88.1, bsz=32, num_updates=8250, lr=4.87098e-05, gnorm=0.461, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=48955
2023-01-08 12:36:10 - progress_bar.py[line:274] - INFO: epoch 001:   8271 / 144806 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2727, wps=59.7, ups=0.34, wpb=86.8, bsz=32, num_updates=8260, lr=4.87062e-05, gnorm=0.486, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=48985
2023-01-08 12:36:39 - progress_bar.py[line:274] - INFO: epoch 001:   8281 / 144806 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1636, wps=60.9, ups=0.35, wpb=86.5, bsz=32, num_updates=8270, lr=4.87027e-05, gnorm=0.531, clip=0, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=49014
2023-01-08 12:37:08 - progress_bar.py[line:274] - INFO: epoch 001:   8291 / 144806 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2361, wps=61.9, ups=0.35, wpb=87.6, bsz=32, num_updates=8280, lr=4.86991e-05, gnorm=0.48, clip=0, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=49043
2023-01-08 12:37:37 - progress_bar.py[line:274] - INFO: epoch 001:   8301 / 144806 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.2256, wps=61.7, ups=0.35, wpb=88, bsz=32, num_updates=8290, lr=4.86955e-05, gnorm=0.551, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=49072
2023-01-08 12:38:06 - progress_bar.py[line:274] - INFO: epoch 001:   8311 / 144806 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.25, wps=60.2, ups=0.35, wpb=86.9, bsz=32, num_updates=8300, lr=4.8692e-05, gnorm=0.573, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=49101
2023-01-08 12:38:35 - progress_bar.py[line:274] - INFO: epoch 001:   8321 / 144806 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2179, wps=63, ups=0.36, wpb=88.4, bsz=32, num_updates=8310, lr=4.86884e-05, gnorm=0.517, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=49130
2023-01-08 12:39:04 - progress_bar.py[line:274] - INFO: epoch 001:   8331 / 144806 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2989, wps=60.2, ups=0.35, wpb=87, bsz=32, num_updates=8320, lr=4.86848e-05, gnorm=0.501, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=49159
2023-01-08 12:39:34 - progress_bar.py[line:274] - INFO: epoch 001:   8341 / 144806 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2313, wps=60.7, ups=0.35, wpb=87.9, bsz=32, num_updates=8330, lr=4.86813e-05, gnorm=0.48, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=49189
2023-01-08 12:40:02 - progress_bar.py[line:274] - INFO: epoch 001:   8351 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2428, wps=61.8, ups=0.36, wpb=86.6, bsz=32, num_updates=8340, lr=4.86777e-05, gnorm=0.527, clip=0, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=49217
2023-01-08 12:40:31 - progress_bar.py[line:274] - INFO: epoch 001:   8361 / 144806 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2465, wps=62.7, ups=0.36, wpb=88.2, bsz=32, num_updates=8350, lr=4.86741e-05, gnorm=0.591, clip=10, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=49246
2023-01-08 12:41:00 - progress_bar.py[line:274] - INFO: epoch 001:   8371 / 144806 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.2174, wps=60.8, ups=0.35, wpb=87.2, bsz=32, num_updates=8360, lr=4.86706e-05, gnorm=0.448, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=49275
2023-01-08 12:41:29 - progress_bar.py[line:274] - INFO: epoch 001:   8381 / 144806 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2649, wps=62, ups=0.35, wpb=88.2, bsz=32, num_updates=8370, lr=4.8667e-05, gnorm=0.534, clip=0, loss_scale=256, train_wall=28, gb_free=15, ema_decay=0.9999, wall=49304
2023-01-08 12:41:58 - progress_bar.py[line:274] - INFO: epoch 001:   8391 / 144806 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2625, wps=60.9, ups=0.35, wpb=86.9, bsz=32, num_updates=8380, lr=4.86634e-05, gnorm=0.629, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=49333
2023-01-08 12:42:27 - progress_bar.py[line:274] - INFO: epoch 001:   8401 / 144806 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.2138, wps=61.5, ups=0.35, wpb=87.3, bsz=32, num_updates=8390, lr=4.86599e-05, gnorm=0.566, clip=0, loss_scale=256, train_wall=28, gb_free=15, ema_decay=0.9999, wall=49362
2023-01-08 12:42:56 - progress_bar.py[line:274] - INFO: epoch 001:   8411 / 144806 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2562, wps=61.1, ups=0.35, wpb=87.3, bsz=32, num_updates=8400, lr=4.86563e-05, gnorm=0.446, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=49391
2023-01-08 12:43:25 - progress_bar.py[line:274] - INFO: epoch 001:   8421 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2821, wps=61.8, ups=0.35, wpb=88.1, bsz=32, num_updates=8410, lr=4.86527e-05, gnorm=0.529, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=49420
2023-01-08 12:43:54 - progress_bar.py[line:274] - INFO: epoch 001:   8431 / 144806 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.2941, wps=60.3, ups=0.35, wpb=86.4, bsz=32, num_updates=8420, lr=4.86492e-05, gnorm=0.621, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=49449
2023-01-08 12:44:22 - progress_bar.py[line:274] - INFO: epoch 001:   8441 / 144806 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2364, wps=62.2, ups=0.36, wpb=87.5, bsz=32, num_updates=8430, lr=4.86456e-05, gnorm=0.515, clip=0, loss_scale=256, train_wall=28, gb_free=15, ema_decay=0.9999, wall=49477
2023-01-08 12:44:51 - progress_bar.py[line:274] - INFO: epoch 001:   8451 / 144806 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2194, wps=62.2, ups=0.35, wpb=88.3, bsz=32, num_updates=8440, lr=4.8642e-05, gnorm=0.525, clip=0, loss_scale=512, train_wall=28, gb_free=14.4, ema_decay=0.9999, wall=49506
2023-01-08 12:45:20 - progress_bar.py[line:274] - INFO: epoch 001:   8461 / 144806 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2115, wps=61.8, ups=0.35, wpb=88.1, bsz=32, num_updates=8450, lr=4.86385e-05, gnorm=0.495, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=49535
2023-01-08 12:45:49 - progress_bar.py[line:274] - INFO: epoch 001:   8471 / 144806 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2137, wps=61.5, ups=0.35, wpb=88.1, bsz=32, num_updates=8460, lr=4.86349e-05, gnorm=0.526, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=49564
2023-01-08 12:46:18 - progress_bar.py[line:274] - INFO: epoch 001:   8481 / 144806 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2515, wps=60.4, ups=0.35, wpb=87.2, bsz=32, num_updates=8470, lr=4.86313e-05, gnorm=0.482, clip=0, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=49593
2023-01-08 12:46:47 - progress_bar.py[line:274] - INFO: epoch 001:   8491 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2575, wps=59.2, ups=0.34, wpb=86.3, bsz=32, num_updates=8480, lr=4.86278e-05, gnorm=0.555, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=49622
2023-01-08 12:47:16 - progress_bar.py[line:274] - INFO: epoch 001:   8501 / 144806 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2333, wps=60.7, ups=0.35, wpb=87.5, bsz=32, num_updates=8490, lr=4.86242e-05, gnorm=0.651, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=49651
2023-01-08 12:47:45 - progress_bar.py[line:274] - INFO: epoch 001:   8511 / 144806 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.2395, wps=61.5, ups=0.35, wpb=87.3, bsz=32, num_updates=8500, lr=4.86206e-05, gnorm=0.567, clip=0, loss_scale=512, train_wall=28, gb_free=15, ema_decay=0.9999, wall=49680
2023-01-08 12:48:14 - progress_bar.py[line:274] - INFO: epoch 001:   8521 / 144806 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.3067, wps=60.7, ups=0.34, wpb=88.4, bsz=32, num_updates=8510, lr=4.86171e-05, gnorm=0.631, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=49710
2023-01-08 12:48:44 - progress_bar.py[line:274] - INFO: epoch 001:   8531 / 144806 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2712, wps=59.8, ups=0.34, wpb=86.9, bsz=32, num_updates=8520, lr=4.86135e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=49739
2023-01-08 12:49:13 - progress_bar.py[line:274] - INFO: epoch 001:   8541 / 144806 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2803, wps=60.9, ups=0.35, wpb=87.3, bsz=32, num_updates=8530, lr=4.86099e-05, gnorm=0.568, clip=0, loss_scale=512, train_wall=29, gb_free=14.8, ema_decay=0.9999, wall=49768
2023-01-08 12:49:42 - progress_bar.py[line:274] - INFO: epoch 001:   8551 / 144806 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.2472, wps=59.2, ups=0.35, wpb=85.8, bsz=32, num_updates=8540, lr=4.86064e-05, gnorm=0.565, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=49797
2023-01-08 12:50:11 - progress_bar.py[line:274] - INFO: epoch 001:   8561 / 144806 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1781, wps=60.6, ups=0.35, wpb=86.7, bsz=32, num_updates=8550, lr=4.86028e-05, gnorm=0.539, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=49826
2023-01-08 12:50:40 - progress_bar.py[line:274] - INFO: epoch 001:   8571 / 144806 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.2327, wps=60.8, ups=0.35, wpb=87.8, bsz=32, num_updates=8560, lr=4.85992e-05, gnorm=0.504, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=49855
2023-01-08 12:51:09 - progress_bar.py[line:274] - INFO: epoch 001:   8581 / 144806 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.3101, wps=61.1, ups=0.35, wpb=87.3, bsz=32, num_updates=8570, lr=4.85957e-05, gnorm=0.598, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=49884
2023-01-08 12:51:38 - progress_bar.py[line:274] - INFO: epoch 001:   8591 / 144806 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2333, wps=60.1, ups=0.34, wpb=87.9, bsz=32, num_updates=8580, lr=4.85921e-05, gnorm=0.431, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=49913
2023-01-08 12:52:07 - progress_bar.py[line:274] - INFO: epoch 001:   8601 / 144806 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2798, wps=60, ups=0.35, wpb=86.3, bsz=32, num_updates=8590, lr=4.85885e-05, gnorm=0.552, clip=0, loss_scale=512, train_wall=29, gb_free=15.7, ema_decay=0.9999, wall=49942
2023-01-08 12:52:36 - progress_bar.py[line:274] - INFO: epoch 001:   8611 / 144806 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2761, wps=59.8, ups=0.35, wpb=85.9, bsz=32, num_updates=8600, lr=4.8585e-05, gnorm=0.511, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=49971
2023-01-08 12:53:05 - progress_bar.py[line:274] - INFO: epoch 001:   8621 / 144806 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.283, wps=60.4, ups=0.35, wpb=86.9, bsz=32, num_updates=8610, lr=4.85814e-05, gnorm=0.607, clip=20, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=50000
2023-01-08 12:53:34 - progress_bar.py[line:274] - INFO: epoch 001:   8631 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2632, wps=61.5, ups=0.35, wpb=88, bsz=32, num_updates=8620, lr=4.85778e-05, gnorm=0.524, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=50029
2023-01-08 12:54:02 - progress_bar.py[line:274] - INFO: epoch 001:   8641 / 144806 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2683, wps=61.9, ups=0.36, wpb=87.2, bsz=32, num_updates=8630, lr=4.85743e-05, gnorm=0.641, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=50057
2023-01-08 12:54:31 - progress_bar.py[line:274] - INFO: epoch 001:   8651 / 144806 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2711, wps=61.8, ups=0.35, wpb=87.8, bsz=32, num_updates=8640, lr=4.85707e-05, gnorm=0.564, clip=0, loss_scale=512, train_wall=28, gb_free=14.8, ema_decay=0.9999, wall=50086
2023-01-08 12:55:00 - progress_bar.py[line:274] - INFO: epoch 001:   8661 / 144806 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.275, wps=61.3, ups=0.35, wpb=87, bsz=32, num_updates=8650, lr=4.85671e-05, gnorm=0.476, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=50115
2023-01-08 12:55:28 - progress_bar.py[line:274] - INFO: epoch 001:   8671 / 144806 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2754, wps=61.2, ups=0.35, wpb=86.7, bsz=32, num_updates=8660, lr=4.85636e-05, gnorm=0.588, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=50143
2023-01-08 12:55:57 - progress_bar.py[line:274] - INFO: epoch 001:   8681 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2442, wps=61.4, ups=0.35, wpb=87.4, bsz=32, num_updates=8670, lr=4.856e-05, gnorm=0.744, clip=10, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=50172
2023-01-08 12:56:26 - progress_bar.py[line:274] - INFO: epoch 001:   8691 / 144806 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2697, wps=60.3, ups=0.34, wpb=87.7, bsz=32, num_updates=8680, lr=4.85564e-05, gnorm=0.549, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=50201
2023-01-08 12:56:55 - progress_bar.py[line:274] - INFO: epoch 001:   8701 / 144806 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.28, wps=60.5, ups=0.35, wpb=87.6, bsz=32, num_updates=8690, lr=4.85529e-05, gnorm=0.558, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=50230
2023-01-08 12:57:25 - progress_bar.py[line:274] - INFO: epoch 001:   8711 / 144806 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2963, wps=60.8, ups=0.34, wpb=88.7, bsz=32, num_updates=8700, lr=4.85493e-05, gnorm=0.562, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=50260
2023-01-08 12:57:54 - progress_bar.py[line:274] - INFO: epoch 001:   8721 / 144806 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2706, wps=58.9, ups=0.34, wpb=86.3, bsz=32, num_updates=8710, lr=4.85457e-05, gnorm=0.65, clip=20, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=50289
2023-01-08 12:58:23 - progress_bar.py[line:274] - INFO: epoch 001:   8731 / 144806 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.2267, wps=60.9, ups=0.35, wpb=87.4, bsz=32, num_updates=8720, lr=4.85422e-05, gnorm=0.581, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=50318
2023-01-08 12:58:52 - progress_bar.py[line:274] - INFO: epoch 001:   8741 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2585, wps=60.9, ups=0.35, wpb=86.7, bsz=32, num_updates=8730, lr=4.85386e-05, gnorm=0.419, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=50347
2023-01-08 12:59:21 - progress_bar.py[line:274] - INFO: epoch 001:   8751 / 144806 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.3113, wps=61.4, ups=0.35, wpb=88.1, bsz=32, num_updates=8740, lr=4.8535e-05, gnorm=0.467, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=50376
2023-01-08 12:59:50 - progress_bar.py[line:274] - INFO: epoch 001:   8761 / 144806 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2749, wps=60.5, ups=0.35, wpb=86.7, bsz=32, num_updates=8750, lr=4.85315e-05, gnorm=0.47, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=50405
2023-01-08 13:00:20 - progress_bar.py[line:274] - INFO: epoch 001:   8771 / 144806 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.239, wps=59.4, ups=0.34, wpb=86.7, bsz=32, num_updates=8760, lr=4.85279e-05, gnorm=0.566, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=50435
2023-01-08 13:00:49 - progress_bar.py[line:274] - INFO: epoch 001:   8781 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3077, wps=60.9, ups=0.35, wpb=87.3, bsz=32, num_updates=8770, lr=4.85243e-05, gnorm=0.451, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=50464
2023-01-08 13:01:18 - progress_bar.py[line:274] - INFO: epoch 001:   8791 / 144806 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2621, wps=60.6, ups=0.35, wpb=87.7, bsz=32, num_updates=8780, lr=4.85208e-05, gnorm=0.555, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=50493
2023-01-08 13:01:46 - progress_bar.py[line:274] - INFO: epoch 001:   8801 / 144806 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=89, nsentences=32, sample_size=89, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2955, wps=63.3, ups=0.36, wpb=89, bsz=32, num_updates=8790, lr=4.85172e-05, gnorm=0.48, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=50521
2023-01-08 13:02:15 - progress_bar.py[line:274] - INFO: epoch 001:   8811 / 144806 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2484, wps=61.2, ups=0.35, wpb=86.6, bsz=32, num_updates=8800, lr=4.85136e-05, gnorm=0.458, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=50550
2023-01-08 13:02:44 - progress_bar.py[line:274] - INFO: epoch 001:   8821 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.298, wps=60.4, ups=0.34, wpb=88.2, bsz=32, num_updates=8810, lr=4.85101e-05, gnorm=0.472, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=50579
2023-01-08 13:03:13 - progress_bar.py[line:274] - INFO: epoch 001:   8831 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3309, wps=62.4, ups=0.35, wpb=88.7, bsz=32, num_updates=8820, lr=4.85065e-05, gnorm=0.614, clip=10, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=50608
2023-01-08 13:03:42 - progress_bar.py[line:274] - INFO: epoch 001:   8841 / 144806 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2606, wps=61.5, ups=0.35, wpb=87.4, bsz=32, num_updates=8830, lr=4.85029e-05, gnorm=0.636, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=50637
2023-01-08 13:04:11 - progress_bar.py[line:274] - INFO: epoch 001:   8851 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3092, wps=59.6, ups=0.34, wpb=87.5, bsz=32, num_updates=8840, lr=4.84994e-05, gnorm=0.616, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=50666
2023-01-08 13:04:40 - progress_bar.py[line:274] - INFO: epoch 001:   8861 / 144806 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2545, wps=60.8, ups=0.35, wpb=87.1, bsz=32, num_updates=8850, lr=4.84958e-05, gnorm=0.525, clip=10, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=50695
2023-01-08 13:05:09 - progress_bar.py[line:274] - INFO: epoch 001:   8871 / 144806 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2372, wps=60.5, ups=0.35, wpb=86.1, bsz=32, num_updates=8860, lr=4.84922e-05, gnorm=0.563, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=50724
2023-01-08 13:05:38 - progress_bar.py[line:274] - INFO: epoch 001:   8881 / 144806 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3106, wps=59.4, ups=0.34, wpb=86.8, bsz=32, num_updates=8870, lr=4.84887e-05, gnorm=0.518, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=50753
2023-01-08 13:06:07 - progress_bar.py[line:274] - INFO: epoch 001:   8891 / 144806 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3377, wps=61, ups=0.35, wpb=87.8, bsz=32, num_updates=8880, lr=4.84851e-05, gnorm=0.564, clip=20, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=50782
2023-01-08 13:06:36 - progress_bar.py[line:274] - INFO: epoch 001:   8901 / 144806 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2875, wps=61, ups=0.35, wpb=87.3, bsz=32, num_updates=8890, lr=4.84815e-05, gnorm=0.487, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=50811
2023-01-08 13:07:05 - progress_bar.py[line:274] - INFO: epoch 001:   8911 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.7, nsentences=32, sample_size=85.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2809, wps=59.6, ups=0.35, wpb=85.7, bsz=32, num_updates=8900, lr=4.8478e-05, gnorm=0.664, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=50840
2023-01-08 13:07:34 - progress_bar.py[line:274] - INFO: epoch 001:   8921 / 144806 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2798, wps=61.4, ups=0.35, wpb=86.8, bsz=32, num_updates=8910, lr=4.84744e-05, gnorm=0.404, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=50869
2023-01-08 13:08:03 - progress_bar.py[line:274] - INFO: epoch 001:   8931 / 144806 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=85.7, nsentences=32, sample_size=85.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.3077, wps=58.8, ups=0.34, wpb=85.7, bsz=32, num_updates=8920, lr=4.84708e-05, gnorm=0.715, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=50898
2023-01-08 13:08:32 - progress_bar.py[line:274] - INFO: epoch 001:   8941 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3117, wps=62.3, ups=0.35, wpb=88.5, bsz=32, num_updates=8930, lr=4.84673e-05, gnorm=0.629, clip=20, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=50927
2023-01-08 13:09:01 - progress_bar.py[line:274] - INFO: epoch 001:   8951 / 144806 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2968, wps=60.4, ups=0.34, wpb=87.9, bsz=32, num_updates=8940, lr=4.84637e-05, gnorm=0.619, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=50956
2023-01-08 13:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   8961 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2318, wps=60.7, ups=0.34, wpb=88, bsz=32, num_updates=8950, lr=4.84601e-05, gnorm=0.562, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=50985
2023-01-08 13:09:59 - progress_bar.py[line:274] - INFO: epoch 001:   8971 / 144806 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.302, wps=61.6, ups=0.35, wpb=88.5, bsz=32, num_updates=8960, lr=4.84566e-05, gnorm=0.414, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=51014
2023-01-08 13:10:28 - progress_bar.py[line:274] - INFO: epoch 001:   8981 / 144806 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.2387, wps=61.1, ups=0.35, wpb=87.1, bsz=32, num_updates=8970, lr=4.8453e-05, gnorm=0.694, clip=10, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=51043
2023-01-08 13:10:57 - progress_bar.py[line:274] - INFO: epoch 001:   8991 / 144806 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=89.2, nsentences=32, sample_size=89.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3566, wps=62.7, ups=0.35, wpb=89.2, bsz=32, num_updates=8980, lr=4.84494e-05, gnorm=0.658, clip=10, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=51072
2023-01-08 13:11:25 - progress_bar.py[line:274] - INFO: epoch 001:   9001 / 144806 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2754, wps=60.8, ups=0.35, wpb=86.6, bsz=32, num_updates=8990, lr=4.84458e-05, gnorm=0.519, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=51101
2023-01-08 13:11:54 - progress_bar.py[line:274] - INFO: epoch 001:   9011 / 144806 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.321, wps=60.4, ups=0.35, wpb=86.7, bsz=32, num_updates=9000, lr=4.84423e-05, gnorm=0.471, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=51129
2023-01-08 13:12:23 - progress_bar.py[line:274] - INFO: epoch 001:   9021 / 144806 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2774, wps=60.4, ups=0.35, wpb=87.2, bsz=32, num_updates=9010, lr=4.84387e-05, gnorm=0.512, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=51159
2023-01-08 13:12:43 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 13:12:54 - progress_bar.py[line:274] - INFO: epoch 001:   9032 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.333, nsentences=32, sample_size=87.333, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2674, wps=59.6, ups=0.32, wpb=87.3, bsz=32, num_updates=9020, lr=4.84351e-05, gnorm=0.534, clip=0, loss_scale=512, train_wall=31, gb_free=15.2, ema_decay=0.9999, wall=51190
2023-01-08 13:13:23 - progress_bar.py[line:274] - INFO: epoch 001:   9042 / 144806 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3311, wps=61.8, ups=0.35, wpb=88.6, bsz=32, num_updates=9030, lr=4.84316e-05, gnorm=0.553, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=51218
2023-01-08 13:13:52 - progress_bar.py[line:274] - INFO: epoch 001:   9052 / 144806 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2397, wps=61, ups=0.35, wpb=86.6, bsz=32, num_updates=9040, lr=4.8428e-05, gnorm=0.461, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=51247
2023-01-08 13:14:21 - progress_bar.py[line:274] - INFO: epoch 001:   9062 / 144806 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2901, wps=61.3, ups=0.35, wpb=86.9, bsz=32, num_updates=9050, lr=4.84244e-05, gnorm=0.701, clip=20, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=51276
2023-01-08 13:14:50 - progress_bar.py[line:274] - INFO: epoch 001:   9072 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2761, wps=59.5, ups=0.35, wpb=85.9, bsz=32, num_updates=9060, lr=4.84209e-05, gnorm=0.585, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=51305
2023-01-08 13:15:18 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 13:15:22 - progress_bar.py[line:274] - INFO: epoch 001:   9083 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.571, nsentences=32, sample_size=87.571, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3239, wps=58.3, ups=0.32, wpb=87.6, bsz=32, num_updates=9070, lr=4.84173e-05, gnorm=0.477, clip=0, loss_scale=256, train_wall=31, gb_free=15.2, ema_decay=0.9999, wall=51337
2023-01-08 13:15:51 - progress_bar.py[line:274] - INFO: epoch 001:   9093 / 144806 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3697, wps=60.3, ups=0.35, wpb=86.9, bsz=32, num_updates=9080, lr=4.84137e-05, gnorm=0.679, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=51366
2023-01-08 13:16:19 - progress_bar.py[line:274] - INFO: epoch 001:   9103 / 144806 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3248, wps=61.5, ups=0.35, wpb=87.7, bsz=32, num_updates=9090, lr=4.84102e-05, gnorm=0.628, clip=0, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=51394
2023-01-08 13:16:48 - progress_bar.py[line:274] - INFO: epoch 001:   9113 / 144806 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2577, wps=61.3, ups=0.35, wpb=87.9, bsz=32, num_updates=9100, lr=4.84066e-05, gnorm=0.595, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=51423
2023-01-08 13:17:17 - progress_bar.py[line:274] - INFO: epoch 001:   9123 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3419, wps=61.1, ups=0.35, wpb=87.5, bsz=32, num_updates=9110, lr=4.8403e-05, gnorm=1.113, clip=10, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=51452
2023-01-08 13:17:47 - progress_bar.py[line:274] - INFO: epoch 001:   9133 / 144806 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2911, wps=59.5, ups=0.34, wpb=87.9, bsz=32, num_updates=9120, lr=4.83995e-05, gnorm=0.686, clip=20, loss_scale=256, train_wall=29, gb_free=14.8, ema_decay=0.9999, wall=51482
2023-01-08 13:18:16 - progress_bar.py[line:274] - INFO: epoch 001:   9143 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2903, wps=60.8, ups=0.35, wpb=86.8, bsz=32, num_updates=9130, lr=4.83959e-05, gnorm=0.491, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=51511
2023-01-08 13:18:44 - progress_bar.py[line:274] - INFO: epoch 001:   9153 / 144806 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2649, wps=61.6, ups=0.35, wpb=88.1, bsz=32, num_updates=9140, lr=4.83923e-05, gnorm=0.532, clip=0, loss_scale=256, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=51540
2023-01-08 13:19:14 - progress_bar.py[line:274] - INFO: epoch 001:   9163 / 144806 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.3165, wps=58.9, ups=0.34, wpb=87.2, bsz=32, num_updates=9150, lr=4.83888e-05, gnorm=0.574, clip=10, loss_scale=256, train_wall=30, gb_free=15.3, ema_decay=0.9999, wall=51569
2023-01-08 13:19:43 - progress_bar.py[line:274] - INFO: epoch 001:   9173 / 144806 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=85.6, nsentences=32, sample_size=85.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2914, wps=59.6, ups=0.35, wpb=85.6, bsz=32, num_updates=9160, lr=4.83852e-05, gnorm=0.61, clip=10, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=51598
2023-01-08 13:20:13 - progress_bar.py[line:274] - INFO: epoch 001:   9183 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3711, wps=59.2, ups=0.34, wpb=86.4, bsz=32, num_updates=9170, lr=4.83816e-05, gnorm=0.781, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=51628
2023-01-08 13:20:41 - progress_bar.py[line:274] - INFO: epoch 001:   9193 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3677, wps=61.4, ups=0.35, wpb=87.5, bsz=32, num_updates=9180, lr=4.83781e-05, gnorm=0.592, clip=10, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=51656
2023-01-08 13:21:10 - progress_bar.py[line:274] - INFO: epoch 001:   9203 / 144806 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2882, wps=61.6, ups=0.35, wpb=87.8, bsz=32, num_updates=9190, lr=4.83745e-05, gnorm=0.497, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=51685
2023-01-08 13:21:39 - progress_bar.py[line:274] - INFO: epoch 001:   9213 / 144806 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2675, wps=60.4, ups=0.35, wpb=86.4, bsz=32, num_updates=9200, lr=4.83709e-05, gnorm=0.472, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=51714
2023-01-08 13:22:08 - progress_bar.py[line:274] - INFO: epoch 001:   9223 / 144806 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3312, wps=61.3, ups=0.35, wpb=87.4, bsz=32, num_updates=9210, lr=4.83674e-05, gnorm=0.516, clip=0, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=51743
2023-01-08 13:22:37 - progress_bar.py[line:274] - INFO: epoch 001:   9233 / 144806 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3396, wps=61.4, ups=0.35, wpb=87.9, bsz=32, num_updates=9220, lr=4.83638e-05, gnorm=0.583, clip=0, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=51772
2023-01-08 13:23:06 - progress_bar.py[line:274] - INFO: epoch 001:   9243 / 144806 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3642, wps=61.1, ups=0.35, wpb=87.8, bsz=32, num_updates=9230, lr=4.83602e-05, gnorm=0.586, clip=10, loss_scale=256, train_wall=29, gb_free=14.8, ema_decay=0.9999, wall=51801
2023-01-08 13:23:34 - progress_bar.py[line:274] - INFO: epoch 001:   9253 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2875, wps=62.1, ups=0.36, wpb=87.2, bsz=32, num_updates=9240, lr=4.83567e-05, gnorm=0.672, clip=0, loss_scale=256, train_wall=28, gb_free=15.5, ema_decay=0.9999, wall=51829
2023-01-08 13:24:03 - progress_bar.py[line:274] - INFO: epoch 001:   9263 / 144806 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3082, wps=60.4, ups=0.35, wpb=86.8, bsz=32, num_updates=9250, lr=4.83531e-05, gnorm=0.54, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=51858
2023-01-08 13:24:32 - progress_bar.py[line:274] - INFO: epoch 001:   9273 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3416, wps=60.1, ups=0.34, wpb=87.4, bsz=32, num_updates=9260, lr=4.83495e-05, gnorm=0.41, clip=0, loss_scale=256, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=51887
2023-01-08 13:25:02 - progress_bar.py[line:274] - INFO: epoch 001:   9283 / 144806 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2885, wps=60, ups=0.34, wpb=87.6, bsz=32, num_updates=9270, lr=4.8346e-05, gnorm=0.504, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=51917
2023-01-08 13:25:31 - progress_bar.py[line:274] - INFO: epoch 001:   9293 / 144806 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3129, wps=60.1, ups=0.35, wpb=86.8, bsz=32, num_updates=9280, lr=4.83424e-05, gnorm=0.48, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=51946
2023-01-08 13:25:59 - progress_bar.py[line:274] - INFO: epoch 001:   9303 / 144806 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2968, wps=61.4, ups=0.35, wpb=86.9, bsz=32, num_updates=9290, lr=4.83388e-05, gnorm=0.549, clip=0, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=51974
2023-01-08 13:26:28 - progress_bar.py[line:274] - INFO: epoch 001:   9313 / 144806 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2941, wps=61.5, ups=0.35, wpb=86.9, bsz=32, num_updates=9300, lr=4.83353e-05, gnorm=0.675, clip=20, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=52003
2023-01-08 13:26:56 - progress_bar.py[line:274] - INFO: epoch 001:   9323 / 144806 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=89.7, nsentences=32, sample_size=89.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3521, wps=63, ups=0.35, wpb=89.7, bsz=32, num_updates=9310, lr=4.83317e-05, gnorm=0.481, clip=0, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=52031
2023-01-08 13:27:26 - progress_bar.py[line:274] - INFO: epoch 001:   9333 / 144806 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2532, wps=60.9, ups=0.34, wpb=88.3, bsz=32, num_updates=9320, lr=4.83281e-05, gnorm=0.503, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=52061
2023-01-08 13:27:55 - progress_bar.py[line:274] - INFO: epoch 001:   9343 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3483, wps=60.2, ups=0.35, wpb=86.8, bsz=32, num_updates=9330, lr=4.83246e-05, gnorm=0.623, clip=20, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=52090
2023-01-08 13:28:24 - progress_bar.py[line:274] - INFO: epoch 001:   9353 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3064, wps=60, ups=0.35, wpb=86.7, bsz=32, num_updates=9340, lr=4.8321e-05, gnorm=0.703, clip=10, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=52119
2023-01-08 13:28:52 - progress_bar.py[line:274] - INFO: epoch 001:   9363 / 144806 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2803, wps=61.8, ups=0.35, wpb=87.8, bsz=32, num_updates=9350, lr=4.83174e-05, gnorm=0.717, clip=20, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=52148
2023-01-08 13:29:21 - progress_bar.py[line:274] - INFO: epoch 001:   9373 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3114, wps=61.8, ups=0.36, wpb=87, bsz=32, num_updates=9360, lr=4.83139e-05, gnorm=0.609, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=52176
2023-01-08 13:29:50 - progress_bar.py[line:274] - INFO: epoch 001:   9383 / 144806 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2547, wps=60.4, ups=0.34, wpb=87.5, bsz=32, num_updates=9370, lr=4.83103e-05, gnorm=0.591, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=52205
2023-01-08 13:30:19 - progress_bar.py[line:274] - INFO: epoch 001:   9393 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3681, wps=61.4, ups=0.35, wpb=88.2, bsz=32, num_updates=9380, lr=4.83067e-05, gnorm=0.431, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=52234
2023-01-08 13:30:48 - progress_bar.py[line:274] - INFO: epoch 001:   9403 / 144806 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.297, wps=60.8, ups=0.35, wpb=87.2, bsz=32, num_updates=9390, lr=4.83032e-05, gnorm=0.534, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=52263
2023-01-08 13:31:17 - progress_bar.py[line:274] - INFO: epoch 001:   9413 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3935, wps=60.2, ups=0.35, wpb=86.8, bsz=32, num_updates=9400, lr=4.82996e-05, gnorm=0.508, clip=10, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=52292
2023-01-08 13:31:46 - progress_bar.py[line:274] - INFO: epoch 001:   9423 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3018, wps=60.2, ups=0.35, wpb=86.8, bsz=32, num_updates=9410, lr=4.8296e-05, gnorm=0.639, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=52321
2023-01-08 13:32:15 - progress_bar.py[line:274] - INFO: epoch 001:   9433 / 144806 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3038, wps=61.4, ups=0.35, wpb=88.1, bsz=32, num_updates=9420, lr=4.82925e-05, gnorm=0.53, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=52350
2023-01-08 13:32:44 - progress_bar.py[line:274] - INFO: epoch 001:   9443 / 144806 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2407, wps=61.1, ups=0.35, wpb=87.2, bsz=32, num_updates=9430, lr=4.82889e-05, gnorm=0.521, clip=0, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=52379
2023-01-08 13:33:12 - progress_bar.py[line:274] - INFO: epoch 001:   9453 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3438, wps=61.7, ups=0.35, wpb=87.4, bsz=32, num_updates=9440, lr=4.82853e-05, gnorm=0.519, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=52407
2023-01-08 13:33:41 - progress_bar.py[line:274] - INFO: epoch 001:   9463 / 144806 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3203, wps=62.5, ups=0.36, wpb=88, bsz=32, num_updates=9450, lr=4.82818e-05, gnorm=0.472, clip=0, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=52436
2023-01-08 13:34:10 - progress_bar.py[line:274] - INFO: epoch 001:   9473 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3245, wps=59.7, ups=0.34, wpb=87, bsz=32, num_updates=9460, lr=4.82782e-05, gnorm=0.475, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=52465
2023-01-08 13:34:39 - progress_bar.py[line:274] - INFO: epoch 001:   9483 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3657, wps=59.9, ups=0.35, wpb=86.2, bsz=32, num_updates=9470, lr=4.82746e-05, gnorm=1.161, clip=20, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=52494
2023-01-08 13:35:08 - progress_bar.py[line:274] - INFO: epoch 001:   9493 / 144806 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3413, wps=62.1, ups=0.35, wpb=87.8, bsz=32, num_updates=9480, lr=4.82711e-05, gnorm=0.765, clip=20, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=52523
2023-01-08 13:35:37 - progress_bar.py[line:274] - INFO: epoch 001:   9503 / 144806 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2905, wps=60.6, ups=0.34, wpb=88.6, bsz=32, num_updates=9490, lr=4.82675e-05, gnorm=0.622, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=52552
2023-01-08 13:36:06 - progress_bar.py[line:274] - INFO: epoch 001:   9513 / 144806 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3693, wps=59.9, ups=0.35, wpb=86.1, bsz=32, num_updates=9500, lr=4.82639e-05, gnorm=0.448, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=52581
2023-01-08 13:36:35 - progress_bar.py[line:274] - INFO: epoch 001:   9523 / 144806 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3503, wps=60.5, ups=0.35, wpb=86.5, bsz=32, num_updates=9510, lr=4.82604e-05, gnorm=0.408, clip=0, loss_scale=256, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=52610
2023-01-08 13:37:04 - progress_bar.py[line:274] - INFO: epoch 001:   9533 / 144806 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3137, wps=60.9, ups=0.35, wpb=88.1, bsz=32, num_updates=9520, lr=4.82568e-05, gnorm=0.563, clip=10, loss_scale=256, train_wall=29, gb_free=14.5, ema_decay=0.9999, wall=52639
2023-01-08 13:37:32 - progress_bar.py[line:274] - INFO: epoch 001:   9543 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3899, wps=62.8, ups=0.36, wpb=87.1, bsz=32, num_updates=9530, lr=4.82532e-05, gnorm=0.44, clip=0, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=52667
2023-01-08 13:38:01 - progress_bar.py[line:274] - INFO: epoch 001:   9553 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2686, wps=60.4, ups=0.35, wpb=86.7, bsz=32, num_updates=9540, lr=4.82497e-05, gnorm=0.514, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=52696
2023-01-08 13:38:31 - progress_bar.py[line:274] - INFO: epoch 001:   9563 / 144806 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2875, wps=60.1, ups=0.34, wpb=87.5, bsz=32, num_updates=9550, lr=4.82461e-05, gnorm=0.431, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=52726
2023-01-08 13:38:59 - progress_bar.py[line:274] - INFO: epoch 001:   9573 / 144806 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3148, wps=61.8, ups=0.35, wpb=87.3, bsz=32, num_updates=9560, lr=4.82425e-05, gnorm=0.444, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=52754
2023-01-08 13:39:28 - progress_bar.py[line:274] - INFO: epoch 001:   9583 / 144806 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2671, wps=61, ups=0.35, wpb=87.3, bsz=32, num_updates=9570, lr=4.8239e-05, gnorm=0.507, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=52783
2023-01-08 13:39:57 - progress_bar.py[line:274] - INFO: epoch 001:   9593 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3169, wps=60.4, ups=0.34, wpb=87.7, bsz=32, num_updates=9580, lr=4.82354e-05, gnorm=0.466, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=52812
2023-01-08 13:40:26 - progress_bar.py[line:274] - INFO: epoch 001:   9603 / 144806 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2944, wps=60.4, ups=0.35, wpb=86.3, bsz=32, num_updates=9590, lr=4.82318e-05, gnorm=0.609, clip=20, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=52841
2023-01-08 13:40:55 - progress_bar.py[line:274] - INFO: epoch 001:   9613 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.375, wps=60.5, ups=0.35, wpb=87.7, bsz=32, num_updates=9600, lr=4.82283e-05, gnorm=0.574, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=52870
2023-01-08 13:41:24 - progress_bar.py[line:274] - INFO: epoch 001:   9623 / 144806 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3488, wps=60.1, ups=0.34, wpb=87.1, bsz=32, num_updates=9610, lr=4.82247e-05, gnorm=0.534, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=52900
2023-01-08 13:41:53 - progress_bar.py[line:274] - INFO: epoch 001:   9633 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2805, wps=60.5, ups=0.35, wpb=86.6, bsz=32, num_updates=9620, lr=4.82211e-05, gnorm=0.538, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=52928
2023-01-08 13:42:22 - progress_bar.py[line:274] - INFO: epoch 001:   9643 / 144806 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3787, wps=61.3, ups=0.35, wpb=87.2, bsz=32, num_updates=9630, lr=4.82176e-05, gnorm=0.596, clip=10, loss_scale=512, train_wall=28, gb_free=15, ema_decay=0.9999, wall=52957
2023-01-08 13:42:50 - progress_bar.py[line:274] - INFO: epoch 001:   9653 / 144806 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2952, wps=61.5, ups=0.35, wpb=86.8, bsz=32, num_updates=9640, lr=4.8214e-05, gnorm=0.544, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=52986
2023-01-08 13:43:20 - progress_bar.py[line:274] - INFO: epoch 001:   9663 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3804, wps=59.3, ups=0.34, wpb=86.4, bsz=32, num_updates=9650, lr=4.82104e-05, gnorm=0.479, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=53015
2023-01-08 13:43:49 - progress_bar.py[line:274] - INFO: epoch 001:   9673 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3558, wps=60.2, ups=0.34, wpb=87.5, bsz=32, num_updates=9660, lr=4.82069e-05, gnorm=0.98, clip=20, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=53044
2023-01-08 13:44:17 - progress_bar.py[line:274] - INFO: epoch 001:   9683 / 144806 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4133, wps=62.1, ups=0.36, wpb=87.4, bsz=32, num_updates=9670, lr=4.82033e-05, gnorm=0.629, clip=10, loss_scale=512, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=53073
2023-01-08 13:44:46 - progress_bar.py[line:274] - INFO: epoch 001:   9693 / 144806 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.3023, wps=60.1, ups=0.35, wpb=86.4, bsz=32, num_updates=9680, lr=4.81997e-05, gnorm=0.624, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=53102
2023-01-08 13:45:16 - progress_bar.py[line:274] - INFO: epoch 001:   9703 / 144806 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3484, wps=60.2, ups=0.35, wpb=86.8, bsz=32, num_updates=9690, lr=4.81962e-05, gnorm=0.498, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=53131
2023-01-08 13:45:44 - progress_bar.py[line:274] - INFO: epoch 001:   9713 / 144806 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2761, wps=61.2, ups=0.35, wpb=87.3, bsz=32, num_updates=9700, lr=4.81926e-05, gnorm=0.526, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=53159
2023-01-08 13:46:13 - progress_bar.py[line:274] - INFO: epoch 001:   9723 / 144806 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2418, wps=60.8, ups=0.35, wpb=87.5, bsz=32, num_updates=9710, lr=4.8189e-05, gnorm=0.461, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=53188
2023-01-08 13:46:42 - progress_bar.py[line:274] - INFO: epoch 001:   9733 / 144806 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.354, wps=61.9, ups=0.35, wpb=87.9, bsz=32, num_updates=9720, lr=4.81855e-05, gnorm=0.649, clip=30, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=53217
2023-01-08 13:47:11 - progress_bar.py[line:274] - INFO: epoch 001:   9743 / 144806 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3608, wps=59.3, ups=0.34, wpb=86.2, bsz=32, num_updates=9730, lr=4.81819e-05, gnorm=0.509, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=53246
2023-01-08 13:47:40 - progress_bar.py[line:274] - INFO: epoch 001:   9753 / 144806 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3049, wps=60.4, ups=0.35, wpb=86.5, bsz=32, num_updates=9740, lr=4.81783e-05, gnorm=0.586, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=53275
2023-01-08 13:48:09 - progress_bar.py[line:274] - INFO: epoch 001:   9763 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3533, wps=60.8, ups=0.35, wpb=87.2, bsz=32, num_updates=9750, lr=4.81748e-05, gnorm=0.584, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=53304
2023-01-08 13:48:38 - progress_bar.py[line:274] - INFO: epoch 001:   9773 / 144806 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3145, wps=61.5, ups=0.35, wpb=87.3, bsz=32, num_updates=9760, lr=4.81712e-05, gnorm=0.543, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=53333
2023-01-08 13:49:06 - progress_bar.py[line:274] - INFO: epoch 001:   9783 / 144806 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3464, wps=62.1, ups=0.35, wpb=88.5, bsz=32, num_updates=9770, lr=4.81676e-05, gnorm=0.623, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=53361
2023-01-08 13:49:35 - progress_bar.py[line:274] - INFO: epoch 001:   9793 / 144806 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3647, wps=60.4, ups=0.35, wpb=87.1, bsz=32, num_updates=9780, lr=4.81641e-05, gnorm=0.553, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=53391
2023-01-08 13:50:05 - progress_bar.py[line:274] - INFO: epoch 001:   9803 / 144806 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3624, wps=60.6, ups=0.35, wpb=87.5, bsz=32, num_updates=9790, lr=4.81605e-05, gnorm=0.575, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=53420
2023-01-08 13:50:34 - progress_bar.py[line:274] - INFO: epoch 001:   9813 / 144806 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3795, wps=59.9, ups=0.35, wpb=86.8, bsz=32, num_updates=9800, lr=4.81569e-05, gnorm=0.551, clip=0, loss_scale=512, train_wall=29, gb_free=15.6, ema_decay=0.9999, wall=53449
2023-01-08 13:51:03 - progress_bar.py[line:274] - INFO: epoch 001:   9823 / 144806 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3919, wps=60.3, ups=0.34, wpb=87.4, bsz=32, num_updates=9810, lr=4.81534e-05, gnorm=0.55, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=53478
2023-01-08 13:51:32 - progress_bar.py[line:274] - INFO: epoch 001:   9833 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3313, wps=60.2, ups=0.35, wpb=86.5, bsz=32, num_updates=9820, lr=4.81498e-05, gnorm=0.624, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=53507
2023-01-08 13:52:01 - progress_bar.py[line:274] - INFO: epoch 001:   9843 / 144806 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2866, wps=60.6, ups=0.35, wpb=85.9, bsz=32, num_updates=9830, lr=4.81462e-05, gnorm=0.518, clip=10, loss_scale=512, train_wall=28, gb_free=15, ema_decay=0.9999, wall=53536
2023-01-08 13:52:30 - progress_bar.py[line:274] - INFO: epoch 001:   9853 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3052, wps=60.2, ups=0.34, wpb=87.2, bsz=32, num_updates=9840, lr=4.81427e-05, gnorm=0.505, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=53565
2023-01-08 13:52:59 - progress_bar.py[line:274] - INFO: epoch 001:   9863 / 144806 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=85.7, nsentences=32, sample_size=85.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3333, wps=59.1, ups=0.34, wpb=85.7, bsz=32, num_updates=9850, lr=4.81391e-05, gnorm=0.904, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=53594
2023-01-08 13:53:29 - progress_bar.py[line:274] - INFO: epoch 001:   9873 / 144806 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3704, wps=59.2, ups=0.34, wpb=86.4, bsz=32, num_updates=9860, lr=4.81355e-05, gnorm=0.632, clip=10, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=53624
2023-01-08 13:53:58 - progress_bar.py[line:274] - INFO: epoch 001:   9883 / 144806 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=85.6, nsentences=32, sample_size=85.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3409, wps=58.7, ups=0.34, wpb=85.6, bsz=32, num_updates=9870, lr=4.8132e-05, gnorm=0.46, clip=0, loss_scale=512, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=53653
2023-01-08 13:54:27 - progress_bar.py[line:274] - INFO: epoch 001:   9893 / 144806 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2138, wps=61.4, ups=0.35, wpb=87.8, bsz=32, num_updates=9880, lr=4.81284e-05, gnorm=0.514, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=53682
2023-01-08 13:54:55 - progress_bar.py[line:274] - INFO: epoch 001:   9903 / 144806 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2961, wps=62.1, ups=0.35, wpb=88.5, bsz=32, num_updates=9890, lr=4.81248e-05, gnorm=0.661, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=53711
2023-01-08 13:55:25 - progress_bar.py[line:274] - INFO: epoch 001:   9913 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4, wps=61.2, ups=0.35, wpb=88.3, bsz=32, num_updates=9900, lr=4.81213e-05, gnorm=0.564, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=53740
2023-01-08 13:55:54 - progress_bar.py[line:274] - INFO: epoch 001:   9923 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3311, wps=60.7, ups=0.34, wpb=88, bsz=32, num_updates=9910, lr=4.81177e-05, gnorm=0.595, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=53769
2023-01-08 13:56:22 - progress_bar.py[line:274] - INFO: epoch 001:   9933 / 144806 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3355, wps=61.5, ups=0.35, wpb=87.5, bsz=32, num_updates=9920, lr=4.81141e-05, gnorm=0.673, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=53798
2023-01-08 13:56:52 - progress_bar.py[line:274] - INFO: epoch 001:   9943 / 144806 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3952, wps=59.5, ups=0.34, wpb=86.5, bsz=32, num_updates=9930, lr=4.81105e-05, gnorm=0.581, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=53827
2023-01-08 13:57:20 - progress_bar.py[line:274] - INFO: epoch 001:   9953 / 144806 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3567, wps=61.8, ups=0.35, wpb=87.7, bsz=32, num_updates=9940, lr=4.8107e-05, gnorm=0.557, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=53855
2023-01-08 13:57:49 - progress_bar.py[line:274] - INFO: epoch 001:   9963 / 144806 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3418, wps=61.4, ups=0.35, wpb=87.7, bsz=32, num_updates=9950, lr=4.81034e-05, gnorm=0.505, clip=0, loss_scale=512, train_wall=28, gb_free=14.5, ema_decay=0.9999, wall=53884
2023-01-08 13:58:18 - progress_bar.py[line:274] - INFO: epoch 001:   9973 / 144806 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3497, wps=61.3, ups=0.35, wpb=87.4, bsz=32, num_updates=9960, lr=4.80998e-05, gnorm=0.535, clip=0, loss_scale=512, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=53913
2023-01-08 13:58:47 - progress_bar.py[line:274] - INFO: epoch 001:   9983 / 144806 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2973, wps=60.5, ups=0.35, wpb=87.7, bsz=32, num_updates=9970, lr=4.80963e-05, gnorm=0.588, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=53942
2023-01-08 13:59:15 - progress_bar.py[line:274] - INFO: epoch 001:   9993 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.396, wps=62.7, ups=0.36, wpb=87.8, bsz=32, num_updates=9980, lr=4.80927e-05, gnorm=0.404, clip=0, loss_scale=512, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=53970
2023-01-08 13:59:44 - progress_bar.py[line:274] - INFO: epoch 001:  10003 / 144806 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3512, wps=60.6, ups=0.35, wpb=87.1, bsz=32, num_updates=9990, lr=4.80891e-05, gnorm=0.546, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=53999
2023-01-08 14:00:13 - progress_bar.py[line:274] - INFO: epoch 001:  10013 / 144806 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3522, wps=61.1, ups=0.35, wpb=87.4, bsz=32, num_updates=10000, lr=4.80856e-05, gnorm=0.412, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=54028
2023-01-08 14:00:13 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 14:00:14 - train.py[line:549] - INFO: 0 / 6234
2023-01-08 14:00:14 - train.py[line:551] - INFO: load:0.85 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 14:00:16 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.30 GiB (GPU 0; 39.59 GiB total capacity; 8.03 GiB already allocated; 3.28 GiB free; 24.72 GiB reserved in total by PyTorch)
2023-01-08 14:00:16 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 22        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8219 MB |    9126 MB |    4719 TB |    4719 TB |
|       from large pool |    8045 MB |    8951 MB |    4717 TB |    4717 TB |
|       from small pool |     174 MB |     174 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8219 MB |    9126 MB |    4719 TB |    4719 TB |
|       from large pool |    8045 MB |    8951 MB |    4717 TB |    4717 TB |
|       from small pool |     174 MB |     174 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   25318 MB |   27510 MB |  256524 MB |  231206 MB |
|       from large pool |   25142 MB |   27330 MB |  256052 MB |  230910 MB |
|       from small pool |     176 MB |     180 MB |     472 MB |     296 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17098 MB |   20357 MB |    4444 TB |    4444 TB |
|       from large pool |   17096 MB |   20355 MB |    4442 TB |    4442 TB |
|       from small pool |       1 MB |       2 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  254021 K  |  254016 K  |
|       from large pool |     698    |     710    |   85995 K  |   85995 K  |
|       from small pool |    3925    |    3943    |  168025 K  |  168021 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  254021 K  |  254016 K  |
|       from large pool |     698    |     710    |   85995 K  |   85995 K  |
|       from small pool |    3925    |    3943    |  168025 K  |  168021 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     184    |     195    |     741    |     557    |
|       from large pool |      96    |     105    |     505    |     409    |
|       from small pool |      88    |      90    |     236    |     148    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     126    |     132    |  185088 K  |  185088 K  |
|       from large pool |      67    |      69    |   43189 K  |   43189 K  |
|       from small pool |      59    |      67    |  141899 K  |  141899 K  |
|===========================================================================|

2023-01-08 14:00:16 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-08 14:00:16 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-08 14:04:29 - train.py[line:549] - INFO: 200 / 6234
2023-01-08 14:04:29 - train.py[line:551] - INFO: load:0.87 valid_run:255.08 task_valid:250.07 collect_output:0.68
2023-01-08 14:08:39 - train.py[line:549] - INFO: 400 / 6234
2023-01-08 14:08:39 - train.py[line:551] - INFO: load:0.90 valid_run:504.05 task_valid:495.73 collect_output:1.39
2023-01-08 14:12:48 - train.py[line:549] - INFO: 600 / 6234
2023-01-08 14:12:48 - train.py[line:551] - INFO: load:0.92 valid_run:753.57 task_valid:742.00 collect_output:2.09
2023-01-08 14:16:54 - train.py[line:549] - INFO: 800 / 6234
2023-01-08 14:16:54 - train.py[line:551] - INFO: load:0.95 valid_run:999.49 task_valid:984.68 collect_output:2.77
2023-01-08 14:21:05 - train.py[line:549] - INFO: 1000 / 6234
2023-01-08 14:21:05 - train.py[line:551] - INFO: load:0.97 valid_run:1250.11 task_valid:1232.11 collect_output:3.43
2023-01-08 14:25:18 - train.py[line:549] - INFO: 1200 / 6234
2023-01-08 14:25:18 - train.py[line:551] - INFO: load:0.99 valid_run:1502.74 task_valid:1481.51 collect_output:4.11
2023-01-08 14:29:29 - train.py[line:549] - INFO: 1400 / 6234
2023-01-08 14:29:29 - train.py[line:551] - INFO: load:1.02 valid_run:1754.54 task_valid:1730.10 collect_output:4.77
2023-01-08 14:33:39 - train.py[line:549] - INFO: 1600 / 6234
2023-01-08 14:33:39 - train.py[line:551] - INFO: load:1.04 valid_run:2004.15 task_valid:1976.48 collect_output:5.43
2023-01-08 14:37:50 - train.py[line:549] - INFO: 1800 / 6234
2023-01-08 14:37:50 - train.py[line:551] - INFO: load:1.07 valid_run:2254.55 task_valid:2223.70 collect_output:6.08
2023-01-08 14:41:54 - train.py[line:549] - INFO: 2000 / 6234
2023-01-08 14:41:54 - train.py[line:551] - INFO: load:1.09 valid_run:2498.75 task_valid:2464.71 collect_output:6.75
2023-01-08 14:46:02 - train.py[line:549] - INFO: 2200 / 6234
2023-01-08 14:46:02 - train.py[line:551] - INFO: load:1.11 valid_run:2747.13 task_valid:2709.87 collect_output:7.42
2023-01-08 14:50:13 - train.py[line:549] - INFO: 2400 / 6234
2023-01-08 14:50:13 - train.py[line:551] - INFO: load:1.14 valid_run:2997.73 task_valid:2957.22 collect_output:8.08
2023-01-08 14:54:19 - train.py[line:549] - INFO: 2600 / 6234
2023-01-08 14:54:19 - train.py[line:551] - INFO: load:1.16 valid_run:3243.52 task_valid:3199.73 collect_output:8.77
2023-01-08 14:58:30 - train.py[line:549] - INFO: 2800 / 6234
2023-01-08 14:58:30 - train.py[line:551] - INFO: load:1.19 valid_run:3494.87 task_valid:3447.83 collect_output:9.44
2023-01-08 15:02:39 - train.py[line:549] - INFO: 3000 / 6234
2023-01-08 15:02:39 - train.py[line:551] - INFO: load:1.21 valid_run:3743.91 task_valid:3693.63 collect_output:10.10
2023-01-08 15:06:45 - train.py[line:549] - INFO: 3200 / 6234
2023-01-08 15:06:45 - train.py[line:551] - INFO: load:1.24 valid_run:3989.48 task_valid:3936.02 collect_output:10.74
2023-01-08 15:10:54 - train.py[line:549] - INFO: 3400 / 6234
2023-01-08 15:10:54 - train.py[line:551] - INFO: load:1.26 valid_run:4238.34 task_valid:4181.67 collect_output:11.38
2023-01-08 15:15:06 - train.py[line:549] - INFO: 3600 / 6234
2023-01-08 15:15:06 - train.py[line:551] - INFO: load:1.29 valid_run:4489.88 task_valid:4429.98 collect_output:12.03
2023-01-08 15:19:16 - train.py[line:549] - INFO: 3800 / 6234
2023-01-08 15:19:16 - train.py[line:551] - INFO: load:1.31 valid_run:4739.84 task_valid:4676.74 collect_output:12.69
2023-01-08 15:23:25 - train.py[line:549] - INFO: 4000 / 6234
2023-01-08 15:23:26 - train.py[line:551] - INFO: load:1.33 valid_run:4989.30 task_valid:4923.01 collect_output:13.33
2023-01-08 15:27:35 - train.py[line:549] - INFO: 4200 / 6234
2023-01-08 15:27:35 - train.py[line:551] - INFO: load:1.36 valid_run:5238.74 task_valid:5169.25 collect_output:13.97
2023-01-08 15:31:48 - train.py[line:549] - INFO: 4400 / 6234
2023-01-08 15:31:48 - train.py[line:551] - INFO: load:1.38 valid_run:5491.66 task_valid:5418.97 collect_output:14.62
2023-01-08 15:35:55 - train.py[line:549] - INFO: 4600 / 6234
2023-01-08 15:35:55 - train.py[line:551] - INFO: load:1.41 valid_run:5738.22 task_valid:5662.31 collect_output:15.26
2023-01-08 15:40:04 - train.py[line:549] - INFO: 4800 / 6234
2023-01-08 15:40:04 - train.py[line:551] - INFO: load:1.43 valid_run:5987.27 task_valid:5908.11 collect_output:15.93
2023-01-08 15:44:13 - train.py[line:549] - INFO: 5000 / 6234
2023-01-08 15:44:13 - train.py[line:551] - INFO: load:1.46 valid_run:6236.44 task_valid:6154.02 collect_output:16.60
2023-01-08 15:48:22 - train.py[line:549] - INFO: 5200 / 6234
2023-01-08 15:48:22 - train.py[line:551] - INFO: load:1.48 valid_run:6485.17 task_valid:6399.51 collect_output:17.25
2023-01-08 15:52:28 - train.py[line:549] - INFO: 5400 / 6234
2023-01-08 15:52:28 - train.py[line:551] - INFO: load:1.51 valid_run:6731.24 task_valid:6642.33 collect_output:17.91
2023-01-08 15:56:42 - train.py[line:549] - INFO: 5600 / 6234
2023-01-08 15:56:42 - train.py[line:551] - INFO: load:1.53 valid_run:6984.83 task_valid:6892.67 collect_output:18.59
2023-01-08 16:00:50 - train.py[line:549] - INFO: 5800 / 6234
2023-01-08 16:00:50 - train.py[line:551] - INFO: load:1.56 valid_run:7233.32 task_valid:7137.86 collect_output:19.27
2023-01-08 16:05:03 - train.py[line:549] - INFO: 6000 / 6234
2023-01-08 16:05:03 - train.py[line:551] - INFO: load:1.58 valid_run:7485.63 task_valid:7386.91 collect_output:19.92
2023-01-08 16:09:15 - train.py[line:549] - INFO: 6200 / 6234
2023-01-08 16:09:15 - train.py[line:551] - INFO: load:1.61 valid_run:7737.80 task_valid:7635.88 collect_output:20.57

====================================================================================================
SGG eval:     R @ 50: 0.4990;     R @ 100: 0.5722;     R @ 500: 0.6296;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3107;    mR @ 100: 0.3648;    mR @ 500: 0.4230;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7585) (covered in:0.7500) (covering:0.3143) (eating:0.6471) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.8301) (says:0.0000) (sitting on:0.6922) (standing on:0.1783) (using:0.6500) (walking in:0.0000) (walking on:0.6036) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4990;     R @ 100: 0.5722;     R @ 500: 0.6296;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3107;    mR @ 100: 0.3648;    mR @ 500: 0.4230;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7585) (covered in:0.7500) (covering:0.3143) (eating:0.6471) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.8301) (says:0.0000) (sitting on:0.6922) (standing on:0.1783) (using:0.6500) (walking in:0.0000) (walking on:0.6036) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-01-08 16:10:08 - train.py[line:487] - INFO: 0.5721571428571428
2023-01-08 16:10:08 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 16:10:09 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.341 | loss_v1 0 | loss_v2 0 | nll_loss 0.189 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.572157 | ppl 1.14 | vqa_score 0.5214 | wps 57.6 | wpb 72 | bsz 24 | num_updates 10000 | best_R@100 0.632103
2023-01-08 16:10:09 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 10000 updates
2023-01-08 16:10:09 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_10000.pt
2023-01-08 16:10:53 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_10000.pt
2023-01-08 16:12:20 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 0.5721571428571428) (writing took 131.7452983725816 seconds)
2023-01-08 16:12:51 - progress_bar.py[line:274] - INFO: epoch 001:  10023 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.284, wps=0.2, ups=0, wpb=87.9, bsz=32, num_updates=10010, lr=4.8082e-05, gnorm=0.612, clip=10, loss_scale=512, train_wall=30, gb_free=15.6, ema_decay=0.9999, wall=61986
2023-01-08 16:13:20 - progress_bar.py[line:274] - INFO: epoch 001:  10033 / 144806 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3312, wps=59.9, ups=0.34, wpb=87.6, bsz=32, num_updates=10020, lr=4.80784e-05, gnorm=0.627, clip=0, loss_scale=512, train_wall=29, gb_free=15.6, ema_decay=0.9999, wall=62015
2023-01-08 16:13:51 - progress_bar.py[line:274] - INFO: epoch 001:  10043 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.375, wps=58.2, ups=0.33, wpb=88.1, bsz=32, num_updates=10030, lr=4.80749e-05, gnorm=0.531, clip=10, loss_scale=512, train_wall=30, gb_free=14.9, ema_decay=0.9999, wall=62046
2023-01-08 16:14:20 - progress_bar.py[line:274] - INFO: epoch 001:  10053 / 144806 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3195, wps=60, ups=0.34, wpb=87.1, bsz=32, num_updates=10040, lr=4.80713e-05, gnorm=0.481, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=62075
2023-01-08 16:14:49 - progress_bar.py[line:274] - INFO: epoch 001:  10063 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3902, wps=61.2, ups=0.35, wpb=87.6, bsz=32, num_updates=10050, lr=4.80677e-05, gnorm=0.465, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=62104
2023-01-08 16:15:18 - progress_bar.py[line:274] - INFO: epoch 001:  10073 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3585, wps=60.4, ups=0.35, wpb=87, bsz=32, num_updates=10060, lr=4.80642e-05, gnorm=0.458, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=62133
2023-01-08 16:15:47 - progress_bar.py[line:274] - INFO: epoch 001:  10083 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3655, wps=60.6, ups=0.35, wpb=87.8, bsz=32, num_updates=10070, lr=4.80606e-05, gnorm=0.447, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=62162
2023-01-08 16:16:16 - progress_bar.py[line:274] - INFO: epoch 001:  10093 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3544, wps=60.8, ups=0.35, wpb=87.6, bsz=32, num_updates=10080, lr=4.8057e-05, gnorm=0.457, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=62191
2023-01-08 16:16:45 - progress_bar.py[line:274] - INFO: epoch 001:  10103 / 144806 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3688, wps=61.4, ups=0.35, wpb=86.9, bsz=32, num_updates=10090, lr=4.80535e-05, gnorm=0.521, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=62220
2023-01-08 16:17:14 - progress_bar.py[line:274] - INFO: epoch 001:  10113 / 144806 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3133, wps=58.7, ups=0.34, wpb=86.9, bsz=32, num_updates=10100, lr=4.80499e-05, gnorm=0.412, clip=0, loss_scale=1024, train_wall=30, gb_free=15.3, ema_decay=0.9999, wall=62250
2023-01-08 16:17:43 - progress_bar.py[line:274] - INFO: epoch 001:  10123 / 144806 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3146, wps=59.6, ups=0.35, wpb=86, bsz=32, num_updates=10110, lr=4.80463e-05, gnorm=0.532, clip=0, loss_scale=1024, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=62279
2023-01-08 16:18:12 - progress_bar.py[line:274] - INFO: epoch 001:  10133 / 144806 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3293, wps=62, ups=0.35, wpb=88.5, bsz=32, num_updates=10120, lr=4.80428e-05, gnorm=0.534, clip=20, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=62307
2023-01-08 16:18:41 - progress_bar.py[line:274] - INFO: epoch 001:  10143 / 144806 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.277, wps=61.7, ups=0.35, wpb=87.6, bsz=32, num_updates=10130, lr=4.80392e-05, gnorm=0.683, clip=10, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=62336
2023-01-08 16:19:10 - progress_bar.py[line:274] - INFO: epoch 001:  10153 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3046, wps=61.1, ups=0.35, wpb=86.9, bsz=32, num_updates=10140, lr=4.80356e-05, gnorm=0.571, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=62365
2023-01-08 16:19:39 - progress_bar.py[line:274] - INFO: epoch 001:  10163 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2745, wps=61.4, ups=0.35, wpb=88.4, bsz=32, num_updates=10150, lr=4.80321e-05, gnorm=0.352, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=62394
2023-01-08 16:20:08 - progress_bar.py[line:274] - INFO: epoch 001:  10173 / 144806 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3602, wps=60.4, ups=0.35, wpb=86.7, bsz=32, num_updates=10160, lr=4.80285e-05, gnorm=0.644, clip=20, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=62423
2023-01-08 16:20:36 - progress_bar.py[line:274] - INFO: epoch 001:  10183 / 144806 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3357, wps=61.3, ups=0.35, wpb=88.1, bsz=32, num_updates=10170, lr=4.80249e-05, gnorm=0.594, clip=10, loss_scale=1024, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=62452
2023-01-08 16:21:06 - progress_bar.py[line:274] - INFO: epoch 001:  10193 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3247, wps=61.2, ups=0.35, wpb=88.2, bsz=32, num_updates=10180, lr=4.80214e-05, gnorm=0.652, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=62481
2023-01-08 16:21:35 - progress_bar.py[line:274] - INFO: epoch 001:  10203 / 144806 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.4101, wps=59.1, ups=0.34, wpb=86.5, bsz=32, num_updates=10190, lr=4.80178e-05, gnorm=0.527, clip=10, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=62510
2023-01-08 16:22:04 - progress_bar.py[line:274] - INFO: epoch 001:  10213 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3097, wps=61.5, ups=0.35, wpb=87.8, bsz=32, num_updates=10200, lr=4.80142e-05, gnorm=0.545, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=62539
2023-01-08 16:22:32 - progress_bar.py[line:274] - INFO: epoch 001:  10223 / 144806 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4161, wps=62.2, ups=0.35, wpb=88.5, bsz=32, num_updates=10210, lr=4.80107e-05, gnorm=0.59, clip=10, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=62568
2023-01-08 16:23:02 - progress_bar.py[line:274] - INFO: epoch 001:  10233 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=89, nsentences=32, sample_size=89, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3399, wps=61.2, ups=0.34, wpb=89, bsz=32, num_updates=10220, lr=4.80071e-05, gnorm=0.697, clip=10, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=62597
2023-01-08 16:23:30 - progress_bar.py[line:274] - INFO: epoch 001:  10243 / 144806 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3455, wps=60.7, ups=0.35, wpb=86.6, bsz=32, num_updates=10230, lr=4.80035e-05, gnorm=0.428, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=62626
2023-01-08 16:24:00 - progress_bar.py[line:274] - INFO: epoch 001:  10253 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4172, wps=61.2, ups=0.35, wpb=88.3, bsz=32, num_updates=10240, lr=4.8e-05, gnorm=0.448, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=62655
2023-01-08 16:24:29 - progress_bar.py[line:274] - INFO: epoch 001:  10263 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3371, wps=59.8, ups=0.35, wpb=86.5, bsz=32, num_updates=10250, lr=4.79964e-05, gnorm=0.628, clip=10, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=62684
2023-01-08 16:24:58 - progress_bar.py[line:274] - INFO: epoch 001:  10273 / 144806 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3145, wps=59.5, ups=0.34, wpb=86.8, bsz=32, num_updates=10260, lr=4.79928e-05, gnorm=0.518, clip=10, loss_scale=1024, train_wall=29, gb_free=15, ema_decay=0.9999, wall=62713
2023-01-08 16:25:27 - progress_bar.py[line:274] - INFO: epoch 001:  10283 / 144806 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.345, wps=60.7, ups=0.35, wpb=86.9, bsz=32, num_updates=10270, lr=4.79893e-05, gnorm=0.412, clip=0, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=62742
2023-01-08 16:25:55 - progress_bar.py[line:274] - INFO: epoch 001:  10293 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3292, wps=61.8, ups=0.36, wpb=87.1, bsz=32, num_updates=10280, lr=4.79857e-05, gnorm=0.554, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=62771
2023-01-08 16:26:25 - progress_bar.py[line:274] - INFO: epoch 001:  10303 / 144806 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3625, wps=60, ups=0.34, wpb=87, bsz=32, num_updates=10290, lr=4.79821e-05, gnorm=0.481, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=62800
2023-01-08 16:26:55 - progress_bar.py[line:274] - INFO: epoch 001:  10313 / 144806 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3625, wps=58.3, ups=0.34, wpb=86.9, bsz=32, num_updates=10300, lr=4.79786e-05, gnorm=0.507, clip=10, loss_scale=1024, train_wall=30, gb_free=15.2, ema_decay=0.9999, wall=62830
2023-01-08 16:27:24 - progress_bar.py[line:274] - INFO: epoch 001:  10323 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.426, wps=60.7, ups=0.35, wpb=87.5, bsz=32, num_updates=10310, lr=4.7975e-05, gnorm=0.449, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=62859
2023-01-08 16:27:53 - progress_bar.py[line:274] - INFO: epoch 001:  10333 / 144806 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3621, wps=59.1, ups=0.34, wpb=85.9, bsz=32, num_updates=10320, lr=4.79714e-05, gnorm=0.489, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=62888
2023-01-08 16:28:22 - progress_bar.py[line:274] - INFO: epoch 001:  10343 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3333, wps=62, ups=0.35, wpb=88.1, bsz=32, num_updates=10330, lr=4.79679e-05, gnorm=0.444, clip=0, loss_scale=1024, train_wall=28, gb_free=15, ema_decay=0.9999, wall=62917
2023-01-08 16:28:51 - progress_bar.py[line:274] - INFO: epoch 001:  10353 / 144806 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.3292, wps=60.9, ups=0.35, wpb=86.9, bsz=32, num_updates=10340, lr=4.79643e-05, gnorm=0.593, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=62946
2023-01-08 16:29:20 - progress_bar.py[line:274] - INFO: epoch 001:  10363 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3562, wps=61, ups=0.35, wpb=87.9, bsz=32, num_updates=10350, lr=4.79607e-05, gnorm=0.346, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=62975
2023-01-08 16:29:49 - progress_bar.py[line:274] - INFO: epoch 001:  10373 / 144806 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3254, wps=59.7, ups=0.35, wpb=86.3, bsz=32, num_updates=10360, lr=4.79572e-05, gnorm=0.448, clip=0, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=63004
2023-01-08 16:30:18 - progress_bar.py[line:274] - INFO: epoch 001:  10383 / 144806 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3851, wps=59.6, ups=0.34, wpb=87.4, bsz=32, num_updates=10370, lr=4.79536e-05, gnorm=0.473, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=63033
2023-01-08 16:30:47 - progress_bar.py[line:274] - INFO: epoch 001:  10393 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3243, wps=60.5, ups=0.35, wpb=87.4, bsz=32, num_updates=10380, lr=4.795e-05, gnorm=0.505, clip=10, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=63062
2023-01-08 16:31:16 - progress_bar.py[line:274] - INFO: epoch 001:  10403 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3226, wps=61.1, ups=0.35, wpb=87.8, bsz=32, num_updates=10390, lr=4.79465e-05, gnorm=0.65, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=63091
2023-01-08 16:31:45 - progress_bar.py[line:274] - INFO: epoch 001:  10413 / 144806 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4176, wps=60.2, ups=0.35, wpb=86.3, bsz=32, num_updates=10400, lr=4.79429e-05, gnorm=0.412, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=63120
2023-01-08 16:32:14 - progress_bar.py[line:274] - INFO: epoch 001:  10423 / 144806 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3768, wps=61.5, ups=0.35, wpb=88.2, bsz=32, num_updates=10410, lr=4.79393e-05, gnorm=0.397, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=63149
2023-01-08 16:32:43 - progress_bar.py[line:274] - INFO: epoch 001:  10433 / 144806 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3436, wps=60.7, ups=0.35, wpb=86.7, bsz=32, num_updates=10420, lr=4.79358e-05, gnorm=0.459, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=63178
2023-01-08 16:33:12 - progress_bar.py[line:274] - INFO: epoch 001:  10443 / 144806 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3665, wps=62.4, ups=0.36, wpb=87.6, bsz=32, num_updates=10430, lr=4.79322e-05, gnorm=0.404, clip=0, loss_scale=1024, train_wall=28, gb_free=15, ema_decay=0.9999, wall=63206
2023-01-08 16:33:41 - progress_bar.py[line:274] - INFO: epoch 001:  10453 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3727, wps=59.5, ups=0.34, wpb=87.5, bsz=32, num_updates=10440, lr=4.79286e-05, gnorm=0.503, clip=0, loss_scale=1024, train_wall=29, gb_free=14.5, ema_decay=0.9999, wall=63236
2023-01-08 16:34:10 - progress_bar.py[line:274] - INFO: epoch 001:  10463 / 144806 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3571, wps=60.4, ups=0.35, wpb=86.8, bsz=32, num_updates=10450, lr=4.79251e-05, gnorm=0.499, clip=10, loss_scale=1024, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=63265
2023-01-08 16:34:39 - progress_bar.py[line:274] - INFO: epoch 001:  10473 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3413, wps=60.7, ups=0.35, wpb=87.1, bsz=32, num_updates=10460, lr=4.79215e-05, gnorm=0.555, clip=10, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=63294
2023-01-08 16:35:08 - progress_bar.py[line:274] - INFO: epoch 001:  10483 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3434, wps=60.2, ups=0.35, wpb=86.8, bsz=32, num_updates=10470, lr=4.79179e-05, gnorm=0.541, clip=10, loss_scale=1024, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=63323
2023-01-08 16:35:38 - progress_bar.py[line:274] - INFO: epoch 001:  10493 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3399, wps=60.3, ups=0.34, wpb=88.1, bsz=32, num_updates=10480, lr=4.79144e-05, gnorm=0.488, clip=10, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=63353
2023-01-08 16:36:07 - progress_bar.py[line:274] - INFO: epoch 001:  10503 / 144806 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3494, wps=60.9, ups=0.35, wpb=87.1, bsz=32, num_updates=10490, lr=4.79108e-05, gnorm=0.526, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=63382
2023-01-08 16:36:21 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 16:36:38 - progress_bar.py[line:274] - INFO: epoch 001:  10514 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.667, nsentences=32, sample_size=87.667, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3409, wps=59.4, ups=0.32, wpb=87.7, bsz=32, num_updates=10500, lr=4.79072e-05, gnorm=0.482, clip=10, loss_scale=512, train_wall=31, gb_free=15.2, ema_decay=0.9999, wall=63413
2023-01-08 16:37:07 - progress_bar.py[line:274] - INFO: epoch 001:  10524 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3734, wps=59.4, ups=0.34, wpb=86.4, bsz=32, num_updates=10510, lr=4.79037e-05, gnorm=0.431, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=63442
2023-01-08 16:37:36 - progress_bar.py[line:274] - INFO: epoch 001:  10534 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3598, wps=60.4, ups=0.35, wpb=86.8, bsz=32, num_updates=10520, lr=4.79001e-05, gnorm=0.577, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=63471
2023-01-08 16:38:05 - progress_bar.py[line:274] - INFO: epoch 001:  10544 / 144806 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3114, wps=61.2, ups=0.35, wpb=88, bsz=32, num_updates=10530, lr=4.78965e-05, gnorm=0.632, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=63500
2023-01-08 16:38:34 - progress_bar.py[line:274] - INFO: epoch 001:  10554 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3484, wps=61.3, ups=0.35, wpb=87.8, bsz=32, num_updates=10540, lr=4.7893e-05, gnorm=0.54, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=63529
2023-01-08 16:39:02 - progress_bar.py[line:274] - INFO: epoch 001:  10564 / 144806 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2941, wps=63.2, ups=0.36, wpb=88.5, bsz=32, num_updates=10550, lr=4.78894e-05, gnorm=0.56, clip=0, loss_scale=512, train_wall=28, gb_free=15, ema_decay=0.9999, wall=63557
2023-01-08 16:39:31 - progress_bar.py[line:274] - INFO: epoch 001:  10574 / 144806 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3642, wps=60.9, ups=0.35, wpb=87.5, bsz=32, num_updates=10560, lr=4.78858e-05, gnorm=0.542, clip=0, loss_scale=512, train_wall=29, gb_free=14.8, ema_decay=0.9999, wall=63586
2023-01-08 16:40:00 - progress_bar.py[line:274] - INFO: epoch 001:  10584 / 144806 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3784, wps=61, ups=0.35, wpb=87.4, bsz=32, num_updates=10570, lr=4.78823e-05, gnorm=0.521, clip=20, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=63615
2023-01-08 16:40:29 - progress_bar.py[line:274] - INFO: epoch 001:  10594 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3418, wps=61, ups=0.35, wpb=86.5, bsz=32, num_updates=10580, lr=4.78787e-05, gnorm=0.738, clip=20, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=63644
2023-01-08 16:40:57 - progress_bar.py[line:274] - INFO: epoch 001:  10604 / 144806 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.3174, wps=60, ups=0.35, wpb=85.8, bsz=32, num_updates=10590, lr=4.78751e-05, gnorm=0.7, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=63672
2023-01-08 16:41:26 - progress_bar.py[line:274] - INFO: epoch 001:  10614 / 144806 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3735, wps=60.6, ups=0.35, wpb=87.3, bsz=32, num_updates=10600, lr=4.78716e-05, gnorm=0.472, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=63702
2023-01-08 16:41:55 - progress_bar.py[line:274] - INFO: epoch 001:  10624 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4091, wps=61.7, ups=0.35, wpb=88.2, bsz=32, num_updates=10610, lr=4.7868e-05, gnorm=0.496, clip=0, loss_scale=512, train_wall=29, gb_free=15.7, ema_decay=0.9999, wall=63730
2023-01-08 16:42:24 - progress_bar.py[line:274] - INFO: epoch 001:  10634 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4, wps=60.8, ups=0.35, wpb=86.4, bsz=32, num_updates=10620, lr=4.78644e-05, gnorm=0.418, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=63759
2023-01-08 16:42:53 - progress_bar.py[line:274] - INFO: epoch 001:  10644 / 144806 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3007, wps=62.5, ups=0.35, wpb=88.7, bsz=32, num_updates=10630, lr=4.78609e-05, gnorm=0.492, clip=10, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=63788
2023-01-08 16:43:22 - progress_bar.py[line:274] - INFO: epoch 001:  10654 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3581, wps=60.5, ups=0.34, wpb=87.9, bsz=32, num_updates=10640, lr=4.78573e-05, gnorm=0.824, clip=40, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=63817
2023-01-08 16:43:50 - progress_bar.py[line:274] - INFO: epoch 001:  10664 / 144806 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3097, wps=61.4, ups=0.35, wpb=86.6, bsz=32, num_updates=10650, lr=4.78537e-05, gnorm=0.457, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=63845
2023-01-08 16:44:19 - progress_bar.py[line:274] - INFO: epoch 001:  10674 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3988, wps=61.6, ups=0.35, wpb=87, bsz=32, num_updates=10660, lr=4.78502e-05, gnorm=0.71, clip=20, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=63874
2023-01-08 16:44:47 - progress_bar.py[line:274] - INFO: epoch 001:  10684 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3423, wps=62.4, ups=0.36, wpb=87.9, bsz=32, num_updates=10670, lr=4.78466e-05, gnorm=0.448, clip=0, loss_scale=512, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=63902
2023-01-08 16:45:16 - progress_bar.py[line:274] - INFO: epoch 001:  10694 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3879, wps=60.4, ups=0.34, wpb=88.3, bsz=32, num_updates=10680, lr=4.7843e-05, gnorm=0.374, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=63932
2023-01-08 16:45:46 - progress_bar.py[line:274] - INFO: epoch 001:  10704 / 144806 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3354, wps=61, ups=0.35, wpb=88, bsz=32, num_updates=10690, lr=4.78395e-05, gnorm=0.535, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=63961
2023-01-08 16:46:15 - progress_bar.py[line:274] - INFO: epoch 001:  10714 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4305, wps=59.2, ups=0.34, wpb=87.1, bsz=32, num_updates=10700, lr=4.78359e-05, gnorm=0.565, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=63990
2023-01-08 16:46:44 - progress_bar.py[line:274] - INFO: epoch 001:  10724 / 144806 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3354, wps=61.2, ups=0.35, wpb=86.7, bsz=32, num_updates=10710, lr=4.78323e-05, gnorm=0.6, clip=10, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=64019
2023-01-08 16:47:13 - progress_bar.py[line:274] - INFO: epoch 001:  10734 / 144806 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3841, wps=60.4, ups=0.35, wpb=86.8, bsz=32, num_updates=10720, lr=4.78288e-05, gnorm=0.467, clip=0, loss_scale=512, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=64048
2023-01-08 16:47:42 - progress_bar.py[line:274] - INFO: epoch 001:  10744 / 144806 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3718, wps=60.5, ups=0.35, wpb=86.9, bsz=32, num_updates=10730, lr=4.78252e-05, gnorm=0.603, clip=20, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=64077
2023-01-08 16:48:11 - progress_bar.py[line:274] - INFO: epoch 001:  10754 / 144806 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3099, wps=60.1, ups=0.35, wpb=87, bsz=32, num_updates=10740, lr=4.78216e-05, gnorm=0.347, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=64106
2023-01-08 16:48:40 - progress_bar.py[line:274] - INFO: epoch 001:  10764 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3856, wps=60.8, ups=0.35, wpb=87.3, bsz=32, num_updates=10750, lr=4.78181e-05, gnorm=0.486, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=64135
2023-01-08 16:49:09 - progress_bar.py[line:274] - INFO: epoch 001:  10774 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3585, wps=60.6, ups=0.35, wpb=87.2, bsz=32, num_updates=10760, lr=4.78145e-05, gnorm=0.467, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=64164
2023-01-08 16:49:38 - progress_bar.py[line:274] - INFO: epoch 001:  10784 / 144806 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.3669, wps=59.2, ups=0.34, wpb=86, bsz=32, num_updates=10770, lr=4.78109e-05, gnorm=0.695, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=64193
2023-01-08 16:50:07 - progress_bar.py[line:274] - INFO: epoch 001:  10794 / 144806 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3718, wps=60.8, ups=0.35, wpb=86.9, bsz=32, num_updates=10780, lr=4.78074e-05, gnorm=0.698, clip=20, loss_scale=512, train_wall=29, gb_free=15.7, ema_decay=0.9999, wall=64222
2023-01-08 16:50:36 - progress_bar.py[line:274] - INFO: epoch 001:  10804 / 144806 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3807, wps=60.3, ups=0.35, wpb=86.7, bsz=32, num_updates=10790, lr=4.78038e-05, gnorm=0.529, clip=10, loss_scale=512, train_wall=29, gb_free=15.7, ema_decay=0.9999, wall=64251
2023-01-08 16:51:05 - progress_bar.py[line:274] - INFO: epoch 001:  10814 / 144806 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3446, wps=60.1, ups=0.34, wpb=87.7, bsz=32, num_updates=10800, lr=4.78002e-05, gnorm=0.442, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=64280
2023-01-08 16:51:34 - progress_bar.py[line:274] - INFO: epoch 001:  10824 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3497, wps=60.6, ups=0.35, wpb=87.1, bsz=32, num_updates=10810, lr=4.77967e-05, gnorm=0.888, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=64309
2023-01-08 16:52:03 - progress_bar.py[line:274] - INFO: epoch 001:  10834 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.354, wps=62, ups=0.35, wpb=88.2, bsz=32, num_updates=10820, lr=4.77931e-05, gnorm=0.444, clip=0, loss_scale=512, train_wall=28, gb_free=14.6, ema_decay=0.9999, wall=64338
2023-01-08 16:52:32 - progress_bar.py[line:274] - INFO: epoch 001:  10844 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5197, wps=60, ups=0.35, wpb=86.9, bsz=32, num_updates=10830, lr=4.77895e-05, gnorm=0.475, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=64367
2023-01-08 16:53:01 - progress_bar.py[line:274] - INFO: epoch 001:  10854 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3374, wps=60.2, ups=0.35, wpb=87, bsz=32, num_updates=10840, lr=4.7786e-05, gnorm=0.513, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=64396
2023-01-08 16:53:30 - progress_bar.py[line:274] - INFO: epoch 001:  10864 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3399, wps=60.8, ups=0.35, wpb=87.6, bsz=32, num_updates=10850, lr=4.77824e-05, gnorm=0.502, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=64425
2023-01-08 16:54:00 - progress_bar.py[line:274] - INFO: epoch 001:  10874 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.327, wps=60.2, ups=0.35, wpb=87, bsz=32, num_updates=10860, lr=4.77788e-05, gnorm=0.47, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=64454
2023-01-08 16:54:29 - progress_bar.py[line:274] - INFO: epoch 001:  10884 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4451, wps=60.5, ups=0.34, wpb=87.9, bsz=32, num_updates=10870, lr=4.77752e-05, gnorm=0.709, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=64484
2023-01-08 16:54:57 - progress_bar.py[line:274] - INFO: epoch 001:  10894 / 144806 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3121, wps=62.7, ups=0.36, wpb=87.2, bsz=32, num_updates=10880, lr=4.77717e-05, gnorm=0.563, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=64512
2023-01-08 16:55:26 - progress_bar.py[line:274] - INFO: epoch 001:  10904 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.359, wps=60.3, ups=0.34, wpb=88.5, bsz=32, num_updates=10890, lr=4.77681e-05, gnorm=0.459, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=64541
2023-01-08 16:55:55 - progress_bar.py[line:274] - INFO: epoch 001:  10914 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3419, wps=60.5, ups=0.35, wpb=87.1, bsz=32, num_updates=10900, lr=4.77645e-05, gnorm=0.298, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=64570
2023-01-08 16:56:25 - progress_bar.py[line:274] - INFO: epoch 001:  10924 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3586, wps=60.6, ups=0.34, wpb=88.2, bsz=32, num_updates=10910, lr=4.7761e-05, gnorm=0.504, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=64600
2023-01-08 16:56:54 - progress_bar.py[line:274] - INFO: epoch 001:  10934 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=89, nsentences=32, sample_size=89, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3929, wps=62, ups=0.35, wpb=89, bsz=32, num_updates=10920, lr=4.77574e-05, gnorm=0.37, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=64629
2023-01-08 16:57:23 - progress_bar.py[line:274] - INFO: epoch 001:  10944 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3436, wps=60.9, ups=0.35, wpb=86.7, bsz=32, num_updates=10930, lr=4.77538e-05, gnorm=0.605, clip=10, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=64658
2023-01-08 16:57:51 - progress_bar.py[line:274] - INFO: epoch 001:  10954 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3789, wps=62.2, ups=0.35, wpb=88.2, bsz=32, num_updates=10940, lr=4.77503e-05, gnorm=0.462, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=64686
2023-01-08 16:58:20 - progress_bar.py[line:274] - INFO: epoch 001:  10964 / 144806 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.3352, wps=59.3, ups=0.35, wpb=85.5, bsz=32, num_updates=10950, lr=4.77467e-05, gnorm=0.517, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=64715
2023-01-08 16:58:49 - progress_bar.py[line:274] - INFO: epoch 001:  10974 / 144806 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=85.1, nsentences=32, sample_size=85.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3353, wps=59.4, ups=0.35, wpb=85.1, bsz=32, num_updates=10960, lr=4.77431e-05, gnorm=0.57, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=64744
2023-01-08 16:59:18 - progress_bar.py[line:274] - INFO: epoch 001:  10984 / 144806 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3919, wps=60.2, ups=0.34, wpb=87.4, bsz=32, num_updates=10970, lr=4.77396e-05, gnorm=0.634, clip=20, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=64773
2023-01-08 16:59:48 - progress_bar.py[line:274] - INFO: epoch 001:  10994 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2938, wps=59.6, ups=0.34, wpb=86.7, bsz=32, num_updates=10980, lr=4.7736e-05, gnorm=0.519, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=64803
2023-01-08 17:00:16 - progress_bar.py[line:274] - INFO: epoch 001:  11004 / 144806 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3459, wps=62.1, ups=0.35, wpb=88, bsz=32, num_updates=10990, lr=4.77324e-05, gnorm=0.448, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=64831
2023-01-08 17:00:45 - progress_bar.py[line:274] - INFO: epoch 001:  11014 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3933, wps=60.9, ups=0.35, wpb=87.4, bsz=32, num_updates=11000, lr=4.77289e-05, gnorm=0.601, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=64860
2023-01-08 17:01:14 - progress_bar.py[line:274] - INFO: epoch 001:  11024 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3677, wps=61.7, ups=0.35, wpb=88.3, bsz=32, num_updates=11010, lr=4.77253e-05, gnorm=0.445, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=64889
2023-01-08 17:01:43 - progress_bar.py[line:274] - INFO: epoch 001:  11034 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3759, wps=60.9, ups=0.35, wpb=88, bsz=32, num_updates=11020, lr=4.77217e-05, gnorm=0.606, clip=20, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=64918
2023-01-08 17:02:12 - progress_bar.py[line:274] - INFO: epoch 001:  11044 / 144806 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3782, wps=60.8, ups=0.35, wpb=86.4, bsz=32, num_updates=11030, lr=4.77182e-05, gnorm=0.417, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=64947
2023-01-08 17:02:41 - progress_bar.py[line:274] - INFO: epoch 001:  11054 / 144806 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3671, wps=61.3, ups=0.35, wpb=88.5, bsz=32, num_updates=11040, lr=4.77146e-05, gnorm=0.535, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=64976
2023-01-08 17:03:01 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 17:03:13 - progress_bar.py[line:274] - INFO: epoch 001:  11065 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.048, nsentences=32, sample_size=88.048, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3353, wps=58.2, ups=0.31, wpb=88, bsz=32, num_updates=11050, lr=4.7711e-05, gnorm=0.53, clip=10, loss_scale=512, train_wall=32, gb_free=15.4, ema_decay=0.9999, wall=65008
2023-01-08 17:03:43 - progress_bar.py[line:274] - INFO: epoch 001:  11075 / 144806 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=84.9, nsentences=32, sample_size=84.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.4044, wps=58, ups=0.34, wpb=84.9, bsz=32, num_updates=11060, lr=4.77075e-05, gnorm=0.482, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=65038
2023-01-08 17:04:12 - progress_bar.py[line:274] - INFO: epoch 001:  11085 / 144806 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3882, wps=60.9, ups=0.35, wpb=87.9, bsz=32, num_updates=11070, lr=4.77039e-05, gnorm=0.391, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65067
2023-01-08 17:04:41 - progress_bar.py[line:274] - INFO: epoch 001:  11095 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4268, wps=60.2, ups=0.35, wpb=86.3, bsz=32, num_updates=11080, lr=4.77003e-05, gnorm=0.425, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=65096
2023-01-08 17:05:10 - progress_bar.py[line:274] - INFO: epoch 001:  11105 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.454, wps=59.8, ups=0.34, wpb=86.8, bsz=32, num_updates=11090, lr=4.76968e-05, gnorm=0.453, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65125
2023-01-08 17:05:39 - progress_bar.py[line:274] - INFO: epoch 001:  11115 / 144806 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4136, wps=60.3, ups=0.35, wpb=87.4, bsz=32, num_updates=11100, lr=4.76932e-05, gnorm=0.692, clip=30, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65154
2023-01-08 17:06:08 - progress_bar.py[line:274] - INFO: epoch 001:  11125 / 144806 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.425, wps=60.5, ups=0.35, wpb=86.7, bsz=32, num_updates=11110, lr=4.76896e-05, gnorm=0.442, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65183
2023-01-08 17:06:37 - progress_bar.py[line:274] - INFO: epoch 001:  11135 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3333, wps=61.3, ups=0.35, wpb=87.5, bsz=32, num_updates=11120, lr=4.76861e-05, gnorm=0.483, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=65212
2023-01-08 17:07:06 - progress_bar.py[line:274] - INFO: epoch 001:  11145 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3374, wps=61.3, ups=0.35, wpb=87.6, bsz=32, num_updates=11130, lr=4.76825e-05, gnorm=0.573, clip=20, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65241
2023-01-08 17:07:34 - progress_bar.py[line:274] - INFO: epoch 001:  11155 / 144806 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3636, wps=61.1, ups=0.35, wpb=86.7, bsz=32, num_updates=11140, lr=4.76789e-05, gnorm=0.565, clip=20, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=65269
2023-01-08 17:08:03 - progress_bar.py[line:274] - INFO: epoch 001:  11165 / 144806 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3869, wps=60.5, ups=0.35, wpb=86.2, bsz=32, num_updates=11150, lr=4.76754e-05, gnorm=0.522, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=65298
2023-01-08 17:08:32 - progress_bar.py[line:274] - INFO: epoch 001:  11175 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.381, wps=60.6, ups=0.35, wpb=86.6, bsz=32, num_updates=11160, lr=4.76718e-05, gnorm=0.585, clip=10, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=65327
2023-01-08 17:09:01 - progress_bar.py[line:274] - INFO: epoch 001:  11185 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3766, wps=60.4, ups=0.34, wpb=87.7, bsz=32, num_updates=11170, lr=4.76682e-05, gnorm=0.511, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65356
2023-01-08 17:09:30 - progress_bar.py[line:274] - INFO: epoch 001:  11195 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4028, wps=61.6, ups=0.35, wpb=88.6, bsz=32, num_updates=11180, lr=4.76647e-05, gnorm=0.416, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=65385
2023-01-08 17:09:59 - progress_bar.py[line:274] - INFO: epoch 001:  11205 / 144806 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.4035, wps=59.6, ups=0.34, wpb=86.4, bsz=32, num_updates=11190, lr=4.76611e-05, gnorm=0.496, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65414
2023-01-08 17:10:28 - progress_bar.py[line:274] - INFO: epoch 001:  11215 / 144806 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3963, wps=60.9, ups=0.35, wpb=87.3, bsz=32, num_updates=11200, lr=4.76575e-05, gnorm=0.435, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65443
2023-01-08 17:10:57 - progress_bar.py[line:274] - INFO: epoch 001:  11225 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.34, wps=61.8, ups=0.35, wpb=88.7, bsz=32, num_updates=11210, lr=4.7654e-05, gnorm=0.371, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65472
2023-01-08 17:11:26 - progress_bar.py[line:274] - INFO: epoch 001:  11235 / 144806 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3219, wps=61.4, ups=0.35, wpb=87.4, bsz=32, num_updates=11220, lr=4.76504e-05, gnorm=0.458, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=65501
2023-01-08 17:11:54 - progress_bar.py[line:274] - INFO: epoch 001:  11245 / 144806 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3681, wps=61.5, ups=0.35, wpb=86.8, bsz=32, num_updates=11230, lr=4.76468e-05, gnorm=0.632, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=65529
2023-01-08 17:12:24 - progress_bar.py[line:274] - INFO: epoch 001:  11255 / 144806 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3733, wps=60.6, ups=0.34, wpb=88.3, bsz=32, num_updates=11240, lr=4.76433e-05, gnorm=0.433, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=65559
2023-01-08 17:12:52 - progress_bar.py[line:274] - INFO: epoch 001:  11265 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3935, wps=62.1, ups=0.35, wpb=88.7, bsz=32, num_updates=11250, lr=4.76397e-05, gnorm=0.402, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=65587
2023-01-08 17:13:21 - progress_bar.py[line:274] - INFO: epoch 001:  11275 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.319, wps=61.1, ups=0.35, wpb=87.1, bsz=32, num_updates=11260, lr=4.76361e-05, gnorm=0.61, clip=10, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=65616
2023-01-08 17:13:50 - progress_bar.py[line:274] - INFO: epoch 001:  11285 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4907, wps=61, ups=0.35, wpb=87.1, bsz=32, num_updates=11270, lr=4.76326e-05, gnorm=0.403, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65645
2023-01-08 17:14:19 - progress_bar.py[line:274] - INFO: epoch 001:  11295 / 144806 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3602, wps=61.6, ups=0.35, wpb=88.3, bsz=32, num_updates=11280, lr=4.7629e-05, gnorm=0.546, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=65674
2023-01-08 17:14:48 - progress_bar.py[line:274] - INFO: epoch 001:  11305 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3899, wps=60.4, ups=0.35, wpb=86.9, bsz=32, num_updates=11290, lr=4.76254e-05, gnorm=0.49, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=65703
2023-01-08 17:15:17 - progress_bar.py[line:274] - INFO: epoch 001:  11315 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4094, wps=60.1, ups=0.35, wpb=86.5, bsz=32, num_updates=11300, lr=4.76219e-05, gnorm=0.445, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=65732
2023-01-08 17:15:45 - progress_bar.py[line:274] - INFO: epoch 001:  11325 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3907, wps=61.6, ups=0.35, wpb=87.1, bsz=32, num_updates=11310, lr=4.76183e-05, gnorm=0.507, clip=0, loss_scale=512, train_wall=28, gb_free=14.9, ema_decay=0.9999, wall=65760
2023-01-08 17:16:15 - progress_bar.py[line:274] - INFO: epoch 001:  11335 / 144806 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3871, wps=60, ups=0.34, wpb=87.1, bsz=32, num_updates=11320, lr=4.76147e-05, gnorm=0.482, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=65790
2023-01-08 17:16:44 - progress_bar.py[line:274] - INFO: epoch 001:  11345 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3526, wps=60.5, ups=0.34, wpb=88.1, bsz=32, num_updates=11330, lr=4.76112e-05, gnorm=0.355, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65819
2023-01-08 17:17:13 - progress_bar.py[line:274] - INFO: epoch 001:  11355 / 144806 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.434, wps=60.4, ups=0.35, wpb=87.1, bsz=32, num_updates=11340, lr=4.76076e-05, gnorm=0.569, clip=20, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65848
2023-01-08 17:17:42 - progress_bar.py[line:274] - INFO: epoch 001:  11365 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3841, wps=59.2, ups=0.34, wpb=86.5, bsz=32, num_updates=11350, lr=4.7604e-05, gnorm=0.477, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65878
2023-01-08 17:18:11 - progress_bar.py[line:274] - INFO: epoch 001:  11375 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3665, wps=60.5, ups=0.35, wpb=86.5, bsz=32, num_updates=11360, lr=4.76005e-05, gnorm=0.428, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65906
2023-01-08 17:18:40 - progress_bar.py[line:274] - INFO: epoch 001:  11385 / 144806 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=89.1, nsentences=32, sample_size=89.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3248, wps=61.5, ups=0.35, wpb=89.1, bsz=32, num_updates=11370, lr=4.75969e-05, gnorm=0.532, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=65936
2023-01-08 17:19:09 - progress_bar.py[line:274] - INFO: epoch 001:  11395 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4178, wps=62.1, ups=0.35, wpb=88, bsz=32, num_updates=11380, lr=4.75933e-05, gnorm=0.414, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=65964
2023-01-08 17:19:38 - progress_bar.py[line:274] - INFO: epoch 001:  11405 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4189, wps=61.4, ups=0.35, wpb=88.3, bsz=32, num_updates=11390, lr=4.75898e-05, gnorm=0.45, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=65993
2023-01-08 17:20:07 - progress_bar.py[line:274] - INFO: epoch 001:  11415 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3774, wps=60.5, ups=0.35, wpb=87.3, bsz=32, num_updates=11400, lr=4.75862e-05, gnorm=0.559, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=66022
2023-01-08 17:20:36 - progress_bar.py[line:274] - INFO: epoch 001:  11425 / 144806 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3291, wps=60.8, ups=0.35, wpb=87.6, bsz=32, num_updates=11410, lr=4.75826e-05, gnorm=0.492, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=66051
2023-01-08 17:21:06 - progress_bar.py[line:274] - INFO: epoch 001:  11435 / 144806 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3442, wps=59.2, ups=0.34, wpb=87.3, bsz=32, num_updates=11420, lr=4.75791e-05, gnorm=0.566, clip=20, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=66081
2023-01-08 17:21:35 - progress_bar.py[line:274] - INFO: epoch 001:  11445 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.381, wps=60.2, ups=0.35, wpb=86.7, bsz=32, num_updates=11430, lr=4.75755e-05, gnorm=0.514, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=66110
2023-01-08 17:22:04 - progress_bar.py[line:274] - INFO: epoch 001:  11455 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4076, wps=59.9, ups=0.35, wpb=86.2, bsz=32, num_updates=11440, lr=4.75719e-05, gnorm=0.498, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=66139
2023-01-08 17:22:34 - progress_bar.py[line:274] - INFO: epoch 001:  11465 / 144806 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3869, wps=58.7, ups=0.34, wpb=85.9, bsz=32, num_updates=11450, lr=4.75684e-05, gnorm=0.381, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=66169
2023-01-08 17:23:02 - progress_bar.py[line:274] - INFO: epoch 001:  11475 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.427, wps=61.1, ups=0.35, wpb=86.4, bsz=32, num_updates=11460, lr=4.75648e-05, gnorm=0.455, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=66197
2023-01-08 17:23:31 - progress_bar.py[line:274] - INFO: epoch 001:  11485 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3902, wps=59.7, ups=0.34, wpb=86.8, bsz=32, num_updates=11470, lr=4.75612e-05, gnorm=0.434, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=66226
2023-01-08 17:24:01 - progress_bar.py[line:274] - INFO: epoch 001:  11495 / 144806 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3522, wps=60.3, ups=0.35, wpb=87.1, bsz=32, num_updates=11480, lr=4.75577e-05, gnorm=0.571, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=66256
2023-01-08 17:24:30 - progress_bar.py[line:274] - INFO: epoch 001:  11505 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3775, wps=61, ups=0.34, wpb=88.5, bsz=32, num_updates=11490, lr=4.75541e-05, gnorm=0.574, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=66285
2023-01-08 17:24:59 - progress_bar.py[line:274] - INFO: epoch 001:  11515 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3701, wps=60.2, ups=0.34, wpb=87.3, bsz=32, num_updates=11500, lr=4.75505e-05, gnorm=0.492, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=66314
2023-01-08 17:25:28 - progress_bar.py[line:274] - INFO: epoch 001:  11525 / 144806 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3179, wps=61.6, ups=0.35, wpb=87.3, bsz=32, num_updates=11510, lr=4.7547e-05, gnorm=0.579, clip=20, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=66343
2023-01-08 17:25:57 - progress_bar.py[line:274] - INFO: epoch 001:  11535 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3529, wps=61.1, ups=0.35, wpb=88.3, bsz=32, num_updates=11520, lr=4.75434e-05, gnorm=0.482, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=66372
2023-01-08 17:26:26 - progress_bar.py[line:274] - INFO: epoch 001:  11545 / 144806 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3554, wps=60.7, ups=0.35, wpb=87.8, bsz=32, num_updates=11530, lr=4.75398e-05, gnorm=0.517, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=66401
2023-01-08 17:26:55 - progress_bar.py[line:274] - INFO: epoch 001:  11555 / 144806 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3804, wps=60.3, ups=0.35, wpb=86.9, bsz=32, num_updates=11540, lr=4.75363e-05, gnorm=0.576, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=66430
2023-01-08 17:27:24 - progress_bar.py[line:274] - INFO: epoch 001:  11565 / 144806 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4464, wps=60.1, ups=0.34, wpb=87.2, bsz=32, num_updates=11550, lr=4.75327e-05, gnorm=0.636, clip=20, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=66459
2023-01-08 17:27:54 - progress_bar.py[line:274] - INFO: epoch 001:  11575 / 144806 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3571, wps=59.4, ups=0.34, wpb=87.2, bsz=32, num_updates=11560, lr=4.75291e-05, gnorm=0.377, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=66489
2023-01-08 17:28:23 - progress_bar.py[line:274] - INFO: epoch 001:  11585 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4437, wps=60.3, ups=0.35, wpb=86.9, bsz=32, num_updates=11570, lr=4.75256e-05, gnorm=0.507, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=66518
2023-01-08 17:28:52 - progress_bar.py[line:274] - INFO: epoch 001:  11595 / 144806 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.4104, wps=59.6, ups=0.34, wpb=86.4, bsz=32, num_updates=11580, lr=4.7522e-05, gnorm=0.43, clip=0, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=66547
2023-01-08 17:29:21 - progress_bar.py[line:274] - INFO: epoch 001:  11605 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.38, wps=62.5, ups=0.36, wpb=87.8, bsz=32, num_updates=11590, lr=4.75184e-05, gnorm=0.474, clip=0, loss_scale=1024, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=66576
2023-01-08 17:29:49 - progress_bar.py[line:274] - INFO: epoch 001:  11615 / 144806 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3977, wps=61.3, ups=0.35, wpb=87.1, bsz=32, num_updates=11600, lr=4.75149e-05, gnorm=0.459, clip=10, loss_scale=1024, train_wall=28, gb_free=14.7, ema_decay=0.9999, wall=66604
2023-01-08 17:30:18 - progress_bar.py[line:274] - INFO: epoch 001:  11625 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4026, wps=60.2, ups=0.35, wpb=86.7, bsz=32, num_updates=11610, lr=4.75113e-05, gnorm=0.547, clip=20, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=66633
2023-01-08 17:30:47 - progress_bar.py[line:274] - INFO: epoch 001:  11635 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3734, wps=62.1, ups=0.35, wpb=88, bsz=32, num_updates=11620, lr=4.75077e-05, gnorm=0.587, clip=10, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=66662
2023-01-08 17:31:16 - progress_bar.py[line:274] - INFO: epoch 001:  11645 / 144806 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4242, wps=59.8, ups=0.35, wpb=86.4, bsz=32, num_updates=11630, lr=4.75042e-05, gnorm=0.54, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=66691
2023-01-08 17:31:45 - progress_bar.py[line:274] - INFO: epoch 001:  11655 / 144806 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4011, wps=60, ups=0.35, wpb=86.2, bsz=32, num_updates=11640, lr=4.75006e-05, gnorm=0.639, clip=10, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=66720
2023-01-08 17:32:14 - progress_bar.py[line:274] - INFO: epoch 001:  11665 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.408, wps=60, ups=0.35, wpb=86.4, bsz=32, num_updates=11650, lr=4.7497e-05, gnorm=0.425, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=66749
2023-01-08 17:32:43 - progress_bar.py[line:274] - INFO: epoch 001:  11675 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3478, wps=60.5, ups=0.35, wpb=87, bsz=32, num_updates=11660, lr=4.74935e-05, gnorm=0.458, clip=0, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=66778
2023-01-08 17:33:12 - progress_bar.py[line:274] - INFO: epoch 001:  11685 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3816, wps=60.5, ups=0.35, wpb=86.8, bsz=32, num_updates=11670, lr=4.74899e-05, gnorm=0.326, clip=0, loss_scale=1024, train_wall=29, gb_free=15, ema_decay=0.9999, wall=66807
2023-01-08 17:33:42 - progress_bar.py[line:274] - INFO: epoch 001:  11695 / 144806 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3609, wps=58.7, ups=0.34, wpb=85.9, bsz=32, num_updates=11680, lr=4.74863e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=66837
2023-01-08 17:34:11 - progress_bar.py[line:274] - INFO: epoch 001:  11705 / 144806 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4013, wps=60.9, ups=0.35, wpb=87.9, bsz=32, num_updates=11690, lr=4.74828e-05, gnorm=0.494, clip=10, loss_scale=1024, train_wall=29, gb_free=14.8, ema_decay=0.9999, wall=66866
2023-01-08 17:34:41 - progress_bar.py[line:274] - INFO: epoch 001:  11715 / 144806 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3869, wps=59.3, ups=0.34, wpb=87.2, bsz=32, num_updates=11700, lr=4.74792e-05, gnorm=0.494, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=66896
2023-01-08 17:35:10 - progress_bar.py[line:274] - INFO: epoch 001:  11725 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4136, wps=60.5, ups=0.35, wpb=86.6, bsz=32, num_updates=11710, lr=4.74756e-05, gnorm=0.457, clip=0, loss_scale=1024, train_wall=29, gb_free=14.8, ema_decay=0.9999, wall=66925
2023-01-08 17:35:39 - progress_bar.py[line:274] - INFO: epoch 001:  11735 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3618, wps=60.7, ups=0.35, wpb=87.1, bsz=32, num_updates=11720, lr=4.74721e-05, gnorm=0.469, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=66954
2023-01-08 17:36:07 - progress_bar.py[line:274] - INFO: epoch 001:  11745 / 144806 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4155, wps=62.9, ups=0.35, wpb=88.8, bsz=32, num_updates=11730, lr=4.74685e-05, gnorm=0.564, clip=10, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=66982
2023-01-08 17:36:36 - progress_bar.py[line:274] - INFO: epoch 001:  11755 / 144806 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4365, wps=59.8, ups=0.35, wpb=86, bsz=32, num_updates=11740, lr=4.74649e-05, gnorm=0.524, clip=0, loss_scale=1024, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=67011
2023-01-08 17:37:05 - progress_bar.py[line:274] - INFO: epoch 001:  11765 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4286, wps=61.4, ups=0.35, wpb=87.8, bsz=32, num_updates=11750, lr=4.74614e-05, gnorm=0.418, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=67040
2023-01-08 17:37:34 - progress_bar.py[line:274] - INFO: epoch 001:  11775 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3484, wps=61.2, ups=0.35, wpb=88.5, bsz=32, num_updates=11760, lr=4.74578e-05, gnorm=0.649, clip=10, loss_scale=1024, train_wall=29, gb_free=15, ema_decay=0.9999, wall=67069
2023-01-08 17:37:43 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 17:38:06 - progress_bar.py[line:274] - INFO: epoch 001:  11786 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.762, nsentences=32, sample_size=86.762, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.375, wps=57.9, ups=0.32, wpb=86.8, bsz=32, num_updates=11770, lr=4.74542e-05, gnorm=0.53, clip=10, loss_scale=512, train_wall=31, gb_free=14.7, ema_decay=0.9999, wall=67101
2023-01-08 17:38:35 - progress_bar.py[line:274] - INFO: epoch 001:  11796 / 144806 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3765, wps=61.3, ups=0.35, wpb=88.1, bsz=32, num_updates=11780, lr=4.74507e-05, gnorm=0.486, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=67130
2023-01-08 17:39:04 - progress_bar.py[line:274] - INFO: epoch 001:  11806 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3892, wps=61.9, ups=0.35, wpb=87.5, bsz=32, num_updates=11790, lr=4.74471e-05, gnorm=0.536, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=67159
2023-01-08 17:39:32 - progress_bar.py[line:274] - INFO: epoch 001:  11816 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3481, wps=62.1, ups=0.35, wpb=87.9, bsz=32, num_updates=11800, lr=4.74435e-05, gnorm=0.373, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=67187
2023-01-08 17:40:01 - progress_bar.py[line:274] - INFO: epoch 001:  11826 / 144806 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.3459, wps=61.4, ups=0.35, wpb=87.1, bsz=32, num_updates=11810, lr=4.74399e-05, gnorm=0.536, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=67216
2023-01-08 17:40:30 - progress_bar.py[line:274] - INFO: epoch 001:  11836 / 144806 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3812, wps=59.7, ups=0.34, wpb=86.7, bsz=32, num_updates=11820, lr=4.74364e-05, gnorm=0.602, clip=20, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=67245
2023-01-08 17:40:59 - progress_bar.py[line:274] - INFO: epoch 001:  11846 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=85.4, nsentences=32, sample_size=85.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4365, wps=58.8, ups=0.34, wpb=85.4, bsz=32, num_updates=11830, lr=4.74328e-05, gnorm=0.445, clip=10, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=67274
2023-01-08 17:41:29 - progress_bar.py[line:274] - INFO: epoch 001:  11856 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4026, wps=61.1, ups=0.35, wpb=88, bsz=32, num_updates=11840, lr=4.74292e-05, gnorm=0.352, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=67304
2023-01-08 17:41:57 - progress_bar.py[line:274] - INFO: epoch 001:  11866 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4157, wps=61.4, ups=0.36, wpb=86.2, bsz=32, num_updates=11850, lr=4.74257e-05, gnorm=0.456, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=67332
2023-01-08 17:42:25 - progress_bar.py[line:274] - INFO: epoch 001:  11876 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4204, wps=61.7, ups=0.35, wpb=86.9, bsz=32, num_updates=11860, lr=4.74221e-05, gnorm=0.433, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=67360
2023-01-08 17:42:54 - progress_bar.py[line:274] - INFO: epoch 001:  11886 / 144806 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4237, wps=60.6, ups=0.35, wpb=86.9, bsz=32, num_updates=11870, lr=4.74185e-05, gnorm=0.409, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=67389
2023-01-08 17:43:23 - progress_bar.py[line:274] - INFO: epoch 001:  11896 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3765, wps=60.4, ups=0.35, wpb=87.5, bsz=32, num_updates=11880, lr=4.7415e-05, gnorm=0.39, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=67418
2023-01-08 17:43:53 - progress_bar.py[line:274] - INFO: epoch 001:  11906 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4088, wps=60.3, ups=0.35, wpb=87.1, bsz=32, num_updates=11890, lr=4.74114e-05, gnorm=0.384, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=67448
2023-01-08 17:44:21 - progress_bar.py[line:274] - INFO: epoch 001:  11916 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3889, wps=61.5, ups=0.35, wpb=87.1, bsz=32, num_updates=11900, lr=4.74078e-05, gnorm=0.481, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=67476
2023-01-08 17:44:50 - progress_bar.py[line:274] - INFO: epoch 001:  11926 / 144806 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4211, wps=60.8, ups=0.35, wpb=85.9, bsz=32, num_updates=11910, lr=4.74043e-05, gnorm=0.406, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=67505
2023-01-08 17:45:19 - progress_bar.py[line:274] - INFO: epoch 001:  11936 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4387, wps=61, ups=0.35, wpb=88, bsz=32, num_updates=11920, lr=4.74007e-05, gnorm=0.43, clip=0, loss_scale=512, train_wall=29, gb_free=15.6, ema_decay=0.9999, wall=67534
2023-01-08 17:45:48 - progress_bar.py[line:274] - INFO: epoch 001:  11946 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3481, wps=60.7, ups=0.35, wpb=87.3, bsz=32, num_updates=11930, lr=4.73971e-05, gnorm=0.353, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=67563
2023-01-08 17:46:16 - progress_bar.py[line:274] - INFO: epoch 001:  11956 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3782, wps=62.4, ups=0.35, wpb=88.6, bsz=32, num_updates=11940, lr=4.73936e-05, gnorm=0.481, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=67592
2023-01-08 17:46:46 - progress_bar.py[line:274] - INFO: epoch 001:  11966 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4242, wps=59.9, ups=0.34, wpb=87.3, bsz=32, num_updates=11950, lr=4.739e-05, gnorm=0.468, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=67621
2023-01-08 17:47:15 - progress_bar.py[line:274] - INFO: epoch 001:  11976 / 144806 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3529, wps=59.2, ups=0.34, wpb=86.2, bsz=32, num_updates=11960, lr=4.73864e-05, gnorm=0.503, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=67650
2023-01-08 17:47:44 - progress_bar.py[line:274] - INFO: epoch 001:  11986 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3941, wps=61.1, ups=0.35, wpb=86.6, bsz=32, num_updates=11970, lr=4.73829e-05, gnorm=0.552, clip=20, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=67679
2023-01-08 17:48:13 - progress_bar.py[line:274] - INFO: epoch 001:  11996 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3819, wps=61.3, ups=0.35, wpb=88.1, bsz=32, num_updates=11980, lr=4.73793e-05, gnorm=0.391, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=67708
2023-01-08 17:48:43 - progress_bar.py[line:274] - INFO: epoch 001:  12006 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3784, wps=61.2, ups=0.35, wpb=88.5, bsz=32, num_updates=11990, lr=4.73757e-05, gnorm=0.696, clip=10, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=67737
2023-01-08 17:49:11 - progress_bar.py[line:274] - INFO: epoch 001:  12016 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4026, wps=61.3, ups=0.35, wpb=86.6, bsz=32, num_updates=12000, lr=4.73722e-05, gnorm=0.508, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=67766
2023-01-08 17:49:11 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 17:49:13 - train.py[line:549] - INFO: 0 / 6234
2023-01-08 17:49:13 - train.py[line:551] - INFO: load:1.02 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 17:49:45 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.97 GiB (GPU 0; 39.59 GiB total capacity; 8.42 GiB already allocated; 4.70 GiB free; 23.31 GiB reserved in total by PyTorch)
2023-01-08 17:49:45 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 36        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8621 MB |   12802 MB |    5773 TB |    5773 TB |
|       from large pool |    8447 MB |   12628 MB |    5770 TB |    5770 TB |
|       from small pool |     174 MB |     174 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8621 MB |   12802 MB |    5773 TB |    5773 TB |
|       from large pool |    8447 MB |   12628 MB |    5770 TB |    5770 TB |
|       from small pool |     174 MB |     174 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   23866 MB |   28384 MB |  438676 MB |  414810 MB |
|       from large pool |   23690 MB |   28206 MB |  437970 MB |  414280 MB |
|       from small pool |     176 MB |     180 MB |     706 MB |     530 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   15244 MB |   18951 MB |    5766 TB |    5766 TB |
|       from large pool |   15242 MB |   18949 MB |    5762 TB |    5762 TB |
|       from small pool |       1 MB |       3 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4634    |    4648    |  311052 K  |  311047 K  |
|       from large pool |     698    |     710    |  105202 K  |  105201 K  |
|       from small pool |    3936    |    3946    |  205850 K  |  205846 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4634    |    4648    |  311052 K  |  311047 K  |
|       from large pool |     698    |     710    |  105202 K  |  105201 K  |
|       from small pool |    3936    |    3946    |  205850 K  |  205846 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     193    |     210    |    1280    |    1087    |
|       from large pool |     105    |     120    |     927    |     822    |
|       from small pool |      88    |      90    |     353    |     265    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     120    |     137    |  228280 K  |  228280 K  |
|       from large pool |      67    |      75    |   54235 K  |   54235 K  |
|       from small pool |      53    |      67    |  174044 K  |  174044 K  |
|===========================================================================|

2023-01-08 17:49:45 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-08 17:49:45 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-08 17:53:27 - train.py[line:549] - INFO: 200 / 6234
2023-01-08 17:53:27 - train.py[line:551] - INFO: load:1.04 valid_run:254.79 task_valid:250.18 collect_output:0.70
2023-01-08 17:57:36 - train.py[line:549] - INFO: 400 / 6234
2023-01-08 17:57:36 - train.py[line:551] - INFO: load:1.07 valid_run:503.62 task_valid:495.74 collect_output:1.39
2023-01-08 18:01:46 - train.py[line:549] - INFO: 600 / 6234
2023-01-08 18:01:46 - train.py[line:551] - INFO: load:1.09 valid_run:753.01 task_valid:741.94 collect_output:2.06
2023-01-08 18:05:51 - train.py[line:549] - INFO: 800 / 6234
2023-01-08 18:05:51 - train.py[line:551] - INFO: load:1.12 valid_run:998.36 task_valid:984.14 collect_output:2.71
2023-01-08 18:10:02 - train.py[line:549] - INFO: 1000 / 6234
2023-01-08 18:10:02 - train.py[line:551] - INFO: load:1.14 valid_run:1249.27 task_valid:1231.87 collect_output:3.38
2023-01-08 18:14:15 - train.py[line:549] - INFO: 1200 / 6234
2023-01-08 18:14:15 - train.py[line:551] - INFO: load:1.17 valid_run:1501.90 task_valid:1481.28 collect_output:4.03
2023-01-08 18:18:27 - train.py[line:549] - INFO: 1400 / 6234
2023-01-08 18:18:27 - train.py[line:551] - INFO: load:1.19 valid_run:1753.63 task_valid:1729.80 collect_output:4.69
2023-01-08 18:22:37 - train.py[line:549] - INFO: 1600 / 6234
2023-01-08 18:22:37 - train.py[line:551] - INFO: load:1.22 valid_run:2003.27 task_valid:1976.20 collect_output:5.39
2023-01-08 18:26:47 - train.py[line:549] - INFO: 1800 / 6234
2023-01-08 18:26:47 - train.py[line:551] - INFO: load:1.24 valid_run:2253.78 task_valid:2223.48 collect_output:6.07
2023-01-08 18:30:52 - train.py[line:549] - INFO: 2000 / 6234
2023-01-08 18:30:52 - train.py[line:551] - INFO: load:1.27 valid_run:2498.14 task_valid:2464.61 collect_output:6.76
2023-01-08 18:35:00 - train.py[line:549] - INFO: 2200 / 6234
2023-01-08 18:35:00 - train.py[line:551] - INFO: load:1.29 valid_run:2746.52 task_valid:2709.76 collect_output:7.44
2023-01-08 18:39:11 - train.py[line:549] - INFO: 2400 / 6234
2023-01-08 18:39:11 - train.py[line:551] - INFO: load:1.32 valid_run:2996.96 task_valid:2956.94 collect_output:8.13
2023-01-08 18:43:16 - train.py[line:549] - INFO: 2600 / 6234
2023-01-08 18:43:16 - train.py[line:551] - INFO: load:1.34 valid_run:3242.48 task_valid:3199.26 collect_output:8.79
2023-01-08 18:47:28 - train.py[line:549] - INFO: 2800 / 6234
2023-01-08 18:47:28 - train.py[line:551] - INFO: load:1.37 valid_run:3493.95 task_valid:3447.53 collect_output:9.46
2023-01-08 18:51:37 - train.py[line:549] - INFO: 3000 / 6234
2023-01-08 18:51:37 - train.py[line:551] - INFO: load:1.39 valid_run:3743.05 task_valid:3693.42 collect_output:10.13
2023-01-08 18:55:42 - train.py[line:549] - INFO: 3200 / 6234
2023-01-08 18:55:43 - train.py[line:551] - INFO: load:1.42 valid_run:3988.57 task_valid:3935.74 collect_output:10.81
2023-01-08 18:59:51 - train.py[line:549] - INFO: 3400 / 6234
2023-01-08 18:59:52 - train.py[line:551] - INFO: load:1.44 valid_run:4237.48 task_valid:4181.44 collect_output:11.48
2023-01-08 19:04:03 - train.py[line:549] - INFO: 3600 / 6234
2023-01-08 19:04:03 - train.py[line:551] - INFO: load:1.47 valid_run:4489.17 task_valid:4429.90 collect_output:12.15
2023-01-08 19:08:14 - train.py[line:549] - INFO: 3800 / 6234
2023-01-08 19:08:14 - train.py[line:551] - INFO: load:1.49 valid_run:4739.35 task_valid:4676.91 collect_output:12.81
2023-01-08 19:12:24 - train.py[line:549] - INFO: 4000 / 6234
2023-01-08 19:12:24 - train.py[line:551] - INFO: load:1.52 valid_run:4989.29 task_valid:4923.60 collect_output:13.49
2023-01-08 19:16:33 - train.py[line:549] - INFO: 4200 / 6234
2023-01-08 19:16:33 - train.py[line:551] - INFO: load:1.55 valid_run:5239.01 task_valid:5170.11 collect_output:14.16
2023-01-08 19:20:47 - train.py[line:549] - INFO: 4400 / 6234
2023-01-08 19:20:47 - train.py[line:551] - INFO: load:1.57 valid_run:5492.39 task_valid:5420.27 collect_output:14.83
2023-01-08 19:24:54 - train.py[line:549] - INFO: 4600 / 6234
2023-01-08 19:24:54 - train.py[line:551] - INFO: load:1.60 valid_run:5739.08 task_valid:5663.73 collect_output:15.51
2023-01-08 19:29:03 - train.py[line:549] - INFO: 4800 / 6234
2023-01-08 19:29:03 - train.py[line:551] - INFO: load:1.62 valid_run:5988.48 task_valid:5909.92 collect_output:16.17
2023-01-08 19:33:12 - train.py[line:549] - INFO: 5000 / 6234
2023-01-08 19:33:12 - train.py[line:551] - INFO: load:1.65 valid_run:6237.71 task_valid:6155.93 collect_output:16.83
2023-01-08 19:37:22 - train.py[line:549] - INFO: 5200 / 6234
2023-01-08 19:37:22 - train.py[line:551] - INFO: load:1.67 valid_run:6486.77 task_valid:6401.77 collect_output:17.49
2023-01-08 19:41:27 - train.py[line:549] - INFO: 5400 / 6234
2023-01-08 19:41:28 - train.py[line:551] - INFO: load:1.70 valid_run:6732.65 task_valid:6644.39 collect_output:18.18
2023-01-08 19:45:41 - train.py[line:549] - INFO: 5600 / 6234
2023-01-08 19:45:41 - train.py[line:551] - INFO: load:1.72 valid_run:6986.36 task_valid:6894.86 collect_output:18.85
2023-01-08 19:49:50 - train.py[line:549] - INFO: 5800 / 6234
2023-01-08 19:49:50 - train.py[line:551] - INFO: load:1.75 valid_run:7234.89 task_valid:7140.14 collect_output:19.55
2023-01-08 19:54:02 - train.py[line:549] - INFO: 6000 / 6234
2023-01-08 19:54:02 - train.py[line:551] - INFO: load:1.77 valid_run:7487.00 task_valid:7389.03 collect_output:20.22
2023-01-08 19:58:14 - train.py[line:549] - INFO: 6200 / 6234
2023-01-08 19:58:14 - train.py[line:551] - INFO: load:1.80 valid_run:7739.15 task_valid:7637.95 collect_output:20.90

====================================================================================================
SGG eval:     R @ 50: 0.4418;     R @ 100: 0.5458;     R @ 500: 0.6085;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2728;    mR @ 100: 0.3456;    mR @ 500: 0.4065;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7049) (covered in:0.6458) (covering:0.2857) (eating:0.6471) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.7791) (says:0.0000) (sitting on:0.6624) (standing on:0.1633) (using:0.6500) (walking in:0.0000) (walking on:0.5495) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4418;     R @ 100: 0.5458;     R @ 500: 0.6085;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2728;    mR @ 100: 0.3456;    mR @ 500: 0.4065;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7049) (covered in:0.6458) (covering:0.2857) (eating:0.6471) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.7791) (says:0.0000) (sitting on:0.6624) (standing on:0.1633) (using:0.6500) (walking in:0.0000) (walking on:0.5495) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-01-08 19:59:08 - train.py[line:487] - INFO: 0.5458047619047618
2023-01-08 19:59:08 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 19:59:08 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.323 | loss_v1 0 | loss_v2 0 | nll_loss 0.161 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.545805 | ppl 1.12 | vqa_score 0.5248 | wps 57.5 | wpb 72 | bsz 24 | num_updates 12000 | best_R@100 0.632103
2023-01-08 19:59:08 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 12000 updates
2023-01-08 19:59:08 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_12000.pt
2023-01-08 19:59:46 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_12000.pt
2023-01-08 20:01:05 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 0.5458047619047618) (writing took 117.02369772642851 seconds)
2023-01-08 20:01:34 - progress_bar.py[line:274] - INFO: epoch 001:  12026 / 144806 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=85.7, nsentences=32, sample_size=85.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3091, wps=0.2, ups=0, wpb=85.7, bsz=32, num_updates=12010, lr=4.73686e-05, gnorm=0.464, clip=0, loss_scale=512, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=75709
2023-01-08 20:02:03 - progress_bar.py[line:274] - INFO: epoch 001:  12036 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4474, wps=60.5, ups=0.35, wpb=87.2, bsz=32, num_updates=12020, lr=4.7365e-05, gnorm=0.517, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=75738
2023-01-08 20:02:32 - progress_bar.py[line:274] - INFO: epoch 001:  12046 / 144806 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3393, wps=60.3, ups=0.35, wpb=86.4, bsz=32, num_updates=12030, lr=4.73615e-05, gnorm=0.49, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=75767
2023-01-08 20:03:01 - progress_bar.py[line:274] - INFO: epoch 001:  12056 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3665, wps=60.8, ups=0.35, wpb=86.9, bsz=32, num_updates=12040, lr=4.73579e-05, gnorm=0.411, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=75796
2023-01-08 20:03:29 - progress_bar.py[line:274] - INFO: epoch 001:  12066 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4452, wps=63.3, ups=0.36, wpb=88.2, bsz=32, num_updates=12050, lr=4.73543e-05, gnorm=0.346, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=75824
2023-01-08 20:03:58 - progress_bar.py[line:274] - INFO: epoch 001:  12076 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4085, wps=61.1, ups=0.35, wpb=87.4, bsz=32, num_updates=12060, lr=4.73508e-05, gnorm=0.313, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=75853
2023-01-08 20:04:27 - progress_bar.py[line:274] - INFO: epoch 001:  12086 / 144806 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3267, wps=61.3, ups=0.35, wpb=88.1, bsz=32, num_updates=12070, lr=4.73472e-05, gnorm=0.435, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=75882
2023-01-08 20:04:56 - progress_bar.py[line:274] - INFO: epoch 001:  12096 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3493, wps=60.3, ups=0.34, wpb=87.6, bsz=32, num_updates=12080, lr=4.73436e-05, gnorm=0.501, clip=0, loss_scale=512, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=75911
2023-01-08 20:05:25 - progress_bar.py[line:274] - INFO: epoch 001:  12106 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3935, wps=60.5, ups=0.35, wpb=87.6, bsz=32, num_updates=12090, lr=4.73401e-05, gnorm=0.441, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=75940
2023-01-08 20:05:54 - progress_bar.py[line:274] - INFO: epoch 001:  12116 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3733, wps=61.5, ups=0.35, wpb=87.4, bsz=32, num_updates=12100, lr=4.73365e-05, gnorm=0.668, clip=30, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=75969
2023-01-08 20:06:23 - progress_bar.py[line:274] - INFO: epoch 001:  12126 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4023, wps=62, ups=0.35, wpb=88, bsz=32, num_updates=12110, lr=4.73329e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=28, gb_free=15, ema_decay=0.9999, wall=75998
2023-01-08 20:06:53 - progress_bar.py[line:274] - INFO: epoch 001:  12136 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.462, wps=59.3, ups=0.34, wpb=87.5, bsz=32, num_updates=12120, lr=4.73294e-05, gnorm=0.505, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=76028
2023-01-08 20:07:22 - progress_bar.py[line:274] - INFO: epoch 001:  12146 / 144806 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4096, wps=60.4, ups=0.34, wpb=87.7, bsz=32, num_updates=12130, lr=4.73258e-05, gnorm=0.623, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=76057
2023-01-08 20:07:52 - progress_bar.py[line:274] - INFO: epoch 001:  12156 / 144806 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.411, wps=58.9, ups=0.34, wpb=86.7, bsz=32, num_updates=12140, lr=4.73222e-05, gnorm=0.518, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=76087
2023-01-08 20:08:20 - progress_bar.py[line:274] - INFO: epoch 001:  12166 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3333, wps=60.6, ups=0.35, wpb=86.7, bsz=32, num_updates=12150, lr=4.73187e-05, gnorm=0.424, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=76116
2023-01-08 20:08:50 - progress_bar.py[line:274] - INFO: epoch 001:  12176 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3333, wps=61.2, ups=0.35, wpb=88.2, bsz=32, num_updates=12160, lr=4.73151e-05, gnorm=0.389, clip=0, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=76145
2023-01-08 20:09:18 - progress_bar.py[line:274] - INFO: epoch 001:  12186 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4451, wps=60.6, ups=0.35, wpb=86.2, bsz=32, num_updates=12170, lr=4.73115e-05, gnorm=0.464, clip=0, loss_scale=512, train_wall=28, gb_free=15.8, ema_decay=0.9999, wall=76173
2023-01-08 20:09:47 - progress_bar.py[line:274] - INFO: epoch 001:  12196 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4082, wps=61.7, ups=0.35, wpb=88, bsz=32, num_updates=12180, lr=4.7308e-05, gnorm=0.415, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=76202
2023-01-08 20:10:16 - progress_bar.py[line:274] - INFO: epoch 001:  12206 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.42, wps=61.2, ups=0.35, wpb=87.6, bsz=32, num_updates=12190, lr=4.73044e-05, gnorm=0.473, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=76231
2023-01-08 20:10:44 - progress_bar.py[line:274] - INFO: epoch 001:  12216 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4062, wps=61.9, ups=0.36, wpb=86.5, bsz=32, num_updates=12200, lr=4.73008e-05, gnorm=0.367, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=76259
2023-01-08 20:11:14 - progress_bar.py[line:274] - INFO: epoch 001:  12226 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4238, wps=60.4, ups=0.35, wpb=87.4, bsz=32, num_updates=12210, lr=4.72973e-05, gnorm=0.501, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=76289
2023-01-08 20:11:43 - progress_bar.py[line:274] - INFO: epoch 001:  12236 / 144806 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.3497, wps=59, ups=0.34, wpb=86.8, bsz=32, num_updates=12220, lr=4.72937e-05, gnorm=0.534, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=76318
2023-01-08 20:12:12 - progress_bar.py[line:274] - INFO: epoch 001:  12246 / 144806 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3988, wps=61, ups=0.35, wpb=86.8, bsz=32, num_updates=12230, lr=4.72901e-05, gnorm=0.519, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=76347
2023-01-08 20:12:41 - progress_bar.py[line:274] - INFO: epoch 001:  12256 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4028, wps=60.4, ups=0.34, wpb=87.9, bsz=32, num_updates=12240, lr=4.72866e-05, gnorm=0.545, clip=10, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=76376
2023-01-08 20:13:11 - progress_bar.py[line:274] - INFO: epoch 001:  12266 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5, wps=60.7, ups=0.34, wpb=88, bsz=32, num_updates=12250, lr=4.7283e-05, gnorm=0.677, clip=20, loss_scale=512, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=76406
2023-01-08 20:13:40 - progress_bar.py[line:274] - INFO: epoch 001:  12276 / 144806 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4192, wps=61.6, ups=0.35, wpb=88.1, bsz=32, num_updates=12260, lr=4.72794e-05, gnorm=0.541, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=76435
2023-01-08 20:14:09 - progress_bar.py[line:274] - INFO: epoch 001:  12286 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3797, wps=60.8, ups=0.35, wpb=87.2, bsz=32, num_updates=12270, lr=4.72759e-05, gnorm=0.436, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=76464
2023-01-08 20:14:37 - progress_bar.py[line:274] - INFO: epoch 001:  12296 / 144806 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3451, wps=63.1, ups=0.36, wpb=88.8, bsz=32, num_updates=12280, lr=4.72723e-05, gnorm=0.475, clip=10, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=76492
2023-01-08 20:15:06 - progress_bar.py[line:274] - INFO: epoch 001:  12306 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.42, wps=61.3, ups=0.35, wpb=87.9, bsz=32, num_updates=12290, lr=4.72687e-05, gnorm=0.478, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=76521
2023-01-08 20:15:35 - progress_bar.py[line:274] - INFO: epoch 001:  12316 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3974, wps=61.4, ups=0.35, wpb=88.1, bsz=32, num_updates=12300, lr=4.72652e-05, gnorm=0.427, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=76550
2023-01-08 20:16:05 - progress_bar.py[line:274] - INFO: epoch 001:  12326 / 144806 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4438, wps=59.4, ups=0.34, wpb=86.3, bsz=32, num_updates=12310, lr=4.72616e-05, gnorm=0.481, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=76579
2023-01-08 20:16:33 - progress_bar.py[line:274] - INFO: epoch 001:  12336 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=61.6, ups=0.36, wpb=86.5, bsz=32, num_updates=12320, lr=4.7258e-05, gnorm=0.42, clip=0, loss_scale=1024, train_wall=28, gb_free=15.6, ema_decay=0.9999, wall=76608
2023-01-08 20:17:03 - progress_bar.py[line:274] - INFO: epoch 001:  12346 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.472, wps=61.2, ups=0.35, wpb=87.6, bsz=32, num_updates=12330, lr=4.72545e-05, gnorm=1.033, clip=20, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=76637
2023-01-08 20:17:32 - progress_bar.py[line:274] - INFO: epoch 001:  12356 / 144806 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3743, wps=61, ups=0.35, wpb=86.3, bsz=32, num_updates=12340, lr=4.72509e-05, gnorm=0.559, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=76667
2023-01-08 20:18:01 - progress_bar.py[line:274] - INFO: epoch 001:  12366 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=89, nsentences=32, sample_size=89, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3677, wps=62.2, ups=0.35, wpb=89, bsz=32, num_updates=12350, lr=4.72473e-05, gnorm=0.366, clip=0, loss_scale=1024, train_wall=29, gb_free=15, ema_decay=0.9999, wall=76696
2023-01-08 20:18:31 - progress_bar.py[line:274] - INFO: epoch 001:  12376 / 144806 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3631, wps=61.4, ups=0.35, wpb=87.7, bsz=32, num_updates=12360, lr=4.72438e-05, gnorm=0.494, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=76725
2023-01-08 20:19:01 - progress_bar.py[line:274] - INFO: epoch 001:  12386 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4286, wps=59.2, ups=0.34, wpb=86.7, bsz=32, num_updates=12370, lr=4.72402e-05, gnorm=0.481, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=76755
2023-01-08 20:19:30 - progress_bar.py[line:274] - INFO: epoch 001:  12396 / 144806 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3563, wps=60.3, ups=0.35, wpb=86.1, bsz=32, num_updates=12380, lr=4.72366e-05, gnorm=0.453, clip=0, loss_scale=1024, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=76785
2023-01-08 20:20:00 - progress_bar.py[line:274] - INFO: epoch 001:  12406 / 144806 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3774, wps=59.9, ups=0.35, wpb=86.7, bsz=32, num_updates=12390, lr=4.72331e-05, gnorm=0.526, clip=10, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=76814
2023-01-08 20:20:30 - progress_bar.py[line:274] - INFO: epoch 001:  12416 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4, wps=59.8, ups=0.34, wpb=87.3, bsz=32, num_updates=12400, lr=4.72295e-05, gnorm=0.299, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=76844
2023-01-08 20:20:59 - progress_bar.py[line:274] - INFO: epoch 001:  12426 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3873, wps=60.5, ups=0.35, wpb=87.6, bsz=32, num_updates=12410, lr=4.72259e-05, gnorm=0.356, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=76874
2023-01-08 20:21:08 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 20:21:31 - progress_bar.py[line:274] - INFO: epoch 001:  12437 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.81, nsentences=32, sample_size=85.81, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3897, wps=57.6, ups=0.32, wpb=85.8, bsz=32, num_updates=12420, lr=4.72224e-05, gnorm=0.482, clip=0, loss_scale=512, train_wall=31, gb_free=15.4, ema_decay=0.9999, wall=76906
2023-01-08 20:22:01 - progress_bar.py[line:274] - INFO: epoch 001:  12447 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.351, wps=59.8, ups=0.34, wpb=86.9, bsz=32, num_updates=12430, lr=4.72188e-05, gnorm=0.459, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=76936
2023-01-08 20:22:30 - progress_bar.py[line:274] - INFO: epoch 001:  12457 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4013, wps=61.3, ups=0.35, wpb=87.9, bsz=32, num_updates=12440, lr=4.72152e-05, gnorm=0.477, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=76965
2023-01-08 20:23:00 - progress_bar.py[line:274] - INFO: epoch 001:  12467 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4643, wps=60.1, ups=0.34, wpb=87.2, bsz=32, num_updates=12450, lr=4.72117e-05, gnorm=0.785, clip=20, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=76995
2023-01-08 20:23:29 - progress_bar.py[line:274] - INFO: epoch 001:  12477 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4177, wps=61.5, ups=0.35, wpb=87.8, bsz=32, num_updates=12460, lr=4.72081e-05, gnorm=0.517, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=77024
2023-01-08 20:23:59 - progress_bar.py[line:274] - INFO: epoch 001:  12487 / 144806 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3867, wps=60.3, ups=0.35, wpb=87.3, bsz=32, num_updates=12470, lr=4.72045e-05, gnorm=0.455, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=77053
2023-01-08 20:24:28 - progress_bar.py[line:274] - INFO: epoch 001:  12497 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4065, wps=61.1, ups=0.35, wpb=87.7, bsz=32, num_updates=12480, lr=4.7201e-05, gnorm=0.508, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=77083
2023-01-08 20:24:58 - progress_bar.py[line:274] - INFO: epoch 001:  12507 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3893, wps=59.7, ups=0.34, wpb=88.3, bsz=32, num_updates=12490, lr=4.71974e-05, gnorm=0.415, clip=0, loss_scale=512, train_wall=30, gb_free=15.2, ema_decay=0.9999, wall=77113
2023-01-08 20:25:28 - progress_bar.py[line:274] - INFO: epoch 001:  12517 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4437, wps=60.5, ups=0.34, wpb=87.7, bsz=32, num_updates=12500, lr=4.71938e-05, gnorm=0.49, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=77142
2023-01-08 20:25:56 - progress_bar.py[line:274] - INFO: epoch 001:  12527 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4024, wps=61.7, ups=0.36, wpb=86.2, bsz=32, num_updates=12510, lr=4.71903e-05, gnorm=0.496, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=77171
2023-01-08 20:26:26 - progress_bar.py[line:274] - INFO: epoch 001:  12537 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4238, wps=61.1, ups=0.35, wpb=87.6, bsz=32, num_updates=12520, lr=4.71867e-05, gnorm=0.478, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=77200
2023-01-08 20:26:56 - progress_bar.py[line:274] - INFO: epoch 001:  12547 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3554, wps=60.2, ups=0.34, wpb=87.4, bsz=32, num_updates=12530, lr=4.71831e-05, gnorm=0.402, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=77231
2023-01-08 20:27:26 - progress_bar.py[line:274] - INFO: epoch 001:  12557 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4295, wps=59.6, ups=0.34, wpb=86.5, bsz=32, num_updates=12540, lr=4.71796e-05, gnorm=0.394, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=77260
2023-01-08 20:27:54 - progress_bar.py[line:274] - INFO: epoch 001:  12567 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4465, wps=61.2, ups=0.35, wpb=86.5, bsz=32, num_updates=12550, lr=4.7176e-05, gnorm=0.464, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=77289
2023-01-08 20:28:24 - progress_bar.py[line:274] - INFO: epoch 001:  12577 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=85.6, nsentences=32, sample_size=85.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4337, wps=60.1, ups=0.35, wpb=85.6, bsz=32, num_updates=12560, lr=4.71724e-05, gnorm=0.513, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=77318
2023-01-08 20:28:53 - progress_bar.py[line:274] - INFO: epoch 001:  12587 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3512, wps=60.2, ups=0.35, wpb=86.3, bsz=32, num_updates=12570, lr=4.71689e-05, gnorm=0.564, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=77348
2023-01-08 20:29:23 - progress_bar.py[line:274] - INFO: epoch 001:  12597 / 144806 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3964, wps=59.4, ups=0.35, wpb=85.9, bsz=32, num_updates=12580, lr=4.71653e-05, gnorm=0.632, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=77377
2023-01-08 20:29:52 - progress_bar.py[line:274] - INFO: epoch 001:  12607 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4198, wps=60.6, ups=0.35, wpb=87.3, bsz=32, num_updates=12590, lr=4.71617e-05, gnorm=0.4, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=77407
2023-01-08 20:30:22 - progress_bar.py[line:274] - INFO: epoch 001:  12617 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4014, wps=61.2, ups=0.35, wpb=88.1, bsz=32, num_updates=12600, lr=4.71582e-05, gnorm=0.418, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=77437
2023-01-08 20:30:51 - progress_bar.py[line:274] - INFO: epoch 001:  12627 / 144806 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4114, wps=61.5, ups=0.35, wpb=87, bsz=32, num_updates=12610, lr=4.71546e-05, gnorm=0.612, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=77466
2023-01-08 20:31:21 - progress_bar.py[line:274] - INFO: epoch 001:  12637 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3372, wps=60.6, ups=0.35, wpb=87.1, bsz=32, num_updates=12620, lr=4.7151e-05, gnorm=0.374, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=77495
2023-01-08 20:31:50 - progress_bar.py[line:274] - INFO: epoch 001:  12647 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4598, wps=60.9, ups=0.35, wpb=86.9, bsz=32, num_updates=12630, lr=4.71475e-05, gnorm=0.415, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=77524
2023-01-08 20:32:20 - progress_bar.py[line:274] - INFO: epoch 001:  12657 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4049, wps=59.7, ups=0.34, wpb=87.3, bsz=32, num_updates=12640, lr=4.71439e-05, gnorm=0.558, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=77554
2023-01-08 20:32:49 - progress_bar.py[line:274] - INFO: epoch 001:  12667 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3933, wps=61.1, ups=0.35, wpb=87.9, bsz=32, num_updates=12650, lr=4.71403e-05, gnorm=0.744, clip=20, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=77584
2023-01-08 20:33:19 - progress_bar.py[line:274] - INFO: epoch 001:  12677 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3827, wps=60.8, ups=0.35, wpb=87, bsz=32, num_updates=12660, lr=4.71368e-05, gnorm=0.5, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=77613
2023-01-08 20:33:48 - progress_bar.py[line:274] - INFO: epoch 001:  12687 / 144806 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3953, wps=60.2, ups=0.35, wpb=86.6, bsz=32, num_updates=12670, lr=4.71332e-05, gnorm=0.472, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=77643
2023-01-08 20:34:18 - progress_bar.py[line:274] - INFO: epoch 001:  12697 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3806, wps=60.1, ups=0.34, wpb=87.1, bsz=32, num_updates=12680, lr=4.71296e-05, gnorm=0.364, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=77672
2023-01-08 20:34:47 - progress_bar.py[line:274] - INFO: epoch 001:  12707 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4189, wps=61.3, ups=0.35, wpb=88, bsz=32, num_updates=12690, lr=4.71261e-05, gnorm=0.418, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=77702
2023-01-08 20:35:17 - progress_bar.py[line:274] - INFO: epoch 001:  12717 / 144806 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4157, wps=59.4, ups=0.34, wpb=86.4, bsz=32, num_updates=12700, lr=4.71225e-05, gnorm=0.445, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=77731
2023-01-08 20:35:46 - progress_bar.py[line:274] - INFO: epoch 001:  12727 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4188, wps=61, ups=0.35, wpb=87.4, bsz=32, num_updates=12710, lr=4.71189e-05, gnorm=0.49, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=77761
2023-01-08 20:36:16 - progress_bar.py[line:274] - INFO: epoch 001:  12737 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4161, wps=60.6, ups=0.34, wpb=88.4, bsz=32, num_updates=12720, lr=4.71154e-05, gnorm=0.495, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=77791
2023-01-08 20:36:45 - progress_bar.py[line:274] - INFO: epoch 001:  12747 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4379, wps=61, ups=0.35, wpb=87, bsz=32, num_updates=12730, lr=4.71118e-05, gnorm=0.458, clip=0, loss_scale=512, train_wall=28, gb_free=15, ema_decay=0.9999, wall=77820
2023-01-08 20:37:15 - progress_bar.py[line:274] - INFO: epoch 001:  12757 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4238, wps=60.4, ups=0.34, wpb=87.5, bsz=32, num_updates=12740, lr=4.71082e-05, gnorm=0.496, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=77850
2023-01-08 20:37:44 - progress_bar.py[line:274] - INFO: epoch 001:  12767 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4151, wps=62, ups=0.35, wpb=87.6, bsz=32, num_updates=12750, lr=4.71046e-05, gnorm=0.29, clip=0, loss_scale=512, train_wall=28, gb_free=15, ema_decay=0.9999, wall=77879
2023-01-08 20:38:14 - progress_bar.py[line:274] - INFO: epoch 001:  12777 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3313, wps=59.7, ups=0.35, wpb=86.2, bsz=32, num_updates=12760, lr=4.71011e-05, gnorm=0.639, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=77908
2023-01-08 20:38:43 - progress_bar.py[line:274] - INFO: epoch 001:  12787 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5033, wps=61.4, ups=0.35, wpb=87.9, bsz=32, num_updates=12770, lr=4.70975e-05, gnorm=0.448, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=77938
2023-01-08 20:39:12 - progress_bar.py[line:274] - INFO: epoch 001:  12797 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.432, wps=61.2, ups=0.35, wpb=86.8, bsz=32, num_updates=12780, lr=4.70939e-05, gnorm=0.574, clip=10, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=77967
2023-01-08 20:39:41 - progress_bar.py[line:274] - INFO: epoch 001:  12807 / 144806 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.506, wps=59.8, ups=0.35, wpb=85.9, bsz=32, num_updates=12790, lr=4.70904e-05, gnorm=0.647, clip=10, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=77996
2023-01-08 20:40:10 - progress_bar.py[line:274] - INFO: epoch 001:  12817 / 144806 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4237, wps=59.8, ups=0.35, wpb=86.2, bsz=32, num_updates=12800, lr=4.70868e-05, gnorm=0.569, clip=20, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=78025
2023-01-08 20:40:38 - progress_bar.py[line:274] - INFO: epoch 001:  12827 / 144806 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4088, wps=61.1, ups=0.35, wpb=87.1, bsz=32, num_updates=12810, lr=4.70832e-05, gnorm=0.457, clip=10, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=78053
2023-01-08 20:41:07 - progress_bar.py[line:274] - INFO: epoch 001:  12837 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4, wps=60.9, ups=0.35, wpb=86.9, bsz=32, num_updates=12820, lr=4.70797e-05, gnorm=0.411, clip=0, loss_scale=512, train_wall=28, gb_free=15, ema_decay=0.9999, wall=78082
2023-01-08 20:41:36 - progress_bar.py[line:274] - INFO: epoch 001:  12847 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3926, wps=60.9, ups=0.35, wpb=87.3, bsz=32, num_updates=12830, lr=4.70761e-05, gnorm=0.604, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=78111
2023-01-08 20:42:05 - progress_bar.py[line:274] - INFO: epoch 001:  12857 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4277, wps=60.3, ups=0.35, wpb=87.1, bsz=32, num_updates=12840, lr=4.70725e-05, gnorm=0.379, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=78140
2023-01-08 20:42:35 - progress_bar.py[line:274] - INFO: epoch 001:  12867 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4458, wps=60, ups=0.34, wpb=87.3, bsz=32, num_updates=12850, lr=4.7069e-05, gnorm=0.45, clip=0, loss_scale=512, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=78170
2023-01-08 20:43:03 - progress_bar.py[line:274] - INFO: epoch 001:  12877 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3951, wps=61.4, ups=0.35, wpb=87.7, bsz=32, num_updates=12860, lr=4.70654e-05, gnorm=0.47, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=78198
2023-01-08 20:43:33 - progress_bar.py[line:274] - INFO: epoch 001:  12887 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3963, wps=60.6, ups=0.35, wpb=87.5, bsz=32, num_updates=12870, lr=4.70618e-05, gnorm=0.424, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=78228
2023-01-08 20:44:01 - progress_bar.py[line:274] - INFO: epoch 001:  12897 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.3, nsentences=32, sample_size=85.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4294, wps=60.6, ups=0.36, wpb=85.3, bsz=32, num_updates=12880, lr=4.70583e-05, gnorm=0.477, clip=0, loss_scale=512, train_wall=28, gb_free=14.9, ema_decay=0.9999, wall=78256
2023-01-08 20:44:30 - progress_bar.py[line:274] - INFO: epoch 001:  12907 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3576, wps=61.5, ups=0.35, wpb=87.6, bsz=32, num_updates=12890, lr=4.70547e-05, gnorm=0.452, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=78285
2023-01-08 20:44:59 - progress_bar.py[line:274] - INFO: epoch 001:  12917 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4596, wps=61.2, ups=0.35, wpb=87.2, bsz=32, num_updates=12900, lr=4.70511e-05, gnorm=0.369, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=78314
2023-01-08 20:45:27 - progress_bar.py[line:274] - INFO: epoch 001:  12927 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4354, wps=62.4, ups=0.35, wpb=88.3, bsz=32, num_updates=12910, lr=4.70476e-05, gnorm=0.607, clip=10, loss_scale=512, train_wall=28, gb_free=15.5, ema_decay=0.9999, wall=78342
2023-01-08 20:45:55 - progress_bar.py[line:274] - INFO: epoch 001:  12937 / 144806 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4214, wps=62.5, ups=0.36, wpb=87.3, bsz=32, num_updates=12920, lr=4.7044e-05, gnorm=0.542, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=78371
2023-01-08 20:46:25 - progress_bar.py[line:274] - INFO: epoch 001:  12947 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3851, wps=60, ups=0.34, wpb=87.4, bsz=32, num_updates=12930, lr=4.70404e-05, gnorm=0.619, clip=10, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=78400
2023-01-08 20:46:54 - progress_bar.py[line:274] - INFO: epoch 001:  12957 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4024, wps=59.9, ups=0.34, wpb=87.6, bsz=32, num_updates=12940, lr=4.70369e-05, gnorm=0.46, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=78429
2023-01-08 20:47:24 - progress_bar.py[line:274] - INFO: epoch 001:  12967 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4524, wps=59.7, ups=0.34, wpb=87.2, bsz=32, num_updates=12950, lr=4.70333e-05, gnorm=0.498, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=78459
2023-01-08 20:47:53 - progress_bar.py[line:274] - INFO: epoch 001:  12977 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4512, wps=60.7, ups=0.35, wpb=86.6, bsz=32, num_updates=12960, lr=4.70297e-05, gnorm=0.462, clip=0, loss_scale=1024, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=78488
2023-01-08 20:48:23 - progress_bar.py[line:274] - INFO: epoch 001:  12987 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4076, wps=59.5, ups=0.34, wpb=87.8, bsz=32, num_updates=12970, lr=4.70262e-05, gnorm=0.422, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=78518
2023-01-08 20:48:51 - progress_bar.py[line:274] - INFO: epoch 001:  12997 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.414, wps=62.1, ups=0.35, wpb=87.9, bsz=32, num_updates=12980, lr=4.70226e-05, gnorm=0.427, clip=10, loss_scale=1024, train_wall=28, gb_free=15, ema_decay=0.9999, wall=78546
2023-01-08 20:49:20 - progress_bar.py[line:274] - INFO: epoch 001:  13007 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.5097, wps=61.4, ups=0.35, wpb=88.3, bsz=32, num_updates=12990, lr=4.7019e-05, gnorm=0.501, clip=0, loss_scale=1024, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=78575
2023-01-08 20:49:50 - progress_bar.py[line:274] - INFO: epoch 001:  13017 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3765, wps=60.2, ups=0.34, wpb=87.5, bsz=32, num_updates=13000, lr=4.70155e-05, gnorm=0.666, clip=20, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=78605
2023-01-08 20:50:19 - progress_bar.py[line:274] - INFO: epoch 001:  13027 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4014, wps=61.1, ups=0.35, wpb=87.6, bsz=32, num_updates=13010, lr=4.70119e-05, gnorm=0.425, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=78634
2023-01-08 20:50:48 - progress_bar.py[line:274] - INFO: epoch 001:  13037 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4276, wps=61, ups=0.35, wpb=88.1, bsz=32, num_updates=13020, lr=4.70083e-05, gnorm=0.577, clip=20, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=78663
2023-01-08 20:51:11 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 20:51:20 - progress_bar.py[line:274] - INFO: epoch 001:  13048 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.667, nsentences=32, sample_size=86.667, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4246, wps=57.2, ups=0.31, wpb=86.7, bsz=32, num_updates=13030, lr=4.70048e-05, gnorm=0.397, clip=0, loss_scale=512, train_wall=32, gb_free=15.3, ema_decay=0.9999, wall=78695
2023-01-08 20:51:49 - progress_bar.py[line:274] - INFO: epoch 001:  13058 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=85.7, nsentences=32, sample_size=85.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4568, wps=59.3, ups=0.35, wpb=85.7, bsz=32, num_updates=13040, lr=4.70012e-05, gnorm=0.684, clip=30, loss_scale=512, train_wall=29, gb_free=15.7, ema_decay=0.9999, wall=78724
2023-01-08 20:52:18 - progress_bar.py[line:274] - INFO: epoch 001:  13068 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4275, wps=61, ups=0.35, wpb=87.6, bsz=32, num_updates=13050, lr=4.69976e-05, gnorm=0.496, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=78753
2023-01-08 20:52:47 - progress_bar.py[line:274] - INFO: epoch 001:  13078 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4573, wps=61.2, ups=0.35, wpb=87.3, bsz=32, num_updates=13060, lr=4.69941e-05, gnorm=0.613, clip=10, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=78782
2023-01-08 20:53:16 - progress_bar.py[line:274] - INFO: epoch 001:  13088 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4276, wps=61.2, ups=0.35, wpb=87.7, bsz=32, num_updates=13070, lr=4.69905e-05, gnorm=0.368, clip=0, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=78811
2023-01-08 20:53:45 - progress_bar.py[line:274] - INFO: epoch 001:  13098 / 144806 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4161, wps=60.5, ups=0.35, wpb=87.5, bsz=32, num_updates=13080, lr=4.69869e-05, gnorm=0.47, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=78840
2023-01-08 20:54:13 - progress_bar.py[line:274] - INFO: epoch 001:  13108 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4114, wps=62.1, ups=0.35, wpb=87.8, bsz=32, num_updates=13090, lr=4.69834e-05, gnorm=0.384, clip=0, loss_scale=512, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=78869
2023-01-08 20:54:43 - progress_bar.py[line:274] - INFO: epoch 001:  13118 / 144806 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4132, wps=59.9, ups=0.35, wpb=86.8, bsz=32, num_updates=13100, lr=4.69798e-05, gnorm=0.424, clip=0, loss_scale=512, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=78898
2023-01-08 20:55:11 - progress_bar.py[line:274] - INFO: epoch 001:  13128 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=89.8, nsentences=32, sample_size=89.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4014, wps=63.3, ups=0.35, wpb=89.8, bsz=32, num_updates=13110, lr=4.69762e-05, gnorm=0.348, clip=0, loss_scale=512, train_wall=28, gb_free=15.5, ema_decay=0.9999, wall=78926
2023-01-08 20:55:40 - progress_bar.py[line:274] - INFO: epoch 001:  13138 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3734, wps=61.6, ups=0.35, wpb=88.1, bsz=32, num_updates=13120, lr=4.69727e-05, gnorm=0.327, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=78955
2023-01-08 20:56:09 - progress_bar.py[line:274] - INFO: epoch 001:  13148 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4072, wps=61.5, ups=0.35, wpb=86.9, bsz=32, num_updates=13130, lr=4.69691e-05, gnorm=0.627, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=78984
2023-01-08 20:56:38 - progress_bar.py[line:274] - INFO: epoch 001:  13158 / 144806 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4148, wps=59.2, ups=0.34, wpb=86.6, bsz=32, num_updates=13140, lr=4.69655e-05, gnorm=0.379, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=79013
2023-01-08 20:57:08 - progress_bar.py[line:274] - INFO: epoch 001:  13168 / 144806 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4364, wps=59.1, ups=0.34, wpb=86.5, bsz=32, num_updates=13150, lr=4.6962e-05, gnorm=0.57, clip=10, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=79043
2023-01-08 20:57:37 - progress_bar.py[line:274] - INFO: epoch 001:  13178 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3951, wps=60.2, ups=0.35, wpb=86.3, bsz=32, num_updates=13160, lr=4.69584e-05, gnorm=0.441, clip=0, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=79072
2023-01-08 20:58:06 - progress_bar.py[line:274] - INFO: epoch 001:  13188 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4268, wps=60.3, ups=0.35, wpb=86.7, bsz=32, num_updates=13170, lr=4.69548e-05, gnorm=0.42, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=79101
2023-01-08 20:58:35 - progress_bar.py[line:274] - INFO: epoch 001:  13198 / 144806 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4132, wps=58.9, ups=0.34, wpb=86.5, bsz=32, num_updates=13180, lr=4.69513e-05, gnorm=0.493, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=79130
2023-01-08 20:59:04 - progress_bar.py[line:274] - INFO: epoch 001:  13208 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3879, wps=61.3, ups=0.35, wpb=86.6, bsz=32, num_updates=13190, lr=4.69477e-05, gnorm=0.406, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=79159
2023-01-08 20:59:33 - progress_bar.py[line:274] - INFO: epoch 001:  13218 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3841, wps=59.4, ups=0.34, wpb=86.1, bsz=32, num_updates=13200, lr=4.69441e-05, gnorm=0.384, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=79188
2023-01-08 21:00:02 - progress_bar.py[line:274] - INFO: epoch 001:  13228 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3515, wps=59.9, ups=0.34, wpb=87, bsz=32, num_updates=13210, lr=4.69406e-05, gnorm=0.576, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=79217
2023-01-08 21:00:31 - progress_bar.py[line:274] - INFO: epoch 001:  13238 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4444, wps=61.6, ups=0.35, wpb=88.2, bsz=32, num_updates=13220, lr=4.6937e-05, gnorm=0.489, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=79246
2023-01-08 21:01:00 - progress_bar.py[line:274] - INFO: epoch 001:  13248 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4277, wps=62.6, ups=0.35, wpb=88.3, bsz=32, num_updates=13230, lr=4.69334e-05, gnorm=0.361, clip=0, loss_scale=512, train_wall=28, gb_free=14.8, ema_decay=0.9999, wall=79275
2023-01-08 21:01:29 - progress_bar.py[line:274] - INFO: epoch 001:  13258 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3459, wps=60, ups=0.35, wpb=86.4, bsz=32, num_updates=13240, lr=4.69299e-05, gnorm=0.688, clip=20, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=79304
2023-01-08 21:01:58 - progress_bar.py[line:274] - INFO: epoch 001:  13268 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3375, wps=59.9, ups=0.35, wpb=86.8, bsz=32, num_updates=13250, lr=4.69263e-05, gnorm=0.526, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=79333
2023-01-08 21:02:27 - progress_bar.py[line:274] - INFO: epoch 001:  13278 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3889, wps=60.8, ups=0.35, wpb=88, bsz=32, num_updates=13260, lr=4.69227e-05, gnorm=0.476, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=79362
2023-01-08 21:02:56 - progress_bar.py[line:274] - INFO: epoch 001:  13288 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3952, wps=60.5, ups=0.35, wpb=86.9, bsz=32, num_updates=13270, lr=4.69192e-05, gnorm=0.481, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=79391
2023-01-08 21:03:25 - progress_bar.py[line:274] - INFO: epoch 001:  13298 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4276, wps=60.4, ups=0.35, wpb=87.3, bsz=32, num_updates=13280, lr=4.69156e-05, gnorm=0.399, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=79420
2023-01-08 21:03:54 - progress_bar.py[line:274] - INFO: epoch 001:  13308 / 144806 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3933, wps=60.9, ups=0.35, wpb=87.7, bsz=32, num_updates=13290, lr=4.6912e-05, gnorm=0.611, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=79449
2023-01-08 21:04:23 - progress_bar.py[line:274] - INFO: epoch 001:  13318 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3677, wps=62.3, ups=0.35, wpb=88.2, bsz=32, num_updates=13300, lr=4.69085e-05, gnorm=0.353, clip=0, loss_scale=512, train_wall=28, gb_free=15.6, ema_decay=0.9999, wall=79478
2023-01-08 21:04:52 - progress_bar.py[line:274] - INFO: epoch 001:  13328 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4012, wps=60.6, ups=0.35, wpb=87.4, bsz=32, num_updates=13310, lr=4.69049e-05, gnorm=0.423, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=79507
2023-01-08 21:05:21 - progress_bar.py[line:274] - INFO: epoch 001:  13338 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3631, wps=61.1, ups=0.35, wpb=86.9, bsz=32, num_updates=13320, lr=4.69013e-05, gnorm=0.481, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=79536
2023-01-08 21:05:50 - progress_bar.py[line:274] - INFO: epoch 001:  13348 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4104, wps=60.3, ups=0.35, wpb=87.3, bsz=32, num_updates=13330, lr=4.68978e-05, gnorm=0.403, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=79565
2023-01-08 21:06:19 - progress_bar.py[line:274] - INFO: epoch 001:  13358 / 144806 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=85.4, nsentences=32, sample_size=85.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3966, wps=59.9, ups=0.35, wpb=85.4, bsz=32, num_updates=13340, lr=4.68942e-05, gnorm=0.444, clip=0, loss_scale=512, train_wall=28, gb_free=15.5, ema_decay=0.9999, wall=79594
2023-01-08 21:06:48 - progress_bar.py[line:274] - INFO: epoch 001:  13368 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4099, wps=60.8, ups=0.34, wpb=88.6, bsz=32, num_updates=13350, lr=4.68906e-05, gnorm=0.495, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=79623
2023-01-08 21:07:18 - progress_bar.py[line:274] - INFO: epoch 001:  13378 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4151, wps=60.1, ups=0.34, wpb=87.4, bsz=32, num_updates=13360, lr=4.68871e-05, gnorm=0.424, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=79653
2023-01-08 21:07:47 - progress_bar.py[line:274] - INFO: epoch 001:  13388 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4036, wps=60.1, ups=0.35, wpb=86.8, bsz=32, num_updates=13370, lr=4.68835e-05, gnorm=0.6, clip=10, loss_scale=512, train_wall=29, gb_free=15.6, ema_decay=0.9999, wall=79682
2023-01-08 21:08:16 - progress_bar.py[line:274] - INFO: epoch 001:  13398 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3421, wps=61, ups=0.35, wpb=87.6, bsz=32, num_updates=13380, lr=4.68799e-05, gnorm=0.46, clip=0, loss_scale=512, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=79711
2023-01-08 21:08:45 - progress_bar.py[line:274] - INFO: epoch 001:  13408 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3987, wps=60.9, ups=0.35, wpb=87.9, bsz=32, num_updates=13390, lr=4.68764e-05, gnorm=0.572, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=79740
2023-01-08 21:09:14 - progress_bar.py[line:274] - INFO: epoch 001:  13418 / 144806 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4651, wps=59.6, ups=0.34, wpb=86.6, bsz=32, num_updates=13400, lr=4.68728e-05, gnorm=0.582, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=79769
2023-01-08 21:09:43 - progress_bar.py[line:274] - INFO: epoch 001:  13428 / 144806 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4214, wps=61.2, ups=0.35, wpb=87.3, bsz=32, num_updates=13410, lr=4.68692e-05, gnorm=0.44, clip=10, loss_scale=512, train_wall=28, gb_free=14.9, ema_decay=0.9999, wall=79798
2023-01-08 21:10:12 - progress_bar.py[line:274] - INFO: epoch 001:  13438 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3655, wps=61.3, ups=0.35, wpb=88.6, bsz=32, num_updates=13420, lr=4.68657e-05, gnorm=0.507, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=79827
2023-01-08 21:10:41 - progress_bar.py[line:274] - INFO: epoch 001:  13448 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4277, wps=60.6, ups=0.35, wpb=86.8, bsz=32, num_updates=13430, lr=4.68621e-05, gnorm=0.453, clip=0, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=79856
2023-01-08 21:11:10 - progress_bar.py[line:274] - INFO: epoch 001:  13458 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3784, wps=61.7, ups=0.35, wpb=87.4, bsz=32, num_updates=13440, lr=4.68585e-05, gnorm=0.42, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=79885
2023-01-08 21:11:39 - progress_bar.py[line:274] - INFO: epoch 001:  13468 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.6, nsentences=32, sample_size=85.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.422, wps=60.3, ups=0.35, wpb=85.6, bsz=32, num_updates=13450, lr=4.6855e-05, gnorm=0.568, clip=10, loss_scale=512, train_wall=28, gb_free=14.7, ema_decay=0.9999, wall=79914
2023-01-08 21:12:07 - progress_bar.py[line:274] - INFO: epoch 001:  13478 / 144806 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4497, wps=61.4, ups=0.35, wpb=87, bsz=32, num_updates=13460, lr=4.68514e-05, gnorm=0.589, clip=20, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=79942
2023-01-08 21:12:37 - progress_bar.py[line:274] - INFO: epoch 001:  13488 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4359, wps=61, ups=0.34, wpb=88.6, bsz=32, num_updates=13470, lr=4.68478e-05, gnorm=0.493, clip=10, loss_scale=512, train_wall=29, gb_free=14.8, ema_decay=0.9999, wall=79972
2023-01-08 21:13:05 - progress_bar.py[line:274] - INFO: epoch 001:  13498 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3893, wps=61.6, ups=0.35, wpb=87.4, bsz=32, num_updates=13480, lr=4.68443e-05, gnorm=0.729, clip=10, loss_scale=512, train_wall=28, gb_free=15, ema_decay=0.9999, wall=80000
2023-01-08 21:13:34 - progress_bar.py[line:274] - INFO: epoch 001:  13508 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.391, wps=61, ups=0.35, wpb=88, bsz=32, num_updates=13490, lr=4.68407e-05, gnorm=0.454, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=80029
2023-01-08 21:14:04 - progress_bar.py[line:274] - INFO: epoch 001:  13518 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.443, wps=60.6, ups=0.35, wpb=87.5, bsz=32, num_updates=13500, lr=4.68371e-05, gnorm=0.361, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=80059
2023-01-08 21:14:33 - progress_bar.py[line:274] - INFO: epoch 001:  13528 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4, wps=59.6, ups=0.34, wpb=86.7, bsz=32, num_updates=13510, lr=4.68336e-05, gnorm=0.455, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=80088
2023-01-08 21:15:02 - progress_bar.py[line:274] - INFO: epoch 001:  13538 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4121, wps=59.5, ups=0.34, wpb=86.3, bsz=32, num_updates=13520, lr=4.683e-05, gnorm=0.406, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=80117
2023-01-08 21:15:31 - progress_bar.py[line:274] - INFO: epoch 001:  13548 / 144806 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3926, wps=60.6, ups=0.35, wpb=86.6, bsz=32, num_updates=13530, lr=4.68264e-05, gnorm=0.575, clip=20, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=80146
2023-01-08 21:16:00 - progress_bar.py[line:274] - INFO: epoch 001:  13558 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4379, wps=62.7, ups=0.35, wpb=88.5, bsz=32, num_updates=13540, lr=4.68229e-05, gnorm=0.499, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=80175
2023-01-08 21:16:28 - progress_bar.py[line:274] - INFO: epoch 001:  13568 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4208, wps=60.8, ups=0.35, wpb=86.1, bsz=32, num_updates=13550, lr=4.68193e-05, gnorm=0.403, clip=10, loss_scale=1024, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=80203
2023-01-08 21:16:58 - progress_bar.py[line:274] - INFO: epoch 001:  13578 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4667, wps=60.6, ups=0.34, wpb=88.4, bsz=32, num_updates=13560, lr=4.68157e-05, gnorm=0.545, clip=10, loss_scale=1024, train_wall=29, gb_free=15, ema_decay=0.9999, wall=80233
2023-01-08 21:17:27 - progress_bar.py[line:274] - INFO: epoch 001:  13588 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4118, wps=60.6, ups=0.35, wpb=87.1, bsz=32, num_updates=13570, lr=4.68122e-05, gnorm=0.429, clip=10, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=80262
2023-01-08 21:17:55 - progress_bar.py[line:274] - INFO: epoch 001:  13598 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4251, wps=61.6, ups=0.35, wpb=87, bsz=32, num_updates=13580, lr=4.68086e-05, gnorm=0.388, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=80290
2023-01-08 21:18:25 - progress_bar.py[line:274] - INFO: epoch 001:  13608 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4268, wps=60, ups=0.34, wpb=87.3, bsz=32, num_updates=13590, lr=4.6805e-05, gnorm=0.495, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=80320
2023-01-08 21:18:54 - progress_bar.py[line:274] - INFO: epoch 001:  13618 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4026, wps=61, ups=0.35, wpb=88.2, bsz=32, num_updates=13600, lr=4.68015e-05, gnorm=0.485, clip=0, loss_scale=1024, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=80349
2023-01-08 21:19:24 - progress_bar.py[line:274] - INFO: epoch 001:  13628 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4615, wps=60.1, ups=0.34, wpb=87.6, bsz=32, num_updates=13610, lr=4.67979e-05, gnorm=0.42, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=80379
2023-01-08 21:19:53 - progress_bar.py[line:274] - INFO: epoch 001:  13638 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4671, wps=60.8, ups=0.35, wpb=87.9, bsz=32, num_updates=13620, lr=4.67943e-05, gnorm=0.393, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=80408
2023-01-08 21:20:22 - progress_bar.py[line:274] - INFO: epoch 001:  13648 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3882, wps=60.3, ups=0.35, wpb=86.8, bsz=32, num_updates=13630, lr=4.67908e-05, gnorm=0.312, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=80437
2023-01-08 21:20:50 - progress_bar.py[line:274] - INFO: epoch 001:  13658 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3684, wps=62, ups=0.35, wpb=87.7, bsz=32, num_updates=13640, lr=4.67872e-05, gnorm=0.46, clip=10, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=80465
2023-01-08 21:21:20 - progress_bar.py[line:274] - INFO: epoch 001:  13668 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4726, wps=60.7, ups=0.34, wpb=88.1, bsz=32, num_updates=13650, lr=4.67836e-05, gnorm=0.411, clip=0, loss_scale=1024, train_wall=29, gb_free=15, ema_decay=0.9999, wall=80495
2023-01-08 21:21:49 - progress_bar.py[line:274] - INFO: epoch 001:  13678 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4795, wps=59.5, ups=0.34, wpb=87.2, bsz=32, num_updates=13660, lr=4.67801e-05, gnorm=0.404, clip=0, loss_scale=1024, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=80524
2023-01-08 21:22:19 - progress_bar.py[line:274] - INFO: epoch 001:  13688 / 144806 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3353, wps=60.2, ups=0.35, wpb=86.4, bsz=32, num_updates=13670, lr=4.67765e-05, gnorm=0.367, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=80553
2023-01-08 21:22:48 - progress_bar.py[line:274] - INFO: epoch 001:  13698 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.323, wps=60.2, ups=0.35, wpb=86.3, bsz=32, num_updates=13680, lr=4.67729e-05, gnorm=0.508, clip=10, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=80583
2023-01-08 21:23:17 - progress_bar.py[line:274] - INFO: epoch 001:  13708 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3951, wps=59.4, ups=0.34, wpb=86.6, bsz=32, num_updates=13690, lr=4.67693e-05, gnorm=0.527, clip=10, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=80612
2023-01-08 21:23:46 - progress_bar.py[line:274] - INFO: epoch 001:  13718 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4233, wps=59.8, ups=0.34, wpb=86.9, bsz=32, num_updates=13700, lr=4.67658e-05, gnorm=0.355, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=80641
2023-01-08 21:24:16 - progress_bar.py[line:274] - INFO: epoch 001:  13728 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4198, wps=59.6, ups=0.34, wpb=87.1, bsz=32, num_updates=13710, lr=4.67622e-05, gnorm=0.526, clip=0, loss_scale=1024, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=80671
2023-01-08 21:24:45 - progress_bar.py[line:274] - INFO: epoch 001:  13738 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4167, wps=62.1, ups=0.35, wpb=88.3, bsz=32, num_updates=13720, lr=4.67586e-05, gnorm=0.316, clip=0, loss_scale=1024, train_wall=28, gb_free=15.5, ema_decay=0.9999, wall=80700
2023-01-08 21:25:14 - progress_bar.py[line:274] - INFO: epoch 001:  13748 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4054, wps=61.2, ups=0.35, wpb=87.4, bsz=32, num_updates=13730, lr=4.67551e-05, gnorm=0.361, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=80729
2023-01-08 21:25:42 - progress_bar.py[line:274] - INFO: epoch 001:  13758 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4099, wps=62.1, ups=0.36, wpb=87.4, bsz=32, num_updates=13740, lr=4.67515e-05, gnorm=0.313, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=80757
2023-01-08 21:26:11 - progress_bar.py[line:274] - INFO: epoch 001:  13768 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4188, wps=60.7, ups=0.35, wpb=87.4, bsz=32, num_updates=13750, lr=4.67479e-05, gnorm=0.416, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=80786
2023-01-08 21:26:40 - progress_bar.py[line:274] - INFO: epoch 001:  13778 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4097, wps=60.7, ups=0.34, wpb=88.2, bsz=32, num_updates=13760, lr=4.67444e-05, gnorm=0.384, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=80815
2023-01-08 21:27:09 - progress_bar.py[line:274] - INFO: epoch 001:  13788 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.404, wps=60.8, ups=0.35, wpb=87.7, bsz=32, num_updates=13770, lr=4.67408e-05, gnorm=0.609, clip=10, loss_scale=1024, train_wall=29, gb_free=15, ema_decay=0.9999, wall=80845
2023-01-08 21:27:39 - progress_bar.py[line:274] - INFO: epoch 001:  13798 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.5, wps=61.2, ups=0.35, wpb=88.2, bsz=32, num_updates=13780, lr=4.67372e-05, gnorm=0.491, clip=10, loss_scale=1024, train_wall=29, gb_free=15, ema_decay=0.9999, wall=80874
2023-01-08 21:28:08 - progress_bar.py[line:274] - INFO: epoch 001:  13808 / 144806 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4167, wps=60.7, ups=0.35, wpb=87.7, bsz=32, num_updates=13790, lr=4.67337e-05, gnorm=0.362, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=80903
2023-01-08 21:28:37 - progress_bar.py[line:274] - INFO: epoch 001:  13818 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4172, wps=60.6, ups=0.35, wpb=86.5, bsz=32, num_updates=13800, lr=4.67301e-05, gnorm=0.423, clip=10, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=80932
2023-01-08 21:29:05 - progress_bar.py[line:274] - INFO: epoch 001:  13828 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4126, wps=61.2, ups=0.35, wpb=87.2, bsz=32, num_updates=13810, lr=4.67265e-05, gnorm=0.368, clip=0, loss_scale=1024, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=80960
2023-01-08 21:29:35 - progress_bar.py[line:274] - INFO: epoch 001:  13838 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4294, wps=60.6, ups=0.34, wpb=88.1, bsz=32, num_updates=13820, lr=4.6723e-05, gnorm=0.437, clip=10, loss_scale=1024, train_wall=29, gb_free=15.6, ema_decay=0.9999, wall=80990
2023-01-08 21:30:04 - progress_bar.py[line:274] - INFO: epoch 001:  13848 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3841, wps=60.4, ups=0.34, wpb=87.9, bsz=32, num_updates=13830, lr=4.67194e-05, gnorm=0.309, clip=0, loss_scale=1024, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=81019
2023-01-08 21:30:33 - progress_bar.py[line:274] - INFO: epoch 001:  13858 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4481, wps=61.4, ups=0.35, wpb=87.8, bsz=32, num_updates=13840, lr=4.67158e-05, gnorm=0.326, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=81048
2023-01-08 21:31:02 - progress_bar.py[line:274] - INFO: epoch 001:  13868 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4444, wps=61.8, ups=0.35, wpb=87.7, bsz=32, num_updates=13850, lr=4.67123e-05, gnorm=0.521, clip=0, loss_scale=1024, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=81077
2023-01-08 21:31:31 - progress_bar.py[line:274] - INFO: epoch 001:  13878 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4156, wps=60.6, ups=0.35, wpb=87.3, bsz=32, num_updates=13860, lr=4.67087e-05, gnorm=0.527, clip=10, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=81106
2023-01-08 21:32:00 - progress_bar.py[line:274] - INFO: epoch 001:  13888 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4192, wps=59.2, ups=0.34, wpb=86.6, bsz=32, num_updates=13870, lr=4.67051e-05, gnorm=0.438, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=81135
2023-01-08 21:32:30 - progress_bar.py[line:274] - INFO: epoch 001:  13898 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.375, wps=60.4, ups=0.35, wpb=87.5, bsz=32, num_updates=13880, lr=4.67016e-05, gnorm=0.377, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=81165
2023-01-08 21:32:59 - progress_bar.py[line:274] - INFO: epoch 001:  13908 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3704, wps=59.6, ups=0.34, wpb=86.9, bsz=32, num_updates=13890, lr=4.6698e-05, gnorm=0.575, clip=20, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=81194
2023-01-08 21:33:29 - progress_bar.py[line:274] - INFO: epoch 001:  13918 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3774, wps=59.8, ups=0.34, wpb=87.5, bsz=32, num_updates=13900, lr=4.66944e-05, gnorm=0.449, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=81224
2023-01-08 21:33:58 - progress_bar.py[line:274] - INFO: epoch 001:  13928 / 144806 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4167, wps=60.8, ups=0.35, wpb=87.2, bsz=32, num_updates=13910, lr=4.66909e-05, gnorm=0.471, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=81253
2023-01-08 21:34:26 - progress_bar.py[line:274] - INFO: epoch 001:  13938 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4065, wps=62.6, ups=0.35, wpb=88.3, bsz=32, num_updates=13920, lr=4.66873e-05, gnorm=0.561, clip=20, loss_scale=1024, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=81281
2023-01-08 21:34:55 - progress_bar.py[line:274] - INFO: epoch 001:  13948 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5133, wps=61.2, ups=0.35, wpb=87.2, bsz=32, num_updates=13930, lr=4.66837e-05, gnorm=0.495, clip=0, loss_scale=1024, train_wall=28, gb_free=15, ema_decay=0.9999, wall=81310
2023-01-08 21:35:24 - progress_bar.py[line:274] - INFO: epoch 001:  13958 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4198, wps=60.9, ups=0.35, wpb=86.6, bsz=32, num_updates=13940, lr=4.66802e-05, gnorm=0.503, clip=10, loss_scale=1024, train_wall=28, gb_free=15.6, ema_decay=0.9999, wall=81339
2023-01-08 21:35:53 - progress_bar.py[line:274] - INFO: epoch 001:  13968 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4487, wps=60.3, ups=0.34, wpb=87.8, bsz=32, num_updates=13950, lr=4.66766e-05, gnorm=0.391, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=81368
2023-01-08 21:36:23 - progress_bar.py[line:274] - INFO: epoch 001:  13978 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4568, wps=59.3, ups=0.34, wpb=86.6, bsz=32, num_updates=13960, lr=4.6673e-05, gnorm=0.433, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=81398
2023-01-08 21:36:52 - progress_bar.py[line:274] - INFO: epoch 001:  13988 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4106, wps=61.1, ups=0.35, wpb=87.9, bsz=32, num_updates=13970, lr=4.66695e-05, gnorm=0.577, clip=10, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=81427
2023-01-08 21:37:21 - progress_bar.py[line:274] - INFO: epoch 001:  13998 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=89, nsentences=32, sample_size=89, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4379, wps=60.6, ups=0.34, wpb=89, bsz=32, num_updates=13980, lr=4.66659e-05, gnorm=0.387, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=81456
2023-01-08 21:37:50 - progress_bar.py[line:274] - INFO: epoch 001:  14008 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4595, wps=61.3, ups=0.35, wpb=87.7, bsz=32, num_updates=13990, lr=4.66623e-05, gnorm=0.551, clip=10, loss_scale=1024, train_wall=29, gb_free=14.8, ema_decay=0.9999, wall=81485
2023-01-08 21:38:19 - progress_bar.py[line:274] - INFO: epoch 001:  14018 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4706, wps=61.4, ups=0.35, wpb=87.6, bsz=32, num_updates=14000, lr=4.66588e-05, gnorm=0.406, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=81514
2023-01-08 21:38:19 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 21:38:21 - train.py[line:549] - INFO: 0 / 6234
2023-01-08 21:38:21 - train.py[line:551] - INFO: load:1.17 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 21:38:22 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.30 GiB (GPU 0; 39.59 GiB total capacity; 8.02 GiB already allocated; 2.35 GiB free; 25.65 GiB reserved in total by PyTorch)
2023-01-08 21:38:22 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 4            |        cudaMalloc retries: 37        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8215 MB |    9121 MB |    6822 TB |    6822 TB |
|       from large pool |    8041 MB |    8947 MB |    6818 TB |    6818 TB |
|       from small pool |     174 MB |     174 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8215 MB |    9121 MB |    6822 TB |    6822 TB |
|       from large pool |    8041 MB |    8947 MB |    6818 TB |    6818 TB |
|       from small pool |     174 MB |     174 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26268 MB |   26272 MB |  450724 MB |  424456 MB |
|       from large pool |   26092 MB |   26092 MB |  449994 MB |  423902 MB |
|       from small pool |     176 MB |     180 MB |     730 MB |     554 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   18052 MB |   21313 MB |    7557 TB |    7557 TB |
|       from large pool |   18050 MB |   21310 MB |    7553 TB |    7553 TB |
|       from small pool |       1 MB |       2 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  367827 K  |  367822 K  |
|       from large pool |     698    |     710    |  124325 K  |  124324 K  |
|       from small pool |    3925    |    3943    |  243501 K  |  243497 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  367827 K  |  367822 K  |
|       from large pool |     698    |     710    |  124325 K  |  124324 K  |
|       from small pool |    3925    |    3943    |  243501 K  |  243497 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     156    |     158    |    1294    |    1138    |
|       from large pool |      68    |      68    |     929    |     861    |
|       from small pool |      88    |      90    |     365    |     277    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     104    |     111    |  271265 K  |  271265 K  |
|       from large pool |      51    |      54    |   64921 K  |   64921 K  |
|       from small pool |      53    |      60    |  206344 K  |  206343 K  |
|===========================================================================|

2023-01-08 21:38:22 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-08 21:38:22 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-08 21:42:35 - train.py[line:549] - INFO: 200 / 6234
2023-01-08 21:42:35 - train.py[line:551] - INFO: load:1.19 valid_run:254.41 task_valid:249.72 collect_output:0.70
2023-01-08 21:46:44 - train.py[line:549] - INFO: 400 / 6234
2023-01-08 21:46:44 - train.py[line:551] - INFO: load:1.22 valid_run:503.35 task_valid:495.42 collect_output:1.40
2023-01-08 21:50:54 - train.py[line:549] - INFO: 600 / 6234
2023-01-08 21:50:54 - train.py[line:551] - INFO: load:1.24 valid_run:753.10 task_valid:741.92 collect_output:2.11
2023-01-08 21:55:00 - train.py[line:549] - INFO: 800 / 6234
2023-01-08 21:55:00 - train.py[line:551] - INFO: load:1.26 valid_run:998.96 task_valid:984.54 collect_output:2.80
2023-01-08 21:59:11 - train.py[line:549] - INFO: 1000 / 6234
2023-01-08 21:59:11 - train.py[line:551] - INFO: load:1.29 valid_run:1249.93 task_valid:1232.27 collect_output:3.48
2023-01-08 22:03:24 - train.py[line:549] - INFO: 1200 / 6234
2023-01-08 22:03:24 - train.py[line:551] - INFO: load:1.31 valid_run:1502.99 task_valid:1482.07 collect_output:4.16
2023-01-08 22:07:36 - train.py[line:549] - INFO: 1400 / 6234
2023-01-08 22:07:36 - train.py[line:551] - INFO: load:1.34 valid_run:1754.92 task_valid:1730.78 collect_output:4.83
2023-01-08 22:11:46 - train.py[line:549] - INFO: 1600 / 6234
2023-01-08 22:11:46 - train.py[line:551] - INFO: load:1.36 valid_run:2004.75 task_valid:1977.40 collect_output:5.52
2023-01-08 22:15:57 - train.py[line:549] - INFO: 1800 / 6234
2023-01-08 22:15:57 - train.py[line:551] - INFO: load:1.39 valid_run:2255.39 task_valid:2224.83 collect_output:6.20
2023-01-08 22:20:01 - train.py[line:549] - INFO: 2000 / 6234
2023-01-08 22:20:01 - train.py[line:551] - INFO: load:1.41 valid_run:2499.69 task_valid:2465.91 collect_output:6.89
2023-01-08 22:24:10 - train.py[line:549] - INFO: 2200 / 6234
2023-01-08 22:24:10 - train.py[line:551] - INFO: load:1.43 valid_run:2748.21 task_valid:2711.21 collect_output:7.57
2023-01-08 22:28:20 - train.py[line:549] - INFO: 2400 / 6234
2023-01-08 22:28:20 - train.py[line:551] - INFO: load:1.46 valid_run:2998.27 task_valid:2958.06 collect_output:8.25
2023-01-08 22:32:25 - train.py[line:549] - INFO: 2600 / 6234
2023-01-08 22:32:25 - train.py[line:551] - INFO: load:1.48 valid_run:3243.72 task_valid:3200.31 collect_output:8.92
2023-01-08 22:36:37 - train.py[line:549] - INFO: 2800 / 6234
2023-01-08 22:36:37 - train.py[line:551] - INFO: load:1.51 valid_run:3494.92 task_valid:3448.30 collect_output:9.60
2023-01-08 22:40:45 - train.py[line:549] - INFO: 3000 / 6234
2023-01-08 22:40:45 - train.py[line:551] - INFO: load:1.53 valid_run:3743.47 task_valid:3693.68 collect_output:10.26
2023-01-08 22:44:51 - train.py[line:549] - INFO: 3200 / 6234
2023-01-08 22:44:51 - train.py[line:551] - INFO: load:1.56 valid_run:3989.23 task_valid:3936.26 collect_output:10.92
2023-01-08 22:49:00 - train.py[line:549] - INFO: 3400 / 6234
2023-01-08 22:49:00 - train.py[line:551] - INFO: load:1.58 valid_run:4238.01 task_valid:4181.85 collect_output:11.58
2023-01-08 22:53:11 - train.py[line:549] - INFO: 3600 / 6234
2023-01-08 22:53:11 - train.py[line:551] - INFO: load:1.60 valid_run:4489.14 task_valid:4429.84 collect_output:12.21
2023-01-08 22:57:21 - train.py[line:549] - INFO: 3800 / 6234
2023-01-08 22:57:21 - train.py[line:551] - INFO: load:1.63 valid_run:4739.23 task_valid:4676.73 collect_output:12.88
2023-01-08 23:01:31 - train.py[line:549] - INFO: 4000 / 6234
2023-01-08 23:01:31 - train.py[line:551] - INFO: load:1.65 valid_run:4989.05 task_valid:4923.32 collect_output:13.55
2023-01-08 23:05:41 - train.py[line:549] - INFO: 4200 / 6234
2023-01-08 23:05:41 - train.py[line:551] - INFO: load:1.68 valid_run:5238.73 task_valid:5169.81 collect_output:14.22
2023-01-08 23:09:54 - train.py[line:549] - INFO: 4400 / 6234
2023-01-08 23:09:54 - train.py[line:551] - INFO: load:1.70 valid_run:5491.53 task_valid:5419.39 collect_output:14.89
2023-01-08 23:14:01 - train.py[line:549] - INFO: 4600 / 6234
2023-01-08 23:14:01 - train.py[line:551] - INFO: load:1.73 valid_run:5738.36 task_valid:5662.95 collect_output:15.58
2023-01-08 23:18:10 - train.py[line:549] - INFO: 4800 / 6234
2023-01-08 23:18:10 - train.py[line:551] - INFO: load:1.76 valid_run:5987.10 task_valid:5908.48 collect_output:16.26
2023-01-08 23:22:19 - train.py[line:549] - INFO: 5000 / 6234
2023-01-08 23:22:19 - train.py[line:551] - INFO: load:1.78 valid_run:6236.13 task_valid:6154.31 collect_output:16.92
2023-01-08 23:26:28 - train.py[line:549] - INFO: 5200 / 6234
2023-01-08 23:26:28 - train.py[line:551] - INFO: load:1.81 valid_run:6485.17 task_valid:6400.13 collect_output:17.57
2023-01-08 23:30:34 - train.py[line:549] - INFO: 5400 / 6234
2023-01-08 23:30:34 - train.py[line:551] - INFO: load:1.84 valid_run:6731.50 task_valid:6643.21 collect_output:18.25
2023-01-08 23:34:48 - train.py[line:549] - INFO: 5600 / 6234
2023-01-08 23:34:48 - train.py[line:551] - INFO: load:1.86 valid_run:6985.50 task_valid:6893.99 collect_output:18.91
2023-01-08 23:38:57 - train.py[line:549] - INFO: 5800 / 6234
2023-01-08 23:38:57 - train.py[line:551] - INFO: load:1.89 valid_run:7234.35 task_valid:7139.59 collect_output:19.59
2023-01-08 23:43:10 - train.py[line:549] - INFO: 6000 / 6234
2023-01-08 23:43:10 - train.py[line:551] - INFO: load:1.91 valid_run:7486.99 task_valid:7389.01 collect_output:20.26
2023-01-08 23:47:23 - train.py[line:549] - INFO: 6200 / 6234
2023-01-08 23:47:23 - train.py[line:551] - INFO: load:1.94 valid_run:7739.58 task_valid:7638.38 collect_output:20.92

====================================================================================================
SGG eval:     R @ 50: 0.4296;     R @ 100: 0.5272;     R @ 500: 0.5904;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2598;    mR @ 100: 0.3340;    mR @ 500: 0.3933;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6927) (covered in:0.6250) (covering:0.3429) (eating:0.5294) (flying in:0.0000) (growing on:0.0000) (hanging from:0.4677) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9940) (playing:0.0000) (riding:0.7565) (says:0.0000) (sitting on:0.6329) (standing on:0.1633) (using:0.6000) (walking in:0.0000) (walking on:0.4865) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4296;     R @ 100: 0.5272;     R @ 500: 0.5904;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2598;    mR @ 100: 0.3340;    mR @ 500: 0.3933;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6927) (covered in:0.6250) (covering:0.3429) (eating:0.5294) (flying in:0.0000) (growing on:0.0000) (hanging from:0.4677) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9940) (playing:0.0000) (riding:0.7565) (says:0.0000) (sitting on:0.6329) (standing on:0.1633) (using:0.6000) (walking in:0.0000) (walking on:0.4865) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-01-08 23:48:16 - train.py[line:487] - INFO: 0.5272047619047618
2023-01-08 23:48:16 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 23:48:16 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.361 | loss_v1 0 | loss_v2 0 | nll_loss 0.207 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.527205 | ppl 1.15 | vqa_score 0.5158 | wps 57.6 | wpb 72 | bsz 24 | num_updates 14000 | best_R@100 0.632103
2023-01-08 23:48:16 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 14000 updates
2023-01-08 23:48:16 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_14000.pt
2023-01-08 23:48:54 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_14000.pt
2023-01-08 23:50:14 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_14000.pt (epoch 1 @ 14000 updates, score 0.5272047619047618) (writing took 118.36681599542499 seconds)
2023-01-08 23:50:44 - progress_bar.py[line:274] - INFO: epoch 001:  14028 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3898, wps=0.2, ups=0, wpb=86.3, bsz=32, num_updates=14010, lr=4.66552e-05, gnorm=0.337, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=89459
2023-01-08 23:51:13 - progress_bar.py[line:274] - INFO: epoch 001:  14038 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4295, wps=61.1, ups=0.35, wpb=87.2, bsz=32, num_updates=14020, lr=4.66516e-05, gnorm=0.489, clip=10, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=89488
2023-01-08 23:51:42 - progress_bar.py[line:274] - INFO: epoch 001:  14048 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3907, wps=61.5, ups=0.35, wpb=88.6, bsz=32, num_updates=14030, lr=4.66481e-05, gnorm=0.285, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=89517
2023-01-08 23:52:12 - progress_bar.py[line:274] - INFO: epoch 001:  14058 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4161, wps=59.2, ups=0.34, wpb=86.6, bsz=32, num_updates=14040, lr=4.66445e-05, gnorm=0.337, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=89547
2023-01-08 23:52:41 - progress_bar.py[line:274] - INFO: epoch 001:  14068 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4201, wps=60, ups=0.35, wpb=86.9, bsz=32, num_updates=14050, lr=4.66409e-05, gnorm=0.318, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=89576
2023-01-08 23:53:09 - progress_bar.py[line:274] - INFO: epoch 001:  14078 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=89.2, nsentences=32, sample_size=89.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.493, wps=63.4, ups=0.36, wpb=89.2, bsz=32, num_updates=14060, lr=4.66374e-05, gnorm=0.364, clip=0, loss_scale=2048, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=89604
2023-01-08 23:53:24 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-08 23:53:41 - progress_bar.py[line:274] - INFO: epoch 001:  14089 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=87.524, nsentences=32, sample_size=87.524, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4091, wps=57.8, ups=0.31, wpb=87.5, bsz=32, num_updates=14070, lr=4.66338e-05, gnorm=0.339, clip=0, loss_scale=1024, train_wall=32, gb_free=15.2, ema_decay=0.9999, wall=89636
2023-01-08 23:54:10 - progress_bar.py[line:274] - INFO: epoch 001:  14099 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.381, wps=62.1, ups=0.35, wpb=88, bsz=32, num_updates=14080, lr=4.66302e-05, gnorm=0.495, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=89665
2023-01-08 23:54:39 - progress_bar.py[line:274] - INFO: epoch 001:  14109 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4815, wps=60, ups=0.35, wpb=86.8, bsz=32, num_updates=14090, lr=4.66267e-05, gnorm=0.514, clip=10, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=89694
2023-01-08 23:55:08 - progress_bar.py[line:274] - INFO: epoch 001:  14119 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4323, wps=61.3, ups=0.35, wpb=88.1, bsz=32, num_updates=14100, lr=4.66231e-05, gnorm=0.444, clip=10, loss_scale=1024, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=89723
2023-01-08 23:55:37 - progress_bar.py[line:274] - INFO: epoch 001:  14129 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4, wps=59.9, ups=0.35, wpb=86.3, bsz=32, num_updates=14110, lr=4.66195e-05, gnorm=0.437, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=89752
2023-01-08 23:56:06 - progress_bar.py[line:274] - INFO: epoch 001:  14139 / 144806 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3681, wps=61.1, ups=0.35, wpb=87.7, bsz=32, num_updates=14120, lr=4.6616e-05, gnorm=0.394, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=89781
2023-01-08 23:56:35 - progress_bar.py[line:274] - INFO: epoch 001:  14149 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4238, wps=61.1, ups=0.35, wpb=87.4, bsz=32, num_updates=14130, lr=4.66124e-05, gnorm=0.389, clip=0, loss_scale=1024, train_wall=29, gb_free=15, ema_decay=0.9999, wall=89810
2023-01-08 23:57:04 - progress_bar.py[line:274] - INFO: epoch 001:  14159 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3818, wps=60.4, ups=0.35, wpb=87.1, bsz=32, num_updates=14140, lr=4.66088e-05, gnorm=0.496, clip=0, loss_scale=1024, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=89839
2023-01-08 23:57:33 - progress_bar.py[line:274] - INFO: epoch 001:  14169 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4242, wps=59.8, ups=0.35, wpb=86.5, bsz=32, num_updates=14150, lr=4.66053e-05, gnorm=0.38, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=89868
2023-01-08 23:58:02 - progress_bar.py[line:274] - INFO: epoch 001:  14179 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4718, wps=61, ups=0.34, wpb=88.8, bsz=32, num_updates=14160, lr=4.66017e-05, gnorm=0.483, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=89897
2023-01-08 23:58:31 - progress_bar.py[line:274] - INFO: epoch 001:  14189 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=85.6, nsentences=32, sample_size=85.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4566, wps=58.8, ups=0.34, wpb=85.6, bsz=32, num_updates=14170, lr=4.65981e-05, gnorm=0.447, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=89927
2023-01-08 23:59:01 - progress_bar.py[line:274] - INFO: epoch 001:  14199 / 144806 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4118, wps=59.6, ups=0.35, wpb=85.8, bsz=32, num_updates=14180, lr=4.65946e-05, gnorm=0.487, clip=10, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=89956
2023-01-08 23:59:29 - progress_bar.py[line:274] - INFO: epoch 001:  14209 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3974, wps=62.2, ups=0.35, wpb=88.1, bsz=32, num_updates=14190, lr=4.6591e-05, gnorm=0.485, clip=10, loss_scale=1024, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=89984
2023-01-08 23:59:57 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-09 00:00:00 - progress_bar.py[line:274] - INFO: epoch 001:  14220 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4022, wps=58.8, ups=0.32, wpb=87, bsz=32, num_updates=14200, lr=4.65874e-05, gnorm=0.718, clip=20, loss_scale=512, train_wall=31, gb_free=15.1, ema_decay=0.9999, wall=90015
2023-01-09 00:00:29 - progress_bar.py[line:274] - INFO: epoch 001:  14230 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=84.7, nsentences=32, sample_size=84.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4114, wps=59.5, ups=0.35, wpb=84.7, bsz=32, num_updates=14210, lr=4.65839e-05, gnorm=0.462, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=90044
2023-01-09 00:00:58 - progress_bar.py[line:274] - INFO: epoch 001:  14240 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4843, wps=59.7, ups=0.34, wpb=86.9, bsz=32, num_updates=14220, lr=4.65803e-05, gnorm=0.469, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=90073
2023-01-09 00:01:27 - progress_bar.py[line:274] - INFO: epoch 001:  14250 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4639, wps=61.3, ups=0.35, wpb=86.4, bsz=32, num_updates=14230, lr=4.65767e-05, gnorm=0.503, clip=10, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=90102
2023-01-09 00:01:56 - progress_bar.py[line:274] - INFO: epoch 001:  14260 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4467, wps=60.3, ups=0.35, wpb=87.1, bsz=32, num_updates=14240, lr=4.65732e-05, gnorm=0.39, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=90131
2023-01-09 00:02:25 - progress_bar.py[line:274] - INFO: epoch 001:  14270 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4753, wps=59.3, ups=0.34, wpb=87.2, bsz=32, num_updates=14250, lr=4.65696e-05, gnorm=0.338, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=90161
2023-01-09 00:02:55 - progress_bar.py[line:274] - INFO: epoch 001:  14280 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3974, wps=60.1, ups=0.35, wpb=86.9, bsz=32, num_updates=14260, lr=4.6566e-05, gnorm=0.436, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=90190
2023-01-09 00:03:24 - progress_bar.py[line:274] - INFO: epoch 001:  14290 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.414, wps=60.8, ups=0.35, wpb=87.2, bsz=32, num_updates=14270, lr=4.65625e-05, gnorm=0.53, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=90219
2023-01-09 00:03:52 - progress_bar.py[line:274] - INFO: epoch 001:  14300 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4247, wps=61.4, ups=0.35, wpb=88, bsz=32, num_updates=14280, lr=4.65589e-05, gnorm=0.542, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=90248
2023-01-09 00:04:21 - progress_bar.py[line:274] - INFO: epoch 001:  14310 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4233, wps=61.1, ups=0.35, wpb=86.9, bsz=32, num_updates=14290, lr=4.65553e-05, gnorm=0.317, clip=0, loss_scale=512, train_wall=28, gb_free=15.6, ema_decay=0.9999, wall=90276
2023-01-09 00:04:50 - progress_bar.py[line:274] - INFO: epoch 001:  14320 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3667, wps=60.9, ups=0.35, wpb=87.3, bsz=32, num_updates=14300, lr=4.65518e-05, gnorm=0.553, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=90305
2023-01-09 00:05:19 - progress_bar.py[line:274] - INFO: epoch 001:  14330 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5062, wps=61.4, ups=0.35, wpb=87.4, bsz=32, num_updates=14310, lr=4.65482e-05, gnorm=0.488, clip=10, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=90334
2023-01-09 00:05:21 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 00:05:50 - progress_bar.py[line:274] - INFO: epoch 001:  14341 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.905, nsentences=32, sample_size=86.905, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4667, wps=58.1, ups=0.32, wpb=86.9, bsz=32, num_updates=14320, lr=4.65446e-05, gnorm=1.472, clip=20, loss_scale=256, train_wall=31, gb_free=15.3, ema_decay=0.9999, wall=90366
2023-01-09 00:06:19 - progress_bar.py[line:274] - INFO: epoch 001:  14351 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4148, wps=60.3, ups=0.35, wpb=86.5, bsz=32, num_updates=14330, lr=4.65411e-05, gnorm=0.399, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=90394
2023-01-09 00:06:48 - progress_bar.py[line:274] - INFO: epoch 001:  14361 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4321, wps=61, ups=0.35, wpb=87.2, bsz=32, num_updates=14340, lr=4.65375e-05, gnorm=0.434, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=90423
2023-01-09 00:07:17 - progress_bar.py[line:274] - INFO: epoch 001:  14371 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3709, wps=60.2, ups=0.35, wpb=87.1, bsz=32, num_updates=14350, lr=4.65339e-05, gnorm=0.457, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=90452
2023-01-09 00:07:46 - progress_bar.py[line:274] - INFO: epoch 001:  14381 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4191, wps=61.7, ups=0.35, wpb=88.6, bsz=32, num_updates=14360, lr=4.65304e-05, gnorm=0.458, clip=10, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=90481
2023-01-09 00:08:15 - progress_bar.py[line:274] - INFO: epoch 001:  14391 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=89.7, nsentences=32, sample_size=89.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3901, wps=62.1, ups=0.35, wpb=89.7, bsz=32, num_updates=14370, lr=4.65268e-05, gnorm=0.364, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=90510
2023-01-09 00:08:45 - progress_bar.py[line:274] - INFO: epoch 001:  14401 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4276, wps=60.3, ups=0.34, wpb=88.1, bsz=32, num_updates=14380, lr=4.65232e-05, gnorm=0.53, clip=10, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=90540
2023-01-09 00:09:14 - progress_bar.py[line:274] - INFO: epoch 001:  14411 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4038, wps=59.6, ups=0.34, wpb=87.6, bsz=32, num_updates=14390, lr=4.65197e-05, gnorm=0.515, clip=10, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=90569
2023-01-09 00:09:43 - progress_bar.py[line:274] - INFO: epoch 001:  14421 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4122, wps=61, ups=0.35, wpb=87.6, bsz=32, num_updates=14400, lr=4.65161e-05, gnorm=0.362, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=90598
2023-01-09 00:10:12 - progress_bar.py[line:274] - INFO: epoch 001:  14431 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4, wps=60.2, ups=0.35, wpb=85.5, bsz=32, num_updates=14410, lr=4.65125e-05, gnorm=0.35, clip=0, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=90627
2023-01-09 00:10:41 - progress_bar.py[line:274] - INFO: epoch 001:  14441 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4379, wps=60.6, ups=0.35, wpb=86.9, bsz=32, num_updates=14420, lr=4.6509e-05, gnorm=0.368, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=90656
2023-01-09 00:11:10 - progress_bar.py[line:274] - INFO: epoch 001:  14451 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4362, wps=61.5, ups=0.35, wpb=88.1, bsz=32, num_updates=14430, lr=4.65054e-05, gnorm=1.073, clip=20, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=90685
2023-01-09 00:11:39 - progress_bar.py[line:274] - INFO: epoch 001:  14461 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.462, wps=60.7, ups=0.34, wpb=88.1, bsz=32, num_updates=14440, lr=4.65018e-05, gnorm=0.594, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=90714
2023-01-09 00:12:07 - progress_bar.py[line:274] - INFO: epoch 001:  14471 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4342, wps=61.9, ups=0.35, wpb=87.4, bsz=32, num_updates=14450, lr=4.64983e-05, gnorm=0.478, clip=10, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=90743
2023-01-09 00:12:36 - progress_bar.py[line:274] - INFO: epoch 001:  14481 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4768, wps=61.7, ups=0.35, wpb=88.1, bsz=32, num_updates=14460, lr=4.64947e-05, gnorm=0.534, clip=10, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=90771
2023-01-09 00:13:05 - progress_bar.py[line:274] - INFO: epoch 001:  14491 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3677, wps=61.5, ups=0.36, wpb=86.4, bsz=32, num_updates=14470, lr=4.64911e-05, gnorm=0.388, clip=0, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=90800
2023-01-09 00:13:34 - progress_bar.py[line:274] - INFO: epoch 001:  14501 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3804, wps=59.3, ups=0.35, wpb=85.8, bsz=32, num_updates=14480, lr=4.64876e-05, gnorm=0.664, clip=20, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=90829
2023-01-09 00:14:02 - progress_bar.py[line:274] - INFO: epoch 001:  14511 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4094, wps=60.6, ups=0.35, wpb=86.1, bsz=32, num_updates=14490, lr=4.6484e-05, gnorm=0.347, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=90857
2023-01-09 00:14:31 - progress_bar.py[line:274] - INFO: epoch 001:  14521 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4765, wps=61, ups=0.35, wpb=87.8, bsz=32, num_updates=14500, lr=4.64804e-05, gnorm=0.512, clip=10, loss_scale=256, train_wall=29, gb_free=15.6, ema_decay=0.9999, wall=90886
2023-01-09 00:15:01 - progress_bar.py[line:274] - INFO: epoch 001:  14531 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4304, wps=59.2, ups=0.34, wpb=86.4, bsz=32, num_updates=14510, lr=4.64769e-05, gnorm=0.573, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=90916
2023-01-09 00:15:30 - progress_bar.py[line:274] - INFO: epoch 001:  14541 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3718, wps=61.5, ups=0.35, wpb=87.4, bsz=32, num_updates=14520, lr=4.64733e-05, gnorm=0.301, clip=0, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=90945
2023-01-09 00:15:58 - progress_bar.py[line:274] - INFO: epoch 001:  14551 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4027, wps=61.8, ups=0.35, wpb=87.8, bsz=32, num_updates=14530, lr=4.64697e-05, gnorm=0.246, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=90973
2023-01-09 00:16:28 - progress_bar.py[line:274] - INFO: epoch 001:  14561 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4524, wps=58.5, ups=0.34, wpb=86.6, bsz=32, num_updates=14540, lr=4.64662e-05, gnorm=0.297, clip=0, loss_scale=256, train_wall=30, gb_free=15.2, ema_decay=0.9999, wall=91003
2023-01-09 00:16:57 - progress_bar.py[line:274] - INFO: epoch 001:  14571 / 144806 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4311, wps=60.2, ups=0.35, wpb=87, bsz=32, num_updates=14550, lr=4.64626e-05, gnorm=0.412, clip=10, loss_scale=256, train_wall=29, gb_free=15.7, ema_decay=0.9999, wall=91032
2023-01-09 00:17:26 - progress_bar.py[line:274] - INFO: epoch 001:  14581 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4024, wps=60.9, ups=0.35, wpb=86.9, bsz=32, num_updates=14560, lr=4.6459e-05, gnorm=1.029, clip=10, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=91061
2023-01-09 00:17:55 - progress_bar.py[line:274] - INFO: epoch 001:  14591 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.415, wps=62.3, ups=0.35, wpb=88.8, bsz=32, num_updates=14570, lr=4.64555e-05, gnorm=0.439, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=91090
2023-01-09 00:18:24 - progress_bar.py[line:274] - INFO: epoch 001:  14601 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3801, wps=60, ups=0.34, wpb=87.2, bsz=32, num_updates=14580, lr=4.64519e-05, gnorm=0.464, clip=20, loss_scale=256, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=91119
2023-01-09 00:18:53 - progress_bar.py[line:274] - INFO: epoch 001:  14611 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3775, wps=60.7, ups=0.34, wpb=88.1, bsz=32, num_updates=14590, lr=4.64483e-05, gnorm=0.456, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=91148
2023-01-09 00:19:22 - progress_bar.py[line:274] - INFO: epoch 001:  14621 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3851, wps=61.4, ups=0.35, wpb=87.5, bsz=32, num_updates=14600, lr=4.64448e-05, gnorm=0.353, clip=0, loss_scale=256, train_wall=28, gb_free=15, ema_decay=0.9999, wall=91177
2023-01-09 00:19:51 - progress_bar.py[line:274] - INFO: epoch 001:  14631 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.487, wps=59.8, ups=0.34, wpb=86.9, bsz=32, num_updates=14610, lr=4.64412e-05, gnorm=0.686, clip=20, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=91206
2023-01-09 00:20:20 - progress_bar.py[line:274] - INFO: epoch 001:  14641 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=84.9, nsentences=32, sample_size=84.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3687, wps=58.8, ups=0.35, wpb=84.9, bsz=32, num_updates=14620, lr=4.64376e-05, gnorm=0.412, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=91235
2023-01-09 00:20:49 - progress_bar.py[line:274] - INFO: epoch 001:  14651 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4907, wps=60.7, ups=0.35, wpb=86.7, bsz=32, num_updates=14630, lr=4.6434e-05, gnorm=0.448, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=91264
2023-01-09 00:21:18 - progress_bar.py[line:274] - INFO: epoch 001:  14661 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3929, wps=61.2, ups=0.35, wpb=86.7, bsz=32, num_updates=14640, lr=4.64305e-05, gnorm=0.427, clip=0, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=91293
2023-01-09 00:21:47 - progress_bar.py[line:274] - INFO: epoch 001:  14671 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4494, wps=60.8, ups=0.35, wpb=87.4, bsz=32, num_updates=14650, lr=4.64269e-05, gnorm=0.526, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=91322
2023-01-09 00:22:15 - progress_bar.py[line:274] - INFO: epoch 001:  14681 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3759, wps=61.9, ups=0.35, wpb=87.6, bsz=32, num_updates=14660, lr=4.64233e-05, gnorm=0.317, clip=10, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=91350
2023-01-09 00:22:45 - progress_bar.py[line:274] - INFO: epoch 001:  14691 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4241, wps=60.9, ups=0.34, wpb=88.8, bsz=32, num_updates=14670, lr=4.64198e-05, gnorm=0.431, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=91380
2023-01-09 00:23:13 - progress_bar.py[line:274] - INFO: epoch 001:  14701 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3931, wps=61.8, ups=0.35, wpb=87.6, bsz=32, num_updates=14680, lr=4.64162e-05, gnorm=0.433, clip=10, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=91408
2023-01-09 00:23:43 - progress_bar.py[line:274] - INFO: epoch 001:  14711 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3827, wps=60.2, ups=0.34, wpb=87.9, bsz=32, num_updates=14690, lr=4.64126e-05, gnorm=0.424, clip=10, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=91438
2023-01-09 00:24:11 - progress_bar.py[line:274] - INFO: epoch 001:  14721 / 144806 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4235, wps=61, ups=0.35, wpb=86.3, bsz=32, num_updates=14700, lr=4.64091e-05, gnorm=0.469, clip=10, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=91466
2023-01-09 00:24:40 - progress_bar.py[line:274] - INFO: epoch 001:  14731 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4107, wps=60.8, ups=0.35, wpb=87.2, bsz=32, num_updates=14710, lr=4.64055e-05, gnorm=0.452, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=91495
2023-01-09 00:25:08 - progress_bar.py[line:274] - INFO: epoch 001:  14741 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4457, wps=61.5, ups=0.36, wpb=86.4, bsz=32, num_updates=14720, lr=4.64019e-05, gnorm=0.601, clip=20, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=91523
2023-01-09 00:25:38 - progress_bar.py[line:274] - INFO: epoch 001:  14751 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4323, wps=60.6, ups=0.34, wpb=88, bsz=32, num_updates=14730, lr=4.63984e-05, gnorm=0.356, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=91553
2023-01-09 00:26:07 - progress_bar.py[line:274] - INFO: epoch 001:  14761 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.457, wps=60.2, ups=0.35, wpb=87.2, bsz=32, num_updates=14740, lr=4.63948e-05, gnorm=0.405, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=91582
2023-01-09 00:26:35 - progress_bar.py[line:274] - INFO: epoch 001:  14771 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3758, wps=61.7, ups=0.35, wpb=87.7, bsz=32, num_updates=14750, lr=4.63912e-05, gnorm=0.333, clip=0, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=91611
2023-01-09 00:27:04 - progress_bar.py[line:274] - INFO: epoch 001:  14781 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4024, wps=60.2, ups=0.35, wpb=86.5, bsz=32, num_updates=14760, lr=4.63877e-05, gnorm=0.423, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=91639
2023-01-09 00:27:33 - progress_bar.py[line:274] - INFO: epoch 001:  14791 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4024, wps=61.4, ups=0.35, wpb=87.1, bsz=32, num_updates=14770, lr=4.63841e-05, gnorm=0.425, clip=0, loss_scale=256, train_wall=28, gb_free=15, ema_decay=0.9999, wall=91668
2023-01-09 00:28:02 - progress_bar.py[line:274] - INFO: epoch 001:  14801 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3694, wps=59.9, ups=0.34, wpb=87, bsz=32, num_updates=14780, lr=4.63805e-05, gnorm=0.378, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=91697
2023-01-09 00:28:31 - progress_bar.py[line:274] - INFO: epoch 001:  14811 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3711, wps=61.1, ups=0.35, wpb=87.1, bsz=32, num_updates=14790, lr=4.6377e-05, gnorm=0.542, clip=10, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=91726
2023-01-09 00:29:00 - progress_bar.py[line:274] - INFO: epoch 001:  14821 / 144806 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.314, wps=59.9, ups=0.34, wpb=86.9, bsz=32, num_updates=14800, lr=4.63734e-05, gnorm=0.391, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=91755
2023-01-09 00:29:29 - progress_bar.py[line:274] - INFO: epoch 001:  14831 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3907, wps=60.8, ups=0.35, wpb=87.4, bsz=32, num_updates=14810, lr=4.63698e-05, gnorm=0.565, clip=20, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=91784
2023-01-09 00:29:59 - progress_bar.py[line:274] - INFO: epoch 001:  14841 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4383, wps=59.7, ups=0.35, wpb=86.4, bsz=32, num_updates=14820, lr=4.63663e-05, gnorm=0.561, clip=10, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=91813
2023-01-09 00:30:28 - progress_bar.py[line:274] - INFO: epoch 001:  14851 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4529, wps=60.1, ups=0.34, wpb=87.5, bsz=32, num_updates=14830, lr=4.63627e-05, gnorm=0.432, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=91843
2023-01-09 00:30:54 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 00:31:00 - progress_bar.py[line:274] - INFO: epoch 001:  14862 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.857, nsentences=32, sample_size=87.857, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3841, wps=58.7, ups=0.32, wpb=87.9, bsz=32, num_updates=14840, lr=4.63591e-05, gnorm=0.456, clip=0, loss_scale=256, train_wall=31, gb_free=15.1, ema_decay=0.9999, wall=91875
2023-01-09 00:31:29 - progress_bar.py[line:274] - INFO: epoch 001:  14872 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.404, wps=60.8, ups=0.35, wpb=87.9, bsz=32, num_updates=14850, lr=4.63556e-05, gnorm=0.353, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=91904
2023-01-09 00:32:00 - progress_bar.py[line:274] - INFO: epoch 001:  14882 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4054, wps=61.8, ups=0.35, wpb=88.6, bsz=32, num_updates=14860, lr=4.6352e-05, gnorm=0.331, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=91933
2023-01-09 00:32:30 - progress_bar.py[line:274] - INFO: epoch 001:  14892 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4667, wps=61.5, ups=0.35, wpb=88.1, bsz=32, num_updates=14870, lr=4.63484e-05, gnorm=0.43, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=91964
2023-01-09 00:33:00 - progress_bar.py[line:274] - INFO: epoch 001:  14902 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=89.5, nsentences=32, sample_size=89.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4189, wps=62.3, ups=0.35, wpb=89.5, bsz=32, num_updates=14880, lr=4.63449e-05, gnorm=0.338, clip=0, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=91994
2023-01-09 00:33:29 - progress_bar.py[line:274] - INFO: epoch 001:  14912 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=85.4, nsentences=32, sample_size=85.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4783, wps=60.9, ups=0.36, wpb=85.4, bsz=32, num_updates=14890, lr=4.63413e-05, gnorm=0.423, clip=0, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=92023
2023-01-09 00:34:00 - progress_bar.py[line:274] - INFO: epoch 001:  14922 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4342, wps=60.7, ups=0.34, wpb=88.9, bsz=32, num_updates=14900, lr=4.63377e-05, gnorm=0.567, clip=10, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=92054
2023-01-09 00:34:30 - progress_bar.py[line:274] - INFO: epoch 001:  14932 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.474, wps=61.1, ups=0.35, wpb=87.2, bsz=32, num_updates=14910, lr=4.63342e-05, gnorm=0.504, clip=10, loss_scale=256, train_wall=28, gb_free=15, ema_decay=0.9999, wall=92084
2023-01-09 00:35:00 - progress_bar.py[line:274] - INFO: epoch 001:  14942 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4437, wps=60.5, ups=0.35, wpb=86.9, bsz=32, num_updates=14920, lr=4.63306e-05, gnorm=0.314, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=92114
2023-01-09 00:35:30 - progress_bar.py[line:274] - INFO: epoch 001:  14952 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4, wps=60.8, ups=0.35, wpb=87.7, bsz=32, num_updates=14930, lr=4.6327e-05, gnorm=0.35, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=92144
2023-01-09 00:36:00 - progress_bar.py[line:274] - INFO: epoch 001:  14962 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.431, wps=60.2, ups=0.35, wpb=85.9, bsz=32, num_updates=14940, lr=4.63235e-05, gnorm=0.409, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=92174
2023-01-09 00:36:30 - progress_bar.py[line:274] - INFO: epoch 001:  14972 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4593, wps=60.9, ups=0.35, wpb=86.9, bsz=32, num_updates=14950, lr=4.63199e-05, gnorm=0.504, clip=20, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=92204
2023-01-09 00:37:01 - progress_bar.py[line:274] - INFO: epoch 001:  14982 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4487, wps=62, ups=0.35, wpb=88.5, bsz=32, num_updates=14960, lr=4.63163e-05, gnorm=0.493, clip=20, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=92234
2023-01-09 00:37:31 - progress_bar.py[line:274] - INFO: epoch 001:  14992 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4747, wps=60.2, ups=0.34, wpb=87.5, bsz=32, num_updates=14970, lr=4.63128e-05, gnorm=0.306, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=92265
2023-01-09 00:38:01 - progress_bar.py[line:274] - INFO: epoch 001:  15002 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4295, wps=59.3, ups=0.34, wpb=86.4, bsz=32, num_updates=14980, lr=4.63092e-05, gnorm=0.452, clip=10, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=92295
2023-01-09 00:38:31 - progress_bar.py[line:274] - INFO: epoch 001:  15012 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4214, wps=60.7, ups=0.35, wpb=87.1, bsz=32, num_updates=14990, lr=4.63056e-05, gnorm=0.488, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=92325
2023-01-09 00:39:02 - progress_bar.py[line:274] - INFO: epoch 001:  15022 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4834, wps=61.2, ups=0.35, wpb=87.6, bsz=32, num_updates=15000, lr=4.63021e-05, gnorm=0.434, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=92355
2023-01-09 00:39:32 - progress_bar.py[line:274] - INFO: epoch 001:  15032 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4671, wps=60.8, ups=0.34, wpb=88.2, bsz=32, num_updates=15010, lr=4.62985e-05, gnorm=0.503, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=92386
2023-01-09 00:40:03 - progress_bar.py[line:274] - INFO: epoch 001:  15042 / 144806 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4557, wps=59.1, ups=0.34, wpb=86.3, bsz=32, num_updates=15020, lr=4.62949e-05, gnorm=0.435, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=92417
2023-01-09 00:40:33 - progress_bar.py[line:274] - INFO: epoch 001:  15052 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4207, wps=60.9, ups=0.35, wpb=86.9, bsz=32, num_updates=15030, lr=4.62914e-05, gnorm=0.328, clip=0, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=92447
2023-01-09 00:41:03 - progress_bar.py[line:274] - INFO: epoch 001:  15062 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4172, wps=60.1, ups=0.35, wpb=86.8, bsz=32, num_updates=15040, lr=4.62878e-05, gnorm=0.334, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=92477
2023-01-09 00:41:33 - progress_bar.py[line:274] - INFO: epoch 001:  15072 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4479, wps=61.5, ups=0.35, wpb=87.7, bsz=32, num_updates=15050, lr=4.62842e-05, gnorm=0.433, clip=20, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=92507
2023-01-09 00:42:04 - progress_bar.py[line:274] - INFO: epoch 001:  15082 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4383, wps=60.4, ups=0.35, wpb=87, bsz=32, num_updates=15060, lr=4.62807e-05, gnorm=0.395, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=92538
2023-01-09 00:42:35 - progress_bar.py[line:274] - INFO: epoch 001:  15092 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4194, wps=59.7, ups=0.34, wpb=87, bsz=32, num_updates=15070, lr=4.62771e-05, gnorm=0.418, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=92568
2023-01-09 00:43:05 - progress_bar.py[line:274] - INFO: epoch 001:  15102 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4361, wps=61.5, ups=0.35, wpb=88.1, bsz=32, num_updates=15080, lr=4.62735e-05, gnorm=0.377, clip=0, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=92598
2023-01-09 00:43:36 - progress_bar.py[line:274] - INFO: epoch 001:  15112 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3818, wps=59.5, ups=0.34, wpb=86.6, bsz=32, num_updates=15090, lr=4.627e-05, gnorm=0.518, clip=10, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=92629
2023-01-09 00:44:08 - progress_bar.py[line:274] - INFO: epoch 001:  15122 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.461, wps=62.4, ups=0.35, wpb=88, bsz=32, num_updates=15100, lr=4.62664e-05, gnorm=0.46, clip=10, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=92660
2023-01-09 00:44:39 - progress_bar.py[line:274] - INFO: epoch 001:  15132 / 144806 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4237, wps=60.4, ups=0.35, wpb=86.4, bsz=32, num_updates=15110, lr=4.62628e-05, gnorm=0.401, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=92692
2023-01-09 00:45:11 - progress_bar.py[line:274] - INFO: epoch 001:  15142 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4386, wps=61.1, ups=0.35, wpb=86.7, bsz=32, num_updates=15120, lr=4.62593e-05, gnorm=0.493, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=92723
2023-01-09 00:45:41 - progress_bar.py[line:274] - INFO: epoch 001:  15152 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4062, wps=61.1, ups=0.35, wpb=87.5, bsz=32, num_updates=15130, lr=4.62557e-05, gnorm=0.522, clip=10, loss_scale=256, train_wall=29, gb_free=14.6, ema_decay=0.9999, wall=92754
2023-01-09 00:46:11 - progress_bar.py[line:274] - INFO: epoch 001:  15162 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.503, wps=60.4, ups=0.35, wpb=86.9, bsz=32, num_updates=15140, lr=4.62521e-05, gnorm=0.459, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=92785
2023-01-09 00:46:42 - progress_bar.py[line:274] - INFO: epoch 001:  15172 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4041, wps=60.8, ups=0.34, wpb=88.2, bsz=32, num_updates=15150, lr=4.62486e-05, gnorm=0.428, clip=0, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=92815
2023-01-09 00:47:12 - progress_bar.py[line:274] - INFO: epoch 001:  15182 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4121, wps=60, ups=0.34, wpb=87.1, bsz=32, num_updates=15160, lr=4.6245e-05, gnorm=0.403, clip=10, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=92846
2023-01-09 00:47:43 - progress_bar.py[line:274] - INFO: epoch 001:  15192 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.434, wps=61, ups=0.35, wpb=87.9, bsz=32, num_updates=15170, lr=4.62414e-05, gnorm=0.304, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=92876
2023-01-09 00:48:13 - progress_bar.py[line:274] - INFO: epoch 001:  15202 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4012, wps=60.4, ups=0.35, wpb=86.6, bsz=32, num_updates=15180, lr=4.62379e-05, gnorm=0.374, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=92907
2023-01-09 00:48:43 - progress_bar.py[line:274] - INFO: epoch 001:  15212 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.443, wps=60.6, ups=0.35, wpb=87, bsz=32, num_updates=15190, lr=4.62343e-05, gnorm=0.491, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=92937
2023-01-09 00:49:13 - progress_bar.py[line:274] - INFO: epoch 001:  15222 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4487, wps=60.9, ups=0.35, wpb=87.1, bsz=32, num_updates=15200, lr=4.62307e-05, gnorm=0.6, clip=20, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=92967
2023-01-09 00:49:43 - progress_bar.py[line:274] - INFO: epoch 001:  15232 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4467, wps=60.4, ups=0.34, wpb=87.6, bsz=32, num_updates=15210, lr=4.62272e-05, gnorm=0.475, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=92997
2023-01-09 00:50:14 - progress_bar.py[line:274] - INFO: epoch 001:  15242 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.487, wps=59.7, ups=0.34, wpb=86.9, bsz=32, num_updates=15220, lr=4.62236e-05, gnorm=0.513, clip=20, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=93027
2023-01-09 00:50:44 - progress_bar.py[line:274] - INFO: epoch 001:  15252 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4527, wps=60.9, ups=0.34, wpb=88.3, bsz=32, num_updates=15230, lr=4.622e-05, gnorm=0.279, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=93058
2023-01-09 00:51:15 - progress_bar.py[line:274] - INFO: epoch 001:  15262 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.485, wps=59.9, ups=0.34, wpb=87, bsz=32, num_updates=15240, lr=4.62165e-05, gnorm=0.456, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=93089
2023-01-09 00:51:45 - progress_bar.py[line:274] - INFO: epoch 001:  15272 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.425, wps=60.1, ups=0.35, wpb=86.2, bsz=32, num_updates=15250, lr=4.62129e-05, gnorm=0.336, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=93119
2023-01-09 00:52:15 - progress_bar.py[line:274] - INFO: epoch 001:  15282 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4188, wps=61.4, ups=0.35, wpb=88, bsz=32, num_updates=15260, lr=4.62093e-05, gnorm=0.337, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=93149
2023-01-09 00:52:45 - progress_bar.py[line:274] - INFO: epoch 001:  15292 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4521, wps=61.4, ups=0.35, wpb=88.5, bsz=32, num_updates=15270, lr=4.62058e-05, gnorm=0.443, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=93179
2023-01-09 00:53:16 - progress_bar.py[line:274] - INFO: epoch 001:  15302 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4268, wps=59.9, ups=0.34, wpb=87.1, bsz=32, num_updates=15280, lr=4.62022e-05, gnorm=0.427, clip=10, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=93209
2023-01-09 00:53:46 - progress_bar.py[line:274] - INFO: epoch 001:  15312 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4533, wps=61.7, ups=0.35, wpb=88.1, bsz=32, num_updates=15290, lr=4.61986e-05, gnorm=0.393, clip=0, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=93240
2023-01-09 00:54:17 - progress_bar.py[line:274] - INFO: epoch 001:  15322 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4934, wps=60.1, ups=0.34, wpb=87.3, bsz=32, num_updates=15300, lr=4.61951e-05, gnorm=0.325, clip=0, loss_scale=256, train_wall=29, gb_free=14.8, ema_decay=0.9999, wall=93270
2023-01-09 00:54:46 - progress_bar.py[line:274] - INFO: epoch 001:  15332 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4035, wps=60.6, ups=0.35, wpb=86.9, bsz=32, num_updates=15310, lr=4.61915e-05, gnorm=0.451, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=93301
2023-01-09 00:55:15 - progress_bar.py[line:274] - INFO: epoch 001:  15342 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4601, wps=61, ups=0.35, wpb=87.8, bsz=32, num_updates=15320, lr=4.61879e-05, gnorm=0.407, clip=10, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=93330
2023-01-09 00:55:44 - progress_bar.py[line:274] - INFO: epoch 001:  15352 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4467, wps=60.8, ups=0.35, wpb=87.4, bsz=32, num_updates=15330, lr=4.61844e-05, gnorm=0.39, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=93359
2023-01-09 00:56:13 - progress_bar.py[line:274] - INFO: epoch 001:  15362 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3812, wps=61.5, ups=0.35, wpb=87.5, bsz=32, num_updates=15340, lr=4.61808e-05, gnorm=0.387, clip=10, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=93388
2023-01-09 00:56:41 - progress_bar.py[line:274] - INFO: epoch 001:  15372 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4114, wps=61.6, ups=0.36, wpb=86.7, bsz=32, num_updates=15350, lr=4.61772e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=93416
2023-01-09 00:57:11 - progress_bar.py[line:274] - INFO: epoch 001:  15382 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.415, wps=61.1, ups=0.35, wpb=87.7, bsz=32, num_updates=15360, lr=4.61737e-05, gnorm=0.382, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=93445
2023-01-09 00:57:39 - progress_bar.py[line:274] - INFO: epoch 001:  15392 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4305, wps=61.9, ups=0.36, wpb=87, bsz=32, num_updates=15370, lr=4.61701e-05, gnorm=0.358, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=93474
2023-01-09 00:57:53 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 00:58:11 - progress_bar.py[line:274] - INFO: epoch 001:  15403 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.429, nsentences=32, sample_size=88.429, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4444, wps=58.9, ups=0.32, wpb=88.4, bsz=32, num_updates=15380, lr=4.61665e-05, gnorm=0.265, clip=0, loss_scale=256, train_wall=31, gb_free=15.2, ema_decay=0.9999, wall=93506
2023-01-09 00:58:40 - progress_bar.py[line:274] - INFO: epoch 001:  15413 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.463, wps=62.1, ups=0.35, wpb=87.5, bsz=32, num_updates=15390, lr=4.6163e-05, gnorm=0.591, clip=20, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=93535
2023-01-09 00:59:09 - progress_bar.py[line:274] - INFO: epoch 001:  15423 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4785, wps=60.7, ups=0.35, wpb=86.6, bsz=32, num_updates=15400, lr=4.61594e-05, gnorm=0.688, clip=20, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=93564
2023-01-09 00:59:38 - progress_bar.py[line:274] - INFO: epoch 001:  15433 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=89.4, nsentences=32, sample_size=89.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4225, wps=62.8, ups=0.35, wpb=89.4, bsz=32, num_updates=15410, lr=4.61558e-05, gnorm=0.402, clip=0, loss_scale=256, train_wall=28, gb_free=14.7, ema_decay=0.9999, wall=93592
2023-01-09 01:00:08 - progress_bar.py[line:274] - INFO: epoch 001:  15443 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4709, wps=59.5, ups=0.34, wpb=87, bsz=32, num_updates=15420, lr=4.61523e-05, gnorm=0.512, clip=10, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=93623
2023-01-09 01:00:38 - progress_bar.py[line:274] - INFO: epoch 001:  15453 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=85.7, nsentences=32, sample_size=85.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3988, wps=58.5, ups=0.34, wpb=85.7, bsz=32, num_updates=15430, lr=4.61487e-05, gnorm=0.461, clip=0, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=93653
2023-01-09 01:01:08 - progress_bar.py[line:274] - INFO: epoch 001:  15463 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4545, wps=61.2, ups=0.35, wpb=86.9, bsz=32, num_updates=15440, lr=4.61451e-05, gnorm=0.512, clip=10, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=93682
2023-01-09 01:01:37 - progress_bar.py[line:274] - INFO: epoch 001:  15473 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.45, wps=60.9, ups=0.35, wpb=88, bsz=32, num_updates=15450, lr=4.61416e-05, gnorm=0.345, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=93712
2023-01-09 01:02:07 - progress_bar.py[line:274] - INFO: epoch 001:  15483 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4189, wps=60.6, ups=0.34, wpb=88, bsz=32, num_updates=15460, lr=4.6138e-05, gnorm=0.297, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=93742
2023-01-09 01:02:37 - progress_bar.py[line:274] - INFO: epoch 001:  15493 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4107, wps=61.5, ups=0.35, wpb=87.8, bsz=32, num_updates=15470, lr=4.61344e-05, gnorm=0.424, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=93771
2023-01-09 01:03:07 - progress_bar.py[line:274] - INFO: epoch 001:  15503 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4157, wps=60.7, ups=0.35, wpb=87.5, bsz=32, num_updates=15480, lr=4.61309e-05, gnorm=0.439, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=93801
2023-01-09 01:03:36 - progress_bar.py[line:274] - INFO: epoch 001:  15513 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4503, wps=61.1, ups=0.35, wpb=88, bsz=32, num_updates=15490, lr=4.61273e-05, gnorm=0.373, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=93831
2023-01-09 01:04:06 - progress_bar.py[line:274] - INFO: epoch 001:  15523 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3899, wps=60.4, ups=0.35, wpb=86.6, bsz=32, num_updates=15500, lr=4.61237e-05, gnorm=0.41, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=93860
2023-01-09 01:04:36 - progress_bar.py[line:274] - INFO: epoch 001:  15533 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4765, wps=61.6, ups=0.35, wpb=87.8, bsz=32, num_updates=15510, lr=4.61202e-05, gnorm=0.696, clip=30, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=93890
2023-01-09 01:05:06 - progress_bar.py[line:274] - INFO: epoch 001:  15543 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4125, wps=59.8, ups=0.34, wpb=87.6, bsz=32, num_updates=15520, lr=4.61166e-05, gnorm=0.339, clip=0, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=93920
2023-01-09 01:05:36 - progress_bar.py[line:274] - INFO: epoch 001:  15553 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4, wps=60.4, ups=0.34, wpb=88.3, bsz=32, num_updates=15530, lr=4.6113e-05, gnorm=0.383, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=93951
2023-01-09 01:06:06 - progress_bar.py[line:274] - INFO: epoch 001:  15563 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3822, wps=60.6, ups=0.35, wpb=87, bsz=32, num_updates=15540, lr=4.61095e-05, gnorm=0.363, clip=0, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=93980
2023-01-09 01:06:36 - progress_bar.py[line:274] - INFO: epoch 001:  15573 / 144806 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4136, wps=60.2, ups=0.35, wpb=86.5, bsz=32, num_updates=15550, lr=4.61059e-05, gnorm=0.578, clip=20, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=94010
2023-01-09 01:07:06 - progress_bar.py[line:274] - INFO: epoch 001:  15583 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3963, wps=59.2, ups=0.34, wpb=86.2, bsz=32, num_updates=15560, lr=4.61023e-05, gnorm=0.697, clip=30, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=94040
2023-01-09 01:07:35 - progress_bar.py[line:274] - INFO: epoch 001:  15593 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4625, wps=61.1, ups=0.35, wpb=86.8, bsz=32, num_updates=15570, lr=4.60987e-05, gnorm=0.428, clip=0, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=94070
2023-01-09 01:08:05 - progress_bar.py[line:274] - INFO: epoch 001:  15603 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4934, wps=61.4, ups=0.35, wpb=87.9, bsz=32, num_updates=15580, lr=4.60952e-05, gnorm=0.387, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=94099
2023-01-09 01:08:35 - progress_bar.py[line:274] - INFO: epoch 001:  15613 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3916, wps=59.8, ups=0.34, wpb=86.9, bsz=32, num_updates=15590, lr=4.60916e-05, gnorm=0.36, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=94129
2023-01-09 01:09:04 - progress_bar.py[line:274] - INFO: epoch 001:  15623 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3841, wps=61.3, ups=0.35, wpb=87.4, bsz=32, num_updates=15600, lr=4.6088e-05, gnorm=0.474, clip=10, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=94158
2023-01-09 01:09:34 - progress_bar.py[line:274] - INFO: epoch 001:  15633 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4516, wps=60.8, ups=0.35, wpb=87.6, bsz=32, num_updates=15610, lr=4.60845e-05, gnorm=0.473, clip=10, loss_scale=256, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=94188
2023-01-09 01:10:03 - progress_bar.py[line:274] - INFO: epoch 001:  15643 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4156, wps=61.7, ups=0.35, wpb=87.6, bsz=32, num_updates=15620, lr=4.60809e-05, gnorm=0.483, clip=20, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=94218
2023-01-09 01:10:33 - progress_bar.py[line:274] - INFO: epoch 001:  15653 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4233, wps=60.2, ups=0.34, wpb=87.4, bsz=32, num_updates=15630, lr=4.60773e-05, gnorm=0.426, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=94248
2023-01-09 01:11:03 - progress_bar.py[line:274] - INFO: epoch 001:  15663 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4337, wps=61.1, ups=0.35, wpb=87, bsz=32, num_updates=15640, lr=4.60738e-05, gnorm=0.389, clip=0, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=94277
2023-01-09 01:11:32 - progress_bar.py[line:274] - INFO: epoch 001:  15673 / 144806 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4571, wps=61.5, ups=0.35, wpb=88.7, bsz=32, num_updates=15650, lr=4.60702e-05, gnorm=0.439, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=94307
2023-01-09 01:12:02 - progress_bar.py[line:274] - INFO: epoch 001:  15683 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4551, wps=60.5, ups=0.35, wpb=87.5, bsz=32, num_updates=15660, lr=4.60666e-05, gnorm=0.364, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=94337
2023-01-09 01:12:32 - progress_bar.py[line:274] - INFO: epoch 001:  15693 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4575, wps=60.4, ups=0.35, wpb=86.5, bsz=32, num_updates=15670, lr=4.60631e-05, gnorm=0.687, clip=10, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=94366
2023-01-09 01:13:01 - progress_bar.py[line:274] - INFO: epoch 001:  15703 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4885, wps=60.7, ups=0.35, wpb=86, bsz=32, num_updates=15680, lr=4.60595e-05, gnorm=0.426, clip=0, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=94395
2023-01-09 01:13:31 - progress_bar.py[line:274] - INFO: epoch 001:  15713 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4398, wps=59.5, ups=0.34, wpb=87.1, bsz=32, num_updates=15690, lr=4.60559e-05, gnorm=0.308, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=94426
2023-01-09 01:14:01 - progress_bar.py[line:274] - INFO: epoch 001:  15723 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.36, wps=61.6, ups=0.35, wpb=88.3, bsz=32, num_updates=15700, lr=4.60524e-05, gnorm=0.431, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=94455
2023-01-09 01:14:31 - progress_bar.py[line:274] - INFO: epoch 001:  15733 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4233, wps=61, ups=0.35, wpb=87.6, bsz=32, num_updates=15710, lr=4.60488e-05, gnorm=0.32, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=94485
2023-01-09 01:15:01 - progress_bar.py[line:274] - INFO: epoch 001:  15743 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4607, wps=59.2, ups=0.34, wpb=86.8, bsz=32, num_updates=15720, lr=4.60452e-05, gnorm=0.31, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=94515
2023-01-09 01:15:30 - progress_bar.py[line:274] - INFO: epoch 001:  15753 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4533, wps=60.9, ups=0.35, wpb=87.2, bsz=32, num_updates=15730, lr=4.60417e-05, gnorm=0.411, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=94545
2023-01-09 01:16:00 - progress_bar.py[line:274] - INFO: epoch 001:  15763 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3631, wps=60.7, ups=0.35, wpb=87.1, bsz=32, num_updates=15740, lr=4.60381e-05, gnorm=0.489, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=94574
2023-01-09 01:16:30 - progress_bar.py[line:274] - INFO: epoch 001:  15773 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4581, wps=59.3, ups=0.34, wpb=87.2, bsz=32, num_updates=15750, lr=4.60345e-05, gnorm=0.473, clip=20, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=94605
2023-01-09 01:17:00 - progress_bar.py[line:274] - INFO: epoch 001:  15783 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3933, wps=61.7, ups=0.35, wpb=87.4, bsz=32, num_updates=15760, lr=4.6031e-05, gnorm=0.528, clip=20, loss_scale=256, train_wall=28, gb_free=15, ema_decay=0.9999, wall=94634
2023-01-09 01:17:30 - progress_bar.py[line:274] - INFO: epoch 001:  15793 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4506, wps=60.2, ups=0.35, wpb=87.2, bsz=32, num_updates=15770, lr=4.60274e-05, gnorm=0.587, clip=20, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=94664
2023-01-09 01:18:00 - progress_bar.py[line:274] - INFO: epoch 001:  15803 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4342, wps=61.2, ups=0.35, wpb=87.8, bsz=32, num_updates=15780, lr=4.60238e-05, gnorm=0.433, clip=10, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=94694
2023-01-09 01:18:29 - progress_bar.py[line:274] - INFO: epoch 001:  15813 / 144806 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4024, wps=60.8, ups=0.35, wpb=87, bsz=32, num_updates=15790, lr=4.60203e-05, gnorm=0.532, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=94723
2023-01-09 01:18:59 - progress_bar.py[line:274] - INFO: epoch 001:  15823 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4367, wps=59.6, ups=0.34, wpb=86.4, bsz=32, num_updates=15800, lr=4.60167e-05, gnorm=0.384, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=94753
2023-01-09 01:19:29 - progress_bar.py[line:274] - INFO: epoch 001:  15833 / 144806 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3602, wps=59, ups=0.34, wpb=86.2, bsz=32, num_updates=15810, lr=4.60131e-05, gnorm=0.52, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=94784
2023-01-09 01:19:59 - progress_bar.py[line:274] - INFO: epoch 001:  15843 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3841, wps=61.5, ups=0.35, wpb=88.2, bsz=32, num_updates=15820, lr=4.60096e-05, gnorm=0.397, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=94813
2023-01-09 01:20:29 - progress_bar.py[line:274] - INFO: epoch 001:  15853 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4028, wps=60.4, ups=0.34, wpb=88.2, bsz=32, num_updates=15830, lr=4.6006e-05, gnorm=0.347, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=94843
2023-01-09 01:20:59 - progress_bar.py[line:274] - INFO: epoch 001:  15863 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4305, wps=61.1, ups=0.35, wpb=87.7, bsz=32, num_updates=15840, lr=4.60024e-05, gnorm=0.37, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=94873
2023-01-09 01:21:29 - progress_bar.py[line:274] - INFO: epoch 001:  15873 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4863, wps=60.4, ups=0.34, wpb=88.1, bsz=32, num_updates=15850, lr=4.59989e-05, gnorm=0.403, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=94903
2023-01-09 01:21:58 - progress_bar.py[line:274] - INFO: epoch 001:  15883 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3963, wps=60.2, ups=0.35, wpb=86.5, bsz=32, num_updates=15860, lr=4.59953e-05, gnorm=0.311, clip=0, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=94933
2023-01-09 01:22:28 - progress_bar.py[line:274] - INFO: epoch 001:  15893 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4082, wps=60.3, ups=0.34, wpb=87.8, bsz=32, num_updates=15870, lr=4.59917e-05, gnorm=0.41, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=94963
2023-01-09 01:22:58 - progress_bar.py[line:274] - INFO: epoch 001:  15903 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3766, wps=60.8, ups=0.35, wpb=87.9, bsz=32, num_updates=15880, lr=4.59882e-05, gnorm=0.413, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=94992
2023-01-09 01:23:27 - progress_bar.py[line:274] - INFO: epoch 001:  15913 / 144806 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4309, wps=60.2, ups=0.35, wpb=85.5, bsz=32, num_updates=15890, lr=4.59846e-05, gnorm=0.555, clip=20, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=95022
2023-01-09 01:23:57 - progress_bar.py[line:274] - INFO: epoch 001:  15923 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4011, wps=60.6, ups=0.35, wpb=86.6, bsz=32, num_updates=15900, lr=4.5981e-05, gnorm=0.345, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=95051
2023-01-09 01:24:26 - progress_bar.py[line:274] - INFO: epoch 001:  15933 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4737, wps=61.8, ups=0.35, wpb=88, bsz=32, num_updates=15910, lr=4.59775e-05, gnorm=0.321, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=95081
2023-01-09 01:24:56 - progress_bar.py[line:274] - INFO: epoch 001:  15943 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4012, wps=62, ups=0.35, wpb=88.1, bsz=32, num_updates=15920, lr=4.59739e-05, gnorm=0.496, clip=10, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=95110
2023-01-09 01:25:26 - progress_bar.py[line:274] - INFO: epoch 001:  15953 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4303, wps=60.5, ups=0.35, wpb=86.9, bsz=32, num_updates=15930, lr=4.59703e-05, gnorm=0.44, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=95140
2023-01-09 01:25:55 - progress_bar.py[line:274] - INFO: epoch 001:  15963 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4832, wps=61, ups=0.34, wpb=88.5, bsz=32, num_updates=15940, lr=4.59668e-05, gnorm=0.305, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=95170
2023-01-09 01:26:25 - progress_bar.py[line:274] - INFO: epoch 001:  15973 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4444, wps=60.2, ups=0.34, wpb=87.4, bsz=32, num_updates=15950, lr=4.59632e-05, gnorm=0.244, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=95200
2023-01-09 01:26:55 - progress_bar.py[line:274] - INFO: epoch 001:  15983 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4702, wps=60.9, ups=0.35, wpb=86.7, bsz=32, num_updates=15960, lr=4.59596e-05, gnorm=0.528, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=95229
2023-01-09 01:27:25 - progress_bar.py[line:274] - INFO: epoch 001:  15993 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4226, wps=59.8, ups=0.35, wpb=86.5, bsz=32, num_updates=15970, lr=4.59561e-05, gnorm=0.439, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=95259
2023-01-09 01:27:54 - progress_bar.py[line:274] - INFO: epoch 001:  16003 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=85.2, nsentences=32, sample_size=85.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4426, wps=60.2, ups=0.35, wpb=85.2, bsz=32, num_updates=15980, lr=4.59525e-05, gnorm=0.281, clip=0, loss_scale=512, train_wall=28, gb_free=15.5, ema_decay=0.9999, wall=95288
2023-01-09 01:28:23 - progress_bar.py[line:274] - INFO: epoch 001:  16013 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3519, wps=60.6, ups=0.35, wpb=86.4, bsz=32, num_updates=15990, lr=4.59489e-05, gnorm=0.379, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=95318
2023-01-09 01:28:53 - progress_bar.py[line:274] - INFO: epoch 001:  16023 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4805, wps=60.7, ups=0.35, wpb=86.8, bsz=32, num_updates=16000, lr=4.59454e-05, gnorm=0.255, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=95347
2023-01-09 01:28:53 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-09 01:28:54 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.91 GiB (GPU 1; 39.59 GiB total capacity; 8.39 GiB already allocated; 4.38 GiB free; 25.88 GiB reserved in total by PyTorch)
2023-01-09 01:28:54 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-09 01:28:54 - train.py[line:549] - INFO: 0 / 6234
2023-01-09 01:28:54 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 4            |        cudaMalloc retries: 26        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8586 MB |    9566 MB |    7887 TB |    7887 TB |
|       from large pool |    8412 MB |    9392 MB |    7883 TB |    7883 TB |
|       from small pool |     174 MB |     174 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8586 MB |    9566 MB |    7887 TB |    7887 TB |
|       from large pool |    8412 MB |    9392 MB |    7883 TB |    7883 TB |
|       from small pool |     174 MB |     174 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26506 MB |   27538 MB |  325862 MB |  299356 MB |
|       from large pool |   26328 MB |   27358 MB |  325292 MB |  298964 MB |
|       from small pool |     178 MB |     180 MB |     570 MB |     392 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17919 MB |   21503 MB |    8684 TB |    8684 TB |
|       from large pool |   17915 MB |   21498 MB |    8680 TB |    8680 TB |
|       from small pool |       3 MB |       4 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  424743 K  |  424739 K  |
|       from large pool |     698    |     710    |  143499 K  |  143499 K  |
|       from small pool |    3925    |    3943    |  281244 K  |  281240 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  424743 K  |  424739 K  |
|       from large pool |     698    |     710    |  143499 K  |  143499 K  |
|       from small pool |    3925    |    3943    |  281244 K  |  281240 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     197    |     203    |    1010    |     813    |
|       from large pool |     108    |     113    |     725    |     617    |
|       from small pool |      89    |      90    |     285    |     196    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     132    |     136    |  314455 K  |  314455 K  |
|       from large pool |      72    |      73    |   74947 K  |   74947 K  |
|       from small pool |      60    |      68    |  239508 K  |  239508 K  |
|===========================================================================|

2023-01-09 01:28:54 - train.py[line:551] - INFO: load:1.08 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-09 01:28:54 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-09 01:29:26 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.97 GiB (GPU 0; 39.59 GiB total capacity; 8.41 GiB already allocated; 2.07 GiB free; 25.93 GiB reserved in total by PyTorch)
2023-01-09 01:29:26 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 5            |        cudaMalloc retries: 39        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8613 MB |   12795 MB |    7876 TB |    7876 TB |
|       from large pool |    8439 MB |   12621 MB |    7871 TB |    7871 TB |
|       from small pool |     174 MB |     174 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8613 MB |   12795 MB |    7876 TB |    7876 TB |
|       from large pool |    8439 MB |   12621 MB |    7871 TB |    7871 TB |
|       from small pool |     174 MB |     174 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26554 MB |   27398 MB |  473636 MB |  447082 MB |
|       from large pool |   26378 MB |   27218 MB |  472856 MB |  446478 MB |
|       from small pool |     176 MB |     180 MB |     780 MB |     604 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17940 MB |   21578 MB |    9176 TB |    9176 TB |
|       from large pool |   17938 MB |   21575 MB |    9172 TB |    9172 TB |
|       from small pool |       1 MB |       3 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4634    |    4648    |  424882 K  |  424878 K  |
|       from large pool |     698    |     710    |  143541 K  |  143540 K  |
|       from small pool |    3936    |    3946    |  281341 K  |  281337 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4634    |    4648    |  424882 K  |  424878 K  |
|       from large pool |     698    |     710    |  143541 K  |  143540 K  |
|       from small pool |    3936    |    3946    |  281341 K  |  281337 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     187    |     192    |    1393    |    1206    |
|       from large pool |      99    |     102    |    1003    |     904    |
|       from small pool |      88    |      90    |     390    |     302    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     110    |     122    |  314608 K  |  314608 K  |
|       from large pool |      65    |      69    |   75766 K  |   75766 K  |
|       from small pool |      45    |      57    |  238841 K  |  238841 K  |
|===========================================================================|

2023-01-09 01:29:26 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-09 01:29:26 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-09 01:33:09 - train.py[line:549] - INFO: 200 / 6234
2023-01-09 01:33:09 - train.py[line:551] - INFO: load:1.10 valid_run:254.37 task_valid:249.87 collect_output:0.71
2023-01-09 01:37:18 - train.py[line:549] - INFO: 400 / 6234
2023-01-09 01:37:18 - train.py[line:551] - INFO: load:1.13 valid_run:503.19 task_valid:495.42 collect_output:1.41
2023-01-09 01:41:27 - train.py[line:549] - INFO: 600 / 6234
2023-01-09 01:41:27 - train.py[line:551] - INFO: load:1.15 valid_run:752.92 task_valid:741.94 collect_output:2.10
2023-01-09 01:45:33 - train.py[line:549] - INFO: 800 / 6234
2023-01-09 01:45:33 - train.py[line:551] - INFO: load:1.18 valid_run:998.73 task_valid:984.58 collect_output:2.76
2023-01-09 01:49:45 - train.py[line:549] - INFO: 1000 / 6234
2023-01-09 01:49:45 - train.py[line:551] - INFO: load:1.20 valid_run:1249.84 task_valid:1232.49 collect_output:3.43
2023-01-09 01:53:58 - train.py[line:549] - INFO: 1200 / 6234
2023-01-09 01:53:58 - train.py[line:551] - INFO: load:1.22 valid_run:1503.05 task_valid:1482.49 collect_output:4.10
2023-01-09 01:58:10 - train.py[line:549] - INFO: 1400 / 6234
2023-01-09 01:58:10 - train.py[line:551] - INFO: load:1.25 valid_run:1755.07 task_valid:1731.29 collect_output:4.76
2023-01-09 02:02:20 - train.py[line:549] - INFO: 1600 / 6234
2023-01-09 02:02:20 - train.py[line:551] - INFO: load:1.27 valid_run:2004.91 task_valid:1977.88 collect_output:5.44
2023-01-09 02:06:31 - train.py[line:549] - INFO: 1800 / 6234
2023-01-09 02:06:31 - train.py[line:551] - INFO: load:1.30 valid_run:2255.80 task_valid:2225.57 collect_output:6.11
2023-01-09 02:10:35 - train.py[line:549] - INFO: 2000 / 6234
2023-01-09 02:10:35 - train.py[line:551] - INFO: load:1.32 valid_run:2500.19 task_valid:2466.76 collect_output:6.78
2023-01-09 02:14:44 - train.py[line:549] - INFO: 2200 / 6234
2023-01-09 02:14:44 - train.py[line:551] - INFO: load:1.34 valid_run:2749.05 task_valid:2712.39 collect_output:7.46
2023-01-09 02:18:55 - train.py[line:549] - INFO: 2400 / 6234
2023-01-09 02:18:55 - train.py[line:551] - INFO: load:1.37 valid_run:2999.72 task_valid:2959.83 collect_output:8.13
2023-01-09 02:23:01 - train.py[line:549] - INFO: 2600 / 6234
2023-01-09 02:23:01 - train.py[line:551] - INFO: load:1.39 valid_run:3245.45 task_valid:3202.34 collect_output:8.81
2023-01-09 02:27:12 - train.py[line:549] - INFO: 2800 / 6234
2023-01-09 02:27:12 - train.py[line:551] - INFO: load:1.42 valid_run:3496.91 task_valid:3450.57 collect_output:9.48
2023-01-09 02:31:22 - train.py[line:549] - INFO: 3000 / 6234
2023-01-09 02:31:22 - train.py[line:551] - INFO: load:1.44 valid_run:3746.27 task_valid:3696.72 collect_output:10.15
2023-01-09 02:35:28 - train.py[line:549] - INFO: 3200 / 6234
2023-01-09 02:35:28 - train.py[line:551] - INFO: load:1.47 valid_run:3991.93 task_valid:3939.18 collect_output:10.80
2023-01-09 02:39:37 - train.py[line:549] - INFO: 3400 / 6234
2023-01-09 02:39:37 - train.py[line:551] - INFO: load:1.49 valid_run:4241.04 task_valid:4185.06 collect_output:11.47
2023-01-09 02:43:49 - train.py[line:549] - INFO: 3600 / 6234
2023-01-09 02:43:49 - train.py[line:551] - INFO: load:1.52 valid_run:4492.92 task_valid:4433.68 collect_output:12.15
2023-01-09 02:47:59 - train.py[line:549] - INFO: 3800 / 6234
2023-01-09 02:47:59 - train.py[line:551] - INFO: load:1.55 valid_run:4743.09 task_valid:4680.62 collect_output:12.83
2023-01-09 02:52:09 - train.py[line:549] - INFO: 4000 / 6234
2023-01-09 02:52:09 - train.py[line:551] - INFO: load:1.57 valid_run:4992.86 task_valid:4927.20 collect_output:13.49
2023-01-09 02:56:18 - train.py[line:549] - INFO: 4200 / 6234
2023-01-09 02:56:18 - train.py[line:551] - INFO: load:1.60 valid_run:5242.43 task_valid:5173.55 collect_output:14.16
2023-01-09 03:00:32 - train.py[line:549] - INFO: 4400 / 6234
2023-01-09 03:00:32 - train.py[line:551] - INFO: load:1.62 valid_run:5495.42 task_valid:5423.34 collect_output:14.81
2023-01-09 03:04:38 - train.py[line:549] - INFO: 4600 / 6234
2023-01-09 03:04:38 - train.py[line:551] - INFO: load:1.64 valid_run:5742.12 task_valid:5666.86 collect_output:15.45
2023-01-09 03:08:48 - train.py[line:549] - INFO: 4800 / 6234
2023-01-09 03:08:48 - train.py[line:551] - INFO: load:1.67 valid_run:5991.52 task_valid:5913.00 collect_output:16.13
2023-01-09 03:12:57 - train.py[line:549] - INFO: 5000 / 6234
2023-01-09 03:12:57 - train.py[line:551] - INFO: load:1.70 valid_run:6240.41 task_valid:6158.67 collect_output:16.79
2023-01-09 03:17:06 - train.py[line:549] - INFO: 5200 / 6234
2023-01-09 03:17:06 - train.py[line:551] - INFO: load:1.72 valid_run:6489.08 task_valid:6404.12 collect_output:17.45
2023-01-09 03:21:12 - train.py[line:549] - INFO: 5400 / 6234
2023-01-09 03:21:12 - train.py[line:551] - INFO: load:1.75 valid_run:6735.16 task_valid:6647.00 collect_output:18.11
2023-01-09 03:25:26 - train.py[line:549] - INFO: 5600 / 6234
2023-01-09 03:25:26 - train.py[line:551] - INFO: load:1.77 valid_run:6988.91 task_valid:6897.52 collect_output:18.77
2023-01-09 03:29:34 - train.py[line:549] - INFO: 5800 / 6234
2023-01-09 03:29:34 - train.py[line:551] - INFO: load:1.80 valid_run:7237.22 task_valid:7142.60 collect_output:19.43
2023-01-09 03:33:46 - train.py[line:549] - INFO: 6000 / 6234
2023-01-09 03:33:46 - train.py[line:551] - INFO: load:1.82 valid_run:7489.46 task_valid:7391.60 collect_output:20.11
2023-01-09 03:37:59 - train.py[line:549] - INFO: 6200 / 6234
2023-01-09 03:37:59 - train.py[line:551] - INFO: load:1.85 valid_run:7741.79 task_valid:7640.70 collect_output:20.79

====================================================================================================
SGG eval:     R @ 50: 0.4208;     R @ 100: 0.5175;     R @ 500: 0.5718;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2540;    mR @ 100: 0.3338;    mR @ 500: 0.3806;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6780) (covered in:0.6875) (covering:0.3714) (eating:0.5882) (flying in:0.0000) (growing on:0.0000) (hanging from:0.4677) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9524) (playing:0.0000) (riding:0.6520) (says:0.0000) (sitting on:0.6667) (standing on:0.1700) (using:0.6500) (walking in:0.0000) (walking on:0.4865) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-01-09 03:38:52 - train.py[line:487] - INFO: 0.5174761904761905

====================================================================================================
SGG eval:     R @ 50: 0.4208;     R @ 100: 0.5175;     R @ 500: 0.5718;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2540;    mR @ 100: 0.3338;    mR @ 500: 0.3806;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6780) (covered in:0.6875) (covering:0.3714) (eating:0.5882) (flying in:0.0000) (growing on:0.0000) (hanging from:0.4677) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9524) (playing:0.0000) (riding:0.6520) (says:0.0000) (sitting on:0.6667) (standing on:0.1700) (using:0.6500) (walking in:0.0000) (walking on:0.4865) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-01-09 03:38:52 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-09 03:38:52 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.385 | loss_v1 0 | loss_v2 0 | nll_loss 0.234 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.517476 | ppl 1.18 | vqa_score 0.4955 | wps 57.5 | wpb 72 | bsz 24 | num_updates 16000 | best_R@100 0.632103
2023-01-09 03:38:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 16000 updates
2023-01-09 03:38:52 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_16000.pt
2023-01-09 03:39:36 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_16000.pt
2023-01-09 03:41:03 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_16000.pt (epoch 1 @ 16000 updates, score 0.5174761904761905) (writing took 131.21002121455967 seconds)
2023-01-09 03:41:32 - progress_bar.py[line:274] - INFO: epoch 001:  16033 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4586, wps=0.2, ups=0, wpb=88.4, bsz=32, num_updates=16010, lr=4.59418e-05, gnorm=0.408, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=103307
2023-01-09 03:42:01 - progress_bar.py[line:274] - INFO: epoch 001:  16043 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4601, wps=59.4, ups=0.34, wpb=86.4, bsz=32, num_updates=16020, lr=4.59382e-05, gnorm=0.378, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=103336
2023-01-09 03:42:30 - progress_bar.py[line:274] - INFO: epoch 001:  16053 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3481, wps=61.2, ups=0.35, wpb=87.7, bsz=32, num_updates=16030, lr=4.59347e-05, gnorm=0.5, clip=20, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=103365
2023-01-09 03:42:59 - progress_bar.py[line:274] - INFO: epoch 001:  16063 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.411, wps=60.8, ups=0.35, wpb=87.3, bsz=32, num_updates=16040, lr=4.59311e-05, gnorm=0.453, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=103394
2023-01-09 03:43:27 - progress_bar.py[line:274] - INFO: epoch 001:  16073 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4379, wps=63.1, ups=0.36, wpb=87.2, bsz=32, num_updates=16050, lr=4.59275e-05, gnorm=0.517, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=103422
2023-01-09 03:43:56 - progress_bar.py[line:274] - INFO: epoch 001:  16083 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=62.1, ups=0.35, wpb=88, bsz=32, num_updates=16060, lr=4.5924e-05, gnorm=0.305, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=103451
2023-01-09 03:44:25 - progress_bar.py[line:274] - INFO: epoch 001:  16093 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4581, wps=60.4, ups=0.34, wpb=87.9, bsz=32, num_updates=16070, lr=4.59204e-05, gnorm=0.642, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=103480
2023-01-09 03:44:54 - progress_bar.py[line:274] - INFO: epoch 001:  16103 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4444, wps=62.4, ups=0.35, wpb=88, bsz=32, num_updates=16080, lr=4.59168e-05, gnorm=0.523, clip=10, loss_scale=512, train_wall=28, gb_free=15.6, ema_decay=0.9999, wall=103509
2023-01-09 03:45:23 - progress_bar.py[line:274] - INFO: epoch 001:  16113 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4375, wps=60.5, ups=0.35, wpb=87.4, bsz=32, num_updates=16090, lr=4.59133e-05, gnorm=0.363, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=103538
2023-01-09 03:45:52 - progress_bar.py[line:274] - INFO: epoch 001:  16123 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3826, wps=61.5, ups=0.35, wpb=88.3, bsz=32, num_updates=16100, lr=4.59097e-05, gnorm=0.255, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=103567
2023-01-09 03:46:21 - progress_bar.py[line:274] - INFO: epoch 001:  16133 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4521, wps=61.3, ups=0.35, wpb=87.9, bsz=32, num_updates=16110, lr=4.59061e-05, gnorm=0.373, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=103596
2023-01-09 03:46:49 - progress_bar.py[line:274] - INFO: epoch 001:  16143 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4013, wps=61.6, ups=0.35, wpb=87.8, bsz=32, num_updates=16120, lr=4.59026e-05, gnorm=0.264, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=103624
2023-01-09 03:47:18 - progress_bar.py[line:274] - INFO: epoch 001:  16153 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4568, wps=60.1, ups=0.35, wpb=86.7, bsz=32, num_updates=16130, lr=4.5899e-05, gnorm=0.361, clip=10, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=103653
2023-01-09 03:47:47 - progress_bar.py[line:274] - INFO: epoch 001:  16163 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4088, wps=61.7, ups=0.35, wpb=87.6, bsz=32, num_updates=16140, lr=4.58954e-05, gnorm=0.483, clip=10, loss_scale=512, train_wall=28, gb_free=15, ema_decay=0.9999, wall=103682
2023-01-09 03:48:16 - progress_bar.py[line:274] - INFO: epoch 001:  16173 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.404, wps=60.8, ups=0.35, wpb=87.2, bsz=32, num_updates=16150, lr=4.58919e-05, gnorm=0.52, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=103711
2023-01-09 03:48:45 - progress_bar.py[line:274] - INFO: epoch 001:  16183 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4224, wps=60.1, ups=0.35, wpb=87.1, bsz=32, num_updates=16160, lr=4.58883e-05, gnorm=0.383, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=103740
2023-01-09 03:49:15 - progress_bar.py[line:274] - INFO: epoch 001:  16193 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4329, wps=60, ups=0.34, wpb=88.1, bsz=32, num_updates=16170, lr=4.58847e-05, gnorm=0.393, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=103770
2023-01-09 03:49:44 - progress_bar.py[line:274] - INFO: epoch 001:  16203 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4675, wps=59.8, ups=0.35, wpb=86.5, bsz=32, num_updates=16180, lr=4.58812e-05, gnorm=0.431, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=103799
2023-01-09 03:50:13 - progress_bar.py[line:274] - INFO: epoch 001:  16213 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4416, wps=59.8, ups=0.34, wpb=87.4, bsz=32, num_updates=16190, lr=4.58776e-05, gnorm=0.569, clip=20, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=103828
2023-01-09 03:50:22 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 03:50:45 - progress_bar.py[line:274] - INFO: epoch 001:  16224 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.381, nsentences=32, sample_size=86.381, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.467, wps=58.2, ups=0.32, wpb=86.4, bsz=32, num_updates=16200, lr=4.5874e-05, gnorm=0.496, clip=0, loss_scale=256, train_wall=31, gb_free=15.1, ema_decay=0.9999, wall=103860
2023-01-09 03:51:14 - progress_bar.py[line:274] - INFO: epoch 001:  16234 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3947, wps=61.3, ups=0.35, wpb=87.8, bsz=32, num_updates=16210, lr=4.58705e-05, gnorm=0.443, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=103889
2023-01-09 03:51:42 - progress_bar.py[line:274] - INFO: epoch 001:  16244 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4395, wps=60.9, ups=0.35, wpb=87.1, bsz=32, num_updates=16220, lr=4.58669e-05, gnorm=0.463, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=103918
2023-01-09 03:52:11 - progress_bar.py[line:274] - INFO: epoch 001:  16254 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5385, wps=60.4, ups=0.35, wpb=86.7, bsz=32, num_updates=16230, lr=4.58633e-05, gnorm=0.55, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=103946
2023-01-09 03:52:41 - progress_bar.py[line:274] - INFO: epoch 001:  16264 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4465, wps=59.7, ups=0.34, wpb=87.1, bsz=32, num_updates=16240, lr=4.58598e-05, gnorm=0.311, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=103976
2023-01-09 03:53:10 - progress_bar.py[line:274] - INFO: epoch 001:  16274 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4072, wps=59.9, ups=0.34, wpb=87.2, bsz=32, num_updates=16250, lr=4.58562e-05, gnorm=0.415, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=104005
2023-01-09 03:53:39 - progress_bar.py[line:274] - INFO: epoch 001:  16284 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=62.7, ups=0.36, wpb=88.2, bsz=32, num_updates=16260, lr=4.58526e-05, gnorm=0.341, clip=0, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=104034
2023-01-09 03:54:07 - progress_bar.py[line:274] - INFO: epoch 001:  16294 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3926, wps=60.7, ups=0.35, wpb=87.1, bsz=32, num_updates=16270, lr=4.58491e-05, gnorm=0.467, clip=10, loss_scale=256, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=104063
2023-01-09 03:54:36 - progress_bar.py[line:274] - INFO: epoch 001:  16304 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.471, wps=61, ups=0.35, wpb=87.1, bsz=32, num_updates=16280, lr=4.58455e-05, gnorm=0.394, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=104091
2023-01-09 03:55:05 - progress_bar.py[line:274] - INFO: epoch 001:  16314 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4, wps=61.1, ups=0.35, wpb=87.9, bsz=32, num_updates=16290, lr=4.58419e-05, gnorm=0.427, clip=0, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=104120
2023-01-09 03:55:34 - progress_bar.py[line:274] - INFO: epoch 001:  16324 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4114, wps=61, ups=0.35, wpb=86.5, bsz=32, num_updates=16300, lr=4.58384e-05, gnorm=0.324, clip=0, loss_scale=256, train_wall=28, gb_free=14.9, ema_decay=0.9999, wall=104149
2023-01-09 03:56:03 - progress_bar.py[line:274] - INFO: epoch 001:  16334 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4057, wps=60.2, ups=0.35, wpb=86.2, bsz=32, num_updates=16310, lr=4.58348e-05, gnorm=0.411, clip=10, loss_scale=256, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=104178
2023-01-09 03:56:31 - progress_bar.py[line:274] - INFO: epoch 001:  16344 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4534, wps=61, ups=0.35, wpb=87.1, bsz=32, num_updates=16320, lr=4.58312e-05, gnorm=0.316, clip=0, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=104207
2023-01-09 03:57:00 - progress_bar.py[line:274] - INFO: epoch 001:  16354 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4091, wps=61, ups=0.35, wpb=86.3, bsz=32, num_updates=16330, lr=4.58277e-05, gnorm=0.493, clip=10, loss_scale=256, train_wall=28, gb_free=15, ema_decay=0.9999, wall=104235
2023-01-09 03:57:29 - progress_bar.py[line:274] - INFO: epoch 001:  16364 / 144806 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=85.7, nsentences=32, sample_size=85.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3905, wps=59.1, ups=0.34, wpb=85.7, bsz=32, num_updates=16340, lr=4.58241e-05, gnorm=0.348, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=104264
2023-01-09 03:57:58 - progress_bar.py[line:274] - INFO: epoch 001:  16374 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4636, wps=61.3, ups=0.35, wpb=88.3, bsz=32, num_updates=16350, lr=4.58205e-05, gnorm=0.342, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=104293
2023-01-09 03:58:27 - progress_bar.py[line:274] - INFO: epoch 001:  16384 / 144806 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3963, wps=59.9, ups=0.35, wpb=86.2, bsz=32, num_updates=16360, lr=4.5817e-05, gnorm=0.592, clip=10, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=104322
2023-01-09 03:58:57 - progress_bar.py[line:274] - INFO: epoch 001:  16394 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5159, wps=60, ups=0.34, wpb=87.1, bsz=32, num_updates=16370, lr=4.58134e-05, gnorm=0.381, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=104352
2023-01-09 03:59:26 - progress_bar.py[line:274] - INFO: epoch 001:  16404 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.5, wps=59.3, ups=0.34, wpb=86.9, bsz=32, num_updates=16380, lr=4.58098e-05, gnorm=0.313, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=104381
2023-01-09 03:59:55 - progress_bar.py[line:274] - INFO: epoch 001:  16414 / 144806 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4294, wps=60.6, ups=0.35, wpb=86.1, bsz=32, num_updates=16390, lr=4.58063e-05, gnorm=0.367, clip=0, loss_scale=256, train_wall=28, gb_free=15.6, ema_decay=0.9999, wall=104410
2023-01-09 04:00:24 - progress_bar.py[line:274] - INFO: epoch 001:  16424 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4452, wps=60.1, ups=0.34, wpb=87.8, bsz=32, num_updates=16400, lr=4.58027e-05, gnorm=0.296, clip=0, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=104439
2023-01-09 04:00:30 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-01-09 04:00:56 - progress_bar.py[line:274] - INFO: epoch 001:  16435 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.619, nsentences=32, sample_size=86.619, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4194, wps=58, ups=0.32, wpb=86.6, bsz=32, num_updates=16410, lr=4.57991e-05, gnorm=0.308, clip=0, loss_scale=128, train_wall=31, gb_free=15.3, ema_decay=0.9999, wall=104471
2023-01-09 04:01:25 - progress_bar.py[line:274] - INFO: epoch 001:  16445 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4056, wps=60.8, ups=0.34, wpb=88.3, bsz=32, num_updates=16420, lr=4.57956e-05, gnorm=0.322, clip=0, loss_scale=128, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=104500
2023-01-09 04:01:53 - progress_bar.py[line:274] - INFO: epoch 001:  16455 / 144806 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=89, nsentences=32, sample_size=89, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4857, wps=63.1, ups=0.35, wpb=89, bsz=32, num_updates=16430, lr=4.5792e-05, gnorm=0.395, clip=0, loss_scale=128, train_wall=28, gb_free=15.5, ema_decay=0.9999, wall=104529
2023-01-09 04:02:23 - progress_bar.py[line:274] - INFO: epoch 001:  16465 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3718, wps=60.5, ups=0.35, wpb=87.6, bsz=32, num_updates=16440, lr=4.57884e-05, gnorm=0.253, clip=0, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=104558
2023-01-09 04:02:51 - progress_bar.py[line:274] - INFO: epoch 001:  16475 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4126, wps=62, ups=0.35, wpb=88.3, bsz=32, num_updates=16450, lr=4.57849e-05, gnorm=0.331, clip=0, loss_scale=128, train_wall=28, gb_free=14.7, ema_decay=0.9999, wall=104586
2023-01-09 04:03:21 - progress_bar.py[line:274] - INFO: epoch 001:  16485 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3585, wps=60, ups=0.34, wpb=88.1, bsz=32, num_updates=16460, lr=4.57813e-05, gnorm=0.348, clip=0, loss_scale=128, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=104616
2023-01-09 04:03:50 - progress_bar.py[line:274] - INFO: epoch 001:  16495 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4122, wps=60.5, ups=0.35, wpb=87.4, bsz=32, num_updates=16470, lr=4.57777e-05, gnorm=0.271, clip=0, loss_scale=128, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=104645
2023-01-09 04:04:19 - progress_bar.py[line:274] - INFO: epoch 001:  16505 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4122, wps=61.7, ups=0.35, wpb=87.9, bsz=32, num_updates=16480, lr=4.57742e-05, gnorm=0.385, clip=0, loss_scale=128, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=104674
2023-01-09 04:04:48 - progress_bar.py[line:274] - INFO: epoch 001:  16515 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.404, wps=60.4, ups=0.34, wpb=87.6, bsz=32, num_updates=16490, lr=4.57706e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=104703
2023-01-09 04:05:17 - progress_bar.py[line:274] - INFO: epoch 001:  16525 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4176, wps=60.3, ups=0.34, wpb=87.8, bsz=32, num_updates=16500, lr=4.5767e-05, gnorm=0.535, clip=10, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=104733
2023-01-09 04:05:46 - progress_bar.py[line:274] - INFO: epoch 001:  16535 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4122, wps=61.3, ups=0.35, wpb=87.2, bsz=32, num_updates=16510, lr=4.57634e-05, gnorm=0.368, clip=10, loss_scale=128, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=104761
2023-01-09 04:06:15 - progress_bar.py[line:274] - INFO: epoch 001:  16545 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=85.2, nsentences=32, sample_size=85.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3964, wps=59.3, ups=0.35, wpb=85.2, bsz=32, num_updates=16520, lr=4.57599e-05, gnorm=0.301, clip=0, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=104790
2023-01-09 04:06:43 - progress_bar.py[line:274] - INFO: epoch 001:  16555 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4655, wps=62.3, ups=0.36, wpb=86.8, bsz=32, num_updates=16530, lr=4.57563e-05, gnorm=0.511, clip=0, loss_scale=128, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=104818
2023-01-09 04:07:13 - progress_bar.py[line:274] - INFO: epoch 001:  16565 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4321, wps=59.5, ups=0.34, wpb=87.3, bsz=32, num_updates=16540, lr=4.57527e-05, gnorm=0.871, clip=20, loss_scale=128, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=104848
2023-01-09 04:07:41 - progress_bar.py[line:274] - INFO: epoch 001:  16575 / 144806 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4306, wps=62.5, ups=0.35, wpb=88.4, bsz=32, num_updates=16550, lr=4.57492e-05, gnorm=0.373, clip=0, loss_scale=128, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=104876
2023-01-09 04:08:10 - progress_bar.py[line:274] - INFO: epoch 001:  16585 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3427, wps=59.9, ups=0.35, wpb=86.2, bsz=32, num_updates=16560, lr=4.57456e-05, gnorm=0.401, clip=0, loss_scale=128, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=104905
2023-01-09 04:08:39 - progress_bar.py[line:274] - INFO: epoch 001:  16595 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3933, wps=61.6, ups=0.35, wpb=87.5, bsz=32, num_updates=16570, lr=4.5742e-05, gnorm=0.366, clip=0, loss_scale=128, train_wall=28, gb_free=14.6, ema_decay=0.9999, wall=104934
2023-01-09 04:09:08 - progress_bar.py[line:274] - INFO: epoch 001:  16605 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4759, wps=62.1, ups=0.35, wpb=88.6, bsz=32, num_updates=16580, lr=4.57385e-05, gnorm=0.51, clip=10, loss_scale=128, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=104963
2023-01-09 04:09:37 - progress_bar.py[line:274] - INFO: epoch 001:  16615 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4398, wps=60.6, ups=0.35, wpb=86.4, bsz=32, num_updates=16590, lr=4.57349e-05, gnorm=0.279, clip=0, loss_scale=128, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=104992
2023-01-09 04:10:06 - progress_bar.py[line:274] - INFO: epoch 001:  16625 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4459, wps=60.4, ups=0.35, wpb=86.9, bsz=32, num_updates=16600, lr=4.57313e-05, gnorm=0.428, clip=0, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=105021
2023-01-09 04:10:35 - progress_bar.py[line:274] - INFO: epoch 001:  16635 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.472, wps=60.4, ups=0.35, wpb=87.3, bsz=32, num_updates=16610, lr=4.57278e-05, gnorm=0.356, clip=0, loss_scale=128, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=105050
2023-01-09 04:11:04 - progress_bar.py[line:274] - INFO: epoch 001:  16645 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.465, wps=59.6, ups=0.35, wpb=86.4, bsz=32, num_updates=16620, lr=4.57242e-05, gnorm=0.289, clip=0, loss_scale=128, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=105079
2023-01-09 04:11:33 - progress_bar.py[line:274] - INFO: epoch 001:  16655 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4012, wps=60.3, ups=0.35, wpb=86.7, bsz=32, num_updates=16630, lr=4.57206e-05, gnorm=0.268, clip=0, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=105108
2023-01-09 04:12:02 - progress_bar.py[line:274] - INFO: epoch 001:  16665 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4177, wps=60.7, ups=0.35, wpb=87.7, bsz=32, num_updates=16640, lr=4.57171e-05, gnorm=0.825, clip=10, loss_scale=128, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=105137
2023-01-09 04:12:31 - progress_bar.py[line:274] - INFO: epoch 001:  16675 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4771, wps=60.8, ups=0.35, wpb=87.6, bsz=32, num_updates=16650, lr=4.57135e-05, gnorm=0.209, clip=0, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=105166
2023-01-09 04:13:00 - progress_bar.py[line:274] - INFO: epoch 001:  16685 / 144806 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3636, wps=59.8, ups=0.35, wpb=86, bsz=32, num_updates=16660, lr=4.57099e-05, gnorm=0.866, clip=40, loss_scale=128, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=105195
2023-01-09 04:13:29 - progress_bar.py[line:274] - INFO: epoch 001:  16695 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4302, wps=59.2, ups=0.34, wpb=86, bsz=32, num_updates=16670, lr=4.57064e-05, gnorm=0.368, clip=0, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=105224
2023-01-09 04:13:58 - progress_bar.py[line:274] - INFO: epoch 001:  16705 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4286, wps=61.4, ups=0.36, wpb=86, bsz=32, num_updates=16680, lr=4.57028e-05, gnorm=0.327, clip=0, loss_scale=128, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=105253
2023-01-09 04:14:26 - progress_bar.py[line:274] - INFO: epoch 001:  16715 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4969, wps=61.6, ups=0.35, wpb=87.9, bsz=32, num_updates=16690, lr=4.56992e-05, gnorm=0.429, clip=10, loss_scale=128, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=105281
2023-01-09 04:14:55 - progress_bar.py[line:274] - INFO: epoch 001:  16725 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4522, wps=60.9, ups=0.35, wpb=87.7, bsz=32, num_updates=16700, lr=4.56957e-05, gnorm=0.428, clip=10, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=105310
2023-01-09 04:15:25 - progress_bar.py[line:274] - INFO: epoch 001:  16735 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4967, wps=60.2, ups=0.35, wpb=87, bsz=32, num_updates=16710, lr=4.56921e-05, gnorm=0.292, clip=0, loss_scale=128, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=105340
2023-01-09 04:15:53 - progress_bar.py[line:274] - INFO: epoch 001:  16745 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4167, wps=61.4, ups=0.35, wpb=87.5, bsz=32, num_updates=16720, lr=4.56885e-05, gnorm=0.286, clip=0, loss_scale=128, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=105368
2023-01-09 04:16:22 - progress_bar.py[line:274] - INFO: epoch 001:  16755 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4777, wps=59.7, ups=0.35, wpb=86, bsz=32, num_updates=16730, lr=4.5685e-05, gnorm=0.369, clip=0, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=105397
2023-01-09 04:16:52 - progress_bar.py[line:274] - INFO: epoch 001:  16765 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4353, wps=59, ups=0.34, wpb=85.8, bsz=32, num_updates=16740, lr=4.56814e-05, gnorm=0.375, clip=0, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=105427
2023-01-09 04:17:21 - progress_bar.py[line:274] - INFO: epoch 001:  16775 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4062, wps=61.2, ups=0.35, wpb=87.6, bsz=32, num_updates=16750, lr=4.56778e-05, gnorm=0.437, clip=0, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=105456
2023-01-09 04:17:50 - progress_bar.py[line:274] - INFO: epoch 001:  16785 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4118, wps=61.1, ups=0.35, wpb=88.3, bsz=32, num_updates=16760, lr=4.56743e-05, gnorm=1.165, clip=10, loss_scale=128, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=105485
2023-01-09 04:18:19 - progress_bar.py[line:274] - INFO: epoch 001:  16795 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4699, wps=60, ups=0.35, wpb=86.5, bsz=32, num_updates=16770, lr=4.56707e-05, gnorm=0.296, clip=0, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=105514
2023-01-09 04:18:48 - progress_bar.py[line:274] - INFO: epoch 001:  16805 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4181, wps=60.3, ups=0.35, wpb=86.4, bsz=32, num_updates=16780, lr=4.56671e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=105543
2023-01-09 04:19:17 - progress_bar.py[line:274] - INFO: epoch 001:  16815 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4494, wps=60.6, ups=0.35, wpb=86.9, bsz=32, num_updates=16790, lr=4.56636e-05, gnorm=0.36, clip=0, loss_scale=128, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=105572
2023-01-09 04:19:46 - progress_bar.py[line:274] - INFO: epoch 001:  16825 / 144806 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4262, wps=60, ups=0.35, wpb=86.3, bsz=32, num_updates=16800, lr=4.566e-05, gnorm=0.538, clip=20, loss_scale=128, train_wall=29, gb_free=15, ema_decay=0.9999, wall=105601
2023-01-09 04:20:14 - progress_bar.py[line:274] - INFO: epoch 001:  16835 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.465, wps=61, ups=0.35, wpb=87.4, bsz=32, num_updates=16810, lr=4.56564e-05, gnorm=0.349, clip=0, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=105630
2023-01-09 04:20:44 - progress_bar.py[line:274] - INFO: epoch 001:  16845 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3871, wps=60.3, ups=0.35, wpb=87.3, bsz=32, num_updates=16820, lr=4.56529e-05, gnorm=0.353, clip=0, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=105659
2023-01-09 04:21:13 - progress_bar.py[line:274] - INFO: epoch 001:  16855 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4099, wps=60.7, ups=0.35, wpb=87.1, bsz=32, num_updates=16830, lr=4.56493e-05, gnorm=0.323, clip=0, loss_scale=128, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=105688
2023-01-09 04:21:42 - progress_bar.py[line:274] - INFO: epoch 001:  16865 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4024, wps=59.9, ups=0.35, wpb=86.1, bsz=32, num_updates=16840, lr=4.56457e-05, gnorm=0.355, clip=0, loss_scale=128, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=105717
2023-01-09 04:22:11 - progress_bar.py[line:274] - INFO: epoch 001:  16875 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4295, wps=60.9, ups=0.35, wpb=88.1, bsz=32, num_updates=16850, lr=4.56422e-05, gnorm=0.305, clip=0, loss_scale=128, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=105746
2023-01-09 04:22:40 - progress_bar.py[line:274] - INFO: epoch 001:  16885 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4583, wps=61, ups=0.35, wpb=88.2, bsz=32, num_updates=16860, lr=4.56386e-05, gnorm=0.351, clip=0, loss_scale=128, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=105775
2023-01-09 04:23:08 - progress_bar.py[line:274] - INFO: epoch 001:  16895 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.451, wps=61.5, ups=0.35, wpb=87.4, bsz=32, num_updates=16870, lr=4.5635e-05, gnorm=0.424, clip=0, loss_scale=128, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=105804
2023-01-09 04:23:37 - progress_bar.py[line:274] - INFO: epoch 001:  16905 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4452, wps=62, ups=0.35, wpb=88.2, bsz=32, num_updates=16880, lr=4.56315e-05, gnorm=0.265, clip=0, loss_scale=128, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=105832
2023-01-09 04:24:06 - progress_bar.py[line:274] - INFO: epoch 001:  16915 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4218, wps=61.8, ups=0.35, wpb=87.9, bsz=32, num_updates=16890, lr=4.56279e-05, gnorm=0.492, clip=20, loss_scale=128, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=105861
2023-01-09 04:24:35 - progress_bar.py[line:274] - INFO: epoch 001:  16925 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4774, wps=59.8, ups=0.34, wpb=87.4, bsz=32, num_updates=16900, lr=4.56243e-05, gnorm=0.365, clip=0, loss_scale=128, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=105890
2023-01-09 04:25:04 - progress_bar.py[line:274] - INFO: epoch 001:  16935 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4321, wps=61.3, ups=0.35, wpb=88.2, bsz=32, num_updates=16910, lr=4.56208e-05, gnorm=0.662, clip=30, loss_scale=128, train_wall=29, gb_free=14.7, ema_decay=0.9999, wall=105919
2023-01-09 04:25:33 - progress_bar.py[line:274] - INFO: epoch 001:  16945 / 144806 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4491, wps=60.7, ups=0.35, wpb=86.4, bsz=32, num_updates=16920, lr=4.56172e-05, gnorm=0.494, clip=20, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=105948
2023-01-09 04:26:02 - progress_bar.py[line:274] - INFO: epoch 001:  16955 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4663, wps=60.5, ups=0.35, wpb=86.9, bsz=32, num_updates=16930, lr=4.56136e-05, gnorm=1.089, clip=10, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=105977
2023-01-09 04:26:30 - progress_bar.py[line:274] - INFO: epoch 001:  16965 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4971, wps=61.9, ups=0.36, wpb=86.7, bsz=32, num_updates=16940, lr=4.56101e-05, gnorm=0.342, clip=0, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=106005
2023-01-09 04:26:59 - progress_bar.py[line:274] - INFO: epoch 001:  16975 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4667, wps=61.6, ups=0.36, wpb=86.6, bsz=32, num_updates=16950, lr=4.56065e-05, gnorm=0.336, clip=0, loss_scale=256, train_wall=28, gb_free=15.6, ema_decay=0.9999, wall=106034
2023-01-09 04:27:28 - progress_bar.py[line:274] - INFO: epoch 001:  16985 / 144806 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4899, wps=61.2, ups=0.35, wpb=88.3, bsz=32, num_updates=16960, lr=4.56029e-05, gnorm=0.439, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=106063
2023-01-09 04:27:57 - progress_bar.py[line:274] - INFO: epoch 001:  16995 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4096, wps=61, ups=0.35, wpb=87.7, bsz=32, num_updates=16970, lr=4.55994e-05, gnorm=0.348, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=106092
2023-01-09 04:28:26 - progress_bar.py[line:274] - INFO: epoch 001:  17005 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3919, wps=60.3, ups=0.34, wpb=87.4, bsz=32, num_updates=16980, lr=4.55958e-05, gnorm=0.303, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=106121
2023-01-09 04:28:55 - progress_bar.py[line:274] - INFO: epoch 001:  17015 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4186, wps=61.4, ups=0.35, wpb=87.7, bsz=32, num_updates=16990, lr=4.55922e-05, gnorm=0.432, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=106150
2023-01-09 04:29:24 - progress_bar.py[line:274] - INFO: epoch 001:  17025 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3544, wps=60.4, ups=0.35, wpb=86.9, bsz=32, num_updates=17000, lr=4.55887e-05, gnorm=0.325, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=106179
2023-01-09 04:29:52 - progress_bar.py[line:274] - INFO: epoch 001:  17035 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.375, wps=61.9, ups=0.35, wpb=87.7, bsz=32, num_updates=17010, lr=4.55851e-05, gnorm=0.284, clip=0, loss_scale=256, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=106207
2023-01-09 04:30:21 - progress_bar.py[line:274] - INFO: epoch 001:  17045 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4321, wps=61.2, ups=0.35, wpb=86.6, bsz=32, num_updates=17020, lr=4.55815e-05, gnorm=0.435, clip=10, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=106236
2023-01-09 04:30:50 - progress_bar.py[line:274] - INFO: epoch 001:  17055 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4497, wps=60.1, ups=0.35, wpb=86.7, bsz=32, num_updates=17030, lr=4.5578e-05, gnorm=0.342, clip=0, loss_scale=256, train_wall=29, gb_free=15.6, ema_decay=0.9999, wall=106265
2023-01-09 04:31:19 - progress_bar.py[line:274] - INFO: epoch 001:  17065 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4506, wps=60.3, ups=0.35, wpb=87.2, bsz=32, num_updates=17040, lr=4.55744e-05, gnorm=0.384, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=106294
2023-01-09 04:31:48 - progress_bar.py[line:274] - INFO: epoch 001:  17075 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4899, wps=61.7, ups=0.35, wpb=88.7, bsz=32, num_updates=17050, lr=4.55708e-05, gnorm=0.31, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=106323
2023-01-09 04:32:17 - progress_bar.py[line:274] - INFO: epoch 001:  17085 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=90, nsentences=32, sample_size=90, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.443, wps=63.7, ups=0.35, wpb=90, bsz=32, num_updates=17060, lr=4.55673e-05, gnorm=0.317, clip=0, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=106352
2023-01-09 04:32:46 - progress_bar.py[line:274] - INFO: epoch 001:  17095 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4667, wps=59.9, ups=0.34, wpb=87.1, bsz=32, num_updates=17070, lr=4.55637e-05, gnorm=0.386, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=106381
2023-01-09 04:33:15 - progress_bar.py[line:274] - INFO: epoch 001:  17105 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4286, wps=61.4, ups=0.35, wpb=88.1, bsz=32, num_updates=17080, lr=4.55601e-05, gnorm=0.324, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=106410
2023-01-09 04:33:44 - progress_bar.py[line:274] - INFO: epoch 001:  17115 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4083, wps=60.4, ups=0.35, wpb=86.9, bsz=32, num_updates=17090, lr=4.55566e-05, gnorm=0.28, clip=0, loss_scale=256, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=106439
2023-01-09 04:34:13 - progress_bar.py[line:274] - INFO: epoch 001:  17125 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3734, wps=60.3, ups=0.34, wpb=87.7, bsz=32, num_updates=17100, lr=4.5553e-05, gnorm=0.472, clip=10, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=106468
2023-01-09 04:34:42 - progress_bar.py[line:274] - INFO: epoch 001:  17135 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.449, wps=62.4, ups=0.35, wpb=88.3, bsz=32, num_updates=17110, lr=4.55494e-05, gnorm=0.316, clip=0, loss_scale=256, train_wall=28, gb_free=15.5, ema_decay=0.9999, wall=106497
2023-01-09 04:35:11 - progress_bar.py[line:274] - INFO: epoch 001:  17145 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4351, wps=60, ups=0.34, wpb=87.6, bsz=32, num_updates=17120, lr=4.55459e-05, gnorm=0.334, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=106526
2023-01-09 04:35:40 - progress_bar.py[line:274] - INFO: epoch 001:  17155 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=89.2, nsentences=32, sample_size=89.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4503, wps=61.5, ups=0.34, wpb=89.2, bsz=32, num_updates=17130, lr=4.55423e-05, gnorm=0.323, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=106555
2023-01-09 04:36:09 - progress_bar.py[line:274] - INFO: epoch 001:  17165 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4151, wps=60.5, ups=0.35, wpb=87.6, bsz=32, num_updates=17140, lr=4.55387e-05, gnorm=0.373, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=106585
2023-01-09 04:36:38 - progress_bar.py[line:274] - INFO: epoch 001:  17175 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4189, wps=62, ups=0.35, wpb=88.5, bsz=32, num_updates=17150, lr=4.55352e-05, gnorm=0.308, clip=0, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=106613
2023-01-09 04:37:07 - progress_bar.py[line:274] - INFO: epoch 001:  17185 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3585, wps=61.4, ups=0.35, wpb=87.8, bsz=32, num_updates=17160, lr=4.55316e-05, gnorm=0.358, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=106642
2023-01-09 04:37:37 - progress_bar.py[line:274] - INFO: epoch 001:  17195 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4568, wps=59.2, ups=0.34, wpb=87.4, bsz=32, num_updates=17170, lr=4.5528e-05, gnorm=0.293, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=106672
2023-01-09 04:38:05 - progress_bar.py[line:274] - INFO: epoch 001:  17205 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4651, wps=60.4, ups=0.35, wpb=86.1, bsz=32, num_updates=17180, lr=4.55245e-05, gnorm=0.456, clip=10, loss_scale=256, train_wall=28, gb_free=14.9, ema_decay=0.9999, wall=106701
2023-01-09 04:38:35 - progress_bar.py[line:274] - INFO: epoch 001:  17215 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4192, wps=60, ups=0.34, wpb=87.3, bsz=32, num_updates=17190, lr=4.55209e-05, gnorm=0.37, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=106730
2023-01-09 04:39:04 - progress_bar.py[line:274] - INFO: epoch 001:  17225 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4509, wps=60.2, ups=0.34, wpb=87.5, bsz=32, num_updates=17200, lr=4.55173e-05, gnorm=0.322, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=106759
2023-01-09 04:39:32 - progress_bar.py[line:274] - INFO: epoch 001:  17235 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4702, wps=62.2, ups=0.36, wpb=87.5, bsz=32, num_updates=17210, lr=4.55138e-05, gnorm=0.488, clip=0, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=106788
2023-01-09 04:40:02 - progress_bar.py[line:274] - INFO: epoch 001:  17245 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4437, wps=60.3, ups=0.35, wpb=87.2, bsz=32, num_updates=17220, lr=4.55102e-05, gnorm=0.448, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=106817
2023-01-09 04:40:31 - progress_bar.py[line:274] - INFO: epoch 001:  17255 / 144806 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=85.6, nsentences=32, sample_size=85.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4201, wps=59.4, ups=0.35, wpb=85.6, bsz=32, num_updates=17230, lr=4.55066e-05, gnorm=0.351, clip=0, loss_scale=256, train_wall=29, gb_free=15, ema_decay=0.9999, wall=106846
2023-01-09 04:41:00 - progress_bar.py[line:274] - INFO: epoch 001:  17265 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4286, wps=59.9, ups=0.35, wpb=86.8, bsz=32, num_updates=17240, lr=4.55031e-05, gnorm=0.387, clip=10, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=106875
2023-01-09 04:41:29 - progress_bar.py[line:274] - INFO: epoch 001:  17275 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5031, wps=60, ups=0.35, wpb=86.7, bsz=32, num_updates=17250, lr=4.54995e-05, gnorm=0.275, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=106904
2023-01-09 04:41:58 - progress_bar.py[line:274] - INFO: epoch 001:  17285 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4083, wps=61.6, ups=0.35, wpb=87.2, bsz=32, num_updates=17260, lr=4.54959e-05, gnorm=0.412, clip=10, loss_scale=256, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=106933
2023-01-09 04:42:27 - progress_bar.py[line:274] - INFO: epoch 001:  17295 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4803, wps=60.5, ups=0.35, wpb=87.1, bsz=32, num_updates=17270, lr=4.54924e-05, gnorm=0.397, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=106962
2023-01-09 04:42:56 - progress_bar.py[line:274] - INFO: epoch 001:  17305 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4512, wps=59.1, ups=0.34, wpb=86.1, bsz=32, num_updates=17280, lr=4.54888e-05, gnorm=0.362, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=106991
2023-01-09 04:43:25 - progress_bar.py[line:274] - INFO: epoch 001:  17315 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4727, wps=61.7, ups=0.35, wpb=88.1, bsz=32, num_updates=17290, lr=4.54852e-05, gnorm=0.359, clip=10, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=107020
2023-01-09 04:43:54 - progress_bar.py[line:274] - INFO: epoch 001:  17325 / 144806 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4527, wps=60.3, ups=0.34, wpb=87.5, bsz=32, num_updates=17300, lr=4.54817e-05, gnorm=0.302, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=107049
2023-01-09 04:44:23 - progress_bar.py[line:274] - INFO: epoch 001:  17335 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4118, wps=58.9, ups=0.34, wpb=85.5, bsz=32, num_updates=17310, lr=4.54781e-05, gnorm=0.34, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=107078
2023-01-09 04:44:52 - progress_bar.py[line:274] - INFO: epoch 001:  17345 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4564, wps=62.1, ups=0.35, wpb=88, bsz=32, num_updates=17320, lr=4.54745e-05, gnorm=0.342, clip=0, loss_scale=256, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=107107
2023-01-09 04:45:21 - progress_bar.py[line:274] - INFO: epoch 001:  17355 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4277, wps=60, ups=0.35, wpb=85.9, bsz=32, num_updates=17330, lr=4.5471e-05, gnorm=0.391, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=107136
2023-01-09 04:45:50 - progress_bar.py[line:274] - INFO: epoch 001:  17365 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4286, wps=60.5, ups=0.35, wpb=87, bsz=32, num_updates=17340, lr=4.54674e-05, gnorm=0.415, clip=0, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=107165
2023-01-09 04:46:19 - progress_bar.py[line:274] - INFO: epoch 001:  17375 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4733, wps=61, ups=0.35, wpb=87.7, bsz=32, num_updates=17350, lr=4.54638e-05, gnorm=0.325, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=107194
2023-01-09 04:46:48 - progress_bar.py[line:274] - INFO: epoch 001:  17385 / 144806 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4872, wps=60.7, ups=0.35, wpb=87.1, bsz=32, num_updates=17360, lr=4.54603e-05, gnorm=0.345, clip=10, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=107223
2023-01-09 04:47:17 - progress_bar.py[line:274] - INFO: epoch 001:  17395 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4907, wps=60.5, ups=0.35, wpb=87.6, bsz=32, num_updates=17370, lr=4.54567e-05, gnorm=0.498, clip=10, loss_scale=256, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=107252
2023-01-09 04:47:46 - progress_bar.py[line:274] - INFO: epoch 001:  17405 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.5266, wps=61, ups=0.35, wpb=87.4, bsz=32, num_updates=17380, lr=4.54531e-05, gnorm=0.403, clip=0, loss_scale=256, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=107281
2023-01-09 04:48:15 - progress_bar.py[line:274] - INFO: epoch 001:  17415 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3665, wps=60.6, ups=0.35, wpb=87, bsz=32, num_updates=17390, lr=4.54496e-05, gnorm=0.575, clip=20, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=107310
2023-01-09 04:48:44 - progress_bar.py[line:274] - INFO: epoch 001:  17425 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4878, wps=60.7, ups=0.34, wpb=88.1, bsz=32, num_updates=17400, lr=4.5446e-05, gnorm=0.395, clip=0, loss_scale=256, train_wall=29, gb_free=14.5, ema_decay=0.9999, wall=107339
2023-01-09 04:49:13 - progress_bar.py[line:274] - INFO: epoch 001:  17435 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4114, wps=61.1, ups=0.35, wpb=87.1, bsz=32, num_updates=17410, lr=4.54424e-05, gnorm=0.238, clip=0, loss_scale=256, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=107368
2023-01-09 04:49:42 - progress_bar.py[line:274] - INFO: epoch 001:  17445 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4359, wps=61.3, ups=0.35, wpb=87.6, bsz=32, num_updates=17420, lr=4.54389e-05, gnorm=0.306, clip=0, loss_scale=256, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=107397
2023-01-09 04:50:11 - progress_bar.py[line:274] - INFO: epoch 001:  17455 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4132, wps=60.4, ups=0.35, wpb=86.8, bsz=32, num_updates=17430, lr=4.54353e-05, gnorm=0.279, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=107426
2023-01-09 04:50:40 - progress_bar.py[line:274] - INFO: epoch 001:  17465 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4821, wps=60, ups=0.34, wpb=87.1, bsz=32, num_updates=17440, lr=4.54317e-05, gnorm=0.327, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=107455
2023-01-09 04:51:09 - progress_bar.py[line:274] - INFO: epoch 001:  17475 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4675, wps=62.5, ups=0.36, wpb=88, bsz=32, num_updates=17450, lr=4.54281e-05, gnorm=0.322, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=107484
2023-01-09 04:51:38 - progress_bar.py[line:274] - INFO: epoch 001:  17485 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4151, wps=60.6, ups=0.35, wpb=87.4, bsz=32, num_updates=17460, lr=4.54246e-05, gnorm=0.379, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=107513
2023-01-09 04:52:06 - progress_bar.py[line:274] - INFO: epoch 001:  17495 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4444, wps=62.9, ups=0.36, wpb=87.7, bsz=32, num_updates=17470, lr=4.5421e-05, gnorm=0.434, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=107541
2023-01-09 04:52:35 - progress_bar.py[line:274] - INFO: epoch 001:  17505 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5266, wps=60.9, ups=0.35, wpb=86.1, bsz=32, num_updates=17480, lr=4.54174e-05, gnorm=0.36, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=107570
2023-01-09 04:53:04 - progress_bar.py[line:274] - INFO: epoch 001:  17515 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4895, wps=60.4, ups=0.34, wpb=88, bsz=32, num_updates=17490, lr=4.54139e-05, gnorm=0.39, clip=0, loss_scale=512, train_wall=29, gb_free=14.8, ema_decay=0.9999, wall=107599
2023-01-09 04:53:33 - progress_bar.py[line:274] - INFO: epoch 001:  17525 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.35, wps=61.1, ups=0.35, wpb=87.5, bsz=32, num_updates=17500, lr=4.54103e-05, gnorm=0.473, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=107628
2023-01-09 04:54:02 - progress_bar.py[line:274] - INFO: epoch 001:  17535 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4386, wps=60.3, ups=0.35, wpb=86, bsz=32, num_updates=17510, lr=4.54067e-05, gnorm=0.277, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=107657
2023-01-09 04:54:31 - progress_bar.py[line:274] - INFO: epoch 001:  17545 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3759, wps=60.3, ups=0.34, wpb=87.6, bsz=32, num_updates=17520, lr=4.54032e-05, gnorm=0.333, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=107686
2023-01-09 04:54:59 - progress_bar.py[line:274] - INFO: epoch 001:  17555 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4621, wps=62.1, ups=0.35, wpb=87.9, bsz=32, num_updates=17530, lr=4.53996e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=107714
2023-01-09 04:55:29 - progress_bar.py[line:274] - INFO: epoch 001:  17565 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4487, wps=58.8, ups=0.34, wpb=86.7, bsz=32, num_updates=17540, lr=4.5396e-05, gnorm=0.41, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=107744
2023-01-09 04:55:58 - progress_bar.py[line:274] - INFO: epoch 001:  17575 / 144806 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=90, nsentences=32, sample_size=90, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5, wps=62.8, ups=0.35, wpb=90, bsz=32, num_updates=17550, lr=4.53925e-05, gnorm=0.4, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=107773
2023-01-09 04:56:27 - progress_bar.py[line:274] - INFO: epoch 001:  17585 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3855, wps=61.2, ups=0.35, wpb=87, bsz=32, num_updates=17560, lr=4.53889e-05, gnorm=0.33, clip=0, loss_scale=512, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=107802
2023-01-09 04:56:56 - progress_bar.py[line:274] - INFO: epoch 001:  17595 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4412, wps=60.2, ups=0.35, wpb=86.1, bsz=32, num_updates=17570, lr=4.53853e-05, gnorm=0.317, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=107831
2023-01-09 04:57:24 - progress_bar.py[line:274] - INFO: epoch 001:  17605 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.488, wps=60.6, ups=0.35, wpb=87, bsz=32, num_updates=17580, lr=4.53818e-05, gnorm=0.54, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=107860
2023-01-09 04:57:53 - progress_bar.py[line:274] - INFO: epoch 001:  17615 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4198, wps=61.1, ups=0.35, wpb=86.4, bsz=32, num_updates=17590, lr=4.53782e-05, gnorm=0.489, clip=10, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=107888
2023-01-09 04:58:22 - progress_bar.py[line:274] - INFO: epoch 001:  17625 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4386, wps=60.4, ups=0.35, wpb=86.8, bsz=32, num_updates=17600, lr=4.53746e-05, gnorm=0.217, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=107917
2023-01-09 04:58:51 - progress_bar.py[line:274] - INFO: epoch 001:  17635 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3885, wps=61.3, ups=0.35, wpb=87.8, bsz=32, num_updates=17610, lr=4.53711e-05, gnorm=0.339, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=107946
2023-01-09 04:59:20 - progress_bar.py[line:274] - INFO: epoch 001:  17645 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4351, wps=62.4, ups=0.35, wpb=88.9, bsz=32, num_updates=17620, lr=4.53675e-05, gnorm=0.326, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=107975
2023-01-09 04:59:49 - progress_bar.py[line:274] - INFO: epoch 001:  17655 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4688, wps=59.9, ups=0.34, wpb=87.4, bsz=32, num_updates=17630, lr=4.53639e-05, gnorm=0.334, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=108004
2023-01-09 05:00:19 - progress_bar.py[line:274] - INFO: epoch 001:  17665 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.5098, wps=58.7, ups=0.33, wpb=87.7, bsz=32, num_updates=17640, lr=4.53604e-05, gnorm=0.488, clip=10, loss_scale=512, train_wall=30, gb_free=15.2, ema_decay=0.9999, wall=108034
2023-01-09 05:00:48 - progress_bar.py[line:274] - INFO: epoch 001:  17675 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4351, wps=61.1, ups=0.35, wpb=87.5, bsz=32, num_updates=17650, lr=4.53568e-05, gnorm=0.288, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=108063
2023-01-09 05:01:18 - progress_bar.py[line:274] - INFO: epoch 001:  17685 / 144806 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4859, wps=60.6, ups=0.34, wpb=88.6, bsz=32, num_updates=17660, lr=4.53532e-05, gnorm=0.337, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=108093
2023-01-09 05:01:47 - progress_bar.py[line:274] - INFO: epoch 001:  17695 / 144806 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=89.9, nsentences=32, sample_size=89.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3986, wps=62.1, ups=0.35, wpb=89.9, bsz=32, num_updates=17670, lr=4.53497e-05, gnorm=0.317, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=108122
2023-01-09 05:02:16 - progress_bar.py[line:274] - INFO: epoch 001:  17705 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4625, wps=60.1, ups=0.35, wpb=86.7, bsz=32, num_updates=17680, lr=4.53461e-05, gnorm=0.36, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=108151
2023-01-09 05:02:45 - progress_bar.py[line:274] - INFO: epoch 001:  17715 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4671, wps=60.9, ups=0.35, wpb=87.4, bsz=32, num_updates=17690, lr=4.53425e-05, gnorm=0.325, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=108180
2023-01-09 05:03:14 - progress_bar.py[line:274] - INFO: epoch 001:  17725 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3397, wps=59.9, ups=0.34, wpb=87.1, bsz=32, num_updates=17700, lr=4.5339e-05, gnorm=0.237, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=108209
2023-01-09 05:03:42 - progress_bar.py[line:274] - INFO: epoch 001:  17735 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4717, wps=63.1, ups=0.36, wpb=88.4, bsz=32, num_updates=17710, lr=4.53354e-05, gnorm=0.359, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=108237
2023-01-09 05:04:12 - progress_bar.py[line:274] - INFO: epoch 001:  17745 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4737, wps=61.1, ups=0.34, wpb=88.9, bsz=32, num_updates=17720, lr=4.53318e-05, gnorm=0.419, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=108267
2023-01-09 05:04:40 - progress_bar.py[line:274] - INFO: epoch 001:  17755 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4194, wps=61.9, ups=0.35, wpb=87.7, bsz=32, num_updates=17730, lr=4.53283e-05, gnorm=0.555, clip=10, loss_scale=512, train_wall=28, gb_free=14.9, ema_decay=0.9999, wall=108295
2023-01-09 05:05:09 - progress_bar.py[line:274] - INFO: epoch 001:  17765 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4356, wps=61, ups=0.35, wpb=87.5, bsz=32, num_updates=17740, lr=4.53247e-05, gnorm=0.413, clip=10, loss_scale=512, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=108324
2023-01-09 05:05:38 - progress_bar.py[line:274] - INFO: epoch 001:  17775 / 144806 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4014, wps=60.8, ups=0.35, wpb=87.4, bsz=32, num_updates=17750, lr=4.53211e-05, gnorm=0.297, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=108353
2023-01-09 05:06:07 - progress_bar.py[line:274] - INFO: epoch 001:  17785 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3526, wps=60.7, ups=0.35, wpb=87.7, bsz=32, num_updates=17760, lr=4.53176e-05, gnorm=0.32, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=108382
2023-01-09 05:06:37 - progress_bar.py[line:274] - INFO: epoch 001:  17795 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.1, nsentences=32, sample_size=85.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4475, wps=58.4, ups=0.34, wpb=85.1, bsz=32, num_updates=17770, lr=4.5314e-05, gnorm=0.325, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=108412
2023-01-09 05:07:06 - progress_bar.py[line:274] - INFO: epoch 001:  17805 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4337, wps=58.7, ups=0.34, wpb=86.6, bsz=32, num_updates=17780, lr=4.53104e-05, gnorm=0.232, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=108442
2023-01-09 05:07:35 - progress_bar.py[line:274] - INFO: epoch 001:  17815 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4562, wps=60.9, ups=0.35, wpb=87.2, bsz=32, num_updates=17790, lr=4.53069e-05, gnorm=0.373, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=108470
2023-01-09 05:08:04 - progress_bar.py[line:274] - INFO: epoch 001:  17825 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3976, wps=61.2, ups=0.35, wpb=86.2, bsz=32, num_updates=17800, lr=4.53033e-05, gnorm=0.454, clip=10, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=108499
2023-01-09 05:08:33 - progress_bar.py[line:274] - INFO: epoch 001:  17835 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4, wps=60.2, ups=0.35, wpb=86.7, bsz=32, num_updates=17810, lr=4.52997e-05, gnorm=0.45, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=108528
2023-01-09 05:09:02 - progress_bar.py[line:274] - INFO: epoch 001:  17845 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4258, wps=61.3, ups=0.35, wpb=87.5, bsz=32, num_updates=17820, lr=4.52962e-05, gnorm=0.438, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=108557
2023-01-09 05:09:30 - progress_bar.py[line:274] - INFO: epoch 001:  17855 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4534, wps=60.9, ups=0.35, wpb=87.1, bsz=32, num_updates=17830, lr=4.52926e-05, gnorm=0.377, clip=0, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=108585
2023-01-09 05:09:59 - progress_bar.py[line:274] - INFO: epoch 001:  17865 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4509, wps=60.4, ups=0.35, wpb=86, bsz=32, num_updates=17840, lr=4.5289e-05, gnorm=0.256, clip=0, loss_scale=512, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=108614
2023-01-09 05:10:28 - progress_bar.py[line:274] - INFO: epoch 001:  17875 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4907, wps=61.4, ups=0.35, wpb=87.6, bsz=32, num_updates=17850, lr=4.52855e-05, gnorm=0.35, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=108643
2023-01-09 05:10:57 - progress_bar.py[line:274] - INFO: epoch 001:  17885 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4176, wps=60.4, ups=0.35, wpb=85.9, bsz=32, num_updates=17860, lr=4.52819e-05, gnorm=0.398, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=108672
2023-01-09 05:11:26 - progress_bar.py[line:274] - INFO: epoch 001:  17895 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4837, wps=62.1, ups=0.35, wpb=87.8, bsz=32, num_updates=17870, lr=4.52783e-05, gnorm=0.259, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=108701
2023-01-09 05:11:55 - progress_bar.py[line:274] - INFO: epoch 001:  17905 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=89.2, nsentences=32, sample_size=89.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3931, wps=61.1, ups=0.34, wpb=89.2, bsz=32, num_updates=17880, lr=4.52748e-05, gnorm=0.436, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=108730
2023-01-09 05:12:24 - progress_bar.py[line:274] - INFO: epoch 001:  17915 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=85.3, nsentences=32, sample_size=85.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4826, wps=61.2, ups=0.36, wpb=85.3, bsz=32, num_updates=17890, lr=4.52712e-05, gnorm=0.413, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=108758
2023-01-09 05:12:53 - progress_bar.py[line:274] - INFO: epoch 001:  17925 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4091, wps=60.1, ups=0.34, wpb=87.6, bsz=32, num_updates=17900, lr=4.52676e-05, gnorm=0.386, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=108788
2023-01-09 05:13:22 - progress_bar.py[line:274] - INFO: epoch 001:  17935 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4062, wps=60.8, ups=0.35, wpb=87.4, bsz=32, num_updates=17910, lr=4.52641e-05, gnorm=0.295, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=108817
2023-01-09 05:13:52 - progress_bar.py[line:274] - INFO: epoch 001:  17945 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4464, wps=60.3, ups=0.35, wpb=86.6, bsz=32, num_updates=17920, lr=4.52605e-05, gnorm=0.304, clip=0, loss_scale=512, train_wall=29, gb_free=14.8, ema_decay=0.9999, wall=108846
2023-01-09 05:14:20 - progress_bar.py[line:274] - INFO: epoch 001:  17955 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4152, wps=61.3, ups=0.35, wpb=86.8, bsz=32, num_updates=17930, lr=4.52569e-05, gnorm=0.358, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=108875
2023-01-09 05:14:49 - progress_bar.py[line:274] - INFO: epoch 001:  17965 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4218, wps=61.6, ups=0.35, wpb=87.8, bsz=32, num_updates=17940, lr=4.52534e-05, gnorm=0.364, clip=0, loss_scale=1024, train_wall=28, gb_free=14.7, ema_decay=0.9999, wall=108904
2023-01-09 05:15:18 - progress_bar.py[line:274] - INFO: epoch 001:  17975 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4942, wps=60.3, ups=0.35, wpb=86.7, bsz=32, num_updates=17950, lr=4.52498e-05, gnorm=0.38, clip=10, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=108933
2023-01-09 05:15:47 - progress_bar.py[line:274] - INFO: epoch 001:  17985 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4437, wps=61.9, ups=0.35, wpb=87.4, bsz=32, num_updates=17960, lr=4.52462e-05, gnorm=0.338, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=108962
2023-01-09 05:16:16 - progress_bar.py[line:274] - INFO: epoch 001:  17995 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5033, wps=60.8, ups=0.35, wpb=87.8, bsz=32, num_updates=17970, lr=4.52427e-05, gnorm=0.327, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=108991
2023-01-09 05:16:45 - progress_bar.py[line:274] - INFO: epoch 001:  18005 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3988, wps=60.2, ups=0.35, wpb=86.1, bsz=32, num_updates=17980, lr=4.52391e-05, gnorm=0.297, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=109020
2023-01-09 05:17:14 - progress_bar.py[line:274] - INFO: epoch 001:  18015 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4938, wps=60.6, ups=0.35, wpb=87.4, bsz=32, num_updates=17990, lr=4.52355e-05, gnorm=0.364, clip=10, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=109049
2023-01-09 05:17:43 - progress_bar.py[line:274] - INFO: epoch 001:  18025 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4966, wps=60.2, ups=0.35, wpb=86.9, bsz=32, num_updates=18000, lr=4.5232e-05, gnorm=0.333, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=109078
2023-01-09 05:17:43 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-09 05:17:44 - train.py[line:549] - INFO: 0 / 6234
2023-01-09 05:17:44 - train.py[line:551] - INFO: load:0.92 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-09 05:17:45 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.91 GiB (GPU 1; 39.59 GiB total capacity; 8.38 GiB already allocated; 4.43 GiB free; 25.83 GiB reserved in total by PyTorch)
2023-01-09 05:17:45 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-09 05:17:45 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 5            |        cudaMalloc retries: 27        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8586 MB |    9566 MB |    8940 TB |    8940 TB |
|       from large pool |    8412 MB |    9391 MB |    8935 TB |    8935 TB |
|       from small pool |     174 MB |     174 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8586 MB |    9566 MB |    8940 TB |    8940 TB |
|       from large pool |    8412 MB |    9391 MB |    8935 TB |    8935 TB |
|       from small pool |     174 MB |     174 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26450 MB |   26454 MB |  332972 MB |  306522 MB |
|       from large pool |   26274 MB |   26274 MB |  332382 MB |  306108 MB |
|       from small pool |     176 MB |     180 MB |     590 MB |     414 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17863 MB |   21410 MB |   10198 TB |   10198 TB |
|       from large pool |   17861 MB |   21407 MB |   10193 TB |   10193 TB |
|       from small pool |       1 MB |       2 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  481638 K  |  481634 K  |
|       from large pool |     698    |     710    |  162662 K  |  162661 K  |
|       from small pool |    3925    |    3943    |  318976 K  |  318972 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  481638 K  |  481634 K  |
|       from large pool |     698    |     710    |  162662 K  |  162661 K  |
|       from small pool |    3925    |    3943    |  318976 K  |  318972 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     167    |     169    |    1025    |     858    |
|       from large pool |      79    |      79    |     730    |     651    |
|       from small pool |      88    |      90    |     295    |     207    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     120    |     122    |  357997 K  |  357997 K  |
|       from large pool |      53    |      53    |   85732 K  |   85732 K  |
|       from small pool |      67    |      74    |  272265 K  |  272265 K  |
|===========================================================================|

2023-01-09 05:17:45 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-09 05:17:45 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.30 GiB (GPU 0; 39.59 GiB total capacity; 8.02 GiB already allocated; 2.62 GiB free; 25.39 GiB reserved in total by PyTorch)
2023-01-09 05:17:45 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 6            |        cudaMalloc retries: 41        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8216 MB |    9122 MB |    8925 TB |    8925 TB |
|       from large pool |    8042 MB |    8948 MB |    8920 TB |    8920 TB |
|       from small pool |     174 MB |     174 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8216 MB |    9122 MB |    8925 TB |    8925 TB |
|       from large pool |    8042 MB |    8948 MB |    8920 TB |    8920 TB |
|       from small pool |     174 MB |     174 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26000 MB |   27468 MB |  495694 MB |  469694 MB |
|       from large pool |   25824 MB |   27288 MB |  494862 MB |  469038 MB |
|       from small pool |     176 MB |     180 MB |     832 MB |     656 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17783 MB |   20824 MB |   10452 TB |   10452 TB |
|       from large pool |   17781 MB |   20821 MB |   10447 TB |   10447 TB |
|       from small pool |       1 MB |       2 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  481657 K  |  481652 K  |
|       from large pool |     698    |     710    |  162664 K  |  162664 K  |
|       from small pool |    3925    |    3943    |  318992 K  |  318988 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  481657 K  |  481652 K  |
|       from large pool |     698    |     710    |  162664 K  |  162664 K  |
|       from small pool |    3925    |    3943    |  318992 K  |  318988 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     183    |     189    |    1463    |    1280    |
|       from large pool |      95    |      99    |    1047    |     952    |
|       from small pool |      88    |      90    |     416    |     328    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     121    |     125    |  357813 K  |  357813 K  |
|       from large pool |      63    |      65    |   86865 K  |   86865 K  |
|       from small pool |      58    |      65    |  270947 K  |  270947 K  |
|===========================================================================|

2023-01-09 05:17:45 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-09 05:17:45 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-09 05:21:58 - train.py[line:549] - INFO: 200 / 6234
2023-01-09 05:21:58 - train.py[line:551] - INFO: load:0.94 valid_run:254.53 task_valid:249.62 collect_output:0.72
2023-01-09 05:26:07 - train.py[line:549] - INFO: 400 / 6234
2023-01-09 05:26:07 - train.py[line:551] - INFO: load:0.97 valid_run:503.33 task_valid:495.18 collect_output:1.39
2023-01-09 05:30:17 - train.py[line:549] - INFO: 600 / 6234
2023-01-09 05:30:17 - train.py[line:551] - INFO: load:0.99 valid_run:753.21 task_valid:741.78 collect_output:2.10
2023-01-09 05:34:23 - train.py[line:549] - INFO: 800 / 6234
2023-01-09 05:34:23 - train.py[line:551] - INFO: load:1.02 valid_run:999.05 task_valid:984.37 collect_output:2.81
2023-01-09 05:38:34 - train.py[line:549] - INFO: 1000 / 6234
2023-01-09 05:38:34 - train.py[line:551] - INFO: load:1.04 valid_run:1250.14 task_valid:1232.25 collect_output:3.49
2023-01-09 05:42:47 - train.py[line:549] - INFO: 1200 / 6234
2023-01-09 05:42:47 - train.py[line:551] - INFO: load:1.07 valid_run:1502.94 task_valid:1481.83 collect_output:4.18
2023-01-09 05:46:59 - train.py[line:549] - INFO: 1400 / 6234
2023-01-09 05:46:59 - train.py[line:551] - INFO: load:1.10 valid_run:1754.93 task_valid:1730.58 collect_output:4.86
2023-01-09 05:51:09 - train.py[line:549] - INFO: 1600 / 6234
2023-01-09 05:51:09 - train.py[line:551] - INFO: load:1.12 valid_run:2004.65 task_valid:1977.09 collect_output:5.53
2023-01-09 05:55:20 - train.py[line:549] - INFO: 1800 / 6234
2023-01-09 05:55:20 - train.py[line:551] - INFO: load:1.15 valid_run:2255.10 task_valid:2224.34 collect_output:6.21
2023-01-09 05:59:24 - train.py[line:549] - INFO: 2000 / 6234
2023-01-09 05:59:24 - train.py[line:551] - INFO: load:1.17 valid_run:2499.59 task_valid:2465.61 collect_output:6.90
2023-01-09 06:03:33 - train.py[line:549] - INFO: 2200 / 6234
2023-01-09 06:03:33 - train.py[line:551] - INFO: load:1.20 valid_run:2748.34 task_valid:2711.10 collect_output:7.58
2023-01-09 06:07:44 - train.py[line:549] - INFO: 2400 / 6234
2023-01-09 06:07:44 - train.py[line:551] - INFO: load:1.22 valid_run:2999.18 task_valid:2958.67 collect_output:8.27
2023-01-09 06:11:50 - train.py[line:549] - INFO: 2600 / 6234
2023-01-09 06:11:50 - train.py[line:551] - INFO: load:1.25 valid_run:3245.01 task_valid:3201.27 collect_output:8.97
2023-01-09 06:16:02 - train.py[line:549] - INFO: 2800 / 6234
2023-01-09 06:16:02 - train.py[line:551] - INFO: load:1.27 valid_run:3496.49 task_valid:3449.52 collect_output:9.64
2023-01-09 06:20:11 - train.py[line:549] - INFO: 3000 / 6234
2023-01-09 06:20:11 - train.py[line:551] - INFO: load:1.30 valid_run:3745.87 task_valid:3695.65 collect_output:10.34
2023-01-09 06:24:17 - train.py[line:549] - INFO: 3200 / 6234
2023-01-09 06:24:17 - train.py[line:551] - INFO: load:1.32 valid_run:3991.78 task_valid:3938.32 collect_output:11.02
2023-01-09 06:28:26 - train.py[line:549] - INFO: 3400 / 6234
2023-01-09 06:28:26 - train.py[line:551] - INFO: load:1.35 valid_run:4240.94 task_valid:4184.24 collect_output:11.70
2023-01-09 06:32:38 - train.py[line:549] - INFO: 3600 / 6234
2023-01-09 06:32:38 - train.py[line:551] - INFO: load:1.38 valid_run:4492.83 task_valid:4432.88 collect_output:12.38
2023-01-09 06:36:49 - train.py[line:549] - INFO: 3800 / 6234
2023-01-09 06:36:49 - train.py[line:551] - INFO: load:1.40 valid_run:4743.19 task_valid:4680.01 collect_output:13.06
2023-01-09 06:40:59 - train.py[line:549] - INFO: 4000 / 6234
2023-01-09 06:40:59 - train.py[line:551] - INFO: load:1.43 valid_run:4993.62 task_valid:4927.15 collect_output:13.75
2023-01-09 06:45:09 - train.py[line:549] - INFO: 4200 / 6234
2023-01-09 06:45:09 - train.py[line:551] - INFO: load:1.46 valid_run:5243.46 task_valid:5173.74 collect_output:14.44
2023-01-09 06:49:22 - train.py[line:549] - INFO: 4400 / 6234
2023-01-09 06:49:22 - train.py[line:551] - INFO: load:1.48 valid_run:5496.64 task_valid:5423.72 collect_output:15.12
2023-01-09 06:53:29 - train.py[line:549] - INFO: 4600 / 6234
2023-01-09 06:53:29 - train.py[line:551] - INFO: load:1.51 valid_run:5743.57 task_valid:5667.38 collect_output:15.80
2023-01-09 06:57:39 - train.py[line:549] - INFO: 4800 / 6234
2023-01-09 06:57:39 - train.py[line:551] - INFO: load:1.53 valid_run:5992.93 task_valid:5913.49 collect_output:16.48
2023-01-09 07:01:48 - train.py[line:549] - INFO: 5000 / 6234
2023-01-09 07:01:48 - train.py[line:551] - INFO: load:1.56 valid_run:6241.98 task_valid:6159.30 collect_output:17.17
2023-01-09 07:05:57 - train.py[line:549] - INFO: 5200 / 6234
2023-01-09 07:05:57 - train.py[line:551] - INFO: load:1.59 valid_run:6491.15 task_valid:6405.20 collect_output:17.86
2023-01-09 07:10:03 - train.py[line:549] - INFO: 5400 / 6234
2023-01-09 07:10:03 - train.py[line:551] - INFO: load:1.61 valid_run:6737.19 task_valid:6647.96 collect_output:18.56
2023-01-09 07:14:18 - train.py[line:549] - INFO: 5600 / 6234
2023-01-09 07:14:18 - train.py[line:551] - INFO: load:1.64 valid_run:6991.26 task_valid:6898.76 collect_output:19.25
2023-01-09 07:18:26 - train.py[line:549] - INFO: 5800 / 6234
2023-01-09 07:18:26 - train.py[line:551] - INFO: load:1.66 valid_run:7239.54 task_valid:7143.81 collect_output:19.93
2023-01-09 07:22:38 - train.py[line:549] - INFO: 6000 / 6234
2023-01-09 07:22:38 - train.py[line:551] - INFO: load:1.69 valid_run:7491.86 task_valid:7392.88 collect_output:20.62
2023-01-09 07:26:51 - train.py[line:549] - INFO: 6200 / 6234
2023-01-09 07:26:51 - train.py[line:551] - INFO: load:1.72 valid_run:7744.43 task_valid:7642.16 collect_output:21.30

====================================================================================================
SGG eval:     R @ 50: 0.4109;     R @ 100: 0.5093;     R @ 500: 0.5506;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2528;    mR @ 100: 0.3302;    mR @ 500: 0.3729;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6732) (covered in:0.7083) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9375) (playing:0.0000) (riding:0.5948) (says:0.0000) (sitting on:0.7015) (standing on:0.1783) (using:0.6000) (walking in:0.0000) (walking on:0.3604) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4109;     R @ 100: 0.5093;     R @ 500: 0.5506;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2528;    mR @ 100: 0.3302;    mR @ 500: 0.3729;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6732) (covered in:0.7083) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9375) (playing:0.0000) (riding:0.5948) (says:0.0000) (sitting on:0.7015) (standing on:0.1783) (using:0.6000) (walking in:0.0000) (walking on:0.3604) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-01-09 07:27:44 - train.py[line:487] - INFO: 0.5093428571428571
2023-01-09 07:27:44 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-09 07:27:45 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.39 | loss_v1 0 | loss_v2 0 | nll_loss 0.237 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.509343 | ppl 1.18 | vqa_score 0.4516 | wps 57.5 | wpb 72 | bsz 24 | num_updates 18000 | best_R@100 0.632103
2023-01-09 07:27:45 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 18000 updates
2023-01-09 07:27:45 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_18000.pt
2023-01-09 07:28:27 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_18000.pt
2023-01-09 07:30:01 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_18000.pt (epoch 1 @ 18000 updates, score 0.5093428571428571) (writing took 136.69034946337342 seconds)
2023-01-09 07:30:11 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-09 07:30:34 - progress_bar.py[line:274] - INFO: epoch 001:  18036 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=87.286, nsentences=32, sample_size=87.286, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4181, wps=0.2, ups=0, wpb=87.3, bsz=32, num_updates=18010, lr=4.52284e-05, gnorm=0.494, clip=0, loss_scale=512, train_wall=32, gb_free=14.9, ema_decay=0.9999, wall=117049
2023-01-09 07:31:03 - progress_bar.py[line:274] - INFO: epoch 001:  18046 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3865, wps=58.8, ups=0.34, wpb=86.1, bsz=32, num_updates=18020, lr=4.52248e-05, gnorm=0.327, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=117078
2023-01-09 07:31:33 - progress_bar.py[line:274] - INFO: epoch 001:  18056 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.434, wps=59.9, ups=0.34, wpb=87.4, bsz=32, num_updates=18030, lr=4.52213e-05, gnorm=0.347, clip=10, loss_scale=512, train_wall=29, gb_free=14.7, ema_decay=0.9999, wall=117108
2023-01-09 07:32:01 - progress_bar.py[line:274] - INFO: epoch 001:  18066 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4246, wps=61.5, ups=0.35, wpb=86.9, bsz=32, num_updates=18040, lr=4.52177e-05, gnorm=0.384, clip=10, loss_scale=512, train_wall=28, gb_free=14.9, ema_decay=0.9999, wall=117136
2023-01-09 07:32:30 - progress_bar.py[line:274] - INFO: epoch 001:  18076 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3787, wps=61.2, ups=0.35, wpb=87.8, bsz=32, num_updates=18050, lr=4.52141e-05, gnorm=0.457, clip=10, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=117165
2023-01-09 07:32:59 - progress_bar.py[line:274] - INFO: epoch 001:  18086 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4877, wps=59.5, ups=0.34, wpb=86.3, bsz=32, num_updates=18060, lr=4.52106e-05, gnorm=0.417, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=117194
2023-01-09 07:33:29 - progress_bar.py[line:274] - INFO: epoch 001:  18096 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.475, wps=60.7, ups=0.35, wpb=87.8, bsz=32, num_updates=18070, lr=4.5207e-05, gnorm=0.722, clip=20, loss_scale=512, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=117224
2023-01-09 07:33:58 - progress_bar.py[line:274] - INFO: epoch 001:  18106 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5, wps=60.8, ups=0.35, wpb=87.2, bsz=32, num_updates=18080, lr=4.52034e-05, gnorm=0.271, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=117253
2023-01-09 07:34:26 - progress_bar.py[line:274] - INFO: epoch 001:  18116 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4539, wps=62.1, ups=0.35, wpb=88.2, bsz=32, num_updates=18090, lr=4.51999e-05, gnorm=0.316, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=117281
2023-01-09 07:34:55 - progress_bar.py[line:274] - INFO: epoch 001:  18126 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4357, wps=61.3, ups=0.34, wpb=88.8, bsz=32, num_updates=18100, lr=4.51963e-05, gnorm=0.336, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=117310
2023-01-09 07:35:24 - progress_bar.py[line:274] - INFO: epoch 001:  18136 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5099, wps=60.8, ups=0.35, wpb=87.5, bsz=32, num_updates=18110, lr=4.51927e-05, gnorm=0.255, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=117339
2023-01-09 07:35:54 - progress_bar.py[line:274] - INFO: epoch 001:  18146 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4671, wps=59.5, ups=0.34, wpb=86.5, bsz=32, num_updates=18120, lr=4.51892e-05, gnorm=0.322, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=117369
2023-01-09 07:36:23 - progress_bar.py[line:274] - INFO: epoch 001:  18156 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4167, wps=60.1, ups=0.34, wpb=87.4, bsz=32, num_updates=18130, lr=4.51856e-05, gnorm=0.264, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=117398
2023-01-09 07:36:52 - progress_bar.py[line:274] - INFO: epoch 001:  18166 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.462, wps=59.6, ups=0.34, wpb=86.4, bsz=32, num_updates=18140, lr=4.5182e-05, gnorm=0.513, clip=10, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=117427
2023-01-09 07:37:21 - progress_bar.py[line:274] - INFO: epoch 001:  18176 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4605, wps=62.2, ups=0.36, wpb=87.5, bsz=32, num_updates=18150, lr=4.51785e-05, gnorm=0.425, clip=0, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=117456
2023-01-09 07:37:50 - progress_bar.py[line:274] - INFO: epoch 001:  18186 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3787, wps=60.8, ups=0.35, wpb=87.4, bsz=32, num_updates=18160, lr=4.51749e-05, gnorm=0.325, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=117485
2023-01-09 07:38:19 - progress_bar.py[line:274] - INFO: epoch 001:  18196 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4114, wps=60.9, ups=0.35, wpb=87.5, bsz=32, num_updates=18170, lr=4.51713e-05, gnorm=0.313, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=117514
2023-01-09 07:38:48 - progress_bar.py[line:274] - INFO: epoch 001:  18206 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4634, wps=60, ups=0.34, wpb=87.5, bsz=32, num_updates=18180, lr=4.51678e-05, gnorm=0.287, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=117543
2023-01-09 07:39:17 - progress_bar.py[line:274] - INFO: epoch 001:  18216 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4233, wps=62.2, ups=0.35, wpb=87.9, bsz=32, num_updates=18190, lr=4.51642e-05, gnorm=0.264, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=117572
2023-01-09 07:39:46 - progress_bar.py[line:274] - INFO: epoch 001:  18226 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4424, wps=60.8, ups=0.35, wpb=87.3, bsz=32, num_updates=18200, lr=4.51606e-05, gnorm=0.424, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=117601
2023-01-09 07:40:15 - progress_bar.py[line:274] - INFO: epoch 001:  18236 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4198, wps=60, ups=0.35, wpb=86.7, bsz=32, num_updates=18210, lr=4.51571e-05, gnorm=0.256, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=117630
2023-01-09 07:40:44 - progress_bar.py[line:274] - INFO: epoch 001:  18246 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5197, wps=60.9, ups=0.35, wpb=87.5, bsz=32, num_updates=18220, lr=4.51535e-05, gnorm=0.706, clip=30, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=117659
2023-01-09 07:41:13 - progress_bar.py[line:274] - INFO: epoch 001:  18256 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4224, wps=60.7, ups=0.35, wpb=87.4, bsz=32, num_updates=18230, lr=4.51499e-05, gnorm=0.591, clip=30, loss_scale=512, train_wall=29, gb_free=15.7, ema_decay=0.9999, wall=117688
2023-01-09 07:41:42 - progress_bar.py[line:274] - INFO: epoch 001:  18266 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5195, wps=60.4, ups=0.35, wpb=87.5, bsz=32, num_updates=18240, lr=4.51464e-05, gnorm=0.309, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=117717
2023-01-09 07:42:11 - progress_bar.py[line:274] - INFO: epoch 001:  18276 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3662, wps=61.9, ups=0.35, wpb=88.2, bsz=32, num_updates=18250, lr=4.51428e-05, gnorm=0.333, clip=0, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=117746
2023-01-09 07:42:40 - progress_bar.py[line:274] - INFO: epoch 001:  18286 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5094, wps=60.7, ups=0.35, wpb=86.9, bsz=32, num_updates=18260, lr=4.51392e-05, gnorm=0.213, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=117775
2023-01-09 07:43:09 - progress_bar.py[line:274] - INFO: epoch 001:  18296 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4397, wps=60.9, ups=0.34, wpb=88.6, bsz=32, num_updates=18270, lr=4.51357e-05, gnorm=0.44, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=117804
2023-01-09 07:43:38 - progress_bar.py[line:274] - INFO: epoch 001:  18306 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4183, wps=60.8, ups=0.35, wpb=87.3, bsz=32, num_updates=18280, lr=4.51321e-05, gnorm=0.332, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=117833
2023-01-09 07:44:07 - progress_bar.py[line:274] - INFO: epoch 001:  18316 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4067, wps=61, ups=0.35, wpb=87.5, bsz=32, num_updates=18290, lr=4.51285e-05, gnorm=0.321, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=117862
2023-01-09 07:44:36 - progress_bar.py[line:274] - INFO: epoch 001:  18326 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4313, wps=60.1, ups=0.34, wpb=87.3, bsz=32, num_updates=18300, lr=4.5125e-05, gnorm=0.274, clip=0, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=117891
2023-01-09 07:45:05 - progress_bar.py[line:274] - INFO: epoch 001:  18336 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5706, wps=61.1, ups=0.35, wpb=87.7, bsz=32, num_updates=18310, lr=4.51214e-05, gnorm=0.311, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=117920
2023-01-09 07:45:34 - progress_bar.py[line:274] - INFO: epoch 001:  18346 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.48, wps=61.1, ups=0.35, wpb=87.5, bsz=32, num_updates=18320, lr=4.51178e-05, gnorm=0.283, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=117949
2023-01-09 07:46:03 - progress_bar.py[line:274] - INFO: epoch 001:  18356 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4679, wps=60.8, ups=0.35, wpb=87.6, bsz=32, num_updates=18330, lr=4.51143e-05, gnorm=0.246, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=117978
2023-01-09 07:46:32 - progress_bar.py[line:274] - INFO: epoch 001:  18366 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4242, wps=62.1, ups=0.35, wpb=88, bsz=32, num_updates=18340, lr=4.51107e-05, gnorm=0.298, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=118007
2023-01-09 07:47:01 - progress_bar.py[line:274] - INFO: epoch 001:  18376 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4503, wps=59.6, ups=0.34, wpb=86.7, bsz=32, num_updates=18350, lr=4.51071e-05, gnorm=0.3, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=118036
2023-01-09 07:47:30 - progress_bar.py[line:274] - INFO: epoch 001:  18386 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.443, wps=60, ups=0.34, wpb=87.1, bsz=32, num_updates=18360, lr=4.51036e-05, gnorm=0.46, clip=10, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=118066
2023-01-09 07:47:59 - progress_bar.py[line:274] - INFO: epoch 001:  18396 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4395, wps=60.5, ups=0.35, wpb=87, bsz=32, num_updates=18370, lr=4.51e-05, gnorm=0.392, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=118095
2023-01-09 07:48:28 - progress_bar.py[line:274] - INFO: epoch 001:  18406 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4417, wps=61, ups=0.35, wpb=86.7, bsz=32, num_updates=18380, lr=4.50964e-05, gnorm=0.41, clip=10, loss_scale=512, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=118123
2023-01-09 07:48:57 - progress_bar.py[line:274] - INFO: epoch 001:  18416 / 144806 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=89.5, nsentences=32, sample_size=89.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4459, wps=61.9, ups=0.35, wpb=89.5, bsz=32, num_updates=18390, lr=4.50928e-05, gnorm=0.366, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=118152
2023-01-09 07:49:27 - progress_bar.py[line:274] - INFO: epoch 001:  18426 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4211, wps=61.1, ups=0.35, wpb=88.5, bsz=32, num_updates=18400, lr=4.50893e-05, gnorm=0.347, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=118182
2023-01-09 07:49:55 - progress_bar.py[line:274] - INFO: epoch 001:  18436 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5031, wps=61.7, ups=0.35, wpb=87.7, bsz=32, num_updates=18410, lr=4.50857e-05, gnorm=0.39, clip=0, loss_scale=512, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=118210
2023-01-09 07:50:24 - progress_bar.py[line:274] - INFO: epoch 001:  18446 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4345, wps=59.8, ups=0.35, wpb=86.5, bsz=32, num_updates=18420, lr=4.50821e-05, gnorm=0.297, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=118239
2023-01-09 07:50:53 - progress_bar.py[line:274] - INFO: epoch 001:  18456 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4188, wps=61.6, ups=0.35, wpb=88.3, bsz=32, num_updates=18430, lr=4.50786e-05, gnorm=0.304, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=118268
2023-01-09 07:51:22 - progress_bar.py[line:274] - INFO: epoch 001:  18466 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4366, wps=61.5, ups=0.35, wpb=88.8, bsz=32, num_updates=18440, lr=4.5075e-05, gnorm=0.347, clip=0, loss_scale=512, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=118298
2023-01-09 07:51:51 - progress_bar.py[line:274] - INFO: epoch 001:  18476 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3885, wps=61.7, ups=0.35, wpb=88.3, bsz=32, num_updates=18450, lr=4.50714e-05, gnorm=0.238, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=118326
2023-01-09 07:52:20 - progress_bar.py[line:274] - INFO: epoch 001:  18486 / 144806 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4783, wps=61.3, ups=0.35, wpb=88.2, bsz=32, num_updates=18460, lr=4.50679e-05, gnorm=0.338, clip=0, loss_scale=512, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=118355
2023-01-09 07:52:49 - progress_bar.py[line:274] - INFO: epoch 001:  18496 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4408, wps=61.4, ups=0.35, wpb=88.3, bsz=32, num_updates=18470, lr=4.50643e-05, gnorm=0.276, clip=0, loss_scale=512, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=118384
2023-01-09 07:53:19 - progress_bar.py[line:274] - INFO: epoch 001:  18506 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3765, wps=60.3, ups=0.35, wpb=86.9, bsz=32, num_updates=18480, lr=4.50607e-05, gnorm=0.245, clip=0, loss_scale=512, train_wall=29, gb_free=15, ema_decay=0.9999, wall=118414
2023-01-09 07:53:47 - progress_bar.py[line:274] - INFO: epoch 001:  18516 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4679, wps=60.8, ups=0.35, wpb=87.1, bsz=32, num_updates=18490, lr=4.50572e-05, gnorm=0.378, clip=0, loss_scale=512, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=118442
2023-01-09 07:54:16 - progress_bar.py[line:274] - INFO: epoch 001:  18526 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4777, wps=62.1, ups=0.35, wpb=88, bsz=32, num_updates=18500, lr=4.50536e-05, gnorm=0.344, clip=0, loss_scale=512, train_wall=28, gb_free=15, ema_decay=0.9999, wall=118471
2023-01-09 07:54:45 - progress_bar.py[line:274] - INFO: epoch 001:  18536 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4774, wps=61.3, ups=0.35, wpb=87.4, bsz=32, num_updates=18510, lr=4.505e-05, gnorm=0.387, clip=10, loss_scale=512, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=118500
2023-01-09 07:55:14 - progress_bar.py[line:274] - INFO: epoch 001:  18546 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4591, wps=60.2, ups=0.34, wpb=87.5, bsz=32, num_updates=18520, lr=4.50465e-05, gnorm=0.337, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=118529
2023-01-09 07:55:43 - progress_bar.py[line:274] - INFO: epoch 001:  18556 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4, wps=60.5, ups=0.35, wpb=86.9, bsz=32, num_updates=18530, lr=4.50429e-05, gnorm=0.306, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=118558
2023-01-09 07:56:12 - progress_bar.py[line:274] - INFO: epoch 001:  18566 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4157, wps=60, ups=0.35, wpb=86.8, bsz=32, num_updates=18540, lr=4.50393e-05, gnorm=0.349, clip=10, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=118587
2023-01-09 07:56:41 - progress_bar.py[line:274] - INFO: epoch 001:  18576 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4813, wps=61.3, ups=0.35, wpb=87.1, bsz=32, num_updates=18550, lr=4.50358e-05, gnorm=0.34, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=118616
2023-01-09 07:57:10 - progress_bar.py[line:274] - INFO: epoch 001:  18586 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3918, wps=60.1, ups=0.34, wpb=87.4, bsz=32, num_updates=18560, lr=4.50322e-05, gnorm=0.363, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=118645
2023-01-09 07:57:39 - progress_bar.py[line:274] - INFO: epoch 001:  18596 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4218, wps=61.1, ups=0.35, wpb=87, bsz=32, num_updates=18570, lr=4.50286e-05, gnorm=0.302, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=118674
2023-01-09 07:58:08 - progress_bar.py[line:274] - INFO: epoch 001:  18606 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4444, wps=60.2, ups=0.34, wpb=87.3, bsz=32, num_updates=18580, lr=4.50251e-05, gnorm=0.328, clip=0, loss_scale=1024, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=118703
2023-01-09 07:58:37 - progress_bar.py[line:274] - INFO: epoch 001:  18616 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4107, wps=60.2, ups=0.35, wpb=86.4, bsz=32, num_updates=18590, lr=4.50215e-05, gnorm=0.323, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=118732
2023-01-09 07:59:07 - progress_bar.py[line:274] - INFO: epoch 001:  18626 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.513, wps=60.3, ups=0.35, wpb=86.9, bsz=32, num_updates=18600, lr=4.50179e-05, gnorm=0.293, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=118762
2023-01-09 07:59:36 - progress_bar.py[line:274] - INFO: epoch 001:  18636 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.454, wps=60, ups=0.35, wpb=86.8, bsz=32, num_updates=18610, lr=4.50144e-05, gnorm=0.442, clip=10, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=118791
2023-01-09 08:00:05 - progress_bar.py[line:274] - INFO: epoch 001:  18646 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4074, wps=59.7, ups=0.34, wpb=86.9, bsz=32, num_updates=18620, lr=4.50108e-05, gnorm=0.26, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=118820
2023-01-09 08:00:34 - progress_bar.py[line:274] - INFO: epoch 001:  18656 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4444, wps=60.6, ups=0.35, wpb=87.3, bsz=32, num_updates=18630, lr=4.50072e-05, gnorm=0.352, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=118849
2023-01-09 08:01:04 - progress_bar.py[line:274] - INFO: epoch 001:  18666 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4909, wps=59.2, ups=0.34, wpb=86.7, bsz=32, num_updates=18640, lr=4.50037e-05, gnorm=0.324, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=118879
2023-01-09 08:01:33 - progress_bar.py[line:274] - INFO: epoch 001:  18676 / 144806 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5069, wps=61.5, ups=0.35, wpb=88.3, bsz=32, num_updates=18650, lr=4.50001e-05, gnorm=0.333, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=118908
2023-01-09 08:02:01 - progress_bar.py[line:274] - INFO: epoch 001:  18686 / 144806 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5177, wps=62.2, ups=0.35, wpb=88.3, bsz=32, num_updates=18660, lr=4.49965e-05, gnorm=0.285, clip=10, loss_scale=1024, train_wall=28, gb_free=15.5, ema_decay=0.9999, wall=118936
2023-01-09 08:02:30 - progress_bar.py[line:274] - INFO: epoch 001:  18696 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4331, wps=61.5, ups=0.35, wpb=87.3, bsz=32, num_updates=18670, lr=4.4993e-05, gnorm=0.191, clip=0, loss_scale=1024, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=118965
2023-01-09 08:02:59 - progress_bar.py[line:274] - INFO: epoch 001:  18706 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4444, wps=61.3, ups=0.35, wpb=87.6, bsz=32, num_updates=18680, lr=4.49894e-05, gnorm=0.332, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=118994
2023-01-09 08:03:28 - progress_bar.py[line:274] - INFO: epoch 001:  18716 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4625, wps=60.6, ups=0.34, wpb=87.9, bsz=32, num_updates=18690, lr=4.49858e-05, gnorm=0.407, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=119023
2023-01-09 08:03:57 - progress_bar.py[line:274] - INFO: epoch 001:  18726 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.378, wps=60.9, ups=0.35, wpb=87.3, bsz=32, num_updates=18700, lr=4.49823e-05, gnorm=0.579, clip=10, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=119052
2023-01-09 08:04:26 - progress_bar.py[line:274] - INFO: epoch 001:  18736 / 144806 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.45, wps=60.8, ups=0.35, wpb=87.8, bsz=32, num_updates=18710, lr=4.49787e-05, gnorm=0.254, clip=0, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=119081
2023-01-09 08:04:55 - progress_bar.py[line:274] - INFO: epoch 001:  18746 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3913, wps=60.2, ups=0.35, wpb=87, bsz=32, num_updates=18720, lr=4.49751e-05, gnorm=0.293, clip=0, loss_scale=1024, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=119110
2023-01-09 08:05:25 - progress_bar.py[line:274] - INFO: epoch 001:  18756 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3593, wps=59.8, ups=0.35, wpb=86.5, bsz=32, num_updates=18730, lr=4.49716e-05, gnorm=0.357, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=119140
2023-01-09 08:05:53 - progress_bar.py[line:274] - INFO: epoch 001:  18766 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4248, wps=61.8, ups=0.35, wpb=87.5, bsz=32, num_updates=18740, lr=4.4968e-05, gnorm=0.381, clip=10, loss_scale=1024, train_wall=28, gb_free=15, ema_decay=0.9999, wall=119168
2023-01-09 08:06:22 - progress_bar.py[line:274] - INFO: epoch 001:  18776 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4437, wps=59.9, ups=0.35, wpb=86.5, bsz=32, num_updates=18750, lr=4.49644e-05, gnorm=0.223, clip=0, loss_scale=1024, train_wall=29, gb_free=14.7, ema_decay=0.9999, wall=119197
2023-01-09 08:06:52 - progress_bar.py[line:274] - INFO: epoch 001:  18786 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5119, wps=60.5, ups=0.35, wpb=87.7, bsz=32, num_updates=18760, lr=4.49609e-05, gnorm=0.31, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=119227
2023-01-09 08:07:20 - progress_bar.py[line:274] - INFO: epoch 001:  18796 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4351, wps=61.8, ups=0.35, wpb=87.4, bsz=32, num_updates=18770, lr=4.49573e-05, gnorm=0.294, clip=10, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=119255
2023-01-09 08:07:49 - progress_bar.py[line:274] - INFO: epoch 001:  18806 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4562, wps=61.3, ups=0.35, wpb=87.2, bsz=32, num_updates=18780, lr=4.49537e-05, gnorm=0.358, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=119284
2023-01-09 08:08:18 - progress_bar.py[line:274] - INFO: epoch 001:  18816 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4663, wps=60.6, ups=0.34, wpb=88.2, bsz=32, num_updates=18790, lr=4.49502e-05, gnorm=0.341, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=119313
2023-01-09 08:08:48 - progress_bar.py[line:274] - INFO: epoch 001:  18826 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4459, wps=60.5, ups=0.34, wpb=88, bsz=32, num_updates=18800, lr=4.49466e-05, gnorm=0.4, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=119343
2023-01-09 08:09:16 - progress_bar.py[line:274] - INFO: epoch 001:  18836 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4268, wps=61.7, ups=0.35, wpb=87.6, bsz=32, num_updates=18810, lr=4.4943e-05, gnorm=0.402, clip=0, loss_scale=1024, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=119371
2023-01-09 08:09:45 - progress_bar.py[line:274] - INFO: epoch 001:  18846 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3827, wps=61, ups=0.35, wpb=87.3, bsz=32, num_updates=18820, lr=4.49395e-05, gnorm=0.346, clip=10, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=119400
2023-01-09 08:10:14 - progress_bar.py[line:274] - INFO: epoch 001:  18856 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4651, wps=59.9, ups=0.35, wpb=86.5, bsz=32, num_updates=18830, lr=4.49359e-05, gnorm=0.371, clip=10, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=119429
2023-01-09 08:10:43 - progress_bar.py[line:274] - INFO: epoch 001:  18866 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4395, wps=60.7, ups=0.35, wpb=86.7, bsz=32, num_updates=18840, lr=4.49323e-05, gnorm=0.271, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=119458
2023-01-09 08:11:12 - progress_bar.py[line:274] - INFO: epoch 001:  18876 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3654, wps=61.6, ups=0.35, wpb=87.1, bsz=32, num_updates=18850, lr=4.49288e-05, gnorm=0.441, clip=10, loss_scale=1024, train_wall=28, gb_free=15, ema_decay=0.9999, wall=119487
2023-01-09 08:11:40 - progress_bar.py[line:274] - INFO: epoch 001:  18886 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4472, wps=61, ups=0.35, wpb=86.8, bsz=32, num_updates=18860, lr=4.49252e-05, gnorm=0.399, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=119515
2023-01-09 08:12:09 - progress_bar.py[line:274] - INFO: epoch 001:  18896 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4698, wps=60.8, ups=0.35, wpb=87.3, bsz=32, num_updates=18870, lr=4.49216e-05, gnorm=0.304, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=119544
2023-01-09 08:12:38 - progress_bar.py[line:274] - INFO: epoch 001:  18906 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4387, wps=60.7, ups=0.35, wpb=87.4, bsz=32, num_updates=18880, lr=4.49181e-05, gnorm=0.277, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=119573
2023-01-09 08:13:07 - progress_bar.py[line:274] - INFO: epoch 001:  18916 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5091, wps=60.8, ups=0.35, wpb=86.7, bsz=32, num_updates=18890, lr=4.49145e-05, gnorm=0.335, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=119602
2023-01-09 08:13:36 - progress_bar.py[line:274] - INFO: epoch 001:  18926 / 144806 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.4786, wps=61.1, ups=0.35, wpb=87.9, bsz=32, num_updates=18900, lr=4.49109e-05, gnorm=0.288, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=119631
2023-01-09 08:14:05 - progress_bar.py[line:274] - INFO: epoch 001:  18936 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3657, wps=60.1, ups=0.35, wpb=86.5, bsz=32, num_updates=18910, lr=4.49074e-05, gnorm=0.331, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=119660
2023-01-09 08:14:35 - progress_bar.py[line:274] - INFO: epoch 001:  18946 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4663, wps=59.5, ups=0.34, wpb=87, bsz=32, num_updates=18920, lr=4.49038e-05, gnorm=0.393, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=119690
2023-01-09 08:15:04 - progress_bar.py[line:274] - INFO: epoch 001:  18956 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4172, wps=61.3, ups=0.35, wpb=88.3, bsz=32, num_updates=18930, lr=4.49002e-05, gnorm=0.304, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=119719
2023-01-09 08:15:33 - progress_bar.py[line:274] - INFO: epoch 001:  18966 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4771, wps=60.3, ups=0.34, wpb=88.2, bsz=32, num_updates=18940, lr=4.48967e-05, gnorm=0.415, clip=0, loss_scale=1024, train_wall=29, gb_free=15.6, ema_decay=0.9999, wall=119748
2023-01-09 08:16:02 - progress_bar.py[line:274] - INFO: epoch 001:  18976 / 144806 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4965, wps=61.5, ups=0.35, wpb=87, bsz=32, num_updates=18950, lr=4.48931e-05, gnorm=0.288, clip=0, loss_scale=1024, train_wall=28, gb_free=15.6, ema_decay=0.9999, wall=119777
2023-01-09 08:16:31 - progress_bar.py[line:274] - INFO: epoch 001:  18986 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=85.7, nsentences=32, sample_size=85.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4524, wps=58.9, ups=0.34, wpb=85.7, bsz=32, num_updates=18960, lr=4.48895e-05, gnorm=0.236, clip=0, loss_scale=1024, train_wall=29, gb_free=15.6, ema_decay=0.9999, wall=119806
2023-01-09 08:17:00 - progress_bar.py[line:274] - INFO: epoch 001:  18996 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4324, wps=61.4, ups=0.35, wpb=87.5, bsz=32, num_updates=18970, lr=4.4886e-05, gnorm=0.261, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=119835
2023-01-09 08:17:29 - progress_bar.py[line:274] - INFO: epoch 001:  19006 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4477, wps=61.1, ups=0.35, wpb=87.5, bsz=32, num_updates=18980, lr=4.48824e-05, gnorm=0.312, clip=10, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=119864
2023-01-09 08:17:58 - progress_bar.py[line:274] - INFO: epoch 001:  19016 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4065, wps=61.4, ups=0.35, wpb=87.8, bsz=32, num_updates=18990, lr=4.48788e-05, gnorm=0.355, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=119893
2023-01-09 08:18:27 - progress_bar.py[line:274] - INFO: epoch 001:  19026 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4571, wps=60.7, ups=0.35, wpb=86.8, bsz=32, num_updates=19000, lr=4.48753e-05, gnorm=0.401, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=119922
2023-01-09 08:18:56 - progress_bar.py[line:274] - INFO: epoch 001:  19036 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4207, wps=61.1, ups=0.35, wpb=87.9, bsz=32, num_updates=19010, lr=4.48717e-05, gnorm=0.315, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=119951
2023-01-09 08:19:25 - progress_bar.py[line:274] - INFO: epoch 001:  19046 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4586, wps=61, ups=0.35, wpb=87.3, bsz=32, num_updates=19020, lr=4.48681e-05, gnorm=0.349, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=119980
2023-01-09 08:19:54 - progress_bar.py[line:274] - INFO: epoch 001:  19056 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4968, wps=59.9, ups=0.34, wpb=87, bsz=32, num_updates=19030, lr=4.48646e-05, gnorm=0.3, clip=10, loss_scale=2048, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=120009
2023-01-09 08:20:23 - progress_bar.py[line:274] - INFO: epoch 001:  19066 / 144806 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5163, wps=60.9, ups=0.35, wpb=88.1, bsz=32, num_updates=19040, lr=4.4861e-05, gnorm=0.278, clip=0, loss_scale=2048, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=120038
2023-01-09 08:20:43 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-09 08:20:55 - progress_bar.py[line:274] - INFO: epoch 001:  19077 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=87.571, nsentences=32, sample_size=87.571, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5294, wps=58, ups=0.32, wpb=87.6, bsz=32, num_updates=19050, lr=4.48574e-05, gnorm=0.232, clip=0, loss_scale=1024, train_wall=32, gb_free=15.2, ema_decay=0.9999, wall=120070
2023-01-09 08:21:23 - progress_bar.py[line:274] - INFO: epoch 001:  19087 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4512, wps=61.8, ups=0.36, wpb=86.9, bsz=32, num_updates=19060, lr=4.48539e-05, gnorm=0.552, clip=20, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=120098
2023-01-09 08:21:52 - progress_bar.py[line:274] - INFO: epoch 001:  19097 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.475, wps=61, ups=0.35, wpb=87.7, bsz=32, num_updates=19070, lr=4.48503e-05, gnorm=0.361, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=120127
2023-01-09 08:22:21 - progress_bar.py[line:274] - INFO: epoch 001:  19107 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4367, wps=61, ups=0.35, wpb=87.8, bsz=32, num_updates=19080, lr=4.48467e-05, gnorm=0.256, clip=0, loss_scale=1024, train_wall=29, gb_free=15.6, ema_decay=0.9999, wall=120156
2023-01-09 08:22:50 - progress_bar.py[line:274] - INFO: epoch 001:  19117 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4487, wps=61.5, ups=0.35, wpb=87, bsz=32, num_updates=19090, lr=4.48432e-05, gnorm=0.544, clip=10, loss_scale=1024, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=120185
2023-01-09 08:23:19 - progress_bar.py[line:274] - INFO: epoch 001:  19127 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4684, wps=59, ups=0.34, wpb=86.6, bsz=32, num_updates=19100, lr=4.48396e-05, gnorm=0.426, clip=10, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=120215
2023-01-09 08:23:49 - progress_bar.py[line:274] - INFO: epoch 001:  19137 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4938, wps=59.9, ups=0.34, wpb=87.6, bsz=32, num_updates=19110, lr=4.4836e-05, gnorm=0.264, clip=0, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=120244
2023-01-09 08:24:18 - progress_bar.py[line:274] - INFO: epoch 001:  19147 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4472, wps=60.5, ups=0.35, wpb=87.5, bsz=32, num_updates=19120, lr=4.48325e-05, gnorm=0.248, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=120273
2023-01-09 08:24:47 - progress_bar.py[line:274] - INFO: epoch 001:  19157 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3793, wps=60.7, ups=0.35, wpb=86.7, bsz=32, num_updates=19130, lr=4.48289e-05, gnorm=0.24, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=120302
2023-01-09 08:25:16 - progress_bar.py[line:274] - INFO: epoch 001:  19167 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5102, wps=61.7, ups=0.35, wpb=87.8, bsz=32, num_updates=19140, lr=4.48253e-05, gnorm=0.344, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=120331
2023-01-09 08:25:45 - progress_bar.py[line:274] - INFO: epoch 001:  19177 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3947, wps=60.3, ups=0.35, wpb=87.2, bsz=32, num_updates=19150, lr=4.48218e-05, gnorm=0.326, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=120360
2023-01-09 08:26:14 - progress_bar.py[line:274] - INFO: epoch 001:  19187 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4387, wps=61.4, ups=0.35, wpb=88.1, bsz=32, num_updates=19160, lr=4.48182e-05, gnorm=0.507, clip=10, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=120389
2023-01-09 08:26:43 - progress_bar.py[line:274] - INFO: epoch 001:  19197 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4183, wps=60.6, ups=0.35, wpb=87.7, bsz=32, num_updates=19170, lr=4.48146e-05, gnorm=0.492, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=120418
2023-01-09 08:27:13 - progress_bar.py[line:274] - INFO: epoch 001:  19207 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4783, wps=59.3, ups=0.34, wpb=87, bsz=32, num_updates=19180, lr=4.48111e-05, gnorm=0.445, clip=10, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=120448
2023-01-09 08:27:42 - progress_bar.py[line:274] - INFO: epoch 001:  19217 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.462, wps=60.4, ups=0.35, wpb=86.8, bsz=32, num_updates=19190, lr=4.48075e-05, gnorm=0.188, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=120477
2023-01-09 08:28:10 - progress_bar.py[line:274] - INFO: epoch 001:  19227 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4354, wps=62.1, ups=0.35, wpb=88.2, bsz=32, num_updates=19200, lr=4.48039e-05, gnorm=0.434, clip=10, loss_scale=1024, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=120505
2023-01-09 08:28:39 - progress_bar.py[line:274] - INFO: epoch 001:  19237 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4387, wps=62.2, ups=0.35, wpb=88.7, bsz=32, num_updates=19210, lr=4.48004e-05, gnorm=0.321, clip=0, loss_scale=1024, train_wall=28, gb_free=15.6, ema_decay=0.9999, wall=120534
2023-01-09 08:29:07 - progress_bar.py[line:274] - INFO: epoch 001:  19247 / 144806 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4302, wps=62, ups=0.36, wpb=86.5, bsz=32, num_updates=19220, lr=4.47968e-05, gnorm=0.427, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=120562
2023-01-09 08:29:36 - progress_bar.py[line:274] - INFO: epoch 001:  19257 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4465, wps=61.3, ups=0.35, wpb=87.6, bsz=32, num_updates=19230, lr=4.47932e-05, gnorm=0.33, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=120591
2023-01-09 08:30:05 - progress_bar.py[line:274] - INFO: epoch 001:  19267 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4, wps=61, ups=0.35, wpb=86.8, bsz=32, num_updates=19240, lr=4.47897e-05, gnorm=0.302, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=120620
2023-01-09 08:30:34 - progress_bar.py[line:274] - INFO: epoch 001:  19277 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3955, wps=59.2, ups=0.34, wpb=86.1, bsz=32, num_updates=19250, lr=4.47861e-05, gnorm=0.246, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=120649
2023-01-09 08:31:03 - progress_bar.py[line:274] - INFO: epoch 001:  19287 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3735, wps=61.2, ups=0.36, wpb=86.1, bsz=32, num_updates=19260, lr=4.47825e-05, gnorm=0.438, clip=10, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=120678
2023-01-09 08:31:32 - progress_bar.py[line:274] - INFO: epoch 001:  19297 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4437, wps=61.1, ups=0.35, wpb=87.3, bsz=32, num_updates=19270, lr=4.4779e-05, gnorm=0.242, clip=0, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=120707
2023-01-09 08:32:01 - progress_bar.py[line:274] - INFO: epoch 001:  19307 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4694, wps=62.2, ups=0.35, wpb=88.9, bsz=32, num_updates=19280, lr=4.47754e-05, gnorm=0.408, clip=0, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=120736
2023-01-09 08:32:30 - progress_bar.py[line:274] - INFO: epoch 001:  19317 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4841, wps=60.4, ups=0.35, wpb=87.5, bsz=32, num_updates=19290, lr=4.47718e-05, gnorm=0.395, clip=10, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=120765
2023-01-09 08:32:59 - progress_bar.py[line:274] - INFO: epoch 001:  19327 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.4, nsentences=32, sample_size=85.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4057, wps=59.4, ups=0.35, wpb=85.4, bsz=32, num_updates=19300, lr=4.47683e-05, gnorm=0.404, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=120794
2023-01-09 08:33:28 - progress_bar.py[line:274] - INFO: epoch 001:  19337 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4304, wps=59.8, ups=0.34, wpb=86.7, bsz=32, num_updates=19310, lr=4.47647e-05, gnorm=0.347, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=120823
2023-01-09 08:33:57 - progress_bar.py[line:274] - INFO: epoch 001:  19347 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5155, wps=61, ups=0.35, wpb=86.7, bsz=32, num_updates=19320, lr=4.47611e-05, gnorm=0.288, clip=0, loss_scale=1024, train_wall=28, gb_free=14.9, ema_decay=0.9999, wall=120852
2023-01-09 08:34:26 - progress_bar.py[line:274] - INFO: epoch 001:  19357 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4667, wps=61.6, ups=0.35, wpb=86.9, bsz=32, num_updates=19330, lr=4.47575e-05, gnorm=0.682, clip=40, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=120881
2023-01-09 08:34:55 - progress_bar.py[line:274] - INFO: epoch 001:  19367 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4724, wps=59.7, ups=0.34, wpb=86.6, bsz=32, num_updates=19340, lr=4.4754e-05, gnorm=0.273, clip=0, loss_scale=1024, train_wall=29, gb_free=15, ema_decay=0.9999, wall=120910
2023-01-09 08:35:24 - progress_bar.py[line:274] - INFO: epoch 001:  19377 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.36, wps=60.6, ups=0.34, wpb=88, bsz=32, num_updates=19350, lr=4.47504e-05, gnorm=0.231, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=120939
2023-01-09 08:35:54 - progress_bar.py[line:274] - INFO: epoch 001:  19387 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4311, wps=60.9, ups=0.35, wpb=88.1, bsz=32, num_updates=19360, lr=4.47468e-05, gnorm=0.37, clip=10, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=120969
2023-01-09 08:36:23 - progress_bar.py[line:274] - INFO: epoch 001:  19397 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4201, wps=59.4, ups=0.34, wpb=86.6, bsz=32, num_updates=19370, lr=4.47433e-05, gnorm=0.248, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=120998
2023-01-09 08:36:52 - progress_bar.py[line:274] - INFO: epoch 001:  19407 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4706, wps=60.2, ups=0.35, wpb=87, bsz=32, num_updates=19380, lr=4.47397e-05, gnorm=0.419, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=121027
2023-01-09 08:37:21 - progress_bar.py[line:274] - INFO: epoch 001:  19417 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=89.5, nsentences=32, sample_size=89.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4545, wps=63.4, ups=0.35, wpb=89.5, bsz=32, num_updates=19390, lr=4.47361e-05, gnorm=0.265, clip=0, loss_scale=1024, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=121056
2023-01-09 08:37:50 - progress_bar.py[line:274] - INFO: epoch 001:  19427 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4276, wps=61.1, ups=0.35, wpb=87.2, bsz=32, num_updates=19400, lr=4.47326e-05, gnorm=0.356, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=121085
2023-01-09 08:38:19 - progress_bar.py[line:274] - INFO: epoch 001:  19437 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4323, wps=61.4, ups=0.35, wpb=88, bsz=32, num_updates=19410, lr=4.4729e-05, gnorm=0.434, clip=20, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=121114
2023-01-09 08:38:48 - progress_bar.py[line:274] - INFO: epoch 001:  19447 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4583, wps=60, ups=0.35, wpb=86.4, bsz=32, num_updates=19420, lr=4.47254e-05, gnorm=0.374, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=121143
2023-01-09 08:39:17 - progress_bar.py[line:274] - INFO: epoch 001:  19457 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4452, wps=61, ups=0.34, wpb=88.6, bsz=32, num_updates=19430, lr=4.47219e-05, gnorm=0.33, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=121172
2023-01-09 08:39:46 - progress_bar.py[line:274] - INFO: epoch 001:  19467 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.462, wps=60.2, ups=0.35, wpb=87.1, bsz=32, num_updates=19440, lr=4.47183e-05, gnorm=0.532, clip=10, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=121201
2023-01-09 08:40:14 - progress_bar.py[line:274] - INFO: epoch 001:  19477 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4294, wps=61.7, ups=0.36, wpb=86.2, bsz=32, num_updates=19450, lr=4.47147e-05, gnorm=0.271, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=121229
2023-01-09 08:40:43 - progress_bar.py[line:274] - INFO: epoch 001:  19487 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4756, wps=61, ups=0.35, wpb=87.4, bsz=32, num_updates=19460, lr=4.47112e-05, gnorm=0.278, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=121258
2023-01-09 08:41:13 - progress_bar.py[line:274] - INFO: epoch 001:  19497 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4497, wps=60.6, ups=0.35, wpb=87.6, bsz=32, num_updates=19470, lr=4.47076e-05, gnorm=0.288, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=121288
2023-01-09 08:41:42 - progress_bar.py[line:274] - INFO: epoch 001:  19507 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3567, wps=59.6, ups=0.34, wpb=86.6, bsz=32, num_updates=19480, lr=4.4704e-05, gnorm=0.274, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=121317
2023-01-09 08:42:11 - progress_bar.py[line:274] - INFO: epoch 001:  19517 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3865, wps=60.9, ups=0.35, wpb=87.4, bsz=32, num_updates=19490, lr=4.47005e-05, gnorm=0.293, clip=0, loss_scale=1024, train_wall=29, gb_free=15.7, ema_decay=0.9999, wall=121346
2023-01-09 08:42:40 - progress_bar.py[line:274] - INFO: epoch 001:  19527 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5183, wps=60.6, ups=0.35, wpb=86.7, bsz=32, num_updates=19500, lr=4.46969e-05, gnorm=0.314, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=121375
2023-01-09 08:43:09 - progress_bar.py[line:274] - INFO: epoch 001:  19537 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3949, wps=60.7, ups=0.35, wpb=86.7, bsz=32, num_updates=19510, lr=4.46933e-05, gnorm=0.312, clip=0, loss_scale=1024, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=121404
2023-01-09 08:43:38 - progress_bar.py[line:274] - INFO: epoch 001:  19547 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4566, wps=61.6, ups=0.35, wpb=87.5, bsz=32, num_updates=19520, lr=4.46898e-05, gnorm=0.306, clip=10, loss_scale=1024, train_wall=28, gb_free=15.7, ema_decay=0.9999, wall=121433
2023-01-09 08:44:07 - progress_bar.py[line:274] - INFO: epoch 001:  19557 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4336, wps=61.3, ups=0.35, wpb=88.4, bsz=32, num_updates=19530, lr=4.46862e-05, gnorm=0.609, clip=10, loss_scale=1024, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=121462
2023-01-09 08:44:36 - progress_bar.py[line:274] - INFO: epoch 001:  19567 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4868, wps=61.6, ups=0.35, wpb=88.9, bsz=32, num_updates=19540, lr=4.46826e-05, gnorm=0.595, clip=10, loss_scale=1024, train_wall=29, gb_free=15, ema_decay=0.9999, wall=121491
2023-01-09 08:45:05 - progress_bar.py[line:274] - INFO: epoch 001:  19577 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4777, wps=60.4, ups=0.35, wpb=87.2, bsz=32, num_updates=19550, lr=4.46791e-05, gnorm=0.304, clip=0, loss_scale=1024, train_wall=29, gb_free=14.7, ema_decay=0.9999, wall=121520
2023-01-09 08:45:34 - progress_bar.py[line:274] - INFO: epoch 001:  19587 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.454, wps=61.5, ups=0.35, wpb=86.8, bsz=32, num_updates=19560, lr=4.46755e-05, gnorm=0.365, clip=10, loss_scale=2048, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=121549
2023-01-09 08:46:02 - progress_bar.py[line:274] - INFO: epoch 001:  19597 / 144806 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5526, wps=62.2, ups=0.35, wpb=88.7, bsz=32, num_updates=19570, lr=4.46719e-05, gnorm=0.345, clip=0, loss_scale=2048, train_wall=28, gb_free=15.5, ema_decay=0.9999, wall=121577
2023-01-09 08:46:32 - progress_bar.py[line:274] - INFO: epoch 001:  19607 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4658, wps=60.4, ups=0.34, wpb=88.2, bsz=32, num_updates=19580, lr=4.46684e-05, gnorm=0.253, clip=0, loss_scale=2048, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=121607
2023-01-09 08:47:01 - progress_bar.py[line:274] - INFO: epoch 001:  19617 / 144806 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=89.2, nsentences=32, sample_size=89.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4895, wps=61.3, ups=0.34, wpb=89.2, bsz=32, num_updates=19590, lr=4.46648e-05, gnorm=0.239, clip=0, loss_scale=2048, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=121636
2023-01-09 08:47:30 - progress_bar.py[line:274] - INFO: epoch 001:  19627 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4198, wps=61.1, ups=0.35, wpb=87.8, bsz=32, num_updates=19600, lr=4.46612e-05, gnorm=0.176, clip=0, loss_scale=2048, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=121665
2023-01-09 08:47:59 - progress_bar.py[line:274] - INFO: epoch 001:  19637 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.478, wps=61.2, ups=0.35, wpb=87.4, bsz=32, num_updates=19610, lr=4.46577e-05, gnorm=0.325, clip=0, loss_scale=2048, train_wall=28, gb_free=15.6, ema_decay=0.9999, wall=121694
2023-01-09 08:48:28 - progress_bar.py[line:274] - INFO: epoch 001:  19647 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.462, wps=59.9, ups=0.34, wpb=87, bsz=32, num_updates=19620, lr=4.46541e-05, gnorm=0.385, clip=0, loss_scale=2048, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=121724
2023-01-09 08:48:43 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-09 08:49:00 - progress_bar.py[line:274] - INFO: epoch 001:  19658 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.048, nsentences=32, sample_size=86.048, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4639, wps=57.6, ups=0.32, wpb=86, bsz=32, num_updates=19630, lr=4.46505e-05, gnorm=0.295, clip=0, loss_scale=1024, train_wall=31, gb_free=15.4, ema_decay=0.9999, wall=121755
2023-01-09 08:49:29 - progress_bar.py[line:274] - INFO: epoch 001:  19668 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4313, wps=60.8, ups=0.35, wpb=87.5, bsz=32, num_updates=19640, lr=4.4647e-05, gnorm=0.438, clip=20, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=121784
2023-01-09 08:49:58 - progress_bar.py[line:274] - INFO: epoch 001:  19678 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4968, wps=61.9, ups=0.35, wpb=87.3, bsz=32, num_updates=19650, lr=4.46434e-05, gnorm=0.334, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=121813
2023-01-09 08:50:27 - progress_bar.py[line:274] - INFO: epoch 001:  19688 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4545, wps=59.6, ups=0.34, wpb=86.9, bsz=32, num_updates=19660, lr=4.46398e-05, gnorm=0.211, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=121842
2023-01-09 08:50:56 - progress_bar.py[line:274] - INFO: epoch 001:  19698 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4679, wps=60, ups=0.35, wpb=86.4, bsz=32, num_updates=19670, lr=4.46363e-05, gnorm=0.435, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=121871
2023-01-09 08:51:25 - progress_bar.py[line:274] - INFO: epoch 001:  19708 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4221, wps=59.7, ups=0.34, wpb=86.9, bsz=32, num_updates=19680, lr=4.46327e-05, gnorm=0.338, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=121900
2023-01-09 08:51:54 - progress_bar.py[line:274] - INFO: epoch 001:  19718 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4625, wps=62.2, ups=0.35, wpb=88.5, bsz=32, num_updates=19690, lr=4.46291e-05, gnorm=0.38, clip=0, loss_scale=1024, train_wall=28, gb_free=15.4, ema_decay=0.9999, wall=121929
2023-01-09 08:52:23 - progress_bar.py[line:274] - INFO: epoch 001:  19728 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4405, wps=60.7, ups=0.35, wpb=87, bsz=32, num_updates=19700, lr=4.46256e-05, gnorm=0.364, clip=0, loss_scale=1024, train_wall=29, gb_free=15, ema_decay=0.9999, wall=121958
2023-01-09 08:52:51 - progress_bar.py[line:274] - INFO: epoch 001:  19738 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4575, wps=61.6, ups=0.35, wpb=86.8, bsz=32, num_updates=19710, lr=4.4622e-05, gnorm=0.24, clip=0, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=121987
2023-01-09 08:53:21 - progress_bar.py[line:274] - INFO: epoch 001:  19748 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4242, wps=60.4, ups=0.35, wpb=87.2, bsz=32, num_updates=19720, lr=4.46184e-05, gnorm=0.68, clip=10, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=122016
2023-01-09 08:53:50 - progress_bar.py[line:274] - INFO: epoch 001:  19758 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4615, wps=60.5, ups=0.35, wpb=87.6, bsz=32, num_updates=19730, lr=4.46149e-05, gnorm=0.323, clip=10, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=122045
2023-01-09 08:54:19 - progress_bar.py[line:274] - INFO: epoch 001:  19768 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5064, wps=61.5, ups=0.35, wpb=87.9, bsz=32, num_updates=19740, lr=4.46113e-05, gnorm=0.374, clip=10, loss_scale=1024, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=122074
2023-01-09 08:54:48 - progress_bar.py[line:274] - INFO: epoch 001:  19778 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4201, wps=60.6, ups=0.35, wpb=87.3, bsz=32, num_updates=19750, lr=4.46077e-05, gnorm=0.257, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=122103
2023-01-09 08:55:17 - progress_bar.py[line:274] - INFO: epoch 001:  19788 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4663, wps=61, ups=0.35, wpb=87.6, bsz=32, num_updates=19760, lr=4.46042e-05, gnorm=0.383, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=122132
2023-01-09 08:55:46 - progress_bar.py[line:274] - INFO: epoch 001:  19798 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3688, wps=59.6, ups=0.34, wpb=86.6, bsz=32, num_updates=19770, lr=4.46006e-05, gnorm=0.272, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=122161
2023-01-09 08:56:15 - progress_bar.py[line:274] - INFO: epoch 001:  19808 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=60.8, ups=0.35, wpb=87.2, bsz=32, num_updates=19780, lr=4.4597e-05, gnorm=0.378, clip=10, loss_scale=1024, train_wall=29, gb_free=15.5, ema_decay=0.9999, wall=122190
2023-01-09 08:56:44 - progress_bar.py[line:274] - INFO: epoch 001:  19818 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4305, wps=61.7, ups=0.35, wpb=88.9, bsz=32, num_updates=19790, lr=4.45935e-05, gnorm=0.367, clip=10, loss_scale=1024, train_wall=29, gb_free=14.9, ema_decay=0.9999, wall=122219
2023-01-09 08:57:13 - progress_bar.py[line:274] - INFO: epoch 001:  19828 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4472, wps=61.6, ups=0.35, wpb=87.4, bsz=32, num_updates=19800, lr=4.45899e-05, gnorm=0.437, clip=10, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=122248
2023-01-09 08:57:41 - progress_bar.py[line:274] - INFO: epoch 001:  19838 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4654, wps=61.1, ups=0.35, wpb=87, bsz=32, num_updates=19810, lr=4.45863e-05, gnorm=0.552, clip=20, loss_scale=1024, train_wall=28, gb_free=15.1, ema_decay=0.9999, wall=122276
2023-01-09 08:58:10 - progress_bar.py[line:274] - INFO: epoch 001:  19848 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4458, wps=60.5, ups=0.35, wpb=87.4, bsz=32, num_updates=19820, lr=4.45828e-05, gnorm=0.247, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=122306
2023-01-09 08:58:40 - progress_bar.py[line:274] - INFO: epoch 001:  19858 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4074, wps=60, ups=0.34, wpb=88.4, bsz=32, num_updates=19830, lr=4.45792e-05, gnorm=0.224, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=122335
2023-01-09 08:59:09 - progress_bar.py[line:274] - INFO: epoch 001:  19868 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4793, wps=60.9, ups=0.35, wpb=87.1, bsz=32, num_updates=19840, lr=4.45756e-05, gnorm=0.36, clip=10, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=122364
2023-01-09 08:59:39 - progress_bar.py[line:274] - INFO: epoch 001:  19878 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4651, wps=59.6, ups=0.35, wpb=86.1, bsz=32, num_updates=19850, lr=4.45721e-05, gnorm=0.322, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=122393
2023-01-09 09:00:08 - progress_bar.py[line:274] - INFO: epoch 001:  19888 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4485, wps=59.1, ups=0.34, wpb=86.3, bsz=32, num_updates=19860, lr=4.45685e-05, gnorm=0.314, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=122423
2023-01-09 09:00:37 - progress_bar.py[line:274] - INFO: epoch 001:  19898 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4269, wps=60, ups=0.35, wpb=86.2, bsz=32, num_updates=19870, lr=4.45649e-05, gnorm=0.29, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=122452
2023-01-09 09:01:06 - progress_bar.py[line:274] - INFO: epoch 001:  19908 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3832, wps=61.3, ups=0.35, wpb=87.1, bsz=32, num_updates=19880, lr=4.45614e-05, gnorm=0.314, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=122481
2023-01-09 09:01:36 - progress_bar.py[line:274] - INFO: epoch 001:  19918 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4671, wps=60.4, ups=0.34, wpb=87.8, bsz=32, num_updates=19890, lr=4.45578e-05, gnorm=0.322, clip=0, loss_scale=1024, train_wall=29, gb_free=15.3, ema_decay=0.9999, wall=122510
2023-01-09 09:02:05 - progress_bar.py[line:274] - INFO: epoch 001:  19928 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5093, wps=60.6, ups=0.34, wpb=88.2, bsz=32, num_updates=19900, lr=4.45542e-05, gnorm=0.297, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=122540
2023-01-09 09:02:34 - progress_bar.py[line:274] - INFO: epoch 001:  19938 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4, wps=60.8, ups=0.35, wpb=87.1, bsz=32, num_updates=19910, lr=4.45507e-05, gnorm=0.291, clip=0, loss_scale=1024, train_wall=29, gb_free=15.1, ema_decay=0.9999, wall=122569
2023-01-09 09:03:02 - progress_bar.py[line:274] - INFO: epoch 001:  19948 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3816, wps=61.8, ups=0.35, wpb=87.7, bsz=32, num_updates=19920, lr=4.45471e-05, gnorm=0.27, clip=0, loss_scale=1024, train_wall=28, gb_free=15.3, ema_decay=0.9999, wall=122597
2023-01-09 09:03:31 - progress_bar.py[line:274] - INFO: epoch 001:  19958 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4483, wps=59.9, ups=0.35, wpb=86.1, bsz=32, num_updates=19930, lr=4.45435e-05, gnorm=0.289, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=122626
2023-01-09 09:04:00 - progress_bar.py[line:274] - INFO: epoch 001:  19968 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3718, wps=61.9, ups=0.36, wpb=86.6, bsz=32, num_updates=19940, lr=4.454e-05, gnorm=0.214, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=122655
2023-01-09 09:04:28 - progress_bar.py[line:274] - INFO: epoch 001:  19978 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4724, wps=60.3, ups=0.35, wpb=85.8, bsz=32, num_updates=19950, lr=4.45364e-05, gnorm=0.319, clip=0, loss_scale=1024, train_wall=28, gb_free=15.2, ema_decay=0.9999, wall=122683
2023-01-09 09:04:57 - progress_bar.py[line:274] - INFO: epoch 001:  19988 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=89.3, nsentences=32, sample_size=89.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4277, wps=61.9, ups=0.35, wpb=89.3, bsz=32, num_updates=19960, lr=4.45328e-05, gnorm=0.25, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=122713
2023-01-09 09:05:27 - progress_bar.py[line:274] - INFO: epoch 001:  19998 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4395, wps=60.6, ups=0.35, wpb=87.6, bsz=32, num_updates=19970, lr=4.45293e-05, gnorm=0.277, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=122742
2023-01-09 09:05:56 - progress_bar.py[line:274] - INFO: epoch 001:  20008 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3987, wps=59.5, ups=0.34, wpb=87.5, bsz=32, num_updates=19980, lr=4.45257e-05, gnorm=0.348, clip=0, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=122771
2023-01-09 09:06:26 - progress_bar.py[line:274] - INFO: epoch 001:  20018 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3929, wps=59.8, ups=0.34, wpb=87, bsz=32, num_updates=19990, lr=4.45221e-05, gnorm=0.303, clip=0, loss_scale=1024, train_wall=29, gb_free=15.4, ema_decay=0.9999, wall=122801
2023-01-09 09:06:55 - progress_bar.py[line:274] - INFO: epoch 001:  20028 / 144806 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4795, wps=61.3, ups=0.35, wpb=88.1, bsz=32, num_updates=20000, lr=4.45186e-05, gnorm=0.381, clip=10, loss_scale=1024, train_wall=29, gb_free=15.2, ema_decay=0.9999, wall=122830
2023-01-09 09:06:55 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-09 09:06:56 - train.py[line:549] - INFO: 0 / 6234
2023-01-09 09:06:56 - train.py[line:551] - INFO: load:1.08 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-09 09:06:58 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.30 GiB (GPU 0; 39.59 GiB total capacity; 8.02 GiB already allocated; 2.73 GiB free; 25.27 GiB reserved in total by PyTorch)
2023-01-09 09:06:58 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 7            |        cudaMalloc retries: 42        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8216 MB |    9122 MB |    9976 TB |    9976 TB |
|       from large pool |    8042 MB |    8948 MB |    9971 TB |    9971 TB |
|       from small pool |     174 MB |     174 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8216 MB |    9122 MB |    9976 TB |    9976 TB |
|       from large pool |    8042 MB |    8948 MB |    9971 TB |    9971 TB |
|       from small pool |     174 MB |     174 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   25880 MB |   26616 MB |  507788 MB |  481908 MB |
|       from large pool |   25704 MB |   26436 MB |  506932 MB |  481228 MB |
|       from small pool |     176 MB |     180 MB |     856 MB |     680 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17663 MB |   20781 MB |   12018 TB |   12018 TB |
|       from large pool |   17661 MB |   20778 MB |   12013 TB |   12013 TB |
|       from small pool |       1 MB |       3 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  538566 K  |  538561 K  |
|       from large pool |     698    |     710    |  181831 K  |  181831 K  |
|       from small pool |    3925    |    3943    |  356734 K  |  356730 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  538566 K  |  538561 K  |
|       from large pool |     698    |     710    |  181831 K  |  181831 K  |
|       from small pool |    3925    |    3943    |  356734 K  |  356730 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     153    |     156    |    1478    |    1325    |
|       from large pool |      65    |      66    |    1050    |     985    |
|       from small pool |      88    |      90    |     428    |     340    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     116    |     119    |  400156 K  |  400156 K  |
|       from large pool |      60    |      61    |   97337 K  |   97337 K  |
|       from small pool |      56    |      63    |  302818 K  |  302818 K  |
|===========================================================================|

2023-01-09 09:06:58 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-09 09:06:58 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-09 09:11:11 - train.py[line:549] - INFO: 200 / 6234
2023-01-09 09:11:11 - train.py[line:551] - INFO: load:1.10 valid_run:254.20 task_valid:249.49 collect_output:0.72
2023-01-09 09:15:20 - train.py[line:549] - INFO: 400 / 6234
2023-01-09 09:15:20 - train.py[line:551] - INFO: load:1.13 valid_run:503.25 task_valid:495.28 collect_output:1.41
2023-01-09 09:19:30 - train.py[line:549] - INFO: 600 / 6234
2023-01-09 09:19:30 - train.py[line:551] - INFO: load:1.15 valid_run:753.23 task_valid:741.73 collect_output:2.41
2023-01-09 09:23:36 - train.py[line:549] - INFO: 800 / 6234
2023-01-09 09:23:36 - train.py[line:551] - INFO: load:1.18 valid_run:999.24 task_valid:984.50 collect_output:3.11
2023-01-09 09:27:47 - train.py[line:549] - INFO: 1000 / 6234
2023-01-09 09:27:47 - train.py[line:551] - INFO: load:1.20 valid_run:1250.34 task_valid:1232.32 collect_output:3.81
2023-01-09 09:32:00 - train.py[line:549] - INFO: 1200 / 6234
2023-01-09 09:32:00 - train.py[line:551] - INFO: load:1.23 valid_run:1503.09 task_valid:1481.82 collect_output:4.51
2023-01-09 09:36:12 - train.py[line:549] - INFO: 1400 / 6234
2023-01-09 09:36:12 - train.py[line:551] - INFO: load:1.25 valid_run:1754.94 task_valid:1730.43 collect_output:5.20
2023-01-09 09:40:21 - train.py[line:549] - INFO: 1600 / 6234
2023-01-09 09:40:21 - train.py[line:551] - INFO: load:1.28 valid_run:2004.49 task_valid:1976.76 collect_output:5.88
2023-01-09 09:44:32 - train.py[line:549] - INFO: 1800 / 6234
2023-01-09 09:44:32 - train.py[line:551] - INFO: load:1.30 valid_run:2254.85 task_valid:2223.92 collect_output:6.55
2023-01-09 09:48:36 - train.py[line:549] - INFO: 2000 / 6234
2023-01-09 09:48:36 - train.py[line:551] - INFO: load:1.33 valid_run:2499.14 task_valid:2465.01 collect_output:7.21
2023-01-09 09:52:45 - train.py[line:549] - INFO: 2200 / 6234
2023-01-09 09:52:45 - train.py[line:551] - INFO: load:1.35 valid_run:2747.55 task_valid:2710.19 collect_output:7.87
2023-01-09 09:56:55 - train.py[line:549] - INFO: 2400 / 6234
2023-01-09 09:56:55 - train.py[line:551] - INFO: load:1.38 valid_run:2997.64 task_valid:2957.08 collect_output:8.53
2023-01-09 10:01:00 - train.py[line:549] - INFO: 2600 / 6234
2023-01-09 10:01:00 - train.py[line:551] - INFO: load:1.41 valid_run:3243.04 task_valid:3199.28 collect_output:9.18
2023-01-09 10:05:12 - train.py[line:549] - INFO: 2800 / 6234
2023-01-09 10:05:12 - train.py[line:551] - INFO: load:1.43 valid_run:3494.19 task_valid:3447.23 collect_output:9.83
2023-01-09 10:08:17 - train.py[line:549] - INFO: 3000 / 6234
2023-01-09 10:08:17 - train.py[line:551] - INFO: load:1.46 valid_run:3679.31 task_valid:3628.88 collect_output:11.48
2023-01-09 10:10:18 - train.py[line:549] - INFO: 3200 / 6234
2023-01-09 10:10:18 - train.py[line:551] - INFO: load:1.48 valid_run:3800.57 task_valid:3743.42 collect_output:17.12
2023-01-09 10:12:20 - train.py[line:549] - INFO: 3400 / 6234
2023-01-09 10:12:20 - train.py[line:551] - INFO: load:1.51 valid_run:3921.93 task_valid:3860.04 collect_output:20.82
2023-01-09 10:14:21 - train.py[line:549] - INFO: 3600 / 6234
2023-01-09 10:14:21 - train.py[line:551] - INFO: load:1.54 valid_run:4042.89 task_valid:3978.37 collect_output:22.40
2023-01-09 10:16:22 - train.py[line:549] - INFO: 3800 / 6234
2023-01-09 10:16:22 - train.py[line:551] - INFO: load:1.56 valid_run:4164.39 task_valid:4095.81 collect_output:25.43
2023-01-09 10:18:23 - train.py[line:549] - INFO: 4000 / 6234
2023-01-09 10:18:23 - train.py[line:551] - INFO: load:1.59 valid_run:4284.91 task_valid:4212.90 collect_output:27.85
2023-01-09 10:20:25 - train.py[line:549] - INFO: 4200 / 6234
2023-01-09 10:20:25 - train.py[line:551] - INFO: load:1.61 valid_run:4406.50 task_valid:4329.76 collect_output:31.53
2023-01-09 10:22:27 - train.py[line:549] - INFO: 4400 / 6234
2023-01-09 10:22:27 - train.py[line:551] - INFO: load:1.64 valid_run:4528.41 task_valid:4448.95 collect_output:33.24
2023-01-09 10:24:27 - train.py[line:549] - INFO: 4600 / 6234
2023-01-09 10:24:27 - train.py[line:551] - INFO: load:1.66 valid_run:4648.78 task_valid:4563.64 collect_output:37.90
2023-01-09 10:26:27 - train.py[line:549] - INFO: 4800 / 6234
2023-01-09 10:26:27 - train.py[line:551] - INFO: load:1.69 valid_run:4768.51 task_valid:4680.07 collect_output:40.18
2023-01-09 10:28:29 - train.py[line:549] - INFO: 5000 / 6234
2023-01-09 10:28:29 - train.py[line:551] - INFO: load:1.72 valid_run:4890.22 task_valid:4796.66 collect_output:44.28
2023-01-09 10:30:31 - train.py[line:549] - INFO: 5200 / 6234
2023-01-09 10:30:31 - train.py[line:551] - INFO: load:1.74 valid_run:5012.94 task_valid:4913.02 collect_output:49.60
2023-01-09 10:32:31 - train.py[line:549] - INFO: 5400 / 6234
2023-01-09 10:32:31 - train.py[line:551] - INFO: load:1.77 valid_run:5132.56 task_valid:5027.70 collect_output:53.52
2023-01-09 10:34:33 - train.py[line:549] - INFO: 5600 / 6234
2023-01-09 10:34:33 - train.py[line:551] - INFO: load:1.79 valid_run:5254.60 task_valid:5147.50 collect_output:54.75
2023-01-09 10:36:35 - train.py[line:549] - INFO: 5800 / 6234
2023-01-09 10:36:35 - train.py[line:551] - INFO: load:1.82 valid_run:5376.20 task_valid:5263.59 collect_output:59.22
2023-01-09 10:38:37 - train.py[line:549] - INFO: 6000 / 6234
2023-01-09 10:38:37 - train.py[line:551] - INFO: load:1.85 valid_run:5498.37 task_valid:5382.71 collect_output:61.21
2023-01-09 10:40:39 - train.py[line:549] - INFO: 6200 / 6234
2023-01-09 10:40:39 - train.py[line:551] - INFO: load:1.87 valid_run:5619.95 task_valid:5501.85 collect_output:62.57

====================================================================================================
SGG eval:     R @ 50: 0.3944;     R @ 100: 0.4750;     R @ 500: 0.5156;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2410;    mR @ 100: 0.3086;    mR @ 500: 0.3499;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5951) (covered in:0.7708) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.5098) (says:0.0000) (sitting on:0.7228) (standing on:0.1650) (using:0.6000) (walking in:0.0000) (walking on:0.1982) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3944;     R @ 100: 0.4750;     R @ 500: 0.5156;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2410;    mR @ 100: 0.3086;    mR @ 500: 0.3499;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5951) (covered in:0.7708) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.5098) (says:0.0000) (sitting on:0.7228) (standing on:0.1650) (using:0.6000) (walking in:0.0000) (walking on:0.1982) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-09 10:41:10 - train.py[line:487] - INFO: 0.47496190476190475
2023-01-09 10:41:10 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-09 10:41:10 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.402 | loss_v1 0 | loss_v2 0 | nll_loss 0.252 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.474962 | ppl 1.19 | vqa_score 0.4268 | wps 79.4 | wpb 72 | bsz 24 | num_updates 20000 | best_R@100 0.632103
2023-01-09 10:41:10 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 20000 updates
2023-01-09 10:41:10 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_20000.pt
2023-01-09 10:41:51 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_20000.pt
2023-01-09 10:43:18 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_20000.pt (epoch 1 @ 20000 updates, score 0.47496190476190475) (writing took 127.82652467489243 seconds)
2023-01-09 10:43:36 - progress_bar.py[line:274] - INFO: epoch 001:  20038 / 144806 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4626, wps=0.3, ups=0, wpb=87.2, bsz=32, num_updates=20010, lr=4.4515e-05, gnorm=0.258, clip=0, loss_scale=1024, train_wall=18, gb_free=15, ema_decay=0.9999, wall=128631
2023-01-09 10:43:55 - progress_bar.py[line:274] - INFO: epoch 001:  20048 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4082, wps=98.2, ups=0.55, wpb=88.5, bsz=32, num_updates=20020, lr=4.45114e-05, gnorm=0.376, clip=10, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=128650
2023-01-09 10:44:13 - progress_bar.py[line:274] - INFO: epoch 001:  20058 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.454, wps=97.9, ups=0.56, wpb=87.6, bsz=32, num_updates=20030, lr=4.45079e-05, gnorm=0.313, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=128668
2023-01-09 10:44:31 - progress_bar.py[line:274] - INFO: epoch 001:  20068 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=97.1, ups=0.55, wpb=87.6, bsz=32, num_updates=20040, lr=4.45043e-05, gnorm=0.296, clip=0, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=128686
2023-01-09 10:44:49 - progress_bar.py[line:274] - INFO: epoch 001:  20078 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4713, wps=100.2, ups=0.57, wpb=87.6, bsz=32, num_updates=20050, lr=4.45007e-05, gnorm=0.368, clip=10, loss_scale=1024, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=128704
2023-01-09 10:45:07 - progress_bar.py[line:274] - INFO: epoch 001:  20088 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4151, wps=97.8, ups=0.56, wpb=86.7, bsz=32, num_updates=20060, lr=4.44972e-05, gnorm=0.329, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=128722
2023-01-09 10:45:25 - progress_bar.py[line:274] - INFO: epoch 001:  20098 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4304, wps=99.2, ups=0.57, wpb=87.7, bsz=32, num_updates=20070, lr=4.44936e-05, gnorm=0.362, clip=0, loss_scale=1024, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=128740
2023-01-09 10:45:43 - progress_bar.py[line:274] - INFO: epoch 001:  20108 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4743, wps=96.1, ups=0.55, wpb=86.8, bsz=32, num_updates=20080, lr=4.449e-05, gnorm=0.391, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=128758
2023-01-09 10:46:01 - progress_bar.py[line:274] - INFO: epoch 001:  20118 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4364, wps=97.3, ups=0.57, wpb=85.8, bsz=32, num_updates=20090, lr=4.44865e-05, gnorm=0.237, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=128776
2023-01-09 10:46:18 - progress_bar.py[line:274] - INFO: epoch 001:  20128 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4636, wps=101.6, ups=0.58, wpb=88.1, bsz=32, num_updates=20100, lr=4.44829e-05, gnorm=0.232, clip=0, loss_scale=1024, train_wall=17, gb_free=15.5, ema_decay=0.9999, wall=128794
2023-01-09 10:46:37 - progress_bar.py[line:274] - INFO: epoch 001:  20138 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4362, wps=96.3, ups=0.55, wpb=87.1, bsz=32, num_updates=20110, lr=4.44793e-05, gnorm=0.321, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=128812
2023-01-09 10:46:54 - progress_bar.py[line:274] - INFO: epoch 001:  20148 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.462, wps=100, ups=0.58, wpb=86.5, bsz=32, num_updates=20120, lr=4.44758e-05, gnorm=0.461, clip=20, loss_scale=1024, train_wall=17, gb_free=15.3, ema_decay=0.9999, wall=128829
2023-01-09 10:47:13 - progress_bar.py[line:274] - INFO: epoch 001:  20158 / 144806 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4, wps=97.9, ups=0.56, wpb=87.7, bsz=32, num_updates=20130, lr=4.44722e-05, gnorm=0.397, clip=10, loss_scale=1024, train_wall=18, gb_free=14.9, ema_decay=0.9999, wall=128848
2023-01-09 10:47:31 - progress_bar.py[line:274] - INFO: epoch 001:  20168 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4331, wps=96.9, ups=0.55, wpb=87.5, bsz=32, num_updates=20140, lr=4.44686e-05, gnorm=0.29, clip=0, loss_scale=2048, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=128866
2023-01-09 10:47:49 - progress_bar.py[line:274] - INFO: epoch 001:  20178 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4419, wps=97, ups=0.56, wpb=86, bsz=32, num_updates=20150, lr=4.44651e-05, gnorm=0.311, clip=0, loss_scale=2048, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=128884
2023-01-09 10:48:07 - progress_bar.py[line:274] - INFO: epoch 001:  20188 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3667, wps=100, ups=0.57, wpb=87.1, bsz=32, num_updates=20160, lr=4.44615e-05, gnorm=0.417, clip=0, loss_scale=2048, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=128902
2023-01-09 10:48:24 - progress_bar.py[line:274] - INFO: epoch 001:  20198 / 144806 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4099, wps=100, ups=0.57, wpb=87.2, bsz=32, num_updates=20170, lr=4.44579e-05, gnorm=0.393, clip=0, loss_scale=2048, train_wall=17, gb_free=15.5, ema_decay=0.9999, wall=128919
2023-01-09 10:48:42 - progress_bar.py[line:274] - INFO: epoch 001:  20208 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4562, wps=98.1, ups=0.56, wpb=87.1, bsz=32, num_updates=20180, lr=4.44544e-05, gnorm=0.276, clip=0, loss_scale=2048, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=128937
2023-01-09 10:49:00 - progress_bar.py[line:274] - INFO: epoch 001:  20218 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4747, wps=99.1, ups=0.57, wpb=87.3, bsz=32, num_updates=20190, lr=4.44508e-05, gnorm=0.361, clip=10, loss_scale=2048, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=128955
2023-01-09 10:49:18 - progress_bar.py[line:274] - INFO: epoch 001:  20228 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4286, wps=100.8, ups=0.57, wpb=88, bsz=32, num_updates=20200, lr=4.44472e-05, gnorm=0.304, clip=0, loss_scale=2048, train_wall=17, gb_free=15.3, ema_decay=0.9999, wall=128973
2023-01-09 10:49:36 - progress_bar.py[line:274] - INFO: epoch 001:  20238 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4267, wps=98.5, ups=0.56, wpb=87.3, bsz=32, num_updates=20210, lr=4.44437e-05, gnorm=0.244, clip=0, loss_scale=2048, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=128991
2023-01-09 10:49:54 - progress_bar.py[line:274] - INFO: epoch 001:  20248 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4691, wps=96.4, ups=0.55, wpb=87.2, bsz=32, num_updates=20220, lr=4.44401e-05, gnorm=0.402, clip=0, loss_scale=2048, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129009
2023-01-09 10:50:12 - progress_bar.py[line:274] - INFO: epoch 001:  20258 / 144806 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3892, wps=98.8, ups=0.58, wpb=85.5, bsz=32, num_updates=20230, lr=4.44365e-05, gnorm=0.35, clip=0, loss_scale=2048, train_wall=17, gb_free=15, ema_decay=0.9999, wall=129027
2023-01-09 10:50:30 - progress_bar.py[line:274] - INFO: epoch 001:  20268 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4477, wps=96.2, ups=0.56, wpb=86.2, bsz=32, num_updates=20240, lr=4.4433e-05, gnorm=0.384, clip=10, loss_scale=2048, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=129045
2023-01-09 10:50:48 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-09 10:50:50 - progress_bar.py[line:274] - INFO: epoch 001:  20279 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.81, nsentences=32, sample_size=86.81, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5054, wps=93.3, ups=0.51, wpb=86.8, bsz=32, num_updates=20250, lr=4.44294e-05, gnorm=0.286, clip=0, loss_scale=1024, train_wall=19, gb_free=15.2, ema_decay=0.9999, wall=129065
2023-01-09 10:51:08 - progress_bar.py[line:274] - INFO: epoch 001:  20289 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3929, wps=98.8, ups=0.56, wpb=88.5, bsz=32, num_updates=20260, lr=4.44258e-05, gnorm=0.381, clip=0, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=129083
2023-01-09 10:51:26 - progress_bar.py[line:274] - INFO: epoch 001:  20299 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4251, wps=97.1, ups=0.56, wpb=86.2, bsz=32, num_updates=20270, lr=4.44222e-05, gnorm=0.341, clip=0, loss_scale=1024, train_wall=18, gb_free=15, ema_decay=0.9999, wall=129101
2023-01-09 10:51:43 - progress_bar.py[line:274] - INFO: epoch 001:  20309 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5215, wps=99.8, ups=0.58, wpb=86.4, bsz=32, num_updates=20280, lr=4.44187e-05, gnorm=0.402, clip=10, loss_scale=1024, train_wall=17, gb_free=15.3, ema_decay=0.9999, wall=129118
2023-01-09 10:52:01 - progress_bar.py[line:274] - INFO: epoch 001:  20319 / 144806 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.422, wps=97.7, ups=0.57, wpb=86.1, bsz=32, num_updates=20290, lr=4.44151e-05, gnorm=0.365, clip=0, loss_scale=1024, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=129136
2023-01-09 10:52:19 - progress_bar.py[line:274] - INFO: epoch 001:  20329 / 144806 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4863, wps=98.5, ups=0.56, wpb=87.2, bsz=32, num_updates=20300, lr=4.44115e-05, gnorm=0.22, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=129154
2023-01-09 10:52:37 - progress_bar.py[line:274] - INFO: epoch 001:  20339 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4188, wps=98.3, ups=0.56, wpb=87.6, bsz=32, num_updates=20310, lr=4.4408e-05, gnorm=0.276, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=129172
2023-01-09 10:52:55 - progress_bar.py[line:274] - INFO: epoch 001:  20349 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5488, wps=96.9, ups=0.56, wpb=86.4, bsz=32, num_updates=20320, lr=4.44044e-05, gnorm=0.399, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129190
2023-01-09 10:53:13 - progress_bar.py[line:274] - INFO: epoch 001:  20359 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4151, wps=98.6, ups=0.56, wpb=87.4, bsz=32, num_updates=20330, lr=4.44008e-05, gnorm=0.22, clip=0, loss_scale=1024, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=129208
2023-01-09 10:53:31 - progress_bar.py[line:274] - INFO: epoch 001:  20369 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4367, wps=100.3, ups=0.57, wpb=87.8, bsz=32, num_updates=20340, lr=4.43973e-05, gnorm=0.332, clip=0, loss_scale=1024, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=129226
2023-01-09 10:53:49 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-09 10:53:51 - progress_bar.py[line:274] - INFO: epoch 001:  20380 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.381, nsentences=32, sample_size=86.381, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4277, wps=93.7, ups=0.52, wpb=86.4, bsz=32, num_updates=20350, lr=4.43937e-05, gnorm=0.342, clip=0, loss_scale=512, train_wall=19, gb_free=15.2, ema_decay=0.9999, wall=129246
2023-01-09 10:54:08 - progress_bar.py[line:274] - INFO: epoch 001:  20390 / 144806 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4873, wps=100.1, ups=0.57, wpb=88, bsz=32, num_updates=20360, lr=4.43901e-05, gnorm=0.23, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=129264
2023-01-09 10:54:26 - progress_bar.py[line:274] - INFO: epoch 001:  20400 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4795, wps=97.5, ups=0.56, wpb=86.7, bsz=32, num_updates=20370, lr=4.43866e-05, gnorm=0.186, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129282
2023-01-09 10:54:45 - progress_bar.py[line:274] - INFO: epoch 001:  20410 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4313, wps=97, ups=0.56, wpb=86.5, bsz=32, num_updates=20380, lr=4.4383e-05, gnorm=0.242, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=129300
2023-01-09 10:55:03 - progress_bar.py[line:274] - INFO: epoch 001:  20420 / 144806 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=84.6, nsentences=32, sample_size=84.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4686, wps=94.8, ups=0.56, wpb=84.6, bsz=32, num_updates=20390, lr=4.43794e-05, gnorm=0.299, clip=0, loss_scale=512, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=129318
2023-01-09 10:55:21 - progress_bar.py[line:274] - INFO: epoch 001:  20430 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4204, wps=97.5, ups=0.56, wpb=87.1, bsz=32, num_updates=20400, lr=4.43759e-05, gnorm=0.415, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129336
2023-01-09 10:55:39 - progress_bar.py[line:274] - INFO: epoch 001:  20440 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4755, wps=99.6, ups=0.56, wpb=88.6, bsz=32, num_updates=20410, lr=4.43723e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=129354
2023-01-09 10:55:56 - progress_bar.py[line:274] - INFO: epoch 001:  20450 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4458, wps=99.1, ups=0.57, wpb=86.6, bsz=32, num_updates=20420, lr=4.43687e-05, gnorm=0.513, clip=10, loss_scale=512, train_wall=17, gb_free=15.4, ema_decay=0.9999, wall=129372
2023-01-09 10:56:15 - progress_bar.py[line:274] - INFO: epoch 001:  20460 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4654, wps=97.3, ups=0.56, wpb=87.1, bsz=32, num_updates=20430, lr=4.43652e-05, gnorm=0.54, clip=20, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=129390
2023-01-09 10:56:33 - progress_bar.py[line:274] - INFO: epoch 001:  20470 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4533, wps=98.2, ups=0.56, wpb=87.1, bsz=32, num_updates=20440, lr=4.43616e-05, gnorm=0.262, clip=0, loss_scale=512, train_wall=18, gb_free=15.7, ema_decay=0.9999, wall=129408
2023-01-09 10:56:50 - progress_bar.py[line:274] - INFO: epoch 001:  20480 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4556, wps=99.3, ups=0.56, wpb=88, bsz=32, num_updates=20450, lr=4.4358e-05, gnorm=0.367, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129426
2023-01-09 10:57:08 - progress_bar.py[line:274] - INFO: epoch 001:  20490 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4337, wps=99.6, ups=0.57, wpb=88, bsz=32, num_updates=20460, lr=4.43545e-05, gnorm=0.236, clip=0, loss_scale=512, train_wall=18, gb_free=15, ema_decay=0.9999, wall=129443
2023-01-09 10:57:26 - progress_bar.py[line:274] - INFO: epoch 001:  20500 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4914, wps=97.9, ups=0.57, wpb=86.5, bsz=32, num_updates=20470, lr=4.43509e-05, gnorm=0.239, clip=0, loss_scale=512, train_wall=18, gb_free=14.9, ema_decay=0.9999, wall=129461
2023-01-09 10:57:44 - progress_bar.py[line:274] - INFO: epoch 001:  20510 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.439, wps=97.4, ups=0.56, wpb=86.9, bsz=32, num_updates=20480, lr=4.43473e-05, gnorm=0.403, clip=0, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=129479
2023-01-09 10:58:02 - progress_bar.py[line:274] - INFO: epoch 001:  20520 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3865, wps=98.7, ups=0.57, wpb=86.8, bsz=32, num_updates=20490, lr=4.43438e-05, gnorm=0.331, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=129497
2023-01-09 10:58:20 - progress_bar.py[line:274] - INFO: epoch 001:  20530 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.503, wps=99.3, ups=0.57, wpb=87.6, bsz=32, num_updates=20500, lr=4.43402e-05, gnorm=0.214, clip=0, loss_scale=512, train_wall=18, gb_free=15, ema_decay=0.9999, wall=129515
2023-01-09 10:58:38 - progress_bar.py[line:274] - INFO: epoch 001:  20540 / 144806 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=89.4, nsentences=32, sample_size=89.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.4683, wps=99.3, ups=0.56, wpb=89.4, bsz=32, num_updates=20510, lr=4.43366e-05, gnorm=0.224, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129533
2023-01-09 10:58:56 - progress_bar.py[line:274] - INFO: epoch 001:  20550 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.474, wps=98, ups=0.56, wpb=87.1, bsz=32, num_updates=20520, lr=4.43331e-05, gnorm=0.272, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=129552
2023-01-09 10:59:14 - progress_bar.py[line:274] - INFO: epoch 001:  20560 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5325, wps=99.3, ups=0.56, wpb=88, bsz=32, num_updates=20530, lr=4.43295e-05, gnorm=0.361, clip=10, loss_scale=512, train_wall=18, gb_free=15.6, ema_decay=0.9999, wall=129569
2023-01-09 10:59:32 - progress_bar.py[line:274] - INFO: epoch 001:  20570 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4904, wps=97.9, ups=0.56, wpb=87.2, bsz=32, num_updates=20540, lr=4.43259e-05, gnorm=0.29, clip=0, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=129588
2023-01-09 10:59:50 - progress_bar.py[line:274] - INFO: epoch 001:  20580 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3904, wps=99.7, ups=0.57, wpb=87.7, bsz=32, num_updates=20550, lr=4.43224e-05, gnorm=0.367, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129605
2023-01-09 11:00:08 - progress_bar.py[line:274] - INFO: epoch 001:  20590 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4556, wps=100.2, ups=0.57, wpb=88, bsz=32, num_updates=20560, lr=4.43188e-05, gnorm=0.278, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129623
2023-01-09 11:00:26 - progress_bar.py[line:274] - INFO: epoch 001:  20600 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4514, wps=100.3, ups=0.57, wpb=87.8, bsz=32, num_updates=20570, lr=4.43152e-05, gnorm=0.377, clip=0, loss_scale=512, train_wall=17, gb_free=15.4, ema_decay=0.9999, wall=129641
2023-01-09 11:00:43 - progress_bar.py[line:274] - INFO: epoch 001:  20610 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4843, wps=100.7, ups=0.58, wpb=86.6, bsz=32, num_updates=20580, lr=4.43117e-05, gnorm=0.268, clip=0, loss_scale=512, train_wall=17, gb_free=15, ema_decay=0.9999, wall=129658
2023-01-09 11:01:01 - progress_bar.py[line:274] - INFO: epoch 001:  20620 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4304, wps=98.2, ups=0.57, wpb=86.6, bsz=32, num_updates=20590, lr=4.43081e-05, gnorm=0.286, clip=0, loss_scale=512, train_wall=18, gb_free=14.9, ema_decay=0.9999, wall=129676
2023-01-09 11:01:19 - progress_bar.py[line:274] - INFO: epoch 001:  20630 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4155, wps=99.1, ups=0.56, wpb=88.6, bsz=32, num_updates=20600, lr=4.43045e-05, gnorm=0.307, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=129694
2023-01-09 11:01:37 - progress_bar.py[line:274] - INFO: epoch 001:  20640 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4094, wps=102.8, ups=0.58, wpb=88.8, bsz=32, num_updates=20610, lr=4.4301e-05, gnorm=0.247, clip=0, loss_scale=512, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=129712
2023-01-09 11:01:55 - progress_bar.py[line:274] - INFO: epoch 001:  20650 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.472, wps=99.3, ups=0.56, wpb=87.9, bsz=32, num_updates=20620, lr=4.42974e-05, gnorm=0.355, clip=0, loss_scale=512, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=129730
2023-01-09 11:02:13 - progress_bar.py[line:274] - INFO: epoch 001:  20660 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4863, wps=97.4, ups=0.56, wpb=87.1, bsz=32, num_updates=20630, lr=4.42938e-05, gnorm=0.224, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129748
2023-01-09 11:02:32 - progress_bar.py[line:274] - INFO: epoch 001:  20670 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4545, wps=99.9, ups=0.57, wpb=88, bsz=32, num_updates=20640, lr=4.42903e-05, gnorm=0.272, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129766
2023-01-09 11:02:50 - progress_bar.py[line:274] - INFO: epoch 001:  20680 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5, wps=98.2, ups=0.57, wpb=86.7, bsz=32, num_updates=20650, lr=4.42867e-05, gnorm=0.301, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129785
2023-01-09 11:03:08 - progress_bar.py[line:274] - INFO: epoch 001:  20690 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4072, wps=101.3, ups=0.58, wpb=87.8, bsz=32, num_updates=20660, lr=4.42831e-05, gnorm=0.232, clip=0, loss_scale=512, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=129803
2023-01-09 11:03:27 - progress_bar.py[line:274] - INFO: epoch 001:  20700 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4485, wps=98.6, ups=0.56, wpb=88.3, bsz=32, num_updates=20670, lr=4.42796e-05, gnorm=0.453, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129821
2023-01-09 11:03:45 - progress_bar.py[line:274] - INFO: epoch 001:  20710 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4783, wps=98.6, ups=0.57, wpb=87.2, bsz=32, num_updates=20680, lr=4.4276e-05, gnorm=0.675, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129840
2023-01-09 11:04:03 - progress_bar.py[line:274] - INFO: epoch 001:  20720 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4833, wps=99.4, ups=0.57, wpb=86.8, bsz=32, num_updates=20690, lr=4.42724e-05, gnorm=0.245, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=129858
2023-01-09 11:04:21 - progress_bar.py[line:274] - INFO: epoch 001:  20730 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4653, wps=99, ups=0.56, wpb=88.1, bsz=32, num_updates=20700, lr=4.42689e-05, gnorm=0.353, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129876
2023-01-09 11:04:40 - progress_bar.py[line:274] - INFO: epoch 001:  20740 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4817, wps=97.5, ups=0.56, wpb=86.3, bsz=32, num_updates=20710, lr=4.42653e-05, gnorm=0.356, clip=0, loss_scale=512, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=129894
2023-01-09 11:04:58 - progress_bar.py[line:274] - INFO: epoch 001:  20750 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4375, wps=97.8, ups=0.56, wpb=87.4, bsz=32, num_updates=20720, lr=4.42617e-05, gnorm=0.226, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=129913
2023-01-09 11:05:17 - progress_bar.py[line:274] - INFO: epoch 001:  20760 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4422, wps=98.3, ups=0.56, wpb=88.2, bsz=32, num_updates=20730, lr=4.42582e-05, gnorm=0.227, clip=0, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=129931
2023-01-09 11:05:35 - progress_bar.py[line:274] - INFO: epoch 001:  20770 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.42, wps=97, ups=0.56, wpb=86.9, bsz=32, num_updates=20740, lr=4.42546e-05, gnorm=0.422, clip=20, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=129950
2023-01-09 11:05:54 - progress_bar.py[line:274] - INFO: epoch 001:  20780 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5321, wps=98.7, ups=0.57, wpb=87.2, bsz=32, num_updates=20750, lr=4.4251e-05, gnorm=0.695, clip=10, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=129968
2023-01-09 11:06:12 - progress_bar.py[line:274] - INFO: epoch 001:  20790 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4182, wps=99.1, ups=0.57, wpb=87.1, bsz=32, num_updates=20760, lr=4.42475e-05, gnorm=0.255, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=129987
2023-01-09 11:06:30 - progress_bar.py[line:274] - INFO: epoch 001:  20800 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4768, wps=99.7, ups=0.57, wpb=88, bsz=32, num_updates=20770, lr=4.42439e-05, gnorm=0.271, clip=0, loss_scale=512, train_wall=18, gb_free=14.9, ema_decay=0.9999, wall=130005
2023-01-09 11:06:48 - progress_bar.py[line:274] - INFO: epoch 001:  20810 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4805, wps=97.6, ups=0.56, wpb=87.2, bsz=32, num_updates=20780, lr=4.42403e-05, gnorm=0.281, clip=0, loss_scale=512, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=130023
2023-01-09 11:07:07 - progress_bar.py[line:274] - INFO: epoch 001:  20820 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4106, wps=99.3, ups=0.56, wpb=88, bsz=32, num_updates=20790, lr=4.42368e-05, gnorm=0.341, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=130041
2023-01-09 11:07:25 - progress_bar.py[line:274] - INFO: epoch 001:  20830 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4294, wps=97.5, ups=0.56, wpb=86.9, bsz=32, num_updates=20800, lr=4.42332e-05, gnorm=0.324, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=130060
2023-01-09 11:07:44 - progress_bar.py[line:274] - INFO: epoch 001:  20840 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4658, wps=99.8, ups=0.57, wpb=87.1, bsz=32, num_updates=20810, lr=4.42296e-05, gnorm=0.288, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=130078
2023-01-09 11:08:02 - progress_bar.py[line:274] - INFO: epoch 001:  20850 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4611, wps=98, ups=0.57, wpb=85.9, bsz=32, num_updates=20820, lr=4.42261e-05, gnorm=0.257, clip=0, loss_scale=512, train_wall=17, gb_free=15.3, ema_decay=0.9999, wall=130096
2023-01-09 11:08:20 - progress_bar.py[line:274] - INFO: epoch 001:  20860 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3567, wps=95.9, ups=0.55, wpb=86.5, bsz=32, num_updates=20830, lr=4.42225e-05, gnorm=0.236, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=130115
2023-01-09 11:08:39 - progress_bar.py[line:274] - INFO: epoch 001:  20870 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4845, wps=97.2, ups=0.55, wpb=87.9, bsz=32, num_updates=20840, lr=4.42189e-05, gnorm=0.358, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=130134
2023-01-09 11:08:57 - progress_bar.py[line:274] - INFO: epoch 001:  20880 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.46, wps=100.1, ups=0.57, wpb=87.7, bsz=32, num_updates=20850, lr=4.42154e-05, gnorm=0.437, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=130152
2023-01-09 11:09:15 - progress_bar.py[line:274] - INFO: epoch 001:  20890 / 144806 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5168, wps=101.2, ups=0.57, wpb=88.3, bsz=32, num_updates=20860, lr=4.42118e-05, gnorm=0.257, clip=0, loss_scale=512, train_wall=17, gb_free=15.4, ema_decay=0.9999, wall=130170
2023-01-09 11:09:33 - progress_bar.py[line:274] - INFO: epoch 001:  20900 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4675, wps=97.5, ups=0.56, wpb=86.4, bsz=32, num_updates=20870, lr=4.42082e-05, gnorm=0.227, clip=0, loss_scale=1024, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=130188
2023-01-09 11:09:52 - progress_bar.py[line:274] - INFO: epoch 001:  20910 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.472, wps=97.3, ups=0.56, wpb=87.3, bsz=32, num_updates=20880, lr=4.42047e-05, gnorm=0.236, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=130207
2023-01-09 11:10:10 - progress_bar.py[line:274] - INFO: epoch 001:  20920 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4586, wps=100, ups=0.57, wpb=88, bsz=32, num_updates=20890, lr=4.42011e-05, gnorm=0.267, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=130225
2023-01-09 11:10:29 - progress_bar.py[line:274] - INFO: epoch 001:  20930 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4464, wps=96.1, ups=0.55, wpb=87.1, bsz=32, num_updates=20900, lr=4.41975e-05, gnorm=0.422, clip=10, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=130244
2023-01-09 11:10:47 - progress_bar.py[line:274] - INFO: epoch 001:  20940 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5223, wps=98.6, ups=0.57, wpb=86.8, bsz=32, num_updates=20910, lr=4.4194e-05, gnorm=0.247, clip=0, loss_scale=1024, train_wall=18, gb_free=15.6, ema_decay=0.9999, wall=130262
2023-01-09 11:11:05 - progress_bar.py[line:274] - INFO: epoch 001:  20950 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4323, wps=98.2, ups=0.57, wpb=86.6, bsz=32, num_updates=20920, lr=4.41904e-05, gnorm=0.468, clip=20, loss_scale=1024, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=130280
2023-01-09 11:11:24 - progress_bar.py[line:274] - INFO: epoch 001:  20960 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4324, wps=100, ups=0.56, wpb=88.6, bsz=32, num_updates=20930, lr=4.41868e-05, gnorm=0.336, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=130298
2023-01-09 11:11:42 - progress_bar.py[line:274] - INFO: epoch 001:  20970 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.432, wps=99.3, ups=0.57, wpb=87.2, bsz=32, num_updates=20940, lr=4.41833e-05, gnorm=0.301, clip=0, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=130316
2023-01-09 11:12:00 - progress_bar.py[line:274] - INFO: epoch 001:  20980 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.46, wps=99.8, ups=0.57, wpb=88.3, bsz=32, num_updates=20950, lr=4.41797e-05, gnorm=0.568, clip=30, loss_scale=1024, train_wall=18, gb_free=14.6, ema_decay=0.9999, wall=130335
2023-01-09 11:12:19 - progress_bar.py[line:274] - INFO: epoch 001:  20990 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4313, wps=99.4, ups=0.57, wpb=87.5, bsz=32, num_updates=20960, lr=4.41761e-05, gnorm=0.257, clip=0, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=130353
2023-01-09 11:12:37 - progress_bar.py[line:274] - INFO: epoch 001:  21000 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3609, wps=98.5, ups=0.57, wpb=87, bsz=32, num_updates=20970, lr=4.41726e-05, gnorm=0.368, clip=10, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=130372
2023-01-09 11:12:55 - progress_bar.py[line:274] - INFO: epoch 001:  21010 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5168, wps=98.9, ups=0.56, wpb=88.2, bsz=32, num_updates=20980, lr=4.4169e-05, gnorm=0.363, clip=10, loss_scale=1024, train_wall=18, gb_free=15, ema_decay=0.9999, wall=130390
2023-01-09 11:13:14 - progress_bar.py[line:274] - INFO: epoch 001:  21020 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4458, wps=98.8, ups=0.56, wpb=87.9, bsz=32, num_updates=20990, lr=4.41654e-05, gnorm=0.252, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=130409
2023-01-09 11:13:33 - progress_bar.py[line:274] - INFO: epoch 001:  21030 / 144806 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5, wps=98.2, ups=0.56, wpb=87.6, bsz=32, num_updates=21000, lr=4.41619e-05, gnorm=0.244, clip=0, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=130427
2023-01-09 11:13:40 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-09 11:13:53 - progress_bar.py[line:274] - INFO: epoch 001:  21041 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.81, nsentences=32, sample_size=88.81, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3851, wps=96.5, ups=0.52, wpb=88.8, bsz=32, num_updates=21010, lr=4.41583e-05, gnorm=0.269, clip=0, loss_scale=512, train_wall=19, gb_free=15.2, ema_decay=0.9999, wall=130447
2023-01-09 11:14:11 - progress_bar.py[line:274] - INFO: epoch 001:  21051 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5402, wps=100, ups=0.58, wpb=86.4, bsz=32, num_updates=21020, lr=4.41547e-05, gnorm=0.21, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=130465
2023-01-09 11:14:29 - progress_bar.py[line:274] - INFO: epoch 001:  21061 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5122, wps=98.1, ups=0.56, wpb=87.2, bsz=32, num_updates=21030, lr=4.41512e-05, gnorm=0.541, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=130484
2023-01-09 11:14:47 - progress_bar.py[line:274] - INFO: epoch 001:  21071 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4012, wps=99, ups=0.58, wpb=86, bsz=32, num_updates=21040, lr=4.41476e-05, gnorm=0.201, clip=0, loss_scale=512, train_wall=17, gb_free=15.6, ema_decay=0.9999, wall=130502
2023-01-09 11:15:06 - progress_bar.py[line:274] - INFO: epoch 001:  21081 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3922, wps=97.3, ups=0.56, wpb=86.4, bsz=32, num_updates=21050, lr=4.4144e-05, gnorm=0.312, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=130520
2023-01-09 11:15:24 - progress_bar.py[line:274] - INFO: epoch 001:  21091 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.557, wps=102.4, ups=0.58, wpb=88.5, bsz=32, num_updates=21060, lr=4.41405e-05, gnorm=0.27, clip=0, loss_scale=512, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=130538
2023-01-09 11:15:42 - progress_bar.py[line:274] - INFO: epoch 001:  21101 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4082, wps=101.8, ups=0.58, wpb=88, bsz=32, num_updates=21070, lr=4.41369e-05, gnorm=0.412, clip=10, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=130557
2023-01-09 11:16:01 - progress_bar.py[line:274] - INFO: epoch 001:  21111 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.425, wps=98.2, ups=0.56, wpb=88.2, bsz=32, num_updates=21080, lr=4.41333e-05, gnorm=0.327, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=130575
2023-01-09 11:16:19 - progress_bar.py[line:274] - INFO: epoch 001:  21121 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5185, wps=96.9, ups=0.55, wpb=87.8, bsz=32, num_updates=21090, lr=4.41298e-05, gnorm=0.347, clip=10, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=130594
2023-01-09 11:16:38 - progress_bar.py[line:274] - INFO: epoch 001:  21131 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4024, wps=99.3, ups=0.57, wpb=87.2, bsz=32, num_updates=21100, lr=4.41262e-05, gnorm=0.354, clip=10, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=130612
2023-01-09 11:16:58 - progress_bar.py[line:274] - INFO: epoch 001:  21141 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4082, wps=99.9, ups=0.57, wpb=88, bsz=32, num_updates=21110, lr=4.41226e-05, gnorm=0.181, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=130631
2023-01-09 11:17:16 - progress_bar.py[line:274] - INFO: epoch 001:  21151 / 144806 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4265, wps=100.5, ups=0.57, wpb=88.3, bsz=32, num_updates=21120, lr=4.41191e-05, gnorm=0.224, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=130651
2023-01-09 11:17:34 - progress_bar.py[line:274] - INFO: epoch 001:  21161 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4405, wps=98.8, ups=0.57, wpb=87.1, bsz=32, num_updates=21130, lr=4.41155e-05, gnorm=0.279, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=130669
2023-01-09 11:17:53 - progress_bar.py[line:274] - INFO: epoch 001:  21171 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4568, wps=98.6, ups=0.56, wpb=87.5, bsz=32, num_updates=21140, lr=4.41119e-05, gnorm=0.441, clip=20, loss_scale=512, train_wall=18, gb_free=15, ema_decay=0.9999, wall=130687
2023-01-09 11:18:11 - progress_bar.py[line:274] - INFO: epoch 001:  21181 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3962, wps=101.4, ups=0.58, wpb=87.5, bsz=32, num_updates=21150, lr=4.41084e-05, gnorm=0.418, clip=0, loss_scale=512, train_wall=17, gb_free=15, ema_decay=0.9999, wall=130705
2023-01-09 11:18:29 - progress_bar.py[line:274] - INFO: epoch 001:  21191 / 144806 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4539, wps=98, ups=0.56, wpb=87.7, bsz=32, num_updates=21160, lr=4.41048e-05, gnorm=0.28, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=130724
2023-01-09 11:18:47 - progress_bar.py[line:274] - INFO: epoch 001:  21201 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4903, wps=102.6, ups=0.58, wpb=87.9, bsz=32, num_updates=21170, lr=4.41012e-05, gnorm=0.271, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=130742
2023-01-09 11:19:05 - progress_bar.py[line:274] - INFO: epoch 001:  21211 / 144806 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=85.5, nsentences=32, sample_size=85.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.5116, wps=96.8, ups=0.57, wpb=85.5, bsz=32, num_updates=21180, lr=4.40977e-05, gnorm=0.52, clip=20, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=130760
2023-01-09 11:19:24 - progress_bar.py[line:274] - INFO: epoch 001:  21221 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3987, wps=98.9, ups=0.57, wpb=87.5, bsz=32, num_updates=21190, lr=4.40941e-05, gnorm=0.35, clip=10, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=130778
2023-01-09 11:19:42 - progress_bar.py[line:274] - INFO: epoch 001:  21231 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5185, wps=98.7, ups=0.56, wpb=88.9, bsz=32, num_updates=21200, lr=4.40905e-05, gnorm=0.27, clip=0, loss_scale=512, train_wall=18, gb_free=15, ema_decay=0.9999, wall=130797
2023-01-09 11:20:01 - progress_bar.py[line:274] - INFO: epoch 001:  21241 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4241, wps=98.5, ups=0.57, wpb=86.3, bsz=32, num_updates=21210, lr=4.40869e-05, gnorm=0.289, clip=10, loss_scale=512, train_wall=17, gb_free=15.3, ema_decay=0.9999, wall=130815
2023-01-09 11:20:19 - progress_bar.py[line:274] - INFO: epoch 001:  21251 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4688, wps=97.7, ups=0.55, wpb=88.1, bsz=32, num_updates=21220, lr=4.40834e-05, gnorm=0.415, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=130834
2023-01-09 11:20:38 - progress_bar.py[line:274] - INFO: epoch 001:  21261 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4911, wps=97.8, ups=0.56, wpb=87, bsz=32, num_updates=21230, lr=4.40798e-05, gnorm=0.351, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=130852
2023-01-09 11:20:56 - progress_bar.py[line:274] - INFO: epoch 001:  21271 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4362, wps=100.8, ups=0.57, wpb=88, bsz=32, num_updates=21240, lr=4.40762e-05, gnorm=0.257, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=130871
2023-01-09 11:21:14 - progress_bar.py[line:274] - INFO: epoch 001:  21281 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4364, wps=99.5, ups=0.57, wpb=87.3, bsz=32, num_updates=21250, lr=4.40727e-05, gnorm=0.265, clip=0, loss_scale=512, train_wall=17, gb_free=15, ema_decay=0.9999, wall=130889
2023-01-09 11:21:32 - progress_bar.py[line:274] - INFO: epoch 001:  21291 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4125, wps=100.3, ups=0.58, wpb=86.6, bsz=32, num_updates=21260, lr=4.40691e-05, gnorm=0.203, clip=0, loss_scale=512, train_wall=17, gb_free=15, ema_decay=0.9999, wall=130907
2023-01-09 11:21:50 - progress_bar.py[line:274] - INFO: epoch 001:  21301 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3951, wps=99.1, ups=0.57, wpb=86.6, bsz=32, num_updates=21270, lr=4.40655e-05, gnorm=0.198, clip=0, loss_scale=512, train_wall=17, gb_free=15, ema_decay=0.9999, wall=130925
2023-01-09 11:22:09 - progress_bar.py[line:274] - INFO: epoch 001:  21311 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4551, wps=96.4, ups=0.55, wpb=86.9, bsz=32, num_updates=21280, lr=4.4062e-05, gnorm=0.38, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=130944
2023-01-09 11:22:27 - progress_bar.py[line:274] - INFO: epoch 001:  21321 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5122, wps=98, ups=0.57, wpb=86.7, bsz=32, num_updates=21290, lr=4.40584e-05, gnorm=0.402, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=130962
2023-01-09 11:22:45 - progress_bar.py[line:274] - INFO: epoch 001:  21331 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4819, wps=97.1, ups=0.56, wpb=86.1, bsz=32, num_updates=21300, lr=4.40548e-05, gnorm=0.519, clip=10, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=130980
2023-01-09 11:23:03 - progress_bar.py[line:274] - INFO: epoch 001:  21341 / 144806 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=89.1, nsentences=32, sample_size=89.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.507, wps=101.6, ups=0.57, wpb=89.1, bsz=32, num_updates=21310, lr=4.40513e-05, gnorm=0.283, clip=10, loss_scale=512, train_wall=17, gb_free=15.3, ema_decay=0.9999, wall=130998
2023-01-09 11:23:21 - progress_bar.py[line:274] - INFO: epoch 001:  21351 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4451, wps=97.5, ups=0.56, wpb=86.8, bsz=32, num_updates=21320, lr=4.40477e-05, gnorm=0.29, clip=0, loss_scale=512, train_wall=18, gb_free=14.6, ema_decay=0.9999, wall=131016
2023-01-09 11:23:39 - progress_bar.py[line:274] - INFO: epoch 001:  21361 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4489, wps=97.6, ups=0.56, wpb=86.4, bsz=32, num_updates=21330, lr=4.40441e-05, gnorm=0.449, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131034
2023-01-09 11:23:57 - progress_bar.py[line:274] - INFO: epoch 001:  21371 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.404, wps=98.2, ups=0.56, wpb=87.3, bsz=32, num_updates=21340, lr=4.40406e-05, gnorm=0.342, clip=10, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=131052
2023-01-09 11:24:15 - progress_bar.py[line:274] - INFO: epoch 001:  21381 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4872, wps=98.6, ups=0.57, wpb=87.1, bsz=32, num_updates=21350, lr=4.4037e-05, gnorm=0.282, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131070
2023-01-09 11:24:33 - progress_bar.py[line:274] - INFO: epoch 001:  21391 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4573, wps=99.4, ups=0.57, wpb=87.4, bsz=32, num_updates=21360, lr=4.40334e-05, gnorm=0.212, clip=0, loss_scale=512, train_wall=18, gb_free=15, ema_decay=0.9999, wall=131088
2023-01-09 11:24:50 - progress_bar.py[line:274] - INFO: epoch 001:  21401 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5061, wps=100.7, ups=0.57, wpb=88.1, bsz=32, num_updates=21370, lr=4.40299e-05, gnorm=0.355, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=131105
2023-01-09 11:25:08 - progress_bar.py[line:274] - INFO: epoch 001:  21411 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4188, wps=99.1, ups=0.57, wpb=87.1, bsz=32, num_updates=21380, lr=4.40263e-05, gnorm=0.397, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131123
2023-01-09 11:25:26 - progress_bar.py[line:274] - INFO: epoch 001:  21421 / 144806 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5329, wps=99.3, ups=0.56, wpb=88, bsz=32, num_updates=21390, lr=4.40227e-05, gnorm=0.279, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131141
2023-01-09 11:25:44 - progress_bar.py[line:274] - INFO: epoch 001:  21431 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.474, wps=98.2, ups=0.56, wpb=87.1, bsz=32, num_updates=21400, lr=4.40192e-05, gnorm=0.421, clip=10, loss_scale=512, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=131159
2023-01-09 11:26:02 - progress_bar.py[line:274] - INFO: epoch 001:  21441 / 144806 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4359, wps=99, ups=0.56, wpb=88.4, bsz=32, num_updates=21410, lr=4.40156e-05, gnorm=0.258, clip=0, loss_scale=512, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=131177
2023-01-09 11:26:20 - progress_bar.py[line:274] - INFO: epoch 001:  21451 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.404, wps=99.7, ups=0.56, wpb=88.8, bsz=32, num_updates=21420, lr=4.4012e-05, gnorm=0.414, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131196
2023-01-09 11:26:39 - progress_bar.py[line:274] - INFO: epoch 001:  21461 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4465, wps=99.3, ups=0.56, wpb=88.1, bsz=32, num_updates=21430, lr=4.40085e-05, gnorm=0.347, clip=0, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=131214
2023-01-09 11:26:57 - progress_bar.py[line:274] - INFO: epoch 001:  21471 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4695, wps=97.6, ups=0.56, wpb=87.2, bsz=32, num_updates=21440, lr=4.40049e-05, gnorm=0.256, clip=0, loss_scale=512, train_wall=18, gb_free=15, ema_decay=0.9999, wall=131232
2023-01-09 11:27:15 - progress_bar.py[line:274] - INFO: epoch 001:  21481 / 144806 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5197, wps=99.5, ups=0.56, wpb=88.4, bsz=32, num_updates=21450, lr=4.40013e-05, gnorm=0.329, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=131250
2023-01-09 11:27:33 - progress_bar.py[line:274] - INFO: epoch 001:  21491 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3939, wps=100.4, ups=0.57, wpb=87.7, bsz=32, num_updates=21460, lr=4.39978e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=17, gb_free=15.3, ema_decay=0.9999, wall=131268
2023-01-09 11:27:51 - progress_bar.py[line:274] - INFO: epoch 001:  21501 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=97.9, ups=0.57, wpb=86.3, bsz=32, num_updates=21470, lr=4.39942e-05, gnorm=0.313, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131286
2023-01-09 11:28:08 - progress_bar.py[line:274] - INFO: epoch 001:  21511 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4813, wps=100, ups=0.57, wpb=87.5, bsz=32, num_updates=21480, lr=4.39906e-05, gnorm=0.342, clip=10, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=131303
2023-01-09 11:28:26 - progress_bar.py[line:274] - INFO: epoch 001:  21521 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4662, wps=100.8, ups=0.57, wpb=88.4, bsz=32, num_updates=21490, lr=4.39871e-05, gnorm=0.285, clip=0, loss_scale=512, train_wall=17, gb_free=15.5, ema_decay=0.9999, wall=131321
2023-01-09 11:28:44 - progress_bar.py[line:274] - INFO: epoch 001:  21531 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4937, wps=98.5, ups=0.57, wpb=87.1, bsz=32, num_updates=21500, lr=4.39835e-05, gnorm=0.214, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131339
2023-01-09 11:29:02 - progress_bar.py[line:274] - INFO: epoch 001:  21541 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4824, wps=97.6, ups=0.56, wpb=87.2, bsz=32, num_updates=21510, lr=4.39799e-05, gnorm=0.271, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=131357
2023-01-09 11:29:20 - progress_bar.py[line:274] - INFO: epoch 001:  21551 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4938, wps=98, ups=0.57, wpb=86.7, bsz=32, num_updates=21520, lr=4.39764e-05, gnorm=0.292, clip=0, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=131375
2023-01-09 11:29:38 - progress_bar.py[line:274] - INFO: epoch 001:  21561 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4878, wps=98.6, ups=0.57, wpb=85.9, bsz=32, num_updates=21530, lr=4.39728e-05, gnorm=0.524, clip=10, loss_scale=1024, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=131393
2023-01-09 11:29:56 - progress_bar.py[line:274] - INFO: epoch 001:  21571 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4259, wps=96.4, ups=0.56, wpb=86.8, bsz=32, num_updates=21540, lr=4.39692e-05, gnorm=0.207, clip=0, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=131411
2023-01-09 11:30:14 - progress_bar.py[line:274] - INFO: epoch 001:  21581 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4241, wps=98.3, ups=0.56, wpb=87.5, bsz=32, num_updates=21550, lr=4.39657e-05, gnorm=0.234, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131430
2023-01-09 11:30:32 - progress_bar.py[line:274] - INFO: epoch 001:  21591 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4268, wps=99.7, ups=0.57, wpb=87.5, bsz=32, num_updates=21560, lr=4.39621e-05, gnorm=0.303, clip=0, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=131447
2023-01-09 11:30:50 - progress_bar.py[line:274] - INFO: epoch 001:  21601 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4258, wps=101.7, ups=0.58, wpb=88.1, bsz=32, num_updates=21570, lr=4.39585e-05, gnorm=0.221, clip=0, loss_scale=1024, train_wall=17, gb_free=15.4, ema_decay=0.9999, wall=131465
2023-01-09 11:31:08 - progress_bar.py[line:274] - INFO: epoch 001:  21611 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4645, wps=99.2, ups=0.56, wpb=88.9, bsz=32, num_updates=21580, lr=4.3955e-05, gnorm=0.192, clip=0, loss_scale=1024, train_wall=18, gb_free=15, ema_decay=0.9999, wall=131483
2023-01-09 11:31:26 - progress_bar.py[line:274] - INFO: epoch 001:  21621 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4663, wps=95.3, ups=0.55, wpb=86, bsz=32, num_updates=21590, lr=4.39514e-05, gnorm=0.324, clip=10, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131502
2023-01-09 11:31:44 - progress_bar.py[line:274] - INFO: epoch 001:  21631 / 144806 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=85.2, nsentences=32, sample_size=85.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4101, wps=97.7, ups=0.57, wpb=85.2, bsz=32, num_updates=21600, lr=4.39478e-05, gnorm=0.262, clip=0, loss_scale=1024, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=131519
2023-01-09 11:32:03 - progress_bar.py[line:274] - INFO: epoch 001:  21641 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5269, wps=97.2, ups=0.56, wpb=86.2, bsz=32, num_updates=21610, lr=4.39443e-05, gnorm=0.419, clip=10, loss_scale=1024, train_wall=18, gb_free=14.6, ema_decay=0.9999, wall=131538
2023-01-09 11:32:21 - progress_bar.py[line:274] - INFO: epoch 001:  21651 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4412, wps=98.8, ups=0.57, wpb=87, bsz=32, num_updates=21620, lr=4.39407e-05, gnorm=0.468, clip=10, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131556
2023-01-09 11:32:39 - progress_bar.py[line:274] - INFO: epoch 001:  21661 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4356, wps=97.1, ups=0.55, wpb=87.7, bsz=32, num_updates=21630, lr=4.39371e-05, gnorm=0.359, clip=10, loss_scale=1024, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=131574
2023-01-09 11:32:57 - progress_bar.py[line:274] - INFO: epoch 001:  21671 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.439, wps=100.4, ups=0.57, wpb=87.6, bsz=32, num_updates=21640, lr=4.39336e-05, gnorm=0.301, clip=0, loss_scale=1024, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=131592
2023-01-09 11:33:15 - progress_bar.py[line:274] - INFO: epoch 001:  21681 / 144806 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4724, wps=97.8, ups=0.56, wpb=87.8, bsz=32, num_updates=21650, lr=4.393e-05, gnorm=0.219, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131610
2023-01-09 11:33:33 - progress_bar.py[line:274] - INFO: epoch 001:  21691 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.488, wps=95.9, ups=0.56, wpb=86.4, bsz=32, num_updates=21660, lr=4.39264e-05, gnorm=0.285, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131628
2023-01-09 11:33:49 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-09 11:33:53 - progress_bar.py[line:274] - INFO: epoch 001:  21702 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.095, nsentences=32, sample_size=87.095, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.459, wps=92.8, ups=0.51, wpb=87.1, bsz=32, num_updates=21670, lr=4.39229e-05, gnorm=0.251, clip=0, loss_scale=512, train_wall=20, gb_free=15.5, ema_decay=0.9999, wall=131648
2023-01-09 11:34:11 - progress_bar.py[line:274] - INFO: epoch 001:  21712 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4518, wps=99.6, ups=0.57, wpb=86.9, bsz=32, num_updates=21680, lr=4.39193e-05, gnorm=0.277, clip=10, loss_scale=512, train_wall=17, gb_free=15.3, ema_decay=0.9999, wall=131666
2023-01-09 11:34:29 - progress_bar.py[line:274] - INFO: epoch 001:  21722 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4371, wps=99, ups=0.57, wpb=87.2, bsz=32, num_updates=21690, lr=4.39157e-05, gnorm=0.314, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131684
2023-01-09 11:34:47 - progress_bar.py[line:274] - INFO: epoch 001:  21732 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4204, wps=99, ups=0.56, wpb=87.9, bsz=32, num_updates=21700, lr=4.39122e-05, gnorm=0.253, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131702
2023-01-09 11:35:05 - progress_bar.py[line:274] - INFO: epoch 001:  21742 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=89, nsentences=32, sample_size=89, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4568, wps=101.2, ups=0.57, wpb=89, bsz=32, num_updates=21710, lr=4.39086e-05, gnorm=0.402, clip=0, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=131720
2023-01-09 11:35:23 - progress_bar.py[line:274] - INFO: epoch 001:  21752 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4049, wps=97, ups=0.56, wpb=86.1, bsz=32, num_updates=21720, lr=4.3905e-05, gnorm=0.193, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=131738
2023-01-09 11:35:41 - progress_bar.py[line:274] - INFO: epoch 001:  21762 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4726, wps=98, ups=0.56, wpb=87.7, bsz=32, num_updates=21730, lr=4.39015e-05, gnorm=0.407, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131756
2023-01-09 11:36:00 - progress_bar.py[line:274] - INFO: epoch 001:  21772 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4238, wps=98.4, ups=0.56, wpb=88, bsz=32, num_updates=21740, lr=4.38979e-05, gnorm=0.305, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=131775
2023-01-09 11:36:18 - progress_bar.py[line:274] - INFO: epoch 001:  21782 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.42, wps=97.5, ups=0.56, wpb=87.5, bsz=32, num_updates=21750, lr=4.38943e-05, gnorm=0.357, clip=0, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=131793
2023-01-09 11:36:36 - progress_bar.py[line:274] - INFO: epoch 001:  21792 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4231, wps=99.9, ups=0.57, wpb=87.7, bsz=32, num_updates=21760, lr=4.38908e-05, gnorm=0.348, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131811
2023-01-09 11:36:54 - progress_bar.py[line:274] - INFO: epoch 001:  21802 / 144806 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4348, wps=101.2, ups=0.57, wpb=88.8, bsz=32, num_updates=21770, lr=4.38872e-05, gnorm=0.238, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=131829
2023-01-09 11:37:12 - progress_bar.py[line:274] - INFO: epoch 001:  21812 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=89.2, nsentences=32, sample_size=89.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4333, wps=100.5, ups=0.56, wpb=89.2, bsz=32, num_updates=21780, lr=4.38836e-05, gnorm=0.392, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131847
2023-01-09 11:37:30 - progress_bar.py[line:274] - INFO: epoch 001:  21822 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.443, wps=99.4, ups=0.57, wpb=87.3, bsz=32, num_updates=21790, lr=4.38801e-05, gnorm=0.205, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=131865
2023-01-09 11:37:48 - progress_bar.py[line:274] - INFO: epoch 001:  21832 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4242, wps=98.6, ups=0.56, wpb=87.4, bsz=32, num_updates=21800, lr=4.38765e-05, gnorm=0.309, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=131883
2023-01-09 11:38:06 - progress_bar.py[line:274] - INFO: epoch 001:  21842 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4012, wps=95.9, ups=0.56, wpb=86.1, bsz=32, num_updates=21810, lr=4.38729e-05, gnorm=0.353, clip=10, loss_scale=512, train_wall=18, gb_free=15, ema_decay=0.9999, wall=131901
2023-01-09 11:38:24 - progress_bar.py[line:274] - INFO: epoch 001:  21852 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=85.2, nsentences=32, sample_size=85.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4438, wps=96.8, ups=0.57, wpb=85.2, bsz=32, num_updates=21820, lr=4.38694e-05, gnorm=0.307, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131919
2023-01-09 11:38:42 - progress_bar.py[line:274] - INFO: epoch 001:  21862 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4393, wps=98.8, ups=0.57, wpb=86.8, bsz=32, num_updates=21830, lr=4.38658e-05, gnorm=0.336, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=131937
2023-01-09 11:39:00 - progress_bar.py[line:274] - INFO: epoch 001:  21872 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4747, wps=98.3, ups=0.56, wpb=87.2, bsz=32, num_updates=21840, lr=4.38622e-05, gnorm=0.315, clip=0, loss_scale=512, train_wall=18, gb_free=15, ema_decay=0.9999, wall=131955
2023-01-09 11:39:18 - progress_bar.py[line:274] - INFO: epoch 001:  21882 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4225, wps=99, ups=0.56, wpb=87.9, bsz=32, num_updates=21850, lr=4.38587e-05, gnorm=0.879, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=131973
2023-01-09 11:39:36 - progress_bar.py[line:274] - INFO: epoch 001:  21892 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4688, wps=100.6, ups=0.58, wpb=87, bsz=32, num_updates=21860, lr=4.38551e-05, gnorm=0.377, clip=0, loss_scale=512, train_wall=17, gb_free=15, ema_decay=0.9999, wall=131991
2023-01-09 11:39:54 - progress_bar.py[line:274] - INFO: epoch 001:  21902 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4934, wps=99.3, ups=0.57, wpb=87.2, bsz=32, num_updates=21870, lr=4.38515e-05, gnorm=0.343, clip=10, loss_scale=512, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=132009
2023-01-09 11:40:12 - progress_bar.py[line:274] - INFO: epoch 001:  21912 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4035, wps=96.1, ups=0.56, wpb=86, bsz=32, num_updates=21880, lr=4.3848e-05, gnorm=0.384, clip=10, loss_scale=512, train_wall=18, gb_free=15.6, ema_decay=0.9999, wall=132027
2023-01-09 11:40:30 - progress_bar.py[line:274] - INFO: epoch 001:  21922 / 144806 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4414, wps=102.8, ups=0.58, wpb=88.9, bsz=32, num_updates=21890, lr=4.38444e-05, gnorm=0.193, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=132045
2023-01-09 11:40:48 - progress_bar.py[line:274] - INFO: epoch 001:  21932 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4329, wps=97.3, ups=0.56, wpb=86.8, bsz=32, num_updates=21900, lr=4.38408e-05, gnorm=0.412, clip=10, loss_scale=512, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=132063
2023-01-09 11:41:06 - progress_bar.py[line:274] - INFO: epoch 001:  21942 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4878, wps=99.2, ups=0.57, wpb=87.3, bsz=32, num_updates=21910, lr=4.38373e-05, gnorm=0.579, clip=10, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=132081
2023-01-09 11:41:24 - progress_bar.py[line:274] - INFO: epoch 001:  21952 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4074, wps=97.2, ups=0.55, wpb=87.7, bsz=32, num_updates=21920, lr=4.38337e-05, gnorm=0.462, clip=20, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=132099
2023-01-09 11:41:42 - progress_bar.py[line:274] - INFO: epoch 001:  21962 / 144806 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4615, wps=98.5, ups=0.56, wpb=87.9, bsz=32, num_updates=21930, lr=4.38301e-05, gnorm=0.765, clip=20, loss_scale=512, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=132117
2023-01-09 11:42:00 - progress_bar.py[line:274] - INFO: epoch 001:  21972 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4025, wps=98.9, ups=0.56, wpb=87.7, bsz=32, num_updates=21940, lr=4.38266e-05, gnorm=0.24, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=132135
2023-01-09 11:42:19 - progress_bar.py[line:274] - INFO: epoch 001:  21982 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4052, wps=96.9, ups=0.56, wpb=86.9, bsz=32, num_updates=21950, lr=4.3823e-05, gnorm=0.279, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=132154
2023-01-09 11:42:36 - progress_bar.py[line:274] - INFO: epoch 001:  21992 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4659, wps=97.8, ups=0.57, wpb=85.8, bsz=32, num_updates=21960, lr=4.38194e-05, gnorm=0.479, clip=10, loss_scale=512, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=132171
2023-01-09 11:42:54 - progress_bar.py[line:274] - INFO: epoch 001:  22002 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4375, wps=99.3, ups=0.57, wpb=87.5, bsz=32, num_updates=21970, lr=4.38159e-05, gnorm=0.256, clip=0, loss_scale=512, train_wall=18, gb_free=14.8, ema_decay=0.9999, wall=132189
2023-01-09 11:43:13 - progress_bar.py[line:274] - INFO: epoch 001:  22012 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4485, wps=98.3, ups=0.56, wpb=88, bsz=32, num_updates=21980, lr=4.38123e-05, gnorm=0.267, clip=0, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=132208
2023-01-09 11:43:31 - progress_bar.py[line:274] - INFO: epoch 001:  22022 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5031, wps=97.1, ups=0.56, wpb=86.8, bsz=32, num_updates=21990, lr=4.38087e-05, gnorm=0.214, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=132226
2023-01-09 11:43:49 - progress_bar.py[line:274] - INFO: epoch 001:  22032 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4013, wps=98.8, ups=0.57, wpb=86.9, bsz=32, num_updates=22000, lr=4.38052e-05, gnorm=0.367, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=132244
2023-01-09 11:43:49 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-09 11:43:50 - train.py[line:549] - INFO: 0 / 6234
2023-01-09 11:43:50 - train.py[line:551] - INFO: load:0.89 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-09 11:45:53 - train.py[line:549] - INFO: 200 / 6234
2023-01-09 11:45:53 - train.py[line:551] - INFO: load:0.91 valid_run:123.05 task_valid:120.44 collect_output:1.55
2023-01-09 11:47:53 - train.py[line:549] - INFO: 400 / 6234
2023-01-09 11:47:53 - train.py[line:551] - INFO: load:0.94 valid_run:242.87 task_valid:236.54 collect_output:4.25
2023-01-09 11:49:55 - train.py[line:549] - INFO: 600 / 6234
2023-01-09 11:49:55 - train.py[line:551] - INFO: load:0.96 valid_run:364.74 task_valid:353.47 collect_output:8.14
2023-01-09 11:51:57 - train.py[line:549] - INFO: 800 / 6234
2023-01-09 11:51:57 - train.py[line:551] - INFO: load:0.99 valid_run:486.52 task_valid:467.69 collect_output:14.66
2023-01-09 11:53:58 - train.py[line:549] - INFO: 1000 / 6234
2023-01-09 11:53:58 - train.py[line:551] - INFO: load:1.01 valid_run:607.13 task_valid:585.50 collect_output:16.42
2023-01-09 11:56:01 - train.py[line:549] - INFO: 1200 / 6234
2023-01-09 11:56:01 - train.py[line:551] - INFO: load:1.04 valid_run:730.07 task_valid:704.64 collect_output:19.19
2023-01-09 11:58:04 - train.py[line:549] - INFO: 1400 / 6234
2023-01-09 11:58:04 - train.py[line:551] - INFO: load:1.06 valid_run:853.08 task_valid:823.19 collect_output:22.60
2023-01-09 12:00:06 - train.py[line:549] - INFO: 1600 / 6234
2023-01-09 12:00:06 - train.py[line:551] - INFO: load:1.09 valid_run:975.13 task_valid:940.42 collect_output:26.39
2023-01-09 12:02:10 - train.py[line:549] - INFO: 1800 / 6234
2023-01-09 12:02:10 - train.py[line:551] - INFO: load:1.12 valid_run:1098.81 task_valid:1058.35 collect_output:31.09
2023-01-09 12:04:11 - train.py[line:549] - INFO: 2000 / 6234
2023-01-09 12:04:12 - train.py[line:551] - INFO: load:1.15 valid_run:1220.39 task_valid:1171.77 collect_output:38.18
2023-01-09 12:06:12 - train.py[line:549] - INFO: 2200 / 6234
2023-01-09 12:06:12 - train.py[line:551] - INFO: load:1.17 valid_run:1340.61 task_valid:1287.91 collect_output:41.22
2023-01-09 12:08:14 - train.py[line:549] - INFO: 2400 / 6234
2023-01-09 12:08:14 - train.py[line:551] - INFO: load:1.20 valid_run:1462.26 task_valid:1405.46 collect_output:44.27
2023-01-09 12:10:13 - train.py[line:549] - INFO: 2600 / 6234
2023-01-09 12:10:13 - train.py[line:551] - INFO: load:1.22 valid_run:1581.36 task_valid:1519.80 collect_output:47.99
2023-01-09 12:12:14 - train.py[line:549] - INFO: 2800 / 6234
2023-01-09 12:12:14 - train.py[line:551] - INFO: load:1.25 valid_run:1702.46 task_valid:1638.01 collect_output:49.86
2023-01-09 12:14:15 - train.py[line:549] - INFO: 3000 / 6234
2023-01-09 12:14:15 - train.py[line:551] - INFO: load:1.27 valid_run:1823.37 task_valid:1754.63 collect_output:53.12
2023-01-09 12:16:16 - train.py[line:549] - INFO: 3200 / 6234
2023-01-09 12:16:16 - train.py[line:551] - INFO: load:1.30 valid_run:1944.39 task_valid:1869.13 collect_output:58.58
2023-01-09 12:18:17 - train.py[line:549] - INFO: 3400 / 6234
2023-01-09 12:18:17 - train.py[line:551] - INFO: load:1.33 valid_run:2065.78 task_valid:1985.79 collect_output:62.27
2023-01-09 12:20:18 - train.py[line:549] - INFO: 3600 / 6234
2023-01-09 12:20:18 - train.py[line:551] - INFO: load:1.35 valid_run:2186.69 task_valid:2104.17 collect_output:63.75
2023-01-09 12:22:20 - train.py[line:549] - INFO: 3800 / 6234
2023-01-09 12:22:20 - train.py[line:551] - INFO: load:1.38 valid_run:2308.09 task_valid:2221.58 collect_output:66.71
2023-01-09 12:24:21 - train.py[line:549] - INFO: 4000 / 6234
2023-01-09 12:24:21 - train.py[line:551] - INFO: load:1.40 valid_run:2428.62 task_valid:2338.68 collect_output:69.11
2023-01-09 12:26:22 - train.py[line:549] - INFO: 4200 / 6234
2023-01-09 12:26:22 - train.py[line:551] - INFO: load:1.43 valid_run:2550.27 task_valid:2455.63 collect_output:72.78
2023-01-09 12:28:24 - train.py[line:549] - INFO: 4400 / 6234
2023-01-09 12:28:24 - train.py[line:551] - INFO: load:1.45 valid_run:2672.41 task_valid:2575.01 collect_output:74.51
2023-01-09 12:30:25 - train.py[line:549] - INFO: 4600 / 6234
2023-01-09 12:30:25 - train.py[line:551] - INFO: load:1.48 valid_run:2792.85 task_valid:2689.94 collect_output:78.99
2023-01-09 12:32:25 - train.py[line:549] - INFO: 4800 / 6234
2023-01-09 12:32:25 - train.py[line:551] - INFO: load:1.50 valid_run:2912.67 task_valid:2806.59 collect_output:81.13
2023-01-09 12:34:27 - train.py[line:549] - INFO: 5000 / 6234
2023-01-09 12:34:27 - train.py[line:551] - INFO: load:1.53 valid_run:3034.23 task_valid:2923.24 collect_output:85.01
2023-01-09 12:36:29 - train.py[line:549] - INFO: 5200 / 6234
2023-01-09 12:36:29 - train.py[line:551] - INFO: load:1.55 valid_run:3156.96 task_valid:3039.78 collect_output:90.16
2023-01-09 12:38:29 - train.py[line:549] - INFO: 5400 / 6234
2023-01-09 12:38:29 - train.py[line:551] - INFO: load:1.58 valid_run:3276.70 task_valid:3154.44 collect_output:94.21
2023-01-09 12:40:31 - train.py[line:549] - INFO: 5600 / 6234
2023-01-09 12:40:31 - train.py[line:551] - INFO: load:1.61 valid_run:3398.93 task_valid:3274.32 collect_output:95.56
2023-01-09 12:42:33 - train.py[line:549] - INFO: 5800 / 6234
2023-01-09 12:42:33 - train.py[line:551] - INFO: load:1.63 valid_run:3520.61 task_valid:3390.49 collect_output:100.03
2023-01-09 12:44:36 - train.py[line:549] - INFO: 6000 / 6234
2023-01-09 12:44:36 - train.py[line:551] - INFO: load:1.66 valid_run:3642.83 task_valid:3509.59 collect_output:102.09
2023-01-09 12:46:37 - train.py[line:549] - INFO: 6200 / 6234
2023-01-09 12:46:37 - train.py[line:551] - INFO: load:1.68 valid_run:3764.23 task_valid:3628.64 collect_output:103.41

====================================================================================================
SGG eval:     R @ 50: 0.3825;     R @ 100: 0.4577;     R @ 500: 0.4961;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2347;    mR @ 100: 0.2968;    mR @ 500: 0.3313;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4610) (covered in:0.6458) (covering:0.3714) (eating:0.5588) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.4592) (says:0.0000) (sitting on:0.7126) (standing on:0.1550) (using:0.6500) (walking in:0.0000) (walking on:0.1802) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3825;     R @ 100: 0.4577;     R @ 500: 0.4961;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2347;    mR @ 100: 0.2968;    mR @ 500: 0.3313;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4610) (covered in:0.6458) (covering:0.3714) (eating:0.5588) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.4592) (says:0.0000) (sitting on:0.7126) (standing on:0.1550) (using:0.6500) (walking in:0.0000) (walking on:0.1802) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-09 12:47:08 - train.py[line:487] - INFO: 0.45766190476190477
2023-01-09 12:47:08 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-09 12:47:09 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.376 | loss_v1 0 | loss_v2 0 | nll_loss 0.224 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.457662 | ppl 1.17 | vqa_score 0.4065 | wps 118.1 | wpb 72 | bsz 24 | num_updates 22000 | best_R@100 0.632103
2023-01-09 12:47:09 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 22000 updates
2023-01-09 12:47:09 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_22000.pt
2023-01-09 12:47:51 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_22000.pt
2023-01-09 12:49:19 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.9_alpha1.0/1_B16_A1_E1_0.032_5e-5_480/checkpoint_1_22000.pt (epoch 1 @ 22000 updates, score 0.45766190476190477) (writing took 129.88963957503438 seconds)
2023-01-09 12:49:37 - progress_bar.py[line:274] - INFO: epoch 001:  22042 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4839, wps=0.4, ups=0, wpb=88.3, bsz=32, num_updates=22010, lr=4.38016e-05, gnorm=0.378, clip=0, loss_scale=512, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=136192
2023-01-09 12:49:55 - progress_bar.py[line:274] - INFO: epoch 001:  22052 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4186, wps=97, ups=0.56, wpb=86.6, bsz=32, num_updates=22020, lr=4.3798e-05, gnorm=0.217, clip=0, loss_scale=512, train_wall=18, gb_free=15, ema_decay=0.9999, wall=136210
2023-01-09 12:50:13 - progress_bar.py[line:274] - INFO: epoch 001:  22062 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4405, wps=98.6, ups=0.56, wpb=87.4, bsz=32, num_updates=22030, lr=4.37945e-05, gnorm=0.288, clip=10, loss_scale=512, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=136228
2023-01-09 12:50:31 - progress_bar.py[line:274] - INFO: epoch 001:  22072 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=84.8, nsentences=32, sample_size=84.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4691, wps=96.9, ups=0.57, wpb=84.8, bsz=32, num_updates=22040, lr=4.37909e-05, gnorm=0.335, clip=0, loss_scale=512, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=136246
2023-01-09 12:50:49 - progress_bar.py[line:274] - INFO: epoch 001:  22082 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5253, wps=98.2, ups=0.57, wpb=86.3, bsz=32, num_updates=22050, lr=4.37873e-05, gnorm=0.415, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=136264
2023-01-09 12:51:07 - progress_bar.py[line:274] - INFO: epoch 001:  22092 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4091, wps=97.1, ups=0.56, wpb=86.6, bsz=32, num_updates=22060, lr=4.37838e-05, gnorm=0.282, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=136282
2023-01-09 12:51:25 - progress_bar.py[line:274] - INFO: epoch 001:  22102 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.474, wps=99.3, ups=0.56, wpb=88.2, bsz=32, num_updates=22070, lr=4.37802e-05, gnorm=0.4, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=136300
2023-01-09 12:51:42 - progress_bar.py[line:274] - INFO: epoch 001:  22112 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4311, wps=99.7, ups=0.58, wpb=86.1, bsz=32, num_updates=22080, lr=4.37766e-05, gnorm=0.266, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=136317
2023-01-09 12:52:01 - progress_bar.py[line:274] - INFO: epoch 001:  22122 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4677, wps=96.1, ups=0.56, wpb=86.2, bsz=32, num_updates=22090, lr=4.37731e-05, gnorm=0.352, clip=10, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=136336
2023-01-09 12:52:18 - progress_bar.py[line:274] - INFO: epoch 001:  22132 / 144806 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=89.2, nsentences=32, sample_size=89.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4698, wps=101.6, ups=0.57, wpb=89.2, bsz=32, num_updates=22100, lr=4.37695e-05, gnorm=0.27, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=136353
2023-01-09 12:52:36 - progress_bar.py[line:274] - INFO: epoch 001:  22142 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4345, wps=100.2, ups=0.57, wpb=87.9, bsz=32, num_updates=22110, lr=4.37659e-05, gnorm=0.254, clip=0, loss_scale=512, train_wall=17, gb_free=15.5, ema_decay=0.9999, wall=136371
2023-01-09 12:52:54 - progress_bar.py[line:274] - INFO: epoch 001:  22152 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.4, nsentences=32, sample_size=85.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4059, wps=99, ups=0.58, wpb=85.4, bsz=32, num_updates=22120, lr=4.37624e-05, gnorm=0.302, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=136389
2023-01-09 12:53:11 - progress_bar.py[line:274] - INFO: epoch 001:  22162 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4596, wps=99.7, ups=0.57, wpb=86.7, bsz=32, num_updates=22130, lr=4.37588e-05, gnorm=0.173, clip=0, loss_scale=512, train_wall=17, gb_free=15.4, ema_decay=0.9999, wall=136406
2023-01-09 12:53:30 - progress_bar.py[line:274] - INFO: epoch 001:  22172 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4539, wps=98.1, ups=0.56, wpb=88, bsz=32, num_updates=22140, lr=4.37552e-05, gnorm=0.233, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=136425
2023-01-09 12:53:47 - progress_bar.py[line:274] - INFO: epoch 001:  22182 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4074, wps=100.6, ups=0.58, wpb=87.2, bsz=32, num_updates=22150, lr=4.37516e-05, gnorm=0.345, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=136442
2023-01-09 12:54:05 - progress_bar.py[line:274] - INFO: epoch 001:  22192 / 144806 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4702, wps=101, ups=0.58, wpb=87.4, bsz=32, num_updates=22160, lr=4.37481e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=17, gb_free=14.6, ema_decay=0.9999, wall=136460
2023-01-09 12:54:22 - progress_bar.py[line:274] - INFO: epoch 001:  22202 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5167, wps=99.7, ups=0.58, wpb=86.1, bsz=32, num_updates=22170, lr=4.37445e-05, gnorm=0.296, clip=0, loss_scale=512, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=136477
2023-01-09 12:54:40 - progress_bar.py[line:274] - INFO: epoch 001:  22212 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4076, wps=99.1, ups=0.56, wpb=87.9, bsz=32, num_updates=22180, lr=4.37409e-05, gnorm=0.245, clip=10, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=136495
2023-01-09 12:54:58 - progress_bar.py[line:274] - INFO: epoch 001:  22222 / 144806 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4797, wps=100, ups=0.57, wpb=88, bsz=32, num_updates=22190, lr=4.37374e-05, gnorm=0.288, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=136513
2023-01-09 12:55:16 - progress_bar.py[line:274] - INFO: epoch 001:  22232 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4491, wps=97.1, ups=0.56, wpb=86.1, bsz=32, num_updates=22200, lr=4.37338e-05, gnorm=0.314, clip=0, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=136531
2023-01-09 12:55:34 - progress_bar.py[line:274] - INFO: epoch 001:  22242 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4231, wps=100.7, ups=0.57, wpb=88.2, bsz=32, num_updates=22210, lr=4.37302e-05, gnorm=0.14, clip=0, loss_scale=1024, train_wall=17, gb_free=15.4, ema_decay=0.9999, wall=136549
2023-01-09 12:55:52 - progress_bar.py[line:274] - INFO: epoch 001:  22252 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4909, wps=101.8, ups=0.58, wpb=88.5, bsz=32, num_updates=22220, lr=4.37267e-05, gnorm=0.42, clip=0, loss_scale=1024, train_wall=17, gb_free=15.4, ema_decay=0.9999, wall=136567
2023-01-09 12:56:10 - progress_bar.py[line:274] - INFO: epoch 001:  22262 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3924, wps=97.8, ups=0.56, wpb=87.7, bsz=32, num_updates=22230, lr=4.37231e-05, gnorm=0.262, clip=10, loss_scale=1024, train_wall=18, gb_free=15, ema_decay=0.9999, wall=136585
2023-01-09 12:56:28 - progress_bar.py[line:274] - INFO: epoch 001:  22272 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4313, wps=99.4, ups=0.57, wpb=87.6, bsz=32, num_updates=22240, lr=4.37195e-05, gnorm=0.168, clip=0, loss_scale=1024, train_wall=18, gb_free=15, ema_decay=0.9999, wall=136603
2023-01-09 12:56:46 - progress_bar.py[line:274] - INFO: epoch 001:  22282 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3665, wps=98.9, ups=0.56, wpb=87.8, bsz=32, num_updates=22250, lr=4.3716e-05, gnorm=0.228, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=136621
2023-01-09 12:57:03 - progress_bar.py[line:274] - INFO: epoch 001:  22292 / 144806 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4783, wps=100.8, ups=0.58, wpb=86.7, bsz=32, num_updates=22260, lr=4.37124e-05, gnorm=0.216, clip=0, loss_scale=1024, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=136638
2023-01-09 12:57:22 - progress_bar.py[line:274] - INFO: epoch 001:  22302 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4636, wps=98, ups=0.56, wpb=87.7, bsz=32, num_updates=22270, lr=4.37088e-05, gnorm=0.281, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=136657
2023-01-09 12:57:39 - progress_bar.py[line:274] - INFO: epoch 001:  22312 / 144806 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4494, wps=100.5, ups=0.57, wpb=87.8, bsz=32, num_updates=22280, lr=4.37053e-05, gnorm=0.195, clip=0, loss_scale=1024, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=136674
2023-01-09 12:57:58 - progress_bar.py[line:274] - INFO: epoch 001:  22322 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5102, wps=98.1, ups=0.56, wpb=88, bsz=32, num_updates=22290, lr=4.37017e-05, gnorm=0.284, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=136692
2023-01-09 12:58:16 - progress_bar.py[line:274] - INFO: epoch 001:  22332 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=85.6, nsentences=32, sample_size=85.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3829, wps=96.3, ups=0.56, wpb=85.6, bsz=32, num_updates=22300, lr=4.36981e-05, gnorm=0.214, clip=0, loss_scale=1024, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=136711
2023-01-09 12:58:34 - progress_bar.py[line:274] - INFO: epoch 001:  22342 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4783, wps=98.1, ups=0.57, wpb=86.4, bsz=32, num_updates=22310, lr=4.36946e-05, gnorm=0.355, clip=10, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=136728
2023-01-09 12:58:51 - progress_bar.py[line:274] - INFO: epoch 001:  22352 / 144806 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4255, wps=101.4, ups=0.57, wpb=88.5, bsz=32, num_updates=22320, lr=4.3691e-05, gnorm=0.244, clip=0, loss_scale=1024, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=136746
2023-01-09 12:59:09 - progress_bar.py[line:274] - INFO: epoch 001:  22362 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5061, wps=98, ups=0.56, wpb=86.9, bsz=32, num_updates=22330, lr=4.36874e-05, gnorm=0.218, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=136764
2023-01-09 12:59:27 - progress_bar.py[line:274] - INFO: epoch 001:  22372 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=86.2, nsentences=32, sample_size=86.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4353, wps=97.1, ups=0.56, wpb=86.2, bsz=32, num_updates=22340, lr=4.36839e-05, gnorm=0.508, clip=10, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=136782
2023-01-09 12:59:46 - progress_bar.py[line:274] - INFO: epoch 001:  22382 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=89.5, nsentences=32, sample_size=89.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4189, wps=99.7, ups=0.56, wpb=89.5, bsz=32, num_updates=22350, lr=4.36803e-05, gnorm=0.238, clip=0, loss_scale=1024, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=136801
2023-01-09 13:00:03 - progress_bar.py[line:274] - INFO: epoch 001:  22392 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3871, wps=100.2, ups=0.58, wpb=86.6, bsz=32, num_updates=22360, lr=4.36767e-05, gnorm=0.325, clip=0, loss_scale=1024, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=136818
2023-01-09 13:00:21 - progress_bar.py[line:274] - INFO: epoch 001:  22402 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4819, wps=97.8, ups=0.56, wpb=87.6, bsz=32, num_updates=22370, lr=4.36732e-05, gnorm=0.231, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=136836
2023-01-09 13:00:40 - progress_bar.py[line:274] - INFO: epoch 001:  22412 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4258, wps=98, ups=0.56, wpb=87.7, bsz=32, num_updates=22380, lr=4.36696e-05, gnorm=0.328, clip=0, loss_scale=1024, train_wall=18, gb_free=15, ema_decay=0.9999, wall=136855
2023-01-09 13:00:58 - progress_bar.py[line:274] - INFO: epoch 001:  22422 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4688, wps=98, ups=0.56, wpb=87.9, bsz=32, num_updates=22390, lr=4.3666e-05, gnorm=0.346, clip=0, loss_scale=1024, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=136873
2023-01-09 13:01:16 - progress_bar.py[line:274] - INFO: epoch 001:  22432 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4717, wps=100.2, ups=0.57, wpb=87.5, bsz=32, num_updates=22400, lr=4.36625e-05, gnorm=0.252, clip=0, loss_scale=1024, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=136891
2023-01-09 13:01:34 - progress_bar.py[line:274] - INFO: epoch 001:  22442 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=98.5, ups=0.57, wpb=87, bsz=32, num_updates=22410, lr=4.36589e-05, gnorm=0.323, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=136909
2023-01-09 13:01:52 - progress_bar.py[line:274] - INFO: epoch 001:  22452 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3855, wps=96.2, ups=0.55, wpb=86.8, bsz=32, num_updates=22420, lr=4.36553e-05, gnorm=0.298, clip=0, loss_scale=1024, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=136927
2023-01-09 13:02:10 - progress_bar.py[line:274] - INFO: epoch 001:  22462 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.451, wps=98.1, ups=0.56, wpb=88.3, bsz=32, num_updates=22430, lr=4.36518e-05, gnorm=0.442, clip=10, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=136945
2023-01-09 13:02:28 - progress_bar.py[line:274] - INFO: epoch 001:  22472 / 144806 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4189, wps=98.7, ups=0.56, wpb=87.4, bsz=32, num_updates=22440, lr=4.36482e-05, gnorm=0.175, clip=0, loss_scale=1024, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=136963
2023-01-09 13:02:46 - progress_bar.py[line:274] - INFO: epoch 001:  22482 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4688, wps=97.2, ups=0.56, wpb=86.3, bsz=32, num_updates=22450, lr=4.36446e-05, gnorm=0.274, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=136981
2023-01-09 13:03:04 - progress_bar.py[line:274] - INFO: epoch 001:  22492 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5163, wps=100, ups=0.57, wpb=87.7, bsz=32, num_updates=22460, lr=4.36411e-05, gnorm=0.215, clip=0, loss_scale=1024, train_wall=17, gb_free=15, ema_decay=0.9999, wall=136999
2023-01-09 13:03:22 - progress_bar.py[line:274] - INFO: epoch 001:  22502 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4691, wps=98, ups=0.56, wpb=86.8, bsz=32, num_updates=22470, lr=4.36375e-05, gnorm=0.315, clip=10, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=137017
2023-01-09 13:03:40 - progress_bar.py[line:274] - INFO: epoch 001:  22512 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3846, wps=97.4, ups=0.56, wpb=87.3, bsz=32, num_updates=22480, lr=4.36339e-05, gnorm=0.302, clip=10, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137035
2023-01-09 13:03:58 - progress_bar.py[line:274] - INFO: epoch 001:  22522 / 144806 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4083, wps=97.9, ups=0.56, wpb=87.7, bsz=32, num_updates=22490, lr=4.36304e-05, gnorm=0.448, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137053
2023-01-09 13:04:16 - progress_bar.py[line:274] - INFO: epoch 001:  22532 / 144806 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3941, wps=97, ups=0.57, wpb=85.8, bsz=32, num_updates=22500, lr=4.36268e-05, gnorm=0.302, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137071
2023-01-09 13:04:34 - progress_bar.py[line:274] - INFO: epoch 001:  22542 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3861, wps=99.6, ups=0.57, wpb=87.6, bsz=32, num_updates=22510, lr=4.36232e-05, gnorm=0.258, clip=0, loss_scale=1024, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=137089
2023-01-09 13:04:52 - progress_bar.py[line:274] - INFO: epoch 001:  22552 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3576, wps=98.5, ups=0.56, wpb=87.4, bsz=32, num_updates=22520, lr=4.36197e-05, gnorm=0.218, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137107
2023-01-09 13:05:10 - progress_bar.py[line:274] - INFO: epoch 001:  22562 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4808, wps=99.6, ups=0.57, wpb=86.8, bsz=32, num_updates=22530, lr=4.36161e-05, gnorm=0.203, clip=0, loss_scale=1024, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=137125
2023-01-09 13:05:28 - progress_bar.py[line:274] - INFO: epoch 001:  22572 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4161, wps=99.2, ups=0.57, wpb=87.4, bsz=32, num_updates=22540, lr=4.36125e-05, gnorm=0.234, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137143
2023-01-09 13:05:46 - progress_bar.py[line:274] - INFO: epoch 001:  22582 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.472, wps=97.4, ups=0.56, wpb=86.5, bsz=32, num_updates=22550, lr=4.3609e-05, gnorm=0.335, clip=10, loss_scale=1024, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=137161
2023-01-09 13:06:03 - progress_bar.py[line:274] - INFO: epoch 001:  22592 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3399, wps=100.5, ups=0.57, wpb=87.7, bsz=32, num_updates=22560, lr=4.36054e-05, gnorm=0.158, clip=0, loss_scale=1024, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=137179
2023-01-09 13:06:21 - progress_bar.py[line:274] - INFO: epoch 001:  22602 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.434, wps=99.7, ups=0.57, wpb=87.6, bsz=32, num_updates=22570, lr=4.36018e-05, gnorm=0.427, clip=10, loss_scale=1024, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=137196
2023-01-09 13:06:39 - progress_bar.py[line:274] - INFO: epoch 001:  22612 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4586, wps=100.8, ups=0.57, wpb=88.2, bsz=32, num_updates=22580, lr=4.35983e-05, gnorm=0.328, clip=0, loss_scale=1024, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=137214
2023-01-09 13:06:57 - progress_bar.py[line:274] - INFO: epoch 001:  22622 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4497, wps=98.4, ups=0.57, wpb=86.4, bsz=32, num_updates=22590, lr=4.35947e-05, gnorm=0.338, clip=10, loss_scale=1024, train_wall=18, gb_free=14.8, ema_decay=0.9999, wall=137232
2023-01-09 13:07:15 - progress_bar.py[line:274] - INFO: epoch 001:  22632 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4713, wps=99.4, ups=0.57, wpb=87.7, bsz=32, num_updates=22600, lr=4.35911e-05, gnorm=0.294, clip=0, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=137250
2023-01-09 13:07:33 - progress_bar.py[line:274] - INFO: epoch 001:  22642 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4491, wps=98, ups=0.56, wpb=87.8, bsz=32, num_updates=22610, lr=4.35876e-05, gnorm=0.321, clip=0, loss_scale=1024, train_wall=18, gb_free=15, ema_decay=0.9999, wall=137268
2023-01-09 13:07:51 - progress_bar.py[line:274] - INFO: epoch 001:  22652 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.425, wps=98, ups=0.56, wpb=87.2, bsz=32, num_updates=22620, lr=4.3584e-05, gnorm=0.245, clip=0, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=137286
2023-01-09 13:08:09 - progress_bar.py[line:274] - INFO: epoch 001:  22662 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4313, wps=98, ups=0.56, wpb=87.8, bsz=32, num_updates=22630, lr=4.35804e-05, gnorm=0.275, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=137304
2023-01-09 13:08:27 - progress_bar.py[line:274] - INFO: epoch 001:  22672 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.485, wps=97.3, ups=0.56, wpb=86.6, bsz=32, num_updates=22640, lr=4.35769e-05, gnorm=0.34, clip=10, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137322
2023-01-09 13:08:46 - progress_bar.py[line:274] - INFO: epoch 001:  22682 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4762, wps=95.5, ups=0.55, wpb=86.7, bsz=32, num_updates=22650, lr=4.35733e-05, gnorm=0.268, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137341
2023-01-09 13:09:04 - progress_bar.py[line:274] - INFO: epoch 001:  22692 / 144806 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4214, wps=97.4, ups=0.56, wpb=86.8, bsz=32, num_updates=22660, lr=4.35697e-05, gnorm=0.348, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=137359
2023-01-09 13:09:22 - progress_bar.py[line:274] - INFO: epoch 001:  22702 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4214, wps=100.7, ups=0.57, wpb=87.7, bsz=32, num_updates=22670, lr=4.35662e-05, gnorm=0.191, clip=0, loss_scale=1024, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=137377
2023-01-09 13:09:40 - progress_bar.py[line:274] - INFO: epoch 001:  22712 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.7, nsentences=32, sample_size=88.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4013, wps=100, ups=0.56, wpb=88.7, bsz=32, num_updates=22680, lr=4.35626e-05, gnorm=0.606, clip=10, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=137395
2023-01-09 13:09:58 - progress_bar.py[line:274] - INFO: epoch 001:  22722 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5035, wps=99.1, ups=0.56, wpb=88.6, bsz=32, num_updates=22690, lr=4.3559e-05, gnorm=0.326, clip=10, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=137413
2023-01-09 13:10:16 - progress_bar.py[line:274] - INFO: epoch 001:  22732 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4533, wps=101, ups=0.57, wpb=88.9, bsz=32, num_updates=22700, lr=4.35555e-05, gnorm=0.514, clip=10, loss_scale=2048, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137431
2023-01-09 13:10:33 - progress_bar.py[line:274] - INFO: epoch 001:  22742 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4398, wps=99.9, ups=0.57, wpb=87.2, bsz=32, num_updates=22710, lr=4.35519e-05, gnorm=0.266, clip=0, loss_scale=2048, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=137448
2023-01-09 13:10:51 - progress_bar.py[line:274] - INFO: epoch 001:  22752 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4971, wps=99.1, ups=0.58, wpb=86, bsz=32, num_updates=22720, lr=4.35483e-05, gnorm=0.322, clip=10, loss_scale=2048, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=137466
2023-01-09 13:11:09 - progress_bar.py[line:274] - INFO: epoch 001:  22762 / 144806 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5752, wps=97.8, ups=0.56, wpb=87.3, bsz=32, num_updates=22730, lr=4.35448e-05, gnorm=0.311, clip=0, loss_scale=2048, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137484
2023-01-09 13:11:27 - progress_bar.py[line:274] - INFO: epoch 001:  22772 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4417, wps=96.8, ups=0.56, wpb=87, bsz=32, num_updates=22740, lr=4.35412e-05, gnorm=0.267, clip=0, loss_scale=2048, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137502
2023-01-09 13:11:45 - progress_bar.py[line:274] - INFO: epoch 001:  22782 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4873, wps=98.6, ups=0.56, wpb=87.6, bsz=32, num_updates=22750, lr=4.35376e-05, gnorm=0.312, clip=0, loss_scale=2048, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137520
2023-01-09 13:12:03 - progress_bar.py[line:274] - INFO: epoch 001:  22792 / 144806 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=84.9, nsentences=32, sample_size=84.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4595, wps=95.4, ups=0.56, wpb=84.9, bsz=32, num_updates=22760, lr=4.35341e-05, gnorm=0.298, clip=0, loss_scale=2048, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=137538
2023-01-09 13:12:21 - progress_bar.py[line:274] - INFO: epoch 001:  22802 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4351, wps=99.4, ups=0.57, wpb=87.8, bsz=32, num_updates=22770, lr=4.35305e-05, gnorm=0.396, clip=0, loss_scale=2048, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137556
2023-01-09 13:12:39 - progress_bar.py[line:274] - INFO: epoch 001:  22812 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4025, wps=100.7, ups=0.58, wpb=87.3, bsz=32, num_updates=22780, lr=4.35269e-05, gnorm=0.285, clip=0, loss_scale=2048, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=137574
2023-01-09 13:12:49 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-09 13:12:59 - progress_bar.py[line:274] - INFO: epoch 001:  22823 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.667, nsentences=32, sample_size=87.667, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4011, wps=94, ups=0.51, wpb=87.7, bsz=32, num_updates=22790, lr=4.35234e-05, gnorm=0.323, clip=0, loss_scale=1024, train_wall=20, gb_free=15.4, ema_decay=0.9999, wall=137594
2023-01-09 13:13:02 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-09 13:13:18 - progress_bar.py[line:274] - INFO: epoch 001:  22834 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.571, nsentences=32, sample_size=87.571, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4167, wps=94.7, ups=0.51, wpb=87.6, bsz=32, num_updates=22800, lr=4.35198e-05, gnorm=0.471, clip=10, loss_scale=512, train_wall=19, gb_free=15.2, ema_decay=0.9999, wall=137613
2023-01-09 13:13:36 - progress_bar.py[line:274] - INFO: epoch 001:  22844 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=85.2, nsentences=32, sample_size=85.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3975, wps=95.9, ups=0.56, wpb=85.2, bsz=32, num_updates=22810, lr=4.35162e-05, gnorm=0.427, clip=20, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137631
2023-01-09 13:13:54 - progress_bar.py[line:274] - INFO: epoch 001:  22854 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4172, wps=98.7, ups=0.57, wpb=86.9, bsz=32, num_updates=22820, lr=4.35127e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137649
2023-01-09 13:14:12 - progress_bar.py[line:274] - INFO: epoch 001:  22864 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4731, wps=97.5, ups=0.56, wpb=87.5, bsz=32, num_updates=22830, lr=4.35091e-05, gnorm=0.222, clip=0, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=137667
2023-01-09 13:14:21 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 13:14:32 - progress_bar.py[line:274] - INFO: epoch 001:  22875 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.619, nsentences=32, sample_size=88.619, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3929, wps=96.5, ups=0.52, wpb=88.6, bsz=32, num_updates=22840, lr=4.35055e-05, gnorm=0.26, clip=0, loss_scale=256, train_wall=19, gb_free=15.3, ema_decay=0.9999, wall=137687
2023-01-09 13:14:50 - progress_bar.py[line:274] - INFO: epoch 001:  22885 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=88.2, nsentences=32, sample_size=88.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4568, wps=99.8, ups=0.57, wpb=88.2, bsz=32, num_updates=22850, lr=4.3502e-05, gnorm=0.231, clip=0, loss_scale=256, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=137705
2023-01-09 13:15:08 - progress_bar.py[line:274] - INFO: epoch 001:  22895 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.4, nsentences=32, sample_size=88.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4934, wps=101.4, ups=0.57, wpb=88.4, bsz=32, num_updates=22860, lr=4.34984e-05, gnorm=0.295, clip=0, loss_scale=256, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=137723
2023-01-09 13:15:26 - progress_bar.py[line:274] - INFO: epoch 001:  22905 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5062, wps=97.7, ups=0.57, wpb=86.3, bsz=32, num_updates=22870, lr=4.34948e-05, gnorm=0.205, clip=0, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137741
2023-01-09 13:15:44 - progress_bar.py[line:274] - INFO: epoch 001:  22915 / 144806 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4423, wps=97.8, ups=0.56, wpb=86.8, bsz=32, num_updates=22880, lr=4.34913e-05, gnorm=0.213, clip=0, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137759
2023-01-09 13:16:02 - progress_bar.py[line:274] - INFO: epoch 001:  22925 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4615, wps=98.3, ups=0.56, wpb=87.9, bsz=32, num_updates=22890, lr=4.34877e-05, gnorm=0.237, clip=0, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137777
2023-01-09 13:16:20 - progress_bar.py[line:274] - INFO: epoch 001:  22935 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4323, wps=101.1, ups=0.58, wpb=87.8, bsz=32, num_updates=22900, lr=4.34841e-05, gnorm=1.005, clip=10, loss_scale=256, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=137795
2023-01-09 13:16:38 - progress_bar.py[line:274] - INFO: epoch 001:  22945 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4188, wps=96.2, ups=0.56, wpb=86.3, bsz=32, num_updates=22910, lr=4.34806e-05, gnorm=0.469, clip=10, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137813
2023-01-09 13:16:56 - progress_bar.py[line:274] - INFO: epoch 001:  22955 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4485, wps=97.3, ups=0.56, wpb=87.1, bsz=32, num_updates=22920, lr=4.3477e-05, gnorm=0.484, clip=20, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137831
2023-01-09 13:17:14 - progress_bar.py[line:274] - INFO: epoch 001:  22965 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.432, wps=97.5, ups=0.56, wpb=86.7, bsz=32, num_updates=22930, lr=4.34734e-05, gnorm=0.333, clip=0, loss_scale=256, train_wall=18, gb_free=15, ema_decay=0.9999, wall=137849
2023-01-09 13:17:32 - progress_bar.py[line:274] - INFO: epoch 001:  22975 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4356, wps=98.8, ups=0.57, wpb=86.8, bsz=32, num_updates=22940, lr=4.34699e-05, gnorm=0.422, clip=0, loss_scale=256, train_wall=18, gb_free=15, ema_decay=0.9999, wall=137867
2023-01-09 13:17:50 - progress_bar.py[line:274] - INFO: epoch 001:  22985 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4379, wps=99, ups=0.56, wpb=87.9, bsz=32, num_updates=22950, lr=4.34663e-05, gnorm=0.31, clip=0, loss_scale=256, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=137885
2023-01-09 13:18:08 - progress_bar.py[line:274] - INFO: epoch 001:  22995 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.463, wps=98.2, ups=0.57, wpb=86.1, bsz=32, num_updates=22960, lr=4.34627e-05, gnorm=0.332, clip=0, loss_scale=256, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=137903
2023-01-09 13:18:26 - progress_bar.py[line:274] - INFO: epoch 001:  23005 / 144806 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4938, wps=96.9, ups=0.56, wpb=86.7, bsz=32, num_updates=22970, lr=4.34592e-05, gnorm=0.175, clip=0, loss_scale=256, train_wall=18, gb_free=15, ema_decay=0.9999, wall=137921
2023-01-09 13:18:44 - progress_bar.py[line:274] - INFO: epoch 001:  23015 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4894, wps=99.4, ups=0.57, wpb=87.7, bsz=32, num_updates=22980, lr=4.34556e-05, gnorm=0.319, clip=0, loss_scale=256, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=137939
2023-01-09 13:19:02 - progress_bar.py[line:274] - INFO: epoch 001:  23025 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3804, wps=99.8, ups=0.56, wpb=88.3, bsz=32, num_updates=22990, lr=4.3452e-05, gnorm=0.256, clip=0, loss_scale=256, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=137957
2023-01-09 13:19:20 - progress_bar.py[line:274] - INFO: epoch 001:  23035 / 144806 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4654, wps=97.4, ups=0.56, wpb=87, bsz=32, num_updates=23000, lr=4.34485e-05, gnorm=0.169, clip=0, loss_scale=256, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=137975
2023-01-09 13:19:38 - progress_bar.py[line:274] - INFO: epoch 001:  23045 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4459, wps=98.1, ups=0.56, wpb=87.7, bsz=32, num_updates=23010, lr=4.34449e-05, gnorm=0.337, clip=0, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=137993
2023-01-09 13:19:56 - progress_bar.py[line:274] - INFO: epoch 001:  23055 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.431, wps=98.1, ups=0.56, wpb=87, bsz=32, num_updates=23020, lr=4.34413e-05, gnorm=0.27, clip=0, loss_scale=256, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=138011
2023-01-09 13:20:14 - progress_bar.py[line:274] - INFO: epoch 001:  23065 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.462, wps=97.5, ups=0.56, wpb=87.7, bsz=32, num_updates=23030, lr=4.34378e-05, gnorm=0.329, clip=10, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138029
2023-01-09 13:20:32 - progress_bar.py[line:274] - INFO: epoch 001:  23075 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.471, wps=100.6, ups=0.58, wpb=87.1, bsz=32, num_updates=23040, lr=4.34342e-05, gnorm=0.304, clip=0, loss_scale=256, train_wall=17, gb_free=15, ema_decay=0.9999, wall=138047
2023-01-09 13:20:50 - progress_bar.py[line:274] - INFO: epoch 001:  23085 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4049, wps=96.5, ups=0.56, wpb=86.9, bsz=32, num_updates=23050, lr=4.34306e-05, gnorm=0.361, clip=0, loss_scale=256, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=138065
2023-01-09 13:21:08 - progress_bar.py[line:274] - INFO: epoch 001:  23095 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4242, wps=98, ups=0.57, wpb=86.7, bsz=32, num_updates=23060, lr=4.34271e-05, gnorm=0.193, clip=0, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138083
2023-01-09 13:21:26 - progress_bar.py[line:274] - INFO: epoch 001:  23105 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.443, wps=98.9, ups=0.57, wpb=87.2, bsz=32, num_updates=23070, lr=4.34235e-05, gnorm=0.269, clip=0, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138101
2023-01-09 13:21:44 - progress_bar.py[line:274] - INFO: epoch 001:  23115 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=87.5, nsentences=32, sample_size=87.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4025, wps=98.6, ups=0.56, wpb=87.5, bsz=32, num_updates=23080, lr=4.34199e-05, gnorm=0.219, clip=0, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138119
2023-01-09 13:22:02 - progress_bar.py[line:274] - INFO: epoch 001:  23125 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4037, wps=99, ups=0.56, wpb=88.6, bsz=32, num_updates=23090, lr=4.34163e-05, gnorm=0.176, clip=0, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138137
2023-01-09 13:22:20 - progress_bar.py[line:274] - INFO: epoch 001:  23135 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=85.2, nsentences=32, sample_size=85.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4583, wps=96.7, ups=0.57, wpb=85.2, bsz=32, num_updates=23100, lr=4.34128e-05, gnorm=0.514, clip=10, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138155
2023-01-09 13:22:38 - progress_bar.py[line:274] - INFO: epoch 001:  23145 / 144806 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4865, wps=101.4, ups=0.57, wpb=88.8, bsz=32, num_updates=23110, lr=4.34092e-05, gnorm=0.259, clip=0, loss_scale=256, train_wall=17, gb_free=15.4, ema_decay=0.9999, wall=138173
2023-01-09 13:22:56 - progress_bar.py[line:274] - INFO: epoch 001:  23155 / 144806 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4395, wps=100.8, ups=0.57, wpb=87.9, bsz=32, num_updates=23120, lr=4.34056e-05, gnorm=0.249, clip=10, loss_scale=256, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=138191
2023-01-09 13:23:14 - progress_bar.py[line:274] - INFO: epoch 001:  23165 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4152, wps=95.8, ups=0.55, wpb=86.3, bsz=32, num_updates=23130, lr=4.34021e-05, gnorm=0.188, clip=0, loss_scale=256, train_wall=18, gb_free=15, ema_decay=0.9999, wall=138209
2023-01-09 13:23:32 - progress_bar.py[line:274] - INFO: epoch 001:  23175 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4, wps=99.3, ups=0.57, wpb=87.2, bsz=32, num_updates=23140, lr=4.33985e-05, gnorm=0.262, clip=0, loss_scale=256, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=138227
2023-01-09 13:23:50 - progress_bar.py[line:274] - INFO: epoch 001:  23185 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5192, wps=99.9, ups=0.57, wpb=87.9, bsz=32, num_updates=23150, lr=4.33949e-05, gnorm=0.418, clip=10, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138245
2023-01-09 13:24:08 - progress_bar.py[line:274] - INFO: epoch 001:  23195 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4177, wps=97.1, ups=0.56, wpb=87, bsz=32, num_updates=23160, lr=4.33914e-05, gnorm=0.247, clip=0, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138263
2023-01-09 13:24:25 - progress_bar.py[line:274] - INFO: epoch 001:  23205 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4133, wps=100.3, ups=0.57, wpb=87.6, bsz=32, num_updates=23170, lr=4.33878e-05, gnorm=0.431, clip=10, loss_scale=256, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=138280
2023-01-09 13:24:43 - progress_bar.py[line:274] - INFO: epoch 001:  23215 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=85.6, nsentences=32, sample_size=85.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3669, wps=96.2, ups=0.56, wpb=85.6, bsz=32, num_updates=23180, lr=4.33842e-05, gnorm=0.2, clip=0, loss_scale=256, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=138299
2023-01-09 13:25:02 - progress_bar.py[line:274] - INFO: epoch 001:  23225 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=88.1, nsentences=32, sample_size=88.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5098, wps=98.7, ups=0.56, wpb=88.1, bsz=32, num_updates=23190, lr=4.33807e-05, gnorm=0.334, clip=0, loss_scale=256, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=138317
2023-01-09 13:25:20 - progress_bar.py[line:274] - INFO: epoch 001:  23235 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4228, wps=98.4, ups=0.56, wpb=87.3, bsz=32, num_updates=23200, lr=4.33771e-05, gnorm=0.191, clip=0, loss_scale=256, train_wall=18, gb_free=15, ema_decay=0.9999, wall=138335
2023-01-09 13:25:37 - progress_bar.py[line:274] - INFO: epoch 001:  23245 / 144806 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5132, wps=99.9, ups=0.57, wpb=88, bsz=32, num_updates=23210, lr=4.33735e-05, gnorm=0.226, clip=0, loss_scale=256, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=138352
2023-01-09 13:25:55 - progress_bar.py[line:274] - INFO: epoch 001:  23255 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4479, wps=98.2, ups=0.56, wpb=87.2, bsz=32, num_updates=23220, lr=4.337e-05, gnorm=0.245, clip=0, loss_scale=256, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=138371
2023-01-09 13:26:13 - progress_bar.py[line:274] - INFO: epoch 001:  23265 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4277, wps=101.2, ups=0.58, wpb=86.8, bsz=32, num_updates=23230, lr=4.33664e-05, gnorm=0.293, clip=0, loss_scale=256, train_wall=17, gb_free=14.6, ema_decay=0.9999, wall=138388
2023-01-09 13:26:31 - progress_bar.py[line:274] - INFO: epoch 001:  23275 / 144806 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4062, wps=99.3, ups=0.57, wpb=87.2, bsz=32, num_updates=23240, lr=4.33628e-05, gnorm=0.285, clip=0, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138406
2023-01-09 13:26:48 - progress_bar.py[line:274] - INFO: epoch 001:  23285 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4257, wps=100, ups=0.57, wpb=87.1, bsz=32, num_updates=23250, lr=4.33593e-05, gnorm=0.354, clip=0, loss_scale=256, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=138423
2023-01-09 13:27:06 - progress_bar.py[line:274] - INFO: epoch 001:  23295 / 144806 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4041, wps=100.3, ups=0.57, wpb=88.3, bsz=32, num_updates=23260, lr=4.33557e-05, gnorm=0.512, clip=10, loss_scale=256, train_wall=18, gb_free=15.6, ema_decay=0.9999, wall=138441
2023-01-09 13:27:24 - progress_bar.py[line:274] - INFO: epoch 001:  23305 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4529, wps=99.9, ups=0.58, wpb=86.5, bsz=32, num_updates=23270, lr=4.33521e-05, gnorm=0.294, clip=0, loss_scale=256, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=138459
2023-01-09 13:27:42 - progress_bar.py[line:274] - INFO: epoch 001:  23315 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4734, wps=95.4, ups=0.55, wpb=86.1, bsz=32, num_updates=23280, lr=4.33486e-05, gnorm=0.499, clip=20, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138477
2023-01-09 13:28:00 - progress_bar.py[line:274] - INFO: epoch 001:  23325 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=85.9, nsentences=32, sample_size=85.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4633, wps=97.8, ups=0.57, wpb=85.9, bsz=32, num_updates=23290, lr=4.3345e-05, gnorm=0.229, clip=0, loss_scale=256, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=138495
2023-01-09 13:28:18 - progress_bar.py[line:274] - INFO: epoch 001:  23335 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4198, wps=97.1, ups=0.56, wpb=86.8, bsz=32, num_updates=23300, lr=4.33414e-05, gnorm=0.316, clip=10, loss_scale=256, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=138513
2023-01-09 13:28:36 - progress_bar.py[line:274] - INFO: epoch 001:  23345 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4601, wps=97.9, ups=0.57, wpb=86.1, bsz=32, num_updates=23310, lr=4.33379e-05, gnorm=0.336, clip=0, loss_scale=256, train_wall=18, gb_free=14.9, ema_decay=0.9999, wall=138531
2023-01-09 13:28:54 - progress_bar.py[line:274] - INFO: epoch 001:  23355 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4524, wps=99.1, ups=0.57, wpb=87.6, bsz=32, num_updates=23320, lr=4.33343e-05, gnorm=0.354, clip=0, loss_scale=256, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=138549
2023-01-09 13:29:12 - progress_bar.py[line:274] - INFO: epoch 001:  23365 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.432, wps=95.4, ups=0.56, wpb=85.8, bsz=32, num_updates=23330, lr=4.33307e-05, gnorm=0.367, clip=0, loss_scale=256, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=138567
2023-01-09 13:29:30 - progress_bar.py[line:274] - INFO: epoch 001:  23375 / 144806 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=88.3, nsentences=32, sample_size=88.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4497, wps=100.3, ups=0.57, wpb=88.3, bsz=32, num_updates=23340, lr=4.33272e-05, gnorm=0.193, clip=0, loss_scale=256, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138585
2023-01-09 13:29:48 - progress_bar.py[line:274] - INFO: epoch 001:  23385 / 144806 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3869, wps=96.7, ups=0.56, wpb=86.6, bsz=32, num_updates=23350, lr=4.33236e-05, gnorm=0.441, clip=10, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=138603
2023-01-09 13:30:06 - progress_bar.py[line:274] - INFO: epoch 001:  23395 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.451, wps=98.9, ups=0.56, wpb=87.7, bsz=32, num_updates=23360, lr=4.332e-05, gnorm=0.318, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138621
2023-01-09 13:30:24 - progress_bar.py[line:274] - INFO: epoch 001:  23405 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4172, wps=98.7, ups=0.57, wpb=86.7, bsz=32, num_updates=23370, lr=4.33165e-05, gnorm=0.332, clip=0, loss_scale=512, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=138639
2023-01-09 13:30:41 - progress_bar.py[line:274] - INFO: epoch 001:  23415 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.471, wps=99.8, ups=0.57, wpb=87.9, bsz=32, num_updates=23380, lr=4.33129e-05, gnorm=0.293, clip=0, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=138656
2023-01-09 13:31:00 - progress_bar.py[line:274] - INFO: epoch 001:  23425 / 144806 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4667, wps=97.9, ups=0.56, wpb=87.6, bsz=32, num_updates=23390, lr=4.33093e-05, gnorm=0.497, clip=10, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=138675
2023-01-09 13:31:17 - progress_bar.py[line:274] - INFO: epoch 001:  23435 / 144806 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=89.5, nsentences=32, sample_size=89.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.48, wps=101.2, ups=0.57, wpb=89.5, bsz=32, num_updates=23400, lr=4.33058e-05, gnorm=0.242, clip=0, loss_scale=512, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=138693
2023-01-09 13:31:35 - progress_bar.py[line:274] - INFO: epoch 001:  23445 / 144806 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=89.1, nsentences=32, sample_size=89.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4315, wps=100.1, ups=0.56, wpb=89.1, bsz=32, num_updates=23410, lr=4.33022e-05, gnorm=0.265, clip=0, loss_scale=512, train_wall=18, gb_free=15.6, ema_decay=0.9999, wall=138711
2023-01-09 13:31:54 - progress_bar.py[line:274] - INFO: epoch 001:  23455 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4277, wps=96.5, ups=0.56, wpb=86.9, bsz=32, num_updates=23420, lr=4.32986e-05, gnorm=0.252, clip=0, loss_scale=512, train_wall=18, gb_free=14.7, ema_decay=0.9999, wall=138729
2023-01-09 13:32:11 - progress_bar.py[line:274] - INFO: epoch 001:  23465 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.522, wps=100.3, ups=0.57, wpb=87.8, bsz=32, num_updates=23430, lr=4.32951e-05, gnorm=0.546, clip=10, loss_scale=512, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=138746
2023-01-09 13:32:29 - progress_bar.py[line:274] - INFO: epoch 001:  23475 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4471, wps=100.8, ups=0.58, wpb=87.2, bsz=32, num_updates=23440, lr=4.32915e-05, gnorm=0.274, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=138764
2023-01-09 13:32:47 - progress_bar.py[line:274] - INFO: epoch 001:  23485 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4713, wps=98.3, ups=0.56, wpb=87.6, bsz=32, num_updates=23450, lr=4.32879e-05, gnorm=0.217, clip=0, loss_scale=512, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=138782
2023-01-09 13:33:05 - progress_bar.py[line:274] - INFO: epoch 001:  23495 / 144806 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=86, nsentences=32, sample_size=86, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.422, wps=97.1, ups=0.56, wpb=86, bsz=32, num_updates=23460, lr=4.32844e-05, gnorm=0.552, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138800
2023-01-09 13:33:23 - progress_bar.py[line:274] - INFO: epoch 001:  23505 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=85.2, nsentences=32, sample_size=85.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4326, wps=95.9, ups=0.56, wpb=85.2, bsz=32, num_updates=23470, lr=4.32808e-05, gnorm=0.305, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138818
2023-01-09 13:33:41 - progress_bar.py[line:274] - INFO: epoch 001:  23515 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=87.8, nsentences=32, sample_size=87.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4663, wps=100.1, ups=0.57, wpb=87.8, bsz=32, num_updates=23480, lr=4.32772e-05, gnorm=0.419, clip=0, loss_scale=512, train_wall=17, gb_free=15.3, ema_decay=0.9999, wall=138836
2023-01-09 13:33:59 - progress_bar.py[line:274] - INFO: epoch 001:  23525 / 144806 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4813, wps=99.4, ups=0.57, wpb=87.9, bsz=32, num_updates=23490, lr=4.32737e-05, gnorm=0.57, clip=10, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=138854
2023-01-09 13:34:17 - progress_bar.py[line:274] - INFO: epoch 001:  23535 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=98.7, ups=0.57, wpb=86.9, bsz=32, num_updates=23500, lr=4.32701e-05, gnorm=0.435, clip=0, loss_scale=512, train_wall=18, gb_free=15.4, ema_decay=0.9999, wall=138872
2023-01-09 13:34:35 - progress_bar.py[line:274] - INFO: epoch 001:  23545 / 144806 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4422, wps=96, ups=0.55, wpb=86.5, bsz=32, num_updates=23510, lr=4.32665e-05, gnorm=0.281, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138890
2023-01-09 13:34:53 - progress_bar.py[line:274] - INFO: epoch 001:  23555 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4641, wps=97.5, ups=0.56, wpb=87.3, bsz=32, num_updates=23520, lr=4.3263e-05, gnorm=0.217, clip=0, loss_scale=512, train_wall=18, gb_free=14.8, ema_decay=0.9999, wall=138908
2023-01-09 13:35:11 - progress_bar.py[line:274] - INFO: epoch 001:  23565 / 144806 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4326, wps=97.5, ups=0.56, wpb=86.9, bsz=32, num_updates=23530, lr=4.32594e-05, gnorm=0.294, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=138926
2023-01-09 13:35:29 - progress_bar.py[line:274] - INFO: epoch 001:  23575 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4479, wps=96.8, ups=0.56, wpb=86.5, bsz=32, num_updates=23540, lr=4.32558e-05, gnorm=0.344, clip=0, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=138944
2023-01-09 13:35:47 - progress_bar.py[line:274] - INFO: epoch 001:  23585 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4695, wps=99.6, ups=0.58, wpb=86.5, bsz=32, num_updates=23550, lr=4.32523e-05, gnorm=0.374, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=138962
2023-01-09 13:36:05 - progress_bar.py[line:274] - INFO: epoch 001:  23595 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.546, wps=99.3, ups=0.57, wpb=87.3, bsz=32, num_updates=23560, lr=4.32487e-05, gnorm=0.331, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=138980
2023-01-09 13:36:22 - progress_bar.py[line:274] - INFO: epoch 001:  23605 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3987, wps=101.3, ups=0.58, wpb=87.6, bsz=32, num_updates=23570, lr=4.32451e-05, gnorm=0.344, clip=10, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=138997
2023-01-09 13:36:40 - progress_bar.py[line:274] - INFO: epoch 001:  23615 / 144806 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4675, wps=98, ups=0.56, wpb=86.9, bsz=32, num_updates=23580, lr=4.32416e-05, gnorm=0.254, clip=0, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=139015
2023-01-09 13:36:58 - progress_bar.py[line:274] - INFO: epoch 001:  23625 / 144806 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=88.5, nsentences=32, sample_size=88.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5034, wps=101.1, ups=0.57, wpb=88.5, bsz=32, num_updates=23590, lr=4.3238e-05, gnorm=0.26, clip=10, loss_scale=512, train_wall=17, gb_free=15.4, ema_decay=0.9999, wall=139033
2023-01-09 13:37:16 - progress_bar.py[line:274] - INFO: epoch 001:  23635 / 144806 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4765, wps=97.5, ups=0.55, wpb=88, bsz=32, num_updates=23600, lr=4.32344e-05, gnorm=0.223, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139051
2023-01-09 13:37:34 - progress_bar.py[line:274] - INFO: epoch 001:  23645 / 144806 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=86.8, nsentences=32, sample_size=86.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5032, wps=97.9, ups=0.56, wpb=86.8, bsz=32, num_updates=23610, lr=4.32309e-05, gnorm=0.266, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139069
2023-01-09 13:37:53 - progress_bar.py[line:274] - INFO: epoch 001:  23655 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=88.9, nsentences=32, sample_size=88.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4534, wps=98.3, ups=0.55, wpb=88.9, bsz=32, num_updates=23620, lr=4.32273e-05, gnorm=0.228, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=139088
2023-01-09 13:38:10 - progress_bar.py[line:274] - INFO: epoch 001:  23665 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4788, wps=98.5, ups=0.57, wpb=86.7, bsz=32, num_updates=23630, lr=4.32237e-05, gnorm=0.377, clip=10, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=139105
2023-01-09 13:38:28 - progress_bar.py[line:274] - INFO: epoch 001:  23675 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4556, wps=97.7, ups=0.56, wpb=87, bsz=32, num_updates=23640, lr=4.32202e-05, gnorm=0.292, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139123
2023-01-09 13:38:46 - progress_bar.py[line:274] - INFO: epoch 001:  23685 / 144806 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4901, wps=99.7, ups=0.57, wpb=87.6, bsz=32, num_updates=23650, lr=4.32166e-05, gnorm=0.298, clip=0, loss_scale=512, train_wall=18, gb_free=15.5, ema_decay=0.9999, wall=139141
2023-01-09 13:39:04 - progress_bar.py[line:274] - INFO: epoch 001:  23695 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4562, wps=98.5, ups=0.57, wpb=87.1, bsz=32, num_updates=23660, lr=4.3213e-05, gnorm=0.245, clip=0, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=139159
2023-01-09 13:39:22 - progress_bar.py[line:274] - INFO: epoch 001:  23705 / 144806 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=87.2, nsentences=32, sample_size=87.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.45, wps=98.5, ups=0.56, wpb=87.2, bsz=32, num_updates=23670, lr=4.32095e-05, gnorm=0.432, clip=10, loss_scale=512, train_wall=18, gb_free=15, ema_decay=0.9999, wall=139177
2023-01-09 13:39:40 - progress_bar.py[line:274] - INFO: epoch 001:  23715 / 144806 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4911, wps=98.1, ups=0.56, wpb=87.7, bsz=32, num_updates=23680, lr=4.32059e-05, gnorm=0.303, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=139195
2023-01-09 13:39:58 - progress_bar.py[line:274] - INFO: epoch 001:  23725 / 144806 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3506, wps=98.6, ups=0.56, wpb=87.4, bsz=32, num_updates=23690, lr=4.32023e-05, gnorm=0.308, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=139213
2023-01-09 13:40:17 - progress_bar.py[line:274] - INFO: epoch 001:  23735 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=85.6, nsentences=32, sample_size=85.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4798, wps=95.3, ups=0.56, wpb=85.6, bsz=32, num_updates=23700, lr=4.31988e-05, gnorm=0.38, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139231
2023-01-09 13:40:34 - progress_bar.py[line:274] - INFO: epoch 001:  23745 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4941, wps=102.9, ups=0.59, wpb=87.7, bsz=32, num_updates=23710, lr=4.31952e-05, gnorm=0.314, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=139249
2023-01-09 13:40:53 - progress_bar.py[line:274] - INFO: epoch 001:  23755 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4875, wps=96.9, ups=0.55, wpb=87.3, bsz=32, num_updates=23720, lr=4.31916e-05, gnorm=0.253, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139268
2023-01-09 13:41:12 - progress_bar.py[line:274] - INFO: epoch 001:  23765 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4314, wps=98.3, ups=0.56, wpb=87, bsz=32, num_updates=23730, lr=4.31881e-05, gnorm=0.519, clip=20, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139286
2023-01-09 13:41:30 - progress_bar.py[line:274] - INFO: epoch 001:  23775 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=85.8, nsentences=32, sample_size=85.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4866, wps=95.6, ups=0.56, wpb=85.8, bsz=32, num_updates=23740, lr=4.31845e-05, gnorm=0.336, clip=10, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=139305
2023-01-09 13:41:48 - progress_bar.py[line:274] - INFO: epoch 001:  23785 / 144806 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4817, wps=100.7, ups=0.58, wpb=87.3, bsz=32, num_updates=23750, lr=4.31809e-05, gnorm=0.317, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=139323
2023-01-09 13:42:07 - progress_bar.py[line:274] - INFO: epoch 001:  23795 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=86.3, nsentences=32, sample_size=86.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.488, wps=97.5, ups=0.56, wpb=86.3, bsz=32, num_updates=23760, lr=4.31774e-05, gnorm=0.349, clip=10, loss_scale=512, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=139341
2023-01-09 13:42:25 - progress_bar.py[line:274] - INFO: epoch 001:  23805 / 144806 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4305, wps=101.1, ups=0.57, wpb=87.9, bsz=32, num_updates=23770, lr=4.31738e-05, gnorm=0.24, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=139360
2023-01-09 13:42:43 - progress_bar.py[line:274] - INFO: epoch 001:  23815 / 144806 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=86.9, nsentences=32, sample_size=86.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4364, wps=99.4, ups=0.57, wpb=86.9, bsz=32, num_updates=23780, lr=4.31702e-05, gnorm=0.386, clip=0, loss_scale=512, train_wall=17, gb_free=15.2, ema_decay=0.9999, wall=139378
2023-01-09 13:43:01 - progress_bar.py[line:274] - INFO: epoch 001:  23825 / 144806 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=88, nsentences=32, sample_size=88, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4545, wps=102.5, ups=0.58, wpb=88, bsz=32, num_updates=23790, lr=4.31667e-05, gnorm=0.225, clip=0, loss_scale=512, train_wall=17, gb_free=15.6, ema_decay=0.9999, wall=139396
2023-01-09 13:43:19 - progress_bar.py[line:274] - INFO: epoch 001:  23835 / 144806 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4694, wps=99.3, ups=0.57, wpb=87.7, bsz=32, num_updates=23800, lr=4.31631e-05, gnorm=0.312, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139414
2023-01-09 13:43:38 - progress_bar.py[line:274] - INFO: epoch 001:  23845 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=87.4, nsentences=32, sample_size=87.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4788, wps=97.4, ups=0.56, wpb=87.4, bsz=32, num_updates=23810, lr=4.31595e-05, gnorm=0.278, clip=0, loss_scale=512, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=139432
2023-01-09 13:43:56 - progress_bar.py[line:274] - INFO: epoch 001:  23855 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.6, nsentences=32, sample_size=86.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.503, wps=99, ups=0.57, wpb=86.6, bsz=32, num_updates=23820, lr=4.3156e-05, gnorm=0.288, clip=10, loss_scale=512, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=139451
2023-01-09 13:44:14 - progress_bar.py[line:274] - INFO: epoch 001:  23865 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.1, nsentences=32, sample_size=86.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4634, wps=96.2, ups=0.56, wpb=86.1, bsz=32, num_updates=23830, lr=4.31524e-05, gnorm=0.222, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139469
2023-01-09 13:44:33 - progress_bar.py[line:274] - INFO: epoch 001:  23875 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.5, nsentences=32, sample_size=86.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4405, wps=98.5, ups=0.57, wpb=86.5, bsz=32, num_updates=23840, lr=4.31488e-05, gnorm=0.427, clip=0, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139487
2023-01-09 13:44:51 - progress_bar.py[line:274] - INFO: epoch 001:  23885 / 144806 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=88.6, nsentences=32, sample_size=88.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.425, wps=100, ups=0.56, wpb=88.6, bsz=32, num_updates=23850, lr=4.31453e-05, gnorm=0.444, clip=10, loss_scale=512, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139506
2023-01-09 13:45:09 - progress_bar.py[line:274] - INFO: epoch 001:  23895 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4901, wps=99.6, ups=0.57, wpb=86.7, bsz=32, num_updates=23860, lr=4.31417e-05, gnorm=0.431, clip=10, loss_scale=1024, train_wall=17, gb_free=14.9, ema_decay=0.9999, wall=139524
2023-01-09 13:45:28 - progress_bar.py[line:274] - INFO: epoch 001:  23905 / 144806 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4321, wps=96.6, ups=0.55, wpb=87.3, bsz=32, num_updates=23870, lr=4.31381e-05, gnorm=0.335, clip=0, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=139542
2023-01-09 13:45:46 - progress_bar.py[line:274] - INFO: epoch 001:  23915 / 144806 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4713, wps=97.6, ups=0.56, wpb=87.6, bsz=32, num_updates=23880, lr=4.31346e-05, gnorm=0.294, clip=0, loss_scale=1024, train_wall=18, gb_free=15.1, ema_decay=0.9999, wall=139561
2023-01-09 13:46:05 - progress_bar.py[line:274] - INFO: epoch 001:  23925 / 144806 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4107, wps=100.3, ups=0.57, wpb=87.6, bsz=32, num_updates=23890, lr=4.3131e-05, gnorm=0.288, clip=0, loss_scale=1024, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=139579
2023-01-09 13:46:23 - progress_bar.py[line:274] - INFO: epoch 001:  23935 / 144806 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=86.7, nsentences=32, sample_size=86.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4881, wps=98.2, ups=0.57, wpb=86.7, bsz=32, num_updates=23900, lr=4.31274e-05, gnorm=0.349, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=139597
2023-01-09 13:46:41 - progress_bar.py[line:274] - INFO: epoch 001:  23945 / 144806 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.434, wps=98.6, ups=0.56, wpb=87.3, bsz=32, num_updates=23910, lr=4.31239e-05, gnorm=0.319, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139616
2023-01-09 13:46:59 - progress_bar.py[line:274] - INFO: epoch 001:  23955 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=87.6, nsentences=32, sample_size=87.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.396, wps=100.7, ups=0.57, wpb=87.6, bsz=32, num_updates=23920, lr=4.31203e-05, gnorm=0.303, clip=0, loss_scale=1024, train_wall=17, gb_free=15.3, ema_decay=0.9999, wall=139634
2023-01-09 13:47:17 - progress_bar.py[line:274] - INFO: epoch 001:  23965 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4345, wps=98.4, ups=0.56, wpb=87.1, bsz=32, num_updates=23930, lr=4.31167e-05, gnorm=0.247, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=139652
2023-01-09 13:47:36 - progress_bar.py[line:274] - INFO: epoch 001:  23975 / 144806 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=87.9, nsentences=32, sample_size=87.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4074, wps=100, ups=0.57, wpb=87.9, bsz=32, num_updates=23940, lr=4.31132e-05, gnorm=0.414, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139670
2023-01-09 13:47:54 - progress_bar.py[line:274] - INFO: epoch 001:  23985 / 144806 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=88.8, nsentences=32, sample_size=88.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4648, wps=102.9, ups=0.58, wpb=88.8, bsz=32, num_updates=23950, lr=4.31096e-05, gnorm=0.312, clip=0, loss_scale=1024, train_wall=17, gb_free=15.1, ema_decay=0.9999, wall=139688
2023-01-09 13:48:12 - progress_bar.py[line:274] - INFO: epoch 001:  23995 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=86.4, nsentences=32, sample_size=86.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4183, wps=97.4, ups=0.56, wpb=86.4, bsz=32, num_updates=23960, lr=4.3106e-05, gnorm=0.411, clip=10, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139707
2023-01-09 13:48:31 - progress_bar.py[line:274] - INFO: epoch 001:  24005 / 144806 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=87.7, nsentences=32, sample_size=87.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4747, wps=97.3, ups=0.55, wpb=87.7, bsz=32, num_updates=23970, lr=4.31025e-05, gnorm=0.328, clip=0, loss_scale=1024, train_wall=18, gb_free=15.2, ema_decay=0.9999, wall=139725
2023-01-09 13:48:49 - progress_bar.py[line:274] - INFO: epoch 001:  24015 / 144806 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=87.3, nsentences=32, sample_size=87.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3987, wps=98.6, ups=0.56, wpb=87.3, bsz=32, num_updates=23980, lr=4.30989e-05, gnorm=0.209, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=139744
2023-01-09 13:49:07 - progress_bar.py[line:274] - INFO: epoch 001:  24025 / 144806 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=87, nsentences=32, sample_size=87, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3926, wps=97.6, ups=0.56, wpb=87, bsz=32, num_updates=23990, lr=4.30953e-05, gnorm=0.321, clip=0, loss_scale=1024, train_wall=18, gb_free=15.3, ema_decay=0.9999, wall=139762
2023-01-09 13:49:25 - progress_bar.py[line:274] - INFO: epoch 001:  24035 / 144806 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=87.1, nsentences=32, sample_size=87.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4667, wps=99.9, ups=0.57, wpb=87.1, bsz=32, num_updates=24000, lr=4.30918e-05, gnorm=0.189, clip=0, loss_scale=1024, train_wall=17, gb_free=15.3, ema_decay=0.9999, wall=139780
2023-01-09 13:49:26 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-09 13:49:27 - train.py[line:549] - INFO: 0 / 6234
2023-01-09 13:49:27 - train.py[line:551] - INFO: load:1.21 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-09 13:51:30 - train.py[line:549] - INFO: 200 / 6234
2023-01-09 13:51:30 - train.py[line:551] - INFO: load:1.24 valid_run:122.54 task_valid:119.80 collect_output:1.59
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 3308718
Killing subprocess 3308719
Main process received SIGINT, exiting
train_vqa_base_distributed-A100-node4-2.sh: line 183: _inference_type}: command not found
