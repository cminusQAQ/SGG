2023-02-20 13:25:37 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2023-02-20 13:25:37 - utils.py[line:261] - INFO: Start init
2023-02-20 13:25:37 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2023-02-20 13:25:37 - utils.py[line:261] - INFO: Start init
2023-02-20 13:25:37 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-02-20 13:25:37 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-02-20 13:25:37 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2023-02-20 13:25:37 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2023-02-20 13:25:41 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 2000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 12, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 2000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='12', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=1, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480', save_interval=10, save_interval_updates=2000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=2000, wandb_project=None, warmup_ratio=0.027, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.027, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-02-20 13:25:42 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-02-20 13:25:42 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2023-02-20 13:25:46 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-02-20 13:25:46 - train.py[line:118] - INFO: task: VqaGenTask
2023-02-20 13:25:46 - train.py[line:119] - INFO: model: OFAModel
2023-02-20 13:25:46 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-02-20 13:25:46 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-02-20 13:25:46 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2023-02-20 13:25:46 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-02-20 13:25:47 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-02-20 13:25:47 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-02-20 13:25:47 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-02-20 13:25:47 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-02-20 13:25:47 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
Done 0.95 cuda cpu, cpu
2023-02-20 13:25:48 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2023-02-20 13:25:48 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2023-02-20 13:25:48 - trainer.py[line:499] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
Done 0.95 cuda cpu, cpu
2023-02-20 13:25:58 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-02-20 13:25:58 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-02-20 13:25:58 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-02-20 13:25:58 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-02-20 13:25:58 - trainer.py[line:314] - INFO: Exponential Moving Average Shadow Model is initialized.
2023-02-20 13:25:59 - trainer.py[line:674] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2023-02-20 13:25:59 - trainer.py[line:694] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E0.tsv slice_id 1 row count 2840444 total row count 5680889
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_train_NA1_E0.tsv slice_id 0 row count 2840445 total row count 5680889
Total steps 142023, warmup steps 3834, warmup_factor 0.0002608242044861763
2023-02-20 13:26:04 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 142023, warmup steps 3834, warmup_factor 0.0002608242044861763
2023-02-20 13:26:04 - trainer.py[line:758] - INFO: begin training epoch 1
2023-02-20 13:26:04 - train.py[line:312] - INFO: Start iterating over samples
2023-02-20 13:26:21 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 142023 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=94.6, ups=0.86, wpb=110, bsz=40, num_updates=10, lr=1.30412e-07, gnorm=7.08, clip=100, loss_scale=128, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=34
2023-02-20 13:26:33 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 142023 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=95.2, ups=0.86, wpb=110.4, bsz=40, num_updates=20, lr=2.60824e-07, gnorm=6.305, clip=100, loss_scale=128, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=45
2023-02-20 13:26:44 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 142023 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=30, lr=3.91236e-07, gnorm=6.465, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=57
2023-02-20 13:26:55 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 142023 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.4, ups=0.88, wpb=111.6, bsz=40, num_updates=40, lr=5.21648e-07, gnorm=5.776, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68
2023-02-20 13:27:06 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 142023 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=50, lr=6.52061e-07, gnorm=4.602, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79
2023-02-20 13:27:18 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 142023 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.114, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=100.9, ups=0.9, wpb=111.6, bsz=40, num_updates=60, lr=7.82473e-07, gnorm=3.389, clip=100, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=90
2023-02-20 13:27:28 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 142023 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.6, ups=0.91, wpb=110, bsz=40, num_updates=70, lr=9.12885e-07, gnorm=2.336, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=101
2023-02-20 13:27:39 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 142023 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=80, lr=1.0433e-06, gnorm=2.373, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=112
2023-02-20 13:27:50 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 142023 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=90, lr=1.17371e-06, gnorm=2.166, clip=100, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=123
2023-02-20 13:28:01 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 142023 loss=0.219, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=100, lr=1.30412e-06, gnorm=1.717, clip=100, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=134
2023-02-20 13:28:12 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 142023 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=102.8, ups=0.92, wpb=112.2, bsz=40, num_updates=110, lr=1.43453e-06, gnorm=1.704, clip=90, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=145
2023-02-20 13:28:24 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 142023 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98, ups=0.88, wpb=111.7, bsz=40, num_updates=120, lr=1.56495e-06, gnorm=1.448, clip=60, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157
2023-02-20 13:28:35 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 142023 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=95.9, ups=0.87, wpb=110.6, bsz=40, num_updates=130, lr=1.69536e-06, gnorm=1.244, clip=80, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=168
2023-02-20 13:28:47 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 142023 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.4, ups=0.88, wpb=111.8, bsz=40, num_updates=140, lr=1.82577e-06, gnorm=0.973, clip=40, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=179
2023-02-20 13:28:58 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 142023 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.6, ups=0.9, wpb=110, bsz=40, num_updates=150, lr=1.95618e-06, gnorm=0.805, clip=10, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=191
2023-02-20 13:29:09 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 142023 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.7, ups=0.88, wpb=111.6, bsz=40, num_updates=160, lr=2.08659e-06, gnorm=0.832, clip=30, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=202
2023-02-20 13:29:20 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 142023 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=99.6, ups=0.89, wpb=111.7, bsz=40, num_updates=170, lr=2.21701e-06, gnorm=0.871, clip=30, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=213
2023-02-20 13:29:32 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 142023 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=180, lr=2.34742e-06, gnorm=0.685, clip=0, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=225
2023-02-20 13:29:43 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 142023 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.2, ups=0.89, wpb=111.4, bsz=40, num_updates=190, lr=2.47783e-06, gnorm=0.842, clip=20, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=236
2023-02-20 13:29:54 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 142023 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.9, wpb=111.8, bsz=40, num_updates=200, lr=2.60824e-06, gnorm=0.48, clip=10, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=247
2023-02-20 13:30:06 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 142023 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.3, ups=0.87, wpb=111.9, bsz=40, num_updates=210, lr=2.73865e-06, gnorm=0.548, clip=0, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=258
2023-02-20 13:30:17 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 142023 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.88, wpb=111.6, bsz=40, num_updates=220, lr=2.86907e-06, gnorm=0.482, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=270
2023-02-20 13:30:28 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 142023 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.88, wpb=111.4, bsz=40, num_updates=230, lr=2.99948e-06, gnorm=0.521, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=281
2023-02-20 13:30:39 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 142023 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.3, ups=0.89, wpb=111.6, bsz=40, num_updates=240, lr=3.12989e-06, gnorm=0.514, clip=0, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=292
2023-02-20 13:30:51 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.7, ups=0.89, wpb=109.6, bsz=40, num_updates=250, lr=3.2603e-06, gnorm=0.547, clip=0, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=304
2023-02-20 13:31:02 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 142023 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.9, wpb=111.5, bsz=40, num_updates=260, lr=3.39071e-06, gnorm=0.506, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=315
2023-02-20 13:31:13 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=270, lr=3.52113e-06, gnorm=0.367, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=326
2023-02-20 13:31:24 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 142023 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.9, ups=0.89, wpb=110.3, bsz=40, num_updates=280, lr=3.65154e-06, gnorm=0.521, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=337
2023-02-20 13:31:36 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 142023 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=95.7, ups=0.87, wpb=110, bsz=40, num_updates=290, lr=3.78195e-06, gnorm=0.431, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=348
2023-02-20 13:31:47 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=300, lr=3.91236e-06, gnorm=0.361, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=360
2023-02-20 13:31:58 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 142023 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102, ups=0.91, wpb=112.2, bsz=40, num_updates=310, lr=4.04278e-06, gnorm=0.288, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=371
2023-02-20 13:32:09 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 142023 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.6, ups=0.9, wpb=111.5, bsz=40, num_updates=320, lr=4.17319e-06, gnorm=0.388, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=382
2023-02-20 13:32:20 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=111.1, bsz=40, num_updates=330, lr=4.3036e-06, gnorm=0.246, clip=0, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=393
2023-02-20 13:32:31 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 142023 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.3, ups=0.9, wpb=110.3, bsz=40, num_updates=340, lr=4.43401e-06, gnorm=0.466, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=404
2023-02-20 13:32:42 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 142023 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.89, wpb=111.9, bsz=40, num_updates=350, lr=4.56442e-06, gnorm=0.35, clip=0, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=415
2023-02-20 13:32:54 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 142023 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.3, ups=0.88, wpb=111, bsz=40, num_updates=360, lr=4.69484e-06, gnorm=0.404, clip=0, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=427
2023-02-20 13:33:05 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.4, ups=0.88, wpb=111.7, bsz=40, num_updates=370, lr=4.82525e-06, gnorm=0.317, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=438
2023-02-20 13:33:16 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.9, wpb=110.5, bsz=40, num_updates=380, lr=4.95566e-06, gnorm=0.247, clip=0, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=449
2023-02-20 13:33:27 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 142023 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.5, ups=0.93, wpb=111.6, bsz=40, num_updates=390, lr=5.08607e-06, gnorm=0.368, clip=0, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=460
2023-02-20 13:33:38 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 142023 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.5, ups=0.91, wpb=112.2, bsz=40, num_updates=400, lr=5.21648e-06, gnorm=0.376, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=471
2023-02-20 13:33:49 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 142023 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.89, wpb=111.6, bsz=40, num_updates=410, lr=5.3469e-06, gnorm=0.289, clip=0, loss_scale=128, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=482
2023-02-20 13:34:00 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 142023 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=104.2, ups=0.93, wpb=112, bsz=40, num_updates=420, lr=5.47731e-06, gnorm=0.359, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=493
2023-02-20 13:34:11 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 142023 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.88, wpb=111.3, bsz=40, num_updates=430, lr=5.60772e-06, gnorm=0.281, clip=0, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=504
2023-02-20 13:34:22 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.5, bsz=40, num_updates=440, lr=5.73813e-06, gnorm=0.269, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=515
2023-02-20 13:34:34 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=450, lr=5.86854e-06, gnorm=0.295, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=527
2023-02-20 13:34:45 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.7, ups=0.92, wpb=110.6, bsz=40, num_updates=460, lr=5.99896e-06, gnorm=0.288, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=538
2023-02-20 13:34:56 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 142023 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100, ups=0.91, wpb=110.4, bsz=40, num_updates=470, lr=6.12937e-06, gnorm=0.343, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=549
2023-02-20 13:35:07 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.2, ups=0.91, wpb=110.8, bsz=40, num_updates=480, lr=6.25978e-06, gnorm=0.328, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=560
2023-02-20 13:35:18 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 142023 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=102.3, ups=0.91, wpb=111.9, bsz=40, num_updates=490, lr=6.39019e-06, gnorm=0.315, clip=0, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=570
2023-02-20 13:35:28 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.2, ups=0.93, wpb=112.3, bsz=40, num_updates=500, lr=6.52061e-06, gnorm=0.3, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=581
2023-02-20 13:35:40 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=510, lr=6.65102e-06, gnorm=0.242, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=592
2023-02-20 13:35:51 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=520, lr=6.78143e-06, gnorm=0.3, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=604
2023-02-20 13:36:02 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.89, wpb=112.1, bsz=40, num_updates=530, lr=6.91184e-06, gnorm=0.264, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=615
2023-02-20 13:36:13 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 142023 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=540, lr=7.04225e-06, gnorm=0.425, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=626
2023-02-20 13:36:25 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=550, lr=7.17267e-06, gnorm=0.354, clip=10, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=637
2023-02-20 13:36:36 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=560, lr=7.30308e-06, gnorm=0.253, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=649
2023-02-20 13:36:47 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.7, bsz=40, num_updates=570, lr=7.43349e-06, gnorm=0.239, clip=0, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=660
2023-02-20 13:36:59 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=580, lr=7.5639e-06, gnorm=0.239, clip=0, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=671
2023-02-20 13:37:10 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 142023 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.9, ups=0.91, wpb=111, bsz=40, num_updates=590, lr=7.69431e-06, gnorm=0.38, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=682
2023-02-20 13:37:21 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.89, wpb=109.8, bsz=40, num_updates=600, lr=7.82473e-06, gnorm=0.356, clip=0, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=694
2023-02-20 13:37:32 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.3, ups=0.87, wpb=110.5, bsz=40, num_updates=610, lr=7.95514e-06, gnorm=0.287, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=705
2023-02-20 13:37:43 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 142023 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.9, wpb=111.9, bsz=40, num_updates=620, lr=8.08555e-06, gnorm=0.249, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=716
2023-02-20 13:37:54 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 142023 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.6, ups=0.92, wpb=111, bsz=40, num_updates=630, lr=8.21596e-06, gnorm=0.361, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=727
2023-02-20 13:38:05 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=640, lr=8.34637e-06, gnorm=0.283, clip=0, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=738
2023-02-20 13:38:17 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.6, bsz=40, num_updates=650, lr=8.47679e-06, gnorm=0.189, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=750
2023-02-20 13:38:28 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=660, lr=8.6072e-06, gnorm=0.261, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=761
2023-02-20 13:38:39 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 142023 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.4, ups=0.87, wpb=110.8, bsz=40, num_updates=670, lr=8.73761e-06, gnorm=0.241, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=772
2023-02-20 13:38:51 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=680, lr=8.86802e-06, gnorm=0.243, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=783
2023-02-20 13:39:02 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 142023 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=690, lr=8.99844e-06, gnorm=0.372, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=795
2023-02-20 13:39:13 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.92, wpb=109.2, bsz=40, num_updates=700, lr=9.12885e-06, gnorm=0.187, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=806
2023-02-20 13:39:24 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=710, lr=9.25926e-06, gnorm=0.206, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=817
2023-02-20 13:39:35 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.89, wpb=112.5, bsz=40, num_updates=720, lr=9.38967e-06, gnorm=0.206, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=828
2023-02-20 13:39:46 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 142023 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.3, ups=0.92, wpb=111.8, bsz=40, num_updates=730, lr=9.52008e-06, gnorm=0.285, clip=0, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=839
2023-02-20 13:39:57 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=740, lr=9.6505e-06, gnorm=0.216, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=850
2023-02-20 13:40:08 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 142023 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=750, lr=9.78091e-06, gnorm=0.342, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=861
2023-02-20 13:40:19 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=760, lr=9.91132e-06, gnorm=0.247, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=872
2023-02-20 13:40:31 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.89, wpb=112, bsz=40, num_updates=770, lr=1.00417e-05, gnorm=0.301, clip=0, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=884
2023-02-20 13:40:42 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=780, lr=1.01721e-05, gnorm=0.303, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=895
2023-02-20 13:40:53 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 142023 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.9, wpb=112.3, bsz=40, num_updates=790, lr=1.03026e-05, gnorm=0.275, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=906
2023-02-20 13:41:05 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=112.1, bsz=40, num_updates=800, lr=1.0433e-05, gnorm=0.271, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=918
2023-02-20 13:41:16 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.2, ups=0.87, wpb=110.6, bsz=40, num_updates=810, lr=1.05634e-05, gnorm=0.29, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=929
2023-02-20 13:41:27 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 142023 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.2, ups=0.92, wpb=109.3, bsz=40, num_updates=820, lr=1.06938e-05, gnorm=0.361, clip=0, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=940
2023-02-20 13:41:38 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 142023 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102, ups=0.92, wpb=111.1, bsz=40, num_updates=830, lr=1.08242e-05, gnorm=0.392, clip=0, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=951
2023-02-20 13:41:49 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.6, ups=0.92, wpb=110.7, bsz=40, num_updates=840, lr=1.09546e-05, gnorm=0.308, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=962
2023-02-20 13:42:00 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.7, bsz=40, num_updates=850, lr=1.1085e-05, gnorm=0.194, clip=0, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=973
2023-02-20 13:42:11 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.7, bsz=40, num_updates=860, lr=1.12154e-05, gnorm=0.306, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=984
2023-02-20 13:42:23 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.88, wpb=112.1, bsz=40, num_updates=870, lr=1.13459e-05, gnorm=0.315, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=995
2023-02-20 13:42:33 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 142023 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=102.4, ups=0.93, wpb=110.6, bsz=40, num_updates=880, lr=1.14763e-05, gnorm=0.344, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1006
2023-02-20 13:42:44 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 142023 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101.3, ups=0.92, wpb=110.6, bsz=40, num_updates=890, lr=1.16067e-05, gnorm=0.423, clip=0, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1017
2023-02-20 13:42:56 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=900, lr=1.17371e-05, gnorm=0.281, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1028
2023-02-20 13:43:07 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=910, lr=1.18675e-05, gnorm=0.246, clip=0, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=1040
2023-02-20 13:43:18 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 142023 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=920, lr=1.19979e-05, gnorm=0.347, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1051
2023-02-20 13:43:29 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=113.8, nsentences=40, sample_size=113.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.1, ups=0.89, wpb=113.8, bsz=40, num_updates=930, lr=1.21283e-05, gnorm=0.316, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1062
2023-02-20 13:43:40 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.3, bsz=40, num_updates=940, lr=1.22587e-05, gnorm=0.301, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1073
2023-02-20 13:43:51 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.3, ups=0.93, wpb=112.1, bsz=40, num_updates=950, lr=1.23891e-05, gnorm=0.29, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1084
2023-02-20 13:44:03 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=112.1, bsz=40, num_updates=960, lr=1.25196e-05, gnorm=0.221, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1096
2023-02-20 13:44:14 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=970, lr=1.265e-05, gnorm=0.221, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1107
2023-02-20 13:44:25 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.4, ups=0.91, wpb=111, bsz=40, num_updates=980, lr=1.27804e-05, gnorm=0.301, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1118
2023-02-20 13:44:35 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.2, ups=0.95, wpb=111.2, bsz=40, num_updates=990, lr=1.29108e-05, gnorm=0.28, clip=0, loss_scale=256, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=1128
2023-02-20 13:44:46 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.91, wpb=109.8, bsz=40, num_updates=1000, lr=1.30412e-05, gnorm=0.265, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1139
2023-02-20 13:44:57 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=111.7, bsz=40, num_updates=1010, lr=1.31716e-05, gnorm=0.218, clip=0, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1150
2023-02-20 13:45:09 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.4, bsz=40, num_updates=1020, lr=1.3302e-05, gnorm=0.238, clip=0, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1162
2023-02-20 13:45:20 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.3, bsz=40, num_updates=1030, lr=1.34324e-05, gnorm=0.22, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1173
2023-02-20 13:45:31 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.92, wpb=110.7, bsz=40, num_updates=1040, lr=1.35629e-05, gnorm=0.411, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1184
2023-02-20 13:45:42 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.6, bsz=40, num_updates=1050, lr=1.36933e-05, gnorm=0.278, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1195
2023-02-20 13:45:53 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=1060, lr=1.38237e-05, gnorm=0.381, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1206
2023-02-20 13:46:04 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=1070, lr=1.39541e-05, gnorm=0.415, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1217
2023-02-20 13:46:15 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=1080, lr=1.40845e-05, gnorm=0.329, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1228
2023-02-20 13:46:26 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.6, bsz=40, num_updates=1090, lr=1.42149e-05, gnorm=0.203, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1239
2023-02-20 13:46:37 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.8, ups=0.92, wpb=110, bsz=40, num_updates=1100, lr=1.43453e-05, gnorm=0.302, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1250
2023-02-20 13:46:48 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=111.9, bsz=40, num_updates=1110, lr=1.44757e-05, gnorm=0.267, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1261
2023-02-20 13:47:00 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.2, ups=0.87, wpb=110.1, bsz=40, num_updates=1120, lr=1.46062e-05, gnorm=0.383, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1272
2023-02-20 13:47:11 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.1, bsz=40, num_updates=1130, lr=1.47366e-05, gnorm=0.282, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1284
2023-02-20 13:47:22 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.88, wpb=112.3, bsz=40, num_updates=1140, lr=1.4867e-05, gnorm=0.332, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1295
2023-02-20 13:47:33 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.5, bsz=40, num_updates=1150, lr=1.49974e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1306
2023-02-20 13:47:44 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=111.1, bsz=40, num_updates=1160, lr=1.51278e-05, gnorm=0.263, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1317
2023-02-20 13:47:55 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=1170, lr=1.52582e-05, gnorm=0.387, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1328
2023-02-20 13:48:06 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.1, ups=0.91, wpb=111.7, bsz=40, num_updates=1180, lr=1.53886e-05, gnorm=0.308, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1339
2023-02-20 13:48:17 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.9, ups=0.93, wpb=111.9, bsz=40, num_updates=1190, lr=1.5519e-05, gnorm=0.216, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1350
2023-02-20 13:48:28 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=1200, lr=1.56495e-05, gnorm=0.252, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1361
2023-02-20 13:48:40 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=1210, lr=1.57799e-05, gnorm=0.226, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1372
2023-02-20 13:48:50 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.2, ups=0.93, wpb=110.2, bsz=40, num_updates=1220, lr=1.59103e-05, gnorm=0.265, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1383
2023-02-20 13:49:02 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.2, bsz=40, num_updates=1230, lr=1.60407e-05, gnorm=0.309, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1395
2023-02-20 13:49:13 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.1, bsz=40, num_updates=1240, lr=1.61711e-05, gnorm=0.208, clip=0, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=1405
2023-02-20 13:49:24 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=95.6, ups=0.88, wpb=108.6, bsz=40, num_updates=1250, lr=1.63015e-05, gnorm=0.21, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1417
2023-02-20 13:49:35 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.89, wpb=110.8, bsz=40, num_updates=1260, lr=1.64319e-05, gnorm=0.293, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1428
2023-02-20 13:49:46 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.8, bsz=40, num_updates=1270, lr=1.65623e-05, gnorm=0.205, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1439
2023-02-20 13:49:57 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=1280, lr=1.66927e-05, gnorm=0.252, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1450
2023-02-20 13:50:09 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=1290, lr=1.68232e-05, gnorm=0.214, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1461
2023-02-20 13:50:20 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.4, ups=0.88, wpb=111.8, bsz=40, num_updates=1300, lr=1.69536e-05, gnorm=0.227, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1473
2023-02-20 13:50:31 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.8, bsz=40, num_updates=1310, lr=1.7084e-05, gnorm=0.24, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1484
2023-02-20 13:50:42 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.7, ups=0.94, wpb=111.3, bsz=40, num_updates=1320, lr=1.72144e-05, gnorm=0.237, clip=0, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=1495
2023-02-20 13:50:53 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.91, wpb=110.5, bsz=40, num_updates=1330, lr=1.73448e-05, gnorm=0.273, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1506
2023-02-20 13:51:04 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.6, bsz=40, num_updates=1340, lr=1.74752e-05, gnorm=0.202, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1517
2023-02-20 13:51:15 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=1350, lr=1.76056e-05, gnorm=0.288, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1528
2023-02-20 13:51:26 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.93, wpb=110.7, bsz=40, num_updates=1360, lr=1.7736e-05, gnorm=0.221, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1539
2023-02-20 13:51:37 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=1370, lr=1.78665e-05, gnorm=0.175, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1550
2023-02-20 13:51:49 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=1380, lr=1.79969e-05, gnorm=0.291, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1561
2023-02-20 13:52:00 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.6, bsz=40, num_updates=1390, lr=1.81273e-05, gnorm=0.268, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1573
2023-02-20 13:52:11 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 142023 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.89, wpb=111.7, bsz=40, num_updates=1400, lr=1.82577e-05, gnorm=0.383, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1584
2023-02-20 13:52:22 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=1410, lr=1.83881e-05, gnorm=0.271, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1595
2023-02-20 13:52:33 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=1420, lr=1.85185e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1606
2023-02-20 13:52:44 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.5, bsz=40, num_updates=1430, lr=1.86489e-05, gnorm=0.204, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=1617
2023-02-20 13:52:55 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=110.9, bsz=40, num_updates=1440, lr=1.87793e-05, gnorm=0.258, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1628
2023-02-20 13:53:06 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.7, ups=0.94, wpb=111.2, bsz=40, num_updates=1450, lr=1.89098e-05, gnorm=0.369, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1639
2023-02-20 13:53:17 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.89, wpb=110, bsz=40, num_updates=1460, lr=1.90402e-05, gnorm=0.256, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1650
2023-02-20 13:53:28 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=1470, lr=1.91706e-05, gnorm=0.293, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1661
2023-02-20 13:53:40 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=1480, lr=1.9301e-05, gnorm=0.296, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1672
2023-02-20 13:53:51 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 142023 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.9, ups=0.9, wpb=112.9, bsz=40, num_updates=1490, lr=1.94314e-05, gnorm=0.288, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1684
2023-02-20 13:54:02 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.2, ups=0.88, wpb=109.9, bsz=40, num_updates=1500, lr=1.95618e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1695
2023-02-20 13:54:13 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.92, wpb=109.1, bsz=40, num_updates=1510, lr=1.96922e-05, gnorm=0.326, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1706
2023-02-20 13:54:24 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.1, bsz=40, num_updates=1520, lr=1.98226e-05, gnorm=0.285, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1717
2023-02-20 13:54:35 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=1530, lr=1.99531e-05, gnorm=0.298, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1728
2023-02-20 13:54:47 - progress_bar.py[line:274] - INFO: epoch 001:   1540 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=111.3, bsz=40, num_updates=1540, lr=2.00835e-05, gnorm=0.246, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1740
2023-02-20 13:54:58 - progress_bar.py[line:274] - INFO: epoch 001:   1550 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111.1, bsz=40, num_updates=1550, lr=2.02139e-05, gnorm=0.208, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1751
2023-02-20 13:55:09 - progress_bar.py[line:274] - INFO: epoch 001:   1560 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=1560, lr=2.03443e-05, gnorm=0.195, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=1762
2023-02-20 13:55:20 - progress_bar.py[line:274] - INFO: epoch 001:   1570 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.93, wpb=110.7, bsz=40, num_updates=1570, lr=2.04747e-05, gnorm=0.267, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1773
2023-02-20 13:55:31 - progress_bar.py[line:274] - INFO: epoch 001:   1580 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=94.2, ups=0.87, wpb=108.6, bsz=40, num_updates=1580, lr=2.06051e-05, gnorm=0.354, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=1784
2023-02-20 13:55:43 - progress_bar.py[line:274] - INFO: epoch 001:   1590 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=1590, lr=2.07355e-05, gnorm=0.447, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1795
2023-02-20 13:55:54 - progress_bar.py[line:274] - INFO: epoch 001:   1600 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=1600, lr=2.08659e-05, gnorm=0.198, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1806
2023-02-20 13:56:05 - progress_bar.py[line:274] - INFO: epoch 001:   1610 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=1610, lr=2.09963e-05, gnorm=0.229, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1818
2023-02-20 13:56:16 - progress_bar.py[line:274] - INFO: epoch 001:   1620 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.5, bsz=40, num_updates=1620, lr=2.11268e-05, gnorm=0.256, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1829
2023-02-20 13:56:27 - progress_bar.py[line:274] - INFO: epoch 001:   1630 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=110.8, bsz=40, num_updates=1630, lr=2.12572e-05, gnorm=0.24, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=1840
2023-02-20 13:56:38 - progress_bar.py[line:274] - INFO: epoch 001:   1640 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.1, ups=0.91, wpb=111.7, bsz=40, num_updates=1640, lr=2.13876e-05, gnorm=0.291, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1851
2023-02-20 13:56:49 - progress_bar.py[line:274] - INFO: epoch 001:   1650 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=1650, lr=2.1518e-05, gnorm=0.159, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1862
2023-02-20 13:57:00 - progress_bar.py[line:274] - INFO: epoch 001:   1660 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.2, bsz=40, num_updates=1660, lr=2.16484e-05, gnorm=0.235, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1873
2023-02-20 13:57:12 - progress_bar.py[line:274] - INFO: epoch 001:   1670 / 142023 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.3, bsz=40, num_updates=1670, lr=2.17788e-05, gnorm=0.204, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1884
2023-02-20 13:57:23 - progress_bar.py[line:274] - INFO: epoch 001:   1680 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.92, wpb=109.1, bsz=40, num_updates=1680, lr=2.19092e-05, gnorm=0.215, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1895
2023-02-20 13:57:34 - progress_bar.py[line:274] - INFO: epoch 001:   1690 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.7, bsz=40, num_updates=1690, lr=2.20396e-05, gnorm=0.179, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1907
2023-02-20 13:57:45 - progress_bar.py[line:274] - INFO: epoch 001:   1700 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.8, bsz=40, num_updates=1700, lr=2.21701e-05, gnorm=0.252, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1918
2023-02-20 13:57:56 - progress_bar.py[line:274] - INFO: epoch 001:   1710 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.5, ups=0.91, wpb=112.9, bsz=40, num_updates=1710, lr=2.23005e-05, gnorm=0.264, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1929
2023-02-20 13:58:08 - progress_bar.py[line:274] - INFO: epoch 001:   1720 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.5, bsz=40, num_updates=1720, lr=2.24309e-05, gnorm=0.277, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1940
2023-02-20 13:58:18 - progress_bar.py[line:274] - INFO: epoch 001:   1730 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=1730, lr=2.25613e-05, gnorm=0.284, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1951
2023-02-20 13:58:30 - progress_bar.py[line:274] - INFO: epoch 001:   1740 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=1740, lr=2.26917e-05, gnorm=0.216, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1962
2023-02-20 13:58:41 - progress_bar.py[line:274] - INFO: epoch 001:   1750 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111, bsz=40, num_updates=1750, lr=2.28221e-05, gnorm=0.267, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1974
2023-02-20 13:58:52 - progress_bar.py[line:274] - INFO: epoch 001:   1760 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.3, bsz=40, num_updates=1760, lr=2.29525e-05, gnorm=0.175, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1985
2023-02-20 13:59:03 - progress_bar.py[line:274] - INFO: epoch 001:   1770 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=1770, lr=2.30829e-05, gnorm=0.216, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1996
2023-02-20 13:59:15 - progress_bar.py[line:274] - INFO: epoch 001:   1780 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.88, wpb=109.4, bsz=40, num_updates=1780, lr=2.32134e-05, gnorm=0.175, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2008
2023-02-20 13:59:26 - progress_bar.py[line:274] - INFO: epoch 001:   1790 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=1790, lr=2.33438e-05, gnorm=0.166, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2019
2023-02-20 13:59:37 - progress_bar.py[line:274] - INFO: epoch 001:   1800 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.4, bsz=40, num_updates=1800, lr=2.34742e-05, gnorm=0.211, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2030
2023-02-20 13:59:49 - progress_bar.py[line:274] - INFO: epoch 001:   1810 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112.1, bsz=40, num_updates=1810, lr=2.36046e-05, gnorm=0.213, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2041
2023-02-20 14:00:00 - progress_bar.py[line:274] - INFO: epoch 001:   1820 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=1820, lr=2.3735e-05, gnorm=0.25, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2052
2023-02-20 14:00:11 - progress_bar.py[line:274] - INFO: epoch 001:   1830 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.4, bsz=40, num_updates=1830, lr=2.38654e-05, gnorm=0.252, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2064
2023-02-20 14:00:22 - progress_bar.py[line:274] - INFO: epoch 001:   1840 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.2, bsz=40, num_updates=1840, lr=2.39958e-05, gnorm=0.194, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2075
2023-02-20 14:00:33 - progress_bar.py[line:274] - INFO: epoch 001:   1850 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.4, ups=0.91, wpb=111.8, bsz=40, num_updates=1850, lr=2.41262e-05, gnorm=0.229, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2086
2023-02-20 14:00:44 - progress_bar.py[line:274] - INFO: epoch 001:   1860 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.91, wpb=112.3, bsz=40, num_updates=1860, lr=2.42567e-05, gnorm=0.213, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2097
2023-02-20 14:00:55 - progress_bar.py[line:274] - INFO: epoch 001:   1870 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.6, bsz=40, num_updates=1870, lr=2.43871e-05, gnorm=0.216, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2108
2023-02-20 14:01:06 - progress_bar.py[line:274] - INFO: epoch 001:   1880 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.91, wpb=110.3, bsz=40, num_updates=1880, lr=2.45175e-05, gnorm=0.284, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2119
2023-02-20 14:01:17 - progress_bar.py[line:274] - INFO: epoch 001:   1890 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.8, bsz=40, num_updates=1890, lr=2.46479e-05, gnorm=0.145, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2130
2023-02-20 14:01:28 - progress_bar.py[line:274] - INFO: epoch 001:   1900 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.93, wpb=111.1, bsz=40, num_updates=1900, lr=2.47783e-05, gnorm=0.162, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2141
2023-02-20 14:01:40 - progress_bar.py[line:274] - INFO: epoch 001:   1910 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.6, bsz=40, num_updates=1910, lr=2.49087e-05, gnorm=0.172, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2152
2023-02-20 14:01:51 - progress_bar.py[line:274] - INFO: epoch 001:   1920 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=1920, lr=2.50391e-05, gnorm=0.249, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2164
2023-02-20 14:02:02 - progress_bar.py[line:274] - INFO: epoch 001:   1930 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=112.1, bsz=40, num_updates=1930, lr=2.51695e-05, gnorm=0.238, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2175
2023-02-20 14:02:13 - progress_bar.py[line:274] - INFO: epoch 001:   1940 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.93, wpb=111.1, bsz=40, num_updates=1940, lr=2.52999e-05, gnorm=0.157, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2186
2023-02-20 14:02:24 - progress_bar.py[line:274] - INFO: epoch 001:   1950 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=1950, lr=2.54304e-05, gnorm=0.238, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2197
2023-02-20 14:02:35 - progress_bar.py[line:274] - INFO: epoch 001:   1960 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=109.8, bsz=40, num_updates=1960, lr=2.55608e-05, gnorm=0.15, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=2208
2023-02-20 14:02:47 - progress_bar.py[line:274] - INFO: epoch 001:   1970 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.9, bsz=40, num_updates=1970, lr=2.56912e-05, gnorm=0.186, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2219
2023-02-20 14:02:58 - progress_bar.py[line:274] - INFO: epoch 001:   1980 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=1980, lr=2.58216e-05, gnorm=0.213, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2231
2023-02-20 14:03:09 - progress_bar.py[line:274] - INFO: epoch 001:   1990 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=1990, lr=2.5952e-05, gnorm=0.158, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2242
2023-02-20 14:03:20 - progress_bar.py[line:274] - INFO: epoch 001:   2000 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.2, ups=0.92, wpb=110.6, bsz=40, num_updates=2000, lr=2.60824e-05, gnorm=0.219, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2253
2023-02-20 14:03:20 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-20 14:03:20 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-02-20 14:03:21 - train.py[line:549] - INFO: 0 / 6234
2023-02-20 14:03:21 - train.py[line:551] - INFO: load:1.19 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-20 14:05:26 - train.py[line:549] - INFO: 200 / 6234
2023-02-20 14:05:26 - train.py[line:551] - INFO: load:1.22 valid_run:124.27 task_valid:121.51 collect_output:1.64
2023-02-20 14:07:26 - train.py[line:549] - INFO: 400 / 6234
2023-02-20 14:07:26 - train.py[line:551] - INFO: load:1.25 valid_run:244.58 task_valid:237.67 collect_output:4.70
2023-02-20 14:09:29 - train.py[line:549] - INFO: 600 / 6234
2023-02-20 14:09:29 - train.py[line:551] - INFO: load:1.27 valid_run:367.45 task_valid:354.48 collect_output:9.67
2023-02-20 14:11:31 - train.py[line:549] - INFO: 800 / 6234
2023-02-20 14:11:31 - train.py[line:551] - INFO: load:1.30 valid_run:489.61 task_valid:468.67 collect_output:16.54
2023-02-20 14:13:32 - train.py[line:549] - INFO: 1000 / 6234
2023-02-20 14:13:32 - train.py[line:551] - INFO: load:1.33 valid_run:610.42 task_valid:586.46 collect_output:18.48
2023-02-20 14:15:35 - train.py[line:549] - INFO: 1200 / 6234
2023-02-20 14:15:35 - train.py[line:551] - INFO: load:1.35 valid_run:733.51 task_valid:705.41 collect_output:21.56
2023-02-20 14:17:39 - train.py[line:549] - INFO: 1400 / 6234
2023-02-20 14:17:39 - train.py[line:551] - INFO: load:1.38 valid_run:857.32 task_valid:824.62 collect_output:25.10
2023-02-20 14:19:41 - train.py[line:549] - INFO: 1600 / 6234
2023-02-20 14:19:41 - train.py[line:551] - INFO: load:1.41 valid_run:979.66 task_valid:941.44 collect_output:29.55
2023-02-20 14:21:45 - train.py[line:549] - INFO: 1800 / 6234
2023-02-20 14:21:45 - train.py[line:551] - INFO: load:1.43 valid_run:1103.49 task_valid:1059.13 collect_output:34.66
2023-02-20 14:23:47 - train.py[line:549] - INFO: 2000 / 6234
2023-02-20 14:23:47 - train.py[line:551] - INFO: load:1.45 valid_run:1225.50 task_valid:1172.46 collect_output:42.27
2023-02-20 14:25:48 - train.py[line:549] - INFO: 2200 / 6234
2023-02-20 14:25:48 - train.py[line:551] - INFO: load:1.48 valid_run:1346.37 task_valid:1289.00 collect_output:45.53
2023-02-20 14:27:51 - train.py[line:549] - INFO: 2400 / 6234
2023-02-20 14:27:51 - train.py[line:551] - INFO: load:1.50 valid_run:1468.47 task_valid:1406.78 collect_output:48.80
2023-02-20 14:29:50 - train.py[line:549] - INFO: 2600 / 6234
2023-02-20 14:29:50 - train.py[line:551] - INFO: load:1.53 valid_run:1587.88 task_valid:1521.32 collect_output:52.59
2023-02-20 14:31:52 - train.py[line:549] - INFO: 2800 / 6234
2023-02-20 14:31:52 - train.py[line:551] - INFO: load:1.55 valid_run:1709.37 task_valid:1639.57 collect_output:54.75
2023-02-20 14:33:53 - train.py[line:549] - INFO: 3000 / 6234
2023-02-20 14:33:53 - train.py[line:551] - INFO: load:1.58 valid_run:1830.62 task_valid:1756.05 collect_output:58.49
2023-02-20 14:35:54 - train.py[line:549] - INFO: 3200 / 6234
2023-02-20 14:35:54 - train.py[line:551] - INFO: load:1.60 valid_run:1952.09 task_valid:1870.58 collect_output:64.37
2023-02-20 14:37:56 - train.py[line:549] - INFO: 3400 / 6234
2023-02-20 14:37:56 - train.py[line:551] - INFO: load:1.63 valid_run:2074.02 task_valid:1987.18 collect_output:68.67
2023-02-20 14:39:58 - train.py[line:549] - INFO: 3600 / 6234
2023-02-20 14:39:58 - train.py[line:551] - INFO: load:1.65 valid_run:2195.12 task_valid:2105.53 collect_output:70.37
2023-02-20 14:41:59 - train.py[line:549] - INFO: 3800 / 6234
2023-02-20 14:41:59 - train.py[line:551] - INFO: load:1.68 valid_run:2316.76 task_valid:2223.00 collect_output:73.50
2023-02-20 14:44:01 - train.py[line:549] - INFO: 4000 / 6234
2023-02-20 14:44:01 - train.py[line:551] - INFO: load:1.70 valid_run:2438.19 task_valid:2340.65 collect_output:76.20
2023-02-20 14:46:03 - train.py[line:549] - INFO: 4200 / 6234
2023-02-20 14:46:03 - train.py[line:551] - INFO: load:1.73 valid_run:2560.76 task_valid:2458.83 collect_output:79.48
2023-02-20 14:48:06 - train.py[line:549] - INFO: 4400 / 6234
2023-02-20 14:48:06 - train.py[line:551] - INFO: load:1.75 valid_run:2683.74 task_valid:2578.94 collect_output:81.28
2023-02-20 14:50:08 - train.py[line:549] - INFO: 4600 / 6234
2023-02-20 14:50:08 - train.py[line:551] - INFO: load:1.78 valid_run:2804.92 task_valid:2694.68 collect_output:85.64
2023-02-20 14:52:08 - train.py[line:549] - INFO: 4800 / 6234
2023-02-20 14:52:08 - train.py[line:551] - INFO: load:1.80 valid_run:2925.34 task_valid:2811.79 collect_output:87.88
2023-02-20 14:54:11 - train.py[line:549] - INFO: 5000 / 6234
2023-02-20 14:54:11 - train.py[line:551] - INFO: load:1.83 valid_run:3047.95 task_valid:2929.37 collect_output:91.84
2023-02-20 14:56:14 - train.py[line:549] - INFO: 5200 / 6234
2023-02-20 14:56:14 - train.py[line:551] - INFO: load:1.85 valid_run:3171.58 task_valid:3046.96 collect_output:96.78
2023-02-20 14:58:15 - train.py[line:549] - INFO: 5400 / 6234
2023-02-20 14:58:15 - train.py[line:551] - INFO: load:1.88 valid_run:3292.25 task_valid:3162.92 collect_output:100.40
2023-02-20 15:00:18 - train.py[line:549] - INFO: 5600 / 6234
2023-02-20 15:00:18 - train.py[line:551] - INFO: load:1.90 valid_run:3415.05 task_valid:3283.43 collect_output:101.60
2023-02-20 15:02:21 - train.py[line:549] - INFO: 5800 / 6234
2023-02-20 15:02:21 - train.py[line:551] - INFO: load:1.93 valid_run:3537.64 task_valid:3400.39 collect_output:106.11
2023-02-20 15:04:24 - train.py[line:549] - INFO: 6000 / 6234
2023-02-20 15:04:24 - train.py[line:551] - INFO: load:1.96 valid_run:3660.69 task_valid:3520.26 collect_output:108.19
2023-02-20 15:06:26 - train.py[line:549] - INFO: 6200 / 6234
2023-02-20 15:06:26 - train.py[line:551] - INFO: load:1.98 valid_run:3782.54 task_valid:3639.61 collect_output:109.59

====================================================================================================
SGG eval:     R @ 50: 0.2908;     R @ 100: 0.3571;     R @ 500: 0.4222;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1196;    mR @ 100: 0.1868;    mR @ 500: 0.2183;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0732) (covered in:0.0000) (covering:0.1429) (eating:0.4412) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.2500) (playing:0.0000) (riding:0.4647) (says:0.0000) (sitting on:0.4127) (standing on:0.4975) (using:0.1500) (walking in:0.0000) (walking on:0.1622) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2908;     R @ 100: 0.3571;     R @ 500: 0.4222;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1196;    mR @ 100: 0.1868;    mR @ 500: 0.2183;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0732) (covered in:0.0000) (covering:0.1429) (eating:0.4412) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.2500) (playing:0.0000) (riding:0.4647) (says:0.0000) (sitting on:0.4127) (standing on:0.4975) (using:0.1500) (walking in:0.0000) (walking on:0.1622) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-02-20 15:06:57 - train.py[line:487] - INFO: 0.35706666666666664
2023-02-20 15:06:57 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-20 15:06:57 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.224 | loss_v1 0 | loss_v2 0 | nll_loss 0.06 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.357067 | ppl 1.04 | vqa_score 0.0968 | wps 117.6 | wpb 72 | bsz 24 | num_updates 2000
2023-02-20 15:06:57 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2023-02-20 15:06:57 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_2000.pt
2023-02-20 15:07:03 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_2000.pt
2023-02-20 15:07:12 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.35706666666666664) (writing took 15.634990997612476 seconds)
2023-02-20 15:07:24 - progress_bar.py[line:274] - INFO: epoch 001:   2010 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=111.5, bsz=40, num_updates=2010, lr=2.62128e-05, gnorm=0.164, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=6097
2023-02-20 15:07:35 - progress_bar.py[line:274] - INFO: epoch 001:   2020 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=2020, lr=2.63432e-05, gnorm=0.15, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=6108
2023-02-20 15:07:46 - progress_bar.py[line:274] - INFO: epoch 001:   2030 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=112.9, bsz=40, num_updates=2030, lr=2.64737e-05, gnorm=0.145, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6119
2023-02-20 15:07:57 - progress_bar.py[line:274] - INFO: epoch 001:   2040 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=110.5, bsz=40, num_updates=2040, lr=2.66041e-05, gnorm=0.171, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6130
2023-02-20 15:08:08 - progress_bar.py[line:274] - INFO: epoch 001:   2050 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=2050, lr=2.67345e-05, gnorm=0.216, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6141
2023-02-20 15:08:19 - progress_bar.py[line:274] - INFO: epoch 001:   2060 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=2060, lr=2.68649e-05, gnorm=0.232, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6152
2023-02-20 15:08:31 - progress_bar.py[line:274] - INFO: epoch 001:   2070 / 142023 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.7, bsz=40, num_updates=2070, lr=2.69953e-05, gnorm=0.24, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6164
2023-02-20 15:08:42 - progress_bar.py[line:274] - INFO: epoch 001:   2080 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.89, wpb=112.4, bsz=40, num_updates=2080, lr=2.71257e-05, gnorm=0.312, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6175
2023-02-20 15:08:53 - progress_bar.py[line:274] - INFO: epoch 001:   2090 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.2, ups=0.93, wpb=111.3, bsz=40, num_updates=2090, lr=2.72561e-05, gnorm=0.25, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6186
2023-02-20 15:09:04 - progress_bar.py[line:274] - INFO: epoch 001:   2100 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.89, wpb=111.8, bsz=40, num_updates=2100, lr=2.73865e-05, gnorm=0.298, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6197
2023-02-20 15:09:15 - progress_bar.py[line:274] - INFO: epoch 001:   2110 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.6, bsz=40, num_updates=2110, lr=2.7517e-05, gnorm=0.294, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6208
2023-02-20 15:09:26 - progress_bar.py[line:274] - INFO: epoch 001:   2120 / 142023 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.9, wpb=111.7, bsz=40, num_updates=2120, lr=2.76474e-05, gnorm=0.301, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6219
2023-02-20 15:09:37 - progress_bar.py[line:274] - INFO: epoch 001:   2130 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.91, wpb=108.8, bsz=40, num_updates=2130, lr=2.77778e-05, gnorm=0.206, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6230
2023-02-20 15:09:49 - progress_bar.py[line:274] - INFO: epoch 001:   2140 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.7, bsz=40, num_updates=2140, lr=2.79082e-05, gnorm=0.156, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6241
2023-02-20 15:10:00 - progress_bar.py[line:274] - INFO: epoch 001:   2150 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.1, bsz=40, num_updates=2150, lr=2.80386e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6253
2023-02-20 15:10:11 - progress_bar.py[line:274] - INFO: epoch 001:   2160 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.9, wpb=112.6, bsz=40, num_updates=2160, lr=2.8169e-05, gnorm=0.191, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=6264
2023-02-20 15:10:22 - progress_bar.py[line:274] - INFO: epoch 001:   2170 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.8, bsz=40, num_updates=2170, lr=2.82994e-05, gnorm=0.199, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6275
2023-02-20 15:10:33 - progress_bar.py[line:274] - INFO: epoch 001:   2180 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=2180, lr=2.84298e-05, gnorm=0.211, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6286
2023-02-20 15:10:44 - progress_bar.py[line:274] - INFO: epoch 001:   2190 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.4, ups=0.93, wpb=112.5, bsz=40, num_updates=2190, lr=2.85603e-05, gnorm=0.295, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6297
2023-02-20 15:10:55 - progress_bar.py[line:274] - INFO: epoch 001:   2200 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=2200, lr=2.86907e-05, gnorm=0.182, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6308
2023-02-20 15:11:06 - progress_bar.py[line:274] - INFO: epoch 001:   2210 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=2210, lr=2.88211e-05, gnorm=0.212, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6319
2023-02-20 15:11:17 - progress_bar.py[line:274] - INFO: epoch 001:   2220 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=2220, lr=2.89515e-05, gnorm=0.136, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6330
2023-02-20 15:11:28 - progress_bar.py[line:274] - INFO: epoch 001:   2230 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=109.8, bsz=40, num_updates=2230, lr=2.90819e-05, gnorm=0.186, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6341
2023-02-20 15:11:39 - progress_bar.py[line:274] - INFO: epoch 001:   2240 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=110.5, bsz=40, num_updates=2240, lr=2.92123e-05, gnorm=0.18, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6352
2023-02-20 15:11:50 - progress_bar.py[line:274] - INFO: epoch 001:   2250 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=111.5, bsz=40, num_updates=2250, lr=2.93427e-05, gnorm=0.155, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6363
2023-02-20 15:12:01 - progress_bar.py[line:274] - INFO: epoch 001:   2260 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.9, bsz=40, num_updates=2260, lr=2.94731e-05, gnorm=0.193, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6374
2023-02-20 15:12:12 - progress_bar.py[line:274] - INFO: epoch 001:   2270 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.2, bsz=40, num_updates=2270, lr=2.96035e-05, gnorm=0.177, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=6385
2023-02-20 15:12:24 - progress_bar.py[line:274] - INFO: epoch 001:   2280 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.87, wpb=113, bsz=40, num_updates=2280, lr=2.9734e-05, gnorm=0.162, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=6397
2023-02-20 15:12:35 - progress_bar.py[line:274] - INFO: epoch 001:   2290 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.6, bsz=40, num_updates=2290, lr=2.98644e-05, gnorm=0.227, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6408
2023-02-20 15:12:46 - progress_bar.py[line:274] - INFO: epoch 001:   2300 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=2300, lr=2.99948e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6419
2023-02-20 15:12:57 - progress_bar.py[line:274] - INFO: epoch 001:   2310 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=2310, lr=3.01252e-05, gnorm=0.2, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6430
2023-02-20 15:13:09 - progress_bar.py[line:274] - INFO: epoch 001:   2320 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=2320, lr=3.02556e-05, gnorm=0.232, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6442
2023-02-20 15:13:20 - progress_bar.py[line:274] - INFO: epoch 001:   2330 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=2330, lr=3.0386e-05, gnorm=0.16, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6453
2023-02-20 15:13:31 - progress_bar.py[line:274] - INFO: epoch 001:   2340 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.87, wpb=110.1, bsz=40, num_updates=2340, lr=3.05164e-05, gnorm=0.189, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6464
2023-02-20 15:13:42 - progress_bar.py[line:274] - INFO: epoch 001:   2350 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.94, wpb=110.8, bsz=40, num_updates=2350, lr=3.06468e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6475
2023-02-20 15:13:53 - progress_bar.py[line:274] - INFO: epoch 001:   2360 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.3, ups=0.9, wpb=112.2, bsz=40, num_updates=2360, lr=3.07773e-05, gnorm=0.227, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6486
2023-02-20 15:14:05 - progress_bar.py[line:274] - INFO: epoch 001:   2370 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.88, wpb=111.5, bsz=40, num_updates=2370, lr=3.09077e-05, gnorm=0.204, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6497
2023-02-20 15:14:15 - progress_bar.py[line:274] - INFO: epoch 001:   2380 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.93, wpb=110.5, bsz=40, num_updates=2380, lr=3.10381e-05, gnorm=0.144, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6508
2023-02-20 15:14:26 - progress_bar.py[line:274] - INFO: epoch 001:   2390 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=2390, lr=3.11685e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6519
2023-02-20 15:14:37 - progress_bar.py[line:274] - INFO: epoch 001:   2400 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.3, ups=0.93, wpb=111.3, bsz=40, num_updates=2400, lr=3.12989e-05, gnorm=0.199, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6530
2023-02-20 15:14:48 - progress_bar.py[line:274] - INFO: epoch 001:   2410 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=111.7, bsz=40, num_updates=2410, lr=3.14293e-05, gnorm=0.148, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6541
2023-02-20 15:14:59 - progress_bar.py[line:274] - INFO: epoch 001:   2420 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.89, wpb=111.6, bsz=40, num_updates=2420, lr=3.15597e-05, gnorm=0.191, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6552
2023-02-20 15:15:11 - progress_bar.py[line:274] - INFO: epoch 001:   2430 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=2430, lr=3.16901e-05, gnorm=0.154, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6564
2023-02-20 15:15:22 - progress_bar.py[line:274] - INFO: epoch 001:   2440 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=112.1, bsz=40, num_updates=2440, lr=3.18206e-05, gnorm=0.163, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6575
2023-02-20 15:15:34 - progress_bar.py[line:274] - INFO: epoch 001:   2450 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=2450, lr=3.1951e-05, gnorm=0.202, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6586
2023-02-20 15:15:44 - progress_bar.py[line:274] - INFO: epoch 001:   2460 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.92, wpb=110.2, bsz=40, num_updates=2460, lr=3.20814e-05, gnorm=0.205, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6597
2023-02-20 15:15:56 - progress_bar.py[line:274] - INFO: epoch 001:   2470 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.5, bsz=40, num_updates=2470, lr=3.22118e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6609
2023-02-20 15:16:07 - progress_bar.py[line:274] - INFO: epoch 001:   2480 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=111.3, bsz=40, num_updates=2480, lr=3.23422e-05, gnorm=0.2, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6620
2023-02-20 15:16:18 - progress_bar.py[line:274] - INFO: epoch 001:   2490 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=2490, lr=3.24726e-05, gnorm=0.162, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=6631
2023-02-20 15:16:29 - progress_bar.py[line:274] - INFO: epoch 001:   2500 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=2500, lr=3.2603e-05, gnorm=0.166, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6642
2023-02-20 15:16:40 - progress_bar.py[line:274] - INFO: epoch 001:   2510 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.9, wpb=109.4, bsz=40, num_updates=2510, lr=3.27334e-05, gnorm=0.202, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6653
2023-02-20 15:16:51 - progress_bar.py[line:274] - INFO: epoch 001:   2520 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.92, wpb=108.3, bsz=40, num_updates=2520, lr=3.28638e-05, gnorm=0.17, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6664
2023-02-20 15:17:03 - progress_bar.py[line:274] - INFO: epoch 001:   2530 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=2530, lr=3.29943e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=6675
2023-02-20 15:17:13 - progress_bar.py[line:274] - INFO: epoch 001:   2540 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.5, ups=0.94, wpb=111.2, bsz=40, num_updates=2540, lr=3.31247e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6686
2023-02-20 15:17:24 - progress_bar.py[line:274] - INFO: epoch 001:   2550 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.93, wpb=111.4, bsz=40, num_updates=2550, lr=3.32551e-05, gnorm=0.165, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6697
2023-02-20 15:17:35 - progress_bar.py[line:274] - INFO: epoch 001:   2560 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.9, bsz=40, num_updates=2560, lr=3.33855e-05, gnorm=0.162, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6708
2023-02-20 15:17:46 - progress_bar.py[line:274] - INFO: epoch 001:   2570 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=2570, lr=3.35159e-05, gnorm=0.143, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6719
2023-02-20 15:17:57 - progress_bar.py[line:274] - INFO: epoch 001:   2580 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.8, bsz=40, num_updates=2580, lr=3.36463e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6730
2023-02-20 15:18:08 - progress_bar.py[line:274] - INFO: epoch 001:   2590 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=2590, lr=3.37767e-05, gnorm=0.149, clip=0, loss_scale=4096, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=6741
2023-02-20 15:18:20 - progress_bar.py[line:274] - INFO: epoch 001:   2600 / 142023 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=2600, lr=3.39071e-05, gnorm=0.232, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6753
2023-02-20 15:18:31 - progress_bar.py[line:274] - INFO: epoch 001:   2610 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.4, bsz=40, num_updates=2610, lr=3.40376e-05, gnorm=0.193, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6764
2023-02-20 15:18:42 - progress_bar.py[line:274] - INFO: epoch 001:   2620 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=112, bsz=40, num_updates=2620, lr=3.4168e-05, gnorm=0.193, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6775
2023-02-20 15:18:53 - progress_bar.py[line:274] - INFO: epoch 001:   2630 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.031, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=98.4, ups=0.89, wpb=110.8, bsz=40, num_updates=2630, lr=3.42984e-05, gnorm=0.144, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6786
2023-02-20 15:19:05 - progress_bar.py[line:274] - INFO: epoch 001:   2640 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=95.4, ups=0.87, wpb=110.1, bsz=40, num_updates=2640, lr=3.44288e-05, gnorm=0.173, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6798
2023-02-20 15:19:16 - progress_bar.py[line:274] - INFO: epoch 001:   2650 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.9, bsz=40, num_updates=2650, lr=3.45592e-05, gnorm=0.138, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6809
2023-02-20 15:19:27 - progress_bar.py[line:274] - INFO: epoch 001:   2660 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.9, ups=0.96, wpb=111.8, bsz=40, num_updates=2660, lr=3.46896e-05, gnorm=0.218, clip=0, loss_scale=4096, train_wall=10, gb_free=10.7, ema_decay=0.9999, wall=6819
2023-02-20 15:19:38 - progress_bar.py[line:274] - INFO: epoch 001:   2670 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=111.8, bsz=40, num_updates=2670, lr=3.482e-05, gnorm=0.189, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6830
2023-02-20 15:19:49 - progress_bar.py[line:274] - INFO: epoch 001:   2680 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.5, bsz=40, num_updates=2680, lr=3.49504e-05, gnorm=0.151, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6842
2023-02-20 15:20:00 - progress_bar.py[line:274] - INFO: epoch 001:   2690 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=2690, lr=3.50809e-05, gnorm=0.134, clip=0, loss_scale=4096, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6853
2023-02-20 15:20:11 - progress_bar.py[line:274] - INFO: epoch 001:   2700 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=2700, lr=3.52113e-05, gnorm=0.122, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6864
2023-02-20 15:20:23 - progress_bar.py[line:274] - INFO: epoch 001:   2710 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.89, wpb=112.1, bsz=40, num_updates=2710, lr=3.53417e-05, gnorm=0.254, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6875
2023-02-20 15:20:34 - progress_bar.py[line:274] - INFO: epoch 001:   2720 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=2720, lr=3.54721e-05, gnorm=0.162, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6887
2023-02-20 15:20:45 - progress_bar.py[line:274] - INFO: epoch 001:   2730 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=2730, lr=3.56025e-05, gnorm=0.212, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6898
2023-02-20 15:20:47 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 15:20:57 - progress_bar.py[line:274] - INFO: epoch 001:   2741 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91.7, ups=0.82, wpb=111.7, bsz=40, num_updates=2740, lr=3.57329e-05, gnorm=0.159, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6910
2023-02-20 15:21:08 - progress_bar.py[line:274] - INFO: epoch 001:   2751 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.1, bsz=40, num_updates=2750, lr=3.58633e-05, gnorm=0.145, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6921
2023-02-20 15:21:19 - progress_bar.py[line:274] - INFO: epoch 001:   2761 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.9, wpb=111.6, bsz=40, num_updates=2760, lr=3.59937e-05, gnorm=0.181, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6932
2023-02-20 15:21:30 - progress_bar.py[line:274] - INFO: epoch 001:   2771 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.93, wpb=110.8, bsz=40, num_updates=2770, lr=3.61242e-05, gnorm=0.184, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6943
2023-02-20 15:21:41 - progress_bar.py[line:274] - INFO: epoch 001:   2781 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=110.8, bsz=40, num_updates=2780, lr=3.62546e-05, gnorm=0.174, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6954
2023-02-20 15:21:53 - progress_bar.py[line:274] - INFO: epoch 001:   2791 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=2790, lr=3.6385e-05, gnorm=0.23, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6965
2023-02-20 15:22:04 - progress_bar.py[line:274] - INFO: epoch 001:   2801 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.3, ups=0.85, wpb=109.6, bsz=40, num_updates=2800, lr=3.65154e-05, gnorm=0.204, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6977
2023-02-20 15:22:16 - progress_bar.py[line:274] - INFO: epoch 001:   2811 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.5, bsz=40, num_updates=2810, lr=3.66458e-05, gnorm=0.193, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6988
2023-02-20 15:22:27 - progress_bar.py[line:274] - INFO: epoch 001:   2821 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110, bsz=40, num_updates=2820, lr=3.67762e-05, gnorm=0.182, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7000
2023-02-20 15:22:38 - progress_bar.py[line:274] - INFO: epoch 001:   2831 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.7, bsz=40, num_updates=2830, lr=3.69066e-05, gnorm=0.189, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7011
2023-02-20 15:22:50 - progress_bar.py[line:274] - INFO: epoch 001:   2841 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=2840, lr=3.7037e-05, gnorm=0.148, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7022
2023-02-20 15:23:01 - progress_bar.py[line:274] - INFO: epoch 001:   2851 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=2850, lr=3.71674e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7034
2023-02-20 15:23:12 - progress_bar.py[line:274] - INFO: epoch 001:   2861 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.7, bsz=40, num_updates=2860, lr=3.72979e-05, gnorm=0.131, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=7045
2023-02-20 15:23:23 - progress_bar.py[line:274] - INFO: epoch 001:   2871 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.8, bsz=40, num_updates=2870, lr=3.74283e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7056
2023-02-20 15:23:34 - progress_bar.py[line:274] - INFO: epoch 001:   2881 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.92, wpb=111.6, bsz=40, num_updates=2880, lr=3.75587e-05, gnorm=0.223, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7067
2023-02-20 15:23:46 - progress_bar.py[line:274] - INFO: epoch 001:   2891 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.1, ups=0.87, wpb=110.5, bsz=40, num_updates=2890, lr=3.76891e-05, gnorm=0.243, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7078
2023-02-20 15:23:57 - progress_bar.py[line:274] - INFO: epoch 001:   2901 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=2900, lr=3.78195e-05, gnorm=0.207, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=7090
2023-02-20 15:24:08 - progress_bar.py[line:274] - INFO: epoch 001:   2911 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.5, bsz=40, num_updates=2910, lr=3.79499e-05, gnorm=0.181, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=7101
2023-02-20 15:24:19 - progress_bar.py[line:274] - INFO: epoch 001:   2921 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=2920, lr=3.80803e-05, gnorm=0.166, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7112
2023-02-20 15:24:31 - progress_bar.py[line:274] - INFO: epoch 001:   2931 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.6, bsz=40, num_updates=2930, lr=3.82107e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7124
2023-02-20 15:24:42 - progress_bar.py[line:274] - INFO: epoch 001:   2941 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.6, ups=0.92, wpb=112, bsz=40, num_updates=2940, lr=3.83412e-05, gnorm=0.183, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7134
2023-02-20 15:24:53 - progress_bar.py[line:274] - INFO: epoch 001:   2951 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=2950, lr=3.84716e-05, gnorm=0.15, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7146
2023-02-20 15:25:04 - progress_bar.py[line:274] - INFO: epoch 001:   2961 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.88, wpb=110.5, bsz=40, num_updates=2960, lr=3.8602e-05, gnorm=0.181, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7157
2023-02-20 15:25:15 - progress_bar.py[line:274] - INFO: epoch 001:   2971 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.7, ups=0.88, wpb=108.8, bsz=40, num_updates=2970, lr=3.87324e-05, gnorm=0.153, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7168
2023-02-20 15:25:27 - progress_bar.py[line:274] - INFO: epoch 001:   2981 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=2980, lr=3.88628e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7179
2023-02-20 15:25:38 - progress_bar.py[line:274] - INFO: epoch 001:   2991 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=2990, lr=3.89932e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7191
2023-02-20 15:25:49 - progress_bar.py[line:274] - INFO: epoch 001:   3001 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=3000, lr=3.91236e-05, gnorm=0.168, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7202
2023-02-20 15:26:00 - progress_bar.py[line:274] - INFO: epoch 001:   3011 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.2, bsz=40, num_updates=3010, lr=3.9254e-05, gnorm=0.147, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7213
2023-02-20 15:26:11 - progress_bar.py[line:274] - INFO: epoch 001:   3021 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.4, bsz=40, num_updates=3020, lr=3.93845e-05, gnorm=0.173, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7224
2023-02-20 15:26:22 - progress_bar.py[line:274] - INFO: epoch 001:   3031 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=111.5, bsz=40, num_updates=3030, lr=3.95149e-05, gnorm=0.18, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7235
2023-02-20 15:26:33 - progress_bar.py[line:274] - INFO: epoch 001:   3041 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.9, wpb=111.6, bsz=40, num_updates=3040, lr=3.96453e-05, gnorm=0.145, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7246
2023-02-20 15:26:44 - progress_bar.py[line:274] - INFO: epoch 001:   3051 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.8, bsz=40, num_updates=3050, lr=3.97757e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7257
2023-02-20 15:26:55 - progress_bar.py[line:274] - INFO: epoch 001:   3061 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.7, bsz=40, num_updates=3060, lr=3.99061e-05, gnorm=0.113, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7268
2023-02-20 15:27:06 - progress_bar.py[line:274] - INFO: epoch 001:   3071 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.91, wpb=110, bsz=40, num_updates=3070, lr=4.00365e-05, gnorm=0.145, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7279
2023-02-20 15:27:18 - progress_bar.py[line:274] - INFO: epoch 001:   3081 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.9, wpb=108.6, bsz=40, num_updates=3080, lr=4.01669e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7290
2023-02-20 15:27:29 - progress_bar.py[line:274] - INFO: epoch 001:   3091 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=111.8, bsz=40, num_updates=3090, lr=4.02973e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7302
2023-02-20 15:27:40 - progress_bar.py[line:274] - INFO: epoch 001:   3101 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111, bsz=40, num_updates=3100, lr=4.04278e-05, gnorm=0.149, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=7313
2023-02-20 15:27:51 - progress_bar.py[line:274] - INFO: epoch 001:   3111 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.93, wpb=110.6, bsz=40, num_updates=3110, lr=4.05582e-05, gnorm=0.146, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7324
2023-02-20 15:28:02 - progress_bar.py[line:274] - INFO: epoch 001:   3121 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.3, ups=0.86, wpb=111.2, bsz=40, num_updates=3120, lr=4.06886e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=7335
2023-02-20 15:28:14 - progress_bar.py[line:274] - INFO: epoch 001:   3131 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111.4, bsz=40, num_updates=3130, lr=4.0819e-05, gnorm=0.129, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7347
2023-02-20 15:28:25 - progress_bar.py[line:274] - INFO: epoch 001:   3141 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.5, bsz=40, num_updates=3140, lr=4.09494e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7358
2023-02-20 15:28:36 - progress_bar.py[line:274] - INFO: epoch 001:   3151 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=3150, lr=4.10798e-05, gnorm=0.156, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=7369
2023-02-20 15:28:48 - progress_bar.py[line:274] - INFO: epoch 001:   3161 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=3160, lr=4.12102e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7381
2023-02-20 15:28:59 - progress_bar.py[line:274] - INFO: epoch 001:   3171 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.5, bsz=40, num_updates=3170, lr=4.13406e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=7391
2023-02-20 15:29:09 - progress_bar.py[line:274] - INFO: epoch 001:   3181 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.93, wpb=110.7, bsz=40, num_updates=3180, lr=4.1471e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7402
2023-02-20 15:29:20 - progress_bar.py[line:274] - INFO: epoch 001:   3191 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.91, wpb=113.3, bsz=40, num_updates=3190, lr=4.16015e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7413
2023-02-20 15:29:31 - progress_bar.py[line:274] - INFO: epoch 001:   3201 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.3, bsz=40, num_updates=3200, lr=4.17319e-05, gnorm=0.158, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7424
2023-02-20 15:29:42 - progress_bar.py[line:274] - INFO: epoch 001:   3211 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.92, wpb=110.1, bsz=40, num_updates=3210, lr=4.18623e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7435
2023-02-20 15:29:53 - progress_bar.py[line:274] - INFO: epoch 001:   3221 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.92, wpb=109.6, bsz=40, num_updates=3220, lr=4.19927e-05, gnorm=0.147, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7446
2023-02-20 15:30:04 - progress_bar.py[line:274] - INFO: epoch 001:   3231 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.93, wpb=109.2, bsz=40, num_updates=3230, lr=4.21231e-05, gnorm=0.153, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7457
2023-02-20 15:30:15 - progress_bar.py[line:274] - INFO: epoch 001:   3241 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.8, bsz=40, num_updates=3240, lr=4.22535e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=7468
2023-02-20 15:30:27 - progress_bar.py[line:274] - INFO: epoch 001:   3251 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.6, bsz=40, num_updates=3250, lr=4.23839e-05, gnorm=0.177, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7479
2023-02-20 15:30:38 - progress_bar.py[line:274] - INFO: epoch 001:   3261 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=3260, lr=4.25143e-05, gnorm=0.149, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7491
2023-02-20 15:30:49 - progress_bar.py[line:274] - INFO: epoch 001:   3271 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.93, wpb=110, bsz=40, num_updates=3270, lr=4.26448e-05, gnorm=0.15, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7501
2023-02-20 15:31:00 - progress_bar.py[line:274] - INFO: epoch 001:   3281 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=3280, lr=4.27752e-05, gnorm=0.127, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7513
2023-02-20 15:31:11 - progress_bar.py[line:274] - INFO: epoch 001:   3291 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=110.4, bsz=40, num_updates=3290, lr=4.29056e-05, gnorm=0.163, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7524
2023-02-20 15:31:22 - progress_bar.py[line:274] - INFO: epoch 001:   3301 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=3300, lr=4.3036e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7535
2023-02-20 15:31:34 - progress_bar.py[line:274] - INFO: epoch 001:   3311 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=3310, lr=4.31664e-05, gnorm=0.224, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7546
2023-02-20 15:31:45 - progress_bar.py[line:274] - INFO: epoch 001:   3321 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.9, bsz=40, num_updates=3320, lr=4.32968e-05, gnorm=0.175, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7558
2023-02-20 15:31:56 - progress_bar.py[line:274] - INFO: epoch 001:   3331 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=110.5, bsz=40, num_updates=3330, lr=4.34272e-05, gnorm=0.155, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=7569
2023-02-20 15:32:07 - progress_bar.py[line:274] - INFO: epoch 001:   3341 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.9, wpb=109, bsz=40, num_updates=3340, lr=4.35576e-05, gnorm=0.294, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7580
2023-02-20 15:32:18 - progress_bar.py[line:274] - INFO: epoch 001:   3351 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.9, wpb=112.9, bsz=40, num_updates=3350, lr=4.36881e-05, gnorm=0.121, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7591
2023-02-20 15:32:29 - progress_bar.py[line:274] - INFO: epoch 001:   3361 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.91, wpb=110, bsz=40, num_updates=3360, lr=4.38185e-05, gnorm=0.125, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7602
2023-02-20 15:32:40 - progress_bar.py[line:274] - INFO: epoch 001:   3371 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=3370, lr=4.39489e-05, gnorm=0.163, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7613
2023-02-20 15:32:51 - progress_bar.py[line:274] - INFO: epoch 001:   3381 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=3380, lr=4.40793e-05, gnorm=0.175, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7624
2023-02-20 15:33:02 - progress_bar.py[line:274] - INFO: epoch 001:   3391 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=110.9, bsz=40, num_updates=3390, lr=4.42097e-05, gnorm=0.139, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7635
2023-02-20 15:33:13 - progress_bar.py[line:274] - INFO: epoch 001:   3401 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=3400, lr=4.43401e-05, gnorm=0.153, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7646
2023-02-20 15:33:24 - progress_bar.py[line:274] - INFO: epoch 001:   3411 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.4, bsz=40, num_updates=3410, lr=4.44705e-05, gnorm=0.163, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7657
2023-02-20 15:33:35 - progress_bar.py[line:274] - INFO: epoch 001:   3421 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.93, wpb=109.8, bsz=40, num_updates=3420, lr=4.46009e-05, gnorm=0.131, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7668
2023-02-20 15:33:47 - progress_bar.py[line:274] - INFO: epoch 001:   3431 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.88, wpb=111.5, bsz=40, num_updates=3430, lr=4.47314e-05, gnorm=0.172, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7679
2023-02-20 15:33:58 - progress_bar.py[line:274] - INFO: epoch 001:   3441 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.91, wpb=110.6, bsz=40, num_updates=3440, lr=4.48618e-05, gnorm=0.233, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7691
2023-02-20 15:34:09 - progress_bar.py[line:274] - INFO: epoch 001:   3451 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.7, ups=0.86, wpb=111.1, bsz=40, num_updates=3450, lr=4.49922e-05, gnorm=0.168, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=7702
2023-02-20 15:34:20 - progress_bar.py[line:274] - INFO: epoch 001:   3461 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=3460, lr=4.51226e-05, gnorm=0.287, clip=10, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7713
2023-02-20 15:34:31 - progress_bar.py[line:274] - INFO: epoch 001:   3471 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.5, bsz=40, num_updates=3470, lr=4.5253e-05, gnorm=0.179, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7724
2023-02-20 15:34:42 - progress_bar.py[line:274] - INFO: epoch 001:   3481 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.92, wpb=109.2, bsz=40, num_updates=3480, lr=4.53834e-05, gnorm=0.146, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=7735
2023-02-20 15:34:53 - progress_bar.py[line:274] - INFO: epoch 001:   3491 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.8, ups=0.92, wpb=111, bsz=40, num_updates=3490, lr=4.55138e-05, gnorm=0.115, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7746
2023-02-20 15:35:04 - progress_bar.py[line:274] - INFO: epoch 001:   3501 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=3500, lr=4.56442e-05, gnorm=0.133, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7757
2023-02-20 15:35:15 - progress_bar.py[line:274] - INFO: epoch 001:   3511 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.5, bsz=40, num_updates=3510, lr=4.57746e-05, gnorm=0.131, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7768
2023-02-20 15:35:27 - progress_bar.py[line:274] - INFO: epoch 001:   3521 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112.2, bsz=40, num_updates=3520, lr=4.59051e-05, gnorm=0.19, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7779
2023-02-20 15:35:38 - progress_bar.py[line:274] - INFO: epoch 001:   3531 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=3530, lr=4.60355e-05, gnorm=0.157, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7791
2023-02-20 15:35:49 - progress_bar.py[line:274] - INFO: epoch 001:   3541 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=111.8, bsz=40, num_updates=3540, lr=4.61659e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7802
2023-02-20 15:36:00 - progress_bar.py[line:274] - INFO: epoch 001:   3551 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.9, wpb=111.7, bsz=40, num_updates=3550, lr=4.62963e-05, gnorm=0.135, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7813
2023-02-20 15:36:11 - progress_bar.py[line:274] - INFO: epoch 001:   3561 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.88, wpb=111.4, bsz=40, num_updates=3560, lr=4.64267e-05, gnorm=0.157, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=7824
2023-02-20 15:36:23 - progress_bar.py[line:274] - INFO: epoch 001:   3571 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=3570, lr=4.65571e-05, gnorm=0.171, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7836
2023-02-20 15:36:34 - progress_bar.py[line:274] - INFO: epoch 001:   3581 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.6, bsz=40, num_updates=3580, lr=4.66875e-05, gnorm=0.148, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7846
2023-02-20 15:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   3591 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.6, bsz=40, num_updates=3590, lr=4.68179e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=7857
2023-02-20 15:36:56 - progress_bar.py[line:274] - INFO: epoch 001:   3601 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.4, bsz=40, num_updates=3600, lr=4.69484e-05, gnorm=0.105, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7868
2023-02-20 15:37:07 - progress_bar.py[line:274] - INFO: epoch 001:   3611 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.91, wpb=110.7, bsz=40, num_updates=3610, lr=4.70788e-05, gnorm=0.16, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7879
2023-02-20 15:37:18 - progress_bar.py[line:274] - INFO: epoch 001:   3621 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=112.1, bsz=40, num_updates=3620, lr=4.72092e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=7891
2023-02-20 15:37:29 - progress_bar.py[line:274] - INFO: epoch 001:   3631 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=3630, lr=4.73396e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7902
2023-02-20 15:37:40 - progress_bar.py[line:274] - INFO: epoch 001:   3641 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=3640, lr=4.747e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7913
2023-02-20 15:37:51 - progress_bar.py[line:274] - INFO: epoch 001:   3651 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=3650, lr=4.76004e-05, gnorm=0.135, clip=0, loss_scale=4096, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=7924
2023-02-20 15:37:58 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 15:38:04 - progress_bar.py[line:274] - INFO: epoch 001:   3662 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.7, ups=0.82, wpb=110.8, bsz=40, num_updates=3660, lr=4.77308e-05, gnorm=0.149, clip=0, loss_scale=2048, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=7936
2023-02-20 15:38:15 - progress_bar.py[line:274] - INFO: epoch 001:   3672 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=112.1, bsz=40, num_updates=3670, lr=4.78612e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=7947
2023-02-20 15:38:26 - progress_bar.py[line:274] - INFO: epoch 001:   3682 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.4, ups=0.88, wpb=111.7, bsz=40, num_updates=3680, lr=4.79917e-05, gnorm=0.165, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=7959
2023-02-20 15:38:37 - progress_bar.py[line:274] - INFO: epoch 001:   3692 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111.1, bsz=40, num_updates=3690, lr=4.81221e-05, gnorm=0.188, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7970
2023-02-20 15:38:48 - progress_bar.py[line:274] - INFO: epoch 001:   3702 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.89, wpb=112.1, bsz=40, num_updates=3700, lr=4.82525e-05, gnorm=0.192, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=7981
2023-02-20 15:38:59 - progress_bar.py[line:274] - INFO: epoch 001:   3712 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.91, wpb=112.4, bsz=40, num_updates=3710, lr=4.83829e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=7992
2023-02-20 15:39:10 - progress_bar.py[line:274] - INFO: epoch 001:   3722 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.5, bsz=40, num_updates=3720, lr=4.85133e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=8003
2023-02-20 15:39:22 - progress_bar.py[line:274] - INFO: epoch 001:   3732 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.87, wpb=111.4, bsz=40, num_updates=3730, lr=4.86437e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=8015
2023-02-20 15:39:33 - progress_bar.py[line:274] - INFO: epoch 001:   3742 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=112.1, bsz=40, num_updates=3740, lr=4.87741e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=8026
2023-02-20 15:39:44 - progress_bar.py[line:274] - INFO: epoch 001:   3752 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.4, bsz=40, num_updates=3750, lr=4.89045e-05, gnorm=0.149, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=8037
2023-02-20 15:39:56 - progress_bar.py[line:274] - INFO: epoch 001:   3762 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.88, wpb=108.8, bsz=40, num_updates=3760, lr=4.9035e-05, gnorm=0.162, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8049
2023-02-20 15:40:07 - progress_bar.py[line:274] - INFO: epoch 001:   3772 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=3770, lr=4.91654e-05, gnorm=0.164, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=8060
2023-02-20 15:40:19 - progress_bar.py[line:274] - INFO: epoch 001:   3782 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.8, ups=0.85, wpb=112.2, bsz=40, num_updates=3780, lr=4.92958e-05, gnorm=0.131, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=8072
2023-02-20 15:40:30 - progress_bar.py[line:274] - INFO: epoch 001:   3792 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.4, ups=0.88, wpb=110.1, bsz=40, num_updates=3790, lr=4.94262e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8083
2023-02-20 15:40:41 - progress_bar.py[line:274] - INFO: epoch 001:   3802 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=3800, lr=4.95566e-05, gnorm=0.153, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=8094
2023-02-20 15:40:52 - progress_bar.py[line:274] - INFO: epoch 001:   3812 / 142023 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.89, wpb=111.8, bsz=40, num_updates=3810, lr=4.9687e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=8105
2023-02-20 15:41:04 - progress_bar.py[line:274] - INFO: epoch 001:   3822 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=3820, lr=4.98174e-05, gnorm=0.166, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8116
2023-02-20 15:41:15 - progress_bar.py[line:274] - INFO: epoch 001:   3832 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.88, wpb=109.3, bsz=40, num_updates=3830, lr=4.99478e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8128
2023-02-20 15:41:26 - progress_bar.py[line:274] - INFO: epoch 001:   3842 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=110.7, bsz=40, num_updates=3840, lr=4.99978e-05, gnorm=0.108, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=8139
2023-02-20 15:41:37 - progress_bar.py[line:274] - INFO: epoch 001:   3852 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=3850, lr=4.99942e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=8150
2023-02-20 15:41:48 - progress_bar.py[line:274] - INFO: epoch 001:   3862 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.1, bsz=40, num_updates=3860, lr=4.99906e-05, gnorm=0.154, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=8161
2023-02-20 15:42:00 - progress_bar.py[line:274] - INFO: epoch 001:   3872 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.8, bsz=40, num_updates=3870, lr=4.9987e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8172
2023-02-20 15:42:10 - progress_bar.py[line:274] - INFO: epoch 001:   3882 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.93, wpb=111.4, bsz=40, num_updates=3880, lr=4.99834e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=8183
2023-02-20 15:42:21 - progress_bar.py[line:274] - INFO: epoch 001:   3892 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=3890, lr=4.99797e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=8194
2023-02-20 15:42:33 - progress_bar.py[line:274] - INFO: epoch 001:   3902 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=3900, lr=4.99761e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=8205
2023-02-20 15:42:43 - progress_bar.py[line:274] - INFO: epoch 001:   3912 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.3, bsz=40, num_updates=3910, lr=4.99725e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=8216
2023-02-20 15:42:55 - progress_bar.py[line:274] - INFO: epoch 001:   3922 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.89, wpb=112.9, bsz=40, num_updates=3920, lr=4.99689e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=8227
2023-02-20 15:43:06 - progress_bar.py[line:274] - INFO: epoch 001:   3932 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.91, wpb=110.8, bsz=40, num_updates=3930, lr=4.99653e-05, gnorm=0.198, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=8238
2023-02-20 15:43:17 - progress_bar.py[line:274] - INFO: epoch 001:   3942 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.3, bsz=40, num_updates=3940, lr=4.99616e-05, gnorm=0.158, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=8250
2023-02-20 15:43:28 - progress_bar.py[line:274] - INFO: epoch 001:   3952 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.5, ups=0.92, wpb=111.5, bsz=40, num_updates=3950, lr=4.9958e-05, gnorm=0.158, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=8261
2023-02-20 15:43:39 - progress_bar.py[line:274] - INFO: epoch 001:   3962 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.7, bsz=40, num_updates=3960, lr=4.99544e-05, gnorm=0.165, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=8272
2023-02-20 15:43:50 - progress_bar.py[line:274] - INFO: epoch 001:   3972 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.89, wpb=111.6, bsz=40, num_updates=3970, lr=4.99508e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=8283
2023-02-20 15:44:01 - progress_bar.py[line:274] - INFO: epoch 001:   3982 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=3980, lr=4.99472e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=8294
2023-02-20 15:44:12 - progress_bar.py[line:274] - INFO: epoch 001:   3992 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=3990, lr=4.99436e-05, gnorm=0.117, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=8305
2023-02-20 15:44:23 - progress_bar.py[line:274] - INFO: epoch 001:   4002 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.94, wpb=111.1, bsz=40, num_updates=4000, lr=4.99399e-05, gnorm=0.107, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=8316
2023-02-20 15:44:23 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-20 15:44:24 - train.py[line:549] - INFO: 0 / 6234
2023-02-20 15:44:24 - train.py[line:551] - INFO: load:1.08 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-20 15:46:28 - train.py[line:549] - INFO: 200 / 6234
2023-02-20 15:46:28 - train.py[line:551] - INFO: load:1.11 valid_run:123.78 task_valid:120.53 collect_output:2.14
2023-02-20 15:48:28 - train.py[line:549] - INFO: 400 / 6234
2023-02-20 15:48:28 - train.py[line:551] - INFO: load:1.13 valid_run:244.01 task_valid:236.87 collect_output:4.96
2023-02-20 15:50:31 - train.py[line:549] - INFO: 600 / 6234
2023-02-20 15:50:31 - train.py[line:551] - INFO: load:1.16 valid_run:366.92 task_valid:353.99 collect_output:9.69
2023-02-20 15:52:34 - train.py[line:549] - INFO: 800 / 6234
2023-02-20 15:52:34 - train.py[line:551] - INFO: load:1.18 valid_run:489.20 task_valid:468.44 collect_output:16.45
2023-02-20 15:54:35 - train.py[line:549] - INFO: 1000 / 6234
2023-02-20 15:54:35 - train.py[line:551] - INFO: load:1.21 valid_run:610.10 task_valid:586.24 collect_output:18.52
2023-02-20 15:56:38 - train.py[line:549] - INFO: 1200 / 6234
2023-02-20 15:56:38 - train.py[line:551] - INFO: load:1.23 valid_run:733.69 task_valid:705.96 collect_output:21.31
2023-02-20 15:58:42 - train.py[line:549] - INFO: 1400 / 6234
2023-02-20 15:58:42 - train.py[line:551] - INFO: load:1.25 valid_run:857.35 task_valid:825.17 collect_output:24.70
2023-02-20 16:00:45 - train.py[line:549] - INFO: 1600 / 6234
2023-02-20 16:00:45 - train.py[line:551] - INFO: load:1.28 valid_run:979.88 task_valid:942.63 collect_output:28.70
2023-02-20 16:02:49 - train.py[line:549] - INFO: 1800 / 6234
2023-02-20 16:02:49 - train.py[line:551] - INFO: load:1.30 valid_run:1104.03 task_valid:1060.89 collect_output:33.45
2023-02-20 16:04:51 - train.py[line:549] - INFO: 2000 / 6234
2023-02-20 16:04:51 - train.py[line:551] - INFO: load:1.33 valid_run:1225.93 task_valid:1174.43 collect_output:40.67
2023-02-20 16:06:52 - train.py[line:549] - INFO: 2200 / 6234
2023-02-20 16:06:52 - train.py[line:551] - INFO: load:1.35 valid_run:1346.87 task_valid:1291.08 collect_output:43.84
2023-02-20 16:08:54 - train.py[line:549] - INFO: 2400 / 6234
2023-02-20 16:08:54 - train.py[line:551] - INFO: load:1.38 valid_run:1469.12 task_valid:1409.03 collect_output:47.01
2023-02-20 16:10:54 - train.py[line:549] - INFO: 2600 / 6234
2023-02-20 16:10:54 - train.py[line:551] - INFO: load:1.40 valid_run:1588.50 task_valid:1523.57 collect_output:50.79
2023-02-20 16:12:55 - train.py[line:549] - INFO: 2800 / 6234
2023-02-20 16:12:55 - train.py[line:551] - INFO: load:1.43 valid_run:1710.27 task_valid:1642.25 collect_output:52.79
2023-02-20 16:14:57 - train.py[line:549] - INFO: 3000 / 6234
2023-02-20 16:14:57 - train.py[line:551] - INFO: load:1.45 valid_run:1832.06 task_valid:1759.62 collect_output:56.08
2023-02-20 16:16:59 - train.py[line:549] - INFO: 3200 / 6234
2023-02-20 16:16:59 - train.py[line:551] - INFO: load:1.47 valid_run:1953.39 task_valid:1874.37 collect_output:61.60
2023-02-20 16:19:01 - train.py[line:549] - INFO: 3400 / 6234
2023-02-20 16:19:01 - train.py[line:551] - INFO: load:1.50 valid_run:2075.51 task_valid:1991.66 collect_output:65.34
2023-02-20 16:21:02 - train.py[line:549] - INFO: 3600 / 6234
2023-02-20 16:21:02 - train.py[line:551] - INFO: load:1.52 valid_run:2196.94 task_valid:2110.47 collect_output:66.88
2023-02-20 16:23:05 - train.py[line:549] - INFO: 3800 / 6234
2023-02-20 16:23:05 - train.py[line:551] - INFO: load:1.55 valid_run:2319.29 task_valid:2228.83 collect_output:69.74
2023-02-20 16:25:06 - train.py[line:549] - INFO: 4000 / 6234
2023-02-20 16:25:06 - train.py[line:551] - INFO: load:1.58 valid_run:2440.56 task_valid:2346.61 collect_output:72.12
2023-02-20 16:27:09 - train.py[line:549] - INFO: 4200 / 6234
2023-02-20 16:27:09 - train.py[line:551] - INFO: load:1.60 valid_run:2563.24 task_valid:2464.71 collect_output:75.56
2023-02-20 16:29:12 - train.py[line:549] - INFO: 4400 / 6234
2023-02-20 16:29:12 - train.py[line:551] - INFO: load:1.63 valid_run:2686.08 task_valid:2584.82 collect_output:77.19
2023-02-20 16:31:13 - train.py[line:549] - INFO: 4600 / 6234
2023-02-20 16:31:13 - train.py[line:551] - INFO: load:1.65 valid_run:2807.20 task_valid:2700.11 collect_output:81.88
2023-02-20 16:33:13 - train.py[line:549] - INFO: 4800 / 6234
2023-02-20 16:33:13 - train.py[line:551] - INFO: load:1.68 valid_run:2927.12 task_valid:2816.50 collect_output:84.40
2023-02-20 16:35:15 - train.py[line:549] - INFO: 5000 / 6234
2023-02-20 16:35:15 - train.py[line:551] - INFO: load:1.70 valid_run:3048.93 task_valid:2933.10 collect_output:88.60
2023-02-20 16:37:18 - train.py[line:549] - INFO: 5200 / 6234
2023-02-20 16:37:18 - train.py[line:551] - INFO: load:1.73 valid_run:3171.89 task_valid:3049.52 collect_output:94.12
2023-02-20 16:39:18 - train.py[line:549] - INFO: 5400 / 6234
2023-02-20 16:39:18 - train.py[line:551] - INFO: load:1.75 valid_run:3291.76 task_valid:3164.07 collect_output:98.40
2023-02-20 16:41:20 - train.py[line:549] - INFO: 5600 / 6234
2023-02-20 16:41:20 - train.py[line:551] - INFO: load:1.78 valid_run:3414.02 task_valid:3283.84 collect_output:99.83
2023-02-20 16:43:22 - train.py[line:549] - INFO: 5800 / 6234
2023-02-20 16:43:22 - train.py[line:551] - INFO: load:1.81 valid_run:3535.83 task_valid:3399.77 collect_output:104.68
2023-02-20 16:45:24 - train.py[line:549] - INFO: 6000 / 6234
2023-02-20 16:45:24 - train.py[line:551] - INFO: load:1.83 valid_run:3658.04 task_valid:3518.76 collect_output:106.85
2023-02-20 16:47:26 - train.py[line:549] - INFO: 6200 / 6234
2023-02-20 16:47:26 - train.py[line:551] - INFO: load:1.86 valid_run:3779.57 task_valid:3637.63 collect_output:108.48

====================================================================================================
SGG eval:     R @ 50: 0.5295;     R @ 100: 0.5754;     R @ 500: 0.6198;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2926;    mR @ 100: 0.3314;    mR @ 500: 0.3922;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4756) (covered in:0.0625) (covering:0.3714) (eating:0.7059) (flying in:0.5455) (growing on:0.0000) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7917) (playing:0.0000) (riding:0.9428) (says:0.0000) (sitting on:0.6091) (standing on:0.4571) (using:0.3000) (walking in:0.0000) (walking on:0.4595) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5295;     R @ 100: 0.5754;     R @ 500: 0.6198;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2926;    mR @ 100: 0.3314;    mR @ 500: 0.3922;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4756) (covered in:0.0625) (covering:0.3714) (eating:0.7059) (flying in:0.5455) (growing on:0.0000) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7917) (playing:0.0000) (riding:0.9428) (says:0.0000) (sitting on:0.6091) (standing on:0.4571) (using:0.3000) (walking in:0.0000) (walking on:0.4595) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================

2023-02-20 16:47:57 - train.py[line:487] - INFO: 0.5753919022154317
2023-02-20 16:47:57 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-20 16:47:57 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.22 | loss_v1 0 | loss_v2 0 | nll_loss 0.048 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.575392 | ppl 1.03 | vqa_score 0.0631 | wps 117.7 | wpb 72 | bsz 24 | num_updates 4000 | best_R@100 0.575392
2023-02-20 16:47:57 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2023-02-20 16:47:57 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_4000.pt
2023-02-20 16:48:03 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_4000.pt
2023-02-20 16:48:08 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.5753919022154317) (writing took 10.965312449261546 seconds)
2023-02-20 16:48:20 - progress_bar.py[line:274] - INFO: epoch 001:   4012 / 142023 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=0.3, ups=0, wpb=110.4, bsz=40, num_updates=4010, lr=4.99363e-05, gnorm=0.181, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=12152
2023-02-20 16:48:31 - progress_bar.py[line:274] - INFO: epoch 001:   4022 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=4020, lr=4.99327e-05, gnorm=0.148, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12163
2023-02-20 16:48:42 - progress_bar.py[line:274] - INFO: epoch 001:   4032 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=111.7, bsz=40, num_updates=4030, lr=4.99291e-05, gnorm=0.141, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12174
2023-02-20 16:48:53 - progress_bar.py[line:274] - INFO: epoch 001:   4042 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=95.7, ups=0.87, wpb=110, bsz=40, num_updates=4040, lr=4.99255e-05, gnorm=0.191, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12186
2023-02-20 16:49:05 - progress_bar.py[line:274] - INFO: epoch 001:   4052 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=4050, lr=4.99218e-05, gnorm=0.141, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12197
2023-02-20 16:49:15 - progress_bar.py[line:274] - INFO: epoch 001:   4062 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.3, ups=0.93, wpb=112.2, bsz=40, num_updates=4060, lr=4.99182e-05, gnorm=0.164, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12208
2023-02-20 16:49:26 - progress_bar.py[line:274] - INFO: epoch 001:   4072 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.8, bsz=40, num_updates=4070, lr=4.99146e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=12219
2023-02-20 16:49:37 - progress_bar.py[line:274] - INFO: epoch 001:   4082 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111, bsz=40, num_updates=4080, lr=4.9911e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12230
2023-02-20 16:49:48 - progress_bar.py[line:274] - INFO: epoch 001:   4092 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.93, wpb=109.8, bsz=40, num_updates=4090, lr=4.99074e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12241
2023-02-20 16:49:59 - progress_bar.py[line:274] - INFO: epoch 001:   4102 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=4100, lr=4.99038e-05, gnorm=0.148, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12252
2023-02-20 16:50:11 - progress_bar.py[line:274] - INFO: epoch 001:   4112 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=4110, lr=4.99001e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12263
2023-02-20 16:50:22 - progress_bar.py[line:274] - INFO: epoch 001:   4122 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=4120, lr=4.98965e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12275
2023-02-20 16:50:33 - progress_bar.py[line:274] - INFO: epoch 001:   4132 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.7, ups=0.87, wpb=109.8, bsz=40, num_updates=4130, lr=4.98929e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12286
2023-02-20 16:50:44 - progress_bar.py[line:274] - INFO: epoch 001:   4142 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.91, wpb=109.2, bsz=40, num_updates=4140, lr=4.98893e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12297
2023-02-20 16:50:55 - progress_bar.py[line:274] - INFO: epoch 001:   4152 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112, bsz=40, num_updates=4150, lr=4.98857e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=12308
2023-02-20 16:51:07 - progress_bar.py[line:274] - INFO: epoch 001:   4162 / 142023 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.89, wpb=111.5, bsz=40, num_updates=4160, lr=4.9882e-05, gnorm=0.161, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12319
2023-02-20 16:51:18 - progress_bar.py[line:274] - INFO: epoch 001:   4172 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=4170, lr=4.98784e-05, gnorm=0.145, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12331
2023-02-20 16:51:29 - progress_bar.py[line:274] - INFO: epoch 001:   4182 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.92, wpb=112.2, bsz=40, num_updates=4180, lr=4.98748e-05, gnorm=0.145, clip=0, loss_scale=4096, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=12342
2023-02-20 16:51:40 - progress_bar.py[line:274] - INFO: epoch 001:   4192 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=4190, lr=4.98712e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12353
2023-02-20 16:51:51 - progress_bar.py[line:274] - INFO: epoch 001:   4202 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.8, ups=0.93, wpb=111.5, bsz=40, num_updates=4200, lr=4.98676e-05, gnorm=0.143, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12364
2023-02-20 16:52:02 - progress_bar.py[line:274] - INFO: epoch 001:   4212 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=4210, lr=4.9864e-05, gnorm=0.12, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=12375
2023-02-20 16:52:13 - progress_bar.py[line:274] - INFO: epoch 001:   4222 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=112.1, bsz=40, num_updates=4220, lr=4.98603e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12386
2023-02-20 16:52:24 - progress_bar.py[line:274] - INFO: epoch 001:   4232 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.8, ups=0.92, wpb=112.5, bsz=40, num_updates=4230, lr=4.98567e-05, gnorm=0.129, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12397
2023-02-20 16:52:35 - progress_bar.py[line:274] - INFO: epoch 001:   4242 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.91, wpb=112.7, bsz=40, num_updates=4240, lr=4.98531e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=12408
2023-02-20 16:52:36 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 16:52:47 - progress_bar.py[line:274] - INFO: epoch 001:   4253 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.8, ups=0.84, wpb=112, bsz=40, num_updates=4250, lr=4.98495e-05, gnorm=0.139, clip=0, loss_scale=2048, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12420
2023-02-20 16:52:58 - progress_bar.py[line:274] - INFO: epoch 001:   4263 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=4260, lr=4.98459e-05, gnorm=0.153, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12431
2023-02-20 16:53:09 - progress_bar.py[line:274] - INFO: epoch 001:   4273 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=4270, lr=4.98422e-05, gnorm=0.155, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12442
2023-02-20 16:53:20 - progress_bar.py[line:274] - INFO: epoch 001:   4283 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.93, wpb=111.4, bsz=40, num_updates=4280, lr=4.98386e-05, gnorm=0.141, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=12453
2023-02-20 16:53:31 - progress_bar.py[line:274] - INFO: epoch 001:   4293 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.4, bsz=40, num_updates=4290, lr=4.9835e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12464
2023-02-20 16:53:43 - progress_bar.py[line:274] - INFO: epoch 001:   4303 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=4300, lr=4.98314e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=12475
2023-02-20 16:53:54 - progress_bar.py[line:274] - INFO: epoch 001:   4313 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=111, bsz=40, num_updates=4310, lr=4.98278e-05, gnorm=0.115, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12487
2023-02-20 16:54:05 - progress_bar.py[line:274] - INFO: epoch 001:   4323 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=110.8, bsz=40, num_updates=4320, lr=4.98242e-05, gnorm=0.13, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12498
2023-02-20 16:54:16 - progress_bar.py[line:274] - INFO: epoch 001:   4333 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=4330, lr=4.98205e-05, gnorm=0.094, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12509
2023-02-20 16:54:28 - progress_bar.py[line:274] - INFO: epoch 001:   4343 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=4340, lr=4.98169e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12521
2023-02-20 16:54:39 - progress_bar.py[line:274] - INFO: epoch 001:   4353 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.89, wpb=111.7, bsz=40, num_updates=4350, lr=4.98133e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12532
2023-02-20 16:54:50 - progress_bar.py[line:274] - INFO: epoch 001:   4363 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=112, bsz=40, num_updates=4360, lr=4.98097e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12543
2023-02-20 16:55:01 - progress_bar.py[line:274] - INFO: epoch 001:   4373 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.6, ups=0.94, wpb=111, bsz=40, num_updates=4370, lr=4.98061e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12554
2023-02-20 16:55:12 - progress_bar.py[line:274] - INFO: epoch 001:   4383 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110, bsz=40, num_updates=4380, lr=4.98024e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=12565
2023-02-20 16:55:23 - progress_bar.py[line:274] - INFO: epoch 001:   4393 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.9, wpb=112.6, bsz=40, num_updates=4390, lr=4.97988e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=12576
2023-02-20 16:55:35 - progress_bar.py[line:274] - INFO: epoch 001:   4403 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=111.3, bsz=40, num_updates=4400, lr=4.97952e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12588
2023-02-20 16:55:46 - progress_bar.py[line:274] - INFO: epoch 001:   4413 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.1, bsz=40, num_updates=4410, lr=4.97916e-05, gnorm=0.136, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12599
2023-02-20 16:55:57 - progress_bar.py[line:274] - INFO: epoch 001:   4423 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=4420, lr=4.9788e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12610
2023-02-20 16:56:08 - progress_bar.py[line:274] - INFO: epoch 001:   4433 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.8, bsz=40, num_updates=4430, lr=4.97844e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12621
2023-02-20 16:56:19 - progress_bar.py[line:274] - INFO: epoch 001:   4443 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=4440, lr=4.97807e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=12632
2023-02-20 16:56:31 - progress_bar.py[line:274] - INFO: epoch 001:   4453 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.5, bsz=40, num_updates=4450, lr=4.97771e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=12643
2023-02-20 16:56:42 - progress_bar.py[line:274] - INFO: epoch 001:   4463 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=4460, lr=4.97735e-05, gnorm=0.144, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12655
2023-02-20 16:56:53 - progress_bar.py[line:274] - INFO: epoch 001:   4473 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.3, bsz=40, num_updates=4470, lr=4.97699e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12666
2023-02-20 16:57:04 - progress_bar.py[line:274] - INFO: epoch 001:   4483 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.88, wpb=111.2, bsz=40, num_updates=4480, lr=4.97663e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12677
2023-02-20 16:57:16 - progress_bar.py[line:274] - INFO: epoch 001:   4493 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.8, bsz=40, num_updates=4490, lr=4.97626e-05, gnorm=0.153, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12688
2023-02-20 16:57:27 - progress_bar.py[line:274] - INFO: epoch 001:   4503 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.3, bsz=40, num_updates=4500, lr=4.9759e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12700
2023-02-20 16:57:38 - progress_bar.py[line:274] - INFO: epoch 001:   4513 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.2, bsz=40, num_updates=4510, lr=4.97554e-05, gnorm=0.154, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12711
2023-02-20 16:57:49 - progress_bar.py[line:274] - INFO: epoch 001:   4523 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=111.9, bsz=40, num_updates=4520, lr=4.97518e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12722
2023-02-20 16:58:00 - progress_bar.py[line:274] - INFO: epoch 001:   4533 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=111.6, bsz=40, num_updates=4530, lr=4.97482e-05, gnorm=0.104, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12733
2023-02-20 16:58:11 - progress_bar.py[line:274] - INFO: epoch 001:   4543 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.89, wpb=109.5, bsz=40, num_updates=4540, lr=4.97446e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12744
2023-02-20 16:58:22 - progress_bar.py[line:274] - INFO: epoch 001:   4553 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=4550, lr=4.97409e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12755
2023-02-20 16:58:34 - progress_bar.py[line:274] - INFO: epoch 001:   4563 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=4560, lr=4.97373e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12766
2023-02-20 16:58:45 - progress_bar.py[line:274] - INFO: epoch 001:   4573 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.1, bsz=40, num_updates=4570, lr=4.97337e-05, gnorm=0.063, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12778
2023-02-20 16:58:56 - progress_bar.py[line:274] - INFO: epoch 001:   4583 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=4580, lr=4.97301e-05, gnorm=0.126, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12789
2023-02-20 16:59:07 - progress_bar.py[line:274] - INFO: epoch 001:   4593 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.9, wpb=110.3, bsz=40, num_updates=4590, lr=4.97265e-05, gnorm=0.14, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12800
2023-02-20 16:59:18 - progress_bar.py[line:274] - INFO: epoch 001:   4603 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.92, wpb=110.6, bsz=40, num_updates=4600, lr=4.97228e-05, gnorm=0.128, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12811
2023-02-20 16:59:29 - progress_bar.py[line:274] - INFO: epoch 001:   4613 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.6, ups=0.94, wpb=110.8, bsz=40, num_updates=4610, lr=4.97192e-05, gnorm=0.173, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12822
2023-02-20 16:59:40 - progress_bar.py[line:274] - INFO: epoch 001:   4623 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.5, bsz=40, num_updates=4620, lr=4.97156e-05, gnorm=0.123, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12832
2023-02-20 16:59:51 - progress_bar.py[line:274] - INFO: epoch 001:   4633 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.4, ups=0.89, wpb=109.7, bsz=40, num_updates=4630, lr=4.9712e-05, gnorm=0.163, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12844
2023-02-20 17:00:02 - progress_bar.py[line:274] - INFO: epoch 001:   4643 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.5, bsz=40, num_updates=4640, lr=4.97084e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12855
2023-02-20 17:00:14 - progress_bar.py[line:274] - INFO: epoch 001:   4653 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=111.7, bsz=40, num_updates=4650, lr=4.97048e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12866
2023-02-20 17:00:25 - progress_bar.py[line:274] - INFO: epoch 001:   4663 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112, bsz=40, num_updates=4660, lr=4.97011e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12877
2023-02-20 17:00:36 - progress_bar.py[line:274] - INFO: epoch 001:   4673 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96, ups=0.87, wpb=110.6, bsz=40, num_updates=4670, lr=4.96975e-05, gnorm=0.136, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12889
2023-02-20 17:00:47 - progress_bar.py[line:274] - INFO: epoch 001:   4683 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.9, wpb=109.4, bsz=40, num_updates=4680, lr=4.96939e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12900
2023-02-20 17:00:58 - progress_bar.py[line:274] - INFO: epoch 001:   4693 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.6, bsz=40, num_updates=4690, lr=4.96903e-05, gnorm=0.093, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12911
2023-02-20 17:01:10 - progress_bar.py[line:274] - INFO: epoch 001:   4703 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.7, bsz=40, num_updates=4700, lr=4.96867e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=12922
2023-02-20 17:01:21 - progress_bar.py[line:274] - INFO: epoch 001:   4713 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=4710, lr=4.9683e-05, gnorm=0.134, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=12934
2023-02-20 17:01:32 - progress_bar.py[line:274] - INFO: epoch 001:   4723 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.3, ups=0.9, wpb=112.2, bsz=40, num_updates=4720, lr=4.96794e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=12945
2023-02-20 17:01:43 - progress_bar.py[line:274] - INFO: epoch 001:   4733 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.6, bsz=40, num_updates=4730, lr=4.96758e-05, gnorm=0.119, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=12956
2023-02-20 17:01:54 - progress_bar.py[line:274] - INFO: epoch 001:   4743 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.2, bsz=40, num_updates=4740, lr=4.96722e-05, gnorm=0.124, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=12967
2023-02-20 17:02:05 - progress_bar.py[line:274] - INFO: epoch 001:   4753 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.93, wpb=111.8, bsz=40, num_updates=4750, lr=4.96686e-05, gnorm=0.112, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=12978
2023-02-20 17:02:16 - progress_bar.py[line:274] - INFO: epoch 001:   4763 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.92, wpb=111.8, bsz=40, num_updates=4760, lr=4.9665e-05, gnorm=0.258, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=12989
2023-02-20 17:02:27 - progress_bar.py[line:274] - INFO: epoch 001:   4773 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.4, ups=0.91, wpb=110.5, bsz=40, num_updates=4770, lr=4.96613e-05, gnorm=0.136, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13000
2023-02-20 17:02:38 - progress_bar.py[line:274] - INFO: epoch 001:   4783 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.1, ups=0.92, wpb=111.9, bsz=40, num_updates=4780, lr=4.96577e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13011
2023-02-20 17:02:49 - progress_bar.py[line:274] - INFO: epoch 001:   4793 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.1, bsz=40, num_updates=4790, lr=4.96541e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13022
2023-02-20 17:03:00 - progress_bar.py[line:274] - INFO: epoch 001:   4803 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=4800, lr=4.96505e-05, gnorm=0.13, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=13033
2023-02-20 17:03:12 - progress_bar.py[line:274] - INFO: epoch 001:   4813 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.4, ups=0.87, wpb=109.9, bsz=40, num_updates=4810, lr=4.96469e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13045
2023-02-20 17:03:23 - progress_bar.py[line:274] - INFO: epoch 001:   4823 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.1, ups=0.9, wpb=111.7, bsz=40, num_updates=4820, lr=4.96432e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13056
2023-02-20 17:03:34 - progress_bar.py[line:274] - INFO: epoch 001:   4833 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=110.9, bsz=40, num_updates=4830, lr=4.96396e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13067
2023-02-20 17:03:45 - progress_bar.py[line:274] - INFO: epoch 001:   4843 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.93, wpb=111.2, bsz=40, num_updates=4840, lr=4.9636e-05, gnorm=0.12, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13078
2023-02-20 17:03:56 - progress_bar.py[line:274] - INFO: epoch 001:   4853 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.93, wpb=110.5, bsz=40, num_updates=4850, lr=4.96324e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13089
2023-02-20 17:04:07 - progress_bar.py[line:274] - INFO: epoch 001:   4863 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=4860, lr=4.96288e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=13100
2023-02-20 17:04:18 - progress_bar.py[line:274] - INFO: epoch 001:   4873 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.3, bsz=40, num_updates=4870, lr=4.96252e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13111
2023-02-20 17:04:29 - progress_bar.py[line:274] - INFO: epoch 001:   4883 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111.1, bsz=40, num_updates=4880, lr=4.96215e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13122
2023-02-20 17:04:41 - progress_bar.py[line:274] - INFO: epoch 001:   4893 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=110, bsz=40, num_updates=4890, lr=4.96179e-05, gnorm=0.12, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13133
2023-02-20 17:04:52 - progress_bar.py[line:274] - INFO: epoch 001:   4903 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.1, bsz=40, num_updates=4900, lr=4.96143e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13145
2023-02-20 17:05:03 - progress_bar.py[line:274] - INFO: epoch 001:   4913 / 142023 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.7, ups=0.88, wpb=112.1, bsz=40, num_updates=4910, lr=4.96107e-05, gnorm=0.124, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13156
2023-02-20 17:05:14 - progress_bar.py[line:274] - INFO: epoch 001:   4923 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=4920, lr=4.96071e-05, gnorm=0.112, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13167
2023-02-20 17:05:26 - progress_bar.py[line:274] - INFO: epoch 001:   4933 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.2, bsz=40, num_updates=4930, lr=4.96034e-05, gnorm=0.105, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=13178
2023-02-20 17:05:37 - progress_bar.py[line:274] - INFO: epoch 001:   4943 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.88, wpb=109.5, bsz=40, num_updates=4940, lr=4.95998e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13190
2023-02-20 17:05:48 - progress_bar.py[line:274] - INFO: epoch 001:   4953 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=4950, lr=4.95962e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13201
2023-02-20 17:05:59 - progress_bar.py[line:274] - INFO: epoch 001:   4963 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=112, bsz=40, num_updates=4960, lr=4.95926e-05, gnorm=0.143, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13212
2023-02-20 17:06:11 - progress_bar.py[line:274] - INFO: epoch 001:   4973 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.8, bsz=40, num_updates=4970, lr=4.9589e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13223
2023-02-20 17:06:21 - progress_bar.py[line:274] - INFO: epoch 001:   4983 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.8, bsz=40, num_updates=4980, lr=4.95854e-05, gnorm=0.101, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13234
2023-02-20 17:06:33 - progress_bar.py[line:274] - INFO: epoch 001:   4993 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.5, ups=0.88, wpb=109.9, bsz=40, num_updates=4990, lr=4.95817e-05, gnorm=0.121, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13246
2023-02-20 17:06:44 - progress_bar.py[line:274] - INFO: epoch 001:   5003 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=111.9, bsz=40, num_updates=5000, lr=4.95781e-05, gnorm=0.112, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13257
2023-02-20 17:06:55 - progress_bar.py[line:274] - INFO: epoch 001:   5013 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.89, wpb=112.7, bsz=40, num_updates=5010, lr=4.95745e-05, gnorm=0.125, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13268
2023-02-20 17:07:06 - progress_bar.py[line:274] - INFO: epoch 001:   5023 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.7, bsz=40, num_updates=5020, lr=4.95709e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13279
2023-02-20 17:07:17 - progress_bar.py[line:274] - INFO: epoch 001:   5033 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111.1, bsz=40, num_updates=5030, lr=4.95673e-05, gnorm=0.149, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13290
2023-02-20 17:07:28 - progress_bar.py[line:274] - INFO: epoch 001:   5043 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=111.1, bsz=40, num_updates=5040, lr=4.95636e-05, gnorm=0.137, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13301
2023-02-20 17:07:40 - progress_bar.py[line:274] - INFO: epoch 001:   5053 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.88, wpb=113.1, bsz=40, num_updates=5050, lr=4.956e-05, gnorm=0.167, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13313
2023-02-20 17:07:51 - progress_bar.py[line:274] - INFO: epoch 001:   5063 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=5060, lr=4.95564e-05, gnorm=0.151, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13324
2023-02-20 17:08:02 - progress_bar.py[line:274] - INFO: epoch 001:   5073 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.6, bsz=40, num_updates=5070, lr=4.95528e-05, gnorm=0.128, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13335
2023-02-20 17:08:13 - progress_bar.py[line:274] - INFO: epoch 001:   5083 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.8, bsz=40, num_updates=5080, lr=4.95492e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13346
2023-02-20 17:08:24 - progress_bar.py[line:274] - INFO: epoch 001:   5093 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.7, bsz=40, num_updates=5090, lr=4.95455e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=13357
2023-02-20 17:08:35 - progress_bar.py[line:274] - INFO: epoch 001:   5103 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.3, ups=0.92, wpb=111.5, bsz=40, num_updates=5100, lr=4.95419e-05, gnorm=0.149, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=13368
2023-02-20 17:08:46 - progress_bar.py[line:274] - INFO: epoch 001:   5113 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.88, wpb=112.7, bsz=40, num_updates=5110, lr=4.95383e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13379
2023-02-20 17:08:57 - progress_bar.py[line:274] - INFO: epoch 001:   5123 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.9, ups=0.92, wpb=112.2, bsz=40, num_updates=5120, lr=4.95347e-05, gnorm=0.146, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13390
2023-02-20 17:09:08 - progress_bar.py[line:274] - INFO: epoch 001:   5133 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.4, bsz=40, num_updates=5130, lr=4.95311e-05, gnorm=0.139, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13401
2023-02-20 17:09:20 - progress_bar.py[line:274] - INFO: epoch 001:   5143 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.89, wpb=110.2, bsz=40, num_updates=5140, lr=4.95275e-05, gnorm=0.133, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13412
2023-02-20 17:09:31 - progress_bar.py[line:274] - INFO: epoch 001:   5153 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.1, bsz=40, num_updates=5150, lr=4.95238e-05, gnorm=0.143, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13424
2023-02-20 17:09:42 - progress_bar.py[line:274] - INFO: epoch 001:   5163 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=111.1, bsz=40, num_updates=5160, lr=4.95202e-05, gnorm=0.134, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13435
2023-02-20 17:09:54 - progress_bar.py[line:274] - INFO: epoch 001:   5173 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111, bsz=40, num_updates=5170, lr=4.95166e-05, gnorm=0.125, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=13446
2023-02-20 17:10:05 - progress_bar.py[line:274] - INFO: epoch 001:   5183 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=5180, lr=4.9513e-05, gnorm=0.195, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13458
2023-02-20 17:10:16 - progress_bar.py[line:274] - INFO: epoch 001:   5193 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.033, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=101.3, ups=0.9, wpb=112.1, bsz=40, num_updates=5190, lr=4.95094e-05, gnorm=0.114, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13469
2023-02-20 17:10:27 - progress_bar.py[line:274] - INFO: epoch 001:   5203 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.8, bsz=40, num_updates=5200, lr=4.95057e-05, gnorm=0.141, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13480
2023-02-20 17:10:38 - progress_bar.py[line:274] - INFO: epoch 001:   5213 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.2, bsz=40, num_updates=5210, lr=4.95021e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13491
2023-02-20 17:10:49 - progress_bar.py[line:274] - INFO: epoch 001:   5223 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=105.5, ups=0.95, wpb=110.6, bsz=40, num_updates=5220, lr=4.94985e-05, gnorm=0.121, clip=0, loss_scale=4096, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=13502
2023-02-20 17:11:00 - progress_bar.py[line:274] - INFO: epoch 001:   5233 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.92, wpb=109.9, bsz=40, num_updates=5230, lr=4.94949e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13513
2023-02-20 17:11:11 - progress_bar.py[line:274] - INFO: epoch 001:   5243 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.5, bsz=40, num_updates=5240, lr=4.94913e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=13524
2023-02-20 17:11:22 - progress_bar.py[line:274] - INFO: epoch 001:   5253 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.6, ups=0.9, wpb=112.3, bsz=40, num_updates=5250, lr=4.94877e-05, gnorm=0.141, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13535
2023-02-20 17:11:35 - progress_bar.py[line:274] - INFO: epoch 001:   5263 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.1, bsz=40, num_updates=5260, lr=4.9484e-05, gnorm=0.112, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13546
2023-02-20 17:11:45 - progress_bar.py[line:274] - INFO: epoch 001:   5273 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111.2, bsz=40, num_updates=5270, lr=4.94804e-05, gnorm=0.093, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13558
2023-02-20 17:11:57 - progress_bar.py[line:274] - INFO: epoch 001:   5283 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112, bsz=40, num_updates=5280, lr=4.94768e-05, gnorm=0.118, clip=0, loss_scale=8192, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=13570
2023-02-20 17:12:08 - progress_bar.py[line:274] - INFO: epoch 001:   5293 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=112, bsz=40, num_updates=5290, lr=4.94732e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13580
2023-02-20 17:12:19 - progress_bar.py[line:274] - INFO: epoch 001:   5303 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=5300, lr=4.94696e-05, gnorm=0.114, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13592
2023-02-20 17:12:30 - progress_bar.py[line:274] - INFO: epoch 001:   5313 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=5310, lr=4.94659e-05, gnorm=0.116, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13603
2023-02-20 17:12:41 - progress_bar.py[line:274] - INFO: epoch 001:   5323 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.94, wpb=110.4, bsz=40, num_updates=5320, lr=4.94623e-05, gnorm=0.127, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13613
2023-02-20 17:12:52 - progress_bar.py[line:274] - INFO: epoch 001:   5333 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=5330, lr=4.94587e-05, gnorm=0.094, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13625
2023-02-20 17:12:56 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-20 17:13:04 - progress_bar.py[line:274] - INFO: epoch 001:   5344 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.1, ups=0.83, wpb=112.1, bsz=40, num_updates=5340, lr=4.94551e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=13637
2023-02-20 17:13:15 - progress_bar.py[line:274] - INFO: epoch 001:   5354 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=5350, lr=4.94515e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13648
2023-02-20 17:13:26 - progress_bar.py[line:274] - INFO: epoch 001:   5364 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=5360, lr=4.94479e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13659
2023-02-20 17:13:37 - progress_bar.py[line:274] - INFO: epoch 001:   5374 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.89, wpb=113.3, bsz=40, num_updates=5370, lr=4.94442e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=13670
2023-02-20 17:13:48 - progress_bar.py[line:274] - INFO: epoch 001:   5384 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=5380, lr=4.94406e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13681
2023-02-20 17:13:59 - progress_bar.py[line:274] - INFO: epoch 001:   5394 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.2, ups=0.94, wpb=110.6, bsz=40, num_updates=5390, lr=4.9437e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13692
2023-02-20 17:14:10 - progress_bar.py[line:274] - INFO: epoch 001:   5404 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.9, wpb=112.2, bsz=40, num_updates=5400, lr=4.94334e-05, gnorm=0.137, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13703
2023-02-20 17:14:21 - progress_bar.py[line:274] - INFO: epoch 001:   5414 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=5410, lr=4.94298e-05, gnorm=0.127, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13714
2023-02-20 17:14:33 - progress_bar.py[line:274] - INFO: epoch 001:   5424 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.2, bsz=40, num_updates=5420, lr=4.94261e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13726
2023-02-20 17:14:44 - progress_bar.py[line:274] - INFO: epoch 001:   5434 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.93, wpb=112.5, bsz=40, num_updates=5430, lr=4.94225e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13737
2023-02-20 17:14:55 - progress_bar.py[line:274] - INFO: epoch 001:   5444 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=5440, lr=4.94189e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=13748
2023-02-20 17:15:06 - progress_bar.py[line:274] - INFO: epoch 001:   5454 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=5450, lr=4.94153e-05, gnorm=0.111, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13759
2023-02-20 17:15:18 - progress_bar.py[line:274] - INFO: epoch 001:   5464 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.87, wpb=111.1, bsz=40, num_updates=5460, lr=4.94117e-05, gnorm=0.112, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13771
2023-02-20 17:15:29 - progress_bar.py[line:274] - INFO: epoch 001:   5474 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=5470, lr=4.94081e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13782
2023-02-20 17:15:40 - progress_bar.py[line:274] - INFO: epoch 001:   5484 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=110.4, bsz=40, num_updates=5480, lr=4.94044e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13793
2023-02-20 17:15:51 - progress_bar.py[line:274] - INFO: epoch 001:   5494 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.93, wpb=111.2, bsz=40, num_updates=5490, lr=4.94008e-05, gnorm=0.123, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13804
2023-02-20 17:16:03 - progress_bar.py[line:274] - INFO: epoch 001:   5504 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.4, bsz=40, num_updates=5500, lr=4.93972e-05, gnorm=0.179, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=13815
2023-02-20 17:16:14 - progress_bar.py[line:274] - INFO: epoch 001:   5514 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.87, wpb=111.9, bsz=40, num_updates=5510, lr=4.93936e-05, gnorm=0.116, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13827
2023-02-20 17:16:25 - progress_bar.py[line:274] - INFO: epoch 001:   5524 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=5520, lr=4.939e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=13838
2023-02-20 17:16:36 - progress_bar.py[line:274] - INFO: epoch 001:   5534 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.1, ups=0.92, wpb=111.1, bsz=40, num_updates=5530, lr=4.93863e-05, gnorm=0.133, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13849
2023-02-20 17:16:48 - progress_bar.py[line:274] - INFO: epoch 001:   5544 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=112.6, bsz=40, num_updates=5540, lr=4.93827e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13861
2023-02-20 17:16:59 - progress_bar.py[line:274] - INFO: epoch 001:   5554 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.8, bsz=40, num_updates=5550, lr=4.93791e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13872
2023-02-20 17:17:10 - progress_bar.py[line:274] - INFO: epoch 001:   5564 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=5560, lr=4.93755e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13883
2023-02-20 17:17:21 - progress_bar.py[line:274] - INFO: epoch 001:   5574 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=5570, lr=4.93719e-05, gnorm=0.144, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13894
2023-02-20 17:17:32 - progress_bar.py[line:274] - INFO: epoch 001:   5584 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.1, bsz=40, num_updates=5580, lr=4.93683e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13905
2023-02-20 17:17:44 - progress_bar.py[line:274] - INFO: epoch 001:   5594 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.4, bsz=40, num_updates=5590, lr=4.93646e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13917
2023-02-20 17:17:55 - progress_bar.py[line:274] - INFO: epoch 001:   5604 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=112.2, bsz=40, num_updates=5600, lr=4.9361e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=13928
2023-02-20 17:18:06 - progress_bar.py[line:274] - INFO: epoch 001:   5614 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.92, wpb=111, bsz=40, num_updates=5610, lr=4.93574e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13939
2023-02-20 17:18:17 - progress_bar.py[line:274] - INFO: epoch 001:   5624 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.3, bsz=40, num_updates=5620, lr=4.93538e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13950
2023-02-20 17:18:29 - progress_bar.py[line:274] - INFO: epoch 001:   5634 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111.1, bsz=40, num_updates=5630, lr=4.93502e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13961
2023-02-20 17:18:40 - progress_bar.py[line:274] - INFO: epoch 001:   5644 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=112.2, bsz=40, num_updates=5640, lr=4.93465e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=13973
2023-02-20 17:18:51 - progress_bar.py[line:274] - INFO: epoch 001:   5654 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.6, bsz=40, num_updates=5650, lr=4.93429e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=13984
2023-02-20 17:19:03 - progress_bar.py[line:274] - INFO: epoch 001:   5664 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.5, bsz=40, num_updates=5660, lr=4.93393e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=13996
2023-02-20 17:19:14 - progress_bar.py[line:274] - INFO: epoch 001:   5674 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=110, bsz=40, num_updates=5670, lr=4.93357e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14007
2023-02-20 17:19:25 - progress_bar.py[line:274] - INFO: epoch 001:   5684 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=5680, lr=4.93321e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14018
2023-02-20 17:19:36 - progress_bar.py[line:274] - INFO: epoch 001:   5694 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=109.9, bsz=40, num_updates=5690, lr=4.93285e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=14029
2023-02-20 17:19:47 - progress_bar.py[line:274] - INFO: epoch 001:   5704 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.1, bsz=40, num_updates=5700, lr=4.93248e-05, gnorm=0.128, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14040
2023-02-20 17:19:59 - progress_bar.py[line:274] - INFO: epoch 001:   5714 / 142023 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.88, wpb=113, bsz=40, num_updates=5710, lr=4.93212e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14051
2023-02-20 17:20:10 - progress_bar.py[line:274] - INFO: epoch 001:   5724 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.89, wpb=112.4, bsz=40, num_updates=5720, lr=4.93176e-05, gnorm=0.133, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14063
2023-02-20 17:20:21 - progress_bar.py[line:274] - INFO: epoch 001:   5734 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112, bsz=40, num_updates=5730, lr=4.9314e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14074
2023-02-20 17:20:32 - progress_bar.py[line:274] - INFO: epoch 001:   5744 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.93, wpb=111.7, bsz=40, num_updates=5740, lr=4.93104e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14084
2023-02-20 17:20:43 - progress_bar.py[line:274] - INFO: epoch 001:   5754 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.5, bsz=40, num_updates=5750, lr=4.93067e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14096
2023-02-20 17:20:54 - progress_bar.py[line:274] - INFO: epoch 001:   5764 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.93, wpb=112, bsz=40, num_updates=5760, lr=4.93031e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=14106
2023-02-20 17:21:05 - progress_bar.py[line:274] - INFO: epoch 001:   5774 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=112, bsz=40, num_updates=5770, lr=4.92995e-05, gnorm=0.14, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14117
2023-02-20 17:21:16 - progress_bar.py[line:274] - INFO: epoch 001:   5784 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=112.1, bsz=40, num_updates=5780, lr=4.92959e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14129
2023-02-20 17:21:27 - progress_bar.py[line:274] - INFO: epoch 001:   5794 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.91, wpb=110.5, bsz=40, num_updates=5790, lr=4.92923e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14140
2023-02-20 17:21:38 - progress_bar.py[line:274] - INFO: epoch 001:   5804 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=5800, lr=4.92887e-05, gnorm=0.125, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14151
2023-02-20 17:21:50 - progress_bar.py[line:274] - INFO: epoch 001:   5814 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=110.7, bsz=40, num_updates=5810, lr=4.9285e-05, gnorm=0.115, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14163
2023-02-20 17:22:01 - progress_bar.py[line:274] - INFO: epoch 001:   5824 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=5820, lr=4.92814e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14174
2023-02-20 17:22:12 - progress_bar.py[line:274] - INFO: epoch 001:   5834 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.5, ups=0.95, wpb=111.9, bsz=40, num_updates=5830, lr=4.92778e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=10, gb_free=10.3, ema_decay=0.9999, wall=14184
2023-02-20 17:22:23 - progress_bar.py[line:274] - INFO: epoch 001:   5844 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.2, bsz=40, num_updates=5840, lr=4.92742e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14196
2023-02-20 17:22:34 - progress_bar.py[line:274] - INFO: epoch 001:   5854 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=94.7, ups=0.87, wpb=108.5, bsz=40, num_updates=5850, lr=4.92706e-05, gnorm=0.106, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14207
2023-02-20 17:22:45 - progress_bar.py[line:274] - INFO: epoch 001:   5864 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=5860, lr=4.92669e-05, gnorm=0.098, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14218
2023-02-20 17:22:57 - progress_bar.py[line:274] - INFO: epoch 001:   5874 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.4, bsz=40, num_updates=5870, lr=4.92633e-05, gnorm=0.096, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14230
2023-02-20 17:23:08 - progress_bar.py[line:274] - INFO: epoch 001:   5884 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.5, bsz=40, num_updates=5880, lr=4.92597e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14241
2023-02-20 17:23:19 - progress_bar.py[line:274] - INFO: epoch 001:   5894 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=5890, lr=4.92561e-05, gnorm=0.088, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14252
2023-02-20 17:23:24 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-20 17:23:31 - progress_bar.py[line:274] - INFO: epoch 001:   5905 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.8, ups=0.81, wpb=111, bsz=40, num_updates=5900, lr=4.92525e-05, gnorm=0.101, clip=0, loss_scale=4096, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=14264
2023-02-20 17:23:43 - progress_bar.py[line:274] - INFO: epoch 001:   5915 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=5910, lr=4.92489e-05, gnorm=0.115, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14275
2023-02-20 17:23:54 - progress_bar.py[line:274] - INFO: epoch 001:   5925 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.7, bsz=40, num_updates=5920, lr=4.92452e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14286
2023-02-20 17:24:05 - progress_bar.py[line:274] - INFO: epoch 001:   5935 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112.1, bsz=40, num_updates=5930, lr=4.92416e-05, gnorm=0.127, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=14298
2023-02-20 17:24:16 - progress_bar.py[line:274] - INFO: epoch 001:   5945 / 142023 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=5940, lr=4.9238e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14309
2023-02-20 17:24:27 - progress_bar.py[line:274] - INFO: epoch 001:   5955 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.88, wpb=111.9, bsz=40, num_updates=5950, lr=4.92344e-05, gnorm=0.111, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14320
2023-02-20 17:24:38 - progress_bar.py[line:274] - INFO: epoch 001:   5965 / 142023 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.91, wpb=112.1, bsz=40, num_updates=5960, lr=4.92308e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=14331
2023-02-20 17:24:50 - progress_bar.py[line:274] - INFO: epoch 001:   5975 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.7, ups=0.87, wpb=110.3, bsz=40, num_updates=5970, lr=4.92271e-05, gnorm=0.132, clip=0, loss_scale=4096, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=14343
2023-02-20 17:25:01 - progress_bar.py[line:274] - INFO: epoch 001:   5985 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.7, bsz=40, num_updates=5980, lr=4.92235e-05, gnorm=0.143, clip=0, loss_scale=4096, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=14354
2023-02-20 17:25:12 - progress_bar.py[line:274] - INFO: epoch 001:   5995 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.5, bsz=40, num_updates=5990, lr=4.92199e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14365
2023-02-20 17:25:24 - progress_bar.py[line:274] - INFO: epoch 001:   6005 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=110.9, bsz=40, num_updates=6000, lr=4.92163e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14377
2023-02-20 17:25:24 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-20 17:25:25 - train.py[line:549] - INFO: 0 / 6234
2023-02-20 17:25:25 - train.py[line:551] - INFO: load:1.18 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-20 17:27:28 - train.py[line:549] - INFO: 200 / 6234
2023-02-20 17:27:28 - train.py[line:551] - INFO: load:1.21 valid_run:122.45 task_valid:119.60 collect_output:1.84
2023-02-20 17:29:28 - train.py[line:549] - INFO: 400 / 6234
2023-02-20 17:29:28 - train.py[line:551] - INFO: load:1.23 valid_run:242.46 task_valid:235.54 collect_output:4.91
2023-02-20 17:31:31 - train.py[line:549] - INFO: 600 / 6234
2023-02-20 17:31:31 - train.py[line:551] - INFO: load:1.25 valid_run:365.19 task_valid:352.20 collect_output:9.99
2023-02-20 17:33:33 - train.py[line:549] - INFO: 800 / 6234
2023-02-20 17:33:33 - train.py[line:551] - INFO: load:1.27 valid_run:487.17 task_valid:466.02 collect_output:17.16
2023-02-20 17:35:33 - train.py[line:549] - INFO: 1000 / 6234
2023-02-20 17:35:33 - train.py[line:551] - INFO: load:1.30 valid_run:607.74 task_valid:583.52 collect_output:19.23
2023-02-20 17:37:37 - train.py[line:549] - INFO: 1200 / 6234
2023-02-20 17:37:37 - train.py[line:551] - INFO: load:1.32 valid_run:730.94 task_valid:702.63 collect_output:22.31
2023-02-20 17:39:40 - train.py[line:549] - INFO: 1400 / 6234
2023-02-20 17:39:40 - train.py[line:551] - INFO: load:1.35 valid_run:853.87 task_valid:820.93 collect_output:25.93
2023-02-20 17:41:42 - train.py[line:549] - INFO: 1600 / 6234
2023-02-20 17:41:42 - train.py[line:551] - INFO: load:1.37 valid_run:975.83 task_valid:937.84 collect_output:29.98
2023-02-20 17:43:46 - train.py[line:549] - INFO: 1800 / 6234
2023-02-20 17:43:46 - train.py[line:551] - INFO: load:1.39 valid_run:1099.67 task_valid:1055.53 collect_output:35.11
2023-02-20 17:45:47 - train.py[line:549] - INFO: 2000 / 6234
2023-02-20 17:45:47 - train.py[line:551] - INFO: load:1.42 valid_run:1221.36 task_valid:1168.44 collect_output:42.90
2023-02-20 17:47:48 - train.py[line:549] - INFO: 2200 / 6234
2023-02-20 17:47:48 - train.py[line:551] - INFO: load:1.44 valid_run:1341.55 task_valid:1284.37 collect_output:46.18
2023-02-20 17:49:49 - train.py[line:549] - INFO: 2400 / 6234
2023-02-20 17:49:49 - train.py[line:551] - INFO: load:1.46 valid_run:1463.23 task_valid:1401.59 collect_output:49.61
2023-02-20 17:51:48 - train.py[line:549] - INFO: 2600 / 6234
2023-02-20 17:51:48 - train.py[line:551] - INFO: load:1.48 valid_run:1582.19 task_valid:1515.62 collect_output:53.54
2023-02-20 17:53:50 - train.py[line:549] - INFO: 2800 / 6234
2023-02-20 17:53:50 - train.py[line:551] - INFO: load:1.51 valid_run:1703.33 task_valid:1633.59 collect_output:55.70
2023-02-20 17:55:51 - train.py[line:549] - INFO: 3000 / 6234
2023-02-20 17:55:51 - train.py[line:551] - INFO: load:1.53 valid_run:1824.40 task_valid:1749.99 collect_output:59.37
2023-02-20 17:57:52 - train.py[line:549] - INFO: 3200 / 6234
2023-02-20 17:57:52 - train.py[line:551] - INFO: load:1.56 valid_run:1945.43 task_valid:1864.17 collect_output:65.21
2023-02-20 17:59:53 - train.py[line:549] - INFO: 3400 / 6234
2023-02-20 17:59:53 - train.py[line:551] - INFO: load:1.58 valid_run:2066.97 task_valid:1980.66 collect_output:69.27
2023-02-20 18:01:54 - train.py[line:549] - INFO: 3600 / 6234
2023-02-20 18:01:54 - train.py[line:551] - INFO: load:1.60 valid_run:2187.78 task_valid:2098.79 collect_output:70.93
2023-02-20 18:03:56 - train.py[line:549] - INFO: 3800 / 6234
2023-02-20 18:03:56 - train.py[line:551] - INFO: load:1.63 valid_run:2309.25 task_valid:2216.09 collect_output:74.10
2023-02-20 18:05:56 - train.py[line:549] - INFO: 4000 / 6234
2023-02-20 18:05:56 - train.py[line:551] - INFO: load:1.65 valid_run:2429.84 task_valid:2332.99 collect_output:76.76
2023-02-20 18:07:58 - train.py[line:549] - INFO: 4200 / 6234
2023-02-20 18:07:58 - train.py[line:551] - INFO: load:1.67 valid_run:2551.70 task_valid:2449.90 collect_output:80.69
2023-02-20 18:10:01 - train.py[line:549] - INFO: 4400 / 6234
2023-02-20 18:10:01 - train.py[line:551] - INFO: load:1.70 valid_run:2673.90 task_valid:2569.17 collect_output:82.60
2023-02-20 18:12:01 - train.py[line:549] - INFO: 4600 / 6234
2023-02-20 18:12:01 - train.py[line:551] - INFO: load:1.72 valid_run:2794.58 task_valid:2683.98 collect_output:87.47
2023-02-20 18:14:01 - train.py[line:549] - INFO: 4800 / 6234
2023-02-20 18:14:01 - train.py[line:551] - INFO: load:1.75 valid_run:2914.54 task_valid:2800.45 collect_output:89.93
2023-02-20 18:16:03 - train.py[line:549] - INFO: 5000 / 6234
2023-02-20 18:16:03 - train.py[line:551] - INFO: load:1.77 valid_run:3036.47 task_valid:2916.94 collect_output:94.34
2023-02-20 18:18:06 - train.py[line:549] - INFO: 5200 / 6234
2023-02-20 18:18:06 - train.py[line:551] - INFO: load:1.79 valid_run:3159.29 task_valid:3033.10 collect_output:99.98
2023-02-20 18:20:06 - train.py[line:549] - INFO: 5400 / 6234
2023-02-20 18:20:06 - train.py[line:551] - INFO: load:1.82 valid_run:3279.08 task_valid:3147.46 collect_output:104.41
2023-02-20 18:22:08 - train.py[line:549] - INFO: 5600 / 6234
2023-02-20 18:22:08 - train.py[line:551] - INFO: load:1.84 valid_run:3401.04 task_valid:3267.05 collect_output:105.79
2023-02-20 18:24:10 - train.py[line:549] - INFO: 5800 / 6234
2023-02-20 18:24:10 - train.py[line:551] - INFO: load:1.86 valid_run:3522.70 task_valid:3382.77 collect_output:110.73
2023-02-20 18:26:12 - train.py[line:549] - INFO: 6000 / 6234
2023-02-20 18:26:12 - train.py[line:551] - INFO: load:1.89 valid_run:3644.72 task_valid:3501.43 collect_output:113.09
2023-02-20 18:28:13 - train.py[line:549] - INFO: 6200 / 6234
2023-02-20 18:28:13 - train.py[line:551] - INFO: load:1.91 valid_run:3765.90 task_valid:3620.04 collect_output:114.64

====================================================================================================
SGG eval:     R @ 50: 0.6171;     R @ 100: 0.6458;     R @ 500: 0.6757;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3926;    mR @ 100: 0.4385;    mR @ 500: 0.4744;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6829) (covered in:0.3542) (covering:0.3714) (eating:0.8235) (flying in:1.0000) (growing on:0.3750) (hanging from:0.4839) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0000) (parked on:1.0000) (playing:0.0000) (riding:0.9722) (says:0.0000) (sitting on:0.6995) (standing on:0.3462) (using:0.4000) (walking in:0.0000) (walking on:0.7297) (watching:0.4306) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6171;     R @ 100: 0.6458;     R @ 500: 0.6757;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3926;    mR @ 100: 0.4385;    mR @ 500: 0.4744;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6829) (covered in:0.3542) (covering:0.3714) (eating:0.8235) (flying in:1.0000) (growing on:0.3750) (hanging from:0.4839) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0000) (parked on:1.0000) (playing:0.0000) (riding:0.9722) (says:0.0000) (sitting on:0.6995) (standing on:0.3462) (using:0.4000) (walking in:0.0000) (walking on:0.7297) (watching:0.4306) 
--------------------------------------------------------
====================================================================================================

2023-02-20 18:28:44 - train.py[line:487] - INFO: 0.6458100840336134
2023-02-20 18:28:44 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-20 18:28:44 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.218 | loss_v1 0 | loss_v2 0 | nll_loss 0.046 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.64581 | ppl 1.03 | vqa_score 0.1667 | wps 118.1 | wpb 72 | bsz 24 | num_updates 6000 | best_R@100 0.64581
2023-02-20 18:28:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2023-02-20 18:28:44 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_6000.pt
2023-02-20 18:28:50 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_6000.pt
2023-02-20 18:28:56 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.6458100840336134) (writing took 11.012592101469636 seconds)
2023-02-20 18:29:07 - progress_bar.py[line:274] - INFO: epoch 001:   6015 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=110.5, bsz=40, num_updates=6010, lr=4.92127e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=18200
2023-02-20 18:29:18 - progress_bar.py[line:274] - INFO: epoch 001:   6025 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.7, bsz=40, num_updates=6020, lr=4.92091e-05, gnorm=0.115, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18211
2023-02-20 18:29:29 - progress_bar.py[line:274] - INFO: epoch 001:   6035 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.5, bsz=40, num_updates=6030, lr=4.92054e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=18222
2023-02-20 18:29:41 - progress_bar.py[line:274] - INFO: epoch 001:   6045 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=6040, lr=4.92018e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18234
2023-02-20 18:29:52 - progress_bar.py[line:274] - INFO: epoch 001:   6055 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=111.7, bsz=40, num_updates=6050, lr=4.91982e-05, gnorm=0.126, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18245
2023-02-20 18:30:03 - progress_bar.py[line:274] - INFO: epoch 001:   6065 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=111.2, bsz=40, num_updates=6060, lr=4.91946e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18256
2023-02-20 18:30:14 - progress_bar.py[line:274] - INFO: epoch 001:   6075 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=105.9, ups=0.94, wpb=112.5, bsz=40, num_updates=6070, lr=4.9191e-05, gnorm=0.12, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=18266
2023-02-20 18:30:25 - progress_bar.py[line:274] - INFO: epoch 001:   6085 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=6080, lr=4.91873e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18278
2023-02-20 18:30:36 - progress_bar.py[line:274] - INFO: epoch 001:   6095 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=6090, lr=4.91837e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18289
2023-02-20 18:30:47 - progress_bar.py[line:274] - INFO: epoch 001:   6105 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=6100, lr=4.91801e-05, gnorm=0.127, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18300
2023-02-20 18:30:58 - progress_bar.py[line:274] - INFO: epoch 001:   6115 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.93, wpb=111.4, bsz=40, num_updates=6110, lr=4.91765e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=18311
2023-02-20 18:31:09 - progress_bar.py[line:274] - INFO: epoch 001:   6125 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.7, bsz=40, num_updates=6120, lr=4.91729e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18322
2023-02-20 18:31:20 - progress_bar.py[line:274] - INFO: epoch 001:   6135 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=6130, lr=4.91693e-05, gnorm=0.116, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=18333
2023-02-20 18:31:32 - progress_bar.py[line:274] - INFO: epoch 001:   6145 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=6140, lr=4.91656e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18344
2023-02-20 18:31:43 - progress_bar.py[line:274] - INFO: epoch 001:   6155 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.1, bsz=40, num_updates=6150, lr=4.9162e-05, gnorm=0.13, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18356
2023-02-20 18:31:54 - progress_bar.py[line:274] - INFO: epoch 001:   6165 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.8, bsz=40, num_updates=6160, lr=4.91584e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18367
2023-02-20 18:32:05 - progress_bar.py[line:274] - INFO: epoch 001:   6175 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.89, wpb=111.4, bsz=40, num_updates=6170, lr=4.91548e-05, gnorm=0.138, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18378
2023-02-20 18:32:16 - progress_bar.py[line:274] - INFO: epoch 001:   6185 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.3, bsz=40, num_updates=6180, lr=4.91512e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18389
2023-02-20 18:32:27 - progress_bar.py[line:274] - INFO: epoch 001:   6195 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=112, bsz=40, num_updates=6190, lr=4.91475e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18400
2023-02-20 18:32:38 - progress_bar.py[line:274] - INFO: epoch 001:   6205 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=6200, lr=4.91439e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=18411
2023-02-20 18:32:50 - progress_bar.py[line:274] - INFO: epoch 001:   6215 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=6210, lr=4.91403e-05, gnorm=0.121, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=18422
2023-02-20 18:33:01 - progress_bar.py[line:274] - INFO: epoch 001:   6225 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.88, wpb=110.2, bsz=40, num_updates=6220, lr=4.91367e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18434
2023-02-20 18:33:12 - progress_bar.py[line:274] - INFO: epoch 001:   6235 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=6230, lr=4.91331e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18445
2023-02-20 18:33:23 - progress_bar.py[line:274] - INFO: epoch 001:   6245 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=6240, lr=4.91295e-05, gnorm=0.105, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18456
2023-02-20 18:33:34 - progress_bar.py[line:274] - INFO: epoch 001:   6255 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.7, bsz=40, num_updates=6250, lr=4.91258e-05, gnorm=0.125, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18467
2023-02-20 18:33:46 - progress_bar.py[line:274] - INFO: epoch 001:   6265 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.5, bsz=40, num_updates=6260, lr=4.91222e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18478
2023-02-20 18:33:57 - progress_bar.py[line:274] - INFO: epoch 001:   6275 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.5, bsz=40, num_updates=6270, lr=4.91186e-05, gnorm=0.174, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18489
2023-02-20 18:34:08 - progress_bar.py[line:274] - INFO: epoch 001:   6285 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=6280, lr=4.9115e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18501
2023-02-20 18:34:19 - progress_bar.py[line:274] - INFO: epoch 001:   6295 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.2, bsz=40, num_updates=6290, lr=4.91114e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18512
2023-02-20 18:34:31 - progress_bar.py[line:274] - INFO: epoch 001:   6305 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=95.7, ups=0.87, wpb=110, bsz=40, num_updates=6300, lr=4.91077e-05, gnorm=0.122, clip=0, loss_scale=4096, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=18523
2023-02-20 18:34:41 - progress_bar.py[line:274] - INFO: epoch 001:   6315 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=112.2, bsz=40, num_updates=6310, lr=4.91041e-05, gnorm=0.101, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18534
2023-02-20 18:34:52 - progress_bar.py[line:274] - INFO: epoch 001:   6325 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.92, wpb=110, bsz=40, num_updates=6320, lr=4.91005e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18545
2023-02-20 18:35:03 - progress_bar.py[line:274] - INFO: epoch 001:   6335 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.91, wpb=111.5, bsz=40, num_updates=6330, lr=4.90969e-05, gnorm=0.119, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=18556
2023-02-20 18:35:15 - progress_bar.py[line:274] - INFO: epoch 001:   6345 / 142023 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.2, ups=0.87, wpb=111.6, bsz=40, num_updates=6340, lr=4.90933e-05, gnorm=0.171, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18568
2023-02-20 18:35:26 - progress_bar.py[line:274] - INFO: epoch 001:   6355 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=6350, lr=4.90897e-05, gnorm=0.111, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18579
2023-02-20 18:35:38 - progress_bar.py[line:274] - INFO: epoch 001:   6365 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=110, bsz=40, num_updates=6360, lr=4.9086e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18590
2023-02-20 18:35:49 - progress_bar.py[line:274] - INFO: epoch 001:   6375 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=109.9, bsz=40, num_updates=6370, lr=4.90824e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18602
2023-02-20 18:36:00 - progress_bar.py[line:274] - INFO: epoch 001:   6385 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.8, bsz=40, num_updates=6380, lr=4.90788e-05, gnorm=0.148, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=18613
2023-02-20 18:36:12 - progress_bar.py[line:274] - INFO: epoch 001:   6395 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.5, bsz=40, num_updates=6390, lr=4.90752e-05, gnorm=0.105, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18624
2023-02-20 18:36:23 - progress_bar.py[line:274] - INFO: epoch 001:   6405 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.89, wpb=111.1, bsz=40, num_updates=6400, lr=4.90716e-05, gnorm=0.151, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=18636
2023-02-20 18:36:34 - progress_bar.py[line:274] - INFO: epoch 001:   6415 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111.3, bsz=40, num_updates=6410, lr=4.90679e-05, gnorm=0.115, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=18647
2023-02-20 18:36:46 - progress_bar.py[line:274] - INFO: epoch 001:   6425 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.87, wpb=110.2, bsz=40, num_updates=6420, lr=4.90643e-05, gnorm=0.119, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18658
2023-02-20 18:36:57 - progress_bar.py[line:274] - INFO: epoch 001:   6435 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=112, bsz=40, num_updates=6430, lr=4.90607e-05, gnorm=0.096, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18670
2023-02-20 18:37:08 - progress_bar.py[line:274] - INFO: epoch 001:   6445 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=6440, lr=4.90571e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18681
2023-02-20 18:37:20 - progress_bar.py[line:274] - INFO: epoch 001:   6455 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=6450, lr=4.90535e-05, gnorm=0.113, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18692
2023-02-20 18:37:30 - progress_bar.py[line:274] - INFO: epoch 001:   6465 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.93, wpb=110.5, bsz=40, num_updates=6460, lr=4.90499e-05, gnorm=0.142, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18703
2023-02-20 18:37:34 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-20 18:37:43 - progress_bar.py[line:274] - INFO: epoch 001:   6476 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.8, ups=0.79, wpb=111.3, bsz=40, num_updates=6470, lr=4.90462e-05, gnorm=0.153, clip=0, loss_scale=4096, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18716
2023-02-20 18:37:54 - progress_bar.py[line:274] - INFO: epoch 001:   6486 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.8, ups=0.94, wpb=112.2, bsz=40, num_updates=6480, lr=4.90426e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18726
2023-02-20 18:38:04 - progress_bar.py[line:274] - INFO: epoch 001:   6496 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.4, ups=0.92, wpb=110.5, bsz=40, num_updates=6490, lr=4.9039e-05, gnorm=0.13, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=18737
2023-02-20 18:38:15 - progress_bar.py[line:274] - INFO: epoch 001:   6506 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.8, bsz=40, num_updates=6500, lr=4.90354e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18748
2023-02-20 18:38:27 - progress_bar.py[line:274] - INFO: epoch 001:   6516 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=6510, lr=4.90318e-05, gnorm=0.111, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18759
2023-02-20 18:38:38 - progress_bar.py[line:274] - INFO: epoch 001:   6526 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.4, bsz=40, num_updates=6520, lr=4.90281e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18771
2023-02-20 18:38:49 - progress_bar.py[line:274] - INFO: epoch 001:   6536 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=6530, lr=4.90245e-05, gnorm=0.105, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18782
2023-02-20 18:39:00 - progress_bar.py[line:274] - INFO: epoch 001:   6546 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=6540, lr=4.90209e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18793
2023-02-20 18:39:12 - progress_bar.py[line:274] - INFO: epoch 001:   6556 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.8, bsz=40, num_updates=6550, lr=4.90173e-05, gnorm=0.114, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18805
2023-02-20 18:39:23 - progress_bar.py[line:274] - INFO: epoch 001:   6566 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.6, bsz=40, num_updates=6560, lr=4.90137e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=18816
2023-02-20 18:39:33 - progress_bar.py[line:274] - INFO: epoch 001:   6576 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.6, ups=0.94, wpb=111.9, bsz=40, num_updates=6570, lr=4.90101e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18826
2023-02-20 18:39:45 - progress_bar.py[line:274] - INFO: epoch 001:   6586 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=6580, lr=4.90064e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18837
2023-02-20 18:39:56 - progress_bar.py[line:274] - INFO: epoch 001:   6596 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=110.8, bsz=40, num_updates=6590, lr=4.90028e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18849
2023-02-20 18:40:07 - progress_bar.py[line:274] - INFO: epoch 001:   6606 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=6600, lr=4.89992e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18860
2023-02-20 18:40:19 - progress_bar.py[line:274] - INFO: epoch 001:   6616 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=6610, lr=4.89956e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18871
2023-02-20 18:40:30 - progress_bar.py[line:274] - INFO: epoch 001:   6626 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=6620, lr=4.8992e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=18882
2023-02-20 18:40:41 - progress_bar.py[line:274] - INFO: epoch 001:   6636 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=6630, lr=4.89883e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=18893
2023-02-20 18:40:52 - progress_bar.py[line:274] - INFO: epoch 001:   6646 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=111.8, bsz=40, num_updates=6640, lr=4.89847e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18904
2023-02-20 18:41:03 - progress_bar.py[line:274] - INFO: epoch 001:   6656 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.4, bsz=40, num_updates=6650, lr=4.89811e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18916
2023-02-20 18:41:14 - progress_bar.py[line:274] - INFO: epoch 001:   6666 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=112, bsz=40, num_updates=6660, lr=4.89775e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=18926
2023-02-20 18:41:24 - progress_bar.py[line:274] - INFO: epoch 001:   6676 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.4, ups=0.93, wpb=109.1, bsz=40, num_updates=6670, lr=4.89739e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18937
2023-02-20 18:41:36 - progress_bar.py[line:274] - INFO: epoch 001:   6686 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112, bsz=40, num_updates=6680, lr=4.89703e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=18948
2023-02-20 18:41:47 - progress_bar.py[line:274] - INFO: epoch 001:   6696 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.6, bsz=40, num_updates=6690, lr=4.89666e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=18960
2023-02-20 18:41:58 - progress_bar.py[line:274] - INFO: epoch 001:   6706 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.87, wpb=110.1, bsz=40, num_updates=6700, lr=4.8963e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=18971
2023-02-20 18:42:10 - progress_bar.py[line:274] - INFO: epoch 001:   6716 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.88, wpb=109.8, bsz=40, num_updates=6710, lr=4.89594e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=18983
2023-02-20 18:42:21 - progress_bar.py[line:274] - INFO: epoch 001:   6726 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.3, bsz=40, num_updates=6720, lr=4.89558e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=18994
2023-02-20 18:42:32 - progress_bar.py[line:274] - INFO: epoch 001:   6736 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.3, bsz=40, num_updates=6730, lr=4.89522e-05, gnorm=0.126, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19005
2023-02-20 18:42:44 - progress_bar.py[line:274] - INFO: epoch 001:   6746 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=109.8, bsz=40, num_updates=6740, lr=4.89485e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19017
2023-02-20 18:42:55 - progress_bar.py[line:274] - INFO: epoch 001:   6756 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=112, bsz=40, num_updates=6750, lr=4.89449e-05, gnorm=0.112, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19028
2023-02-20 18:43:07 - progress_bar.py[line:274] - INFO: epoch 001:   6766 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.5, bsz=40, num_updates=6760, lr=4.89413e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19039
2023-02-20 18:43:18 - progress_bar.py[line:274] - INFO: epoch 001:   6776 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.4, bsz=40, num_updates=6770, lr=4.89377e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19051
2023-02-20 18:43:29 - progress_bar.py[line:274] - INFO: epoch 001:   6786 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.92, wpb=112.7, bsz=40, num_updates=6780, lr=4.89341e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19062
2023-02-20 18:43:40 - progress_bar.py[line:274] - INFO: epoch 001:   6796 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=6790, lr=4.89305e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19073
2023-02-20 18:43:51 - progress_bar.py[line:274] - INFO: epoch 001:   6806 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.89, wpb=112.9, bsz=40, num_updates=6800, lr=4.89268e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19084
2023-02-20 18:44:02 - progress_bar.py[line:274] - INFO: epoch 001:   6816 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111, bsz=40, num_updates=6810, lr=4.89232e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=19095
2023-02-20 18:44:13 - progress_bar.py[line:274] - INFO: epoch 001:   6826 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.93, wpb=110.5, bsz=40, num_updates=6820, lr=4.89196e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=19106
2023-02-20 18:44:24 - progress_bar.py[line:274] - INFO: epoch 001:   6836 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=6830, lr=4.8916e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19117
2023-02-20 18:44:35 - progress_bar.py[line:274] - INFO: epoch 001:   6846 / 142023 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.87, wpb=113.3, bsz=40, num_updates=6840, lr=4.89124e-05, gnorm=0.151, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19128
2023-02-20 18:44:46 - progress_bar.py[line:274] - INFO: epoch 001:   6856 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=110.4, bsz=40, num_updates=6850, lr=4.89087e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19139
2023-02-20 18:44:58 - progress_bar.py[line:274] - INFO: epoch 001:   6866 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.88, wpb=109.3, bsz=40, num_updates=6860, lr=4.89051e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19151
2023-02-20 18:45:09 - progress_bar.py[line:274] - INFO: epoch 001:   6876 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.9, bsz=40, num_updates=6870, lr=4.89015e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19162
2023-02-20 18:45:20 - progress_bar.py[line:274] - INFO: epoch 001:   6886 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.89, wpb=111, bsz=40, num_updates=6880, lr=4.88979e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19173
2023-02-20 18:45:32 - progress_bar.py[line:274] - INFO: epoch 001:   6896 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=6890, lr=4.88943e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=19185
2023-02-20 18:45:43 - progress_bar.py[line:274] - INFO: epoch 001:   6906 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=6900, lr=4.88906e-05, gnorm=0.13, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19196
2023-02-20 18:45:54 - progress_bar.py[line:274] - INFO: epoch 001:   6916 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=111.1, bsz=40, num_updates=6910, lr=4.8887e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19207
2023-02-20 18:46:06 - progress_bar.py[line:274] - INFO: epoch 001:   6926 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=6920, lr=4.88834e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19219
2023-02-20 18:46:17 - progress_bar.py[line:274] - INFO: epoch 001:   6936 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=6930, lr=4.88798e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19230
2023-02-20 18:46:28 - progress_bar.py[line:274] - INFO: epoch 001:   6946 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=112.1, bsz=40, num_updates=6940, lr=4.88762e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19241
2023-02-20 18:46:40 - progress_bar.py[line:274] - INFO: epoch 001:   6956 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.6, bsz=40, num_updates=6950, lr=4.88726e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19253
2023-02-20 18:46:51 - progress_bar.py[line:274] - INFO: epoch 001:   6966 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112.2, bsz=40, num_updates=6960, lr=4.88689e-05, gnorm=0.141, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19264
2023-02-20 18:47:02 - progress_bar.py[line:274] - INFO: epoch 001:   6976 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.5, bsz=40, num_updates=6970, lr=4.88653e-05, gnorm=0.12, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19275
2023-02-20 18:47:13 - progress_bar.py[line:274] - INFO: epoch 001:   6986 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=111.9, bsz=40, num_updates=6980, lr=4.88617e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19286
2023-02-20 18:47:25 - progress_bar.py[line:274] - INFO: epoch 001:   6996 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=6990, lr=4.88581e-05, gnorm=0.094, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19298
2023-02-20 18:47:36 - progress_bar.py[line:274] - INFO: epoch 001:   7006 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.92, wpb=110, bsz=40, num_updates=7000, lr=4.88545e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19308
2023-02-20 18:47:47 - progress_bar.py[line:274] - INFO: epoch 001:   7016 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.89, wpb=112.6, bsz=40, num_updates=7010, lr=4.88508e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19320
2023-02-20 18:47:58 - progress_bar.py[line:274] - INFO: epoch 001:   7026 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=7020, lr=4.88472e-05, gnorm=0.09, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19331
2023-02-20 18:48:10 - progress_bar.py[line:274] - INFO: epoch 001:   7036 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.8, ups=0.87, wpb=111.7, bsz=40, num_updates=7030, lr=4.88436e-05, gnorm=0.115, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19342
2023-02-20 18:48:11 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-20 18:48:22 - progress_bar.py[line:274] - INFO: epoch 001:   7047 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.6, ups=0.84, wpb=111.2, bsz=40, num_updates=7040, lr=4.884e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=19354
2023-02-20 18:48:32 - progress_bar.py[line:274] - INFO: epoch 001:   7057 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.92, wpb=110.2, bsz=40, num_updates=7050, lr=4.88364e-05, gnorm=0.101, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19365
2023-02-20 18:48:43 - progress_bar.py[line:274] - INFO: epoch 001:   7067 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.9, ups=0.93, wpb=112.8, bsz=40, num_updates=7060, lr=4.88328e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=19376
2023-02-20 18:48:54 - progress_bar.py[line:274] - INFO: epoch 001:   7077 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=7070, lr=4.88291e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19387
2023-02-20 18:49:06 - progress_bar.py[line:274] - INFO: epoch 001:   7087 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.1, ups=0.87, wpb=110.2, bsz=40, num_updates=7080, lr=4.88255e-05, gnorm=0.114, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19399
2023-02-20 18:49:17 - progress_bar.py[line:274] - INFO: epoch 001:   7097 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.89, wpb=111.5, bsz=40, num_updates=7090, lr=4.88219e-05, gnorm=0.126, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19410
2023-02-20 18:49:28 - progress_bar.py[line:274] - INFO: epoch 001:   7107 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.93, wpb=111, bsz=40, num_updates=7100, lr=4.88183e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19421
2023-02-20 18:49:39 - progress_bar.py[line:274] - INFO: epoch 001:   7117 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=7110, lr=4.88147e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19432
2023-02-20 18:49:50 - progress_bar.py[line:274] - INFO: epoch 001:   7127 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=7120, lr=4.8811e-05, gnorm=0.129, clip=0, loss_scale=4096, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=19443
2023-02-20 18:50:01 - progress_bar.py[line:274] - INFO: epoch 001:   7137 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.93, wpb=110.9, bsz=40, num_updates=7130, lr=4.88074e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19454
2023-02-20 18:50:12 - progress_bar.py[line:274] - INFO: epoch 001:   7147 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102, ups=0.91, wpb=112.7, bsz=40, num_updates=7140, lr=4.88038e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19465
2023-02-20 18:50:23 - progress_bar.py[line:274] - INFO: epoch 001:   7157 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111, bsz=40, num_updates=7150, lr=4.88002e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=19476
2023-02-20 18:50:35 - progress_bar.py[line:274] - INFO: epoch 001:   7167 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.88, wpb=113.3, bsz=40, num_updates=7160, lr=4.87966e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19487
2023-02-20 18:50:46 - progress_bar.py[line:274] - INFO: epoch 001:   7177 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=7170, lr=4.8793e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19499
2023-02-20 18:50:57 - progress_bar.py[line:274] - INFO: epoch 001:   7187 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=7180, lr=4.87893e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10, ema_decay=0.9999, wall=19510
2023-02-20 18:51:08 - progress_bar.py[line:274] - INFO: epoch 001:   7197 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.89, wpb=112.4, bsz=40, num_updates=7190, lr=4.87857e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19521
2023-02-20 18:51:19 - progress_bar.py[line:274] - INFO: epoch 001:   7207 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.89, wpb=113, bsz=40, num_updates=7200, lr=4.87821e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19532
2023-02-20 18:51:30 - progress_bar.py[line:274] - INFO: epoch 001:   7217 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.2, bsz=40, num_updates=7210, lr=4.87785e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19543
2023-02-20 18:51:42 - progress_bar.py[line:274] - INFO: epoch 001:   7227 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=7220, lr=4.87749e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10, ema_decay=0.9999, wall=19555
2023-02-20 18:51:53 - progress_bar.py[line:274] - INFO: epoch 001:   7237 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.2, bsz=40, num_updates=7230, lr=4.87712e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19566
2023-02-20 18:52:04 - progress_bar.py[line:274] - INFO: epoch 001:   7247 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.6, bsz=40, num_updates=7240, lr=4.87676e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19577
2023-02-20 18:52:15 - progress_bar.py[line:274] - INFO: epoch 001:   7257 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=7250, lr=4.8764e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19588
2023-02-20 18:52:26 - progress_bar.py[line:274] - INFO: epoch 001:   7267 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.4, bsz=40, num_updates=7260, lr=4.87604e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19599
2023-02-20 18:52:37 - progress_bar.py[line:274] - INFO: epoch 001:   7277 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.5, bsz=40, num_updates=7270, lr=4.87568e-05, gnorm=0.121, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19610
2023-02-20 18:52:49 - progress_bar.py[line:274] - INFO: epoch 001:   7287 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.3, ups=0.87, wpb=110.6, bsz=40, num_updates=7280, lr=4.87532e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=19621
2023-02-20 18:53:00 - progress_bar.py[line:274] - INFO: epoch 001:   7297 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=7290, lr=4.87495e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=19633
2023-02-20 18:53:11 - progress_bar.py[line:274] - INFO: epoch 001:   7307 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.2, bsz=40, num_updates=7300, lr=4.87459e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19644
2023-02-20 18:53:22 - progress_bar.py[line:274] - INFO: epoch 001:   7317 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=7310, lr=4.87423e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19655
2023-02-20 18:53:33 - progress_bar.py[line:274] - INFO: epoch 001:   7327 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.9, wpb=111.6, bsz=40, num_updates=7320, lr=4.87387e-05, gnorm=0.125, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19666
2023-02-20 18:53:44 - progress_bar.py[line:274] - INFO: epoch 001:   7337 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=7330, lr=4.87351e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19677
2023-02-20 18:53:55 - progress_bar.py[line:274] - INFO: epoch 001:   7347 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.6, bsz=40, num_updates=7340, lr=4.87314e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19688
2023-02-20 18:54:06 - progress_bar.py[line:274] - INFO: epoch 001:   7357 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112.6, bsz=40, num_updates=7350, lr=4.87278e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19699
2023-02-20 18:54:18 - progress_bar.py[line:274] - INFO: epoch 001:   7367 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=112.1, bsz=40, num_updates=7360, lr=4.87242e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19711
2023-02-20 18:54:29 - progress_bar.py[line:274] - INFO: epoch 001:   7377 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=7370, lr=4.87206e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19722
2023-02-20 18:54:40 - progress_bar.py[line:274] - INFO: epoch 001:   7387 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.5, bsz=40, num_updates=7380, lr=4.8717e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19733
2023-02-20 18:54:51 - progress_bar.py[line:274] - INFO: epoch 001:   7397 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=7390, lr=4.87134e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19744
2023-02-20 18:55:02 - progress_bar.py[line:274] - INFO: epoch 001:   7407 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=7400, lr=4.87097e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19755
2023-02-20 18:55:05 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 18:55:15 - progress_bar.py[line:274] - INFO: epoch 001:   7418 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.2, ups=0.83, wpb=111.2, bsz=40, num_updates=7410, lr=4.87061e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19767
2023-02-20 18:55:26 - progress_bar.py[line:274] - INFO: epoch 001:   7428 / 142023 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.2, ups=0.9, wpb=112.6, bsz=40, num_updates=7420, lr=4.87025e-05, gnorm=0.125, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=19779
2023-02-20 18:55:36 - progress_bar.py[line:274] - INFO: epoch 001:   7438 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.93, wpb=110.6, bsz=40, num_updates=7430, lr=4.86989e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=19789
2023-02-20 18:55:48 - progress_bar.py[line:274] - INFO: epoch 001:   7448 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.88, wpb=110.3, bsz=40, num_updates=7440, lr=4.86953e-05, gnorm=0.116, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19801
2023-02-20 18:55:59 - progress_bar.py[line:274] - INFO: epoch 001:   7458 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.8, bsz=40, num_updates=7450, lr=4.86916e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19812
2023-02-20 18:56:10 - progress_bar.py[line:274] - INFO: epoch 001:   7468 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=112, bsz=40, num_updates=7460, lr=4.8688e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19823
2023-02-20 18:56:22 - progress_bar.py[line:274] - INFO: epoch 001:   7478 / 142023 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.89, wpb=110.7, bsz=40, num_updates=7470, lr=4.86844e-05, gnorm=0.121, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19834
2023-02-20 18:56:32 - progress_bar.py[line:274] - INFO: epoch 001:   7488 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.93, wpb=111.3, bsz=40, num_updates=7480, lr=4.86808e-05, gnorm=0.099, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=19845
2023-02-20 18:56:44 - progress_bar.py[line:274] - INFO: epoch 001:   7498 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=111.3, bsz=40, num_updates=7490, lr=4.86772e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19856
2023-02-20 18:56:54 - progress_bar.py[line:274] - INFO: epoch 001:   7508 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.5, bsz=40, num_updates=7500, lr=4.86736e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19867
2023-02-20 18:57:05 - progress_bar.py[line:274] - INFO: epoch 001:   7518 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.9, ups=0.92, wpb=111, bsz=40, num_updates=7510, lr=4.86699e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19878
2023-02-20 18:57:17 - progress_bar.py[line:274] - INFO: epoch 001:   7528 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.88, wpb=109.2, bsz=40, num_updates=7520, lr=4.86663e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19890
2023-02-20 18:57:28 - progress_bar.py[line:274] - INFO: epoch 001:   7538 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.7, ups=0.91, wpb=108.9, bsz=40, num_updates=7530, lr=4.86627e-05, gnorm=0.144, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19901
2023-02-20 18:57:39 - progress_bar.py[line:274] - INFO: epoch 001:   7548 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=7540, lr=4.86591e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=19912
2023-02-20 18:57:50 - progress_bar.py[line:274] - INFO: epoch 001:   7558 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.9, bsz=40, num_updates=7550, lr=4.86555e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19923
2023-02-20 18:58:01 - progress_bar.py[line:274] - INFO: epoch 001:   7568 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.2, bsz=40, num_updates=7560, lr=4.86518e-05, gnorm=0.11, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=19934
2023-02-20 18:58:12 - progress_bar.py[line:274] - INFO: epoch 001:   7578 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.92, wpb=109.4, bsz=40, num_updates=7570, lr=4.86482e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19945
2023-02-20 18:58:23 - progress_bar.py[line:274] - INFO: epoch 001:   7588 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.5, ups=0.92, wpb=111.6, bsz=40, num_updates=7580, lr=4.86446e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19956
2023-02-20 18:58:34 - progress_bar.py[line:274] - INFO: epoch 001:   7598 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=111.7, bsz=40, num_updates=7590, lr=4.8641e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=19967
2023-02-20 18:58:45 - progress_bar.py[line:274] - INFO: epoch 001:   7608 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.9, bsz=40, num_updates=7600, lr=4.86374e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19978
2023-02-20 18:58:56 - progress_bar.py[line:274] - INFO: epoch 001:   7618 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.5, bsz=40, num_updates=7610, lr=4.86338e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19989
2023-02-20 18:59:08 - progress_bar.py[line:274] - INFO: epoch 001:   7628 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.88, wpb=111.4, bsz=40, num_updates=7620, lr=4.86301e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20001
2023-02-20 18:59:19 - progress_bar.py[line:274] - INFO: epoch 001:   7638 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=7630, lr=4.86265e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20012
2023-02-20 18:59:30 - progress_bar.py[line:274] - INFO: epoch 001:   7648 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.9, bsz=40, num_updates=7640, lr=4.86229e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20023
2023-02-20 18:59:41 - progress_bar.py[line:274] - INFO: epoch 001:   7658 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111, bsz=40, num_updates=7650, lr=4.86193e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20034
2023-02-20 18:59:52 - progress_bar.py[line:274] - INFO: epoch 001:   7668 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=7660, lr=4.86157e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20045
2023-02-20 19:00:04 - progress_bar.py[line:274] - INFO: epoch 001:   7678 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=111.1, bsz=40, num_updates=7670, lr=4.8612e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20057
2023-02-20 19:00:15 - progress_bar.py[line:274] - INFO: epoch 001:   7688 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=109.7, bsz=40, num_updates=7680, lr=4.86084e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20068
2023-02-20 19:00:26 - progress_bar.py[line:274] - INFO: epoch 001:   7698 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.1, bsz=40, num_updates=7690, lr=4.86048e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20078
2023-02-20 19:00:37 - progress_bar.py[line:274] - INFO: epoch 001:   7708 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=7700, lr=4.86012e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20090
2023-02-20 19:00:48 - progress_bar.py[line:274] - INFO: epoch 001:   7718 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=7710, lr=4.85976e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20101
2023-02-20 19:00:59 - progress_bar.py[line:274] - INFO: epoch 001:   7728 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.8, ups=0.92, wpb=113, bsz=40, num_updates=7720, lr=4.8594e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20112
2023-02-20 19:01:10 - progress_bar.py[line:274] - INFO: epoch 001:   7738 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=112, bsz=40, num_updates=7730, lr=4.85903e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20123
2023-02-20 19:01:21 - progress_bar.py[line:274] - INFO: epoch 001:   7748 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.3, bsz=40, num_updates=7740, lr=4.85867e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20134
2023-02-20 19:01:33 - progress_bar.py[line:274] - INFO: epoch 001:   7758 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.9, bsz=40, num_updates=7750, lr=4.85831e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20145
2023-02-20 19:01:44 - progress_bar.py[line:274] - INFO: epoch 001:   7768 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=112.1, bsz=40, num_updates=7760, lr=4.85795e-05, gnorm=0.083, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=20157
2023-02-20 19:01:55 - progress_bar.py[line:274] - INFO: epoch 001:   7778 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.2, bsz=40, num_updates=7770, lr=4.85759e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=20168
2023-02-20 19:02:06 - progress_bar.py[line:274] - INFO: epoch 001:   7788 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=7780, lr=4.85722e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20179
2023-02-20 19:02:17 - progress_bar.py[line:274] - INFO: epoch 001:   7798 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=7790, lr=4.85686e-05, gnorm=0.101, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20190
2023-02-20 19:02:29 - progress_bar.py[line:274] - INFO: epoch 001:   7808 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.4, bsz=40, num_updates=7800, lr=4.8565e-05, gnorm=0.114, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20201
2023-02-20 19:02:40 - progress_bar.py[line:274] - INFO: epoch 001:   7818 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.88, wpb=109.8, bsz=40, num_updates=7810, lr=4.85614e-05, gnorm=0.105, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20213
2023-02-20 19:02:51 - progress_bar.py[line:274] - INFO: epoch 001:   7828 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.2, ups=0.94, wpb=110.5, bsz=40, num_updates=7820, lr=4.85578e-05, gnorm=0.118, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20223
2023-02-20 19:03:02 - progress_bar.py[line:274] - INFO: epoch 001:   7838 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=7830, lr=4.85542e-05, gnorm=0.12, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20234
2023-02-20 19:03:13 - progress_bar.py[line:274] - INFO: epoch 001:   7848 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.91, wpb=110.6, bsz=40, num_updates=7840, lr=4.85505e-05, gnorm=0.106, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20246
2023-02-20 19:03:24 - progress_bar.py[line:274] - INFO: epoch 001:   7858 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=7850, lr=4.85469e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20257
2023-02-20 19:03:35 - progress_bar.py[line:274] - INFO: epoch 001:   7868 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112, bsz=40, num_updates=7860, lr=4.85433e-05, gnorm=0.089, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20268
2023-02-20 19:03:46 - progress_bar.py[line:274] - INFO: epoch 001:   7878 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=7870, lr=4.85397e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20279
2023-02-20 19:03:57 - progress_bar.py[line:274] - INFO: epoch 001:   7888 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=7880, lr=4.85361e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20290
2023-02-20 19:04:08 - progress_bar.py[line:274] - INFO: epoch 001:   7898 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.91, wpb=110.4, bsz=40, num_updates=7890, lr=4.85324e-05, gnorm=0.096, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20301
2023-02-20 19:04:19 - progress_bar.py[line:274] - INFO: epoch 001:   7908 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=7900, lr=4.85288e-05, gnorm=0.103, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=20312
2023-02-20 19:04:31 - progress_bar.py[line:274] - INFO: epoch 001:   7918 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=110.7, bsz=40, num_updates=7910, lr=4.85252e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20324
2023-02-20 19:04:42 - progress_bar.py[line:274] - INFO: epoch 001:   7928 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=7920, lr=4.85216e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20335
2023-02-20 19:04:53 - progress_bar.py[line:274] - INFO: epoch 001:   7938 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=7930, lr=4.8518e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20346
2023-02-20 19:05:05 - progress_bar.py[line:274] - INFO: epoch 001:   7948 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=94.8, ups=0.86, wpb=110.7, bsz=40, num_updates=7940, lr=4.85144e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=20358
2023-02-20 19:05:16 - progress_bar.py[line:274] - INFO: epoch 001:   7958 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.2, bsz=40, num_updates=7950, lr=4.85107e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20369
2023-02-20 19:05:27 - progress_bar.py[line:274] - INFO: epoch 001:   7968 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=7960, lr=4.85071e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20380
2023-02-20 19:05:39 - progress_bar.py[line:274] - INFO: epoch 001:   7978 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=7970, lr=4.85035e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20391
2023-02-20 19:05:50 - progress_bar.py[line:274] - INFO: epoch 001:   7988 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.3, bsz=40, num_updates=7980, lr=4.84999e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20403
2023-02-20 19:06:01 - progress_bar.py[line:274] - INFO: epoch 001:   7998 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.91, wpb=109.5, bsz=40, num_updates=7990, lr=4.84963e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20414
2023-02-20 19:06:12 - progress_bar.py[line:274] - INFO: epoch 001:   8008 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.4, bsz=40, num_updates=8000, lr=4.84926e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20425
2023-02-20 19:06:12 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-20 19:06:13 - train.py[line:549] - INFO: 0 / 6234
2023-02-20 19:06:13 - train.py[line:551] - INFO: load:1.12 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-20 19:08:16 - train.py[line:549] - INFO: 200 / 6234
2023-02-20 19:08:16 - train.py[line:551] - INFO: load:1.14 valid_run:122.44 task_valid:119.08 collect_output:2.32
2023-02-20 19:10:16 - train.py[line:549] - INFO: 400 / 6234
2023-02-20 19:10:16 - train.py[line:551] - INFO: load:1.17 valid_run:242.61 task_valid:235.41 collect_output:5.11
2023-02-20 19:12:18 - train.py[line:549] - INFO: 600 / 6234
2023-02-20 19:12:18 - train.py[line:551] - INFO: load:1.19 valid_run:364.76 task_valid:352.34 collect_output:9.29
2023-02-20 19:14:21 - train.py[line:549] - INFO: 800 / 6234
2023-02-20 19:14:21 - train.py[line:551] - INFO: load:1.21 valid_run:486.97 task_valid:466.45 collect_output:16.37
2023-02-20 19:16:21 - train.py[line:549] - INFO: 1000 / 6234
2023-02-20 19:16:21 - train.py[line:551] - INFO: load:1.24 valid_run:607.55 task_valid:584.02 collect_output:18.38
2023-02-20 19:18:24 - train.py[line:549] - INFO: 1200 / 6234
2023-02-20 19:18:24 - train.py[line:551] - INFO: load:1.26 valid_run:730.65 task_valid:703.11 collect_output:21.37
2023-02-20 19:20:28 - train.py[line:549] - INFO: 1400 / 6234
2023-02-20 19:20:28 - train.py[line:551] - INFO: load:1.29 valid_run:853.90 task_valid:821.66 collect_output:25.05
2023-02-20 19:22:30 - train.py[line:549] - INFO: 1600 / 6234
2023-02-20 19:22:30 - train.py[line:551] - INFO: load:1.31 valid_run:975.98 task_valid:938.64 collect_output:29.14
2023-02-20 19:24:34 - train.py[line:549] - INFO: 1800 / 6234
2023-02-20 19:24:34 - train.py[line:551] - INFO: load:1.33 valid_run:1099.81 task_valid:1056.17 collect_output:34.40
2023-02-20 19:26:36 - train.py[line:549] - INFO: 2000 / 6234
2023-02-20 19:26:36 - train.py[line:551] - INFO: load:1.36 valid_run:1221.61 task_valid:1169.18 collect_output:42.14
2023-02-20 19:28:36 - train.py[line:549] - INFO: 2200 / 6234
2023-02-20 19:28:36 - train.py[line:551] - INFO: load:1.38 valid_run:1341.95 task_valid:1285.10 collect_output:45.55
2023-02-20 19:30:38 - train.py[line:549] - INFO: 2400 / 6234
2023-02-20 19:30:38 - train.py[line:551] - INFO: load:1.41 valid_run:1463.79 task_valid:1402.35 collect_output:49.11
2023-02-20 19:32:37 - train.py[line:549] - INFO: 2600 / 6234
2023-02-20 19:32:37 - train.py[line:551] - INFO: load:1.43 valid_run:1582.93 task_valid:1516.43 collect_output:53.15
2023-02-20 19:34:38 - train.py[line:549] - INFO: 2800 / 6234
2023-02-20 19:34:38 - train.py[line:551] - INFO: load:1.45 valid_run:1704.32 task_valid:1634.56 collect_output:55.37
2023-02-20 19:36:40 - train.py[line:549] - INFO: 3000 / 6234
2023-02-20 19:36:40 - train.py[line:551] - INFO: load:1.48 valid_run:1825.57 task_valid:1750.90 collect_output:59.29
2023-02-20 19:38:41 - train.py[line:549] - INFO: 3200 / 6234
2023-02-20 19:38:41 - train.py[line:551] - INFO: load:1.50 valid_run:1946.94 task_valid:1865.25 collect_output:65.27
2023-02-20 19:40:43 - train.py[line:549] - INFO: 3400 / 6234
2023-02-20 19:40:43 - train.py[line:551] - INFO: load:1.53 valid_run:2068.45 task_valid:1981.72 collect_output:69.30
2023-02-20 19:42:44 - train.py[line:549] - INFO: 3600 / 6234
2023-02-20 19:42:44 - train.py[line:551] - INFO: load:1.55 valid_run:2189.26 task_valid:2099.87 collect_output:70.93
2023-02-20 19:44:45 - train.py[line:549] - INFO: 3800 / 6234
2023-02-20 19:44:45 - train.py[line:551] - INFO: load:1.58 valid_run:2310.54 task_valid:2216.93 collect_output:74.13
2023-02-20 19:46:46 - train.py[line:549] - INFO: 4000 / 6234
2023-02-20 19:46:46 - train.py[line:551] - INFO: load:1.60 valid_run:2431.04 task_valid:2333.84 collect_output:76.70
2023-02-20 19:48:47 - train.py[line:549] - INFO: 4200 / 6234
2023-02-20 19:48:47 - train.py[line:551] - INFO: load:1.63 valid_run:2552.77 task_valid:2450.56 collect_output:80.72
2023-02-20 19:50:49 - train.py[line:549] - INFO: 4400 / 6234
2023-02-20 19:50:49 - train.py[line:551] - INFO: load:1.65 valid_run:2674.88 task_valid:2569.68 collect_output:82.70
2023-02-20 19:52:50 - train.py[line:549] - INFO: 4600 / 6234
2023-02-20 19:52:50 - train.py[line:551] - INFO: load:1.68 valid_run:2795.25 task_valid:2684.19 collect_output:87.57
2023-02-20 19:54:50 - train.py[line:549] - INFO: 4800 / 6234
2023-02-20 19:54:50 - train.py[line:551] - INFO: load:1.70 valid_run:2915.00 task_valid:2800.45 collect_output:90.05
2023-02-20 19:56:51 - train.py[line:549] - INFO: 5000 / 6234
2023-02-20 19:56:51 - train.py[line:551] - INFO: load:1.73 valid_run:3036.69 task_valid:2916.90 collect_output:94.27
2023-02-20 19:58:54 - train.py[line:549] - INFO: 5200 / 6234
2023-02-20 19:58:54 - train.py[line:551] - INFO: load:1.75 valid_run:3159.45 task_valid:3033.12 collect_output:99.81
2023-02-20 20:00:54 - train.py[line:549] - INFO: 5400 / 6234
2023-02-20 20:00:54 - train.py[line:551] - INFO: load:1.78 valid_run:3279.04 task_valid:3147.51 collect_output:103.98
2023-02-20 20:02:56 - train.py[line:549] - INFO: 5600 / 6234
2023-02-20 20:02:56 - train.py[line:551] - INFO: load:1.80 valid_run:3400.96 task_valid:3267.12 collect_output:105.28
2023-02-20 20:04:58 - train.py[line:549] - INFO: 5800 / 6234
2023-02-20 20:04:58 - train.py[line:551] - INFO: load:1.83 valid_run:3522.58 task_valid:3382.90 collect_output:110.12
2023-02-20 20:07:00 - train.py[line:549] - INFO: 6000 / 6234
2023-02-20 20:07:00 - train.py[line:551] - INFO: load:1.85 valid_run:3644.61 task_valid:3501.50 collect_output:112.54
2023-02-20 20:09:01 - train.py[line:549] - INFO: 6200 / 6234
2023-02-20 20:09:01 - train.py[line:551] - INFO: load:1.88 valid_run:3765.77 task_valid:3619.99 collect_output:114.17

====================================================================================================
SGG eval:     R @ 50: 0.6509;     R @ 100: 0.6794;     R @ 500: 0.7025;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4313;    mR @ 100: 0.4709;    mR @ 500: 0.5022;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7317) (covered in:0.5625) (covering:0.3714) (eating:0.8235) (flying in:0.9545) (growing on:0.5000) (hanging from:0.4516) (lying on:0.1667) (mounted on:0.0000) (painted on:0.0000) (parked on:1.0000) (playing:0.0000) (riding:0.9663) (says:0.0000) (sitting on:0.7642) (standing on:0.3593) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.5139) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6509;     R @ 100: 0.6794;     R @ 500: 0.7025;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4313;    mR @ 100: 0.4709;    mR @ 500: 0.5022;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7317) (covered in:0.5625) (covering:0.3714) (eating:0.8235) (flying in:0.9545) (growing on:0.5000) (hanging from:0.4516) (lying on:0.1667) (mounted on:0.0000) (painted on:0.0000) (parked on:1.0000) (playing:0.0000) (riding:0.9663) (says:0.0000) (sitting on:0.7642) (standing on:0.3593) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.5139) 
--------------------------------------------------------
====================================================================================================

2023-02-20 20:09:32 - train.py[line:487] - INFO: 0.6794139801375095
2023-02-20 20:09:32 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-20 20:09:32 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.222 | loss_v1 0 | loss_v2 0 | nll_loss 0.052 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.679414 | ppl 1.04 | vqa_score 0.2579 | wps 118.1 | wpb 72 | bsz 24 | num_updates 8000 | best_R@100 0.679414
2023-02-20 20:09:32 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2023-02-20 20:09:32 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_8000.pt
2023-02-20 20:09:38 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_8000.pt
2023-02-20 20:09:43 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.6794139801375095) (writing took 11.09860030002892 seconds)
2023-02-20 20:09:54 - progress_bar.py[line:274] - INFO: epoch 001:   8018 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=112.1, bsz=40, num_updates=8010, lr=4.8489e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24247
2023-02-20 20:10:06 - progress_bar.py[line:274] - INFO: epoch 001:   8028 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=8020, lr=4.84854e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24258
2023-02-20 20:10:17 - progress_bar.py[line:274] - INFO: epoch 001:   8038 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.87, wpb=111.3, bsz=40, num_updates=8030, lr=4.84818e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24270
2023-02-20 20:10:28 - progress_bar.py[line:274] - INFO: epoch 001:   8048 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.87, wpb=110.4, bsz=40, num_updates=8040, lr=4.84782e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24281
2023-02-20 20:10:40 - progress_bar.py[line:274] - INFO: epoch 001:   8058 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=8050, lr=4.84746e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24292
2023-02-20 20:10:51 - progress_bar.py[line:274] - INFO: epoch 001:   8068 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.88, wpb=112.6, bsz=40, num_updates=8060, lr=4.84709e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24304
2023-02-20 20:11:02 - progress_bar.py[line:274] - INFO: epoch 001:   8078 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.4, bsz=40, num_updates=8070, lr=4.84673e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24315
2023-02-20 20:11:13 - progress_bar.py[line:274] - INFO: epoch 001:   8088 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=8080, lr=4.84637e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24326
2023-02-20 20:11:24 - progress_bar.py[line:274] - INFO: epoch 001:   8098 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=8090, lr=4.84601e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24337
2023-02-20 20:11:35 - progress_bar.py[line:274] - INFO: epoch 001:   8108 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.6, ups=0.87, wpb=109.7, bsz=40, num_updates=8100, lr=4.84565e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=24348
2023-02-20 20:11:47 - progress_bar.py[line:274] - INFO: epoch 001:   8118 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=8110, lr=4.84528e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24359
2023-02-20 20:11:58 - progress_bar.py[line:274] - INFO: epoch 001:   8128 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=8120, lr=4.84492e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24371
2023-02-20 20:12:09 - progress_bar.py[line:274] - INFO: epoch 001:   8138 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.92, wpb=112.5, bsz=40, num_updates=8130, lr=4.84456e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24381
2023-02-20 20:12:20 - progress_bar.py[line:274] - INFO: epoch 001:   8148 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.88, wpb=113.2, bsz=40, num_updates=8140, lr=4.8442e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24393
2023-02-20 20:12:31 - progress_bar.py[line:274] - INFO: epoch 001:   8158 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=8150, lr=4.84384e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24404
2023-02-20 20:12:43 - progress_bar.py[line:274] - INFO: epoch 001:   8168 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.2, ups=0.87, wpb=109.4, bsz=40, num_updates=8160, lr=4.84348e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24415
2023-02-20 20:12:54 - progress_bar.py[line:274] - INFO: epoch 001:   8178 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=8170, lr=4.84311e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24426
2023-02-20 20:13:05 - progress_bar.py[line:274] - INFO: epoch 001:   8188 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.89, wpb=109, bsz=40, num_updates=8180, lr=4.84275e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24438
2023-02-20 20:13:16 - progress_bar.py[line:274] - INFO: epoch 001:   8198 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.1, bsz=40, num_updates=8190, lr=4.84239e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=24449
2023-02-20 20:13:28 - progress_bar.py[line:274] - INFO: epoch 001:   8208 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.86, wpb=112.5, bsz=40, num_updates=8200, lr=4.84203e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=24461
2023-02-20 20:13:39 - progress_bar.py[line:274] - INFO: epoch 001:   8218 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.2, bsz=40, num_updates=8210, lr=4.84167e-05, gnorm=0.132, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24472
2023-02-20 20:13:50 - progress_bar.py[line:274] - INFO: epoch 001:   8228 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.2, bsz=40, num_updates=8220, lr=4.8413e-05, gnorm=0.112, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24483
2023-02-20 20:14:01 - progress_bar.py[line:274] - INFO: epoch 001:   8238 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=8230, lr=4.84094e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24494
2023-02-20 20:14:12 - progress_bar.py[line:274] - INFO: epoch 001:   8248 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.2, ups=0.94, wpb=111.4, bsz=40, num_updates=8240, lr=4.84058e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24505
2023-02-20 20:14:23 - progress_bar.py[line:274] - INFO: epoch 001:   8258 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=8250, lr=4.84022e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24516
2023-02-20 20:14:34 - progress_bar.py[line:274] - INFO: epoch 001:   8268 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.6, bsz=40, num_updates=8260, lr=4.83986e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24527
2023-02-20 20:14:45 - progress_bar.py[line:274] - INFO: epoch 001:   8278 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=111.1, bsz=40, num_updates=8270, lr=4.8395e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24538
2023-02-20 20:14:56 - progress_bar.py[line:274] - INFO: epoch 001:   8288 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=8280, lr=4.83913e-05, gnorm=0.116, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24549
2023-02-20 20:15:07 - progress_bar.py[line:274] - INFO: epoch 001:   8298 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.4, bsz=40, num_updates=8290, lr=4.83877e-05, gnorm=0.163, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24560
2023-02-20 20:15:18 - progress_bar.py[line:274] - INFO: epoch 001:   8308 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=8300, lr=4.83841e-05, gnorm=0.132, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24571
2023-02-20 20:15:29 - progress_bar.py[line:274] - INFO: epoch 001:   8318 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=8310, lr=4.83805e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24582
2023-02-20 20:15:40 - progress_bar.py[line:274] - INFO: epoch 001:   8328 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=111.5, bsz=40, num_updates=8320, lr=4.83769e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24593
2023-02-20 20:15:51 - progress_bar.py[line:274] - INFO: epoch 001:   8338 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.91, wpb=112.1, bsz=40, num_updates=8330, lr=4.83732e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24604
2023-02-20 20:16:03 - progress_bar.py[line:274] - INFO: epoch 001:   8348 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=8340, lr=4.83696e-05, gnorm=0.119, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24615
2023-02-20 20:16:14 - progress_bar.py[line:274] - INFO: epoch 001:   8358 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111, bsz=40, num_updates=8350, lr=4.8366e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24627
2023-02-20 20:16:25 - progress_bar.py[line:274] - INFO: epoch 001:   8368 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=8360, lr=4.83624e-05, gnorm=0.048, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24638
2023-02-20 20:16:36 - progress_bar.py[line:274] - INFO: epoch 001:   8378 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.5, bsz=40, num_updates=8370, lr=4.83588e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24649
2023-02-20 20:16:47 - progress_bar.py[line:274] - INFO: epoch 001:   8388 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.7, bsz=40, num_updates=8380, lr=4.83552e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24660
2023-02-20 20:16:58 - progress_bar.py[line:274] - INFO: epoch 001:   8398 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=8390, lr=4.83515e-05, gnorm=0.155, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24671
2023-02-20 20:17:09 - progress_bar.py[line:274] - INFO: epoch 001:   8408 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.2, bsz=40, num_updates=8400, lr=4.83479e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24682
2023-02-20 20:17:20 - progress_bar.py[line:274] - INFO: epoch 001:   8418 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.9, ups=0.93, wpb=110.6, bsz=40, num_updates=8410, lr=4.83443e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=24693
2023-02-20 20:17:31 - progress_bar.py[line:274] - INFO: epoch 001:   8428 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.9, wpb=110.5, bsz=40, num_updates=8420, lr=4.83407e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=24704
2023-02-20 20:17:39 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-20 20:17:43 - progress_bar.py[line:274] - INFO: epoch 001:   8439 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89, ups=0.81, wpb=110.3, bsz=40, num_updates=8430, lr=4.83371e-05, gnorm=0.128, clip=0, loss_scale=4096, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=24716
2023-02-20 20:17:55 - progress_bar.py[line:274] - INFO: epoch 001:   8449 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=8440, lr=4.83334e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24728
2023-02-20 20:18:06 - progress_bar.py[line:274] - INFO: epoch 001:   8459 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.5, bsz=40, num_updates=8450, lr=4.83298e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24739
2023-02-20 20:18:17 - progress_bar.py[line:274] - INFO: epoch 001:   8469 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=8460, lr=4.83262e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24750
2023-02-20 20:18:28 - progress_bar.py[line:274] - INFO: epoch 001:   8479 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.9, wpb=109.7, bsz=40, num_updates=8470, lr=4.83226e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24761
2023-02-20 20:18:40 - progress_bar.py[line:274] - INFO: epoch 001:   8489 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.9, bsz=40, num_updates=8480, lr=4.8319e-05, gnorm=0.05, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24772
2023-02-20 20:18:50 - progress_bar.py[line:274] - INFO: epoch 001:   8499 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.4, bsz=40, num_updates=8490, lr=4.83154e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24783
2023-02-20 20:19:01 - progress_bar.py[line:274] - INFO: epoch 001:   8509 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.2, bsz=40, num_updates=8500, lr=4.83117e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24794
2023-02-20 20:19:12 - progress_bar.py[line:274] - INFO: epoch 001:   8519 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=8510, lr=4.83081e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24805
2023-02-20 20:19:24 - progress_bar.py[line:274] - INFO: epoch 001:   8529 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.8, bsz=40, num_updates=8520, lr=4.83045e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24817
2023-02-20 20:19:35 - progress_bar.py[line:274] - INFO: epoch 001:   8539 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.88, wpb=111.5, bsz=40, num_updates=8530, lr=4.83009e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24828
2023-02-20 20:19:46 - progress_bar.py[line:274] - INFO: epoch 001:   8549 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.4, bsz=40, num_updates=8540, lr=4.82973e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24839
2023-02-20 20:19:58 - progress_bar.py[line:274] - INFO: epoch 001:   8559 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=8550, lr=4.82936e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24851
2023-02-20 20:20:09 - progress_bar.py[line:274] - INFO: epoch 001:   8569 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.9, bsz=40, num_updates=8560, lr=4.829e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=24862
2023-02-20 20:20:20 - progress_bar.py[line:274] - INFO: epoch 001:   8579 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.9, bsz=40, num_updates=8570, lr=4.82864e-05, gnorm=0.129, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24873
2023-02-20 20:20:31 - progress_bar.py[line:274] - INFO: epoch 001:   8589 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.1, ups=0.87, wpb=112.5, bsz=40, num_updates=8580, lr=4.82828e-05, gnorm=0.116, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24884
2023-02-20 20:20:42 - progress_bar.py[line:274] - INFO: epoch 001:   8599 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=8590, lr=4.82792e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24895
2023-02-20 20:20:53 - progress_bar.py[line:274] - INFO: epoch 001:   8609 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.3, bsz=40, num_updates=8600, lr=4.82756e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24906
2023-02-20 20:21:04 - progress_bar.py[line:274] - INFO: epoch 001:   8619 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.5, bsz=40, num_updates=8610, lr=4.82719e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24917
2023-02-20 20:21:16 - progress_bar.py[line:274] - INFO: epoch 001:   8629 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=8620, lr=4.82683e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24929
2023-02-20 20:21:27 - progress_bar.py[line:274] - INFO: epoch 001:   8639 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.88, wpb=112.2, bsz=40, num_updates=8630, lr=4.82647e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24940
2023-02-20 20:21:38 - progress_bar.py[line:274] - INFO: epoch 001:   8649 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110.7, bsz=40, num_updates=8640, lr=4.82611e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24951
2023-02-20 20:21:49 - progress_bar.py[line:274] - INFO: epoch 001:   8659 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.1, ups=0.88, wpb=111.7, bsz=40, num_updates=8650, lr=4.82575e-05, gnorm=0.114, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24962
2023-02-20 20:22:00 - progress_bar.py[line:274] - INFO: epoch 001:   8669 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=8660, lr=4.82538e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24973
2023-02-20 20:22:11 - progress_bar.py[line:274] - INFO: epoch 001:   8679 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.92, wpb=110.4, bsz=40, num_updates=8670, lr=4.82502e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24984
2023-02-20 20:22:23 - progress_bar.py[line:274] - INFO: epoch 001:   8689 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.4, bsz=40, num_updates=8680, lr=4.82466e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=24996
2023-02-20 20:22:34 - progress_bar.py[line:274] - INFO: epoch 001:   8699 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.7, bsz=40, num_updates=8690, lr=4.8243e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25007
2023-02-20 20:22:45 - progress_bar.py[line:274] - INFO: epoch 001:   8709 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.4, ups=0.91, wpb=111.9, bsz=40, num_updates=8700, lr=4.82394e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=25018
2023-02-20 20:22:56 - progress_bar.py[line:274] - INFO: epoch 001:   8719 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=8710, lr=4.82357e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25029
2023-02-20 20:23:07 - progress_bar.py[line:274] - INFO: epoch 001:   8729 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.9, bsz=40, num_updates=8720, lr=4.82321e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25040
2023-02-20 20:23:18 - progress_bar.py[line:274] - INFO: epoch 001:   8739 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=8730, lr=4.82285e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25051
2023-02-20 20:23:30 - progress_bar.py[line:274] - INFO: epoch 001:   8749 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.6, bsz=40, num_updates=8740, lr=4.82249e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25062
2023-02-20 20:23:41 - progress_bar.py[line:274] - INFO: epoch 001:   8759 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.6, bsz=40, num_updates=8750, lr=4.82213e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25074
2023-02-20 20:23:52 - progress_bar.py[line:274] - INFO: epoch 001:   8769 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=8760, lr=4.82177e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25085
2023-02-20 20:24:03 - progress_bar.py[line:274] - INFO: epoch 001:   8779 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.5, bsz=40, num_updates=8770, lr=4.8214e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25096
2023-02-20 20:24:14 - progress_bar.py[line:274] - INFO: epoch 001:   8789 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.8, bsz=40, num_updates=8780, lr=4.82104e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25107
2023-02-20 20:24:25 - progress_bar.py[line:274] - INFO: epoch 001:   8799 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.2, ups=0.94, wpb=111.5, bsz=40, num_updates=8790, lr=4.82068e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25118
2023-02-20 20:24:35 - progress_bar.py[line:274] - INFO: epoch 001:   8809 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.3, ups=0.96, wpb=111.2, bsz=40, num_updates=8800, lr=4.82032e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=10, gb_free=10.1, ema_decay=0.9999, wall=25128
2023-02-20 20:24:46 - progress_bar.py[line:274] - INFO: epoch 001:   8819 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.92, wpb=109.7, bsz=40, num_updates=8810, lr=4.81996e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25139
2023-02-20 20:24:57 - progress_bar.py[line:274] - INFO: epoch 001:   8829 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.5, bsz=40, num_updates=8820, lr=4.81959e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25150
2023-02-20 20:25:09 - progress_bar.py[line:274] - INFO: epoch 001:   8839 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=8830, lr=4.81923e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25162
2023-02-20 20:25:20 - progress_bar.py[line:274] - INFO: epoch 001:   8849 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.3, bsz=40, num_updates=8840, lr=4.81887e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25173
2023-02-20 20:25:31 - progress_bar.py[line:274] - INFO: epoch 001:   8859 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.7, bsz=40, num_updates=8850, lr=4.81851e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25184
2023-02-20 20:25:43 - progress_bar.py[line:274] - INFO: epoch 001:   8869 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=8860, lr=4.81815e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25196
2023-02-20 20:25:54 - progress_bar.py[line:274] - INFO: epoch 001:   8879 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.3, bsz=40, num_updates=8870, lr=4.81779e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25207
2023-02-20 20:26:05 - progress_bar.py[line:274] - INFO: epoch 001:   8889 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.91, wpb=108.3, bsz=40, num_updates=8880, lr=4.81742e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25218
2023-02-20 20:26:16 - progress_bar.py[line:274] - INFO: epoch 001:   8899 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=8890, lr=4.81706e-05, gnorm=0.152, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25229
2023-02-20 20:26:28 - progress_bar.py[line:274] - INFO: epoch 001:   8909 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.87, wpb=110.5, bsz=40, num_updates=8900, lr=4.8167e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25240
2023-02-20 20:26:39 - progress_bar.py[line:274] - INFO: epoch 001:   8919 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.88, wpb=111.6, bsz=40, num_updates=8910, lr=4.81634e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25252
2023-02-20 20:26:50 - progress_bar.py[line:274] - INFO: epoch 001:   8929 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.9, ups=0.93, wpb=110.7, bsz=40, num_updates=8920, lr=4.81598e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25263
2023-02-20 20:27:01 - progress_bar.py[line:274] - INFO: epoch 001:   8939 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.89, wpb=112.7, bsz=40, num_updates=8930, lr=4.81561e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25274
2023-02-20 20:27:12 - progress_bar.py[line:274] - INFO: epoch 001:   8949 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=8940, lr=4.81525e-05, gnorm=0.097, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25285
2023-02-20 20:27:23 - progress_bar.py[line:274] - INFO: epoch 001:   8959 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=8950, lr=4.81489e-05, gnorm=0.099, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25296
2023-02-20 20:27:34 - progress_bar.py[line:274] - INFO: epoch 001:   8969 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=8960, lr=4.81453e-05, gnorm=0.094, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25307
2023-02-20 20:27:46 - progress_bar.py[line:274] - INFO: epoch 001:   8979 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.3, ups=0.87, wpb=109.7, bsz=40, num_updates=8970, lr=4.81417e-05, gnorm=0.099, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25319
2023-02-20 20:27:57 - progress_bar.py[line:274] - INFO: epoch 001:   8989 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.4, bsz=40, num_updates=8980, lr=4.81381e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25330
2023-02-20 20:28:08 - progress_bar.py[line:274] - INFO: epoch 001:   8999 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.7, bsz=40, num_updates=8990, lr=4.81344e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25341
2023-02-20 20:28:20 - progress_bar.py[line:274] - INFO: epoch 001:   9009 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.88, wpb=111.2, bsz=40, num_updates=9000, lr=4.81308e-05, gnorm=0.103, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25352
2023-02-20 20:28:31 - progress_bar.py[line:274] - INFO: epoch 001:   9019 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=9010, lr=4.81272e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25363
2023-02-20 20:28:42 - progress_bar.py[line:274] - INFO: epoch 001:   9029 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.3, ups=0.86, wpb=110, bsz=40, num_updates=9020, lr=4.81236e-05, gnorm=0.091, clip=0, loss_scale=8192, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=25375
2023-02-20 20:28:53 - progress_bar.py[line:274] - INFO: epoch 001:   9039 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.3, bsz=40, num_updates=9030, lr=4.812e-05, gnorm=0.088, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25386
2023-02-20 20:29:04 - progress_bar.py[line:274] - INFO: epoch 001:   9049 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=110.8, bsz=40, num_updates=9040, lr=4.81163e-05, gnorm=0.086, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25397
2023-02-20 20:29:15 - progress_bar.py[line:274] - INFO: epoch 001:   9059 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.8, bsz=40, num_updates=9050, lr=4.81127e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25408
2023-02-20 20:29:26 - progress_bar.py[line:274] - INFO: epoch 001:   9069 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.5, bsz=40, num_updates=9060, lr=4.81091e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25419
2023-02-20 20:29:38 - progress_bar.py[line:274] - INFO: epoch 001:   9079 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.1, ups=0.88, wpb=109.8, bsz=40, num_updates=9070, lr=4.81055e-05, gnorm=0.107, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25430
2023-02-20 20:29:49 - progress_bar.py[line:274] - INFO: epoch 001:   9089 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=9080, lr=4.81019e-05, gnorm=0.095, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25442
2023-02-20 20:30:00 - progress_bar.py[line:274] - INFO: epoch 001:   9099 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=9090, lr=4.80983e-05, gnorm=0.091, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25453
2023-02-20 20:30:11 - progress_bar.py[line:274] - INFO: epoch 001:   9109 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=9100, lr=4.80946e-05, gnorm=0.102, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25464
2023-02-20 20:30:22 - progress_bar.py[line:274] - INFO: epoch 001:   9119 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.2, ups=0.92, wpb=109.9, bsz=40, num_updates=9110, lr=4.8091e-05, gnorm=0.088, clip=0, loss_scale=8192, train_wall=11, gb_free=10, ema_decay=0.9999, wall=25475
2023-02-20 20:30:33 - progress_bar.py[line:274] - INFO: epoch 001:   9129 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=9120, lr=4.80874e-05, gnorm=0.094, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25486
2023-02-20 20:30:44 - progress_bar.py[line:274] - INFO: epoch 001:   9139 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.6, bsz=40, num_updates=9130, lr=4.80838e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25497
2023-02-20 20:30:55 - progress_bar.py[line:274] - INFO: epoch 001:   9149 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.6, bsz=40, num_updates=9140, lr=4.80802e-05, gnorm=0.096, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25508
2023-02-20 20:31:07 - progress_bar.py[line:274] - INFO: epoch 001:   9159 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.5, bsz=40, num_updates=9150, lr=4.80765e-05, gnorm=0.127, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25520
2023-02-20 20:31:18 - progress_bar.py[line:274] - INFO: epoch 001:   9169 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=9160, lr=4.80729e-05, gnorm=0.098, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25530
2023-02-20 20:31:28 - progress_bar.py[line:274] - INFO: epoch 001:   9179 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111, bsz=40, num_updates=9170, lr=4.80693e-05, gnorm=0.085, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25541
2023-02-20 20:31:39 - progress_bar.py[line:274] - INFO: epoch 001:   9189 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=112.2, bsz=40, num_updates=9180, lr=4.80657e-05, gnorm=0.086, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25552
2023-02-20 20:31:51 - progress_bar.py[line:274] - INFO: epoch 001:   9199 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.5, bsz=40, num_updates=9190, lr=4.80621e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25563
2023-02-20 20:32:02 - progress_bar.py[line:274] - INFO: epoch 001:   9209 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.89, wpb=112.8, bsz=40, num_updates=9200, lr=4.80585e-05, gnorm=0.095, clip=0, loss_scale=8192, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=25575
2023-02-20 20:32:13 - progress_bar.py[line:274] - INFO: epoch 001:   9219 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=9210, lr=4.80548e-05, gnorm=0.12, clip=0, loss_scale=8192, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=25586
2023-02-20 20:32:24 - progress_bar.py[line:274] - INFO: epoch 001:   9229 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=9220, lr=4.80512e-05, gnorm=0.1, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25597
2023-02-20 20:32:35 - progress_bar.py[line:274] - INFO: epoch 001:   9239 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.93, wpb=110.9, bsz=40, num_updates=9230, lr=4.80476e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25608
2023-02-20 20:32:46 - progress_bar.py[line:274] - INFO: epoch 001:   9249 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.7, bsz=40, num_updates=9240, lr=4.8044e-05, gnorm=0.089, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25619
2023-02-20 20:32:57 - progress_bar.py[line:274] - INFO: epoch 001:   9259 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.1, bsz=40, num_updates=9250, lr=4.80404e-05, gnorm=0.088, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25630
2023-02-20 20:33:09 - progress_bar.py[line:274] - INFO: epoch 001:   9269 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=95.9, ups=0.87, wpb=110, bsz=40, num_updates=9260, lr=4.80367e-05, gnorm=0.097, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25642
2023-02-20 20:33:20 - progress_bar.py[line:274] - INFO: epoch 001:   9279 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=110.2, bsz=40, num_updates=9270, lr=4.80331e-05, gnorm=0.098, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25653
2023-02-20 20:33:31 - progress_bar.py[line:274] - INFO: epoch 001:   9289 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.93, wpb=110.9, bsz=40, num_updates=9280, lr=4.80295e-05, gnorm=0.101, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25663
2023-02-20 20:33:42 - progress_bar.py[line:274] - INFO: epoch 001:   9299 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.92, wpb=110, bsz=40, num_updates=9290, lr=4.80259e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25674
2023-02-20 20:33:53 - progress_bar.py[line:274] - INFO: epoch 001:   9309 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=112.9, bsz=40, num_updates=9300, lr=4.80223e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25685
2023-02-20 20:34:04 - progress_bar.py[line:274] - INFO: epoch 001:   9319 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.4, bsz=40, num_updates=9310, lr=4.80187e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25697
2023-02-20 20:34:15 - progress_bar.py[line:274] - INFO: epoch 001:   9329 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.92, wpb=110.4, bsz=40, num_updates=9320, lr=4.8015e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25708
2023-02-20 20:34:26 - progress_bar.py[line:274] - INFO: epoch 001:   9339 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.4, bsz=40, num_updates=9330, lr=4.80114e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25718
2023-02-20 20:34:37 - progress_bar.py[line:274] - INFO: epoch 001:   9349 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=9340, lr=4.80078e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25730
2023-02-20 20:34:48 - progress_bar.py[line:274] - INFO: epoch 001:   9359 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112, bsz=40, num_updates=9350, lr=4.80042e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25741
2023-02-20 20:34:59 - progress_bar.py[line:274] - INFO: epoch 001:   9369 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=9360, lr=4.80006e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25752
2023-02-20 20:35:10 - progress_bar.py[line:274] - INFO: epoch 001:   9379 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=9370, lr=4.79969e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25763
2023-02-20 20:35:21 - progress_bar.py[line:274] - INFO: epoch 001:   9389 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=9380, lr=4.79933e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25774
2023-02-20 20:35:32 - progress_bar.py[line:274] - INFO: epoch 001:   9399 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.91, wpb=108.8, bsz=40, num_updates=9390, lr=4.79897e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25785
2023-02-20 20:35:43 - progress_bar.py[line:274] - INFO: epoch 001:   9409 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.9, wpb=110.8, bsz=40, num_updates=9400, lr=4.79861e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25796
2023-02-20 20:35:55 - progress_bar.py[line:274] - INFO: epoch 001:   9419 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96, ups=0.87, wpb=110.5, bsz=40, num_updates=9410, lr=4.79825e-05, gnorm=0.095, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25808
2023-02-20 20:36:06 - progress_bar.py[line:274] - INFO: epoch 001:   9429 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.88, wpb=111.2, bsz=40, num_updates=9420, lr=4.79789e-05, gnorm=0.122, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25819
2023-02-20 20:36:17 - progress_bar.py[line:274] - INFO: epoch 001:   9439 / 142023 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.92, wpb=109.4, bsz=40, num_updates=9430, lr=4.79752e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25830
2023-02-20 20:36:28 - progress_bar.py[line:274] - INFO: epoch 001:   9449 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111, bsz=40, num_updates=9440, lr=4.79716e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25841
2023-02-20 20:36:29 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-20 20:36:41 - progress_bar.py[line:274] - INFO: epoch 001:   9460 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.3, ups=0.81, wpb=110.5, bsz=40, num_updates=9450, lr=4.7968e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=25854
2023-02-20 20:36:52 - progress_bar.py[line:274] - INFO: epoch 001:   9470 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=111.2, bsz=40, num_updates=9460, lr=4.79644e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25865
2023-02-20 20:37:04 - progress_bar.py[line:274] - INFO: epoch 001:   9480 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=110.8, bsz=40, num_updates=9470, lr=4.79608e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25877
2023-02-20 20:37:15 - progress_bar.py[line:274] - INFO: epoch 001:   9490 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.3, bsz=40, num_updates=9480, lr=4.79571e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25888
2023-02-20 20:37:26 - progress_bar.py[line:274] - INFO: epoch 001:   9500 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.91, wpb=109.2, bsz=40, num_updates=9490, lr=4.79535e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25899
2023-02-20 20:37:37 - progress_bar.py[line:274] - INFO: epoch 001:   9510 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.89, wpb=112.5, bsz=40, num_updates=9500, lr=4.79499e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25910
2023-02-20 20:37:48 - progress_bar.py[line:274] - INFO: epoch 001:   9520 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=111.1, bsz=40, num_updates=9510, lr=4.79463e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25921
2023-02-20 20:37:59 - progress_bar.py[line:274] - INFO: epoch 001:   9530 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.4, bsz=40, num_updates=9520, lr=4.79427e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25932
2023-02-20 20:38:10 - progress_bar.py[line:274] - INFO: epoch 001:   9540 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.2, bsz=40, num_updates=9530, lr=4.79391e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25943
2023-02-20 20:38:21 - progress_bar.py[line:274] - INFO: epoch 001:   9550 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.9, wpb=110.4, bsz=40, num_updates=9540, lr=4.79354e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25954
2023-02-20 20:38:33 - progress_bar.py[line:274] - INFO: epoch 001:   9560 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=9550, lr=4.79318e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25966
2023-02-20 20:38:44 - progress_bar.py[line:274] - INFO: epoch 001:   9570 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.4, bsz=40, num_updates=9560, lr=4.79282e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25977
2023-02-20 20:38:55 - progress_bar.py[line:274] - INFO: epoch 001:   9580 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.5, bsz=40, num_updates=9570, lr=4.79246e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25988
2023-02-20 20:39:06 - progress_bar.py[line:274] - INFO: epoch 001:   9590 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=9580, lr=4.7921e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25999
2023-02-20 20:39:17 - progress_bar.py[line:274] - INFO: epoch 001:   9600 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=9590, lr=4.79173e-05, gnorm=0.105, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26010
2023-02-20 20:39:29 - progress_bar.py[line:274] - INFO: epoch 001:   9610 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=9600, lr=4.79137e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26022
2023-02-20 20:39:40 - progress_bar.py[line:274] - INFO: epoch 001:   9620 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.9, bsz=40, num_updates=9610, lr=4.79101e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=26033
2023-02-20 20:39:51 - progress_bar.py[line:274] - INFO: epoch 001:   9630 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.4, bsz=40, num_updates=9620, lr=4.79065e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26044
2023-02-20 20:40:02 - progress_bar.py[line:274] - INFO: epoch 001:   9640 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.1, bsz=40, num_updates=9630, lr=4.79029e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26055
2023-02-20 20:40:13 - progress_bar.py[line:274] - INFO: epoch 001:   9650 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=109.9, bsz=40, num_updates=9640, lr=4.78993e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26066
2023-02-20 20:40:25 - progress_bar.py[line:274] - INFO: epoch 001:   9660 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=9650, lr=4.78956e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26077
2023-02-20 20:40:36 - progress_bar.py[line:274] - INFO: epoch 001:   9670 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=9660, lr=4.7892e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=26089
2023-02-20 20:40:47 - progress_bar.py[line:274] - INFO: epoch 001:   9680 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112.4, bsz=40, num_updates=9670, lr=4.78884e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26100
2023-02-20 20:40:58 - progress_bar.py[line:274] - INFO: epoch 001:   9690 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=109.9, bsz=40, num_updates=9680, lr=4.78848e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26111
2023-02-20 20:41:09 - progress_bar.py[line:274] - INFO: epoch 001:   9700 / 142023 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.9, wpb=112.3, bsz=40, num_updates=9690, lr=4.78812e-05, gnorm=0.143, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26122
2023-02-20 20:41:21 - progress_bar.py[line:274] - INFO: epoch 001:   9710 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.3, bsz=40, num_updates=9700, lr=4.78775e-05, gnorm=0.11, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26134
2023-02-20 20:41:32 - progress_bar.py[line:274] - INFO: epoch 001:   9720 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111.2, bsz=40, num_updates=9710, lr=4.78739e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26145
2023-02-20 20:41:43 - progress_bar.py[line:274] - INFO: epoch 001:   9730 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=9720, lr=4.78703e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26156
2023-02-20 20:41:54 - progress_bar.py[line:274] - INFO: epoch 001:   9740 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.91, wpb=110.4, bsz=40, num_updates=9730, lr=4.78667e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=26167
2023-02-20 20:42:05 - progress_bar.py[line:274] - INFO: epoch 001:   9750 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.6, bsz=40, num_updates=9740, lr=4.78631e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26178
2023-02-20 20:42:16 - progress_bar.py[line:274] - INFO: epoch 001:   9760 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=9750, lr=4.78595e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26189
2023-02-20 20:42:27 - progress_bar.py[line:274] - INFO: epoch 001:   9770 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=111.1, bsz=40, num_updates=9760, lr=4.78558e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=26200
2023-02-20 20:42:39 - progress_bar.py[line:274] - INFO: epoch 001:   9780 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.89, wpb=110.3, bsz=40, num_updates=9770, lr=4.78522e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26212
2023-02-20 20:42:50 - progress_bar.py[line:274] - INFO: epoch 001:   9790 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.1, bsz=40, num_updates=9780, lr=4.78486e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26222
2023-02-20 20:43:01 - progress_bar.py[line:274] - INFO: epoch 001:   9800 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.92, wpb=110.9, bsz=40, num_updates=9790, lr=4.7845e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26233
2023-02-20 20:43:11 - progress_bar.py[line:274] - INFO: epoch 001:   9810 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.6, bsz=40, num_updates=9800, lr=4.78414e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=26244
2023-02-20 20:43:22 - progress_bar.py[line:274] - INFO: epoch 001:   9820 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.5, ups=0.93, wpb=110.2, bsz=40, num_updates=9810, lr=4.78377e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=26255
2023-02-20 20:43:33 - progress_bar.py[line:274] - INFO: epoch 001:   9830 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.2, bsz=40, num_updates=9820, lr=4.78341e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26266
2023-02-20 20:43:45 - progress_bar.py[line:274] - INFO: epoch 001:   9840 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=112, bsz=40, num_updates=9830, lr=4.78305e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=26277
2023-02-20 20:43:56 - progress_bar.py[line:274] - INFO: epoch 001:   9850 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=9840, lr=4.78269e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26288
2023-02-20 20:44:07 - progress_bar.py[line:274] - INFO: epoch 001:   9860 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=111, bsz=40, num_updates=9850, lr=4.78233e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26300
2023-02-20 20:44:18 - progress_bar.py[line:274] - INFO: epoch 001:   9870 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=9860, lr=4.78197e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26311
2023-02-20 20:44:29 - progress_bar.py[line:274] - INFO: epoch 001:   9880 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=9870, lr=4.7816e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26322
2023-02-20 20:44:40 - progress_bar.py[line:274] - INFO: epoch 001:   9890 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.7, bsz=40, num_updates=9880, lr=4.78124e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26333
2023-02-20 20:44:52 - progress_bar.py[line:274] - INFO: epoch 001:   9900 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=9890, lr=4.78088e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=26344
2023-02-20 20:45:03 - progress_bar.py[line:274] - INFO: epoch 001:   9910 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.7, bsz=40, num_updates=9900, lr=4.78052e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26356
2023-02-20 20:45:14 - progress_bar.py[line:274] - INFO: epoch 001:   9920 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=9910, lr=4.78016e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26367
2023-02-20 20:45:25 - progress_bar.py[line:274] - INFO: epoch 001:   9930 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.9, bsz=40, num_updates=9920, lr=4.77979e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26378
2023-02-20 20:45:36 - progress_bar.py[line:274] - INFO: epoch 001:   9940 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.8, bsz=40, num_updates=9930, lr=4.77943e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26389
2023-02-20 20:45:47 - progress_bar.py[line:274] - INFO: epoch 001:   9950 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.4, bsz=40, num_updates=9940, lr=4.77907e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26400
2023-02-20 20:45:58 - progress_bar.py[line:274] - INFO: epoch 001:   9960 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=111.4, bsz=40, num_updates=9950, lr=4.77871e-05, gnorm=0.127, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26411
2023-02-20 20:46:10 - progress_bar.py[line:274] - INFO: epoch 001:   9970 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.5, bsz=40, num_updates=9960, lr=4.77835e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=26422
2023-02-20 20:46:21 - progress_bar.py[line:274] - INFO: epoch 001:   9980 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.3, bsz=40, num_updates=9970, lr=4.77799e-05, gnorm=0.089, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26433
2023-02-20 20:46:31 - progress_bar.py[line:274] - INFO: epoch 001:   9990 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106, ups=0.94, wpb=112.4, bsz=40, num_updates=9980, lr=4.77762e-05, gnorm=0.092, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26444
2023-02-20 20:46:42 - progress_bar.py[line:274] - INFO: epoch 001:  10000 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.92, wpb=110.1, bsz=40, num_updates=9990, lr=4.77726e-05, gnorm=0.086, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26455
2023-02-20 20:46:53 - progress_bar.py[line:274] - INFO: epoch 001:  10010 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.5, bsz=40, num_updates=10000, lr=4.7769e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26466
2023-02-20 20:46:53 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-20 20:46:55 - train.py[line:549] - INFO: 0 / 6234
2023-02-20 20:46:55 - train.py[line:551] - INFO: load:1.05 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-20 20:48:57 - train.py[line:549] - INFO: 200 / 6234
2023-02-20 20:48:57 - train.py[line:551] - INFO: load:1.07 valid_run:122.08 task_valid:119.18 collect_output:1.86
2023-02-20 20:50:57 - train.py[line:549] - INFO: 400 / 6234
2023-02-20 20:50:57 - train.py[line:551] - INFO: load:1.10 valid_run:241.95 task_valid:235.11 collect_output:4.80
2023-02-20 20:52:59 - train.py[line:549] - INFO: 600 / 6234
2023-02-20 20:52:59 - train.py[line:551] - INFO: load:1.12 valid_run:363.93 task_valid:351.89 collect_output:9.01
2023-02-20 20:55:01 - train.py[line:549] - INFO: 800 / 6234
2023-02-20 20:55:01 - train.py[line:551] - INFO: load:1.15 valid_run:485.92 task_valid:465.87 collect_output:15.99
2023-02-20 20:57:02 - train.py[line:549] - INFO: 1000 / 6234
2023-02-20 20:57:02 - train.py[line:551] - INFO: load:1.17 valid_run:606.52 task_valid:583.50 collect_output:17.95
2023-02-20 20:59:05 - train.py[line:549] - INFO: 1200 / 6234
2023-02-20 20:59:05 - train.py[line:551] - INFO: load:1.19 valid_run:729.44 task_valid:702.40 collect_output:20.95
2023-02-20 21:01:08 - train.py[line:549] - INFO: 1400 / 6234
2023-02-20 21:01:08 - train.py[line:551] - INFO: load:1.22 valid_run:852.53 task_valid:820.75 collect_output:24.70
2023-02-20 21:03:10 - train.py[line:549] - INFO: 1600 / 6234
2023-02-20 21:03:10 - train.py[line:551] - INFO: load:1.24 valid_run:974.44 task_valid:937.54 collect_output:28.81
2023-02-20 21:05:14 - train.py[line:549] - INFO: 1800 / 6234
2023-02-20 21:05:14 - train.py[line:551] - INFO: load:1.27 valid_run:1098.25 task_valid:1055.09 collect_output:34.06
2023-02-20 21:07:15 - train.py[line:549] - INFO: 2000 / 6234
2023-02-20 21:07:15 - train.py[line:551] - INFO: load:1.29 valid_run:1219.98 task_valid:1168.01 collect_output:41.86
2023-02-20 21:09:16 - train.py[line:549] - INFO: 2200 / 6234
2023-02-20 21:09:16 - train.py[line:551] - INFO: load:1.31 valid_run:1340.10 task_valid:1283.81 collect_output:45.19
2023-02-20 21:11:17 - train.py[line:549] - INFO: 2400 / 6234
2023-02-20 21:11:17 - train.py[line:551] - INFO: load:1.34 valid_run:1461.78 task_valid:1401.00 collect_output:48.66
2023-02-20 21:13:17 - train.py[line:549] - INFO: 2600 / 6234
2023-02-20 21:13:17 - train.py[line:551] - INFO: load:1.36 valid_run:1580.93 task_valid:1515.05 collect_output:52.75
2023-02-20 21:15:18 - train.py[line:549] - INFO: 2800 / 6234
2023-02-20 21:15:18 - train.py[line:551] - INFO: load:1.39 valid_run:1702.02 task_valid:1633.12 collect_output:54.77
2023-02-20 21:17:19 - train.py[line:549] - INFO: 3000 / 6234
2023-02-20 21:17:19 - train.py[line:551] - INFO: load:1.41 valid_run:1823.01 task_valid:1749.52 collect_output:58.35
2023-02-20 21:19:20 - train.py[line:549] - INFO: 3200 / 6234
2023-02-20 21:19:20 - train.py[line:551] - INFO: load:1.43 valid_run:1944.12 task_valid:1863.77 collect_output:64.22
2023-02-20 21:21:21 - train.py[line:549] - INFO: 3400 / 6234
2023-02-20 21:21:21 - train.py[line:551] - INFO: load:1.46 valid_run:2065.39 task_valid:1980.06 collect_output:68.22
2023-02-20 21:23:22 - train.py[line:549] - INFO: 3600 / 6234
2023-02-20 21:23:22 - train.py[line:551] - INFO: load:1.48 valid_run:2186.02 task_valid:2098.04 collect_output:69.87
2023-02-20 21:25:23 - train.py[line:549] - INFO: 3800 / 6234
2023-02-20 21:25:23 - train.py[line:551] - INFO: load:1.50 valid_run:2307.33 task_valid:2215.37 collect_output:72.82
2023-02-20 21:27:24 - train.py[line:549] - INFO: 4000 / 6234
2023-02-20 21:27:24 - train.py[line:551] - INFO: load:1.53 valid_run:2427.78 task_valid:2332.19 collect_output:75.45
2023-02-20 21:29:25 - train.py[line:549] - INFO: 4200 / 6234
2023-02-20 21:29:25 - train.py[line:551] - INFO: load:1.55 valid_run:2549.45 task_valid:2448.98 collect_output:79.32
2023-02-20 21:31:28 - train.py[line:549] - INFO: 4400 / 6234
2023-02-20 21:31:28 - train.py[line:551] - INFO: load:1.58 valid_run:2671.59 task_valid:2568.17 collect_output:81.25
2023-02-20 21:33:28 - train.py[line:549] - INFO: 4600 / 6234
2023-02-20 21:33:28 - train.py[line:551] - INFO: load:1.60 valid_run:2791.93 task_valid:2682.85 collect_output:85.91
2023-02-20 21:35:28 - train.py[line:549] - INFO: 4800 / 6234
2023-02-20 21:35:28 - train.py[line:551] - INFO: load:1.62 valid_run:2911.85 task_valid:2799.39 collect_output:88.26
2023-02-20 21:37:30 - train.py[line:549] - INFO: 5000 / 6234
2023-02-20 21:37:30 - train.py[line:551] - INFO: load:1.65 valid_run:3033.51 task_valid:2915.81 collect_output:92.50
2023-02-20 21:39:33 - train.py[line:549] - INFO: 5200 / 6234
2023-02-20 21:39:33 - train.py[line:551] - INFO: load:1.67 valid_run:3156.55 task_valid:3032.12 collect_output:98.20
2023-02-20 21:41:32 - train.py[line:549] - INFO: 5400 / 6234
2023-02-20 21:41:32 - train.py[line:551] - INFO: load:1.70 valid_run:3276.03 task_valid:3146.34 collect_output:102.45
2023-02-20 21:43:35 - train.py[line:549] - INFO: 5600 / 6234
2023-02-20 21:43:35 - train.py[line:551] - INFO: load:1.72 valid_run:3398.18 task_valid:3265.95 collect_output:103.98
2023-02-20 21:45:36 - train.py[line:549] - INFO: 5800 / 6234
2023-02-20 21:45:36 - train.py[line:551] - INFO: load:1.74 valid_run:3519.89 task_valid:3381.67 collect_output:108.98
2023-02-20 21:47:38 - train.py[line:549] - INFO: 6000 / 6234
2023-02-20 21:47:38 - train.py[line:551] - INFO: load:1.77 valid_run:3641.87 task_valid:3500.30 collect_output:111.29
2023-02-20 21:49:40 - train.py[line:549] - INFO: 6200 / 6234
2023-02-20 21:49:40 - train.py[line:551] - INFO: load:1.79 valid_run:3763.20 task_valid:3619.16 collect_output:112.73

====================================================================================================
SGG eval:     R @ 50: 0.6536;     R @ 100: 0.6936;     R @ 500: 0.7130;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4099;    mR @ 100: 0.4833;    mR @ 500: 0.5366;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.5625) (covering:0.4429) (eating:0.8235) (flying in:0.5000) (growing on:0.3750) (hanging from:0.5645) (lying on:0.1167) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9696) (says:0.5000) (sitting on:0.7653) (standing on:0.3677) (using:0.6000) (walking in:0.0000) (walking on:0.7297) (watching:0.5139) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6536;     R @ 100: 0.6936;     R @ 500: 0.7130;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4099;    mR @ 100: 0.4833;    mR @ 500: 0.5366;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.5625) (covering:0.4429) (eating:0.8235) (flying in:0.5000) (growing on:0.3750) (hanging from:0.5645) (lying on:0.1167) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9696) (says:0.5000) (sitting on:0.7653) (standing on:0.3677) (using:0.6000) (walking in:0.0000) (walking on:0.7297) (watching:0.5139) 
--------------------------------------------------------
====================================================================================================

2023-02-20 21:50:11 - train.py[line:487] - INFO: 0.6935957983193277
2023-02-20 21:50:11 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-20 21:50:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.22 | loss_v1 0 | loss_v2 0 | nll_loss 0.048 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.693596 | ppl 1.03 | vqa_score 0.3074 | wps 118.2 | wpb 72 | bsz 24 | num_updates 10000 | best_R@100 0.693596
2023-02-20 21:50:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 10000 updates
2023-02-20 21:50:11 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_10000.pt
2023-02-20 21:50:17 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_10000.pt
2023-02-20 21:50:22 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 0.6935957983193277) (writing took 11.626720894128084 seconds)
2023-02-20 21:50:34 - progress_bar.py[line:274] - INFO: epoch 001:  10020 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=0.3, ups=0, wpb=109.3, bsz=40, num_updates=10010, lr=4.77654e-05, gnorm=0.114, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30286
2023-02-20 21:50:45 - progress_bar.py[line:274] - INFO: epoch 001:  10030 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.8, bsz=40, num_updates=10020, lr=4.77618e-05, gnorm=0.089, clip=0, loss_scale=8192, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=30298
2023-02-20 21:50:56 - progress_bar.py[line:274] - INFO: epoch 001:  10040 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.5, bsz=40, num_updates=10030, lr=4.77581e-05, gnorm=0.095, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30309
2023-02-20 21:51:07 - progress_bar.py[line:274] - INFO: epoch 001:  10050 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=10040, lr=4.77545e-05, gnorm=0.089, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30320
2023-02-20 21:51:18 - progress_bar.py[line:274] - INFO: epoch 001:  10060 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.6, bsz=40, num_updates=10050, lr=4.77509e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30331
2023-02-20 21:51:29 - progress_bar.py[line:274] - INFO: epoch 001:  10070 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=10060, lr=4.77473e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30342
2023-02-20 21:51:41 - progress_bar.py[line:274] - INFO: epoch 001:  10080 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=10070, lr=4.77437e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30353
2023-02-20 21:51:52 - progress_bar.py[line:274] - INFO: epoch 001:  10090 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.1, bsz=40, num_updates=10080, lr=4.77401e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30365
2023-02-20 21:52:03 - progress_bar.py[line:274] - INFO: epoch 001:  10100 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=110.9, bsz=40, num_updates=10090, lr=4.77364e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30376
2023-02-20 21:52:14 - progress_bar.py[line:274] - INFO: epoch 001:  10110 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.9, bsz=40, num_updates=10100, lr=4.77328e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=30387
2023-02-20 21:52:25 - progress_bar.py[line:274] - INFO: epoch 001:  10120 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=111.7, bsz=40, num_updates=10110, lr=4.77292e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30398
2023-02-20 21:52:37 - progress_bar.py[line:274] - INFO: epoch 001:  10130 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.9, wpb=109.9, bsz=40, num_updates=10120, lr=4.77256e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30409
2023-02-20 21:52:48 - progress_bar.py[line:274] - INFO: epoch 001:  10140 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.9, bsz=40, num_updates=10130, lr=4.7722e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10, ema_decay=0.9999, wall=30421
2023-02-20 21:52:58 - progress_bar.py[line:274] - INFO: epoch 001:  10150 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.93, wpb=111.9, bsz=40, num_updates=10140, lr=4.77183e-05, gnorm=0.088, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30431
2023-02-20 21:53:10 - progress_bar.py[line:274] - INFO: epoch 001:  10160 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.8, bsz=40, num_updates=10150, lr=4.77147e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30443
2023-02-20 21:53:21 - progress_bar.py[line:274] - INFO: epoch 001:  10170 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.5, bsz=40, num_updates=10160, lr=4.77111e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30454
2023-02-20 21:53:32 - progress_bar.py[line:274] - INFO: epoch 001:  10180 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=111.1, bsz=40, num_updates=10170, lr=4.77075e-05, gnorm=0.085, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30465
2023-02-20 21:53:43 - progress_bar.py[line:274] - INFO: epoch 001:  10190 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.2, bsz=40, num_updates=10180, lr=4.77039e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=30476
2023-02-20 21:53:54 - progress_bar.py[line:274] - INFO: epoch 001:  10200 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=10190, lr=4.77003e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30487
2023-02-20 21:54:05 - progress_bar.py[line:274] - INFO: epoch 001:  10210 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.9, ups=0.95, wpb=111.8, bsz=40, num_updates=10200, lr=4.76966e-05, gnorm=0.1, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30497
2023-02-20 21:54:16 - progress_bar.py[line:274] - INFO: epoch 001:  10220 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.88, wpb=111.1, bsz=40, num_updates=10210, lr=4.7693e-05, gnorm=0.101, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30509
2023-02-20 21:54:27 - progress_bar.py[line:274] - INFO: epoch 001:  10230 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=110, bsz=40, num_updates=10220, lr=4.76894e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30520
2023-02-20 21:54:38 - progress_bar.py[line:274] - INFO: epoch 001:  10240 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=10230, lr=4.76858e-05, gnorm=0.103, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30531
2023-02-20 21:54:49 - progress_bar.py[line:274] - INFO: epoch 001:  10250 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.7, bsz=40, num_updates=10240, lr=4.76822e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30542
2023-02-20 21:55:00 - progress_bar.py[line:274] - INFO: epoch 001:  10260 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=10250, lr=4.76785e-05, gnorm=0.083, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30553
2023-02-20 21:55:11 - progress_bar.py[line:274] - INFO: epoch 001:  10270 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112.1, bsz=40, num_updates=10260, lr=4.76749e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30564
2023-02-20 21:55:23 - progress_bar.py[line:274] - INFO: epoch 001:  10280 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111, bsz=40, num_updates=10270, lr=4.76713e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30575
2023-02-20 21:55:34 - progress_bar.py[line:274] - INFO: epoch 001:  10290 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=10280, lr=4.76677e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30587
2023-02-20 21:55:45 - progress_bar.py[line:274] - INFO: epoch 001:  10300 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.3, bsz=40, num_updates=10290, lr=4.76641e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30598
2023-02-20 21:55:56 - progress_bar.py[line:274] - INFO: epoch 001:  10310 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.3, bsz=40, num_updates=10300, lr=4.76605e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30609
2023-02-20 21:56:07 - progress_bar.py[line:274] - INFO: epoch 001:  10320 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.92, wpb=111.8, bsz=40, num_updates=10310, lr=4.76568e-05, gnorm=0.106, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30620
2023-02-20 21:56:18 - progress_bar.py[line:274] - INFO: epoch 001:  10330 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.4, bsz=40, num_updates=10320, lr=4.76532e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30630
2023-02-20 21:56:29 - progress_bar.py[line:274] - INFO: epoch 001:  10340 / 142023 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.91, wpb=109.3, bsz=40, num_updates=10330, lr=4.76496e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30641
2023-02-20 21:56:40 - progress_bar.py[line:274] - INFO: epoch 001:  10350 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.5, bsz=40, num_updates=10340, lr=4.7646e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30653
2023-02-20 21:56:51 - progress_bar.py[line:274] - INFO: epoch 001:  10360 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=10350, lr=4.76424e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30664
2023-02-20 21:57:02 - progress_bar.py[line:274] - INFO: epoch 001:  10370 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=10360, lr=4.76387e-05, gnorm=0.086, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30675
2023-02-20 21:57:13 - progress_bar.py[line:274] - INFO: epoch 001:  10380 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=10370, lr=4.76351e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=30686
2023-02-20 21:57:24 - progress_bar.py[line:274] - INFO: epoch 001:  10390 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=10380, lr=4.76315e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30697
2023-02-20 21:57:36 - progress_bar.py[line:274] - INFO: epoch 001:  10400 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.89, wpb=110.4, bsz=40, num_updates=10390, lr=4.76279e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30708
2023-02-20 21:57:47 - progress_bar.py[line:274] - INFO: epoch 001:  10410 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.8, bsz=40, num_updates=10400, lr=4.76243e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30719
2023-02-20 21:57:58 - progress_bar.py[line:274] - INFO: epoch 001:  10420 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.8, bsz=40, num_updates=10410, lr=4.76206e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30730
2023-02-20 21:58:09 - progress_bar.py[line:274] - INFO: epoch 001:  10430 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111.1, bsz=40, num_updates=10420, lr=4.7617e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30742
2023-02-20 21:58:20 - progress_bar.py[line:274] - INFO: epoch 001:  10440 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=10430, lr=4.76134e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30753
2023-02-20 21:58:31 - progress_bar.py[line:274] - INFO: epoch 001:  10450 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112.4, bsz=40, num_updates=10440, lr=4.76098e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30764
2023-02-20 21:58:43 - progress_bar.py[line:274] - INFO: epoch 001:  10460 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=10450, lr=4.76062e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30776
2023-02-20 21:58:53 - progress_bar.py[line:274] - INFO: epoch 001:  10470 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.3, ups=0.94, wpb=111.5, bsz=40, num_updates=10460, lr=4.76026e-05, gnorm=0.088, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=30786
2023-02-20 21:59:01 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8192.0
2023-02-20 21:59:05 - progress_bar.py[line:274] - INFO: epoch 001:  10481 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.2, ups=0.84, wpb=110.4, bsz=40, num_updates=10470, lr=4.75989e-05, gnorm=0.076, clip=0, loss_scale=8192, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=30798
2023-02-20 21:59:17 - progress_bar.py[line:274] - INFO: epoch 001:  10491 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.88, wpb=109.8, bsz=40, num_updates=10480, lr=4.75953e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30809
2023-02-20 21:59:28 - progress_bar.py[line:274] - INFO: epoch 001:  10501 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.2, bsz=40, num_updates=10490, lr=4.75917e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30821
2023-02-20 21:59:39 - progress_bar.py[line:274] - INFO: epoch 001:  10511 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=10500, lr=4.75881e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30832
2023-02-20 21:59:50 - progress_bar.py[line:274] - INFO: epoch 001:  10521 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=10510, lr=4.75845e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10, ema_decay=0.9999, wall=30843
2023-02-20 22:00:02 - progress_bar.py[line:274] - INFO: epoch 001:  10531 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.6, bsz=40, num_updates=10520, lr=4.75808e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30855
2023-02-20 22:00:13 - progress_bar.py[line:274] - INFO: epoch 001:  10541 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.2, bsz=40, num_updates=10530, lr=4.75772e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30866
2023-02-20 22:00:24 - progress_bar.py[line:274] - INFO: epoch 001:  10551 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.1, ups=0.91, wpb=111.6, bsz=40, num_updates=10540, lr=4.75736e-05, gnorm=0.1, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30877
2023-02-20 22:00:35 - progress_bar.py[line:274] - INFO: epoch 001:  10561 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110.1, bsz=40, num_updates=10550, lr=4.757e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30888
2023-02-20 22:00:47 - progress_bar.py[line:274] - INFO: epoch 001:  10571 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.2, bsz=40, num_updates=10560, lr=4.75664e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30900
2023-02-20 22:00:58 - progress_bar.py[line:274] - INFO: epoch 001:  10581 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=10570, lr=4.75628e-05, gnorm=0.11, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30911
2023-02-20 22:01:09 - progress_bar.py[line:274] - INFO: epoch 001:  10591 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.9, bsz=40, num_updates=10580, lr=4.75591e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30922
2023-02-20 22:01:18 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-20 22:01:21 - progress_bar.py[line:274] - INFO: epoch 001:  10602 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.7, ups=0.81, wpb=111.3, bsz=40, num_updates=10590, lr=4.75555e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=30934
2023-02-20 22:01:33 - progress_bar.py[line:274] - INFO: epoch 001:  10612 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.3, bsz=40, num_updates=10600, lr=4.75519e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30946
2023-02-20 22:01:44 - progress_bar.py[line:274] - INFO: epoch 001:  10622 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.7, bsz=40, num_updates=10610, lr=4.75483e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30957
2023-02-20 22:01:55 - progress_bar.py[line:274] - INFO: epoch 001:  10632 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=10620, lr=4.75447e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30968
2023-02-20 22:02:06 - progress_bar.py[line:274] - INFO: epoch 001:  10642 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.7, bsz=40, num_updates=10630, lr=4.7541e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30979
2023-02-20 22:02:17 - progress_bar.py[line:274] - INFO: epoch 001:  10652 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.5, bsz=40, num_updates=10640, lr=4.75374e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30990
2023-02-20 22:02:28 - progress_bar.py[line:274] - INFO: epoch 001:  10662 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=10650, lr=4.75338e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31001
2023-02-20 22:02:40 - progress_bar.py[line:274] - INFO: epoch 001:  10672 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=10660, lr=4.75302e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31013
2023-02-20 22:02:51 - progress_bar.py[line:274] - INFO: epoch 001:  10682 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.2, ups=0.93, wpb=112.1, bsz=40, num_updates=10670, lr=4.75266e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31023
2023-02-20 22:03:02 - progress_bar.py[line:274] - INFO: epoch 001:  10692 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.93, wpb=110, bsz=40, num_updates=10680, lr=4.7523e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31034
2023-02-20 22:03:13 - progress_bar.py[line:274] - INFO: epoch 001:  10702 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=10690, lr=4.75193e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31046
2023-02-20 22:03:24 - progress_bar.py[line:274] - INFO: epoch 001:  10712 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.6, bsz=40, num_updates=10700, lr=4.75157e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=31057
2023-02-20 22:03:35 - progress_bar.py[line:274] - INFO: epoch 001:  10722 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.4, bsz=40, num_updates=10710, lr=4.75121e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31068
2023-02-20 22:03:47 - progress_bar.py[line:274] - INFO: epoch 001:  10732 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.91, wpb=109.4, bsz=40, num_updates=10720, lr=4.75085e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31079
2023-02-20 22:03:58 - progress_bar.py[line:274] - INFO: epoch 001:  10742 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.6, bsz=40, num_updates=10730, lr=4.75049e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31090
2023-02-20 22:04:09 - progress_bar.py[line:274] - INFO: epoch 001:  10752 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.87, wpb=113.1, bsz=40, num_updates=10740, lr=4.75012e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=31102
2023-02-20 22:04:20 - progress_bar.py[line:274] - INFO: epoch 001:  10762 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.7, bsz=40, num_updates=10750, lr=4.74976e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31113
2023-02-20 22:04:32 - progress_bar.py[line:274] - INFO: epoch 001:  10772 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.8, ups=0.87, wpb=110.2, bsz=40, num_updates=10760, lr=4.7494e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=31124
2023-02-20 22:04:43 - progress_bar.py[line:274] - INFO: epoch 001:  10782 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.91, wpb=109.9, bsz=40, num_updates=10770, lr=4.74904e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31136
2023-02-20 22:04:54 - progress_bar.py[line:274] - INFO: epoch 001:  10792 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.8, bsz=40, num_updates=10780, lr=4.74868e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31147
2023-02-20 22:05:05 - progress_bar.py[line:274] - INFO: epoch 001:  10802 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.4, bsz=40, num_updates=10790, lr=4.74832e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31158
2023-02-20 22:05:16 - progress_bar.py[line:274] - INFO: epoch 001:  10812 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.88, wpb=110.1, bsz=40, num_updates=10800, lr=4.74795e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31169
2023-02-20 22:05:27 - progress_bar.py[line:274] - INFO: epoch 001:  10822 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.3, bsz=40, num_updates=10810, lr=4.74759e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31180
2023-02-20 22:05:39 - progress_bar.py[line:274] - INFO: epoch 001:  10832 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.87, wpb=111.9, bsz=40, num_updates=10820, lr=4.74723e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31192
2023-02-20 22:05:50 - progress_bar.py[line:274] - INFO: epoch 001:  10842 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.5, bsz=40, num_updates=10830, lr=4.74687e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31203
2023-02-20 22:06:01 - progress_bar.py[line:274] - INFO: epoch 001:  10852 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=10840, lr=4.74651e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31214
2023-02-20 22:06:12 - progress_bar.py[line:274] - INFO: epoch 001:  10862 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.5, bsz=40, num_updates=10850, lr=4.74614e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31225
2023-02-20 22:06:24 - progress_bar.py[line:274] - INFO: epoch 001:  10872 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.87, wpb=110.2, bsz=40, num_updates=10860, lr=4.74578e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31237
2023-02-20 22:06:35 - progress_bar.py[line:274] - INFO: epoch 001:  10882 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=10870, lr=4.74542e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31248
2023-02-20 22:06:46 - progress_bar.py[line:274] - INFO: epoch 001:  10892 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.89, wpb=109.3, bsz=40, num_updates=10880, lr=4.74506e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31259
2023-02-20 22:06:57 - progress_bar.py[line:274] - INFO: epoch 001:  10902 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.9, ups=0.94, wpb=111.2, bsz=40, num_updates=10890, lr=4.7447e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31270
2023-02-20 22:07:08 - progress_bar.py[line:274] - INFO: epoch 001:  10912 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.5, bsz=40, num_updates=10900, lr=4.74434e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31281
2023-02-20 22:07:19 - progress_bar.py[line:274] - INFO: epoch 001:  10922 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=10910, lr=4.74397e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31292
2023-02-20 22:07:31 - progress_bar.py[line:274] - INFO: epoch 001:  10932 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=10920, lr=4.74361e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31303
2023-02-20 22:07:42 - progress_bar.py[line:274] - INFO: epoch 001:  10942 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.5, bsz=40, num_updates=10930, lr=4.74325e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31314
2023-02-20 22:07:53 - progress_bar.py[line:274] - INFO: epoch 001:  10952 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.88, wpb=109.3, bsz=40, num_updates=10940, lr=4.74289e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31326
2023-02-20 22:08:04 - progress_bar.py[line:274] - INFO: epoch 001:  10962 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.2, bsz=40, num_updates=10950, lr=4.74253e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=31337
2023-02-20 22:08:16 - progress_bar.py[line:274] - INFO: epoch 001:  10972 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=110.4, bsz=40, num_updates=10960, lr=4.74216e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31348
2023-02-20 22:08:27 - progress_bar.py[line:274] - INFO: epoch 001:  10982 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=10970, lr=4.7418e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31360
2023-02-20 22:08:38 - progress_bar.py[line:274] - INFO: epoch 001:  10992 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.88, wpb=109.3, bsz=40, num_updates=10980, lr=4.74144e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31371
2023-02-20 22:08:49 - progress_bar.py[line:274] - INFO: epoch 001:  11002 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=10990, lr=4.74108e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31382
2023-02-20 22:09:01 - progress_bar.py[line:274] - INFO: epoch 001:  11012 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112.1, bsz=40, num_updates=11000, lr=4.74072e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31394
2023-02-20 22:09:12 - progress_bar.py[line:274] - INFO: epoch 001:  11022 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.6, bsz=40, num_updates=11010, lr=4.74036e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31405
2023-02-20 22:09:23 - progress_bar.py[line:274] - INFO: epoch 001:  11032 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=11020, lr=4.73999e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31416
2023-02-20 22:09:34 - progress_bar.py[line:274] - INFO: epoch 001:  11042 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=11030, lr=4.73963e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31427
2023-02-20 22:09:45 - progress_bar.py[line:274] - INFO: epoch 001:  11052 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=11040, lr=4.73927e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31438
2023-02-20 22:09:57 - progress_bar.py[line:274] - INFO: epoch 001:  11062 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112, bsz=40, num_updates=11050, lr=4.73891e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31450
2023-02-20 22:10:08 - progress_bar.py[line:274] - INFO: epoch 001:  11072 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=111.8, bsz=40, num_updates=11060, lr=4.73855e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31461
2023-02-20 22:10:19 - progress_bar.py[line:274] - INFO: epoch 001:  11082 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.89, wpb=111.4, bsz=40, num_updates=11070, lr=4.73818e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=31472
2023-02-20 22:10:31 - progress_bar.py[line:274] - INFO: epoch 001:  11092 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.86, wpb=111.8, bsz=40, num_updates=11080, lr=4.73782e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=31484
2023-02-20 22:10:42 - progress_bar.py[line:274] - INFO: epoch 001:  11102 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=11090, lr=4.73746e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31495
2023-02-20 22:10:53 - progress_bar.py[line:274] - INFO: epoch 001:  11112 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.4, bsz=40, num_updates=11100, lr=4.7371e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31506
2023-02-20 22:11:04 - progress_bar.py[line:274] - INFO: epoch 001:  11122 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=103.9, ups=0.92, wpb=113.1, bsz=40, num_updates=11110, lr=4.73674e-05, gnorm=0.076, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31517
2023-02-20 22:11:15 - progress_bar.py[line:274] - INFO: epoch 001:  11132 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=11120, lr=4.73638e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31528
2023-02-20 22:11:26 - progress_bar.py[line:274] - INFO: epoch 001:  11142 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.1, bsz=40, num_updates=11130, lr=4.73601e-05, gnorm=0.095, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31539
2023-02-20 22:11:37 - progress_bar.py[line:274] - INFO: epoch 001:  11152 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=11140, lr=4.73565e-05, gnorm=0.077, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31550
2023-02-20 22:11:48 - progress_bar.py[line:274] - INFO: epoch 001:  11162 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110, bsz=40, num_updates=11150, lr=4.73529e-05, gnorm=0.087, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31561
2023-02-20 22:12:00 - progress_bar.py[line:274] - INFO: epoch 001:  11172 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=11160, lr=4.73493e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31573
2023-02-20 22:12:11 - progress_bar.py[line:274] - INFO: epoch 001:  11182 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=110.4, bsz=40, num_updates=11170, lr=4.73457e-05, gnorm=0.107, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31584
2023-02-20 22:12:22 - progress_bar.py[line:274] - INFO: epoch 001:  11192 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.7, bsz=40, num_updates=11180, lr=4.7342e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31594
2023-02-20 22:12:30 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-20 22:12:34 - progress_bar.py[line:274] - INFO: epoch 001:  11203 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.7, ups=0.84, wpb=110.6, bsz=40, num_updates=11190, lr=4.73384e-05, gnorm=0.109, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=31606
2023-02-20 22:12:45 - progress_bar.py[line:274] - INFO: epoch 001:  11213 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.88, wpb=109, bsz=40, num_updates=11200, lr=4.73348e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31618
2023-02-20 22:12:56 - progress_bar.py[line:274] - INFO: epoch 001:  11223 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=11210, lr=4.73312e-05, gnorm=0.101, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31629
2023-02-20 22:13:07 - progress_bar.py[line:274] - INFO: epoch 001:  11233 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=11220, lr=4.73276e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31640
2023-02-20 22:13:18 - progress_bar.py[line:274] - INFO: epoch 001:  11243 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.5, bsz=40, num_updates=11230, lr=4.7324e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31651
2023-02-20 22:13:29 - progress_bar.py[line:274] - INFO: epoch 001:  11253 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=110.5, bsz=40, num_updates=11240, lr=4.73203e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31662
2023-02-20 22:13:40 - progress_bar.py[line:274] - INFO: epoch 001:  11263 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.2, bsz=40, num_updates=11250, lr=4.73167e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31673
2023-02-20 22:13:51 - progress_bar.py[line:274] - INFO: epoch 001:  11273 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.8, ups=0.93, wpb=111.6, bsz=40, num_updates=11260, lr=4.73131e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31684
2023-02-20 22:14:02 - progress_bar.py[line:274] - INFO: epoch 001:  11283 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.92, wpb=109.4, bsz=40, num_updates=11270, lr=4.73095e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=31695
2023-02-20 22:14:13 - progress_bar.py[line:274] - INFO: epoch 001:  11293 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.4, bsz=40, num_updates=11280, lr=4.73059e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31706
2023-02-20 22:14:25 - progress_bar.py[line:274] - INFO: epoch 001:  11303 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111.4, bsz=40, num_updates=11290, lr=4.73022e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=31718
2023-02-20 22:14:36 - progress_bar.py[line:274] - INFO: epoch 001:  11313 / 142023 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.88, wpb=109.6, bsz=40, num_updates=11300, lr=4.72986e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=31729
2023-02-20 22:14:47 - progress_bar.py[line:274] - INFO: epoch 001:  11323 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=11310, lr=4.7295e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31740
2023-02-20 22:14:59 - progress_bar.py[line:274] - INFO: epoch 001:  11333 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=110.8, bsz=40, num_updates=11320, lr=4.72914e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31752
2023-02-20 22:15:10 - progress_bar.py[line:274] - INFO: epoch 001:  11343 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111.2, bsz=40, num_updates=11330, lr=4.72878e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31763
2023-02-20 22:15:21 - progress_bar.py[line:274] - INFO: epoch 001:  11353 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.5, bsz=40, num_updates=11340, lr=4.72842e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31774
2023-02-20 22:15:32 - progress_bar.py[line:274] - INFO: epoch 001:  11363 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.7, bsz=40, num_updates=11350, lr=4.72805e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31785
2023-02-20 22:15:43 - progress_bar.py[line:274] - INFO: epoch 001:  11373 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=11360, lr=4.72769e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31796
2023-02-20 22:15:54 - progress_bar.py[line:274] - INFO: epoch 001:  11383 / 142023 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=110, bsz=40, num_updates=11370, lr=4.72733e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31807
2023-02-20 22:16:06 - progress_bar.py[line:274] - INFO: epoch 001:  11393 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=11380, lr=4.72697e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31818
2023-02-20 22:16:17 - progress_bar.py[line:274] - INFO: epoch 001:  11403 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=11390, lr=4.72661e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31829
2023-02-20 22:16:28 - progress_bar.py[line:274] - INFO: epoch 001:  11413 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=11400, lr=4.72624e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31841
2023-02-20 22:16:39 - progress_bar.py[line:274] - INFO: epoch 001:  11423 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112.4, bsz=40, num_updates=11410, lr=4.72588e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31852
2023-02-20 22:16:50 - progress_bar.py[line:274] - INFO: epoch 001:  11433 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112.3, bsz=40, num_updates=11420, lr=4.72552e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31863
2023-02-20 22:17:01 - progress_bar.py[line:274] - INFO: epoch 001:  11443 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.8, bsz=40, num_updates=11430, lr=4.72516e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31874
2023-02-20 22:17:13 - progress_bar.py[line:274] - INFO: epoch 001:  11453 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.88, wpb=112.2, bsz=40, num_updates=11440, lr=4.7248e-05, gnorm=0.116, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31885
2023-02-20 22:17:24 - progress_bar.py[line:274] - INFO: epoch 001:  11463 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.2, bsz=40, num_updates=11450, lr=4.72444e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31896
2023-02-20 22:17:35 - progress_bar.py[line:274] - INFO: epoch 001:  11473 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=11460, lr=4.72407e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31908
2023-02-20 22:17:46 - progress_bar.py[line:274] - INFO: epoch 001:  11483 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.88, wpb=111.1, bsz=40, num_updates=11470, lr=4.72371e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31919
2023-02-20 22:17:58 - progress_bar.py[line:274] - INFO: epoch 001:  11493 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.87, wpb=110.2, bsz=40, num_updates=11480, lr=4.72335e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31930
2023-02-20 22:18:09 - progress_bar.py[line:274] - INFO: epoch 001:  11503 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=11490, lr=4.72299e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31942
2023-02-20 22:18:20 - progress_bar.py[line:274] - INFO: epoch 001:  11513 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.6, bsz=40, num_updates=11500, lr=4.72263e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31953
2023-02-20 22:18:31 - progress_bar.py[line:274] - INFO: epoch 001:  11523 / 142023 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=11510, lr=4.72226e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31964
2023-02-20 22:18:42 - progress_bar.py[line:274] - INFO: epoch 001:  11533 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111, bsz=40, num_updates=11520, lr=4.7219e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31975
2023-02-20 22:18:53 - progress_bar.py[line:274] - INFO: epoch 001:  11543 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.1, bsz=40, num_updates=11530, lr=4.72154e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31986
2023-02-20 22:19:04 - progress_bar.py[line:274] - INFO: epoch 001:  11553 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.6, bsz=40, num_updates=11540, lr=4.72118e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31997
2023-02-20 22:19:15 - progress_bar.py[line:274] - INFO: epoch 001:  11563 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=11550, lr=4.72082e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32008
2023-02-20 22:19:26 - progress_bar.py[line:274] - INFO: epoch 001:  11573 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.3, bsz=40, num_updates=11560, lr=4.72046e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32019
2023-02-20 22:19:38 - progress_bar.py[line:274] - INFO: epoch 001:  11583 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.7, bsz=40, num_updates=11570, lr=4.72009e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32030
2023-02-20 22:19:49 - progress_bar.py[line:274] - INFO: epoch 001:  11593 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=111.8, bsz=40, num_updates=11580, lr=4.71973e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32042
2023-02-20 22:20:00 - progress_bar.py[line:274] - INFO: epoch 001:  11603 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=11590, lr=4.71937e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32053
2023-02-20 22:20:11 - progress_bar.py[line:274] - INFO: epoch 001:  11613 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.89, wpb=112.2, bsz=40, num_updates=11600, lr=4.71901e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=32064
2023-02-20 22:20:22 - progress_bar.py[line:274] - INFO: epoch 001:  11623 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=113, bsz=40, num_updates=11610, lr=4.71865e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32075
2023-02-20 22:20:33 - progress_bar.py[line:274] - INFO: epoch 001:  11633 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112.5, bsz=40, num_updates=11620, lr=4.71828e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32086
2023-02-20 22:20:45 - progress_bar.py[line:274] - INFO: epoch 001:  11643 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.8, bsz=40, num_updates=11630, lr=4.71792e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32098
2023-02-20 22:20:56 - progress_bar.py[line:274] - INFO: epoch 001:  11653 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.87, wpb=112.8, bsz=40, num_updates=11640, lr=4.71756e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32109
2023-02-20 22:21:07 - progress_bar.py[line:274] - INFO: epoch 001:  11663 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=11650, lr=4.7172e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32120
2023-02-20 22:21:18 - progress_bar.py[line:274] - INFO: epoch 001:  11673 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.6, bsz=40, num_updates=11660, lr=4.71684e-05, gnorm=0.126, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32131
2023-02-20 22:21:29 - progress_bar.py[line:274] - INFO: epoch 001:  11683 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.88, wpb=111.1, bsz=40, num_updates=11670, lr=4.71648e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32142
2023-02-20 22:21:41 - progress_bar.py[line:274] - INFO: epoch 001:  11693 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.6, bsz=40, num_updates=11680, lr=4.71611e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32154
2023-02-20 22:21:52 - progress_bar.py[line:274] - INFO: epoch 001:  11703 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.3, bsz=40, num_updates=11690, lr=4.71575e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=32165
2023-02-20 22:22:03 - progress_bar.py[line:274] - INFO: epoch 001:  11713 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=101.2, ups=0.92, wpb=110.2, bsz=40, num_updates=11700, lr=4.71539e-05, gnorm=0.038, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32176
2023-02-20 22:22:14 - progress_bar.py[line:274] - INFO: epoch 001:  11723 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=113.1, bsz=40, num_updates=11710, lr=4.71503e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32187
2023-02-20 22:22:25 - progress_bar.py[line:274] - INFO: epoch 001:  11733 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.89, wpb=110.3, bsz=40, num_updates=11720, lr=4.71467e-05, gnorm=0.09, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32198
2023-02-20 22:22:36 - progress_bar.py[line:274] - INFO: epoch 001:  11743 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.9, wpb=111.1, bsz=40, num_updates=11730, lr=4.7143e-05, gnorm=0.106, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=32209
2023-02-20 22:22:48 - progress_bar.py[line:274] - INFO: epoch 001:  11753 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.9, wpb=109.4, bsz=40, num_updates=11740, lr=4.71394e-05, gnorm=0.089, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32220
2023-02-20 22:22:59 - progress_bar.py[line:274] - INFO: epoch 001:  11763 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.6, bsz=40, num_updates=11750, lr=4.71358e-05, gnorm=0.087, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32232
2023-02-20 22:23:10 - progress_bar.py[line:274] - INFO: epoch 001:  11773 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.2, ups=0.89, wpb=113.2, bsz=40, num_updates=11760, lr=4.71322e-05, gnorm=0.083, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32243
2023-02-20 22:23:21 - progress_bar.py[line:274] - INFO: epoch 001:  11783 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.89, wpb=112.6, bsz=40, num_updates=11770, lr=4.71286e-05, gnorm=0.083, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32254
2023-02-20 22:23:32 - progress_bar.py[line:274] - INFO: epoch 001:  11793 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.9, wpb=109.6, bsz=40, num_updates=11780, lr=4.7125e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32265
2023-02-20 22:23:44 - progress_bar.py[line:274] - INFO: epoch 001:  11803 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.7, bsz=40, num_updates=11790, lr=4.71213e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=32276
2023-02-20 22:23:55 - progress_bar.py[line:274] - INFO: epoch 001:  11813 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.6, bsz=40, num_updates=11800, lr=4.71177e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32288
2023-02-20 22:24:06 - progress_bar.py[line:274] - INFO: epoch 001:  11823 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.5, bsz=40, num_updates=11810, lr=4.71141e-05, gnorm=0.087, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32299
2023-02-20 22:24:17 - progress_bar.py[line:274] - INFO: epoch 001:  11833 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.2, bsz=40, num_updates=11820, lr=4.71105e-05, gnorm=0.104, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32310
2023-02-20 22:24:29 - progress_bar.py[line:274] - INFO: epoch 001:  11843 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.1, bsz=40, num_updates=11830, lr=4.71069e-05, gnorm=0.091, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=32322
2023-02-20 22:24:40 - progress_bar.py[line:274] - INFO: epoch 001:  11853 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.9, bsz=40, num_updates=11840, lr=4.71032e-05, gnorm=0.089, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32333
2023-02-20 22:24:51 - progress_bar.py[line:274] - INFO: epoch 001:  11863 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.94, wpb=110.2, bsz=40, num_updates=11850, lr=4.70996e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=32343
2023-02-20 22:25:02 - progress_bar.py[line:274] - INFO: epoch 001:  11873 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.9, wpb=110.3, bsz=40, num_updates=11860, lr=4.7096e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32355
2023-02-20 22:25:13 - progress_bar.py[line:274] - INFO: epoch 001:  11883 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.9, bsz=40, num_updates=11870, lr=4.70924e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=32366
2023-02-20 22:25:24 - progress_bar.py[line:274] - INFO: epoch 001:  11893 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=11880, lr=4.70888e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=32377
2023-02-20 22:25:36 - progress_bar.py[line:274] - INFO: epoch 001:  11903 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=11890, lr=4.70852e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32388
2023-02-20 22:25:47 - progress_bar.py[line:274] - INFO: epoch 001:  11913 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.4, bsz=40, num_updates=11900, lr=4.70815e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32400
2023-02-20 22:25:58 - progress_bar.py[line:274] - INFO: epoch 001:  11923 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.8, bsz=40, num_updates=11910, lr=4.70779e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=32411
2023-02-20 22:26:09 - progress_bar.py[line:274] - INFO: epoch 001:  11933 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.91, wpb=109.3, bsz=40, num_updates=11920, lr=4.70743e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32422
2023-02-20 22:26:20 - progress_bar.py[line:274] - INFO: epoch 001:  11943 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.93, wpb=110.3, bsz=40, num_updates=11930, lr=4.70707e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32432
2023-02-20 22:26:31 - progress_bar.py[line:274] - INFO: epoch 001:  11953 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.4, bsz=40, num_updates=11940, lr=4.70671e-05, gnorm=0.093, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32443
2023-02-20 22:26:42 - progress_bar.py[line:274] - INFO: epoch 001:  11963 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.4, bsz=40, num_updates=11950, lr=4.70634e-05, gnorm=0.097, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32455
2023-02-20 22:26:53 - progress_bar.py[line:274] - INFO: epoch 001:  11973 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.2, bsz=40, num_updates=11960, lr=4.70598e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32466
2023-02-20 22:27:04 - progress_bar.py[line:274] - INFO: epoch 001:  11983 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.87, wpb=112.8, bsz=40, num_updates=11970, lr=4.70562e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32477
2023-02-20 22:27:15 - progress_bar.py[line:274] - INFO: epoch 001:  11993 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.1, bsz=40, num_updates=11980, lr=4.70526e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32488
2023-02-20 22:27:26 - progress_bar.py[line:274] - INFO: epoch 001:  12003 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.1, ups=0.94, wpb=112.4, bsz=40, num_updates=11990, lr=4.7049e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32499
2023-02-20 22:27:37 - progress_bar.py[line:274] - INFO: epoch 001:  12013 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=12000, lr=4.70454e-05, gnorm=0.097, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32510
2023-02-20 22:27:37 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-20 22:27:38 - train.py[line:549] - INFO: 0 / 6234
2023-02-20 22:27:38 - train.py[line:551] - INFO: load:0.99 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-20 22:29:41 - train.py[line:549] - INFO: 200 / 6234
2023-02-20 22:29:41 - train.py[line:551] - INFO: load:1.02 valid_run:122.38 task_valid:119.41 collect_output:1.92
2023-02-20 22:31:41 - train.py[line:549] - INFO: 400 / 6234
2023-02-20 22:31:41 - train.py[line:551] - INFO: load:1.04 valid_run:242.46 task_valid:235.40 collect_output:5.01
2023-02-20 22:33:43 - train.py[line:549] - INFO: 600 / 6234
2023-02-20 22:33:43 - train.py[line:551] - INFO: load:1.06 valid_run:364.52 task_valid:352.27 collect_output:9.20
2023-02-20 22:35:45 - train.py[line:549] - INFO: 800 / 6234
2023-02-20 22:35:45 - train.py[line:551] - INFO: load:1.08 valid_run:486.71 task_valid:466.26 collect_output:16.37
2023-02-20 22:37:46 - train.py[line:549] - INFO: 1000 / 6234
2023-02-20 22:37:46 - train.py[line:551] - INFO: load:1.11 valid_run:607.43 task_valid:583.90 collect_output:18.42
2023-02-20 22:39:49 - train.py[line:549] - INFO: 1200 / 6234
2023-02-20 22:39:49 - train.py[line:551] - INFO: load:1.13 valid_run:730.50 task_valid:702.78 collect_output:21.59
2023-02-20 22:41:52 - train.py[line:549] - INFO: 1400 / 6234
2023-02-20 22:41:52 - train.py[line:551] - INFO: load:1.15 valid_run:853.63 task_valid:821.17 collect_output:25.34
2023-02-20 22:43:55 - train.py[line:549] - INFO: 1600 / 6234
2023-02-20 22:43:55 - train.py[line:551] - INFO: load:1.18 valid_run:975.91 task_valid:938.31 collect_output:29.47
2023-02-20 22:45:58 - train.py[line:549] - INFO: 1800 / 6234
2023-02-20 22:45:58 - train.py[line:551] - INFO: load:1.20 valid_run:1099.69 task_valid:1055.90 collect_output:34.64
2023-02-20 22:48:00 - train.py[line:549] - INFO: 2000 / 6234
2023-02-20 22:48:00 - train.py[line:551] - INFO: load:1.23 valid_run:1221.54 task_valid:1168.87 collect_output:42.53
2023-02-20 22:50:01 - train.py[line:549] - INFO: 2200 / 6234
2023-02-20 22:50:01 - train.py[line:551] - INFO: load:1.25 valid_run:1341.93 task_valid:1284.90 collect_output:45.87
2023-02-20 22:52:03 - train.py[line:549] - INFO: 2400 / 6234
2023-02-20 22:52:03 - train.py[line:551] - INFO: load:1.27 valid_run:1463.65 task_valid:1402.16 collect_output:49.32
2023-02-20 22:54:02 - train.py[line:549] - INFO: 2600 / 6234
2023-02-20 22:54:02 - train.py[line:551] - INFO: load:1.30 valid_run:1582.64 task_valid:1516.16 collect_output:53.32
2023-02-20 22:56:03 - train.py[line:549] - INFO: 2800 / 6234
2023-02-20 22:56:03 - train.py[line:551] - INFO: load:1.32 valid_run:1703.86 task_valid:1634.23 collect_output:55.48
2023-02-20 22:58:04 - train.py[line:549] - INFO: 3000 / 6234
2023-02-20 22:58:04 - train.py[line:551] - INFO: load:1.35 valid_run:1824.86 task_valid:1750.58 collect_output:59.13
2023-02-20 23:00:05 - train.py[line:549] - INFO: 3200 / 6234
2023-02-20 23:00:05 - train.py[line:551] - INFO: load:1.37 valid_run:1946.19 task_valid:1864.89 collect_output:65.14
2023-02-20 23:02:07 - train.py[line:549] - INFO: 3400 / 6234
2023-02-20 23:02:07 - train.py[line:551] - INFO: load:1.39 valid_run:2067.77 task_valid:1981.41 collect_output:69.19
2023-02-20 23:04:08 - train.py[line:549] - INFO: 3600 / 6234
2023-02-20 23:04:08 - train.py[line:551] - INFO: load:1.42 valid_run:2188.58 task_valid:2099.50 collect_output:70.93
2023-02-20 23:06:10 - train.py[line:549] - INFO: 3800 / 6234
2023-02-20 23:06:10 - train.py[line:551] - INFO: load:1.44 valid_run:2310.25 task_valid:2216.75 collect_output:74.32
2023-02-20 23:08:10 - train.py[line:549] - INFO: 4000 / 6234
2023-02-20 23:08:10 - train.py[line:551] - INFO: load:1.47 valid_run:2430.81 task_valid:2333.61 collect_output:77.02
2023-02-20 23:10:12 - train.py[line:549] - INFO: 4200 / 6234
2023-02-20 23:10:12 - train.py[line:551] - INFO: load:1.49 valid_run:2552.77 task_valid:2450.65 collect_output:80.92
2023-02-20 23:12:15 - train.py[line:549] - INFO: 4400 / 6234
2023-02-20 23:12:15 - train.py[line:551] - INFO: load:1.52 valid_run:2675.27 task_valid:2570.07 collect_output:83.00
2023-02-20 23:14:15 - train.py[line:549] - INFO: 4600 / 6234
2023-02-20 23:14:15 - train.py[line:551] - INFO: load:1.54 valid_run:2795.79 task_valid:2684.80 collect_output:87.80
2023-02-20 23:16:15 - train.py[line:549] - INFO: 4800 / 6234
2023-02-20 23:16:15 - train.py[line:551] - INFO: load:1.57 valid_run:2915.80 task_valid:2801.16 collect_output:90.44
2023-02-20 23:18:17 - train.py[line:549] - INFO: 5000 / 6234
2023-02-20 23:18:17 - train.py[line:551] - INFO: load:1.59 valid_run:3037.66 task_valid:2917.80 collect_output:94.65
2023-02-20 23:20:20 - train.py[line:549] - INFO: 5200 / 6234
2023-02-20 23:20:20 - train.py[line:551] - INFO: load:1.61 valid_run:3160.50 task_valid:3034.14 collect_output:100.11
2023-02-20 23:22:20 - train.py[line:549] - INFO: 5400 / 6234
2023-02-20 23:22:20 - train.py[line:551] - INFO: load:1.64 valid_run:3280.21 task_valid:3148.69 collect_output:104.24
2023-02-20 23:24:22 - train.py[line:549] - INFO: 5600 / 6234
2023-02-20 23:24:22 - train.py[line:551] - INFO: load:1.66 valid_run:3402.32 task_valid:3268.45 collect_output:105.57
2023-02-20 23:26:24 - train.py[line:549] - INFO: 5800 / 6234
2023-02-20 23:26:24 - train.py[line:551] - INFO: load:1.69 valid_run:3524.22 task_valid:3384.28 collect_output:110.63
2023-02-20 23:28:27 - train.py[line:549] - INFO: 6000 / 6234
2023-02-20 23:28:27 - train.py[line:551] - INFO: load:1.71 valid_run:3646.54 task_valid:3503.22 collect_output:112.99
2023-02-20 23:30:28 - train.py[line:549] - INFO: 6200 / 6234
2023-02-20 23:30:28 - train.py[line:551] - INFO: load:1.74 valid_run:3767.86 task_valid:3621.93 collect_output:114.55

====================================================================================================
SGG eval:     R @ 50: 0.6459;     R @ 100: 0.6861;     R @ 500: 0.7043;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3938;    mR @ 100: 0.4608;    mR @ 500: 0.5163;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.5625) (covering:0.4429) (eating:0.8235) (flying in:0.0000) (growing on:0.5000) (hanging from:0.5484) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9843) (says:0.5000) (sitting on:0.7404) (standing on:0.3777) (using:0.6000) (walking in:0.0000) (walking on:0.7568) (watching:0.4444) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6459;     R @ 100: 0.6861;     R @ 500: 0.7043;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3938;    mR @ 100: 0.4608;    mR @ 500: 0.5163;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.5625) (covering:0.4429) (eating:0.8235) (flying in:0.0000) (growing on:0.5000) (hanging from:0.5484) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9843) (says:0.5000) (sitting on:0.7404) (standing on:0.3777) (using:0.6000) (walking in:0.0000) (walking on:0.7568) (watching:0.4444) 
--------------------------------------------------------
====================================================================================================

2023-02-20 23:30:59 - train.py[line:487] - INFO: 0.6860957983193278
2023-02-20 23:30:59 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-20 23:30:59 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.218 | loss_v1 0 | loss_v2 0 | nll_loss 0.051 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.686096 | ppl 1.04 | vqa_score 0.3277 | wps 118 | wpb 72 | bsz 24 | num_updates 12000 | best_R@100 0.693596
2023-02-20 23:30:59 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 12000 updates
2023-02-20 23:30:59 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_12000.pt
2023-02-20 23:31:05 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_12000.pt
2023-02-20 23:31:08 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 0.6860957983193278) (writing took 8.570890503004193 seconds)
2023-02-20 23:31:19 - progress_bar.py[line:274] - INFO: epoch 001:  12023 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=111.9, bsz=40, num_updates=12010, lr=4.70417e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36332
2023-02-20 23:31:20 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-20 23:31:31 - progress_bar.py[line:274] - INFO: epoch 001:  12034 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.5, ups=0.85, wpb=112.4, bsz=40, num_updates=12020, lr=4.70381e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=36343
2023-02-20 23:31:42 - progress_bar.py[line:274] - INFO: epoch 001:  12044 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.88, wpb=109.8, bsz=40, num_updates=12030, lr=4.70345e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36355
2023-02-20 23:31:53 - progress_bar.py[line:274] - INFO: epoch 001:  12054 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.89, wpb=109.7, bsz=40, num_updates=12040, lr=4.70309e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36366
2023-02-20 23:32:04 - progress_bar.py[line:274] - INFO: epoch 001:  12064 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111, bsz=40, num_updates=12050, lr=4.70273e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36377
2023-02-20 23:32:15 - progress_bar.py[line:274] - INFO: epoch 001:  12074 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=12060, lr=4.70236e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36388
2023-02-20 23:32:26 - progress_bar.py[line:274] - INFO: epoch 001:  12084 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=12070, lr=4.702e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36399
2023-02-20 23:32:37 - progress_bar.py[line:274] - INFO: epoch 001:  12094 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.9, bsz=40, num_updates=12080, lr=4.70164e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=36410
2023-02-20 23:32:49 - progress_bar.py[line:274] - INFO: epoch 001:  12104 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.4, bsz=40, num_updates=12090, lr=4.70128e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36421
2023-02-20 23:33:00 - progress_bar.py[line:274] - INFO: epoch 001:  12114 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=12100, lr=4.70092e-05, gnorm=0.13, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=36433
2023-02-20 23:33:10 - progress_bar.py[line:274] - INFO: epoch 001:  12124 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.3, ups=0.93, wpb=111.9, bsz=40, num_updates=12110, lr=4.70056e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36443
2023-02-20 23:33:22 - progress_bar.py[line:274] - INFO: epoch 001:  12134 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=12120, lr=4.70019e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=36454
2023-02-20 23:33:33 - progress_bar.py[line:274] - INFO: epoch 001:  12144 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.1, bsz=40, num_updates=12130, lr=4.69983e-05, gnorm=0.049, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36466
2023-02-20 23:33:44 - progress_bar.py[line:274] - INFO: epoch 001:  12154 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=12140, lr=4.69947e-05, gnorm=0.044, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=36477
2023-02-20 23:33:55 - progress_bar.py[line:274] - INFO: epoch 001:  12164 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112.1, bsz=40, num_updates=12150, lr=4.69911e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36488
2023-02-20 23:34:07 - progress_bar.py[line:274] - INFO: epoch 001:  12174 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.8, bsz=40, num_updates=12160, lr=4.69875e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36499
2023-02-20 23:34:17 - progress_bar.py[line:274] - INFO: epoch 001:  12184 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.93, wpb=110.6, bsz=40, num_updates=12170, lr=4.69838e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36510
2023-02-20 23:34:28 - progress_bar.py[line:274] - INFO: epoch 001:  12194 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=12180, lr=4.69802e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36521
2023-02-20 23:34:40 - progress_bar.py[line:274] - INFO: epoch 001:  12204 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=12190, lr=4.69766e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36532
2023-02-20 23:34:48 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-02-20 23:34:51 - progress_bar.py[line:274] - INFO: epoch 001:  12215 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.1, ups=0.86, wpb=110.5, bsz=40, num_updates=12200, lr=4.6973e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=36544
2023-02-20 23:35:02 - progress_bar.py[line:274] - INFO: epoch 001:  12225 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=12210, lr=4.69694e-05, gnorm=0.062, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36555
2023-02-20 23:35:14 - progress_bar.py[line:274] - INFO: epoch 001:  12235 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=111.1, bsz=40, num_updates=12220, lr=4.69657e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36567
2023-02-20 23:35:25 - progress_bar.py[line:274] - INFO: epoch 001:  12245 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=112.1, bsz=40, num_updates=12230, lr=4.69621e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=36578
2023-02-20 23:35:36 - progress_bar.py[line:274] - INFO: epoch 001:  12255 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.92, wpb=109.8, bsz=40, num_updates=12240, lr=4.69585e-05, gnorm=0.062, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36589
2023-02-20 23:35:47 - progress_bar.py[line:274] - INFO: epoch 001:  12265 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.9, bsz=40, num_updates=12250, lr=4.69549e-05, gnorm=0.086, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36600
2023-02-20 23:35:58 - progress_bar.py[line:274] - INFO: epoch 001:  12275 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=98.3, ups=0.88, wpb=111.2, bsz=40, num_updates=12260, lr=4.69513e-05, gnorm=0.047, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36611
2023-02-20 23:36:09 - progress_bar.py[line:274] - INFO: epoch 001:  12285 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=105.8, ups=0.94, wpb=112.1, bsz=40, num_updates=12270, lr=4.69477e-05, gnorm=0.09, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36622
2023-02-20 23:36:20 - progress_bar.py[line:274] - INFO: epoch 001:  12295 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=110.8, bsz=40, num_updates=12280, lr=4.6944e-05, gnorm=0.08, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36633
2023-02-20 23:36:31 - progress_bar.py[line:274] - INFO: epoch 001:  12305 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=12290, lr=4.69404e-05, gnorm=0.063, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=36644
2023-02-20 23:36:42 - progress_bar.py[line:274] - INFO: epoch 001:  12315 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=12300, lr=4.69368e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36655
2023-02-20 23:36:53 - progress_bar.py[line:274] - INFO: epoch 001:  12325 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=12310, lr=4.69332e-05, gnorm=0.1, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36666
2023-02-20 23:37:05 - progress_bar.py[line:274] - INFO: epoch 001:  12335 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=12320, lr=4.69296e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36677
2023-02-20 23:37:16 - progress_bar.py[line:274] - INFO: epoch 001:  12345 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.4, bsz=40, num_updates=12330, lr=4.69259e-05, gnorm=0.074, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36688
2023-02-20 23:37:27 - progress_bar.py[line:274] - INFO: epoch 001:  12355 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=12340, lr=4.69223e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36700
2023-02-20 23:37:38 - progress_bar.py[line:274] - INFO: epoch 001:  12365 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=110.6, bsz=40, num_updates=12350, lr=4.69187e-05, gnorm=0.059, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36711
2023-02-20 23:37:49 - progress_bar.py[line:274] - INFO: epoch 001:  12375 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.5, bsz=40, num_updates=12360, lr=4.69151e-05, gnorm=0.065, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36722
2023-02-20 23:38:00 - progress_bar.py[line:274] - INFO: epoch 001:  12385 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.92, wpb=109.9, bsz=40, num_updates=12370, lr=4.69115e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36733
2023-02-20 23:38:11 - progress_bar.py[line:274] - INFO: epoch 001:  12395 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=109.7, bsz=40, num_updates=12380, lr=4.69079e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36744
2023-02-20 23:38:22 - progress_bar.py[line:274] - INFO: epoch 001:  12405 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=12390, lr=4.69042e-05, gnorm=0.077, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36755
2023-02-20 23:38:34 - progress_bar.py[line:274] - INFO: epoch 001:  12415 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.1, ups=0.91, wpb=111.4, bsz=40, num_updates=12400, lr=4.69006e-05, gnorm=0.091, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=36766
2023-02-20 23:38:45 - progress_bar.py[line:274] - INFO: epoch 001:  12425 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.6, bsz=40, num_updates=12410, lr=4.6897e-05, gnorm=0.061, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36777
2023-02-20 23:38:56 - progress_bar.py[line:274] - INFO: epoch 001:  12435 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=12420, lr=4.68934e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36789
2023-02-20 23:39:07 - progress_bar.py[line:274] - INFO: epoch 001:  12445 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.3, bsz=40, num_updates=12430, lr=4.68898e-05, gnorm=0.087, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=36800
2023-02-20 23:39:18 - progress_bar.py[line:274] - INFO: epoch 001:  12455 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.4, bsz=40, num_updates=12440, lr=4.68861e-05, gnorm=0.059, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36811
2023-02-20 23:39:29 - progress_bar.py[line:274] - INFO: epoch 001:  12465 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=12450, lr=4.68825e-05, gnorm=0.066, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=36822
2023-02-20 23:39:41 - progress_bar.py[line:274] - INFO: epoch 001:  12475 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.89, wpb=111.7, bsz=40, num_updates=12460, lr=4.68789e-05, gnorm=0.088, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36834
2023-02-20 23:39:52 - progress_bar.py[line:274] - INFO: epoch 001:  12485 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=12470, lr=4.68753e-05, gnorm=0.065, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36845
2023-02-20 23:40:04 - progress_bar.py[line:274] - INFO: epoch 001:  12495 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112.8, bsz=40, num_updates=12480, lr=4.68717e-05, gnorm=0.057, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36856
2023-02-20 23:40:15 - progress_bar.py[line:274] - INFO: epoch 001:  12505 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=12490, lr=4.68681e-05, gnorm=0.075, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=36868
2023-02-20 23:40:26 - progress_bar.py[line:274] - INFO: epoch 001:  12515 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.88, wpb=111.1, bsz=40, num_updates=12500, lr=4.68644e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36879
2023-02-20 23:40:37 - progress_bar.py[line:274] - INFO: epoch 001:  12525 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.9, bsz=40, num_updates=12510, lr=4.68608e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36890
2023-02-20 23:40:48 - progress_bar.py[line:274] - INFO: epoch 001:  12535 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=12520, lr=4.68572e-05, gnorm=0.085, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36901
2023-02-20 23:41:00 - progress_bar.py[line:274] - INFO: epoch 001:  12545 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=12530, lr=4.68536e-05, gnorm=0.064, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36912
2023-02-20 23:41:11 - progress_bar.py[line:274] - INFO: epoch 001:  12555 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=12540, lr=4.685e-05, gnorm=0.076, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36923
2023-02-20 23:41:22 - progress_bar.py[line:274] - INFO: epoch 001:  12565 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111.1, bsz=40, num_updates=12550, lr=4.68463e-05, gnorm=0.069, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=36935
2023-02-20 23:41:33 - progress_bar.py[line:274] - INFO: epoch 001:  12575 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=12560, lr=4.68427e-05, gnorm=0.097, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36946
2023-02-20 23:41:44 - progress_bar.py[line:274] - INFO: epoch 001:  12585 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.4, bsz=40, num_updates=12570, lr=4.68391e-05, gnorm=0.098, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=36957
2023-02-20 23:41:55 - progress_bar.py[line:274] - INFO: epoch 001:  12595 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=12580, lr=4.68355e-05, gnorm=0.049, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=36968
2023-02-20 23:42:06 - progress_bar.py[line:274] - INFO: epoch 001:  12605 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=12590, lr=4.68319e-05, gnorm=0.068, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=36979
2023-02-20 23:42:17 - progress_bar.py[line:274] - INFO: epoch 001:  12615 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=12600, lr=4.68283e-05, gnorm=0.081, clip=0, loss_scale=2048, train_wall=11, gb_free=11, ema_decay=0.9999, wall=36990
2023-02-20 23:42:29 - progress_bar.py[line:274] - INFO: epoch 001:  12625 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.8, bsz=40, num_updates=12610, lr=4.68246e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37002
2023-02-20 23:42:40 - progress_bar.py[line:274] - INFO: epoch 001:  12635 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111, bsz=40, num_updates=12620, lr=4.6821e-05, gnorm=0.102, clip=0, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=37013
2023-02-20 23:42:51 - progress_bar.py[line:274] - INFO: epoch 001:  12645 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=12630, lr=4.68174e-05, gnorm=0.071, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37024
2023-02-20 23:43:02 - progress_bar.py[line:274] - INFO: epoch 001:  12655 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.8, bsz=40, num_updates=12640, lr=4.68138e-05, gnorm=0.059, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37035
2023-02-20 23:43:14 - progress_bar.py[line:274] - INFO: epoch 001:  12665 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=12650, lr=4.68102e-05, gnorm=0.082, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37047
2023-02-20 23:43:25 - progress_bar.py[line:274] - INFO: epoch 001:  12675 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=112, bsz=40, num_updates=12660, lr=4.68065e-05, gnorm=0.078, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37058
2023-02-20 23:43:36 - progress_bar.py[line:274] - INFO: epoch 001:  12685 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=12670, lr=4.68029e-05, gnorm=0.084, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37069
2023-02-20 23:43:48 - progress_bar.py[line:274] - INFO: epoch 001:  12695 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.6, bsz=40, num_updates=12680, lr=4.67993e-05, gnorm=0.067, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=37080
2023-02-20 23:43:59 - progress_bar.py[line:274] - INFO: epoch 001:  12705 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.88, wpb=111.6, bsz=40, num_updates=12690, lr=4.67957e-05, gnorm=0.072, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37092
2023-02-20 23:44:10 - progress_bar.py[line:274] - INFO: epoch 001:  12715 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.91, wpb=109.7, bsz=40, num_updates=12700, lr=4.67921e-05, gnorm=0.095, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37103
2023-02-20 23:44:21 - progress_bar.py[line:274] - INFO: epoch 001:  12725 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=12710, lr=4.67885e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37114
2023-02-20 23:44:32 - progress_bar.py[line:274] - INFO: epoch 001:  12735 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=112, bsz=40, num_updates=12720, lr=4.67848e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37125
2023-02-20 23:44:43 - progress_bar.py[line:274] - INFO: epoch 001:  12745 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.4, bsz=40, num_updates=12730, lr=4.67812e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37136
2023-02-20 23:44:54 - progress_bar.py[line:274] - INFO: epoch 001:  12755 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=12740, lr=4.67776e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37147
2023-02-20 23:45:05 - progress_bar.py[line:274] - INFO: epoch 001:  12765 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=12750, lr=4.6774e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37158
2023-02-20 23:45:16 - progress_bar.py[line:274] - INFO: epoch 001:  12775 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=12760, lr=4.67704e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37169
2023-02-20 23:45:28 - progress_bar.py[line:274] - INFO: epoch 001:  12785 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=111.2, bsz=40, num_updates=12770, lr=4.67667e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37181
2023-02-20 23:45:39 - progress_bar.py[line:274] - INFO: epoch 001:  12795 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=12780, lr=4.67631e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37192
2023-02-20 23:45:50 - progress_bar.py[line:274] - INFO: epoch 001:  12805 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.7, bsz=40, num_updates=12790, lr=4.67595e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=37203
2023-02-20 23:46:01 - progress_bar.py[line:274] - INFO: epoch 001:  12815 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111, bsz=40, num_updates=12800, lr=4.67559e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37214
2023-02-20 23:46:12 - progress_bar.py[line:274] - INFO: epoch 001:  12825 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.91, wpb=110, bsz=40, num_updates=12810, lr=4.67523e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37225
2023-02-20 23:46:25 - progress_bar.py[line:274] - INFO: epoch 001:  12835 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=12820, lr=4.67487e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37238
2023-02-20 23:46:36 - progress_bar.py[line:274] - INFO: epoch 001:  12845 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.4, bsz=40, num_updates=12830, lr=4.6745e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37249
2023-02-20 23:46:47 - progress_bar.py[line:274] - INFO: epoch 001:  12855 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.91, wpb=109.9, bsz=40, num_updates=12840, lr=4.67414e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37260
2023-02-20 23:46:58 - progress_bar.py[line:274] - INFO: epoch 001:  12865 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=111.9, bsz=40, num_updates=12850, lr=4.67378e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=37271
2023-02-20 23:47:09 - progress_bar.py[line:274] - INFO: epoch 001:  12875 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=12860, lr=4.67342e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=37282
2023-02-20 23:47:20 - progress_bar.py[line:274] - INFO: epoch 001:  12885 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=12870, lr=4.67306e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37293
2023-02-20 23:47:32 - progress_bar.py[line:274] - INFO: epoch 001:  12895 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=12880, lr=4.67269e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37304
2023-02-20 23:47:43 - progress_bar.py[line:274] - INFO: epoch 001:  12905 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111, bsz=40, num_updates=12890, lr=4.67233e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=37316
2023-02-20 23:47:54 - progress_bar.py[line:274] - INFO: epoch 001:  12915 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.6, bsz=40, num_updates=12900, lr=4.67197e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=37327
2023-02-20 23:48:05 - progress_bar.py[line:274] - INFO: epoch 001:  12925 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=12910, lr=4.67161e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37338
2023-02-20 23:48:16 - progress_bar.py[line:274] - INFO: epoch 001:  12935 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=12920, lr=4.67125e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=37349
2023-02-20 23:48:27 - progress_bar.py[line:274] - INFO: epoch 001:  12945 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=12930, lr=4.67089e-05, gnorm=0.111, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=37360
2023-02-20 23:48:39 - progress_bar.py[line:274] - INFO: epoch 001:  12955 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.3, bsz=40, num_updates=12940, lr=4.67052e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37371
2023-02-20 23:48:50 - progress_bar.py[line:274] - INFO: epoch 001:  12965 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.3, bsz=40, num_updates=12950, lr=4.67016e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37383
2023-02-20 23:49:01 - progress_bar.py[line:274] - INFO: epoch 001:  12975 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.7, bsz=40, num_updates=12960, lr=4.6698e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37394
2023-02-20 23:49:12 - progress_bar.py[line:274] - INFO: epoch 001:  12985 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=102.8, ups=0.93, wpb=110.6, bsz=40, num_updates=12970, lr=4.66944e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37405
2023-02-20 23:49:23 - progress_bar.py[line:274] - INFO: epoch 001:  12995 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.87, wpb=112.9, bsz=40, num_updates=12980, lr=4.66908e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37416
2023-02-20 23:49:34 - progress_bar.py[line:274] - INFO: epoch 001:  13005 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.93, wpb=110.6, bsz=40, num_updates=12990, lr=4.66871e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=37427
2023-02-20 23:49:46 - progress_bar.py[line:274] - INFO: epoch 001:  13015 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=112, bsz=40, num_updates=13000, lr=4.66835e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37438
2023-02-20 23:49:57 - progress_bar.py[line:274] - INFO: epoch 001:  13025 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.1, bsz=40, num_updates=13010, lr=4.66799e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=37450
2023-02-20 23:50:08 - progress_bar.py[line:274] - INFO: epoch 001:  13035 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=13020, lr=4.66763e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37461
2023-02-20 23:50:19 - progress_bar.py[line:274] - INFO: epoch 001:  13045 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=13030, lr=4.66727e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37472
2023-02-20 23:50:31 - progress_bar.py[line:274] - INFO: epoch 001:  13055 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=13040, lr=4.66691e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37483
2023-02-20 23:50:41 - progress_bar.py[line:274] - INFO: epoch 001:  13065 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.4, ups=0.92, wpb=111.6, bsz=40, num_updates=13050, lr=4.66654e-05, gnorm=0.218, clip=10, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37494
2023-02-20 23:50:53 - progress_bar.py[line:274] - INFO: epoch 001:  13075 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=13060, lr=4.66618e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37505
2023-02-20 23:51:04 - progress_bar.py[line:274] - INFO: epoch 001:  13085 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=110.9, bsz=40, num_updates=13070, lr=4.66582e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=37517
2023-02-20 23:51:15 - progress_bar.py[line:274] - INFO: epoch 001:  13095 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=13080, lr=4.66546e-05, gnorm=0.112, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37528
2023-02-20 23:51:27 - progress_bar.py[line:274] - INFO: epoch 001:  13105 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.6, bsz=40, num_updates=13090, lr=4.6651e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=37540
2023-02-20 23:51:38 - progress_bar.py[line:274] - INFO: epoch 001:  13115 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112.5, bsz=40, num_updates=13100, lr=4.66473e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37551
2023-02-20 23:51:49 - progress_bar.py[line:274] - INFO: epoch 001:  13125 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.92, wpb=110.3, bsz=40, num_updates=13110, lr=4.66437e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37562
2023-02-20 23:52:01 - progress_bar.py[line:274] - INFO: epoch 001:  13135 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.5, ups=0.87, wpb=110.1, bsz=40, num_updates=13120, lr=4.66401e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37573
2023-02-20 23:52:12 - progress_bar.py[line:274] - INFO: epoch 001:  13145 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.92, wpb=110.2, bsz=40, num_updates=13130, lr=4.66365e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37584
2023-02-20 23:52:22 - progress_bar.py[line:274] - INFO: epoch 001:  13155 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111.2, bsz=40, num_updates=13140, lr=4.66329e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=37595
2023-02-20 23:52:34 - progress_bar.py[line:274] - INFO: epoch 001:  13165 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=111, bsz=40, num_updates=13150, lr=4.66293e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37607
2023-02-20 23:52:45 - progress_bar.py[line:274] - INFO: epoch 001:  13175 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=111.9, bsz=40, num_updates=13160, lr=4.66256e-05, gnorm=0.114, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37618
2023-02-20 23:52:56 - progress_bar.py[line:274] - INFO: epoch 001:  13185 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=112.2, bsz=40, num_updates=13170, lr=4.6622e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37629
2023-02-20 23:53:07 - progress_bar.py[line:274] - INFO: epoch 001:  13195 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.91, wpb=109.7, bsz=40, num_updates=13180, lr=4.66184e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37640
2023-02-20 23:53:18 - progress_bar.py[line:274] - INFO: epoch 001:  13205 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.6, bsz=40, num_updates=13190, lr=4.66148e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37651
2023-02-20 23:53:29 - progress_bar.py[line:274] - INFO: epoch 001:  13215 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.1, bsz=40, num_updates=13200, lr=4.66112e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37662
2023-02-20 23:53:41 - progress_bar.py[line:274] - INFO: epoch 001:  13225 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.9, wpb=111.2, bsz=40, num_updates=13210, lr=4.66075e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37673
2023-02-20 23:53:52 - progress_bar.py[line:274] - INFO: epoch 001:  13235 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.89, wpb=110.6, bsz=40, num_updates=13220, lr=4.66039e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37685
2023-02-20 23:54:03 - progress_bar.py[line:274] - INFO: epoch 001:  13245 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111, bsz=40, num_updates=13230, lr=4.66003e-05, gnorm=0.096, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=37696
2023-02-20 23:54:14 - progress_bar.py[line:274] - INFO: epoch 001:  13255 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.4, bsz=40, num_updates=13240, lr=4.65967e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37706
2023-02-20 23:54:25 - progress_bar.py[line:274] - INFO: epoch 001:  13265 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.1, bsz=40, num_updates=13250, lr=4.65931e-05, gnorm=0.083, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37718
2023-02-20 23:54:36 - progress_bar.py[line:274] - INFO: epoch 001:  13275 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.89, wpb=110.5, bsz=40, num_updates=13260, lr=4.65895e-05, gnorm=0.103, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37729
2023-02-20 23:54:47 - progress_bar.py[line:274] - INFO: epoch 001:  13285 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=13270, lr=4.65858e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37740
2023-02-20 23:54:58 - progress_bar.py[line:274] - INFO: epoch 001:  13295 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=113.9, nsentences=40, sample_size=113.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.1, ups=0.93, wpb=113.9, bsz=40, num_updates=13280, lr=4.65822e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37751
2023-02-20 23:55:09 - progress_bar.py[line:274] - INFO: epoch 001:  13305 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.1, ups=0.87, wpb=110.8, bsz=40, num_updates=13290, lr=4.65786e-05, gnorm=0.107, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37762
2023-02-20 23:55:21 - progress_bar.py[line:274] - INFO: epoch 001:  13315 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.1, bsz=40, num_updates=13300, lr=4.6575e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37773
2023-02-20 23:55:32 - progress_bar.py[line:274] - INFO: epoch 001:  13325 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=13310, lr=4.65714e-05, gnorm=0.102, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37785
2023-02-20 23:55:43 - progress_bar.py[line:274] - INFO: epoch 001:  13335 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.9, bsz=40, num_updates=13320, lr=4.65677e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37796
2023-02-20 23:55:54 - progress_bar.py[line:274] - INFO: epoch 001:  13345 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=13330, lr=4.65641e-05, gnorm=0.102, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=37807
2023-02-20 23:56:05 - progress_bar.py[line:274] - INFO: epoch 001:  13355 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=111.1, bsz=40, num_updates=13340, lr=4.65605e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37818
2023-02-20 23:56:16 - progress_bar.py[line:274] - INFO: epoch 001:  13365 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=13350, lr=4.65569e-05, gnorm=0.091, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37829
2023-02-20 23:56:28 - progress_bar.py[line:274] - INFO: epoch 001:  13375 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.1, bsz=40, num_updates=13360, lr=4.65533e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37840
2023-02-20 23:56:39 - progress_bar.py[line:274] - INFO: epoch 001:  13385 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=13370, lr=4.65497e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=37852
2023-02-20 23:56:50 - progress_bar.py[line:274] - INFO: epoch 001:  13395 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.1, bsz=40, num_updates=13380, lr=4.6546e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37863
2023-02-20 23:57:02 - progress_bar.py[line:274] - INFO: epoch 001:  13405 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=13390, lr=4.65424e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37874
2023-02-20 23:57:13 - progress_bar.py[line:274] - INFO: epoch 001:  13415 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=13400, lr=4.65388e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37885
2023-02-20 23:57:23 - progress_bar.py[line:274] - INFO: epoch 001:  13425 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.3, bsz=40, num_updates=13410, lr=4.65352e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=37896
2023-02-20 23:57:35 - progress_bar.py[line:274] - INFO: epoch 001:  13435 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.4, bsz=40, num_updates=13420, lr=4.65316e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37907
2023-02-20 23:57:46 - progress_bar.py[line:274] - INFO: epoch 001:  13445 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.3, ups=0.87, wpb=109.4, bsz=40, num_updates=13430, lr=4.65279e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=37919
2023-02-20 23:57:57 - progress_bar.py[line:274] - INFO: epoch 001:  13455 / 142023 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=13440, lr=4.65243e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37930
2023-02-20 23:58:09 - progress_bar.py[line:274] - INFO: epoch 001:  13465 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=111, bsz=40, num_updates=13450, lr=4.65207e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=37941
2023-02-20 23:58:20 - progress_bar.py[line:274] - INFO: epoch 001:  13475 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.5, bsz=40, num_updates=13460, lr=4.65171e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=37953
2023-02-20 23:58:31 - progress_bar.py[line:274] - INFO: epoch 001:  13485 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.6, bsz=40, num_updates=13470, lr=4.65135e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37964
2023-02-20 23:58:43 - progress_bar.py[line:274] - INFO: epoch 001:  13495 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=112.2, bsz=40, num_updates=13480, lr=4.65099e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=37975
2023-02-20 23:58:54 - progress_bar.py[line:274] - INFO: epoch 001:  13505 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.9, wpb=110.1, bsz=40, num_updates=13490, lr=4.65062e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=37987
2023-02-20 23:59:05 - progress_bar.py[line:274] - INFO: epoch 001:  13515 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111, bsz=40, num_updates=13500, lr=4.65026e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=37997
2023-02-20 23:59:16 - progress_bar.py[line:274] - INFO: epoch 001:  13525 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=13510, lr=4.6499e-05, gnorm=0.087, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38009
2023-02-20 23:59:27 - progress_bar.py[line:274] - INFO: epoch 001:  13535 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.2, bsz=40, num_updates=13520, lr=4.64954e-05, gnorm=0.093, clip=0, loss_scale=8192, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=38020
2023-02-20 23:59:38 - progress_bar.py[line:274] - INFO: epoch 001:  13545 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.92, wpb=109.3, bsz=40, num_updates=13530, lr=4.64918e-05, gnorm=0.11, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38031
2023-02-20 23:59:50 - progress_bar.py[line:274] - INFO: epoch 001:  13555 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=110.8, bsz=40, num_updates=13540, lr=4.64881e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38042
2023-02-21 00:00:01 - progress_bar.py[line:274] - INFO: epoch 001:  13565 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.8, bsz=40, num_updates=13550, lr=4.64845e-05, gnorm=0.085, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38053
2023-02-21 00:00:12 - progress_bar.py[line:274] - INFO: epoch 001:  13575 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.6, bsz=40, num_updates=13560, lr=4.64809e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=38064
2023-02-21 00:00:22 - progress_bar.py[line:274] - INFO: epoch 001:  13585 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112.2, bsz=40, num_updates=13570, lr=4.64773e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38075
2023-02-21 00:00:34 - progress_bar.py[line:274] - INFO: epoch 001:  13595 / 142023 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.6, bsz=40, num_updates=13580, lr=4.64737e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38086
2023-02-21 00:00:45 - progress_bar.py[line:274] - INFO: epoch 001:  13605 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111, bsz=40, num_updates=13590, lr=4.64701e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=38098
2023-02-21 00:00:56 - progress_bar.py[line:274] - INFO: epoch 001:  13615 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=13600, lr=4.64664e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38109
2023-02-21 00:01:01 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 00:01:08 - progress_bar.py[line:274] - INFO: epoch 001:  13626 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=92.4, ups=0.83, wpb=111.9, bsz=40, num_updates=13610, lr=4.64628e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=38121
2023-02-21 00:01:19 - progress_bar.py[line:274] - INFO: epoch 001:  13636 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=110.6, bsz=40, num_updates=13620, lr=4.64592e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38132
2023-02-21 00:01:30 - progress_bar.py[line:274] - INFO: epoch 001:  13646 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=13630, lr=4.64556e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=38143
2023-02-21 00:01:41 - progress_bar.py[line:274] - INFO: epoch 001:  13656 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.3, bsz=40, num_updates=13640, lr=4.6452e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38154
2023-02-21 00:01:52 - progress_bar.py[line:274] - INFO: epoch 001:  13666 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.6, bsz=40, num_updates=13650, lr=4.64483e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38165
2023-02-21 00:02:04 - progress_bar.py[line:274] - INFO: epoch 001:  13676 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.3, bsz=40, num_updates=13660, lr=4.64447e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38177
2023-02-21 00:02:15 - progress_bar.py[line:274] - INFO: epoch 001:  13686 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=112.6, bsz=40, num_updates=13670, lr=4.64411e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38188
2023-02-21 00:02:26 - progress_bar.py[line:274] - INFO: epoch 001:  13696 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.6, bsz=40, num_updates=13680, lr=4.64375e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=38199
2023-02-21 00:02:37 - progress_bar.py[line:274] - INFO: epoch 001:  13706 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.1, bsz=40, num_updates=13690, lr=4.64339e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=38210
2023-02-21 00:02:48 - progress_bar.py[line:274] - INFO: epoch 001:  13716 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=101.1, ups=0.91, wpb=111.6, bsz=40, num_updates=13700, lr=4.64303e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=38221
2023-02-21 00:02:59 - progress_bar.py[line:274] - INFO: epoch 001:  13726 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=13710, lr=4.64266e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=38232
2023-02-21 00:03:11 - progress_bar.py[line:274] - INFO: epoch 001:  13736 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.1, bsz=40, num_updates=13720, lr=4.6423e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38244
2023-02-21 00:03:22 - progress_bar.py[line:274] - INFO: epoch 001:  13746 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=13730, lr=4.64194e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=38255
2023-02-21 00:03:33 - progress_bar.py[line:274] - INFO: epoch 001:  13756 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.6, bsz=40, num_updates=13740, lr=4.64158e-05, gnorm=0.045, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38266
2023-02-21 00:03:44 - progress_bar.py[line:274] - INFO: epoch 001:  13766 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=110.8, bsz=40, num_updates=13750, lr=4.64122e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=38277
2023-02-21 00:03:55 - progress_bar.py[line:274] - INFO: epoch 001:  13776 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.4, bsz=40, num_updates=13760, lr=4.64085e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38288
2023-02-21 00:04:07 - progress_bar.py[line:274] - INFO: epoch 001:  13786 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.7, bsz=40, num_updates=13770, lr=4.64049e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38299
2023-02-21 00:04:18 - progress_bar.py[line:274] - INFO: epoch 001:  13796 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=13780, lr=4.64013e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38311
2023-02-21 00:04:29 - progress_bar.py[line:274] - INFO: epoch 001:  13806 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.5, bsz=40, num_updates=13790, lr=4.63977e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38322
2023-02-21 00:04:40 - progress_bar.py[line:274] - INFO: epoch 001:  13816 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.89, wpb=112.4, bsz=40, num_updates=13800, lr=4.63941e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38333
2023-02-21 00:04:51 - progress_bar.py[line:274] - INFO: epoch 001:  13826 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.93, wpb=112.2, bsz=40, num_updates=13810, lr=4.63905e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38344
2023-02-21 00:05:02 - progress_bar.py[line:274] - INFO: epoch 001:  13836 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.91, wpb=113.2, bsz=40, num_updates=13820, lr=4.63868e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38355
2023-02-21 00:05:14 - progress_bar.py[line:274] - INFO: epoch 001:  13846 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=110.8, bsz=40, num_updates=13830, lr=4.63832e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38366
2023-02-21 00:05:25 - progress_bar.py[line:274] - INFO: epoch 001:  13856 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=13840, lr=4.63796e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38377
2023-02-21 00:05:36 - progress_bar.py[line:274] - INFO: epoch 001:  13866 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.92, wpb=110.3, bsz=40, num_updates=13850, lr=4.6376e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=38388
2023-02-21 00:05:47 - progress_bar.py[line:274] - INFO: epoch 001:  13876 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.89, wpb=110, bsz=40, num_updates=13860, lr=4.63724e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38400
2023-02-21 00:05:58 - progress_bar.py[line:274] - INFO: epoch 001:  13886 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=13870, lr=4.63687e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38411
2023-02-21 00:06:09 - progress_bar.py[line:274] - INFO: epoch 001:  13896 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.6, ups=0.92, wpb=111.6, bsz=40, num_updates=13880, lr=4.63651e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=38422
2023-02-21 00:06:20 - progress_bar.py[line:274] - INFO: epoch 001:  13906 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.92, wpb=109.5, bsz=40, num_updates=13890, lr=4.63615e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38433
2023-02-21 00:06:31 - progress_bar.py[line:274] - INFO: epoch 001:  13916 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.9, wpb=109.6, bsz=40, num_updates=13900, lr=4.63579e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38444
2023-02-21 00:06:42 - progress_bar.py[line:274] - INFO: epoch 001:  13926 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.2, bsz=40, num_updates=13910, lr=4.63543e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38455
2023-02-21 00:06:53 - progress_bar.py[line:274] - INFO: epoch 001:  13936 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.4, ups=0.92, wpb=110.6, bsz=40, num_updates=13920, lr=4.63507e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38466
2023-02-21 00:07:04 - progress_bar.py[line:274] - INFO: epoch 001:  13946 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.9, bsz=40, num_updates=13930, lr=4.6347e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38477
2023-02-21 00:07:15 - progress_bar.py[line:274] - INFO: epoch 001:  13956 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=110.5, bsz=40, num_updates=13940, lr=4.63434e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38488
2023-02-21 00:07:27 - progress_bar.py[line:274] - INFO: epoch 001:  13966 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=13950, lr=4.63398e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38499
2023-02-21 00:07:38 - progress_bar.py[line:274] - INFO: epoch 001:  13976 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.5, bsz=40, num_updates=13960, lr=4.63362e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=38511
2023-02-21 00:07:49 - progress_bar.py[line:274] - INFO: epoch 001:  13986 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=13970, lr=4.63326e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=38522
2023-02-21 00:08:01 - progress_bar.py[line:274] - INFO: epoch 001:  13996 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=110.6, bsz=40, num_updates=13980, lr=4.63289e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=38533
2023-02-21 00:08:11 - progress_bar.py[line:274] - INFO: epoch 001:  14006 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.8, bsz=40, num_updates=13990, lr=4.63253e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=38544
2023-02-21 00:08:22 - progress_bar.py[line:274] - INFO: epoch 001:  14016 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.3, bsz=40, num_updates=14000, lr=4.63217e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=38555
2023-02-21 00:08:22 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 00:08:24 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 00:08:24 - train.py[line:551] - INFO: load:1.05 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 00:10:26 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 00:10:26 - train.py[line:551] - INFO: load:1.07 valid_run:122.30 task_valid:119.12 collect_output:2.14
2023-02-21 00:12:26 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 00:12:26 - train.py[line:551] - INFO: load:1.09 valid_run:242.18 task_valid:235.07 collect_output:5.08
2023-02-21 00:14:28 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 00:14:28 - train.py[line:551] - INFO: load:1.12 valid_run:364.17 task_valid:351.74 collect_output:9.41
2023-02-21 00:16:30 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 00:16:30 - train.py[line:551] - INFO: load:1.14 valid_run:486.27 task_valid:465.66 collect_output:16.58
2023-02-21 00:18:31 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 00:18:31 - train.py[line:551] - INFO: load:1.16 valid_run:606.84 task_valid:583.24 collect_output:18.58
2023-02-21 00:20:34 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 00:20:34 - train.py[line:551] - INFO: load:1.19 valid_run:729.84 task_valid:702.15 collect_output:21.67
2023-02-21 00:22:37 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 00:22:37 - train.py[line:551] - INFO: load:1.21 valid_run:852.96 task_valid:820.49 collect_output:25.45
2023-02-21 00:24:39 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 00:24:39 - train.py[line:551] - INFO: load:1.24 valid_run:975.08 task_valid:937.46 collect_output:29.59
2023-02-21 00:26:43 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 00:26:43 - train.py[line:551] - INFO: load:1.26 valid_run:1098.78 task_valid:1054.86 collect_output:34.90
2023-02-21 00:28:45 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 00:28:45 - train.py[line:551] - INFO: load:1.29 valid_run:1220.53 task_valid:1167.66 collect_output:42.87
2023-02-21 00:30:45 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 00:30:45 - train.py[line:551] - INFO: load:1.31 valid_run:1340.70 task_valid:1283.34 collect_output:46.35
2023-02-21 00:32:47 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 00:32:47 - train.py[line:551] - INFO: load:1.33 valid_run:1462.26 task_valid:1400.50 collect_output:49.76
2023-02-21 00:34:46 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 00:34:46 - train.py[line:551] - INFO: load:1.36 valid_run:1581.17 task_valid:1514.43 collect_output:53.75
2023-02-21 00:36:47 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 00:36:47 - train.py[line:551] - INFO: load:1.38 valid_run:1702.25 task_valid:1632.42 collect_output:55.85
2023-02-21 00:38:48 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 00:38:48 - train.py[line:551] - INFO: load:1.41 valid_run:1823.38 task_valid:1748.79 collect_output:59.59
2023-02-21 00:40:49 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 00:40:49 - train.py[line:551] - INFO: load:1.43 valid_run:1944.46 task_valid:1862.93 collect_output:65.52
2023-02-21 00:42:50 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 00:42:50 - train.py[line:551] - INFO: load:1.46 valid_run:2065.84 task_valid:1979.19 collect_output:69.65
2023-02-21 00:44:51 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 00:44:51 - train.py[line:551] - INFO: load:1.48 valid_run:2186.65 task_valid:2097.31 collect_output:71.32
2023-02-21 00:46:53 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 00:46:53 - train.py[line:551] - INFO: load:1.51 valid_run:2307.92 task_valid:2214.37 collect_output:74.52
2023-02-21 00:48:53 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 00:48:53 - train.py[line:551] - INFO: load:1.53 valid_run:2428.31 task_valid:2331.11 collect_output:77.18
2023-02-21 00:50:55 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 00:50:55 - train.py[line:551] - INFO: load:1.55 valid_run:2549.97 task_valid:2447.80 collect_output:81.16
2023-02-21 00:52:57 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 00:52:57 - train.py[line:551] - INFO: load:1.58 valid_run:2672.16 task_valid:2567.02 collect_output:83.13
2023-02-21 00:54:57 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 00:54:57 - train.py[line:551] - INFO: load:1.60 valid_run:2792.48 task_valid:2681.56 collect_output:87.90
2023-02-21 00:56:57 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 00:56:57 - train.py[line:551] - INFO: load:1.63 valid_run:2912.29 task_valid:2797.86 collect_output:90.42
2023-02-21 00:58:59 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 00:58:59 - train.py[line:551] - INFO: load:1.65 valid_run:3034.14 task_valid:2914.22 collect_output:94.90
2023-02-21 01:01:02 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 01:01:02 - train.py[line:551] - INFO: load:1.68 valid_run:3157.30 task_valid:3030.33 collect_output:100.93
2023-02-21 01:03:02 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 01:03:02 - train.py[line:551] - INFO: load:1.70 valid_run:3277.26 task_valid:3144.61 collect_output:105.57
2023-02-21 01:05:05 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 01:05:05 - train.py[line:551] - INFO: load:1.73 valid_run:3399.42 task_valid:3264.25 collect_output:107.07
2023-02-21 01:07:06 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 01:07:06 - train.py[line:551] - INFO: load:1.75 valid_run:3521.16 task_valid:3380.02 collect_output:112.03
2023-02-21 01:09:09 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 01:09:09 - train.py[line:551] - INFO: load:1.78 valid_run:3643.26 task_valid:3498.82 collect_output:114.31
2023-02-21 01:11:10 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 01:11:10 - train.py[line:551] - INFO: load:1.80 valid_run:3764.51 task_valid:3617.47 collect_output:115.91

====================================================================================================
SGG eval:     R @ 50: 0.6371;     R @ 100: 0.6692;     R @ 500: 0.6910;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3905;    mR @ 100: 0.4389;    mR @ 500: 0.4864;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.5625) (covering:0.4429) (eating:0.7647) (flying in:0.3636) (growing on:0.3750) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:1.0000) (playing:0.0000) (riding:0.9696) (says:0.0000) (sitting on:0.7336) (standing on:0.3660) (using:0.6000) (walking in:0.0000) (walking on:0.7568) (watching:0.3750) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6371;     R @ 100: 0.6692;     R @ 500: 0.6910;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3905;    mR @ 100: 0.4389;    mR @ 500: 0.4864;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.5625) (covering:0.4429) (eating:0.7647) (flying in:0.3636) (growing on:0.3750) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:1.0000) (playing:0.0000) (riding:0.9696) (says:0.0000) (sitting on:0.7336) (standing on:0.3660) (using:0.6000) (walking in:0.0000) (walking on:0.7568) (watching:0.3750) 
--------------------------------------------------------
====================================================================================================

2023-02-21 01:11:41 - train.py[line:487] - INFO: 0.6692170104405398
2023-02-21 01:11:41 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 01:11:41 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.218 | loss_v1 0 | loss_v2 0 | nll_loss 0.047 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.669217 | ppl 1.03 | vqa_score 0.3198 | wps 118.1 | wpb 72 | bsz 24 | num_updates 14000 | best_R@100 0.693596
2023-02-21 01:11:41 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 14000 updates
2023-02-21 01:11:41 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_14000.pt
2023-02-21 01:11:47 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_14000.pt
2023-02-21 01:11:50 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_14000.pt (epoch 1 @ 14000 updates, score 0.6692170104405398) (writing took 8.308447439223528 seconds)
2023-02-21 01:12:01 - progress_bar.py[line:274] - INFO: epoch 001:  14026 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=110, bsz=40, num_updates=14010, lr=4.63181e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42374
2023-02-21 01:12:12 - progress_bar.py[line:274] - INFO: epoch 001:  14036 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.3, ups=0.9, wpb=112, bsz=40, num_updates=14020, lr=4.63145e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42385
2023-02-21 01:12:23 - progress_bar.py[line:274] - INFO: epoch 001:  14046 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.94, wpb=110.4, bsz=40, num_updates=14030, lr=4.63108e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42396
2023-02-21 01:12:34 - progress_bar.py[line:274] - INFO: epoch 001:  14056 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=14040, lr=4.63072e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42407
2023-02-21 01:12:45 - progress_bar.py[line:274] - INFO: epoch 001:  14066 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=14050, lr=4.63036e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42418
2023-02-21 01:12:56 - progress_bar.py[line:274] - INFO: epoch 001:  14076 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.89, wpb=108.9, bsz=40, num_updates=14060, lr=4.63e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42429
2023-02-21 01:13:07 - progress_bar.py[line:274] - INFO: epoch 001:  14086 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.5, bsz=40, num_updates=14070, lr=4.62964e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42440
2023-02-21 01:13:19 - progress_bar.py[line:274] - INFO: epoch 001:  14096 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.2, bsz=40, num_updates=14080, lr=4.62928e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42451
2023-02-21 01:13:30 - progress_bar.py[line:274] - INFO: epoch 001:  14106 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.5, ups=0.88, wpb=109.8, bsz=40, num_updates=14090, lr=4.62891e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=42463
2023-02-21 01:13:41 - progress_bar.py[line:274] - INFO: epoch 001:  14116 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=14100, lr=4.62855e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42474
2023-02-21 01:13:52 - progress_bar.py[line:274] - INFO: epoch 001:  14126 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=111.8, bsz=40, num_updates=14110, lr=4.62819e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42485
2023-02-21 01:14:03 - progress_bar.py[line:274] - INFO: epoch 001:  14136 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.7, bsz=40, num_updates=14120, lr=4.62783e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42496
2023-02-21 01:14:14 - progress_bar.py[line:274] - INFO: epoch 001:  14146 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=14130, lr=4.62747e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42507
2023-02-21 01:14:25 - progress_bar.py[line:274] - INFO: epoch 001:  14156 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.92, wpb=109.8, bsz=40, num_updates=14140, lr=4.6271e-05, gnorm=0.044, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42518
2023-02-21 01:14:36 - progress_bar.py[line:274] - INFO: epoch 001:  14166 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.6, bsz=40, num_updates=14150, lr=4.62674e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42529
2023-02-21 01:14:47 - progress_bar.py[line:274] - INFO: epoch 001:  14176 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=14160, lr=4.62638e-05, gnorm=0.099, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42540
2023-02-21 01:14:58 - progress_bar.py[line:274] - INFO: epoch 001:  14186 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=14170, lr=4.62602e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42551
2023-02-21 01:15:10 - progress_bar.py[line:274] - INFO: epoch 001:  14196 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=110.1, bsz=40, num_updates=14180, lr=4.62566e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42562
2023-02-21 01:15:21 - progress_bar.py[line:274] - INFO: epoch 001:  14206 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.89, wpb=108.8, bsz=40, num_updates=14190, lr=4.6253e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42574
2023-02-21 01:15:32 - progress_bar.py[line:274] - INFO: epoch 001:  14216 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.7, bsz=40, num_updates=14200, lr=4.62493e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42585
2023-02-21 01:15:43 - progress_bar.py[line:274] - INFO: epoch 001:  14226 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.94, wpb=109.8, bsz=40, num_updates=14210, lr=4.62457e-05, gnorm=0.077, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42596
2023-02-21 01:15:54 - progress_bar.py[line:274] - INFO: epoch 001:  14236 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.7, bsz=40, num_updates=14220, lr=4.62421e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42607
2023-02-21 01:16:05 - progress_bar.py[line:274] - INFO: epoch 001:  14246 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.1, bsz=40, num_updates=14230, lr=4.62385e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42618
2023-02-21 01:16:16 - progress_bar.py[line:274] - INFO: epoch 001:  14256 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=14240, lr=4.62349e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42629
2023-02-21 01:16:27 - progress_bar.py[line:274] - INFO: epoch 001:  14266 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.8, ups=0.91, wpb=110.8, bsz=40, num_updates=14250, lr=4.62312e-05, gnorm=0.095, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=42640
2023-02-21 01:16:38 - progress_bar.py[line:274] - INFO: epoch 001:  14276 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=14260, lr=4.62276e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42651
2023-02-21 01:16:49 - progress_bar.py[line:274] - INFO: epoch 001:  14286 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=14270, lr=4.6224e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42662
2023-02-21 01:17:01 - progress_bar.py[line:274] - INFO: epoch 001:  14296 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.9, bsz=40, num_updates=14280, lr=4.62204e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42674
2023-02-21 01:17:12 - progress_bar.py[line:274] - INFO: epoch 001:  14306 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=112.1, bsz=40, num_updates=14290, lr=4.62168e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42685
2023-02-21 01:17:24 - progress_bar.py[line:274] - INFO: epoch 001:  14316 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111, bsz=40, num_updates=14300, lr=4.62132e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42696
2023-02-21 01:17:35 - progress_bar.py[line:274] - INFO: epoch 001:  14326 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.3, bsz=40, num_updates=14310, lr=4.62095e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42707
2023-02-21 01:17:46 - progress_bar.py[line:274] - INFO: epoch 001:  14336 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=14320, lr=4.62059e-05, gnorm=0.087, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42719
2023-02-21 01:17:57 - progress_bar.py[line:274] - INFO: epoch 001:  14346 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.92, wpb=110.2, bsz=40, num_updates=14330, lr=4.62023e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42729
2023-02-21 01:18:08 - progress_bar.py[line:274] - INFO: epoch 001:  14356 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.2, ups=0.87, wpb=109.3, bsz=40, num_updates=14340, lr=4.61987e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42741
2023-02-21 01:18:19 - progress_bar.py[line:274] - INFO: epoch 001:  14366 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.2, bsz=40, num_updates=14350, lr=4.61951e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42752
2023-02-21 01:18:30 - progress_bar.py[line:274] - INFO: epoch 001:  14376 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.6, bsz=40, num_updates=14360, lr=4.61914e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42763
2023-02-21 01:18:41 - progress_bar.py[line:274] - INFO: epoch 001:  14386 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.6, bsz=40, num_updates=14370, lr=4.61878e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42774
2023-02-21 01:18:53 - progress_bar.py[line:274] - INFO: epoch 001:  14396 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=14380, lr=4.61842e-05, gnorm=0.039, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42786
2023-02-21 01:19:04 - progress_bar.py[line:274] - INFO: epoch 001:  14406 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=111.9, bsz=40, num_updates=14390, lr=4.61806e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=42797
2023-02-21 01:19:15 - progress_bar.py[line:274] - INFO: epoch 001:  14416 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.4, bsz=40, num_updates=14400, lr=4.6177e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42808
2023-02-21 01:19:26 - progress_bar.py[line:274] - INFO: epoch 001:  14426 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=14410, lr=4.61734e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42819
2023-02-21 01:19:37 - progress_bar.py[line:274] - INFO: epoch 001:  14436 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.92, wpb=109.8, bsz=40, num_updates=14420, lr=4.61697e-05, gnorm=0.088, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42830
2023-02-21 01:19:48 - progress_bar.py[line:274] - INFO: epoch 001:  14446 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.4, ups=0.92, wpb=111.8, bsz=40, num_updates=14430, lr=4.61661e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42841
2023-02-21 01:19:59 - progress_bar.py[line:274] - INFO: epoch 001:  14456 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.4, bsz=40, num_updates=14440, lr=4.61625e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42852
2023-02-21 01:20:10 - progress_bar.py[line:274] - INFO: epoch 001:  14466 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=14450, lr=4.61589e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42863
2023-02-21 01:20:21 - progress_bar.py[line:274] - INFO: epoch 001:  14476 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.92, wpb=110.2, bsz=40, num_updates=14460, lr=4.61553e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42874
2023-02-21 01:20:32 - progress_bar.py[line:274] - INFO: epoch 001:  14486 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.87, wpb=110.7, bsz=40, num_updates=14470, lr=4.61516e-05, gnorm=0.088, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42885
2023-02-21 01:20:43 - progress_bar.py[line:274] - INFO: epoch 001:  14496 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.1, bsz=40, num_updates=14480, lr=4.6148e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42896
2023-02-21 01:20:55 - progress_bar.py[line:274] - INFO: epoch 001:  14506 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.9, wpb=110.1, bsz=40, num_updates=14490, lr=4.61444e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42907
2023-02-21 01:21:06 - progress_bar.py[line:274] - INFO: epoch 001:  14516 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.87, wpb=112.8, bsz=40, num_updates=14500, lr=4.61408e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42919
2023-02-21 01:21:17 - progress_bar.py[line:274] - INFO: epoch 001:  14526 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=14510, lr=4.61372e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42930
2023-02-21 01:21:29 - progress_bar.py[line:274] - INFO: epoch 001:  14536 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=14520, lr=4.61336e-05, gnorm=0.04, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42942
2023-02-21 01:21:40 - progress_bar.py[line:274] - INFO: epoch 001:  14546 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.8, ups=0.91, wpb=112.4, bsz=40, num_updates=14530, lr=4.61299e-05, gnorm=0.106, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42953
2023-02-21 01:21:51 - progress_bar.py[line:274] - INFO: epoch 001:  14556 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.9, wpb=112.8, bsz=40, num_updates=14540, lr=4.61263e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42964
2023-02-21 01:22:02 - progress_bar.py[line:274] - INFO: epoch 001:  14566 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=14550, lr=4.61227e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42975
2023-02-21 01:22:13 - progress_bar.py[line:274] - INFO: epoch 001:  14576 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.3, bsz=40, num_updates=14560, lr=4.61191e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42986
2023-02-21 01:22:25 - progress_bar.py[line:274] - INFO: epoch 001:  14586 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=14570, lr=4.61155e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42998
2023-02-21 01:22:36 - progress_bar.py[line:274] - INFO: epoch 001:  14596 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.4, bsz=40, num_updates=14580, lr=4.61118e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43009
2023-02-21 01:22:47 - progress_bar.py[line:274] - INFO: epoch 001:  14606 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=14590, lr=4.61082e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43020
2023-02-21 01:22:59 - progress_bar.py[line:274] - INFO: epoch 001:  14616 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.7, bsz=40, num_updates=14600, lr=4.61046e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43031
2023-02-21 01:23:09 - progress_bar.py[line:274] - INFO: epoch 001:  14626 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.93, wpb=111.3, bsz=40, num_updates=14610, lr=4.6101e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43042
2023-02-21 01:23:10 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 01:23:22 - progress_bar.py[line:274] - INFO: epoch 001:  14637 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.5, ups=0.82, wpb=110.4, bsz=40, num_updates=14620, lr=4.60974e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=43054
2023-02-21 01:23:33 - progress_bar.py[line:274] - INFO: epoch 001:  14647 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.87, wpb=110.6, bsz=40, num_updates=14630, lr=4.60938e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43066
2023-02-21 01:23:44 - progress_bar.py[line:274] - INFO: epoch 001:  14657 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.2, bsz=40, num_updates=14640, lr=4.60901e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43077
2023-02-21 01:23:55 - progress_bar.py[line:274] - INFO: epoch 001:  14667 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=14650, lr=4.60865e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10, ema_decay=0.9999, wall=43088
2023-02-21 01:24:06 - progress_bar.py[line:274] - INFO: epoch 001:  14677 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.92, wpb=110.3, bsz=40, num_updates=14660, lr=4.60829e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43099
2023-02-21 01:24:17 - progress_bar.py[line:274] - INFO: epoch 001:  14687 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=110.7, bsz=40, num_updates=14670, lr=4.60793e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43110
2023-02-21 01:24:28 - progress_bar.py[line:274] - INFO: epoch 001:  14697 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.89, wpb=112.3, bsz=40, num_updates=14680, lr=4.60757e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43121
2023-02-21 01:24:39 - progress_bar.py[line:274] - INFO: epoch 001:  14707 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.5, ups=0.94, wpb=111.9, bsz=40, num_updates=14690, lr=4.6072e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43132
2023-02-21 01:24:50 - progress_bar.py[line:274] - INFO: epoch 001:  14717 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=14700, lr=4.60684e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43143
2023-02-21 01:25:02 - progress_bar.py[line:274] - INFO: epoch 001:  14727 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=14710, lr=4.60648e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43154
2023-02-21 01:25:13 - progress_bar.py[line:274] - INFO: epoch 001:  14737 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=14720, lr=4.60612e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43166
2023-02-21 01:25:24 - progress_bar.py[line:274] - INFO: epoch 001:  14747 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=14730, lr=4.60576e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43177
2023-02-21 01:25:35 - progress_bar.py[line:274] - INFO: epoch 001:  14757 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=111.1, bsz=40, num_updates=14740, lr=4.6054e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43188
2023-02-21 01:25:46 - progress_bar.py[line:274] - INFO: epoch 001:  14767 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.93, wpb=112.4, bsz=40, num_updates=14750, lr=4.60503e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43199
2023-02-21 01:25:57 - progress_bar.py[line:274] - INFO: epoch 001:  14777 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=14760, lr=4.60467e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43210
2023-02-21 01:26:08 - progress_bar.py[line:274] - INFO: epoch 001:  14787 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.93, wpb=110.6, bsz=40, num_updates=14770, lr=4.60431e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43221
2023-02-21 01:26:19 - progress_bar.py[line:274] - INFO: epoch 001:  14797 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.3, bsz=40, num_updates=14780, lr=4.60395e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43232
2023-02-21 01:26:30 - progress_bar.py[line:274] - INFO: epoch 001:  14807 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.9, bsz=40, num_updates=14790, lr=4.60359e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43243
2023-02-21 01:26:41 - progress_bar.py[line:274] - INFO: epoch 001:  14817 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.3, bsz=40, num_updates=14800, lr=4.60322e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43254
2023-02-21 01:26:52 - progress_bar.py[line:274] - INFO: epoch 001:  14827 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=112, bsz=40, num_updates=14810, lr=4.60286e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43265
2023-02-21 01:27:03 - progress_bar.py[line:274] - INFO: epoch 001:  14837 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=111, bsz=40, num_updates=14820, lr=4.6025e-05, gnorm=0.047, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43276
2023-02-21 01:27:14 - progress_bar.py[line:274] - INFO: epoch 001:  14847 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.6, bsz=40, num_updates=14830, lr=4.60214e-05, gnorm=0.049, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43287
2023-02-21 01:27:25 - progress_bar.py[line:274] - INFO: epoch 001:  14857 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.92, wpb=109.7, bsz=40, num_updates=14840, lr=4.60178e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=43298
2023-02-21 01:27:36 - progress_bar.py[line:274] - INFO: epoch 001:  14867 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=14850, lr=4.60142e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43309
2023-02-21 01:27:47 - progress_bar.py[line:274] - INFO: epoch 001:  14877 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.5, bsz=40, num_updates=14860, lr=4.60105e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43320
2023-02-21 01:27:58 - progress_bar.py[line:274] - INFO: epoch 001:  14887 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.6, bsz=40, num_updates=14870, lr=4.60069e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43331
2023-02-21 01:28:10 - progress_bar.py[line:274] - INFO: epoch 001:  14897 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112.3, bsz=40, num_updates=14880, lr=4.60033e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43343
2023-02-21 01:28:21 - progress_bar.py[line:274] - INFO: epoch 001:  14907 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.6, bsz=40, num_updates=14890, lr=4.59997e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43354
2023-02-21 01:28:33 - progress_bar.py[line:274] - INFO: epoch 001:  14917 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=112.3, bsz=40, num_updates=14900, lr=4.59961e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43366
2023-02-21 01:28:44 - progress_bar.py[line:274] - INFO: epoch 001:  14927 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.5, bsz=40, num_updates=14910, lr=4.59924e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43377
2023-02-21 01:28:55 - progress_bar.py[line:274] - INFO: epoch 001:  14937 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.4, bsz=40, num_updates=14920, lr=4.59888e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43388
2023-02-21 01:29:06 - progress_bar.py[line:274] - INFO: epoch 001:  14947 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112.6, bsz=40, num_updates=14930, lr=4.59852e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43399
2023-02-21 01:29:17 - progress_bar.py[line:274] - INFO: epoch 001:  14957 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=14940, lr=4.59816e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43410
2023-02-21 01:29:29 - progress_bar.py[line:274] - INFO: epoch 001:  14967 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=14950, lr=4.5978e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43422
2023-02-21 01:29:40 - progress_bar.py[line:274] - INFO: epoch 001:  14977 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=14960, lr=4.59744e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43433
2023-02-21 01:29:51 - progress_bar.py[line:274] - INFO: epoch 001:  14987 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.4, bsz=40, num_updates=14970, lr=4.59707e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43444
2023-02-21 01:30:02 - progress_bar.py[line:274] - INFO: epoch 001:  14997 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.8, bsz=40, num_updates=14980, lr=4.59671e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43455
2023-02-21 01:30:13 - progress_bar.py[line:274] - INFO: epoch 001:  15007 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.92, wpb=110.1, bsz=40, num_updates=14990, lr=4.59635e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43466
2023-02-21 01:30:24 - progress_bar.py[line:274] - INFO: epoch 001:  15017 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.9, wpb=111.7, bsz=40, num_updates=15000, lr=4.59599e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43477
2023-02-21 01:30:35 - progress_bar.py[line:274] - INFO: epoch 001:  15027 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.2, bsz=40, num_updates=15010, lr=4.59563e-05, gnorm=0.049, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43488
2023-02-21 01:30:46 - progress_bar.py[line:274] - INFO: epoch 001:  15037 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.4, bsz=40, num_updates=15020, lr=4.59526e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43499
2023-02-21 01:30:57 - progress_bar.py[line:274] - INFO: epoch 001:  15047 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=110.5, bsz=40, num_updates=15030, lr=4.5949e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43510
2023-02-21 01:31:09 - progress_bar.py[line:274] - INFO: epoch 001:  15057 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.6, bsz=40, num_updates=15040, lr=4.59454e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43522
2023-02-21 01:31:20 - progress_bar.py[line:274] - INFO: epoch 001:  15067 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=15050, lr=4.59418e-05, gnorm=0.107, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43533
2023-02-21 01:31:31 - progress_bar.py[line:274] - INFO: epoch 001:  15077 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=110.5, bsz=40, num_updates=15060, lr=4.59382e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43544
2023-02-21 01:31:42 - progress_bar.py[line:274] - INFO: epoch 001:  15087 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.88, wpb=109.7, bsz=40, num_updates=15070, lr=4.59346e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43555
2023-02-21 01:31:54 - progress_bar.py[line:274] - INFO: epoch 001:  15097 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.89, wpb=112.5, bsz=40, num_updates=15080, lr=4.59309e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43566
2023-02-21 01:32:05 - progress_bar.py[line:274] - INFO: epoch 001:  15107 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=15090, lr=4.59273e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43577
2023-02-21 01:32:16 - progress_bar.py[line:274] - INFO: epoch 001:  15117 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=113, bsz=40, num_updates=15100, lr=4.59237e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=43588
2023-02-21 01:32:27 - progress_bar.py[line:274] - INFO: epoch 001:  15127 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=15110, lr=4.59201e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43600
2023-02-21 01:32:38 - progress_bar.py[line:274] - INFO: epoch 001:  15137 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.91, wpb=109, bsz=40, num_updates=15120, lr=4.59165e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43611
2023-02-21 01:32:49 - progress_bar.py[line:274] - INFO: epoch 001:  15147 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=109.8, bsz=40, num_updates=15130, lr=4.59128e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43622
2023-02-21 01:33:01 - progress_bar.py[line:274] - INFO: epoch 001:  15157 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.87, wpb=110.2, bsz=40, num_updates=15140, lr=4.59092e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43633
2023-02-21 01:33:12 - progress_bar.py[line:274] - INFO: epoch 001:  15167 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.1, bsz=40, num_updates=15150, lr=4.59056e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43645
2023-02-21 01:33:23 - progress_bar.py[line:274] - INFO: epoch 001:  15177 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.1, bsz=40, num_updates=15160, lr=4.5902e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43656
2023-02-21 01:33:34 - progress_bar.py[line:274] - INFO: epoch 001:  15187 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.7, bsz=40, num_updates=15170, lr=4.58984e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43667
2023-02-21 01:33:45 - progress_bar.py[line:274] - INFO: epoch 001:  15197 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.4, bsz=40, num_updates=15180, lr=4.58948e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43678
2023-02-21 01:33:46 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 01:33:58 - progress_bar.py[line:274] - INFO: epoch 001:  15208 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=86.6, ups=0.79, wpb=109.9, bsz=40, num_updates=15190, lr=4.58911e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=43691
2023-02-21 01:34:09 - progress_bar.py[line:274] - INFO: epoch 001:  15218 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.3, bsz=40, num_updates=15200, lr=4.58875e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43702
2023-02-21 01:34:20 - progress_bar.py[line:274] - INFO: epoch 001:  15228 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.6, bsz=40, num_updates=15210, lr=4.58839e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43713
2023-02-21 01:34:32 - progress_bar.py[line:274] - INFO: epoch 001:  15238 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.5, ups=0.87, wpb=110.6, bsz=40, num_updates=15220, lr=4.58803e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43725
2023-02-21 01:34:43 - progress_bar.py[line:274] - INFO: epoch 001:  15248 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.9, bsz=40, num_updates=15230, lr=4.58767e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43736
2023-02-21 01:34:54 - progress_bar.py[line:274] - INFO: epoch 001:  15258 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=15240, lr=4.5873e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43747
2023-02-21 01:35:05 - progress_bar.py[line:274] - INFO: epoch 001:  15268 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=15250, lr=4.58694e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43758
2023-02-21 01:35:16 - progress_bar.py[line:274] - INFO: epoch 001:  15278 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.7, ups=0.92, wpb=110.5, bsz=40, num_updates=15260, lr=4.58658e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43769
2023-02-21 01:35:27 - progress_bar.py[line:274] - INFO: epoch 001:  15288 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.7, bsz=40, num_updates=15270, lr=4.58622e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43780
2023-02-21 01:35:39 - progress_bar.py[line:274] - INFO: epoch 001:  15298 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.5, ups=0.88, wpb=109.7, bsz=40, num_updates=15280, lr=4.58586e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43792
2023-02-21 01:35:50 - progress_bar.py[line:274] - INFO: epoch 001:  15308 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.8, ups=0.92, wpb=110.9, bsz=40, num_updates=15290, lr=4.5855e-05, gnorm=0.129, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43802
2023-02-21 01:36:01 - progress_bar.py[line:274] - INFO: epoch 001:  15318 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=15300, lr=4.58513e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43814
2023-02-21 01:36:12 - progress_bar.py[line:274] - INFO: epoch 001:  15328 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=15310, lr=4.58477e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43825
2023-02-21 01:36:23 - progress_bar.py[line:274] - INFO: epoch 001:  15338 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.5, ups=0.93, wpb=111.1, bsz=40, num_updates=15320, lr=4.58441e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43836
2023-02-21 01:36:34 - progress_bar.py[line:274] - INFO: epoch 001:  15348 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=110.6, bsz=40, num_updates=15330, lr=4.58405e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43847
2023-02-21 01:36:45 - progress_bar.py[line:274] - INFO: epoch 001:  15358 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=112.1, bsz=40, num_updates=15340, lr=4.58369e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43858
2023-02-21 01:36:56 - progress_bar.py[line:274] - INFO: epoch 001:  15368 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.7, bsz=40, num_updates=15350, lr=4.58332e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43869
2023-02-21 01:37:07 - progress_bar.py[line:274] - INFO: epoch 001:  15378 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=15360, lr=4.58296e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43880
2023-02-21 01:37:18 - progress_bar.py[line:274] - INFO: epoch 001:  15388 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.3, ups=0.91, wpb=111.6, bsz=40, num_updates=15370, lr=4.5826e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43891
2023-02-21 01:37:29 - progress_bar.py[line:274] - INFO: epoch 001:  15398 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=15380, lr=4.58224e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=43902
2023-02-21 01:37:40 - progress_bar.py[line:274] - INFO: epoch 001:  15408 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=15390, lr=4.58188e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43913
2023-02-21 01:37:52 - progress_bar.py[line:274] - INFO: epoch 001:  15418 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=15400, lr=4.58152e-05, gnorm=0.1, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43924
2023-02-21 01:38:03 - progress_bar.py[line:274] - INFO: epoch 001:  15428 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=15410, lr=4.58115e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43935
2023-02-21 01:38:14 - progress_bar.py[line:274] - INFO: epoch 001:  15438 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=15420, lr=4.58079e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43947
2023-02-21 01:38:25 - progress_bar.py[line:274] - INFO: epoch 001:  15448 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=15430, lr=4.58043e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43958
2023-02-21 01:38:36 - progress_bar.py[line:274] - INFO: epoch 001:  15458 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111.1, bsz=40, num_updates=15440, lr=4.58007e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43969
2023-02-21 01:38:47 - progress_bar.py[line:274] - INFO: epoch 001:  15468 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.7, bsz=40, num_updates=15450, lr=4.57971e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43980
2023-02-21 01:38:59 - progress_bar.py[line:274] - INFO: epoch 001:  15478 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=15460, lr=4.57934e-05, gnorm=0.047, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43991
2023-02-21 01:39:09 - progress_bar.py[line:274] - INFO: epoch 001:  15488 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.93, wpb=110.7, bsz=40, num_updates=15470, lr=4.57898e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44002
2023-02-21 01:39:21 - progress_bar.py[line:274] - INFO: epoch 001:  15498 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.7, bsz=40, num_updates=15480, lr=4.57862e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44014
2023-02-21 01:39:32 - progress_bar.py[line:274] - INFO: epoch 001:  15508 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=15490, lr=4.57826e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44025
2023-02-21 01:39:43 - progress_bar.py[line:274] - INFO: epoch 001:  15518 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.2, bsz=40, num_updates=15500, lr=4.5779e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44036
2023-02-21 01:39:54 - progress_bar.py[line:274] - INFO: epoch 001:  15528 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111, bsz=40, num_updates=15510, lr=4.57754e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44047
2023-02-21 01:40:06 - progress_bar.py[line:274] - INFO: epoch 001:  15538 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=110.4, bsz=40, num_updates=15520, lr=4.57717e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=44058
2023-02-21 01:40:17 - progress_bar.py[line:274] - INFO: epoch 001:  15548 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=15530, lr=4.57681e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44070
2023-02-21 01:40:28 - progress_bar.py[line:274] - INFO: epoch 001:  15558 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.7, bsz=40, num_updates=15540, lr=4.57645e-05, gnorm=0.045, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44081
2023-02-21 01:40:39 - progress_bar.py[line:274] - INFO: epoch 001:  15568 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=110.9, bsz=40, num_updates=15550, lr=4.57609e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44092
2023-02-21 01:40:50 - progress_bar.py[line:274] - INFO: epoch 001:  15578 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.93, wpb=110.8, bsz=40, num_updates=15560, lr=4.57573e-05, gnorm=0.046, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44103
2023-02-21 01:41:01 - progress_bar.py[line:274] - INFO: epoch 001:  15588 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=110.7, bsz=40, num_updates=15570, lr=4.57536e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44114
2023-02-21 01:41:13 - progress_bar.py[line:274] - INFO: epoch 001:  15598 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=15580, lr=4.575e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44125
2023-02-21 01:41:24 - progress_bar.py[line:274] - INFO: epoch 001:  15608 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=15590, lr=4.57464e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44136
2023-02-21 01:41:35 - progress_bar.py[line:274] - INFO: epoch 001:  15618 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.3, bsz=40, num_updates=15600, lr=4.57428e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44148
2023-02-21 01:41:46 - progress_bar.py[line:274] - INFO: epoch 001:  15628 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.6, bsz=40, num_updates=15610, lr=4.57392e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44159
2023-02-21 01:41:57 - progress_bar.py[line:274] - INFO: epoch 001:  15638 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=15620, lr=4.57356e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44170
2023-02-21 01:42:08 - progress_bar.py[line:274] - INFO: epoch 001:  15648 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.92, wpb=112.2, bsz=40, num_updates=15630, lr=4.57319e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=44181
2023-02-21 01:42:19 - progress_bar.py[line:274] - INFO: epoch 001:  15658 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.93, wpb=111.4, bsz=40, num_updates=15640, lr=4.57283e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44192
2023-02-21 01:42:30 - progress_bar.py[line:274] - INFO: epoch 001:  15668 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.9, bsz=40, num_updates=15650, lr=4.57247e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44203
2023-02-21 01:42:41 - progress_bar.py[line:274] - INFO: epoch 001:  15678 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.1, ups=0.92, wpb=111.3, bsz=40, num_updates=15660, lr=4.57211e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44214
2023-02-21 01:42:52 - progress_bar.py[line:274] - INFO: epoch 001:  15688 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=15670, lr=4.57175e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44225
2023-02-21 01:43:04 - progress_bar.py[line:274] - INFO: epoch 001:  15698 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=15680, lr=4.57138e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44236
2023-02-21 01:43:15 - progress_bar.py[line:274] - INFO: epoch 001:  15708 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.9, wpb=110.5, bsz=40, num_updates=15690, lr=4.57102e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44248
2023-02-21 01:43:26 - progress_bar.py[line:274] - INFO: epoch 001:  15718 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.3, bsz=40, num_updates=15700, lr=4.57066e-05, gnorm=0.045, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44259
2023-02-21 01:43:37 - progress_bar.py[line:274] - INFO: epoch 001:  15728 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.5, bsz=40, num_updates=15710, lr=4.5703e-05, gnorm=0.077, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44270
2023-02-21 01:43:48 - progress_bar.py[line:274] - INFO: epoch 001:  15738 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.4, ups=0.89, wpb=110, bsz=40, num_updates=15720, lr=4.56994e-05, gnorm=0.076, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44281
2023-02-21 01:43:59 - progress_bar.py[line:274] - INFO: epoch 001:  15748 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.2, bsz=40, num_updates=15730, lr=4.56958e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44292
2023-02-21 01:44:11 - progress_bar.py[line:274] - INFO: epoch 001:  15758 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=15740, lr=4.56921e-05, gnorm=0.044, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44303
2023-02-21 01:44:22 - progress_bar.py[line:274] - INFO: epoch 001:  15768 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=15750, lr=4.56885e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44314
2023-02-21 01:44:33 - progress_bar.py[line:274] - INFO: epoch 001:  15778 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111.2, bsz=40, num_updates=15760, lr=4.56849e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44325
2023-02-21 01:44:44 - progress_bar.py[line:274] - INFO: epoch 001:  15788 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=112.1, bsz=40, num_updates=15770, lr=4.56813e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44337
2023-02-21 01:44:55 - progress_bar.py[line:274] - INFO: epoch 001:  15798 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112, bsz=40, num_updates=15780, lr=4.56777e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44348
2023-02-21 01:45:06 - progress_bar.py[line:274] - INFO: epoch 001:  15808 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.7, bsz=40, num_updates=15790, lr=4.5674e-05, gnorm=0.076, clip=0, loss_scale=8192, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=44359
2023-02-21 01:45:18 - progress_bar.py[line:274] - INFO: epoch 001:  15818 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.5, bsz=40, num_updates=15800, lr=4.56704e-05, gnorm=0.076, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44370
2023-02-21 01:45:29 - progress_bar.py[line:274] - INFO: epoch 001:  15828 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=15810, lr=4.56668e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44381
2023-02-21 01:45:40 - progress_bar.py[line:274] - INFO: epoch 001:  15838 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.87, wpb=112.8, bsz=40, num_updates=15820, lr=4.56632e-05, gnorm=0.086, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44393
2023-02-21 01:45:51 - progress_bar.py[line:274] - INFO: epoch 001:  15848 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=15830, lr=4.56596e-05, gnorm=0.103, clip=0, loss_scale=8192, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44404
2023-02-21 01:46:02 - progress_bar.py[line:274] - INFO: epoch 001:  15858 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.5, bsz=40, num_updates=15840, lr=4.56559e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44415
2023-02-21 01:46:08 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 01:46:14 - progress_bar.py[line:274] - INFO: epoch 001:  15869 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.3, ups=0.84, wpb=110, bsz=40, num_updates=15850, lr=4.56523e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=44427
2023-02-21 01:46:25 - progress_bar.py[line:274] - INFO: epoch 001:  15879 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.1, bsz=40, num_updates=15860, lr=4.56487e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44438
2023-02-21 01:46:36 - progress_bar.py[line:274] - INFO: epoch 001:  15889 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=15870, lr=4.56451e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44449
2023-02-21 01:46:48 - progress_bar.py[line:274] - INFO: epoch 001:  15899 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.7, bsz=40, num_updates=15880, lr=4.56415e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44460
2023-02-21 01:46:59 - progress_bar.py[line:274] - INFO: epoch 001:  15909 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110.1, bsz=40, num_updates=15890, lr=4.56379e-05, gnorm=0.044, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44472
2023-02-21 01:47:10 - progress_bar.py[line:274] - INFO: epoch 001:  15919 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=15900, lr=4.56342e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44483
2023-02-21 01:47:21 - progress_bar.py[line:274] - INFO: epoch 001:  15929 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=15910, lr=4.56306e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44494
2023-02-21 01:47:32 - progress_bar.py[line:274] - INFO: epoch 001:  15939 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.3, bsz=40, num_updates=15920, lr=4.5627e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44505
2023-02-21 01:47:44 - progress_bar.py[line:274] - INFO: epoch 001:  15949 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95, ups=0.86, wpb=111, bsz=40, num_updates=15930, lr=4.56234e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=44517
2023-02-21 01:47:55 - progress_bar.py[line:274] - INFO: epoch 001:  15959 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=15940, lr=4.56198e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44528
2023-02-21 01:48:06 - progress_bar.py[line:274] - INFO: epoch 001:  15969 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.6, bsz=40, num_updates=15950, lr=4.56161e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44539
2023-02-21 01:48:18 - progress_bar.py[line:274] - INFO: epoch 001:  15979 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=15960, lr=4.56125e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44550
2023-02-21 01:48:29 - progress_bar.py[line:274] - INFO: epoch 001:  15989 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.87, wpb=110.4, bsz=40, num_updates=15970, lr=4.56089e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44562
2023-02-21 01:48:40 - progress_bar.py[line:274] - INFO: epoch 001:  15999 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=15980, lr=4.56053e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44573
2023-02-21 01:48:51 - progress_bar.py[line:274] - INFO: epoch 001:  16009 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110.7, bsz=40, num_updates=15990, lr=4.56017e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44584
2023-02-21 01:49:02 - progress_bar.py[line:274] - INFO: epoch 001:  16019 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.7, bsz=40, num_updates=16000, lr=4.55981e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44595
2023-02-21 01:49:02 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 01:49:04 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 01:49:04 - train.py[line:551] - INFO: load:1.25 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 01:51:06 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 01:51:06 - train.py[line:551] - INFO: load:1.27 valid_run:122.29 task_valid:119.07 collect_output:2.20
2023-02-21 01:53:06 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 01:53:06 - train.py[line:551] - INFO: load:1.30 valid_run:242.12 task_valid:234.95 collect_output:5.12
2023-02-21 01:55:08 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 01:55:08 - train.py[line:551] - INFO: load:1.32 valid_run:364.00 task_valid:351.49 collect_output:9.45
2023-02-21 01:57:10 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 01:57:10 - train.py[line:551] - INFO: load:1.35 valid_run:485.85 task_valid:465.39 collect_output:16.37
2023-02-21 01:59:10 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 01:59:10 - train.py[line:551] - INFO: load:1.37 valid_run:606.33 task_valid:582.99 collect_output:18.24
2023-02-21 02:01:13 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 02:01:13 - train.py[line:551] - INFO: load:1.40 valid_run:729.29 task_valid:701.84 collect_output:21.33
2023-02-21 02:03:17 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 02:03:17 - train.py[line:551] - INFO: load:1.42 valid_run:852.46 task_valid:820.35 collect_output:24.98
2023-02-21 02:05:18 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 02:05:18 - train.py[line:551] - INFO: load:1.45 valid_run:974.20 task_valid:936.97 collect_output:29.08
2023-02-21 02:07:22 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 02:07:22 - train.py[line:551] - INFO: load:1.47 valid_run:1097.85 task_valid:1054.35 collect_output:34.34
2023-02-21 02:09:24 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 02:09:24 - train.py[line:551] - INFO: load:1.50 valid_run:1219.53 task_valid:1167.11 collect_output:42.24
2023-02-21 02:11:24 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 02:11:24 - train.py[line:551] - INFO: load:1.52 valid_run:1339.68 task_valid:1282.97 collect_output:45.51
2023-02-21 02:13:26 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 02:13:26 - train.py[line:551] - INFO: load:1.55 valid_run:1461.26 task_valid:1400.23 collect_output:48.81
2023-02-21 02:15:25 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 02:15:25 - train.py[line:551] - INFO: load:1.57 valid_run:1580.09 task_valid:1514.07 collect_output:52.79
2023-02-21 02:17:26 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 02:17:26 - train.py[line:551] - INFO: load:1.60 valid_run:1701.13 task_valid:1631.98 collect_output:54.90
2023-02-21 02:19:27 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 02:19:27 - train.py[line:551] - INFO: load:1.62 valid_run:1822.17 task_valid:1748.23 collect_output:58.66
2023-02-21 02:21:28 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 02:21:28 - train.py[line:551] - INFO: load:1.65 valid_run:1943.22 task_valid:1862.40 collect_output:64.51
2023-02-21 02:23:29 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 02:23:29 - train.py[line:551] - INFO: load:1.68 valid_run:2064.74 task_valid:1978.80 collect_output:68.61
2023-02-21 02:25:30 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 02:25:30 - train.py[line:551] - INFO: load:1.70 valid_run:2185.50 task_valid:2096.87 collect_output:70.27
2023-02-21 02:27:32 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 02:27:32 - train.py[line:551] - INFO: load:1.73 valid_run:2306.81 task_valid:2214.03 collect_output:73.41
2023-02-21 02:29:32 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 02:29:32 - train.py[line:551] - INFO: load:1.76 valid_run:2427.21 task_valid:2330.80 collect_output:76.03
2023-02-21 02:31:34 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 02:31:34 - train.py[line:551] - INFO: load:1.78 valid_run:2548.84 task_valid:2447.43 collect_output:80.02
2023-02-21 02:33:36 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 02:33:36 - train.py[line:551] - INFO: load:1.81 valid_run:2671.07 task_valid:2566.74 collect_output:81.93
2023-02-21 02:35:36 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 02:35:36 - train.py[line:551] - INFO: load:1.84 valid_run:2791.34 task_valid:2681.20 collect_output:86.73
2023-02-21 02:37:36 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 02:37:36 - train.py[line:551] - INFO: load:1.86 valid_run:2911.14 task_valid:2797.52 collect_output:89.19
2023-02-21 02:39:38 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 02:39:38 - train.py[line:551] - INFO: load:1.89 valid_run:3032.81 task_valid:2914.01 collect_output:93.35
2023-02-21 02:41:41 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 02:41:41 - train.py[line:551] - INFO: load:1.92 valid_run:3155.48 task_valid:3030.10 collect_output:98.92
2023-02-21 02:43:40 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 02:43:40 - train.py[line:551] - INFO: load:1.94 valid_run:3274.88 task_valid:3144.41 collect_output:103.02
2023-02-21 02:45:42 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 02:45:42 - train.py[line:551] - INFO: load:1.97 valid_run:3396.90 task_valid:3264.18 collect_output:104.27
2023-02-21 02:47:44 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 02:47:44 - train.py[line:551] - INFO: load:2.00 valid_run:3518.49 task_valid:3379.77 collect_output:109.25
2023-02-21 02:49:46 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 02:49:46 - train.py[line:551] - INFO: load:2.02 valid_run:3640.64 task_valid:3498.36 collect_output:111.79
2023-02-21 02:51:47 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 02:51:47 - train.py[line:551] - INFO: load:2.05 valid_run:3761.91 task_valid:3617.09 collect_output:113.32

====================================================================================================
SGG eval:     R @ 50: 0.6237;     R @ 100: 0.6573;     R @ 500: 0.6817;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3770;    mR @ 100: 0.4088;    mR @ 500: 0.4520;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.5625) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.3750) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:1.0000) (playing:0.0000) (riding:0.9696) (says:0.0000) (sitting on:0.7245) (standing on:0.3493) (using:0.6000) (walking in:0.0000) (walking on:0.7297) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6237;     R @ 100: 0.6573;     R @ 500: 0.6817;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3770;    mR @ 100: 0.4088;    mR @ 500: 0.4520;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.5625) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.3750) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:1.0000) (playing:0.0000) (riding:0.9696) (says:0.0000) (sitting on:0.7245) (standing on:0.3493) (using:0.6000) (walking in:0.0000) (walking on:0.7297) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-02-21 02:52:19 - train.py[line:487] - INFO: 0.6572624649859944
2023-02-21 02:52:19 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 02:52:19 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.217 | loss_v1 0 | loss_v2 0 | nll_loss 0.045 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.657262 | ppl 1.03 | vqa_score 0.3176 | wps 118.2 | wpb 72 | bsz 24 | num_updates 16000 | best_R@100 0.693596
2023-02-21 02:52:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 16000 updates
2023-02-21 02:52:19 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_16000.pt
2023-02-21 02:52:24 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_16000.pt
2023-02-21 02:52:27 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_16000.pt (epoch 1 @ 16000 updates, score 0.6572624649859944) (writing took 8.113029334694147 seconds)
2023-02-21 02:52:38 - progress_bar.py[line:274] - INFO: epoch 001:  16029 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=111.4, bsz=40, num_updates=16010, lr=4.55944e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48411
2023-02-21 02:52:49 - progress_bar.py[line:274] - INFO: epoch 001:  16039 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.88, wpb=109.1, bsz=40, num_updates=16020, lr=4.55908e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48422
2023-02-21 02:53:00 - progress_bar.py[line:274] - INFO: epoch 001:  16049 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=16030, lr=4.55872e-05, gnorm=0.047, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48433
2023-02-21 02:53:11 - progress_bar.py[line:274] - INFO: epoch 001:  16059 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.93, wpb=110.4, bsz=40, num_updates=16040, lr=4.55836e-05, gnorm=0.049, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48444
2023-02-21 02:53:22 - progress_bar.py[line:274] - INFO: epoch 001:  16069 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.1, bsz=40, num_updates=16050, lr=4.558e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48455
2023-02-21 02:53:33 - progress_bar.py[line:274] - INFO: epoch 001:  16079 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=113.2, bsz=40, num_updates=16060, lr=4.55763e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48466
2023-02-21 02:53:44 - progress_bar.py[line:274] - INFO: epoch 001:  16089 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.92, wpb=110.3, bsz=40, num_updates=16070, lr=4.55727e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48477
2023-02-21 02:53:55 - progress_bar.py[line:274] - INFO: epoch 001:  16099 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112.2, bsz=40, num_updates=16080, lr=4.55691e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48488
2023-02-21 02:54:06 - progress_bar.py[line:274] - INFO: epoch 001:  16109 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.4, bsz=40, num_updates=16090, lr=4.55655e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48499
2023-02-21 02:54:18 - progress_bar.py[line:274] - INFO: epoch 001:  16119 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=16100, lr=4.55619e-05, gnorm=0.098, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=48510
2023-02-21 02:54:29 - progress_bar.py[line:274] - INFO: epoch 001:  16129 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.89, wpb=112.6, bsz=40, num_updates=16110, lr=4.55583e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48522
2023-02-21 02:54:40 - progress_bar.py[line:274] - INFO: epoch 001:  16139 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=16120, lr=4.55546e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=48533
2023-02-21 02:54:51 - progress_bar.py[line:274] - INFO: epoch 001:  16149 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.4, bsz=40, num_updates=16130, lr=4.5551e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48544
2023-02-21 02:55:02 - progress_bar.py[line:274] - INFO: epoch 001:  16159 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.7, ups=0.94, wpb=111, bsz=40, num_updates=16140, lr=4.55474e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48554
2023-02-21 02:55:13 - progress_bar.py[line:274] - INFO: epoch 001:  16169 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.7, bsz=40, num_updates=16150, lr=4.55438e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48566
2023-02-21 02:55:24 - progress_bar.py[line:274] - INFO: epoch 001:  16179 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.9, wpb=109.7, bsz=40, num_updates=16160, lr=4.55402e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48577
2023-02-21 02:55:35 - progress_bar.py[line:274] - INFO: epoch 001:  16189 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=16170, lr=4.55365e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48588
2023-02-21 02:55:46 - progress_bar.py[line:274] - INFO: epoch 001:  16199 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=112.5, bsz=40, num_updates=16180, lr=4.55329e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48599
2023-02-21 02:55:57 - progress_bar.py[line:274] - INFO: epoch 001:  16209 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.2, bsz=40, num_updates=16190, lr=4.55293e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=48610
2023-02-21 02:56:08 - progress_bar.py[line:274] - INFO: epoch 001:  16219 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.5, bsz=40, num_updates=16200, lr=4.55257e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48621
2023-02-21 02:56:19 - progress_bar.py[line:274] - INFO: epoch 001:  16229 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=16210, lr=4.55221e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=48632
2023-02-21 02:56:30 - progress_bar.py[line:274] - INFO: epoch 001:  16239 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=16220, lr=4.55185e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48643
2023-02-21 02:56:41 - progress_bar.py[line:274] - INFO: epoch 001:  16249 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=16230, lr=4.55148e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48654
2023-02-21 02:56:52 - progress_bar.py[line:274] - INFO: epoch 001:  16259 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.5, bsz=40, num_updates=16240, lr=4.55112e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48665
2023-02-21 02:57:03 - progress_bar.py[line:274] - INFO: epoch 001:  16269 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.4, bsz=40, num_updates=16250, lr=4.55076e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48676
2023-02-21 02:57:15 - progress_bar.py[line:274] - INFO: epoch 001:  16279 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.87, wpb=110.2, bsz=40, num_updates=16260, lr=4.5504e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48688
2023-02-21 02:57:26 - progress_bar.py[line:274] - INFO: epoch 001:  16289 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=16270, lr=4.55004e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48699
2023-02-21 02:57:37 - progress_bar.py[line:274] - INFO: epoch 001:  16299 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=16280, lr=4.54967e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48710
2023-02-21 02:57:48 - progress_bar.py[line:274] - INFO: epoch 001:  16309 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.4, ups=0.89, wpb=109.1, bsz=40, num_updates=16290, lr=4.54931e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48721
2023-02-21 02:58:00 - progress_bar.py[line:274] - INFO: epoch 001:  16319 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.3, bsz=40, num_updates=16300, lr=4.54895e-05, gnorm=0.099, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=48733
2023-02-21 02:58:11 - progress_bar.py[line:274] - INFO: epoch 001:  16329 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.5, bsz=40, num_updates=16310, lr=4.54859e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48744
2023-02-21 02:58:23 - progress_bar.py[line:274] - INFO: epoch 001:  16339 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112.3, bsz=40, num_updates=16320, lr=4.54823e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=48755
2023-02-21 02:58:34 - progress_bar.py[line:274] - INFO: epoch 001:  16349 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112.3, bsz=40, num_updates=16330, lr=4.54787e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48767
2023-02-21 02:58:45 - progress_bar.py[line:274] - INFO: epoch 001:  16359 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.89, wpb=111.5, bsz=40, num_updates=16340, lr=4.5475e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=48778
2023-02-21 02:58:56 - progress_bar.py[line:274] - INFO: epoch 001:  16369 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=110, bsz=40, num_updates=16350, lr=4.54714e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=48789
2023-02-21 02:59:07 - progress_bar.py[line:274] - INFO: epoch 001:  16379 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.7, bsz=40, num_updates=16360, lr=4.54678e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=48800
2023-02-21 02:59:19 - progress_bar.py[line:274] - INFO: epoch 001:  16389 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.2, bsz=40, num_updates=16370, lr=4.54642e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=48812
2023-02-21 02:59:30 - progress_bar.py[line:274] - INFO: epoch 001:  16399 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.7, bsz=40, num_updates=16380, lr=4.54606e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=48822
2023-02-21 02:59:41 - progress_bar.py[line:274] - INFO: epoch 001:  16409 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=16390, lr=4.54569e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48834
2023-02-21 02:59:52 - progress_bar.py[line:274] - INFO: epoch 001:  16419 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=16400, lr=4.54533e-05, gnorm=0.083, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48845
2023-02-21 03:00:03 - progress_bar.py[line:274] - INFO: epoch 001:  16429 / 142023 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.7, ups=0.88, wpb=111, bsz=40, num_updates=16410, lr=4.54497e-05, gnorm=0.11, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48856
2023-02-21 03:00:14 - progress_bar.py[line:274] - INFO: epoch 001:  16439 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.8, ups=0.92, wpb=111.1, bsz=40, num_updates=16420, lr=4.54461e-05, gnorm=0.128, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48867
2023-02-21 03:00:25 - progress_bar.py[line:274] - INFO: epoch 001:  16449 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.6, bsz=40, num_updates=16430, lr=4.54425e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48878
2023-02-21 03:00:36 - progress_bar.py[line:274] - INFO: epoch 001:  16459 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111.1, bsz=40, num_updates=16440, lr=4.54389e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48889
2023-02-21 03:00:47 - progress_bar.py[line:274] - INFO: epoch 001:  16469 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.92, wpb=110.9, bsz=40, num_updates=16450, lr=4.54352e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=48900
2023-02-21 03:00:58 - progress_bar.py[line:274] - INFO: epoch 001:  16479 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.91, wpb=109.9, bsz=40, num_updates=16460, lr=4.54316e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48911
2023-02-21 03:01:09 - progress_bar.py[line:274] - INFO: epoch 001:  16489 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.9, wpb=110.3, bsz=40, num_updates=16470, lr=4.5428e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48922
2023-02-21 03:01:21 - progress_bar.py[line:274] - INFO: epoch 001:  16499 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=16480, lr=4.54244e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48933
2023-02-21 03:01:32 - progress_bar.py[line:274] - INFO: epoch 001:  16509 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=16490, lr=4.54208e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=48945
2023-02-21 03:01:35 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 03:01:44 - progress_bar.py[line:274] - INFO: epoch 001:  16520 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.6, ups=0.81, wpb=110.8, bsz=40, num_updates=16500, lr=4.54171e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=48957
2023-02-21 03:01:55 - progress_bar.py[line:274] - INFO: epoch 001:  16530 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.4, bsz=40, num_updates=16510, lr=4.54135e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48968
2023-02-21 03:02:07 - progress_bar.py[line:274] - INFO: epoch 001:  16540 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=16520, lr=4.54099e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48979
2023-02-21 03:02:18 - progress_bar.py[line:274] - INFO: epoch 001:  16550 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=112, bsz=40, num_updates=16530, lr=4.54063e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=48991
2023-02-21 03:02:29 - progress_bar.py[line:274] - INFO: epoch 001:  16560 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111.1, bsz=40, num_updates=16540, lr=4.54027e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49002
2023-02-21 03:02:40 - progress_bar.py[line:274] - INFO: epoch 001:  16570 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.4, bsz=40, num_updates=16550, lr=4.53991e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49013
2023-02-21 03:02:51 - progress_bar.py[line:274] - INFO: epoch 001:  16580 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.3, bsz=40, num_updates=16560, lr=4.53954e-05, gnorm=0.046, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49024
2023-02-21 03:03:03 - progress_bar.py[line:274] - INFO: epoch 001:  16590 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.4, bsz=40, num_updates=16570, lr=4.53918e-05, gnorm=0.05, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49035
2023-02-21 03:03:14 - progress_bar.py[line:274] - INFO: epoch 001:  16600 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112, bsz=40, num_updates=16580, lr=4.53882e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49047
2023-02-21 03:03:25 - progress_bar.py[line:274] - INFO: epoch 001:  16610 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112.2, bsz=40, num_updates=16590, lr=4.53846e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49058
2023-02-21 03:03:36 - progress_bar.py[line:274] - INFO: epoch 001:  16620 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.6, bsz=40, num_updates=16600, lr=4.5381e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49069
2023-02-21 03:03:48 - progress_bar.py[line:274] - INFO: epoch 001:  16630 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.3, bsz=40, num_updates=16610, lr=4.53773e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49080
2023-02-21 03:03:59 - progress_bar.py[line:274] - INFO: epoch 001:  16640 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.3, bsz=40, num_updates=16620, lr=4.53737e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49092
2023-02-21 03:04:10 - progress_bar.py[line:274] - INFO: epoch 001:  16650 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=16630, lr=4.53701e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=49103
2023-02-21 03:04:21 - progress_bar.py[line:274] - INFO: epoch 001:  16660 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=16640, lr=4.53665e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49114
2023-02-21 03:04:32 - progress_bar.py[line:274] - INFO: epoch 001:  16670 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110, bsz=40, num_updates=16650, lr=4.53629e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49125
2023-02-21 03:04:43 - progress_bar.py[line:274] - INFO: epoch 001:  16680 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111.1, bsz=40, num_updates=16660, lr=4.53593e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49136
2023-02-21 03:04:54 - progress_bar.py[line:274] - INFO: epoch 001:  16690 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.93, wpb=110, bsz=40, num_updates=16670, lr=4.53556e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49147
2023-02-21 03:05:04 - progress_bar.py[line:274] - INFO: epoch 001:  16700 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.7, ups=0.94, wpb=111.1, bsz=40, num_updates=16680, lr=4.5352e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49157
2023-02-21 03:05:15 - progress_bar.py[line:274] - INFO: epoch 001:  16710 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=16690, lr=4.53484e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49168
2023-02-21 03:05:27 - progress_bar.py[line:274] - INFO: epoch 001:  16720 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.89, wpb=113.3, bsz=40, num_updates=16700, lr=4.53448e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49179
2023-02-21 03:05:38 - progress_bar.py[line:274] - INFO: epoch 001:  16730 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=16710, lr=4.53412e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49191
2023-02-21 03:05:49 - progress_bar.py[line:274] - INFO: epoch 001:  16740 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.91, wpb=112.7, bsz=40, num_updates=16720, lr=4.53375e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49202
2023-02-21 03:06:00 - progress_bar.py[line:274] - INFO: epoch 001:  16750 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.5, bsz=40, num_updates=16730, lr=4.53339e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49213
2023-02-21 03:06:11 - progress_bar.py[line:274] - INFO: epoch 001:  16760 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=16740, lr=4.53303e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49224
2023-02-21 03:06:23 - progress_bar.py[line:274] - INFO: epoch 001:  16770 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112.2, bsz=40, num_updates=16750, lr=4.53267e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49235
2023-02-21 03:06:34 - progress_bar.py[line:274] - INFO: epoch 001:  16780 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.87, wpb=110.3, bsz=40, num_updates=16760, lr=4.53231e-05, gnorm=0.049, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49247
2023-02-21 03:06:45 - progress_bar.py[line:274] - INFO: epoch 001:  16790 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.6, bsz=40, num_updates=16770, lr=4.53195e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=49258
2023-02-21 03:06:56 - progress_bar.py[line:274] - INFO: epoch 001:  16800 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=16780, lr=4.53158e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49269
2023-02-21 03:07:07 - progress_bar.py[line:274] - INFO: epoch 001:  16810 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.2, bsz=40, num_updates=16790, lr=4.53122e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49280
2023-02-21 03:07:19 - progress_bar.py[line:274] - INFO: epoch 001:  16820 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.4, bsz=40, num_updates=16800, lr=4.53086e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49291
2023-02-21 03:07:30 - progress_bar.py[line:274] - INFO: epoch 001:  16830 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.89, wpb=113.2, bsz=40, num_updates=16810, lr=4.5305e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49303
2023-02-21 03:07:41 - progress_bar.py[line:274] - INFO: epoch 001:  16840 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.4, bsz=40, num_updates=16820, lr=4.53014e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=49314
2023-02-21 03:07:53 - progress_bar.py[line:274] - INFO: epoch 001:  16850 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.87, wpb=113.2, bsz=40, num_updates=16830, lr=4.52977e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49325
2023-02-21 03:08:04 - progress_bar.py[line:274] - INFO: epoch 001:  16860 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111.1, bsz=40, num_updates=16840, lr=4.52941e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49336
2023-02-21 03:08:15 - progress_bar.py[line:274] - INFO: epoch 001:  16870 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.5, ups=0.87, wpb=110.1, bsz=40, num_updates=16850, lr=4.52905e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49348
2023-02-21 03:08:26 - progress_bar.py[line:274] - INFO: epoch 001:  16880 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.92, wpb=110.6, bsz=40, num_updates=16860, lr=4.52869e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49359
2023-02-21 03:08:37 - progress_bar.py[line:274] - INFO: epoch 001:  16890 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.2, bsz=40, num_updates=16870, lr=4.52833e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49370
2023-02-21 03:08:48 - progress_bar.py[line:274] - INFO: epoch 001:  16900 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.4, bsz=40, num_updates=16880, lr=4.52797e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49381
2023-02-21 03:09:00 - progress_bar.py[line:274] - INFO: epoch 001:  16910 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.6, bsz=40, num_updates=16890, lr=4.5276e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49392
2023-02-21 03:09:11 - progress_bar.py[line:274] - INFO: epoch 001:  16920 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=16900, lr=4.52724e-05, gnorm=0.104, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49403
2023-02-21 03:09:21 - progress_bar.py[line:274] - INFO: epoch 001:  16930 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.92, wpb=110.4, bsz=40, num_updates=16910, lr=4.52688e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=49414
2023-02-21 03:09:33 - progress_bar.py[line:274] - INFO: epoch 001:  16940 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=110.6, bsz=40, num_updates=16920, lr=4.52652e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49426
2023-02-21 03:09:44 - progress_bar.py[line:274] - INFO: epoch 001:  16950 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.9, wpb=111.2, bsz=40, num_updates=16930, lr=4.52616e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49437
2023-02-21 03:09:55 - progress_bar.py[line:274] - INFO: epoch 001:  16960 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.1, ups=0.93, wpb=111.8, bsz=40, num_updates=16940, lr=4.52579e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49448
2023-02-21 03:10:06 - progress_bar.py[line:274] - INFO: epoch 001:  16970 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.8, bsz=40, num_updates=16950, lr=4.52543e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49459
2023-02-21 03:10:17 - progress_bar.py[line:274] - INFO: epoch 001:  16980 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.6, bsz=40, num_updates=16960, lr=4.52507e-05, gnorm=0.042, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49470
2023-02-21 03:10:28 - progress_bar.py[line:274] - INFO: epoch 001:  16990 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.93, wpb=111.2, bsz=40, num_updates=16970, lr=4.52471e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49481
2023-02-21 03:10:39 - progress_bar.py[line:274] - INFO: epoch 001:  17000 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.5, bsz=40, num_updates=16980, lr=4.52435e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49492
2023-02-21 03:10:50 - progress_bar.py[line:274] - INFO: epoch 001:  17010 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.93, wpb=110.3, bsz=40, num_updates=16990, lr=4.52399e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49503
2023-02-21 03:11:01 - progress_bar.py[line:274] - INFO: epoch 001:  17020 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.2, bsz=40, num_updates=17000, lr=4.52362e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49514
2023-02-21 03:11:12 - progress_bar.py[line:274] - INFO: epoch 001:  17030 / 142023 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=112.1, bsz=40, num_updates=17010, lr=4.52326e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49525
2023-02-21 03:11:24 - progress_bar.py[line:274] - INFO: epoch 001:  17040 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=17020, lr=4.5229e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49536
2023-02-21 03:11:35 - progress_bar.py[line:274] - INFO: epoch 001:  17050 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.87, wpb=112, bsz=40, num_updates=17030, lr=4.52254e-05, gnorm=0.044, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49548
2023-02-21 03:11:46 - progress_bar.py[line:274] - INFO: epoch 001:  17060 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.6, bsz=40, num_updates=17040, lr=4.52218e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49559
2023-02-21 03:11:58 - progress_bar.py[line:274] - INFO: epoch 001:  17070 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.3, ups=0.87, wpb=110.6, bsz=40, num_updates=17050, lr=4.52181e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49570
2023-02-21 03:12:09 - progress_bar.py[line:274] - INFO: epoch 001:  17080 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=112, bsz=40, num_updates=17060, lr=4.52145e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49582
2023-02-21 03:12:20 - progress_bar.py[line:274] - INFO: epoch 001:  17090 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.7, bsz=40, num_updates=17070, lr=4.52109e-05, gnorm=0.083, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=49593
2023-02-21 03:12:31 - progress_bar.py[line:274] - INFO: epoch 001:  17100 / 142023 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.91, wpb=110, bsz=40, num_updates=17080, lr=4.52073e-05, gnorm=0.039, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49604
2023-02-21 03:12:42 - progress_bar.py[line:274] - INFO: epoch 001:  17110 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=112.1, bsz=40, num_updates=17090, lr=4.52037e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49615
2023-02-21 03:12:53 - progress_bar.py[line:274] - INFO: epoch 001:  17120 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.9, wpb=109, bsz=40, num_updates=17100, lr=4.52001e-05, gnorm=0.105, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49626
2023-02-21 03:13:05 - progress_bar.py[line:274] - INFO: epoch 001:  17130 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.7, bsz=40, num_updates=17110, lr=4.51964e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49637
2023-02-21 03:13:16 - progress_bar.py[line:274] - INFO: epoch 001:  17140 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=17120, lr=4.51928e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49649
2023-02-21 03:13:27 - progress_bar.py[line:274] - INFO: epoch 001:  17150 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.3, bsz=40, num_updates=17130, lr=4.51892e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49660
2023-02-21 03:13:38 - progress_bar.py[line:274] - INFO: epoch 001:  17160 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=17140, lr=4.51856e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49671
2023-02-21 03:13:49 - progress_bar.py[line:274] - INFO: epoch 001:  17170 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.5, bsz=40, num_updates=17150, lr=4.5182e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49682
2023-02-21 03:14:00 - progress_bar.py[line:274] - INFO: epoch 001:  17180 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.5, bsz=40, num_updates=17160, lr=4.51783e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49693
2023-02-21 03:14:12 - progress_bar.py[line:274] - INFO: epoch 001:  17190 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=110.5, bsz=40, num_updates=17170, lr=4.51747e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49705
2023-02-21 03:14:22 - progress_bar.py[line:274] - INFO: epoch 001:  17200 / 142023 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.8, ups=0.94, wpb=110.1, bsz=40, num_updates=17180, lr=4.51711e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49715
2023-02-21 03:14:34 - progress_bar.py[line:274] - INFO: epoch 001:  17210 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.3, bsz=40, num_updates=17190, lr=4.51675e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49726
2023-02-21 03:14:45 - progress_bar.py[line:274] - INFO: epoch 001:  17220 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=109.8, bsz=40, num_updates=17200, lr=4.51639e-05, gnorm=0.088, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49738
2023-02-21 03:14:56 - progress_bar.py[line:274] - INFO: epoch 001:  17230 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.9, bsz=40, num_updates=17210, lr=4.51603e-05, gnorm=0.076, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49749
2023-02-21 03:15:07 - progress_bar.py[line:274] - INFO: epoch 001:  17240 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.4, bsz=40, num_updates=17220, lr=4.51566e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49760
2023-02-21 03:15:08 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 03:15:19 - progress_bar.py[line:274] - INFO: epoch 001:  17251 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91.6, ups=0.83, wpb=110.8, bsz=40, num_updates=17230, lr=4.5153e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=49772
2023-02-21 03:15:30 - progress_bar.py[line:274] - INFO: epoch 001:  17261 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=17240, lr=4.51494e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49783
2023-02-21 03:15:41 - progress_bar.py[line:274] - INFO: epoch 001:  17271 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.9, bsz=40, num_updates=17250, lr=4.51458e-05, gnorm=0.05, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49794
2023-02-21 03:15:53 - progress_bar.py[line:274] - INFO: epoch 001:  17281 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.7, bsz=40, num_updates=17260, lr=4.51422e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49806
2023-02-21 03:16:04 - progress_bar.py[line:274] - INFO: epoch 001:  17291 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.92, wpb=109.8, bsz=40, num_updates=17270, lr=4.51385e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49816
2023-02-21 03:16:15 - progress_bar.py[line:274] - INFO: epoch 001:  17301 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.87, wpb=110.2, bsz=40, num_updates=17280, lr=4.51349e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=49828
2023-02-21 03:16:27 - progress_bar.py[line:274] - INFO: epoch 001:  17311 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=111.5, bsz=40, num_updates=17290, lr=4.51313e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49839
2023-02-21 03:16:38 - progress_bar.py[line:274] - INFO: epoch 001:  17321 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.9, wpb=110.3, bsz=40, num_updates=17300, lr=4.51277e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49851
2023-02-21 03:16:49 - progress_bar.py[line:274] - INFO: epoch 001:  17331 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.9, bsz=40, num_updates=17310, lr=4.51241e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49862
2023-02-21 03:17:00 - progress_bar.py[line:274] - INFO: epoch 001:  17341 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111, bsz=40, num_updates=17320, lr=4.51205e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49873
2023-02-21 03:17:11 - progress_bar.py[line:274] - INFO: epoch 001:  17351 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=17330, lr=4.51168e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49884
2023-02-21 03:17:23 - progress_bar.py[line:274] - INFO: epoch 001:  17361 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.88, wpb=109.9, bsz=40, num_updates=17340, lr=4.51132e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49896
2023-02-21 03:17:34 - progress_bar.py[line:274] - INFO: epoch 001:  17371 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.92, wpb=110, bsz=40, num_updates=17350, lr=4.51096e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49906
2023-02-21 03:17:45 - progress_bar.py[line:274] - INFO: epoch 001:  17381 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.7, bsz=40, num_updates=17360, lr=4.5106e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49918
2023-02-21 03:17:56 - progress_bar.py[line:274] - INFO: epoch 001:  17391 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=17370, lr=4.51024e-05, gnorm=0.047, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49929
2023-02-21 03:18:07 - progress_bar.py[line:274] - INFO: epoch 001:  17401 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=17380, lr=4.50987e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49940
2023-02-21 03:18:19 - progress_bar.py[line:274] - INFO: epoch 001:  17411 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=17390, lr=4.50951e-05, gnorm=0.102, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49952
2023-02-21 03:18:30 - progress_bar.py[line:274] - INFO: epoch 001:  17421 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.8, bsz=40, num_updates=17400, lr=4.50915e-05, gnorm=0.048, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49963
2023-02-21 03:18:41 - progress_bar.py[line:274] - INFO: epoch 001:  17431 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.92, wpb=110.1, bsz=40, num_updates=17410, lr=4.50879e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49974
2023-02-21 03:18:52 - progress_bar.py[line:274] - INFO: epoch 001:  17441 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.3, bsz=40, num_updates=17420, lr=4.50843e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=49984
2023-02-21 03:19:03 - progress_bar.py[line:274] - INFO: epoch 001:  17451 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=17430, lr=4.50807e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49996
2023-02-21 03:19:14 - progress_bar.py[line:274] - INFO: epoch 001:  17461 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.2, bsz=40, num_updates=17440, lr=4.5077e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50007
2023-02-21 03:19:26 - progress_bar.py[line:274] - INFO: epoch 001:  17471 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.87, wpb=110.5, bsz=40, num_updates=17450, lr=4.50734e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=50019
2023-02-21 03:19:37 - progress_bar.py[line:274] - INFO: epoch 001:  17481 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.5, bsz=40, num_updates=17460, lr=4.50698e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50030
2023-02-21 03:19:48 - progress_bar.py[line:274] - INFO: epoch 001:  17491 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.8, bsz=40, num_updates=17470, lr=4.50662e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50041
2023-02-21 03:19:59 - progress_bar.py[line:274] - INFO: epoch 001:  17501 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.93, wpb=111.3, bsz=40, num_updates=17480, lr=4.50626e-05, gnorm=0.049, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50052
2023-02-21 03:20:10 - progress_bar.py[line:274] - INFO: epoch 001:  17511 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.8, bsz=40, num_updates=17490, lr=4.50589e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50063
2023-02-21 03:20:21 - progress_bar.py[line:274] - INFO: epoch 001:  17521 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=17500, lr=4.50553e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50074
2023-02-21 03:20:33 - progress_bar.py[line:274] - INFO: epoch 001:  17531 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=100.9, ups=0.9, wpb=112.6, bsz=40, num_updates=17510, lr=4.50517e-05, gnorm=0.048, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50085
2023-02-21 03:20:43 - progress_bar.py[line:274] - INFO: epoch 001:  17541 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=107.2, ups=0.97, wpb=110.6, bsz=40, num_updates=17520, lr=4.50481e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=10, gb_free=10.5, ema_decay=0.9999, wall=50096
2023-02-21 03:20:54 - progress_bar.py[line:274] - INFO: epoch 001:  17551 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=111.9, bsz=40, num_updates=17530, lr=4.50445e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=50107
2023-02-21 03:21:06 - progress_bar.py[line:274] - INFO: epoch 001:  17561 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.4, bsz=40, num_updates=17540, lr=4.50408e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=50119
2023-02-21 03:21:17 - progress_bar.py[line:274] - INFO: epoch 001:  17571 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110.7, bsz=40, num_updates=17550, lr=4.50372e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50129
2023-02-21 03:21:28 - progress_bar.py[line:274] - INFO: epoch 001:  17581 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=17560, lr=4.50336e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=50141
2023-02-21 03:21:39 - progress_bar.py[line:274] - INFO: epoch 001:  17591 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=17570, lr=4.503e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50152
2023-02-21 03:21:50 - progress_bar.py[line:274] - INFO: epoch 001:  17601 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=110, bsz=40, num_updates=17580, lr=4.50264e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50163
2023-02-21 03:22:01 - progress_bar.py[line:274] - INFO: epoch 001:  17611 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.2, ups=0.9, wpb=111.8, bsz=40, num_updates=17590, lr=4.50228e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50174
2023-02-21 03:22:12 - progress_bar.py[line:274] - INFO: epoch 001:  17621 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=17600, lr=4.50191e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50185
2023-02-21 03:22:23 - progress_bar.py[line:274] - INFO: epoch 001:  17631 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=17610, lr=4.50155e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50196
2023-02-21 03:22:35 - progress_bar.py[line:274] - INFO: epoch 001:  17641 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.9, bsz=40, num_updates=17620, lr=4.50119e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50208
2023-02-21 03:22:46 - progress_bar.py[line:274] - INFO: epoch 001:  17651 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=17630, lr=4.50083e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50219
2023-02-21 03:22:57 - progress_bar.py[line:274] - INFO: epoch 001:  17661 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.88, wpb=109.1, bsz=40, num_updates=17640, lr=4.50047e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50230
2023-02-21 03:23:08 - progress_bar.py[line:274] - INFO: epoch 001:  17671 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.3, bsz=40, num_updates=17650, lr=4.5001e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50241
2023-02-21 03:23:19 - progress_bar.py[line:274] - INFO: epoch 001:  17681 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=111.8, bsz=40, num_updates=17660, lr=4.49974e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50252
2023-02-21 03:23:30 - progress_bar.py[line:274] - INFO: epoch 001:  17691 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=111.9, bsz=40, num_updates=17670, lr=4.49938e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50263
2023-02-21 03:23:41 - progress_bar.py[line:274] - INFO: epoch 001:  17701 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.7, bsz=40, num_updates=17680, lr=4.49902e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50274
2023-02-21 03:23:52 - progress_bar.py[line:274] - INFO: epoch 001:  17711 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.4, bsz=40, num_updates=17690, lr=4.49866e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50285
2023-02-21 03:24:04 - progress_bar.py[line:274] - INFO: epoch 001:  17721 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=112.1, bsz=40, num_updates=17700, lr=4.4983e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50296
2023-02-21 03:24:15 - progress_bar.py[line:274] - INFO: epoch 001:  17731 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=17710, lr=4.49793e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50308
2023-02-21 03:24:26 - progress_bar.py[line:274] - INFO: epoch 001:  17741 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=17720, lr=4.49757e-05, gnorm=0.045, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50319
2023-02-21 03:24:37 - progress_bar.py[line:274] - INFO: epoch 001:  17751 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=17730, lr=4.49721e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=50330
2023-02-21 03:24:48 - progress_bar.py[line:274] - INFO: epoch 001:  17761 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.7, bsz=40, num_updates=17740, lr=4.49685e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50341
2023-02-21 03:24:59 - progress_bar.py[line:274] - INFO: epoch 001:  17771 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=112.1, bsz=40, num_updates=17750, lr=4.49649e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50352
2023-02-21 03:25:10 - progress_bar.py[line:274] - INFO: epoch 001:  17781 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=17760, lr=4.49612e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=50363
2023-02-21 03:25:21 - progress_bar.py[line:274] - INFO: epoch 001:  17791 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.5, bsz=40, num_updates=17770, lr=4.49576e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=50374
2023-02-21 03:25:33 - progress_bar.py[line:274] - INFO: epoch 001:  17801 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.6, ups=0.86, wpb=111.3, bsz=40, num_updates=17780, lr=4.4954e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=50386
2023-02-21 03:25:44 - progress_bar.py[line:274] - INFO: epoch 001:  17811 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=17790, lr=4.49504e-05, gnorm=0.083, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=50397
2023-02-21 03:25:56 - progress_bar.py[line:274] - INFO: epoch 001:  17821 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=17800, lr=4.49468e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=50408
2023-02-21 03:26:07 - progress_bar.py[line:274] - INFO: epoch 001:  17831 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.8, bsz=40, num_updates=17810, lr=4.49432e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=50419
2023-02-21 03:26:18 - progress_bar.py[line:274] - INFO: epoch 001:  17841 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.3, bsz=40, num_updates=17820, lr=4.49395e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=50430
2023-02-21 03:26:29 - progress_bar.py[line:274] - INFO: epoch 001:  17851 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=111.9, bsz=40, num_updates=17830, lr=4.49359e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50442
2023-02-21 03:26:40 - progress_bar.py[line:274] - INFO: epoch 001:  17861 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=17840, lr=4.49323e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50453
2023-02-21 03:26:51 - progress_bar.py[line:274] - INFO: epoch 001:  17871 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=17850, lr=4.49287e-05, gnorm=0.041, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50464
2023-02-21 03:27:03 - progress_bar.py[line:274] - INFO: epoch 001:  17881 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.87, wpb=110.3, bsz=40, num_updates=17860, lr=4.49251e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50475
2023-02-21 03:27:14 - progress_bar.py[line:274] - INFO: epoch 001:  17891 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.3, bsz=40, num_updates=17870, lr=4.49214e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50486
2023-02-21 03:27:25 - progress_bar.py[line:274] - INFO: epoch 001:  17901 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.9, wpb=109.4, bsz=40, num_updates=17880, lr=4.49178e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50498
2023-02-21 03:27:35 - progress_bar.py[line:274] - INFO: epoch 001:  17911 / 142023 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.93, wpb=108.8, bsz=40, num_updates=17890, lr=4.49142e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50508
2023-02-21 03:27:47 - progress_bar.py[line:274] - INFO: epoch 001:  17921 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=110.3, bsz=40, num_updates=17900, lr=4.49106e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=50519
2023-02-21 03:27:58 - progress_bar.py[line:274] - INFO: epoch 001:  17931 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=112, bsz=40, num_updates=17910, lr=4.4907e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50531
2023-02-21 03:28:09 - progress_bar.py[line:274] - INFO: epoch 001:  17941 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=17920, lr=4.49034e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50542
2023-02-21 03:28:20 - progress_bar.py[line:274] - INFO: epoch 001:  17951 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=17930, lr=4.48997e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=50553
2023-02-21 03:28:31 - progress_bar.py[line:274] - INFO: epoch 001:  17961 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=17940, lr=4.48961e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50564
2023-02-21 03:28:42 - progress_bar.py[line:274] - INFO: epoch 001:  17971 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=110.6, bsz=40, num_updates=17950, lr=4.48925e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50575
2023-02-21 03:28:54 - progress_bar.py[line:274] - INFO: epoch 001:  17981 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.87, wpb=110.6, bsz=40, num_updates=17960, lr=4.48889e-05, gnorm=0.087, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50587
2023-02-21 03:29:05 - progress_bar.py[line:274] - INFO: epoch 001:  17991 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.2, ups=0.91, wpb=111.2, bsz=40, num_updates=17970, lr=4.48853e-05, gnorm=0.076, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=50598
2023-02-21 03:29:16 - progress_bar.py[line:274] - INFO: epoch 001:  18001 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.92, wpb=110.2, bsz=40, num_updates=17980, lr=4.48816e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50609
2023-02-21 03:29:27 - progress_bar.py[line:274] - INFO: epoch 001:  18011 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.88, wpb=111.5, bsz=40, num_updates=17990, lr=4.4878e-05, gnorm=0.085, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=50620
2023-02-21 03:29:38 - progress_bar.py[line:274] - INFO: epoch 001:  18021 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.7, bsz=40, num_updates=18000, lr=4.48744e-05, gnorm=0.105, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50631
2023-02-21 03:29:38 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 03:29:40 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 03:29:40 - train.py[line:551] - INFO: load:1.12 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 03:31:42 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 03:31:42 - train.py[line:551] - INFO: load:1.14 valid_run:122.36 task_valid:119.49 collect_output:1.79
2023-02-21 03:33:42 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 03:33:42 - train.py[line:551] - INFO: load:1.17 valid_run:242.19 task_valid:235.42 collect_output:4.63
2023-02-21 03:35:44 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 03:35:44 - train.py[line:551] - INFO: load:1.19 valid_run:363.97 task_valid:351.94 collect_output:8.90
2023-02-21 03:37:46 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 03:37:46 - train.py[line:551] - INFO: load:1.22 valid_run:485.85 task_valid:465.88 collect_output:15.82
2023-02-21 03:39:46 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 03:39:46 - train.py[line:551] - INFO: load:1.24 valid_run:606.25 task_valid:583.30 collect_output:17.79
2023-02-21 03:41:49 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 03:41:49 - train.py[line:551] - INFO: load:1.27 valid_run:729.17 task_valid:702.17 collect_output:20.83
2023-02-21 03:43:52 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 03:43:52 - train.py[line:551] - INFO: load:1.29 valid_run:852.11 task_valid:820.37 collect_output:24.54
2023-02-21 03:45:54 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 03:45:54 - train.py[line:551] - INFO: load:1.32 valid_run:974.11 task_valid:937.16 collect_output:28.74
2023-02-21 03:47:58 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 03:47:58 - train.py[line:551] - INFO: load:1.34 valid_run:1097.78 task_valid:1054.45 collect_output:34.12
2023-02-21 03:49:59 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 03:49:59 - train.py[line:551] - INFO: load:1.37 valid_run:1219.39 task_valid:1167.13 collect_output:42.03
2023-02-21 03:52:00 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 03:52:00 - train.py[line:551] - INFO: load:1.39 valid_run:1339.56 task_valid:1282.91 collect_output:45.39
2023-02-21 03:54:01 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 03:54:01 - train.py[line:551] - INFO: load:1.42 valid_run:1461.26 task_valid:1400.06 collect_output:48.93
2023-02-21 03:56:00 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 03:56:00 - train.py[line:551] - INFO: load:1.44 valid_run:1580.10 task_valid:1513.97 collect_output:52.84
2023-02-21 03:58:01 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 03:58:01 - train.py[line:551] - INFO: load:1.47 valid_run:1701.03 task_valid:1631.78 collect_output:54.95
2023-02-21 04:00:02 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 04:00:02 - train.py[line:551] - INFO: load:1.49 valid_run:1821.95 task_valid:1747.94 collect_output:58.71
2023-02-21 04:02:03 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 04:02:03 - train.py[line:551] - INFO: load:1.52 valid_run:1943.03 task_valid:1862.05 collect_output:64.67
2023-02-21 04:04:05 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 04:04:05 - train.py[line:551] - INFO: load:1.54 valid_run:2064.28 task_valid:1978.20 collect_output:68.75
2023-02-21 04:06:06 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 04:06:06 - train.py[line:551] - INFO: load:1.57 valid_run:2184.95 task_valid:2096.18 collect_output:70.43
2023-02-21 04:08:07 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 04:08:07 - train.py[line:551] - INFO: load:1.59 valid_run:2306.19 task_valid:2213.16 collect_output:73.69
2023-02-21 04:10:07 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 04:10:07 - train.py[line:551] - INFO: load:1.62 valid_run:2426.48 task_valid:2329.70 collect_output:76.44
2023-02-21 04:12:09 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 04:12:09 - train.py[line:551] - INFO: load:1.65 valid_run:2548.18 task_valid:2446.43 collect_output:80.41
2023-02-21 04:14:11 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 04:14:11 - train.py[line:551] - INFO: load:1.67 valid_run:2670.18 task_valid:2565.35 collect_output:82.48
2023-02-21 04:16:11 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 04:16:11 - train.py[line:551] - INFO: load:1.70 valid_run:2790.63 task_valid:2679.93 collect_output:87.36
2023-02-21 04:18:11 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 04:18:11 - train.py[line:551] - INFO: load:1.72 valid_run:2910.45 task_valid:2796.10 collect_output:89.98
2023-02-21 04:20:13 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 04:20:13 - train.py[line:551] - INFO: load:1.75 valid_run:3032.08 task_valid:2912.53 collect_output:94.17
2023-02-21 04:22:16 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 04:22:16 - train.py[line:551] - INFO: load:1.78 valid_run:3154.88 task_valid:3028.67 collect_output:99.81
2023-02-21 04:24:16 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 04:24:16 - train.py[line:551] - INFO: load:1.80 valid_run:3274.52 task_valid:3142.95 collect_output:104.15
2023-02-21 04:26:18 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 04:26:18 - train.py[line:551] - INFO: load:1.83 valid_run:3396.45 task_valid:3262.54 collect_output:105.49
2023-02-21 04:28:19 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 04:28:19 - train.py[line:551] - INFO: load:1.86 valid_run:3518.20 task_valid:3378.23 collect_output:110.54
2023-02-21 04:30:21 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 04:30:21 - train.py[line:551] - INFO: load:1.88 valid_run:3640.11 task_valid:3496.86 collect_output:112.81
2023-02-21 04:32:23 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 04:32:23 - train.py[line:551] - INFO: load:1.91 valid_run:3761.20 task_valid:3615.30 collect_output:114.46

====================================================================================================
SGG eval:     R @ 50: 0.6213;     R @ 100: 0.6588;     R @ 500: 0.6809;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3734;    mR @ 100: 0.4124;    mR @ 500: 0.4475;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.3750) (hanging from:0.5484) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:1.0000) (playing:0.0000) (riding:0.9402) (says:0.0000) (sitting on:0.7211) (standing on:0.3843) (using:0.5500) (walking in:0.0000) (walking on:0.7162) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6213;     R @ 100: 0.6588;     R @ 500: 0.6809;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3734;    mR @ 100: 0.4124;    mR @ 500: 0.4475;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.3750) (hanging from:0.5484) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:1.0000) (playing:0.0000) (riding:0.9402) (says:0.0000) (sitting on:0.7211) (standing on:0.3843) (using:0.5500) (walking in:0.0000) (walking on:0.7162) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-02-21 04:32:54 - train.py[line:487] - INFO: 0.6587624649859944
2023-02-21 04:32:54 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 04:32:54 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.218 | loss_v1 0 | loss_v2 0 | nll_loss 0.047 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.658762 | ppl 1.03 | vqa_score 0.3142 | wps 118.2 | wpb 72 | bsz 24 | num_updates 18000 | best_R@100 0.693596
2023-02-21 04:32:54 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 18000 updates
2023-02-21 04:32:54 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_18000.pt
2023-02-21 04:32:59 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_18000.pt
2023-02-21 04:33:02 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_18000.pt (epoch 1 @ 18000 updates, score 0.6587624649859944) (writing took 8.323289878666401 seconds)
2023-02-21 04:33:13 - progress_bar.py[line:274] - INFO: epoch 001:  18031 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=111.3, bsz=40, num_updates=18010, lr=4.48708e-05, gnorm=0.049, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54446
2023-02-21 04:33:25 - progress_bar.py[line:274] - INFO: epoch 001:  18041 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.89, wpb=110.4, bsz=40, num_updates=18020, lr=4.48672e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54457
2023-02-21 04:33:36 - progress_bar.py[line:274] - INFO: epoch 001:  18051 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=110.6, bsz=40, num_updates=18030, lr=4.48636e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54469
2023-02-21 04:33:47 - progress_bar.py[line:274] - INFO: epoch 001:  18061 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=18040, lr=4.48599e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54480
2023-02-21 04:33:59 - progress_bar.py[line:274] - INFO: epoch 001:  18071 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=18050, lr=4.48563e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54491
2023-02-21 04:34:10 - progress_bar.py[line:274] - INFO: epoch 001:  18081 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=18060, lr=4.48527e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54503
2023-02-21 04:34:21 - progress_bar.py[line:274] - INFO: epoch 001:  18091 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=109.7, bsz=40, num_updates=18070, lr=4.48491e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54514
2023-02-21 04:34:32 - progress_bar.py[line:274] - INFO: epoch 001:  18101 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=18080, lr=4.48455e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54525
2023-02-21 04:34:44 - progress_bar.py[line:274] - INFO: epoch 001:  18111 / 142023 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=109.8, bsz=40, num_updates=18090, lr=4.48418e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54536
2023-02-21 04:34:50 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 04:34:56 - progress_bar.py[line:274] - INFO: epoch 001:  18122 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.8, ups=0.81, wpb=111.2, bsz=40, num_updates=18100, lr=4.48382e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=54549
2023-02-21 04:35:07 - progress_bar.py[line:274] - INFO: epoch 001:  18132 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=18110, lr=4.48346e-05, gnorm=0.045, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54560
2023-02-21 04:35:18 - progress_bar.py[line:274] - INFO: epoch 001:  18142 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=112.1, bsz=40, num_updates=18120, lr=4.4831e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54571
2023-02-21 04:35:29 - progress_bar.py[line:274] - INFO: epoch 001:  18152 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=18130, lr=4.48274e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54582
2023-02-21 04:35:40 - progress_bar.py[line:274] - INFO: epoch 001:  18162 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.2, ups=0.94, wpb=111.7, bsz=40, num_updates=18140, lr=4.48238e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54592
2023-02-21 04:35:51 - progress_bar.py[line:274] - INFO: epoch 001:  18172 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.3, bsz=40, num_updates=18150, lr=4.48201e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54603
2023-02-21 04:36:02 - progress_bar.py[line:274] - INFO: epoch 001:  18182 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.9, bsz=40, num_updates=18160, lr=4.48165e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54615
2023-02-21 04:36:13 - progress_bar.py[line:274] - INFO: epoch 001:  18192 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=111.1, bsz=40, num_updates=18170, lr=4.48129e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54626
2023-02-21 04:36:24 - progress_bar.py[line:274] - INFO: epoch 001:  18202 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=112, bsz=40, num_updates=18180, lr=4.48093e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54637
2023-02-21 04:36:35 - progress_bar.py[line:274] - INFO: epoch 001:  18212 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.9, bsz=40, num_updates=18190, lr=4.48057e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=54648
2023-02-21 04:36:47 - progress_bar.py[line:274] - INFO: epoch 001:  18222 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.88, wpb=113, bsz=40, num_updates=18200, lr=4.4802e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54659
2023-02-21 04:36:58 - progress_bar.py[line:274] - INFO: epoch 001:  18232 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=18210, lr=4.47984e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54671
2023-02-21 04:37:09 - progress_bar.py[line:274] - INFO: epoch 001:  18242 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=112.1, bsz=40, num_updates=18220, lr=4.47948e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54682
2023-02-21 04:37:20 - progress_bar.py[line:274] - INFO: epoch 001:  18252 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=110.8, bsz=40, num_updates=18230, lr=4.47912e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54693
2023-02-21 04:37:31 - progress_bar.py[line:274] - INFO: epoch 001:  18262 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=110.2, bsz=40, num_updates=18240, lr=4.47876e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54704
2023-02-21 04:37:43 - progress_bar.py[line:274] - INFO: epoch 001:  18272 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.6, bsz=40, num_updates=18250, lr=4.4784e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54716
2023-02-21 04:37:54 - progress_bar.py[line:274] - INFO: epoch 001:  18282 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=112, bsz=40, num_updates=18260, lr=4.47803e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54727
2023-02-21 04:38:05 - progress_bar.py[line:274] - INFO: epoch 001:  18292 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.1, bsz=40, num_updates=18270, lr=4.47767e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54738
2023-02-21 04:38:16 - progress_bar.py[line:274] - INFO: epoch 001:  18302 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.7, ups=0.94, wpb=110.9, bsz=40, num_updates=18280, lr=4.47731e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54749
2023-02-21 04:38:27 - progress_bar.py[line:274] - INFO: epoch 001:  18312 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.1, bsz=40, num_updates=18290, lr=4.47695e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54760
2023-02-21 04:38:39 - progress_bar.py[line:274] - INFO: epoch 001:  18322 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.7, bsz=40, num_updates=18300, lr=4.47659e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54771
2023-02-21 04:38:49 - progress_bar.py[line:274] - INFO: epoch 001:  18332 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.93, wpb=110.4, bsz=40, num_updates=18310, lr=4.47622e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54782
2023-02-21 04:39:01 - progress_bar.py[line:274] - INFO: epoch 001:  18342 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111.2, bsz=40, num_updates=18320, lr=4.47586e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54793
2023-02-21 04:39:12 - progress_bar.py[line:274] - INFO: epoch 001:  18352 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.5, bsz=40, num_updates=18330, lr=4.4755e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54805
2023-02-21 04:39:23 - progress_bar.py[line:274] - INFO: epoch 001:  18362 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.89, wpb=112.3, bsz=40, num_updates=18340, lr=4.47514e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54816
2023-02-21 04:39:34 - progress_bar.py[line:274] - INFO: epoch 001:  18372 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=18350, lr=4.47478e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54827
2023-02-21 04:39:45 - progress_bar.py[line:274] - INFO: epoch 001:  18382 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.7, bsz=40, num_updates=18360, lr=4.47442e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54838
2023-02-21 04:39:56 - progress_bar.py[line:274] - INFO: epoch 001:  18392 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=110.8, bsz=40, num_updates=18370, lr=4.47405e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54849
2023-02-21 04:40:07 - progress_bar.py[line:274] - INFO: epoch 001:  18402 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=18380, lr=4.47369e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54860
2023-02-21 04:40:18 - progress_bar.py[line:274] - INFO: epoch 001:  18412 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.89, wpb=108.9, bsz=40, num_updates=18390, lr=4.47333e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54871
2023-02-21 04:40:29 - progress_bar.py[line:274] - INFO: epoch 001:  18422 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.93, wpb=110.1, bsz=40, num_updates=18400, lr=4.47297e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54882
2023-02-21 04:40:41 - progress_bar.py[line:274] - INFO: epoch 001:  18432 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=18410, lr=4.47261e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54893
2023-02-21 04:40:52 - progress_bar.py[line:274] - INFO: epoch 001:  18442 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.89, wpb=109.3, bsz=40, num_updates=18420, lr=4.47224e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54905
2023-02-21 04:41:03 - progress_bar.py[line:274] - INFO: epoch 001:  18452 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.4, bsz=40, num_updates=18430, lr=4.47188e-05, gnorm=0.044, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54916
2023-02-21 04:41:14 - progress_bar.py[line:274] - INFO: epoch 001:  18462 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112, bsz=40, num_updates=18440, lr=4.47152e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54927
2023-02-21 04:41:25 - progress_bar.py[line:274] - INFO: epoch 001:  18472 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=18450, lr=4.47116e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54938
2023-02-21 04:41:36 - progress_bar.py[line:274] - INFO: epoch 001:  18482 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.9, bsz=40, num_updates=18460, lr=4.4708e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54949
2023-02-21 04:41:47 - progress_bar.py[line:274] - INFO: epoch 001:  18492 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.2, bsz=40, num_updates=18470, lr=4.47044e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54960
2023-02-21 04:41:59 - progress_bar.py[line:274] - INFO: epoch 001:  18502 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.3, bsz=40, num_updates=18480, lr=4.47007e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54971
2023-02-21 04:42:10 - progress_bar.py[line:274] - INFO: epoch 001:  18512 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111.1, bsz=40, num_updates=18490, lr=4.46971e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54983
2023-02-21 04:42:21 - progress_bar.py[line:274] - INFO: epoch 001:  18522 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=18500, lr=4.46935e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54994
2023-02-21 04:42:32 - progress_bar.py[line:274] - INFO: epoch 001:  18532 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.91, wpb=110, bsz=40, num_updates=18510, lr=4.46899e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55005
2023-02-21 04:42:43 - progress_bar.py[line:274] - INFO: epoch 001:  18542 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=18520, lr=4.46863e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55016
2023-02-21 04:42:54 - progress_bar.py[line:274] - INFO: epoch 001:  18552 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.1, ups=0.93, wpb=111.7, bsz=40, num_updates=18530, lr=4.46826e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55027
2023-02-21 04:43:05 - progress_bar.py[line:274] - INFO: epoch 001:  18562 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.8, bsz=40, num_updates=18540, lr=4.4679e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=55038
2023-02-21 04:43:16 - progress_bar.py[line:274] - INFO: epoch 001:  18572 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=112, bsz=40, num_updates=18550, lr=4.46754e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55049
2023-02-21 04:43:27 - progress_bar.py[line:274] - INFO: epoch 001:  18582 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=18560, lr=4.46718e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55060
2023-02-21 04:43:38 - progress_bar.py[line:274] - INFO: epoch 001:  18592 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=18570, lr=4.46682e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55071
2023-02-21 04:43:50 - progress_bar.py[line:274] - INFO: epoch 001:  18602 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=111, bsz=40, num_updates=18580, lr=4.46646e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55083
2023-02-21 04:44:01 - progress_bar.py[line:274] - INFO: epoch 001:  18612 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.7, bsz=40, num_updates=18590, lr=4.46609e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55094
2023-02-21 04:44:12 - progress_bar.py[line:274] - INFO: epoch 001:  18622 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.8, ups=0.91, wpb=111.1, bsz=40, num_updates=18600, lr=4.46573e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=55105
2023-02-21 04:44:23 - progress_bar.py[line:274] - INFO: epoch 001:  18632 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.92, wpb=110, bsz=40, num_updates=18610, lr=4.46537e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=55116
2023-02-21 04:44:34 - progress_bar.py[line:274] - INFO: epoch 001:  18642 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.9, bsz=40, num_updates=18620, lr=4.46501e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55127
2023-02-21 04:44:45 - progress_bar.py[line:274] - INFO: epoch 001:  18652 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.6, bsz=40, num_updates=18630, lr=4.46465e-05, gnorm=0.044, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55138
2023-02-21 04:44:56 - progress_bar.py[line:274] - INFO: epoch 001:  18662 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=110.9, bsz=40, num_updates=18640, lr=4.46428e-05, gnorm=0.045, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55149
2023-02-21 04:45:07 - progress_bar.py[line:274] - INFO: epoch 001:  18672 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=111.9, bsz=40, num_updates=18650, lr=4.46392e-05, gnorm=0.04, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55160
2023-02-21 04:45:19 - progress_bar.py[line:274] - INFO: epoch 001:  18682 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.7, bsz=40, num_updates=18660, lr=4.46356e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=55171
2023-02-21 04:45:30 - progress_bar.py[line:274] - INFO: epoch 001:  18692 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.8, bsz=40, num_updates=18670, lr=4.4632e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55182
2023-02-21 04:45:41 - progress_bar.py[line:274] - INFO: epoch 001:  18702 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.8, bsz=40, num_updates=18680, lr=4.46284e-05, gnorm=0.091, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55193
2023-02-21 04:45:52 - progress_bar.py[line:274] - INFO: epoch 001:  18712 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.8, bsz=40, num_updates=18690, lr=4.46248e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55205
2023-02-21 04:46:03 - progress_bar.py[line:274] - INFO: epoch 001:  18722 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=18700, lr=4.46211e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55216
2023-02-21 04:46:15 - progress_bar.py[line:274] - INFO: epoch 001:  18732 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=112.1, bsz=40, num_updates=18710, lr=4.46175e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55227
2023-02-21 04:46:25 - progress_bar.py[line:274] - INFO: epoch 001:  18742 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.6, ups=0.96, wpb=111.6, bsz=40, num_updates=18720, lr=4.46139e-05, gnorm=0.045, clip=0, loss_scale=8192, train_wall=10, gb_free=10.7, ema_decay=0.9999, wall=55238
2023-02-21 04:46:36 - progress_bar.py[line:274] - INFO: epoch 001:  18752 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.5, bsz=40, num_updates=18730, lr=4.46103e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55249
2023-02-21 04:46:47 - progress_bar.py[line:274] - INFO: epoch 001:  18762 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.7, bsz=40, num_updates=18740, lr=4.46067e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55260
2023-02-21 04:46:58 - progress_bar.py[line:274] - INFO: epoch 001:  18772 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.9, bsz=40, num_updates=18750, lr=4.4603e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=55271
2023-02-21 04:47:10 - progress_bar.py[line:274] - INFO: epoch 001:  18782 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.5, bsz=40, num_updates=18760, lr=4.45994e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55283
2023-02-21 04:47:17 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 04:47:22 - progress_bar.py[line:274] - INFO: epoch 001:  18793 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.1, ups=0.84, wpb=111.1, bsz=40, num_updates=18770, lr=4.45958e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=55294
2023-02-21 04:47:33 - progress_bar.py[line:274] - INFO: epoch 001:  18803 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=18780, lr=4.45922e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55306
2023-02-21 04:47:44 - progress_bar.py[line:274] - INFO: epoch 001:  18813 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.7, bsz=40, num_updates=18790, lr=4.45886e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55317
2023-02-21 04:47:55 - progress_bar.py[line:274] - INFO: epoch 001:  18823 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=18800, lr=4.4585e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55328
2023-02-21 04:48:06 - progress_bar.py[line:274] - INFO: epoch 001:  18833 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.9, bsz=40, num_updates=18810, lr=4.45813e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55339
2023-02-21 04:48:17 - progress_bar.py[line:274] - INFO: epoch 001:  18843 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.4, bsz=40, num_updates=18820, lr=4.45777e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=55350
2023-02-21 04:48:29 - progress_bar.py[line:274] - INFO: epoch 001:  18853 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=18830, lr=4.45741e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55362
2023-02-21 04:48:40 - progress_bar.py[line:274] - INFO: epoch 001:  18863 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=18840, lr=4.45705e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55373
2023-02-21 04:48:51 - progress_bar.py[line:274] - INFO: epoch 001:  18873 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=18850, lr=4.45669e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55384
2023-02-21 04:49:02 - progress_bar.py[line:274] - INFO: epoch 001:  18883 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.92, wpb=109.7, bsz=40, num_updates=18860, lr=4.45632e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=55395
2023-02-21 04:49:13 - progress_bar.py[line:274] - INFO: epoch 001:  18893 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.93, wpb=110.7, bsz=40, num_updates=18870, lr=4.45596e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55406
2023-02-21 04:49:24 - progress_bar.py[line:274] - INFO: epoch 001:  18903 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=18880, lr=4.4556e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55417
2023-02-21 04:49:35 - progress_bar.py[line:274] - INFO: epoch 001:  18913 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=18890, lr=4.45524e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55428
2023-02-21 04:49:47 - progress_bar.py[line:274] - INFO: epoch 001:  18923 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.88, wpb=110.8, bsz=40, num_updates=18900, lr=4.45488e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55439
2023-02-21 04:49:58 - progress_bar.py[line:274] - INFO: epoch 001:  18933 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.9, bsz=40, num_updates=18910, lr=4.45452e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55451
2023-02-21 04:50:09 - progress_bar.py[line:274] - INFO: epoch 001:  18943 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=18920, lr=4.45415e-05, gnorm=0.046, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55462
2023-02-21 04:50:20 - progress_bar.py[line:274] - INFO: epoch 001:  18953 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=18930, lr=4.45379e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55473
2023-02-21 04:50:31 - progress_bar.py[line:274] - INFO: epoch 001:  18963 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=18940, lr=4.45343e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55484
2023-02-21 04:50:43 - progress_bar.py[line:274] - INFO: epoch 001:  18973 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=18950, lr=4.45307e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55496
2023-02-21 04:50:54 - progress_bar.py[line:274] - INFO: epoch 001:  18983 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=18960, lr=4.45271e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55507
2023-02-21 04:51:05 - progress_bar.py[line:274] - INFO: epoch 001:  18993 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=18970, lr=4.45234e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=55518
2023-02-21 04:51:16 - progress_bar.py[line:274] - INFO: epoch 001:  19003 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=109.8, bsz=40, num_updates=18980, lr=4.45198e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55529
2023-02-21 04:51:27 - progress_bar.py[line:274] - INFO: epoch 001:  19013 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.5, bsz=40, num_updates=18990, lr=4.45162e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55540
2023-02-21 04:51:39 - progress_bar.py[line:274] - INFO: epoch 001:  19023 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.5, bsz=40, num_updates=19000, lr=4.45126e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55552
2023-02-21 04:51:50 - progress_bar.py[line:274] - INFO: epoch 001:  19033 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.6, ups=0.92, wpb=111.6, bsz=40, num_updates=19010, lr=4.4509e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55562
2023-02-21 04:52:01 - progress_bar.py[line:274] - INFO: epoch 001:  19043 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.7, bsz=40, num_updates=19020, lr=4.45054e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55574
2023-02-21 04:52:12 - progress_bar.py[line:274] - INFO: epoch 001:  19053 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.5, ups=0.94, wpb=110.8, bsz=40, num_updates=19030, lr=4.45017e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55584
2023-02-21 04:52:22 - progress_bar.py[line:274] - INFO: epoch 001:  19063 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111.2, bsz=40, num_updates=19040, lr=4.44981e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55595
2023-02-21 04:52:34 - progress_bar.py[line:274] - INFO: epoch 001:  19073 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=110.9, bsz=40, num_updates=19050, lr=4.44945e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55607
2023-02-21 04:52:45 - progress_bar.py[line:274] - INFO: epoch 001:  19083 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.9, bsz=40, num_updates=19060, lr=4.44909e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55618
2023-02-21 04:52:56 - progress_bar.py[line:274] - INFO: epoch 001:  19093 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=110.9, bsz=40, num_updates=19070, lr=4.44873e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55629
2023-02-21 04:53:07 - progress_bar.py[line:274] - INFO: epoch 001:  19103 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.93, wpb=110.6, bsz=40, num_updates=19080, lr=4.44836e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55640
2023-02-21 04:53:18 - progress_bar.py[line:274] - INFO: epoch 001:  19113 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=19090, lr=4.448e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55651
2023-02-21 04:53:29 - progress_bar.py[line:274] - INFO: epoch 001:  19123 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.93, wpb=110.5, bsz=40, num_updates=19100, lr=4.44764e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55662
2023-02-21 04:53:40 - progress_bar.py[line:274] - INFO: epoch 001:  19133 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=110.6, bsz=40, num_updates=19110, lr=4.44728e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55673
2023-02-21 04:53:52 - progress_bar.py[line:274] - INFO: epoch 001:  19143 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.6, bsz=40, num_updates=19120, lr=4.44692e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55684
2023-02-21 04:54:03 - progress_bar.py[line:274] - INFO: epoch 001:  19153 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=19130, lr=4.44656e-05, gnorm=0.118, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=55696
2023-02-21 04:54:14 - progress_bar.py[line:274] - INFO: epoch 001:  19163 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.89, wpb=112.3, bsz=40, num_updates=19140, lr=4.44619e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55707
2023-02-21 04:54:25 - progress_bar.py[line:274] - INFO: epoch 001:  19173 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.2, bsz=40, num_updates=19150, lr=4.44583e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55718
2023-02-21 04:54:36 - progress_bar.py[line:274] - INFO: epoch 001:  19183 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=19160, lr=4.44547e-05, gnorm=0.048, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55729
2023-02-21 04:54:47 - progress_bar.py[line:274] - INFO: epoch 001:  19193 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.93, wpb=110.2, bsz=40, num_updates=19170, lr=4.44511e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55740
2023-02-21 04:54:58 - progress_bar.py[line:274] - INFO: epoch 001:  19203 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.7, bsz=40, num_updates=19180, lr=4.44475e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55751
2023-02-21 04:55:09 - progress_bar.py[line:274] - INFO: epoch 001:  19213 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=19190, lr=4.44438e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55762
2023-02-21 04:55:21 - progress_bar.py[line:274] - INFO: epoch 001:  19223 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.4, bsz=40, num_updates=19200, lr=4.44402e-05, gnorm=0.05, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55773
2023-02-21 04:55:32 - progress_bar.py[line:274] - INFO: epoch 001:  19233 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.88, wpb=113, bsz=40, num_updates=19210, lr=4.44366e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55785
2023-02-21 04:55:43 - progress_bar.py[line:274] - INFO: epoch 001:  19243 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.2, bsz=40, num_updates=19220, lr=4.4433e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55796
2023-02-21 04:55:55 - progress_bar.py[line:274] - INFO: epoch 001:  19253 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=19230, lr=4.44294e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55807
2023-02-21 04:56:05 - progress_bar.py[line:274] - INFO: epoch 001:  19263 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.1, ups=0.93, wpb=111.9, bsz=40, num_updates=19240, lr=4.44258e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55818
2023-02-21 04:56:17 - progress_bar.py[line:274] - INFO: epoch 001:  19273 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.88, wpb=110.8, bsz=40, num_updates=19250, lr=4.44221e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55829
2023-02-21 04:56:28 - progress_bar.py[line:274] - INFO: epoch 001:  19283 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=111.1, bsz=40, num_updates=19260, lr=4.44185e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55841
2023-02-21 04:56:39 - progress_bar.py[line:274] - INFO: epoch 001:  19293 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.92, wpb=110.4, bsz=40, num_updates=19270, lr=4.44149e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55852
2023-02-21 04:56:50 - progress_bar.py[line:274] - INFO: epoch 001:  19303 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.92, wpb=112.7, bsz=40, num_updates=19280, lr=4.44113e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55863
2023-02-21 04:57:01 - progress_bar.py[line:274] - INFO: epoch 001:  19313 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=111.5, bsz=40, num_updates=19290, lr=4.44077e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55874
2023-02-21 04:57:13 - progress_bar.py[line:274] - INFO: epoch 001:  19323 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=19300, lr=4.4404e-05, gnorm=0.049, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55885
2023-02-21 04:57:24 - progress_bar.py[line:274] - INFO: epoch 001:  19333 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.91, wpb=110.6, bsz=40, num_updates=19310, lr=4.44004e-05, gnorm=0.093, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55897
2023-02-21 04:57:33 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 04:57:36 - progress_bar.py[line:274] - INFO: epoch 001:  19344 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.5, ups=0.84, wpb=111.5, bsz=40, num_updates=19320, lr=4.43968e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=55908
2023-02-21 04:57:47 - progress_bar.py[line:274] - INFO: epoch 001:  19354 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=19330, lr=4.43932e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55919
2023-02-21 04:57:57 - progress_bar.py[line:274] - INFO: epoch 001:  19364 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.6, ups=0.93, wpb=112.1, bsz=40, num_updates=19340, lr=4.43896e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55930
2023-02-21 04:58:09 - progress_bar.py[line:274] - INFO: epoch 001:  19374 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=19350, lr=4.43859e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=55941
2023-02-21 04:58:20 - progress_bar.py[line:274] - INFO: epoch 001:  19384 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.9, wpb=109.6, bsz=40, num_updates=19360, lr=4.43823e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55952
2023-02-21 04:58:31 - progress_bar.py[line:274] - INFO: epoch 001:  19394 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.7, bsz=40, num_updates=19370, lr=4.43787e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55964
2023-02-21 04:58:42 - progress_bar.py[line:274] - INFO: epoch 001:  19404 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112.3, bsz=40, num_updates=19380, lr=4.43751e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55975
2023-02-21 04:58:54 - progress_bar.py[line:274] - INFO: epoch 001:  19414 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.5, bsz=40, num_updates=19390, lr=4.43715e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55987
2023-02-21 04:59:05 - progress_bar.py[line:274] - INFO: epoch 001:  19424 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.1, bsz=40, num_updates=19400, lr=4.43679e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=55998
2023-02-21 04:59:16 - progress_bar.py[line:274] - INFO: epoch 001:  19434 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.3, bsz=40, num_updates=19410, lr=4.43642e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56009
2023-02-21 04:59:27 - progress_bar.py[line:274] - INFO: epoch 001:  19444 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.6, bsz=40, num_updates=19420, lr=4.43606e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56020
2023-02-21 04:59:38 - progress_bar.py[line:274] - INFO: epoch 001:  19454 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.9, wpb=111.3, bsz=40, num_updates=19430, lr=4.4357e-05, gnorm=0.106, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56031
2023-02-21 04:59:49 - progress_bar.py[line:274] - INFO: epoch 001:  19464 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.93, wpb=110.7, bsz=40, num_updates=19440, lr=4.43534e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56042
2023-02-21 05:00:00 - progress_bar.py[line:274] - INFO: epoch 001:  19474 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111.5, bsz=40, num_updates=19450, lr=4.43498e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=56053
2023-02-21 05:00:11 - progress_bar.py[line:274] - INFO: epoch 001:  19484 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=113.6, nsentences=40, sample_size=113.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.7, ups=0.93, wpb=113.6, bsz=40, num_updates=19460, lr=4.43461e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56064
2023-02-21 05:00:22 - progress_bar.py[line:274] - INFO: epoch 001:  19494 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=19470, lr=4.43425e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=56075
2023-02-21 05:00:33 - progress_bar.py[line:274] - INFO: epoch 001:  19504 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=106.3, ups=0.96, wpb=110.7, bsz=40, num_updates=19480, lr=4.43389e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=56086
2023-02-21 05:00:44 - progress_bar.py[line:274] - INFO: epoch 001:  19514 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=19490, lr=4.43353e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56097
2023-02-21 05:00:55 - progress_bar.py[line:274] - INFO: epoch 001:  19524 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=19500, lr=4.43317e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56108
2023-02-21 05:01:06 - progress_bar.py[line:274] - INFO: epoch 001:  19534 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=19510, lr=4.43281e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=56119
2023-02-21 05:01:17 - progress_bar.py[line:274] - INFO: epoch 001:  19544 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.4, bsz=40, num_updates=19520, lr=4.43244e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56130
2023-02-21 05:01:28 - progress_bar.py[line:274] - INFO: epoch 001:  19554 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.3, bsz=40, num_updates=19530, lr=4.43208e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56141
2023-02-21 05:01:39 - progress_bar.py[line:274] - INFO: epoch 001:  19564 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.9, bsz=40, num_updates=19540, lr=4.43172e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=56152
2023-02-21 05:01:50 - progress_bar.py[line:274] - INFO: epoch 001:  19574 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.93, wpb=111.3, bsz=40, num_updates=19550, lr=4.43136e-05, gnorm=0.042, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56162
2023-02-21 05:02:01 - progress_bar.py[line:274] - INFO: epoch 001:  19584 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.6, bsz=40, num_updates=19560, lr=4.431e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=56174
2023-02-21 05:02:12 - progress_bar.py[line:274] - INFO: epoch 001:  19594 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=19570, lr=4.43063e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=56185
2023-02-21 05:02:24 - progress_bar.py[line:274] - INFO: epoch 001:  19604 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.3, bsz=40, num_updates=19580, lr=4.43027e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56196
2023-02-21 05:02:35 - progress_bar.py[line:274] - INFO: epoch 001:  19614 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=19590, lr=4.42991e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56207
2023-02-21 05:02:46 - progress_bar.py[line:274] - INFO: epoch 001:  19624 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=19600, lr=4.42955e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56219
2023-02-21 05:02:57 - progress_bar.py[line:274] - INFO: epoch 001:  19634 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.5, bsz=40, num_updates=19610, lr=4.42919e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=56230
2023-02-21 05:03:08 - progress_bar.py[line:274] - INFO: epoch 001:  19644 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=110.4, bsz=40, num_updates=19620, lr=4.42883e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56241
2023-02-21 05:03:19 - progress_bar.py[line:274] - INFO: epoch 001:  19654 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.8, ups=0.93, wpb=111.5, bsz=40, num_updates=19630, lr=4.42846e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56252
2023-02-21 05:03:30 - progress_bar.py[line:274] - INFO: epoch 001:  19664 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112.1, bsz=40, num_updates=19640, lr=4.4281e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56263
2023-02-21 05:03:41 - progress_bar.py[line:274] - INFO: epoch 001:  19674 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112.1, bsz=40, num_updates=19650, lr=4.42774e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56274
2023-02-21 05:03:53 - progress_bar.py[line:274] - INFO: epoch 001:  19684 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.3, bsz=40, num_updates=19660, lr=4.42738e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56285
2023-02-21 05:04:04 - progress_bar.py[line:274] - INFO: epoch 001:  19694 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=111.8, bsz=40, num_updates=19670, lr=4.42702e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56297
2023-02-21 05:04:15 - progress_bar.py[line:274] - INFO: epoch 001:  19704 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.6, bsz=40, num_updates=19680, lr=4.42665e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56308
2023-02-21 05:04:26 - progress_bar.py[line:274] - INFO: epoch 001:  19714 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=19690, lr=4.42629e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=56319
2023-02-21 05:04:37 - progress_bar.py[line:274] - INFO: epoch 001:  19724 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.4, bsz=40, num_updates=19700, lr=4.42593e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56330
2023-02-21 05:04:48 - progress_bar.py[line:274] - INFO: epoch 001:  19734 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.1, bsz=40, num_updates=19710, lr=4.42557e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=56341
2023-02-21 05:05:00 - progress_bar.py[line:274] - INFO: epoch 001:  19744 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=112.2, bsz=40, num_updates=19720, lr=4.42521e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56353
2023-02-21 05:05:11 - progress_bar.py[line:274] - INFO: epoch 001:  19754 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.7, bsz=40, num_updates=19730, lr=4.42485e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=56364
2023-02-21 05:05:23 - progress_bar.py[line:274] - INFO: epoch 001:  19764 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=110.8, bsz=40, num_updates=19740, lr=4.42448e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56375
2023-02-21 05:05:34 - progress_bar.py[line:274] - INFO: epoch 001:  19774 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=19750, lr=4.42412e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=56387
2023-02-21 05:05:45 - progress_bar.py[line:274] - INFO: epoch 001:  19784 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=19760, lr=4.42376e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=56398
2023-02-21 05:05:56 - progress_bar.py[line:274] - INFO: epoch 001:  19794 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.4, ups=0.9, wpb=111, bsz=40, num_updates=19770, lr=4.4234e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56409
2023-02-21 05:06:07 - progress_bar.py[line:274] - INFO: epoch 001:  19804 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.88, wpb=109.4, bsz=40, num_updates=19780, lr=4.42304e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56420
2023-02-21 05:06:19 - progress_bar.py[line:274] - INFO: epoch 001:  19814 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.88, wpb=109.4, bsz=40, num_updates=19790, lr=4.42267e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56432
2023-02-21 05:06:30 - progress_bar.py[line:274] - INFO: epoch 001:  19824 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=112, bsz=40, num_updates=19800, lr=4.42231e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56443
2023-02-21 05:06:41 - progress_bar.py[line:274] - INFO: epoch 001:  19834 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=112, bsz=40, num_updates=19810, lr=4.42195e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56454
2023-02-21 05:06:52 - progress_bar.py[line:274] - INFO: epoch 001:  19844 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.7, bsz=40, num_updates=19820, lr=4.42159e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56465
2023-02-21 05:07:03 - progress_bar.py[line:274] - INFO: epoch 001:  19854 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.6, bsz=40, num_updates=19830, lr=4.42123e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56476
2023-02-21 05:07:14 - progress_bar.py[line:274] - INFO: epoch 001:  19864 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.7, bsz=40, num_updates=19840, lr=4.42087e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=56487
2023-02-21 05:07:25 - progress_bar.py[line:274] - INFO: epoch 001:  19874 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=19850, lr=4.4205e-05, gnorm=0.041, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56498
2023-02-21 05:07:37 - progress_bar.py[line:274] - INFO: epoch 001:  19884 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=110.6, bsz=40, num_updates=19860, lr=4.42014e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56510
2023-02-21 05:07:48 - progress_bar.py[line:274] - INFO: epoch 001:  19894 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=19870, lr=4.41978e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56521
2023-02-21 05:08:00 - progress_bar.py[line:274] - INFO: epoch 001:  19904 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.88, wpb=113.3, bsz=40, num_updates=19880, lr=4.41942e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56532
2023-02-21 05:08:11 - progress_bar.py[line:274] - INFO: epoch 001:  19914 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.9, bsz=40, num_updates=19890, lr=4.41906e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=56544
2023-02-21 05:08:22 - progress_bar.py[line:274] - INFO: epoch 001:  19924 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=113, bsz=40, num_updates=19900, lr=4.41869e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56555
2023-02-21 05:08:33 - progress_bar.py[line:274] - INFO: epoch 001:  19934 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.6, bsz=40, num_updates=19910, lr=4.41833e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=56566
2023-02-21 05:08:44 - progress_bar.py[line:274] - INFO: epoch 001:  19944 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=19920, lr=4.41797e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56577
2023-02-21 05:08:56 - progress_bar.py[line:274] - INFO: epoch 001:  19954 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=19930, lr=4.41761e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56588
2023-02-21 05:09:07 - progress_bar.py[line:274] - INFO: epoch 001:  19964 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=19940, lr=4.41725e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=56600
2023-02-21 05:09:18 - progress_bar.py[line:274] - INFO: epoch 001:  19974 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.2, bsz=40, num_updates=19950, lr=4.41689e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56611
2023-02-21 05:09:29 - progress_bar.py[line:274] - INFO: epoch 001:  19984 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=109.8, bsz=40, num_updates=19960, lr=4.41652e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=56622
2023-02-21 05:09:41 - progress_bar.py[line:274] - INFO: epoch 001:  19994 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=19970, lr=4.41616e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=56633
2023-02-21 05:09:52 - progress_bar.py[line:274] - INFO: epoch 001:  20004 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.92, wpb=110, bsz=40, num_updates=19980, lr=4.4158e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=56644
2023-02-21 05:10:03 - progress_bar.py[line:274] - INFO: epoch 001:  20014 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.4, bsz=40, num_updates=19990, lr=4.41544e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56655
2023-02-21 05:10:14 - progress_bar.py[line:274] - INFO: epoch 001:  20024 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.7, bsz=40, num_updates=20000, lr=4.41508e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=56667
2023-02-21 05:10:14 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 05:10:15 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 05:10:15 - train.py[line:551] - INFO: load:0.93 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 05:12:18 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 05:12:18 - train.py[line:551] - INFO: load:0.95 valid_run:122.53 task_valid:119.26 collect_output:2.24
2023-02-21 05:14:18 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 05:14:18 - train.py[line:551] - INFO: load:0.97 valid_run:242.30 task_valid:235.09 collect_output:5.19
2023-02-21 05:16:20 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 05:16:20 - train.py[line:551] - INFO: load:1.00 valid_run:364.38 task_valid:351.77 collect_output:9.60
2023-02-21 05:18:22 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 05:18:22 - train.py[line:551] - INFO: load:1.02 valid_run:486.26 task_valid:465.72 collect_output:16.51
2023-02-21 05:20:22 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 05:20:22 - train.py[line:551] - INFO: load:1.04 valid_run:606.80 task_valid:583.30 collect_output:18.48
2023-02-21 05:22:25 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 05:22:25 - train.py[line:551] - INFO: load:1.07 valid_run:729.82 task_valid:702.39 collect_output:21.41
2023-02-21 05:24:28 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 05:24:28 - train.py[line:551] - INFO: load:1.09 valid_run:852.80 task_valid:820.74 collect_output:25.04
2023-02-21 05:26:30 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 05:26:30 - train.py[line:551] - INFO: load:1.11 valid_run:974.77 task_valid:937.66 collect_output:29.09
2023-02-21 05:28:34 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 05:28:34 - train.py[line:551] - INFO: load:1.14 valid_run:1098.40 task_valid:1055.11 collect_output:34.27
2023-02-21 05:30:36 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 05:30:36 - train.py[line:551] - INFO: load:1.16 valid_run:1219.94 task_valid:1168.02 collect_output:41.90
2023-02-21 05:32:36 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 05:32:36 - train.py[line:551] - INFO: load:1.19 valid_run:1340.03 task_valid:1283.69 collect_output:45.29
2023-02-21 05:34:38 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 05:34:38 - train.py[line:551] - INFO: load:1.21 valid_run:1461.65 task_valid:1400.85 collect_output:48.76
2023-02-21 05:36:36 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 05:36:36 - train.py[line:551] - INFO: load:1.23 valid_run:1580.56 task_valid:1514.91 collect_output:52.62
2023-02-21 05:38:38 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 05:38:38 - train.py[line:551] - INFO: load:1.26 valid_run:1701.67 task_valid:1632.88 collect_output:54.75
2023-02-21 05:40:39 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 05:40:39 - train.py[line:551] - INFO: load:1.28 valid_run:1822.62 task_valid:1749.13 collect_output:58.46
2023-02-21 05:42:40 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 05:42:40 - train.py[line:551] - INFO: load:1.31 valid_run:1943.65 task_valid:1863.44 collect_output:64.18
2023-02-21 05:44:41 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 05:44:41 - train.py[line:551] - INFO: load:1.33 valid_run:2065.17 task_valid:1979.81 collect_output:68.32
2023-02-21 05:46:42 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 05:46:42 - train.py[line:551] - INFO: load:1.35 valid_run:2185.95 task_valid:2097.97 collect_output:69.94
2023-02-21 05:48:44 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 05:48:44 - train.py[line:551] - INFO: load:1.38 valid_run:2307.37 task_valid:2215.28 collect_output:73.03
2023-02-21 05:50:44 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 05:50:44 - train.py[line:551] - INFO: load:1.40 valid_run:2427.84 task_valid:2332.16 collect_output:75.61
2023-02-21 05:52:46 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 05:52:46 - train.py[line:551] - INFO: load:1.43 valid_run:2549.64 task_valid:2449.06 collect_output:79.48
2023-02-21 05:54:48 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 05:54:48 - train.py[line:551] - INFO: load:1.45 valid_run:2671.88 task_valid:2568.32 collect_output:81.45
2023-02-21 05:56:49 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 05:56:49 - train.py[line:551] - INFO: load:1.47 valid_run:2792.25 task_valid:2682.84 collect_output:86.28
2023-02-21 05:58:49 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 05:58:49 - train.py[line:551] - INFO: load:1.50 valid_run:2912.20 task_valid:2799.34 collect_output:88.71
2023-02-21 06:00:51 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 06:00:51 - train.py[line:551] - INFO: load:1.52 valid_run:3033.89 task_valid:2915.88 collect_output:92.85
2023-02-21 06:02:53 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 06:02:53 - train.py[line:551] - INFO: load:1.55 valid_run:3156.79 task_valid:3032.16 collect_output:98.46
2023-02-21 06:04:53 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 06:04:53 - train.py[line:551] - INFO: load:1.57 valid_run:3276.51 task_valid:3146.61 collect_output:102.70
2023-02-21 06:06:55 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 06:06:55 - train.py[line:551] - INFO: load:1.60 valid_run:3398.54 task_valid:3266.30 collect_output:104.02
2023-02-21 06:08:57 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 06:08:57 - train.py[line:551] - INFO: load:1.62 valid_run:3520.26 task_valid:3382.20 collect_output:108.81
2023-02-21 06:10:59 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 06:10:59 - train.py[line:551] - INFO: load:1.64 valid_run:3642.31 task_valid:3500.93 collect_output:111.10
2023-02-21 06:13:01 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 06:13:01 - train.py[line:551] - INFO: load:1.67 valid_run:3763.56 task_valid:3619.63 collect_output:112.62

====================================================================================================
SGG eval:     R @ 50: 0.6212;     R @ 100: 0.6503;     R @ 500: 0.6777;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3742;    mR @ 100: 0.4068;    mR @ 500: 0.4460;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7317) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.3750) (hanging from:0.4839) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:1.0000) (playing:0.0000) (riding:0.9304) (says:0.0000) (sitting on:0.7211) (standing on:0.3743) (using:0.5500) (walking in:0.0000) (walking on:0.7568) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6212;     R @ 100: 0.6503;     R @ 500: 0.6777;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3742;    mR @ 100: 0.4068;    mR @ 500: 0.4460;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7317) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.3750) (hanging from:0.4839) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:1.0000) (playing:0.0000) (riding:0.9304) (says:0.0000) (sitting on:0.7211) (standing on:0.3743) (using:0.5500) (walking in:0.0000) (walking on:0.7568) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================

2023-02-21 06:13:32 - train.py[line:487] - INFO: 0.6502624649859944
2023-02-21 06:13:32 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 06:13:32 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.218 | loss_v1 0 | loss_v2 0 | nll_loss 0.046 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.650262 | ppl 1.03 | vqa_score 0.3086 | wps 118.2 | wpb 72 | bsz 24 | num_updates 20000 | best_R@100 0.693596
2023-02-21 06:13:32 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 20000 updates
2023-02-21 06:13:32 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_20000.pt
2023-02-21 06:13:37 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_20000.pt
2023-02-21 06:13:40 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_20000.pt (epoch 1 @ 20000 updates, score 0.6502624649859944) (writing took 8.361278219148517 seconds)
2023-02-21 06:13:51 - progress_bar.py[line:274] - INFO: epoch 001:  20034 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=110.7, bsz=40, num_updates=20010, lr=4.41471e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60484
2023-02-21 06:14:03 - progress_bar.py[line:274] - INFO: epoch 001:  20044 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=20020, lr=4.41435e-05, gnorm=0.077, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60496
2023-02-21 06:14:14 - progress_bar.py[line:274] - INFO: epoch 001:  20054 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99, ups=0.9, wpb=110.6, bsz=40, num_updates=20030, lr=4.41399e-05, gnorm=0.091, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60507
2023-02-21 06:14:25 - progress_bar.py[line:274] - INFO: epoch 001:  20064 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.91, wpb=112.3, bsz=40, num_updates=20040, lr=4.41363e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60518
2023-02-21 06:14:36 - progress_bar.py[line:274] - INFO: epoch 001:  20074 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=101.5, ups=0.9, wpb=112.2, bsz=40, num_updates=20050, lr=4.41327e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60529
2023-02-21 06:14:47 - progress_bar.py[line:274] - INFO: epoch 001:  20084 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=112.1, bsz=40, num_updates=20060, lr=4.41291e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=60540
2023-02-21 06:14:58 - progress_bar.py[line:274] - INFO: epoch 001:  20094 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=20070, lr=4.41254e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=60551
2023-02-21 06:15:09 - progress_bar.py[line:274] - INFO: epoch 001:  20104 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110, bsz=40, num_updates=20080, lr=4.41218e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60562
2023-02-21 06:15:20 - progress_bar.py[line:274] - INFO: epoch 001:  20114 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=20090, lr=4.41182e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60573
2023-02-21 06:15:31 - progress_bar.py[line:274] - INFO: epoch 001:  20124 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.93, wpb=111, bsz=40, num_updates=20100, lr=4.41146e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60584
2023-02-21 06:15:42 - progress_bar.py[line:274] - INFO: epoch 001:  20134 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.8, bsz=40, num_updates=20110, lr=4.4111e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=60595
2023-02-21 06:15:53 - progress_bar.py[line:274] - INFO: epoch 001:  20144 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.6, bsz=40, num_updates=20120, lr=4.41073e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60606
2023-02-21 06:16:05 - progress_bar.py[line:274] - INFO: epoch 001:  20154 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=20130, lr=4.41037e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60617
2023-02-21 06:16:16 - progress_bar.py[line:274] - INFO: epoch 001:  20164 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.2, bsz=40, num_updates=20140, lr=4.41001e-05, gnorm=0.083, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60629
2023-02-21 06:16:27 - progress_bar.py[line:274] - INFO: epoch 001:  20174 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.92, wpb=111.4, bsz=40, num_updates=20150, lr=4.40965e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=60640
2023-02-21 06:16:38 - progress_bar.py[line:274] - INFO: epoch 001:  20184 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.9, bsz=40, num_updates=20160, lr=4.40929e-05, gnorm=0.046, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60651
2023-02-21 06:16:49 - progress_bar.py[line:274] - INFO: epoch 001:  20194 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.93, wpb=110, bsz=40, num_updates=20170, lr=4.40893e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=60662
2023-02-21 06:17:00 - progress_bar.py[line:274] - INFO: epoch 001:  20204 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.6, bsz=40, num_updates=20180, lr=4.40856e-05, gnorm=0.041, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60673
2023-02-21 06:17:11 - progress_bar.py[line:274] - INFO: epoch 001:  20214 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.4, bsz=40, num_updates=20190, lr=4.4082e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=60684
2023-02-21 06:17:22 - progress_bar.py[line:274] - INFO: epoch 001:  20224 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=20200, lr=4.40784e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60695
2023-02-21 06:17:34 - progress_bar.py[line:274] - INFO: epoch 001:  20234 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=20210, lr=4.40748e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60707
2023-02-21 06:17:45 - progress_bar.py[line:274] - INFO: epoch 001:  20244 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.7, bsz=40, num_updates=20220, lr=4.40712e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60718
2023-02-21 06:17:56 - progress_bar.py[line:274] - INFO: epoch 001:  20254 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.91, wpb=110.1, bsz=40, num_updates=20230, lr=4.40675e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60729
2023-02-21 06:18:07 - progress_bar.py[line:274] - INFO: epoch 001:  20264 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.6, bsz=40, num_updates=20240, lr=4.40639e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=60740
2023-02-21 06:18:18 - progress_bar.py[line:274] - INFO: epoch 001:  20274 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.6, bsz=40, num_updates=20250, lr=4.40603e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=60751
2023-02-21 06:18:29 - progress_bar.py[line:274] - INFO: epoch 001:  20284 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.1, bsz=40, num_updates=20260, lr=4.40567e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60762
2023-02-21 06:18:41 - progress_bar.py[line:274] - INFO: epoch 001:  20294 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.88, wpb=109.9, bsz=40, num_updates=20270, lr=4.40531e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=60773
2023-02-21 06:18:52 - progress_bar.py[line:274] - INFO: epoch 001:  20304 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.5, bsz=40, num_updates=20280, lr=4.40495e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60785
2023-02-21 06:19:03 - progress_bar.py[line:274] - INFO: epoch 001:  20314 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.92, wpb=110.3, bsz=40, num_updates=20290, lr=4.40458e-05, gnorm=0.101, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=60796
2023-02-21 06:19:14 - progress_bar.py[line:274] - INFO: epoch 001:  20324 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=20300, lr=4.40422e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=60807
2023-02-21 06:19:25 - progress_bar.py[line:274] - INFO: epoch 001:  20334 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=20310, lr=4.40386e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60818
2023-02-21 06:19:36 - progress_bar.py[line:274] - INFO: epoch 001:  20344 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=20320, lr=4.4035e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60829
2023-02-21 06:19:47 - progress_bar.py[line:274] - INFO: epoch 001:  20354 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.3, ups=0.94, wpb=111.6, bsz=40, num_updates=20330, lr=4.40314e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60840
2023-02-21 06:19:58 - progress_bar.py[line:274] - INFO: epoch 001:  20364 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.1, bsz=40, num_updates=20340, lr=4.40277e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60851
2023-02-21 06:20:09 - progress_bar.py[line:274] - INFO: epoch 001:  20374 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=20350, lr=4.40241e-05, gnorm=0.069, clip=0, loss_scale=16384, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=60862
2023-02-21 06:20:18 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8192.0
2023-02-21 06:20:21 - progress_bar.py[line:274] - INFO: epoch 001:  20385 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91.4, ups=0.83, wpb=110.2, bsz=40, num_updates=20360, lr=4.40205e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=60874
2023-02-21 06:20:32 - progress_bar.py[line:274] - INFO: epoch 001:  20395 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.5, bsz=40, num_updates=20370, lr=4.40169e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60885
2023-02-21 06:20:43 - progress_bar.py[line:274] - INFO: epoch 001:  20405 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=20380, lr=4.40133e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60896
2023-02-21 06:20:54 - progress_bar.py[line:274] - INFO: epoch 001:  20415 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.7, bsz=40, num_updates=20390, lr=4.40097e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=60907
2023-02-21 06:21:06 - progress_bar.py[line:274] - INFO: epoch 001:  20425 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=20400, lr=4.4006e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=60919
2023-02-21 06:21:17 - progress_bar.py[line:274] - INFO: epoch 001:  20435 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.89, wpb=111.6, bsz=40, num_updates=20410, lr=4.40024e-05, gnorm=0.086, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60930
2023-02-21 06:21:28 - progress_bar.py[line:274] - INFO: epoch 001:  20445 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.5, ups=0.87, wpb=109.7, bsz=40, num_updates=20420, lr=4.39988e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60941
2023-02-21 06:21:40 - progress_bar.py[line:274] - INFO: epoch 001:  20455 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.4, bsz=40, num_updates=20430, lr=4.39952e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60953
2023-02-21 06:21:51 - progress_bar.py[line:274] - INFO: epoch 001:  20465 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=109.9, bsz=40, num_updates=20440, lr=4.39916e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60964
2023-02-21 06:22:02 - progress_bar.py[line:274] - INFO: epoch 001:  20475 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=97.6, ups=0.88, wpb=110.7, bsz=40, num_updates=20450, lr=4.39879e-05, gnorm=0.034, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60975
2023-02-21 06:22:14 - progress_bar.py[line:274] - INFO: epoch 001:  20485 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=20460, lr=4.39843e-05, gnorm=0.047, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=60987
2023-02-21 06:22:25 - progress_bar.py[line:274] - INFO: epoch 001:  20495 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.93, wpb=109.3, bsz=40, num_updates=20470, lr=4.39807e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60997
2023-02-21 06:22:36 - progress_bar.py[line:274] - INFO: epoch 001:  20505 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=111.3, bsz=40, num_updates=20480, lr=4.39771e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61009
2023-02-21 06:22:47 - progress_bar.py[line:274] - INFO: epoch 001:  20515 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.1, bsz=40, num_updates=20490, lr=4.39735e-05, gnorm=0.083, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61020
2023-02-21 06:22:58 - progress_bar.py[line:274] - INFO: epoch 001:  20525 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.91, wpb=109.9, bsz=40, num_updates=20500, lr=4.39699e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61031
2023-02-21 06:23:09 - progress_bar.py[line:274] - INFO: epoch 001:  20535 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=20510, lr=4.39662e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61042
2023-02-21 06:23:21 - progress_bar.py[line:274] - INFO: epoch 001:  20545 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.3, bsz=40, num_updates=20520, lr=4.39626e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61053
2023-02-21 06:23:31 - progress_bar.py[line:274] - INFO: epoch 001:  20555 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.9, bsz=40, num_updates=20530, lr=4.3959e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61064
2023-02-21 06:23:43 - progress_bar.py[line:274] - INFO: epoch 001:  20565 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=20540, lr=4.39554e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61076
2023-02-21 06:23:54 - progress_bar.py[line:274] - INFO: epoch 001:  20575 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=111.8, bsz=40, num_updates=20550, lr=4.39518e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61087
2023-02-21 06:24:05 - progress_bar.py[line:274] - INFO: epoch 001:  20585 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.9, ups=0.93, wpb=111.7, bsz=40, num_updates=20560, lr=4.39481e-05, gnorm=0.045, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61097
2023-02-21 06:24:16 - progress_bar.py[line:274] - INFO: epoch 001:  20595 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=20570, lr=4.39445e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61109
2023-02-21 06:24:27 - progress_bar.py[line:274] - INFO: epoch 001:  20605 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.9, bsz=40, num_updates=20580, lr=4.39409e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61120
2023-02-21 06:24:38 - progress_bar.py[line:274] - INFO: epoch 001:  20615 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=20590, lr=4.39373e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61131
2023-02-21 06:24:50 - progress_bar.py[line:274] - INFO: epoch 001:  20625 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=111.5, bsz=40, num_updates=20600, lr=4.39337e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61142
2023-02-21 06:25:01 - progress_bar.py[line:274] - INFO: epoch 001:  20635 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.9, bsz=40, num_updates=20610, lr=4.39301e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61154
2023-02-21 06:25:12 - progress_bar.py[line:274] - INFO: epoch 001:  20645 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.93, wpb=112, bsz=40, num_updates=20620, lr=4.39264e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61165
2023-02-21 06:25:23 - progress_bar.py[line:274] - INFO: epoch 001:  20655 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=109.5, bsz=40, num_updates=20630, lr=4.39228e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61176
2023-02-21 06:25:34 - progress_bar.py[line:274] - INFO: epoch 001:  20665 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=20640, lr=4.39192e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61187
2023-02-21 06:25:45 - progress_bar.py[line:274] - INFO: epoch 001:  20675 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.5, bsz=40, num_updates=20650, lr=4.39156e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61198
2023-02-21 06:25:57 - progress_bar.py[line:274] - INFO: epoch 001:  20685 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.87, wpb=110.1, bsz=40, num_updates=20660, lr=4.3912e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61209
2023-02-21 06:26:08 - progress_bar.py[line:274] - INFO: epoch 001:  20695 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.87, wpb=111.4, bsz=40, num_updates=20670, lr=4.39083e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61221
2023-02-21 06:26:19 - progress_bar.py[line:274] - INFO: epoch 001:  20705 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.92, wpb=112.6, bsz=40, num_updates=20680, lr=4.39047e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61232
2023-02-21 06:26:30 - progress_bar.py[line:274] - INFO: epoch 001:  20715 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.7, bsz=40, num_updates=20690, lr=4.39011e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61243
2023-02-21 06:26:41 - progress_bar.py[line:274] - INFO: epoch 001:  20725 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.93, wpb=111.4, bsz=40, num_updates=20700, lr=4.38975e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61253
2023-02-21 06:26:52 - progress_bar.py[line:274] - INFO: epoch 001:  20735 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.9, bsz=40, num_updates=20710, lr=4.38939e-05, gnorm=0.077, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61265
2023-02-21 06:27:03 - progress_bar.py[line:274] - INFO: epoch 001:  20745 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.8, ups=0.88, wpb=109.6, bsz=40, num_updates=20720, lr=4.38903e-05, gnorm=0.076, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61276
2023-02-21 06:27:14 - progress_bar.py[line:274] - INFO: epoch 001:  20755 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.93, wpb=111.1, bsz=40, num_updates=20730, lr=4.38866e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61287
2023-02-21 06:27:25 - progress_bar.py[line:274] - INFO: epoch 001:  20765 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=20740, lr=4.3883e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61298
2023-02-21 06:27:36 - progress_bar.py[line:274] - INFO: epoch 001:  20775 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.4, bsz=40, num_updates=20750, lr=4.38794e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61309
2023-02-21 06:27:47 - progress_bar.py[line:274] - INFO: epoch 001:  20785 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=20760, lr=4.38758e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61320
2023-02-21 06:27:58 - progress_bar.py[line:274] - INFO: epoch 001:  20795 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.89, wpb=108.8, bsz=40, num_updates=20770, lr=4.38722e-05, gnorm=0.113, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61331
2023-02-21 06:28:09 - progress_bar.py[line:274] - INFO: epoch 001:  20805 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=20780, lr=4.38685e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61342
2023-02-21 06:28:17 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 06:28:22 - progress_bar.py[line:274] - INFO: epoch 001:  20816 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.7, ups=0.81, wpb=110.9, bsz=40, num_updates=20790, lr=4.38649e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=61355
2023-02-21 06:28:33 - progress_bar.py[line:274] - INFO: epoch 001:  20826 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.4, bsz=40, num_updates=20800, lr=4.38613e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61366
2023-02-21 06:28:44 - progress_bar.py[line:274] - INFO: epoch 001:  20836 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=20810, lr=4.38577e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61377
2023-02-21 06:28:55 - progress_bar.py[line:274] - INFO: epoch 001:  20846 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.92, wpb=112.6, bsz=40, num_updates=20820, lr=4.38541e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61388
2023-02-21 06:29:06 - progress_bar.py[line:274] - INFO: epoch 001:  20856 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=20830, lr=4.38505e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61399
2023-02-21 06:29:18 - progress_bar.py[line:274] - INFO: epoch 001:  20866 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=20840, lr=4.38468e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=61411
2023-02-21 06:29:29 - progress_bar.py[line:274] - INFO: epoch 001:  20876 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.7, bsz=40, num_updates=20850, lr=4.38432e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61421
2023-02-21 06:29:40 - progress_bar.py[line:274] - INFO: epoch 001:  20886 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=20860, lr=4.38396e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61433
2023-02-21 06:29:51 - progress_bar.py[line:274] - INFO: epoch 001:  20896 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=20870, lr=4.3836e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=61444
2023-02-21 06:30:02 - progress_bar.py[line:274] - INFO: epoch 001:  20906 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.2, bsz=40, num_updates=20880, lr=4.38324e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61455
2023-02-21 06:30:13 - progress_bar.py[line:274] - INFO: epoch 001:  20916 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.4, bsz=40, num_updates=20890, lr=4.38287e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61466
2023-02-21 06:30:24 - progress_bar.py[line:274] - INFO: epoch 001:  20926 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.91, wpb=109.1, bsz=40, num_updates=20900, lr=4.38251e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61477
2023-02-21 06:30:35 - progress_bar.py[line:274] - INFO: epoch 001:  20936 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.93, wpb=111.5, bsz=40, num_updates=20910, lr=4.38215e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61488
2023-02-21 06:30:47 - progress_bar.py[line:274] - INFO: epoch 001:  20946 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=111.2, bsz=40, num_updates=20920, lr=4.38179e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61499
2023-02-21 06:30:57 - progress_bar.py[line:274] - INFO: epoch 001:  20956 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.6, bsz=40, num_updates=20930, lr=4.38143e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61510
2023-02-21 06:31:09 - progress_bar.py[line:274] - INFO: epoch 001:  20966 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=111, bsz=40, num_updates=20940, lr=4.38107e-05, gnorm=0.045, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61522
2023-02-21 06:31:20 - progress_bar.py[line:274] - INFO: epoch 001:  20976 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.7, bsz=40, num_updates=20950, lr=4.3807e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61533
2023-02-21 06:31:32 - progress_bar.py[line:274] - INFO: epoch 001:  20986 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.89, wpb=110.7, bsz=40, num_updates=20960, lr=4.38034e-05, gnorm=0.124, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61544
2023-02-21 06:31:43 - progress_bar.py[line:274] - INFO: epoch 001:  20996 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=111.1, bsz=40, num_updates=20970, lr=4.37998e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=61556
2023-02-21 06:31:54 - progress_bar.py[line:274] - INFO: epoch 001:  21006 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.1, ups=0.94, wpb=111.3, bsz=40, num_updates=20980, lr=4.37962e-05, gnorm=0.092, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61567
2023-02-21 06:32:05 - progress_bar.py[line:274] - INFO: epoch 001:  21016 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=20990, lr=4.37926e-05, gnorm=0.05, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61578
2023-02-21 06:32:16 - progress_bar.py[line:274] - INFO: epoch 001:  21026 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=21000, lr=4.37889e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61589
2023-02-21 06:32:27 - progress_bar.py[line:274] - INFO: epoch 001:  21036 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.6, bsz=40, num_updates=21010, lr=4.37853e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61600
2023-02-21 06:32:38 - progress_bar.py[line:274] - INFO: epoch 001:  21046 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.93, wpb=111, bsz=40, num_updates=21020, lr=4.37817e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61611
2023-02-21 06:32:49 - progress_bar.py[line:274] - INFO: epoch 001:  21056 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.9, wpb=109.5, bsz=40, num_updates=21030, lr=4.37781e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61622
2023-02-21 06:33:00 - progress_bar.py[line:274] - INFO: epoch 001:  21066 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=21040, lr=4.37745e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61633
2023-02-21 06:33:11 - progress_bar.py[line:274] - INFO: epoch 001:  21076 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=110.6, bsz=40, num_updates=21050, lr=4.37709e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61644
2023-02-21 06:33:23 - progress_bar.py[line:274] - INFO: epoch 001:  21086 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111, bsz=40, num_updates=21060, lr=4.37672e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61655
2023-02-21 06:33:33 - progress_bar.py[line:274] - INFO: epoch 001:  21096 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111.4, bsz=40, num_updates=21070, lr=4.37636e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61666
2023-02-21 06:33:45 - progress_bar.py[line:274] - INFO: epoch 001:  21106 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.9, bsz=40, num_updates=21080, lr=4.376e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=61677
2023-02-21 06:33:56 - progress_bar.py[line:274] - INFO: epoch 001:  21116 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=21090, lr=4.37564e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61689
2023-02-21 06:34:07 - progress_bar.py[line:274] - INFO: epoch 001:  21126 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=110.8, bsz=40, num_updates=21100, lr=4.37528e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61700
2023-02-21 06:34:17 - progress_bar.py[line:274] - INFO: epoch 001:  21136 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.93, wpb=111.3, bsz=40, num_updates=21110, lr=4.37491e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61710
2023-02-21 06:34:28 - progress_bar.py[line:274] - INFO: epoch 001:  21146 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.5, bsz=40, num_updates=21120, lr=4.37455e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61721
2023-02-21 06:34:39 - progress_bar.py[line:274] - INFO: epoch 001:  21156 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.3, bsz=40, num_updates=21130, lr=4.37419e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=61732
2023-02-21 06:34:51 - progress_bar.py[line:274] - INFO: epoch 001:  21166 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=21140, lr=4.37383e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61744
2023-02-21 06:35:02 - progress_bar.py[line:274] - INFO: epoch 001:  21176 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=21150, lr=4.37347e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61755
2023-02-21 06:35:14 - progress_bar.py[line:274] - INFO: epoch 001:  21186 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.88, wpb=110.5, bsz=40, num_updates=21160, lr=4.3731e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61766
2023-02-21 06:35:25 - progress_bar.py[line:274] - INFO: epoch 001:  21196 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.8, bsz=40, num_updates=21170, lr=4.37274e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61777
2023-02-21 06:35:36 - progress_bar.py[line:274] - INFO: epoch 001:  21206 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.7, bsz=40, num_updates=21180, lr=4.37238e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61789
2023-02-21 06:35:47 - progress_bar.py[line:274] - INFO: epoch 001:  21216 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112.1, bsz=40, num_updates=21190, lr=4.37202e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61800
2023-02-21 06:35:58 - progress_bar.py[line:274] - INFO: epoch 001:  21226 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.5, bsz=40, num_updates=21200, lr=4.37166e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61811
2023-02-21 06:36:09 - progress_bar.py[line:274] - INFO: epoch 001:  21236 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.9, wpb=112.7, bsz=40, num_updates=21210, lr=4.3713e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61822
2023-02-21 06:36:21 - progress_bar.py[line:274] - INFO: epoch 001:  21246 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=21220, lr=4.37093e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61833
2023-02-21 06:36:32 - progress_bar.py[line:274] - INFO: epoch 001:  21256 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.3, bsz=40, num_updates=21230, lr=4.37057e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61845
2023-02-21 06:36:43 - progress_bar.py[line:274] - INFO: epoch 001:  21266 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=21240, lr=4.37021e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61856
2023-02-21 06:36:54 - progress_bar.py[line:274] - INFO: epoch 001:  21276 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.9, bsz=40, num_updates=21250, lr=4.36985e-05, gnorm=0.09, clip=0, loss_scale=4096, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=61867
2023-02-21 06:37:05 - progress_bar.py[line:274] - INFO: epoch 001:  21286 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=21260, lr=4.36949e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61878
2023-02-21 06:37:16 - progress_bar.py[line:274] - INFO: epoch 001:  21296 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=21270, lr=4.36912e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61889
2023-02-21 06:37:27 - progress_bar.py[line:274] - INFO: epoch 001:  21306 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.5, bsz=40, num_updates=21280, lr=4.36876e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61900
2023-02-21 06:37:39 - progress_bar.py[line:274] - INFO: epoch 001:  21316 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.7, bsz=40, num_updates=21290, lr=4.3684e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61912
2023-02-21 06:37:50 - progress_bar.py[line:274] - INFO: epoch 001:  21326 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=21300, lr=4.36804e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61923
2023-02-21 06:38:01 - progress_bar.py[line:274] - INFO: epoch 001:  21336 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.5, bsz=40, num_updates=21310, lr=4.36768e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61934
2023-02-21 06:38:12 - progress_bar.py[line:274] - INFO: epoch 001:  21346 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105, ups=0.95, wpb=110.6, bsz=40, num_updates=21320, lr=4.36732e-05, gnorm=0.085, clip=0, loss_scale=8192, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=61945
2023-02-21 06:38:23 - progress_bar.py[line:274] - INFO: epoch 001:  21356 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.9, bsz=40, num_updates=21330, lr=4.36695e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61956
2023-02-21 06:38:34 - progress_bar.py[line:274] - INFO: epoch 001:  21366 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.3, bsz=40, num_updates=21340, lr=4.36659e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61967
2023-02-21 06:38:46 - progress_bar.py[line:274] - INFO: epoch 001:  21376 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.4, bsz=40, num_updates=21350, lr=4.36623e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61978
2023-02-21 06:38:57 - progress_bar.py[line:274] - INFO: epoch 001:  21386 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.5, bsz=40, num_updates=21360, lr=4.36587e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=61990
2023-02-21 06:39:08 - progress_bar.py[line:274] - INFO: epoch 001:  21396 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.7, bsz=40, num_updates=21370, lr=4.36551e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62001
2023-02-21 06:39:19 - progress_bar.py[line:274] - INFO: epoch 001:  21406 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.93, wpb=110.7, bsz=40, num_updates=21380, lr=4.36514e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62012
2023-02-21 06:39:30 - progress_bar.py[line:274] - INFO: epoch 001:  21416 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.3, bsz=40, num_updates=21390, lr=4.36478e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62023
2023-02-21 06:39:42 - progress_bar.py[line:274] - INFO: epoch 001:  21426 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.4, bsz=40, num_updates=21400, lr=4.36442e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62035
2023-02-21 06:39:54 - progress_bar.py[line:274] - INFO: epoch 001:  21436 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.88, wpb=110.7, bsz=40, num_updates=21410, lr=4.36406e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62046
2023-02-21 06:40:05 - progress_bar.py[line:274] - INFO: epoch 001:  21446 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=21420, lr=4.3637e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62058
2023-02-21 06:40:16 - progress_bar.py[line:274] - INFO: epoch 001:  21456 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.4, bsz=40, num_updates=21430, lr=4.36334e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62069
2023-02-21 06:40:28 - progress_bar.py[line:274] - INFO: epoch 001:  21466 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=112.2, bsz=40, num_updates=21440, lr=4.36297e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=62081
2023-02-21 06:40:39 - progress_bar.py[line:274] - INFO: epoch 001:  21476 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.93, wpb=110.8, bsz=40, num_updates=21450, lr=4.36261e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62091
2023-02-21 06:40:50 - progress_bar.py[line:274] - INFO: epoch 001:  21486 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.7, bsz=40, num_updates=21460, lr=4.36225e-05, gnorm=0.087, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62103
2023-02-21 06:41:01 - progress_bar.py[line:274] - INFO: epoch 001:  21496 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.88, wpb=112.8, bsz=40, num_updates=21470, lr=4.36189e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62114
2023-02-21 06:41:12 - progress_bar.py[line:274] - INFO: epoch 001:  21506 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=21480, lr=4.36153e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62125
2023-02-21 06:41:23 - progress_bar.py[line:274] - INFO: epoch 001:  21516 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.5, bsz=40, num_updates=21490, lr=4.36116e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62136
2023-02-21 06:41:35 - progress_bar.py[line:274] - INFO: epoch 001:  21526 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=21500, lr=4.3608e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62148
2023-02-21 06:41:46 - progress_bar.py[line:274] - INFO: epoch 001:  21536 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=21510, lr=4.36044e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62159
2023-02-21 06:41:57 - progress_bar.py[line:274] - INFO: epoch 001:  21546 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=21520, lr=4.36008e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62170
2023-02-21 06:42:08 - progress_bar.py[line:274] - INFO: epoch 001:  21556 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=21530, lr=4.35972e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62181
2023-02-21 06:42:19 - progress_bar.py[line:274] - INFO: epoch 001:  21566 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.5, bsz=40, num_updates=21540, lr=4.35936e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62192
2023-02-21 06:42:31 - progress_bar.py[line:274] - INFO: epoch 001:  21576 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=111.9, bsz=40, num_updates=21550, lr=4.35899e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62204
2023-02-21 06:42:42 - progress_bar.py[line:274] - INFO: epoch 001:  21586 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.9, bsz=40, num_updates=21560, lr=4.35863e-05, gnorm=0.086, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62214
2023-02-21 06:42:53 - progress_bar.py[line:274] - INFO: epoch 001:  21596 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.2, bsz=40, num_updates=21570, lr=4.35827e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62226
2023-02-21 06:43:04 - progress_bar.py[line:274] - INFO: epoch 001:  21606 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.9, bsz=40, num_updates=21580, lr=4.35791e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62237
2023-02-21 06:43:15 - progress_bar.py[line:274] - INFO: epoch 001:  21616 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=21590, lr=4.35755e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62248
2023-02-21 06:43:26 - progress_bar.py[line:274] - INFO: epoch 001:  21626 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.92, wpb=109.3, bsz=40, num_updates=21600, lr=4.35718e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62259
2023-02-21 06:43:38 - progress_bar.py[line:274] - INFO: epoch 001:  21636 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=112.1, bsz=40, num_updates=21610, lr=4.35682e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62271
2023-02-21 06:43:49 - progress_bar.py[line:274] - INFO: epoch 001:  21646 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=21620, lr=4.35646e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62282
2023-02-21 06:44:00 - progress_bar.py[line:274] - INFO: epoch 001:  21656 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.5, bsz=40, num_updates=21630, lr=4.3561e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62293
2023-02-21 06:44:11 - progress_bar.py[line:274] - INFO: epoch 001:  21666 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.2, bsz=40, num_updates=21640, lr=4.35574e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62304
2023-02-21 06:44:23 - progress_bar.py[line:274] - INFO: epoch 001:  21676 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=21650, lr=4.35538e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62315
2023-02-21 06:44:34 - progress_bar.py[line:274] - INFO: epoch 001:  21686 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.4, bsz=40, num_updates=21660, lr=4.35501e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62327
2023-02-21 06:44:45 - progress_bar.py[line:274] - INFO: epoch 001:  21696 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=112, bsz=40, num_updates=21670, lr=4.35465e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62338
2023-02-21 06:44:56 - progress_bar.py[line:274] - INFO: epoch 001:  21706 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.3, bsz=40, num_updates=21680, lr=4.35429e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62349
2023-02-21 06:45:07 - progress_bar.py[line:274] - INFO: epoch 001:  21716 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=112.1, bsz=40, num_updates=21690, lr=4.35393e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62360
2023-02-21 06:45:18 - progress_bar.py[line:274] - INFO: epoch 001:  21726 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.8, bsz=40, num_updates=21700, lr=4.35357e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62371
2023-02-21 06:45:29 - progress_bar.py[line:274] - INFO: epoch 001:  21736 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.8, bsz=40, num_updates=21710, lr=4.3532e-05, gnorm=0.049, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62382
2023-02-21 06:45:40 - progress_bar.py[line:274] - INFO: epoch 001:  21746 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.7, bsz=40, num_updates=21720, lr=4.35284e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62393
2023-02-21 06:45:52 - progress_bar.py[line:274] - INFO: epoch 001:  21756 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.6, bsz=40, num_updates=21730, lr=4.35248e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62404
2023-02-21 06:46:03 - progress_bar.py[line:274] - INFO: epoch 001:  21766 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.9, bsz=40, num_updates=21740, lr=4.35212e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62416
2023-02-21 06:46:14 - progress_bar.py[line:274] - INFO: epoch 001:  21776 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.92, wpb=109.8, bsz=40, num_updates=21750, lr=4.35176e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62427
2023-02-21 06:46:25 - progress_bar.py[line:274] - INFO: epoch 001:  21786 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110.6, bsz=40, num_updates=21760, lr=4.3514e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62437
2023-02-21 06:46:35 - progress_bar.py[line:274] - INFO: epoch 001:  21796 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.4, bsz=40, num_updates=21770, lr=4.35103e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62448
2023-02-21 06:46:47 - progress_bar.py[line:274] - INFO: epoch 001:  21806 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=21780, lr=4.35067e-05, gnorm=0.046, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62459
2023-02-21 06:46:57 - progress_bar.py[line:274] - INFO: epoch 001:  21816 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.6, bsz=40, num_updates=21790, lr=4.35031e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62470
2023-02-21 06:47:09 - progress_bar.py[line:274] - INFO: epoch 001:  21826 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=111, bsz=40, num_updates=21800, lr=4.34995e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62481
2023-02-21 06:47:20 - progress_bar.py[line:274] - INFO: epoch 001:  21836 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.5, bsz=40, num_updates=21810, lr=4.34959e-05, gnorm=0.067, clip=0, loss_scale=16384, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62493
2023-02-21 06:47:31 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8192.0
2023-02-21 06:47:32 - progress_bar.py[line:274] - INFO: epoch 001:  21847 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88.7, ups=0.8, wpb=110.9, bsz=40, num_updates=21820, lr=4.34922e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=62505
2023-02-21 06:47:44 - progress_bar.py[line:274] - INFO: epoch 001:  21857 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=109.8, bsz=40, num_updates=21830, lr=4.34886e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62516
2023-02-21 06:47:46 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 06:47:56 - progress_bar.py[line:274] - INFO: epoch 001:  21868 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.1, ups=0.83, wpb=111, bsz=40, num_updates=21840, lr=4.3485e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=62528
2023-02-21 06:48:07 - progress_bar.py[line:274] - INFO: epoch 001:  21878 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=112.4, bsz=40, num_updates=21850, lr=4.34814e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62540
2023-02-21 06:48:18 - progress_bar.py[line:274] - INFO: epoch 001:  21888 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.89, wpb=109.1, bsz=40, num_updates=21860, lr=4.34778e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62551
2023-02-21 06:48:29 - progress_bar.py[line:274] - INFO: epoch 001:  21898 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.92, wpb=110.6, bsz=40, num_updates=21870, lr=4.34742e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62562
2023-02-21 06:48:40 - progress_bar.py[line:274] - INFO: epoch 001:  21908 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.2, bsz=40, num_updates=21880, lr=4.34705e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62573
2023-02-21 06:48:51 - progress_bar.py[line:274] - INFO: epoch 001:  21918 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.7, ups=0.92, wpb=111.6, bsz=40, num_updates=21890, lr=4.34669e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62583
2023-02-21 06:49:02 - progress_bar.py[line:274] - INFO: epoch 001:  21928 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=110.4, bsz=40, num_updates=21900, lr=4.34633e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62594
2023-02-21 06:49:13 - progress_bar.py[line:274] - INFO: epoch 001:  21938 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.7, bsz=40, num_updates=21910, lr=4.34597e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62606
2023-02-21 06:49:24 - progress_bar.py[line:274] - INFO: epoch 001:  21948 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.9, bsz=40, num_updates=21920, lr=4.34561e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62617
2023-02-21 06:49:35 - progress_bar.py[line:274] - INFO: epoch 001:  21958 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=21930, lr=4.34524e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62628
2023-02-21 06:49:46 - progress_bar.py[line:274] - INFO: epoch 001:  21968 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=21940, lr=4.34488e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62639
2023-02-21 06:49:57 - progress_bar.py[line:274] - INFO: epoch 001:  21978 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.3, bsz=40, num_updates=21950, lr=4.34452e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62650
2023-02-21 06:50:08 - progress_bar.py[line:274] - INFO: epoch 001:  21988 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=21960, lr=4.34416e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62661
2023-02-21 06:50:20 - progress_bar.py[line:274] - INFO: epoch 001:  21998 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=110.7, bsz=40, num_updates=21970, lr=4.3438e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62673
2023-02-21 06:50:31 - progress_bar.py[line:274] - INFO: epoch 001:  22008 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.4, bsz=40, num_updates=21980, lr=4.34344e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62684
2023-02-21 06:50:42 - progress_bar.py[line:274] - INFO: epoch 001:  22018 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.6, bsz=40, num_updates=21990, lr=4.34307e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62695
2023-02-21 06:50:53 - progress_bar.py[line:274] - INFO: epoch 001:  22028 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.4, bsz=40, num_updates=22000, lr=4.34271e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62706
2023-02-21 06:50:53 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 06:50:55 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 06:50:55 - train.py[line:551] - INFO: load:1.14 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 06:52:57 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 06:52:57 - train.py[line:551] - INFO: load:1.16 valid_run:122.41 task_valid:119.48 collect_output:1.90
2023-02-21 06:54:57 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 06:54:57 - train.py[line:551] - INFO: load:1.19 valid_run:242.29 task_valid:235.48 collect_output:4.77
2023-02-21 06:56:59 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 06:56:59 - train.py[line:551] - INFO: load:1.21 valid_run:364.26 task_valid:352.21 collect_output:8.99
2023-02-21 06:59:01 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 06:59:01 - train.py[line:551] - INFO: load:1.24 valid_run:486.39 task_valid:466.20 collect_output:16.12
2023-02-21 07:01:02 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 07:01:02 - train.py[line:551] - INFO: load:1.26 valid_run:606.89 task_valid:583.69 collect_output:18.13
2023-02-21 07:03:05 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 07:03:05 - train.py[line:551] - INFO: load:1.28 valid_run:729.89 task_valid:702.72 collect_output:21.11
2023-02-21 07:05:08 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 07:05:08 - train.py[line:551] - INFO: load:1.31 valid_run:852.96 task_valid:821.06 collect_output:24.83
2023-02-21 07:07:10 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 07:07:10 - train.py[line:551] - INFO: load:1.34 valid_run:974.88 task_valid:938.01 collect_output:28.79
2023-02-21 07:09:14 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 07:09:14 - train.py[line:551] - INFO: load:1.36 valid_run:1098.55 task_valid:1055.47 collect_output:33.98
2023-02-21 07:11:16 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 07:11:16 - train.py[line:551] - INFO: load:1.39 valid_run:1220.38 task_valid:1168.53 collect_output:41.73
2023-02-21 07:13:16 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 07:13:16 - train.py[line:551] - INFO: load:1.41 valid_run:1340.65 task_valid:1284.40 collect_output:45.12
2023-02-21 07:15:18 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 07:15:18 - train.py[line:551] - INFO: load:1.44 valid_run:1462.21 task_valid:1401.57 collect_output:48.51
2023-02-21 07:17:17 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 07:17:17 - train.py[line:551] - INFO: load:1.46 valid_run:1581.14 task_valid:1515.56 collect_output:52.43
2023-02-21 07:19:18 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 07:19:18 - train.py[line:551] - INFO: load:1.49 valid_run:1702.18 task_valid:1633.44 collect_output:54.56
2023-02-21 07:21:19 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 07:21:19 - train.py[line:551] - INFO: load:1.51 valid_run:1823.23 task_valid:1749.77 collect_output:58.24
2023-02-21 07:23:20 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 07:23:20 - train.py[line:551] - INFO: load:1.54 valid_run:1944.33 task_valid:1864.00 collect_output:64.08
2023-02-21 07:25:21 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 07:25:21 - train.py[line:551] - INFO: load:1.56 valid_run:2065.80 task_valid:1980.33 collect_output:68.22
2023-02-21 07:27:22 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 07:27:22 - train.py[line:551] - INFO: load:1.59 valid_run:2186.70 task_valid:2098.54 collect_output:69.88
2023-02-21 07:29:24 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 07:29:24 - train.py[line:551] - INFO: load:1.61 valid_run:2308.17 task_valid:2215.69 collect_output:73.18
2023-02-21 07:31:24 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 07:31:24 - train.py[line:551] - INFO: load:1.64 valid_run:2428.56 task_valid:2332.34 collect_output:75.93
2023-02-21 07:33:26 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 07:33:26 - train.py[line:551] - INFO: load:1.67 valid_run:2550.27 task_valid:2449.10 collect_output:79.86
2023-02-21 07:35:28 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 07:35:28 - train.py[line:551] - INFO: load:1.69 valid_run:2672.46 task_valid:2568.26 collect_output:81.88
2023-02-21 07:37:29 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 07:37:29 - train.py[line:551] - INFO: load:1.72 valid_run:2792.86 task_valid:2682.78 collect_output:86.76
2023-02-21 07:39:29 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 07:39:29 - train.py[line:551] - INFO: load:1.74 valid_run:2912.85 task_valid:2799.13 collect_output:89.37
2023-02-21 07:41:31 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 07:41:31 - train.py[line:551] - INFO: load:1.77 valid_run:3034.48 task_valid:2915.51 collect_output:93.61
2023-02-21 07:43:33 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 07:43:33 - train.py[line:551] - INFO: load:1.79 valid_run:3157.26 task_valid:3031.65 collect_output:99.24
2023-02-21 07:45:33 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 07:45:33 - train.py[line:551] - INFO: load:1.82 valid_run:3276.71 task_valid:3145.89 collect_output:103.45
2023-02-21 07:47:35 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 07:47:35 - train.py[line:551] - INFO: load:1.85 valid_run:3398.72 task_valid:3265.57 collect_output:104.77
2023-02-21 07:49:37 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 07:49:37 - train.py[line:551] - INFO: load:1.87 valid_run:3520.44 task_valid:3381.22 collect_output:109.84
2023-02-21 07:51:39 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 07:51:39 - train.py[line:551] - INFO: load:1.90 valid_run:3642.25 task_valid:3499.73 collect_output:112.11
2023-02-21 07:53:40 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 07:53:40 - train.py[line:551] - INFO: load:1.92 valid_run:3763.51 task_valid:3618.49 collect_output:113.61

====================================================================================================
SGG eval:     R @ 50: 0.6092;     R @ 100: 0.6403;     R @ 500: 0.6670;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3685;    mR @ 100: 0.4041;    mR @ 500: 0.4419;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3871) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9206) (says:0.0000) (sitting on:0.7143) (standing on:0.3910) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6092;     R @ 100: 0.6403;     R @ 500: 0.6670;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3685;    mR @ 100: 0.4041;    mR @ 500: 0.4419;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3871) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9206) (says:0.0000) (sitting on:0.7143) (standing on:0.3910) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================

2023-02-21 07:54:11 - train.py[line:487] - INFO: 0.6402624649859944
2023-02-21 07:54:11 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 07:54:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.219 | loss_v1 0 | loss_v2 0 | nll_loss 0.048 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.640262 | ppl 1.03 | vqa_score 0.3041 | wps 118.2 | wpb 72 | bsz 24 | num_updates 22000 | best_R@100 0.693596
2023-02-21 07:54:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 22000 updates
2023-02-21 07:54:11 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_22000.pt
2023-02-21 07:54:17 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_22000.pt
2023-02-21 07:54:20 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_22000.pt (epoch 1 @ 22000 updates, score 0.6402624649859944) (writing took 8.727388909086585 seconds)
2023-02-21 07:54:31 - progress_bar.py[line:274] - INFO: epoch 001:  22038 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=111.7, bsz=40, num_updates=22010, lr=4.34235e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66523
2023-02-21 07:54:42 - progress_bar.py[line:274] - INFO: epoch 001:  22048 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.89, wpb=109.3, bsz=40, num_updates=22020, lr=4.34199e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=66535
2023-02-21 07:54:53 - progress_bar.py[line:274] - INFO: epoch 001:  22058 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.87, wpb=113.1, bsz=40, num_updates=22030, lr=4.34163e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66546
2023-02-21 07:55:05 - progress_bar.py[line:274] - INFO: epoch 001:  22068 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=22040, lr=4.34126e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66557
2023-02-21 07:55:16 - progress_bar.py[line:274] - INFO: epoch 001:  22078 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.4, bsz=40, num_updates=22050, lr=4.3409e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=66569
2023-02-21 07:55:27 - progress_bar.py[line:274] - INFO: epoch 001:  22088 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.4, bsz=40, num_updates=22060, lr=4.34054e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66580
2023-02-21 07:55:38 - progress_bar.py[line:274] - INFO: epoch 001:  22098 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.9, ups=0.92, wpb=111.1, bsz=40, num_updates=22070, lr=4.34018e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66591
2023-02-21 07:55:49 - progress_bar.py[line:274] - INFO: epoch 001:  22108 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.6, bsz=40, num_updates=22080, lr=4.33982e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66602
2023-02-21 07:56:00 - progress_bar.py[line:274] - INFO: epoch 001:  22118 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.91, wpb=109.8, bsz=40, num_updates=22090, lr=4.33946e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66613
2023-02-21 07:56:11 - progress_bar.py[line:274] - INFO: epoch 001:  22128 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.93, wpb=111.2, bsz=40, num_updates=22100, lr=4.33909e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66624
2023-02-21 07:56:22 - progress_bar.py[line:274] - INFO: epoch 001:  22138 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=22110, lr=4.33873e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66635
2023-02-21 07:56:33 - progress_bar.py[line:274] - INFO: epoch 001:  22148 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.89, wpb=113, bsz=40, num_updates=22120, lr=4.33837e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66646
2023-02-21 07:56:45 - progress_bar.py[line:274] - INFO: epoch 001:  22158 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.3, bsz=40, num_updates=22130, lr=4.33801e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66657
2023-02-21 07:56:56 - progress_bar.py[line:274] - INFO: epoch 001:  22168 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.5, bsz=40, num_updates=22140, lr=4.33765e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66669
2023-02-21 07:57:07 - progress_bar.py[line:274] - INFO: epoch 001:  22178 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.7, bsz=40, num_updates=22150, lr=4.33728e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66680
2023-02-21 07:57:18 - progress_bar.py[line:274] - INFO: epoch 001:  22188 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.2, bsz=40, num_updates=22160, lr=4.33692e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66691
2023-02-21 07:57:29 - progress_bar.py[line:274] - INFO: epoch 001:  22198 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.89, wpb=112.3, bsz=40, num_updates=22170, lr=4.33656e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66702
2023-02-21 07:57:40 - progress_bar.py[line:274] - INFO: epoch 001:  22208 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.92, wpb=110.3, bsz=40, num_updates=22180, lr=4.3362e-05, gnorm=0.05, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66713
2023-02-21 07:57:51 - progress_bar.py[line:274] - INFO: epoch 001:  22218 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.9, bsz=40, num_updates=22190, lr=4.33584e-05, gnorm=0.045, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66724
2023-02-21 07:58:02 - progress_bar.py[line:274] - INFO: epoch 001:  22228 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.87, wpb=111.2, bsz=40, num_updates=22200, lr=4.33548e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66735
2023-02-21 07:58:13 - progress_bar.py[line:274] - INFO: epoch 001:  22238 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=22210, lr=4.33511e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66746
2023-02-21 07:58:24 - progress_bar.py[line:274] - INFO: epoch 001:  22248 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=22220, lr=4.33475e-05, gnorm=0.086, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=66757
2023-02-21 07:58:36 - progress_bar.py[line:274] - INFO: epoch 001:  22258 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.7, bsz=40, num_updates=22230, lr=4.33439e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66769
2023-02-21 07:58:47 - progress_bar.py[line:274] - INFO: epoch 001:  22268 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.9, bsz=40, num_updates=22240, lr=4.33403e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66780
2023-02-21 07:58:58 - progress_bar.py[line:274] - INFO: epoch 001:  22278 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.3, bsz=40, num_updates=22250, lr=4.33367e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66791
2023-02-21 07:59:09 - progress_bar.py[line:274] - INFO: epoch 001:  22288 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110.7, bsz=40, num_updates=22260, lr=4.3333e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=66802
2023-02-21 07:59:20 - progress_bar.py[line:274] - INFO: epoch 001:  22298 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=111, bsz=40, num_updates=22270, lr=4.33294e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66813
2023-02-21 07:59:31 - progress_bar.py[line:274] - INFO: epoch 001:  22308 / 142023 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=106.4, ups=0.94, wpb=112.9, bsz=40, num_updates=22280, lr=4.33258e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=66824
2023-02-21 07:59:42 - progress_bar.py[line:274] - INFO: epoch 001:  22318 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.4, bsz=40, num_updates=22290, lr=4.33222e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66835
2023-02-21 07:59:54 - progress_bar.py[line:274] - INFO: epoch 001:  22328 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=111, bsz=40, num_updates=22300, lr=4.33186e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66847
2023-02-21 08:00:05 - progress_bar.py[line:274] - INFO: epoch 001:  22338 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=110.5, bsz=40, num_updates=22310, lr=4.3315e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66857
2023-02-21 08:00:16 - progress_bar.py[line:274] - INFO: epoch 001:  22348 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.6, bsz=40, num_updates=22320, lr=4.33113e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66869
2023-02-21 08:00:27 - progress_bar.py[line:274] - INFO: epoch 001:  22358 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.89, wpb=112.8, bsz=40, num_updates=22330, lr=4.33077e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66880
2023-02-21 08:00:39 - progress_bar.py[line:274] - INFO: epoch 001:  22368 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=22340, lr=4.33041e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66891
2023-02-21 08:00:50 - progress_bar.py[line:274] - INFO: epoch 001:  22378 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=22350, lr=4.33005e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=66903
2023-02-21 08:01:01 - progress_bar.py[line:274] - INFO: epoch 001:  22388 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=22360, lr=4.32969e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66914
2023-02-21 08:01:12 - progress_bar.py[line:274] - INFO: epoch 001:  22398 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=112.1, bsz=40, num_updates=22370, lr=4.32932e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66925
2023-02-21 08:01:23 - progress_bar.py[line:274] - INFO: epoch 001:  22408 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=22380, lr=4.32896e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66936
2023-02-21 08:01:34 - progress_bar.py[line:274] - INFO: epoch 001:  22418 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=22390, lr=4.3286e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66947
2023-02-21 08:01:45 - progress_bar.py[line:274] - INFO: epoch 001:  22428 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.5, bsz=40, num_updates=22400, lr=4.32824e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66958
2023-02-21 08:01:56 - progress_bar.py[line:274] - INFO: epoch 001:  22438 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.7, bsz=40, num_updates=22410, lr=4.32788e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66969
2023-02-21 08:02:08 - progress_bar.py[line:274] - INFO: epoch 001:  22448 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=22420, lr=4.32752e-05, gnorm=0.046, clip=0, loss_scale=8192, train_wall=11, gb_free=10, ema_decay=0.9999, wall=66981
2023-02-21 08:02:19 - progress_bar.py[line:274] - INFO: epoch 001:  22458 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.4, bsz=40, num_updates=22430, lr=4.32715e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66992
2023-02-21 08:02:30 - progress_bar.py[line:274] - INFO: epoch 001:  22468 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.93, wpb=111.3, bsz=40, num_updates=22440, lr=4.32679e-05, gnorm=0.038, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67002
2023-02-21 08:02:41 - progress_bar.py[line:274] - INFO: epoch 001:  22478 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111, bsz=40, num_updates=22450, lr=4.32643e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67014
2023-02-21 08:02:52 - progress_bar.py[line:274] - INFO: epoch 001:  22488 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.4, ups=0.87, wpb=111.4, bsz=40, num_updates=22460, lr=4.32607e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67025
2023-02-21 08:03:04 - progress_bar.py[line:274] - INFO: epoch 001:  22498 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.8, bsz=40, num_updates=22470, lr=4.32571e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67036
2023-02-21 08:03:15 - progress_bar.py[line:274] - INFO: epoch 001:  22508 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.3, bsz=40, num_updates=22480, lr=4.32534e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67048
2023-02-21 08:03:26 - progress_bar.py[line:274] - INFO: epoch 001:  22518 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.2, bsz=40, num_updates=22490, lr=4.32498e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67059
2023-02-21 08:03:37 - progress_bar.py[line:274] - INFO: epoch 001:  22528 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.1, bsz=40, num_updates=22500, lr=4.32462e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67070
2023-02-21 08:03:48 - progress_bar.py[line:274] - INFO: epoch 001:  22538 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.9, wpb=110.2, bsz=40, num_updates=22510, lr=4.32426e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67081
2023-02-21 08:03:59 - progress_bar.py[line:274] - INFO: epoch 001:  22548 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.2, ups=0.94, wpb=111.6, bsz=40, num_updates=22520, lr=4.3239e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67092
2023-02-21 08:04:10 - progress_bar.py[line:274] - INFO: epoch 001:  22558 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=22530, lr=4.32354e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67103
2023-02-21 08:04:21 - progress_bar.py[line:274] - INFO: epoch 001:  22568 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.88, wpb=109.3, bsz=40, num_updates=22540, lr=4.32317e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67114
2023-02-21 08:04:33 - progress_bar.py[line:274] - INFO: epoch 001:  22578 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=22550, lr=4.32281e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67125
2023-02-21 08:04:44 - progress_bar.py[line:274] - INFO: epoch 001:  22588 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=22560, lr=4.32245e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67137
2023-02-21 08:04:55 - progress_bar.py[line:274] - INFO: epoch 001:  22598 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=22570, lr=4.32209e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67148
2023-02-21 08:05:06 - progress_bar.py[line:274] - INFO: epoch 001:  22608 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.5, bsz=40, num_updates=22580, lr=4.32173e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67159
2023-02-21 08:05:18 - progress_bar.py[line:274] - INFO: epoch 001:  22618 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.7, bsz=40, num_updates=22590, lr=4.32136e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67171
2023-02-21 08:05:29 - progress_bar.py[line:274] - INFO: epoch 001:  22628 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.5, bsz=40, num_updates=22600, lr=4.321e-05, gnorm=0.047, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67181
2023-02-21 08:05:40 - progress_bar.py[line:274] - INFO: epoch 001:  22638 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.9, wpb=109.6, bsz=40, num_updates=22610, lr=4.32064e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67193
2023-02-21 08:05:51 - progress_bar.py[line:274] - INFO: epoch 001:  22648 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=111, bsz=40, num_updates=22620, lr=4.32028e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=67203
2023-02-21 08:06:02 - progress_bar.py[line:274] - INFO: epoch 001:  22658 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=112, bsz=40, num_updates=22630, lr=4.31992e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67215
2023-02-21 08:06:13 - progress_bar.py[line:274] - INFO: epoch 001:  22668 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=22640, lr=4.31956e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67226
2023-02-21 08:06:24 - progress_bar.py[line:274] - INFO: epoch 001:  22678 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.87, wpb=111.1, bsz=40, num_updates=22650, lr=4.31919e-05, gnorm=0.095, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67237
2023-02-21 08:06:36 - progress_bar.py[line:274] - INFO: epoch 001:  22688 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.1, bsz=40, num_updates=22660, lr=4.31883e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=67248
2023-02-21 08:06:47 - progress_bar.py[line:274] - INFO: epoch 001:  22698 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=110.2, bsz=40, num_updates=22670, lr=4.31847e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67259
2023-02-21 08:06:58 - progress_bar.py[line:274] - INFO: epoch 001:  22708 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.8, bsz=40, num_updates=22680, lr=4.31811e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67271
2023-02-21 08:07:09 - progress_bar.py[line:274] - INFO: epoch 001:  22718 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.1, bsz=40, num_updates=22690, lr=4.31775e-05, gnorm=0.076, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67282
2023-02-21 08:07:20 - progress_bar.py[line:274] - INFO: epoch 001:  22728 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=22700, lr=4.31738e-05, gnorm=0.085, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67293
2023-02-21 08:07:31 - progress_bar.py[line:274] - INFO: epoch 001:  22738 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.9, bsz=40, num_updates=22710, lr=4.31702e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67304
2023-02-21 08:07:43 - progress_bar.py[line:274] - INFO: epoch 001:  22748 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.3, bsz=40, num_updates=22720, lr=4.31666e-05, gnorm=0.097, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67316
2023-02-21 08:07:54 - progress_bar.py[line:274] - INFO: epoch 001:  22758 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.92, wpb=110.8, bsz=40, num_updates=22730, lr=4.3163e-05, gnorm=0.077, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=67326
2023-02-21 08:08:05 - progress_bar.py[line:274] - INFO: epoch 001:  22768 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.2, bsz=40, num_updates=22740, lr=4.31594e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=67338
2023-02-21 08:08:16 - progress_bar.py[line:274] - INFO: epoch 001:  22778 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.91, wpb=110.2, bsz=40, num_updates=22750, lr=4.31558e-05, gnorm=0.104, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67349
2023-02-21 08:08:27 - progress_bar.py[line:274] - INFO: epoch 001:  22788 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.5, bsz=40, num_updates=22760, lr=4.31521e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67360
2023-02-21 08:08:38 - progress_bar.py[line:274] - INFO: epoch 001:  22798 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.7, bsz=40, num_updates=22770, lr=4.31485e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67371
2023-02-21 08:08:49 - progress_bar.py[line:274] - INFO: epoch 001:  22808 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.93, wpb=110.8, bsz=40, num_updates=22780, lr=4.31449e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67382
2023-02-21 08:09:00 - progress_bar.py[line:274] - INFO: epoch 001:  22818 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=22790, lr=4.31413e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67393
2023-02-21 08:09:11 - progress_bar.py[line:274] - INFO: epoch 001:  22828 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=22800, lr=4.31377e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67404
2023-02-21 08:09:22 - progress_bar.py[line:274] - INFO: epoch 001:  22838 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=111.3, bsz=40, num_updates=22810, lr=4.3134e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67415
2023-02-21 08:09:33 - progress_bar.py[line:274] - INFO: epoch 001:  22848 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.93, wpb=112.2, bsz=40, num_updates=22820, lr=4.31304e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67426
2023-02-21 08:09:44 - progress_bar.py[line:274] - INFO: epoch 001:  22858 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.91, wpb=109.8, bsz=40, num_updates=22830, lr=4.31268e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67437
2023-02-21 08:09:55 - progress_bar.py[line:274] - INFO: epoch 001:  22868 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=22840, lr=4.31232e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67448
2023-02-21 08:10:06 - progress_bar.py[line:274] - INFO: epoch 001:  22878 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.6, bsz=40, num_updates=22850, lr=4.31196e-05, gnorm=0.085, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67459
2023-02-21 08:10:17 - progress_bar.py[line:274] - INFO: epoch 001:  22888 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=22860, lr=4.31159e-05, gnorm=0.072, clip=0, loss_scale=16384, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67470
2023-02-21 08:10:29 - progress_bar.py[line:274] - INFO: epoch 001:  22898 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.4, bsz=40, num_updates=22870, lr=4.31123e-05, gnorm=0.056, clip=0, loss_scale=16384, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67481
2023-02-21 08:10:38 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8192.0
2023-02-21 08:10:41 - progress_bar.py[line:274] - INFO: epoch 001:  22909 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90, ups=0.82, wpb=110.1, bsz=40, num_updates=22880, lr=4.31087e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=67494
2023-02-21 08:10:52 - progress_bar.py[line:274] - INFO: epoch 001:  22919 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.8, bsz=40, num_updates=22890, lr=4.31051e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67505
2023-02-21 08:11:04 - progress_bar.py[line:274] - INFO: epoch 001:  22929 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.2, bsz=40, num_updates=22900, lr=4.31015e-05, gnorm=0.085, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67516
2023-02-21 08:11:15 - progress_bar.py[line:274] - INFO: epoch 001:  22939 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=22910, lr=4.30979e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67528
2023-02-21 08:11:26 - progress_bar.py[line:274] - INFO: epoch 001:  22949 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.9, wpb=111.9, bsz=40, num_updates=22920, lr=4.30942e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67539
2023-02-21 08:11:37 - progress_bar.py[line:274] - INFO: epoch 001:  22959 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.3, bsz=40, num_updates=22930, lr=4.30906e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67550
2023-02-21 08:11:48 - progress_bar.py[line:274] - INFO: epoch 001:  22969 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=113.4, nsentences=40, sample_size=113.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.91, wpb=113.4, bsz=40, num_updates=22940, lr=4.3087e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67561
2023-02-21 08:12:00 - progress_bar.py[line:274] - INFO: epoch 001:  22979 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.8, ups=0.87, wpb=110.6, bsz=40, num_updates=22950, lr=4.30834e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67572
2023-02-21 08:12:11 - progress_bar.py[line:274] - INFO: epoch 001:  22989 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.8, bsz=40, num_updates=22960, lr=4.30798e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67583
2023-02-21 08:12:22 - progress_bar.py[line:274] - INFO: epoch 001:  22999 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=22970, lr=4.30761e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67595
2023-02-21 08:12:33 - progress_bar.py[line:274] - INFO: epoch 001:  23009 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.3, ups=0.87, wpb=109.4, bsz=40, num_updates=22980, lr=4.30725e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67606
2023-02-21 08:12:44 - progress_bar.py[line:274] - INFO: epoch 001:  23019 / 142023 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=22990, lr=4.30689e-05, gnorm=0.099, clip=0, loss_scale=8192, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=67617
2023-02-21 08:12:55 - progress_bar.py[line:274] - INFO: epoch 001:  23029 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.9, wpb=112.7, bsz=40, num_updates=23000, lr=4.30653e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67628
2023-02-21 08:13:06 - progress_bar.py[line:274] - INFO: epoch 001:  23039 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=111, bsz=40, num_updates=23010, lr=4.30617e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67639
2023-02-21 08:13:17 - progress_bar.py[line:274] - INFO: epoch 001:  23049 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=23020, lr=4.30581e-05, gnorm=0.088, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67650
2023-02-21 08:13:29 - progress_bar.py[line:274] - INFO: epoch 001:  23059 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.9, bsz=40, num_updates=23030, lr=4.30544e-05, gnorm=0.109, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67662
2023-02-21 08:13:40 - progress_bar.py[line:274] - INFO: epoch 001:  23069 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=23040, lr=4.30508e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67673
2023-02-21 08:13:51 - progress_bar.py[line:274] - INFO: epoch 001:  23079 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.4, bsz=40, num_updates=23050, lr=4.30472e-05, gnorm=0.091, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67684
2023-02-21 08:14:03 - progress_bar.py[line:274] - INFO: epoch 001:  23089 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.2, bsz=40, num_updates=23060, lr=4.30436e-05, gnorm=0.043, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67695
2023-02-21 08:14:14 - progress_bar.py[line:274] - INFO: epoch 001:  23099 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.5, bsz=40, num_updates=23070, lr=4.304e-05, gnorm=0.047, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67706
2023-02-21 08:14:25 - progress_bar.py[line:274] - INFO: epoch 001:  23109 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112.8, bsz=40, num_updates=23080, lr=4.30363e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67718
2023-02-21 08:14:36 - progress_bar.py[line:274] - INFO: epoch 001:  23119 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=23090, lr=4.30327e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67729
2023-02-21 08:14:47 - progress_bar.py[line:274] - INFO: epoch 001:  23129 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.8, bsz=40, num_updates=23100, lr=4.30291e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67740
2023-02-21 08:14:58 - progress_bar.py[line:274] - INFO: epoch 001:  23139 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.8, bsz=40, num_updates=23110, lr=4.30255e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=67751
2023-02-21 08:15:10 - progress_bar.py[line:274] - INFO: epoch 001:  23149 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=111.1, bsz=40, num_updates=23120, lr=4.30219e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67763
2023-02-21 08:15:21 - progress_bar.py[line:274] - INFO: epoch 001:  23159 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.5, bsz=40, num_updates=23130, lr=4.30183e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67774
2023-02-21 08:15:33 - progress_bar.py[line:274] - INFO: epoch 001:  23169 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=23140, lr=4.30146e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67785
2023-02-21 08:15:44 - progress_bar.py[line:274] - INFO: epoch 001:  23179 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=23150, lr=4.3011e-05, gnorm=0.077, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67797
2023-02-21 08:15:48 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 08:15:56 - progress_bar.py[line:274] - INFO: epoch 001:  23190 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.2, ups=0.82, wpb=110.2, bsz=40, num_updates=23160, lr=4.30074e-05, gnorm=0.117, clip=0, loss_scale=4096, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=67809
2023-02-21 08:16:07 - progress_bar.py[line:274] - INFO: epoch 001:  23200 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112.1, bsz=40, num_updates=23170, lr=4.30038e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67820
2023-02-21 08:16:19 - progress_bar.py[line:274] - INFO: epoch 001:  23210 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.6, bsz=40, num_updates=23180, lr=4.30002e-05, gnorm=0.049, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67831
2023-02-21 08:16:29 - progress_bar.py[line:274] - INFO: epoch 001:  23220 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.7, bsz=40, num_updates=23190, lr=4.29965e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67842
2023-02-21 08:16:40 - progress_bar.py[line:274] - INFO: epoch 001:  23230 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.92, wpb=113.1, bsz=40, num_updates=23200, lr=4.29929e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67853
2023-02-21 08:16:51 - progress_bar.py[line:274] - INFO: epoch 001:  23240 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.7, bsz=40, num_updates=23210, lr=4.29893e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67864
2023-02-21 08:17:03 - progress_bar.py[line:274] - INFO: epoch 001:  23250 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.1, ups=0.88, wpb=109.9, bsz=40, num_updates=23220, lr=4.29857e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67876
2023-02-21 08:17:14 - progress_bar.py[line:274] - INFO: epoch 001:  23260 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.6, bsz=40, num_updates=23230, lr=4.29821e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67887
2023-02-21 08:17:25 - progress_bar.py[line:274] - INFO: epoch 001:  23270 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.8, bsz=40, num_updates=23240, lr=4.29785e-05, gnorm=0.043, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67898
2023-02-21 08:17:37 - progress_bar.py[line:274] - INFO: epoch 001:  23280 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.4, bsz=40, num_updates=23250, lr=4.29748e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67909
2023-02-21 08:17:48 - progress_bar.py[line:274] - INFO: epoch 001:  23290 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=112, bsz=40, num_updates=23260, lr=4.29712e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=67920
2023-02-21 08:17:59 - progress_bar.py[line:274] - INFO: epoch 001:  23300 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.9, wpb=109.1, bsz=40, num_updates=23270, lr=4.29676e-05, gnorm=0.048, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67932
2023-02-21 08:18:10 - progress_bar.py[line:274] - INFO: epoch 001:  23310 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=23280, lr=4.2964e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67943
2023-02-21 08:18:21 - progress_bar.py[line:274] - INFO: epoch 001:  23320 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.3, bsz=40, num_updates=23290, lr=4.29604e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67954
2023-02-21 08:18:32 - progress_bar.py[line:274] - INFO: epoch 001:  23330 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.1, ups=0.94, wpb=111.5, bsz=40, num_updates=23300, lr=4.29567e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67965
2023-02-21 08:18:43 - progress_bar.py[line:274] - INFO: epoch 001:  23340 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=23310, lr=4.29531e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67976
2023-02-21 08:18:54 - progress_bar.py[line:274] - INFO: epoch 001:  23350 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.1, bsz=40, num_updates=23320, lr=4.29495e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67987
2023-02-21 08:19:05 - progress_bar.py[line:274] - INFO: epoch 001:  23360 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=111, bsz=40, num_updates=23330, lr=4.29459e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67998
2023-02-21 08:19:16 - progress_bar.py[line:274] - INFO: epoch 001:  23370 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=23340, lr=4.29423e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68009
2023-02-21 08:19:28 - progress_bar.py[line:274] - INFO: epoch 001:  23380 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=23350, lr=4.29387e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68020
2023-02-21 08:19:39 - progress_bar.py[line:274] - INFO: epoch 001:  23390 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.5, bsz=40, num_updates=23360, lr=4.2935e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=68032
2023-02-21 08:19:50 - progress_bar.py[line:274] - INFO: epoch 001:  23400 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=23370, lr=4.29314e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68043
2023-02-21 08:20:02 - progress_bar.py[line:274] - INFO: epoch 001:  23410 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=110.8, bsz=40, num_updates=23380, lr=4.29278e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=68055
2023-02-21 08:20:13 - progress_bar.py[line:274] - INFO: epoch 001:  23420 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112.3, bsz=40, num_updates=23390, lr=4.29242e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68066
2023-02-21 08:20:24 - progress_bar.py[line:274] - INFO: epoch 001:  23430 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.8, bsz=40, num_updates=23400, lr=4.29206e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=68077
2023-02-21 08:20:35 - progress_bar.py[line:274] - INFO: epoch 001:  23440 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.1, bsz=40, num_updates=23410, lr=4.29169e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=68088
2023-02-21 08:20:46 - progress_bar.py[line:274] - INFO: epoch 001:  23450 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=112.4, bsz=40, num_updates=23420, lr=4.29133e-05, gnorm=0.046, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68099
2023-02-21 08:20:58 - progress_bar.py[line:274] - INFO: epoch 001:  23460 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.8, ups=0.87, wpb=110, bsz=40, num_updates=23430, lr=4.29097e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68111
2023-02-21 08:21:09 - progress_bar.py[line:274] - INFO: epoch 001:  23470 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=110.4, bsz=40, num_updates=23440, lr=4.29061e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68122
2023-02-21 08:21:20 - progress_bar.py[line:274] - INFO: epoch 001:  23480 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110, bsz=40, num_updates=23450, lr=4.29025e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68133
2023-02-21 08:21:31 - progress_bar.py[line:274] - INFO: epoch 001:  23490 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=23460, lr=4.28989e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68144
2023-02-21 08:21:42 - progress_bar.py[line:274] - INFO: epoch 001:  23500 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.92, wpb=112.6, bsz=40, num_updates=23470, lr=4.28952e-05, gnorm=0.044, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68155
2023-02-21 08:21:53 - progress_bar.py[line:274] - INFO: epoch 001:  23510 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.9, wpb=112.5, bsz=40, num_updates=23480, lr=4.28916e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68166
2023-02-21 08:22:04 - progress_bar.py[line:274] - INFO: epoch 001:  23520 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.6, bsz=40, num_updates=23490, lr=4.2888e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68177
2023-02-21 08:22:16 - progress_bar.py[line:274] - INFO: epoch 001:  23530 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=23500, lr=4.28844e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68189
2023-02-21 08:22:27 - progress_bar.py[line:274] - INFO: epoch 001:  23540 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.7, bsz=40, num_updates=23510, lr=4.28808e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68200
2023-02-21 08:22:38 - progress_bar.py[line:274] - INFO: epoch 001:  23550 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.92, wpb=112.3, bsz=40, num_updates=23520, lr=4.28771e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68211
2023-02-21 08:22:49 - progress_bar.py[line:274] - INFO: epoch 001:  23560 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=110.8, bsz=40, num_updates=23530, lr=4.28735e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68222
2023-02-21 08:23:01 - progress_bar.py[line:274] - INFO: epoch 001:  23570 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110.1, bsz=40, num_updates=23540, lr=4.28699e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68233
2023-02-21 08:23:12 - progress_bar.py[line:274] - INFO: epoch 001:  23580 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=23550, lr=4.28663e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68245
2023-02-21 08:23:23 - progress_bar.py[line:274] - INFO: epoch 001:  23590 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.5, bsz=40, num_updates=23560, lr=4.28627e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=68256
2023-02-21 08:23:34 - progress_bar.py[line:274] - INFO: epoch 001:  23600 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=111.2, bsz=40, num_updates=23570, lr=4.28591e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=68267
2023-02-21 08:23:46 - progress_bar.py[line:274] - INFO: epoch 001:  23610 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=23580, lr=4.28554e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=68279
2023-02-21 08:23:57 - progress_bar.py[line:274] - INFO: epoch 001:  23620 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.3, bsz=40, num_updates=23590, lr=4.28518e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=68290
2023-02-21 08:24:08 - progress_bar.py[line:274] - INFO: epoch 001:  23630 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=110.9, bsz=40, num_updates=23600, lr=4.28482e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68300
2023-02-21 08:24:19 - progress_bar.py[line:274] - INFO: epoch 001:  23640 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=112, bsz=40, num_updates=23610, lr=4.28446e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68312
2023-02-21 08:24:30 - progress_bar.py[line:274] - INFO: epoch 001:  23650 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.91, wpb=109.6, bsz=40, num_updates=23620, lr=4.2841e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=68323
2023-02-21 08:24:42 - progress_bar.py[line:274] - INFO: epoch 001:  23660 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.87, wpb=110, bsz=40, num_updates=23630, lr=4.28373e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68335
2023-02-21 08:24:53 - progress_bar.py[line:274] - INFO: epoch 001:  23670 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=110.8, bsz=40, num_updates=23640, lr=4.28337e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=68346
2023-02-21 08:25:04 - progress_bar.py[line:274] - INFO: epoch 001:  23680 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.92, wpb=110.2, bsz=40, num_updates=23650, lr=4.28301e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68356
2023-02-21 08:25:15 - progress_bar.py[line:274] - INFO: epoch 001:  23690 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.91, wpb=109.8, bsz=40, num_updates=23660, lr=4.28265e-05, gnorm=0.048, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68368
2023-02-21 08:25:26 - progress_bar.py[line:274] - INFO: epoch 001:  23700 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=110.7, bsz=40, num_updates=23670, lr=4.28229e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=68379
2023-02-21 08:25:37 - progress_bar.py[line:274] - INFO: epoch 001:  23710 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.87, wpb=112.4, bsz=40, num_updates=23680, lr=4.28193e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68390
2023-02-21 08:25:48 - progress_bar.py[line:274] - INFO: epoch 001:  23720 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111.1, bsz=40, num_updates=23690, lr=4.28156e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68401
2023-02-21 08:25:59 - progress_bar.py[line:274] - INFO: epoch 001:  23730 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.7, bsz=40, num_updates=23700, lr=4.2812e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68412
2023-02-21 08:26:10 - progress_bar.py[line:274] - INFO: epoch 001:  23740 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.3, bsz=40, num_updates=23710, lr=4.28084e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68423
2023-02-21 08:26:21 - progress_bar.py[line:274] - INFO: epoch 001:  23750 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112, bsz=40, num_updates=23720, lr=4.28048e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68434
2023-02-21 08:26:33 - progress_bar.py[line:274] - INFO: epoch 001:  23760 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=111.1, bsz=40, num_updates=23730, lr=4.28012e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68446
2023-02-21 08:26:44 - progress_bar.py[line:274] - INFO: epoch 001:  23770 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.2, bsz=40, num_updates=23740, lr=4.27975e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=68457
2023-02-21 08:26:56 - progress_bar.py[line:274] - INFO: epoch 001:  23780 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=111.2, bsz=40, num_updates=23750, lr=4.27939e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68469
2023-02-21 08:27:07 - progress_bar.py[line:274] - INFO: epoch 001:  23790 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.6, bsz=40, num_updates=23760, lr=4.27903e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68480
2023-02-21 08:27:18 - progress_bar.py[line:274] - INFO: epoch 001:  23800 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=23770, lr=4.27867e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=68491
2023-02-21 08:27:29 - progress_bar.py[line:274] - INFO: epoch 001:  23810 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.1, bsz=40, num_updates=23780, lr=4.27831e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=68502
2023-02-21 08:27:40 - progress_bar.py[line:274] - INFO: epoch 001:  23820 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.6, ups=0.91, wpb=113.3, bsz=40, num_updates=23790, lr=4.27795e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=68513
2023-02-21 08:27:52 - progress_bar.py[line:274] - INFO: epoch 001:  23830 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.6, bsz=40, num_updates=23800, lr=4.27758e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68525
2023-02-21 08:28:03 - progress_bar.py[line:274] - INFO: epoch 001:  23840 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.1, bsz=40, num_updates=23810, lr=4.27722e-05, gnorm=0.076, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=68536
2023-02-21 08:28:14 - progress_bar.py[line:274] - INFO: epoch 001:  23850 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.5, bsz=40, num_updates=23820, lr=4.27686e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68547
2023-02-21 08:28:20 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 08:28:27 - progress_bar.py[line:274] - INFO: epoch 001:  23861 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91.5, ups=0.82, wpb=111.8, bsz=40, num_updates=23830, lr=4.2765e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=68559
2023-02-21 08:28:38 - progress_bar.py[line:274] - INFO: epoch 001:  23871 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=23840, lr=4.27614e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68571
2023-02-21 08:28:49 - progress_bar.py[line:274] - INFO: epoch 001:  23881 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=23850, lr=4.27577e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68582
2023-02-21 08:29:00 - progress_bar.py[line:274] - INFO: epoch 001:  23891 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.8, bsz=40, num_updates=23860, lr=4.27541e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68593
2023-02-21 08:29:11 - progress_bar.py[line:274] - INFO: epoch 001:  23901 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=23870, lr=4.27505e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68604
2023-02-21 08:29:23 - progress_bar.py[line:274] - INFO: epoch 001:  23911 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.5, ups=0.87, wpb=110.1, bsz=40, num_updates=23880, lr=4.27469e-05, gnorm=0.044, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68616
2023-02-21 08:29:34 - progress_bar.py[line:274] - INFO: epoch 001:  23921 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.89, wpb=109.6, bsz=40, num_updates=23890, lr=4.27433e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68627
2023-02-21 08:29:46 - progress_bar.py[line:274] - INFO: epoch 001:  23931 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.86, wpb=111.3, bsz=40, num_updates=23900, lr=4.27397e-05, gnorm=0.045, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=68639
2023-02-21 08:29:57 - progress_bar.py[line:274] - INFO: epoch 001:  23941 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.88, wpb=110.2, bsz=40, num_updates=23910, lr=4.2736e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=68650
2023-02-21 08:30:08 - progress_bar.py[line:274] - INFO: epoch 001:  23951 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.3, bsz=40, num_updates=23920, lr=4.27324e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68661
2023-02-21 08:30:20 - progress_bar.py[line:274] - INFO: epoch 001:  23961 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=23930, lr=4.27288e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68673
2023-02-21 08:30:31 - progress_bar.py[line:274] - INFO: epoch 001:  23971 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.5, bsz=40, num_updates=23940, lr=4.27252e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=68684
2023-02-21 08:30:42 - progress_bar.py[line:274] - INFO: epoch 001:  23981 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.4, bsz=40, num_updates=23950, lr=4.27216e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=68695
2023-02-21 08:30:54 - progress_bar.py[line:274] - INFO: epoch 001:  23991 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=111.1, bsz=40, num_updates=23960, lr=4.27179e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68707
2023-02-21 08:31:05 - progress_bar.py[line:274] - INFO: epoch 001:  24001 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.1, bsz=40, num_updates=23970, lr=4.27143e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68718
2023-02-21 08:31:16 - progress_bar.py[line:274] - INFO: epoch 001:  24011 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=110.8, bsz=40, num_updates=23980, lr=4.27107e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68729
2023-02-21 08:31:27 - progress_bar.py[line:274] - INFO: epoch 001:  24021 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.1, bsz=40, num_updates=23990, lr=4.27071e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68740
2023-02-21 08:31:38 - progress_bar.py[line:274] - INFO: epoch 001:  24031 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.2, bsz=40, num_updates=24000, lr=4.27035e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68751
2023-02-21 08:31:38 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 08:31:39 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 08:31:39 - train.py[line:551] - INFO: load:0.98 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 08:33:44 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 08:33:44 - train.py[line:551] - INFO: load:1.01 valid_run:124.79 task_valid:121.18 collect_output:2.23
2023-02-21 08:35:47 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 08:35:47 - train.py[line:551] - INFO: load:1.04 valid_run:247.35 task_valid:238.92 collect_output:5.78
2023-02-21 08:37:51 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 08:37:51 - train.py[line:551] - INFO: load:1.07 valid_run:371.70 task_valid:357.25 collect_output:10.55
2023-02-21 08:39:56 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 08:39:56 - train.py[line:551] - INFO: load:1.09 valid_run:495.87 task_valid:472.85 collect_output:17.90
2023-02-21 08:41:58 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 08:41:58 - train.py[line:551] - INFO: load:1.12 valid_run:618.45 task_valid:591.83 collect_output:20.28
2023-02-21 08:44:04 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 08:44:04 - train.py[line:551] - INFO: load:1.15 valid_run:743.80 task_valid:712.26 collect_output:23.89
2023-02-21 08:46:09 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 08:46:09 - train.py[line:551] - INFO: load:1.18 valid_run:869.46 task_valid:832.40 collect_output:28.19
2023-02-21 08:48:13 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 08:48:13 - train.py[line:551] - INFO: load:1.21 valid_run:993.54 task_valid:950.75 collect_output:32.62
2023-02-21 08:50:20 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 08:50:20 - train.py[line:551] - INFO: load:1.23 valid_run:1119.78 task_valid:1070.12 collect_output:38.19
2023-02-21 08:52:24 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 08:52:24 - train.py[line:551] - INFO: load:1.26 valid_run:1244.01 task_valid:1184.95 collect_output:46.36
2023-02-21 08:54:27 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 08:54:27 - train.py[line:551] - INFO: load:1.29 valid_run:1366.88 task_valid:1302.55 collect_output:50.35
2023-02-21 08:56:31 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 08:56:31 - train.py[line:551] - INFO: load:1.32 valid_run:1490.82 task_valid:1421.13 collect_output:54.39
2023-02-21 08:58:32 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 08:58:32 - train.py[line:551] - INFO: load:1.35 valid_run:1612.23 task_valid:1537.04 collect_output:58.56
2023-02-21 09:00:36 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 09:00:36 - train.py[line:551] - INFO: load:1.38 valid_run:1735.88 task_valid:1656.95 collect_output:61.02
2023-02-21 09:02:40 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 09:02:40 - train.py[line:551] - INFO: load:1.41 valid_run:1859.39 task_valid:1775.06 collect_output:65.09
2023-02-21 09:04:43 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 09:04:43 - train.py[line:551] - INFO: load:1.44 valid_run:1982.89 task_valid:1890.95 collect_output:71.41
2023-02-21 09:06:47 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 09:06:47 - train.py[line:551] - INFO: load:1.47 valid_run:2106.70 task_valid:2008.99 collect_output:75.90
2023-02-21 09:08:50 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 09:08:50 - train.py[line:551] - INFO: load:1.50 valid_run:2229.70 task_valid:2128.80 collect_output:77.83
2023-02-21 09:10:54 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 09:10:54 - train.py[line:551] - INFO: load:1.53 valid_run:2353.71 task_valid:2248.11 collect_output:81.28
2023-02-21 09:12:57 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 09:12:57 - train.py[line:551] - INFO: load:1.56 valid_run:2476.63 task_valid:2366.32 collect_output:84.78
2023-02-21 09:15:02 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 09:15:02 - train.py[line:551] - INFO: load:1.59 valid_run:2601.03 task_valid:2485.14 collect_output:89.01
2023-02-21 09:17:06 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 09:17:06 - train.py[line:551] - INFO: load:1.61 valid_run:2725.43 task_valid:2605.95 collect_output:91.33
2023-02-21 09:19:09 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 09:19:09 - train.py[line:551] - INFO: load:1.64 valid_run:2847.96 task_valid:2722.23 collect_output:96.32
2023-02-21 09:21:11 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 09:21:11 - train.py[line:551] - INFO: load:1.67 valid_run:2970.53 task_valid:2840.37 collect_output:99.45
2023-02-21 09:23:15 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 09:23:15 - train.py[line:551] - INFO: load:1.70 valid_run:3094.35 task_valid:2958.72 collect_output:103.65
2023-02-21 09:25:21 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 09:25:21 - train.py[line:551] - INFO: load:1.74 valid_run:3219.48 task_valid:3076.55 collect_output:109.70
2023-02-21 09:27:23 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 09:27:23 - train.py[line:551] - INFO: load:1.77 valid_run:3341.69 task_valid:3193.07 collect_output:114.05
2023-02-21 09:29:28 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 09:29:28 - train.py[line:551] - INFO: load:1.81 valid_run:3466.41 task_valid:3314.94 collect_output:115.54
2023-02-21 09:31:32 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 09:31:32 - train.py[line:551] - INFO: load:1.84 valid_run:3590.39 task_valid:3432.61 collect_output:120.54
2023-02-21 09:33:36 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 09:33:36 - train.py[line:551] - INFO: load:1.87 valid_run:3714.52 task_valid:3553.26 collect_output:122.79
2023-02-21 09:35:39 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 09:35:39 - train.py[line:551] - INFO: load:1.90 valid_run:3837.09 task_valid:3672.79 collect_output:124.70

====================================================================================================
SGG eval:     R @ 50: 0.6060;     R @ 100: 0.6326;     R @ 500: 0.6571;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3693;    mR @ 100: 0.4006;    mR @ 500: 0.4372;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3871) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.6946) (standing on:0.3927) (using:0.5500) (walking in:0.0000) (walking on:0.7297) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================

2023-02-21 09:36:10 - train.py[line:487] - INFO: 0.632629131652661

====================================================================================================
SGG eval:     R @ 50: 0.6060;     R @ 100: 0.6326;     R @ 500: 0.6571;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3693;    mR @ 100: 0.4006;    mR @ 500: 0.4372;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3871) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.6946) (standing on:0.3927) (using:0.5500) (walking in:0.0000) (walking on:0.7297) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================

2023-02-21 09:36:11 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 09:36:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.217 | loss_v1 0 | loss_v2 0 | nll_loss 0.047 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.632629 | ppl 1.03 | vqa_score 0.3018 | wps 115.9 | wpb 72 | bsz 24 | num_updates 24000 | best_R@100 0.693596
2023-02-21 09:36:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 24000 updates
2023-02-21 09:36:11 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_24000.pt
2023-02-21 09:36:17 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_24000.pt
2023-02-21 09:36:20 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_24000.pt (epoch 1 @ 24000 updates, score 0.632629131652661) (writing took 9.097758442163467 seconds)
2023-02-21 09:36:32 - progress_bar.py[line:274] - INFO: epoch 001:  24041 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=110.3, bsz=40, num_updates=24010, lr=4.26999e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=72644
2023-02-21 09:36:44 - progress_bar.py[line:274] - INFO: epoch 001:  24051 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=112.1, bsz=40, num_updates=24020, lr=4.26962e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72656
2023-02-21 09:36:56 - progress_bar.py[line:274] - INFO: epoch 001:  24061 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=111, bsz=40, num_updates=24030, lr=4.26926e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72668
2023-02-21 09:37:07 - progress_bar.py[line:274] - INFO: epoch 001:  24071 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=24040, lr=4.2689e-05, gnorm=0.043, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72680
2023-02-21 09:37:18 - progress_bar.py[line:274] - INFO: epoch 001:  24081 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.4, bsz=40, num_updates=24050, lr=4.26854e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=72691
2023-02-21 09:37:29 - progress_bar.py[line:274] - INFO: epoch 001:  24091 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.1, bsz=40, num_updates=24060, lr=4.26818e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72702
2023-02-21 09:37:41 - progress_bar.py[line:274] - INFO: epoch 001:  24101 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.9, bsz=40, num_updates=24070, lr=4.26781e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72714
2023-02-21 09:37:52 - progress_bar.py[line:274] - INFO: epoch 001:  24111 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.87, wpb=112.7, bsz=40, num_updates=24080, lr=4.26745e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72725
2023-02-21 09:38:03 - progress_bar.py[line:274] - INFO: epoch 001:  24121 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.93, wpb=111.7, bsz=40, num_updates=24090, lr=4.26709e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72736
2023-02-21 09:38:14 - progress_bar.py[line:274] - INFO: epoch 001:  24131 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=24100, lr=4.26673e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72747
2023-02-21 09:38:26 - progress_bar.py[line:274] - INFO: epoch 001:  24141 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=110.8, bsz=40, num_updates=24110, lr=4.26637e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=72759
2023-02-21 09:38:37 - progress_bar.py[line:274] - INFO: epoch 001:  24151 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=111.9, bsz=40, num_updates=24120, lr=4.26601e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72770
2023-02-21 09:38:48 - progress_bar.py[line:274] - INFO: epoch 001:  24161 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.89, wpb=110.2, bsz=40, num_updates=24130, lr=4.26564e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72781
2023-02-21 09:39:00 - progress_bar.py[line:274] - INFO: epoch 001:  24171 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.88, wpb=110.2, bsz=40, num_updates=24140, lr=4.26528e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72793
2023-02-21 09:39:11 - progress_bar.py[line:274] - INFO: epoch 001:  24181 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112.3, bsz=40, num_updates=24150, lr=4.26492e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72804
2023-02-21 09:39:22 - progress_bar.py[line:274] - INFO: epoch 001:  24191 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=111.3, bsz=40, num_updates=24160, lr=4.26456e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72815
2023-02-21 09:39:34 - progress_bar.py[line:274] - INFO: epoch 001:  24201 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.3, bsz=40, num_updates=24170, lr=4.2642e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72827
2023-02-21 09:39:45 - progress_bar.py[line:274] - INFO: epoch 001:  24211 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.8, bsz=40, num_updates=24180, lr=4.26383e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72838
2023-02-21 09:39:56 - progress_bar.py[line:274] - INFO: epoch 001:  24221 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=109.7, bsz=40, num_updates=24190, lr=4.26347e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72849
2023-02-21 09:40:08 - progress_bar.py[line:274] - INFO: epoch 001:  24231 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=110.4, bsz=40, num_updates=24200, lr=4.26311e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=72861
2023-02-21 09:40:19 - progress_bar.py[line:274] - INFO: epoch 001:  24241 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.6, bsz=40, num_updates=24210, lr=4.26275e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72872
2023-02-21 09:40:31 - progress_bar.py[line:274] - INFO: epoch 001:  24251 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.7, ups=0.87, wpb=108.7, bsz=40, num_updates=24220, lr=4.26239e-05, gnorm=0.049, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72883
2023-02-21 09:40:42 - progress_bar.py[line:274] - INFO: epoch 001:  24261 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.9, wpb=110.5, bsz=40, num_updates=24230, lr=4.26203e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72895
2023-02-21 09:40:53 - progress_bar.py[line:274] - INFO: epoch 001:  24271 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=111.3, bsz=40, num_updates=24240, lr=4.26166e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=72906
2023-02-21 09:41:04 - progress_bar.py[line:274] - INFO: epoch 001:  24281 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112.2, bsz=40, num_updates=24250, lr=4.2613e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=72917
2023-02-21 09:41:16 - progress_bar.py[line:274] - INFO: epoch 001:  24291 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=111.4, bsz=40, num_updates=24260, lr=4.26094e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=72929
2023-02-21 09:41:27 - progress_bar.py[line:274] - INFO: epoch 001:  24301 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=110.6, bsz=40, num_updates=24270, lr=4.26058e-05, gnorm=0.047, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72940
2023-02-21 09:41:38 - progress_bar.py[line:274] - INFO: epoch 001:  24311 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.3, bsz=40, num_updates=24280, lr=4.26022e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72951
2023-02-21 09:41:50 - progress_bar.py[line:274] - INFO: epoch 001:  24321 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.6, bsz=40, num_updates=24290, lr=4.25985e-05, gnorm=0.046, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=72963
2023-02-21 09:42:01 - progress_bar.py[line:274] - INFO: epoch 001:  24331 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.91, wpb=112, bsz=40, num_updates=24300, lr=4.25949e-05, gnorm=0.042, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=72973
2023-02-21 09:42:12 - progress_bar.py[line:274] - INFO: epoch 001:  24341 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=111.1, bsz=40, num_updates=24310, lr=4.25913e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=72985
2023-02-21 09:42:23 - progress_bar.py[line:274] - INFO: epoch 001:  24351 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.7, bsz=40, num_updates=24320, lr=4.25877e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=72996
2023-02-21 09:42:35 - progress_bar.py[line:274] - INFO: epoch 001:  24361 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=24330, lr=4.25841e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73007
2023-02-21 09:42:46 - progress_bar.py[line:274] - INFO: epoch 001:  24371 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.8, bsz=40, num_updates=24340, lr=4.25805e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73019
2023-02-21 09:42:57 - progress_bar.py[line:274] - INFO: epoch 001:  24381 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.8, bsz=40, num_updates=24350, lr=4.25768e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73030
2023-02-21 09:43:08 - progress_bar.py[line:274] - INFO: epoch 001:  24391 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.9, bsz=40, num_updates=24360, lr=4.25732e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73041
2023-02-21 09:43:19 - progress_bar.py[line:274] - INFO: epoch 001:  24401 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112.6, bsz=40, num_updates=24370, lr=4.25696e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73052
2023-02-21 09:43:31 - progress_bar.py[line:274] - INFO: epoch 001:  24411 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.87, wpb=111.3, bsz=40, num_updates=24380, lr=4.2566e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73064
2023-02-21 09:43:42 - progress_bar.py[line:274] - INFO: epoch 001:  24421 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.9, wpb=109.4, bsz=40, num_updates=24390, lr=4.25624e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73075
2023-02-21 09:43:53 - progress_bar.py[line:274] - INFO: epoch 001:  24431 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.88, wpb=109.1, bsz=40, num_updates=24400, lr=4.25587e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73086
2023-02-21 09:44:04 - progress_bar.py[line:274] - INFO: epoch 001:  24441 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=111.5, bsz=40, num_updates=24410, lr=4.25551e-05, gnorm=0.096, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73097
2023-02-21 09:44:16 - progress_bar.py[line:274] - INFO: epoch 001:  24451 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=112.3, bsz=40, num_updates=24420, lr=4.25515e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73108
2023-02-21 09:44:27 - progress_bar.py[line:274] - INFO: epoch 001:  24461 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.9, ups=0.85, wpb=111, bsz=40, num_updates=24430, lr=4.25479e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=73120
2023-02-21 09:44:39 - progress_bar.py[line:274] - INFO: epoch 001:  24471 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.86, wpb=111, bsz=40, num_updates=24440, lr=4.25443e-05, gnorm=0.044, clip=0, loss_scale=8192, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=73132
2023-02-21 09:44:50 - progress_bar.py[line:274] - INFO: epoch 001:  24481 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.6, bsz=40, num_updates=24450, lr=4.25407e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73143
2023-02-21 09:45:01 - progress_bar.py[line:274] - INFO: epoch 001:  24491 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=24460, lr=4.2537e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73154
2023-02-21 09:45:13 - progress_bar.py[line:274] - INFO: epoch 001:  24501 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111.1, bsz=40, num_updates=24470, lr=4.25334e-05, gnorm=0.046, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73166
2023-02-21 09:45:24 - progress_bar.py[line:274] - INFO: epoch 001:  24511 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112.2, bsz=40, num_updates=24480, lr=4.25298e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73177
2023-02-21 09:45:35 - progress_bar.py[line:274] - INFO: epoch 001:  24521 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=112.1, bsz=40, num_updates=24490, lr=4.25262e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73188
2023-02-21 09:45:47 - progress_bar.py[line:274] - INFO: epoch 001:  24531 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.88, wpb=110.1, bsz=40, num_updates=24500, lr=4.25226e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73200
2023-02-21 09:45:58 - progress_bar.py[line:274] - INFO: epoch 001:  24541 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.88, wpb=109.6, bsz=40, num_updates=24510, lr=4.25189e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73211
2023-02-21 09:46:10 - progress_bar.py[line:274] - INFO: epoch 001:  24551 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.4, bsz=40, num_updates=24520, lr=4.25153e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73222
2023-02-21 09:46:21 - progress_bar.py[line:274] - INFO: epoch 001:  24561 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=112.6, bsz=40, num_updates=24530, lr=4.25117e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73234
2023-02-21 09:46:32 - progress_bar.py[line:274] - INFO: epoch 001:  24571 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.9, wpb=109.6, bsz=40, num_updates=24540, lr=4.25081e-05, gnorm=0.049, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73245
2023-02-21 09:46:44 - progress_bar.py[line:274] - INFO: epoch 001:  24581 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.89, wpb=110.1, bsz=40, num_updates=24550, lr=4.25045e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73256
2023-02-21 09:46:55 - progress_bar.py[line:274] - INFO: epoch 001:  24591 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.87, wpb=112.4, bsz=40, num_updates=24560, lr=4.25009e-05, gnorm=0.077, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73268
2023-02-21 09:47:07 - progress_bar.py[line:274] - INFO: epoch 001:  24601 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.86, wpb=111.9, bsz=40, num_updates=24570, lr=4.24972e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=73279
2023-02-21 09:47:18 - progress_bar.py[line:274] - INFO: epoch 001:  24611 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=111, bsz=40, num_updates=24580, lr=4.24936e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73291
2023-02-21 09:47:30 - progress_bar.py[line:274] - INFO: epoch 001:  24621 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.2, ups=0.86, wpb=111.2, bsz=40, num_updates=24590, lr=4.249e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=73303
2023-02-21 09:47:41 - progress_bar.py[line:274] - INFO: epoch 001:  24631 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.7, bsz=40, num_updates=24600, lr=4.24864e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73314
2023-02-21 09:47:52 - progress_bar.py[line:274] - INFO: epoch 001:  24641 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=110.6, bsz=40, num_updates=24610, lr=4.24828e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73325
2023-02-21 09:48:03 - progress_bar.py[line:274] - INFO: epoch 001:  24651 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.9, bsz=40, num_updates=24620, lr=4.24791e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73336
2023-02-21 09:48:15 - progress_bar.py[line:274] - INFO: epoch 001:  24661 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.87, wpb=111.6, bsz=40, num_updates=24630, lr=4.24755e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73348
2023-02-21 09:48:26 - progress_bar.py[line:274] - INFO: epoch 001:  24671 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.3, bsz=40, num_updates=24640, lr=4.24719e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73359
2023-02-21 09:48:38 - progress_bar.py[line:274] - INFO: epoch 001:  24681 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=110.9, bsz=40, num_updates=24650, lr=4.24683e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=73370
2023-02-21 09:48:49 - progress_bar.py[line:274] - INFO: epoch 001:  24691 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.6, bsz=40, num_updates=24660, lr=4.24647e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=73382
2023-02-21 09:49:00 - progress_bar.py[line:274] - INFO: epoch 001:  24701 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=24670, lr=4.2461e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73393
2023-02-21 09:49:11 - progress_bar.py[line:274] - INFO: epoch 001:  24711 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112.1, bsz=40, num_updates=24680, lr=4.24574e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73404
2023-02-21 09:49:23 - progress_bar.py[line:274] - INFO: epoch 001:  24721 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.88, wpb=109.2, bsz=40, num_updates=24690, lr=4.24538e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73416
2023-02-21 09:49:34 - progress_bar.py[line:274] - INFO: epoch 001:  24731 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.6, bsz=40, num_updates=24700, lr=4.24502e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73426
2023-02-21 09:49:45 - progress_bar.py[line:274] - INFO: epoch 001:  24741 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111, bsz=40, num_updates=24710, lr=4.24466e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73438
2023-02-21 09:49:56 - progress_bar.py[line:274] - INFO: epoch 001:  24751 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.87, wpb=110.7, bsz=40, num_updates=24720, lr=4.2443e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73449
2023-02-21 09:50:08 - progress_bar.py[line:274] - INFO: epoch 001:  24761 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.9, wpb=110.8, bsz=40, num_updates=24730, lr=4.24393e-05, gnorm=0.105, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73460
2023-02-21 09:50:19 - progress_bar.py[line:274] - INFO: epoch 001:  24771 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.87, wpb=110.6, bsz=40, num_updates=24740, lr=4.24357e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73472
2023-02-21 09:50:31 - progress_bar.py[line:274] - INFO: epoch 001:  24781 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.86, wpb=111.7, bsz=40, num_updates=24750, lr=4.24321e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=73484
2023-02-21 09:50:42 - progress_bar.py[line:274] - INFO: epoch 001:  24791 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=109.9, bsz=40, num_updates=24760, lr=4.24285e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73495
2023-02-21 09:50:53 - progress_bar.py[line:274] - INFO: epoch 001:  24801 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=110.3, bsz=40, num_updates=24770, lr=4.24249e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73506
2023-02-21 09:50:59 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 09:51:05 - progress_bar.py[line:274] - INFO: epoch 001:  24812 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91.8, ups=0.83, wpb=110.2, bsz=40, num_updates=24780, lr=4.24212e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=73518
2023-02-21 09:51:16 - progress_bar.py[line:274] - INFO: epoch 001:  24822 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=24790, lr=4.24176e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73529
2023-02-21 09:51:28 - progress_bar.py[line:274] - INFO: epoch 001:  24832 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.6, ups=0.88, wpb=110.3, bsz=40, num_updates=24800, lr=4.2414e-05, gnorm=0.116, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73541
2023-02-21 09:51:39 - progress_bar.py[line:274] - INFO: epoch 001:  24842 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.4, bsz=40, num_updates=24810, lr=4.24104e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73552
2023-02-21 09:51:50 - progress_bar.py[line:274] - INFO: epoch 001:  24852 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.5, bsz=40, num_updates=24820, lr=4.24068e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73563
2023-02-21 09:52:02 - progress_bar.py[line:274] - INFO: epoch 001:  24862 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.4, bsz=40, num_updates=24830, lr=4.24032e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73574
2023-02-21 09:52:12 - progress_bar.py[line:274] - INFO: epoch 001:  24872 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112.1, bsz=40, num_updates=24840, lr=4.23995e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73585
2023-02-21 09:52:24 - progress_bar.py[line:274] - INFO: epoch 001:  24882 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.9, bsz=40, num_updates=24850, lr=4.23959e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73597
2023-02-21 09:52:35 - progress_bar.py[line:274] - INFO: epoch 001:  24892 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.89, wpb=112.3, bsz=40, num_updates=24860, lr=4.23923e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73608
2023-02-21 09:52:46 - progress_bar.py[line:274] - INFO: epoch 001:  24902 / 142023 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.88, wpb=113, bsz=40, num_updates=24870, lr=4.23887e-05, gnorm=0.091, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73619
2023-02-21 09:52:58 - progress_bar.py[line:274] - INFO: epoch 001:  24912 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.5, bsz=40, num_updates=24880, lr=4.23851e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73630
2023-02-21 09:53:09 - progress_bar.py[line:274] - INFO: epoch 001:  24922 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=111.2, bsz=40, num_updates=24890, lr=4.23814e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73642
2023-02-21 09:53:20 - progress_bar.py[line:274] - INFO: epoch 001:  24932 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.8, bsz=40, num_updates=24900, lr=4.23778e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73653
2023-02-21 09:53:31 - progress_bar.py[line:274] - INFO: epoch 001:  24942 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111.1, bsz=40, num_updates=24910, lr=4.23742e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73664
2023-02-21 09:53:43 - progress_bar.py[line:274] - INFO: epoch 001:  24952 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=112, bsz=40, num_updates=24920, lr=4.23706e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73675
2023-02-21 09:53:54 - progress_bar.py[line:274] - INFO: epoch 001:  24962 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=24930, lr=4.2367e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73686
2023-02-21 09:54:05 - progress_bar.py[line:274] - INFO: epoch 001:  24972 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.6, bsz=40, num_updates=24940, lr=4.23634e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73697
2023-02-21 09:54:16 - progress_bar.py[line:274] - INFO: epoch 001:  24982 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=112.1, bsz=40, num_updates=24950, lr=4.23597e-05, gnorm=0.108, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73709
2023-02-21 09:54:27 - progress_bar.py[line:274] - INFO: epoch 001:  24992 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=112.2, bsz=40, num_updates=24960, lr=4.23561e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73720
2023-02-21 09:54:38 - progress_bar.py[line:274] - INFO: epoch 001:  25002 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=112, bsz=40, num_updates=24970, lr=4.23525e-05, gnorm=0.038, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73731
2023-02-21 09:54:50 - progress_bar.py[line:274] - INFO: epoch 001:  25012 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=24980, lr=4.23489e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73743
2023-02-21 09:55:01 - progress_bar.py[line:274] - INFO: epoch 001:  25022 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.3, bsz=40, num_updates=24990, lr=4.23453e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73754
2023-02-21 09:55:13 - progress_bar.py[line:274] - INFO: epoch 001:  25032 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.87, wpb=110.5, bsz=40, num_updates=25000, lr=4.23416e-05, gnorm=0.082, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73766
2023-02-21 09:55:24 - progress_bar.py[line:274] - INFO: epoch 001:  25042 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112, bsz=40, num_updates=25010, lr=4.2338e-05, gnorm=0.05, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73777
2023-02-21 09:55:35 - progress_bar.py[line:274] - INFO: epoch 001:  25052 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.6, bsz=40, num_updates=25020, lr=4.23344e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73788
2023-02-21 09:55:46 - progress_bar.py[line:274] - INFO: epoch 001:  25062 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111, bsz=40, num_updates=25030, lr=4.23308e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73799
2023-02-21 09:55:57 - progress_bar.py[line:274] - INFO: epoch 001:  25072 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=111.6, bsz=40, num_updates=25040, lr=4.23272e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73810
2023-02-21 09:56:08 - progress_bar.py[line:274] - INFO: epoch 001:  25082 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.7, bsz=40, num_updates=25050, lr=4.23236e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73821
2023-02-21 09:56:20 - progress_bar.py[line:274] - INFO: epoch 001:  25092 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=25060, lr=4.23199e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73832
2023-02-21 09:56:31 - progress_bar.py[line:274] - INFO: epoch 001:  25102 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.87, wpb=110.9, bsz=40, num_updates=25070, lr=4.23163e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=73844
2023-02-21 09:56:43 - progress_bar.py[line:274] - INFO: epoch 001:  25112 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=111.1, bsz=40, num_updates=25080, lr=4.23127e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73855
2023-02-21 09:56:54 - progress_bar.py[line:274] - INFO: epoch 001:  25122 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.4, bsz=40, num_updates=25090, lr=4.23091e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73867
2023-02-21 09:57:05 - progress_bar.py[line:274] - INFO: epoch 001:  25132 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=111.1, bsz=40, num_updates=25100, lr=4.23055e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73878
2023-02-21 09:57:17 - progress_bar.py[line:274] - INFO: epoch 001:  25142 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.4, ups=0.86, wpb=109.6, bsz=40, num_updates=25110, lr=4.23018e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=73890
2023-02-21 09:57:28 - progress_bar.py[line:274] - INFO: epoch 001:  25152 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.87, wpb=110.3, bsz=40, num_updates=25120, lr=4.22982e-05, gnorm=0.045, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73901
2023-02-21 09:57:39 - progress_bar.py[line:274] - INFO: epoch 001:  25162 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.5, bsz=40, num_updates=25130, lr=4.22946e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73912
2023-02-21 09:57:51 - progress_bar.py[line:274] - INFO: epoch 001:  25172 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.3, ups=0.86, wpb=111, bsz=40, num_updates=25140, lr=4.2291e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=73924
2023-02-21 09:58:02 - progress_bar.py[line:274] - INFO: epoch 001:  25182 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=111.3, bsz=40, num_updates=25150, lr=4.22874e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73935
2023-02-21 09:58:14 - progress_bar.py[line:274] - INFO: epoch 001:  25192 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.8, bsz=40, num_updates=25160, lr=4.22838e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73947
2023-02-21 09:58:25 - progress_bar.py[line:274] - INFO: epoch 001:  25202 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.7, bsz=40, num_updates=25170, lr=4.22801e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73958
2023-02-21 09:58:36 - progress_bar.py[line:274] - INFO: epoch 001:  25212 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112.1, bsz=40, num_updates=25180, lr=4.22765e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73969
2023-02-21 09:58:47 - progress_bar.py[line:274] - INFO: epoch 001:  25222 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=25190, lr=4.22729e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73980
2023-02-21 09:58:58 - progress_bar.py[line:274] - INFO: epoch 001:  25232 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.7, bsz=40, num_updates=25200, lr=4.22693e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73991
2023-02-21 09:59:09 - progress_bar.py[line:274] - INFO: epoch 001:  25242 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.5, bsz=40, num_updates=25210, lr=4.22657e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74002
2023-02-21 09:59:21 - progress_bar.py[line:274] - INFO: epoch 001:  25252 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.9, bsz=40, num_updates=25220, lr=4.2262e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74014
2023-02-21 09:59:32 - progress_bar.py[line:274] - INFO: epoch 001:  25262 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.87, wpb=112, bsz=40, num_updates=25230, lr=4.22584e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74025
2023-02-21 09:59:44 - progress_bar.py[line:274] - INFO: epoch 001:  25272 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=111, bsz=40, num_updates=25240, lr=4.22548e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74036
2023-02-21 09:59:55 - progress_bar.py[line:274] - INFO: epoch 001:  25282 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.86, wpb=111.4, bsz=40, num_updates=25250, lr=4.22512e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=74048
2023-02-21 10:00:07 - progress_bar.py[line:274] - INFO: epoch 001:  25292 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.86, wpb=111.8, bsz=40, num_updates=25260, lr=4.22476e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=74060
2023-02-21 10:00:18 - progress_bar.py[line:274] - INFO: epoch 001:  25302 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.9, wpb=109.8, bsz=40, num_updates=25270, lr=4.2244e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74071
2023-02-21 10:00:29 - progress_bar.py[line:274] - INFO: epoch 001:  25312 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.4, bsz=40, num_updates=25280, lr=4.22403e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74082
2023-02-21 10:00:41 - progress_bar.py[line:274] - INFO: epoch 001:  25322 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=25290, lr=4.22367e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74094
2023-02-21 10:00:53 - progress_bar.py[line:274] - INFO: epoch 001:  25332 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=112.3, bsz=40, num_updates=25300, lr=4.22331e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74106
2023-02-21 10:01:04 - progress_bar.py[line:274] - INFO: epoch 001:  25342 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.7, bsz=40, num_updates=25310, lr=4.22295e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74117
2023-02-21 10:01:15 - progress_bar.py[line:274] - INFO: epoch 001:  25352 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.91, wpb=108.7, bsz=40, num_updates=25320, lr=4.22259e-05, gnorm=0.087, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74128
2023-02-21 10:01:26 - progress_bar.py[line:274] - INFO: epoch 001:  25362 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.91, wpb=109.7, bsz=40, num_updates=25330, lr=4.22222e-05, gnorm=0.102, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74139
2023-02-21 10:01:37 - progress_bar.py[line:274] - INFO: epoch 001:  25372 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.5, bsz=40, num_updates=25340, lr=4.22186e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74150
2023-02-21 10:01:49 - progress_bar.py[line:274] - INFO: epoch 001:  25382 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.9, wpb=109.9, bsz=40, num_updates=25350, lr=4.2215e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74161
2023-02-21 10:02:00 - progress_bar.py[line:274] - INFO: epoch 001:  25392 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=111, bsz=40, num_updates=25360, lr=4.22114e-05, gnorm=0.042, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=74173
2023-02-21 10:02:12 - progress_bar.py[line:274] - INFO: epoch 001:  25402 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.86, wpb=112.4, bsz=40, num_updates=25370, lr=4.22078e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=74184
2023-02-21 10:02:23 - progress_bar.py[line:274] - INFO: epoch 001:  25412 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=25380, lr=4.22042e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74196
2023-02-21 10:02:34 - progress_bar.py[line:274] - INFO: epoch 001:  25422 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.3, bsz=40, num_updates=25390, lr=4.22005e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74207
2023-02-21 10:02:45 - progress_bar.py[line:274] - INFO: epoch 001:  25432 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.2, bsz=40, num_updates=25400, lr=4.21969e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74218
2023-02-21 10:02:57 - progress_bar.py[line:274] - INFO: epoch 001:  25442 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=111, bsz=40, num_updates=25410, lr=4.21933e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74229
2023-02-21 10:03:08 - progress_bar.py[line:274] - INFO: epoch 001:  25452 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.8, bsz=40, num_updates=25420, lr=4.21897e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74241
2023-02-21 10:03:19 - progress_bar.py[line:274] - INFO: epoch 001:  25462 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.3, bsz=40, num_updates=25430, lr=4.21861e-05, gnorm=0.099, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74252
2023-02-21 10:03:30 - progress_bar.py[line:274] - INFO: epoch 001:  25472 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.4, bsz=40, num_updates=25440, lr=4.21824e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74263
2023-02-21 10:03:41 - progress_bar.py[line:274] - INFO: epoch 001:  25482 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.9, wpb=111, bsz=40, num_updates=25450, lr=4.21788e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74274
2023-02-21 10:03:53 - progress_bar.py[line:274] - INFO: epoch 001:  25492 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=25460, lr=4.21752e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74286
2023-02-21 10:04:04 - progress_bar.py[line:274] - INFO: epoch 001:  25502 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=112.1, bsz=40, num_updates=25470, lr=4.21716e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74297
2023-02-21 10:04:15 - progress_bar.py[line:274] - INFO: epoch 001:  25512 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111, bsz=40, num_updates=25480, lr=4.2168e-05, gnorm=0.044, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74308
2023-02-21 10:04:27 - progress_bar.py[line:274] - INFO: epoch 001:  25522 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.89, wpb=109.9, bsz=40, num_updates=25490, lr=4.21644e-05, gnorm=0.045, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=74319
2023-02-21 10:04:38 - progress_bar.py[line:274] - INFO: epoch 001:  25532 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.6, bsz=40, num_updates=25500, lr=4.21607e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74331
2023-02-21 10:04:49 - progress_bar.py[line:274] - INFO: epoch 001:  25542 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111, bsz=40, num_updates=25510, lr=4.21571e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74342
2023-02-21 10:05:00 - progress_bar.py[line:274] - INFO: epoch 001:  25552 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=25520, lr=4.21535e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74353
2023-02-21 10:05:11 - progress_bar.py[line:274] - INFO: epoch 001:  25562 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.92, wpb=109.7, bsz=40, num_updates=25530, lr=4.21499e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=74364
2023-02-21 10:05:23 - progress_bar.py[line:274] - INFO: epoch 001:  25572 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.86, wpb=112, bsz=40, num_updates=25540, lr=4.21463e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=12, gb_free=11, ema_decay=0.9999, wall=74376
2023-02-21 10:05:34 - progress_bar.py[line:274] - INFO: epoch 001:  25582 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=112.2, bsz=40, num_updates=25550, lr=4.21426e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74387
2023-02-21 10:05:45 - progress_bar.py[line:274] - INFO: epoch 001:  25592 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.2, bsz=40, num_updates=25560, lr=4.2139e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74398
2023-02-21 10:05:56 - progress_bar.py[line:274] - INFO: epoch 001:  25602 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.4, bsz=40, num_updates=25570, lr=4.21354e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=74409
2023-02-21 10:06:08 - progress_bar.py[line:274] - INFO: epoch 001:  25612 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.87, wpb=112.7, bsz=40, num_updates=25580, lr=4.21318e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74420
2023-02-21 10:06:19 - progress_bar.py[line:274] - INFO: epoch 001:  25622 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.034, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=99, ups=0.9, wpb=110.3, bsz=40, num_updates=25590, lr=4.21282e-05, gnorm=0.038, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74432
2023-02-21 10:06:30 - progress_bar.py[line:274] - INFO: epoch 001:  25632 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=112.1, bsz=40, num_updates=25600, lr=4.21246e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74443
2023-02-21 10:06:41 - progress_bar.py[line:274] - INFO: epoch 001:  25642 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.7, ups=0.92, wpb=111.9, bsz=40, num_updates=25610, lr=4.21209e-05, gnorm=0.04, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74454
2023-02-21 10:06:52 - progress_bar.py[line:274] - INFO: epoch 001:  25652 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.9, bsz=40, num_updates=25620, lr=4.21173e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74465
2023-02-21 10:07:04 - progress_bar.py[line:274] - INFO: epoch 001:  25662 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=110.8, bsz=40, num_updates=25630, lr=4.21137e-05, gnorm=0.046, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74476
2023-02-21 10:07:15 - progress_bar.py[line:274] - INFO: epoch 001:  25672 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.1, bsz=40, num_updates=25640, lr=4.21101e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74488
2023-02-21 10:07:26 - progress_bar.py[line:274] - INFO: epoch 001:  25682 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=111.4, bsz=40, num_updates=25650, lr=4.21065e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74499
2023-02-21 10:07:38 - progress_bar.py[line:274] - INFO: epoch 001:  25692 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.88, wpb=112.8, bsz=40, num_updates=25660, lr=4.21028e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74511
2023-02-21 10:07:49 - progress_bar.py[line:274] - INFO: epoch 001:  25702 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.91, wpb=110.4, bsz=40, num_updates=25670, lr=4.20992e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74522
2023-02-21 10:08:00 - progress_bar.py[line:274] - INFO: epoch 001:  25712 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.92, wpb=110.3, bsz=40, num_updates=25680, lr=4.20956e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74533
2023-02-21 10:08:11 - progress_bar.py[line:274] - INFO: epoch 001:  25722 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.7, bsz=40, num_updates=25690, lr=4.2092e-05, gnorm=0.083, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74544
2023-02-21 10:08:22 - progress_bar.py[line:274] - INFO: epoch 001:  25732 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.7, bsz=40, num_updates=25700, lr=4.20884e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74555
2023-02-21 10:08:33 - progress_bar.py[line:274] - INFO: epoch 001:  25742 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=25710, lr=4.20848e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74566
2023-02-21 10:08:45 - progress_bar.py[line:274] - INFO: epoch 001:  25752 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.9, wpb=109.5, bsz=40, num_updates=25720, lr=4.20811e-05, gnorm=0.11, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74577
2023-02-21 10:08:56 - progress_bar.py[line:274] - INFO: epoch 001:  25762 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.86, wpb=111.7, bsz=40, num_updates=25730, lr=4.20775e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74589
2023-02-21 10:09:07 - progress_bar.py[line:274] - INFO: epoch 001:  25772 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112.4, bsz=40, num_updates=25740, lr=4.20739e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74600
2023-02-21 10:09:18 - progress_bar.py[line:274] - INFO: epoch 001:  25782 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.1, bsz=40, num_updates=25750, lr=4.20703e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74611
2023-02-21 10:09:29 - progress_bar.py[line:274] - INFO: epoch 001:  25792 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110.1, bsz=40, num_updates=25760, lr=4.20667e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=74622
2023-02-21 10:09:41 - progress_bar.py[line:274] - INFO: epoch 001:  25802 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.4, bsz=40, num_updates=25770, lr=4.2063e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74634
2023-02-21 10:09:52 - progress_bar.py[line:274] - INFO: epoch 001:  25812 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.87, wpb=110.1, bsz=40, num_updates=25780, lr=4.20594e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74645
2023-02-21 10:10:04 - progress_bar.py[line:274] - INFO: epoch 001:  25822 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.6, ups=0.86, wpb=110.4, bsz=40, num_updates=25790, lr=4.20558e-05, gnorm=0.094, clip=0, loss_scale=8192, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=74657
2023-02-21 10:10:15 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8192.0
2023-02-21 10:10:16 - progress_bar.py[line:274] - INFO: epoch 001:  25833 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=91.9, ups=0.82, wpb=111.7, bsz=40, num_updates=25800, lr=4.20522e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=74669
2023-02-21 10:10:28 - progress_bar.py[line:274] - INFO: epoch 001:  25843 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.8, ups=0.87, wpb=110.4, bsz=40, num_updates=25810, lr=4.20486e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74681
2023-02-21 10:10:39 - progress_bar.py[line:274] - INFO: epoch 001:  25853 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.87, wpb=112, bsz=40, num_updates=25820, lr=4.2045e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=74692
2023-02-21 10:10:51 - progress_bar.py[line:274] - INFO: epoch 001:  25863 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.1, ups=0.86, wpb=110.6, bsz=40, num_updates=25830, lr=4.20413e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=74704
2023-02-21 10:11:02 - progress_bar.py[line:274] - INFO: epoch 001:  25873 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.9, bsz=40, num_updates=25840, lr=4.20377e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74715
2023-02-21 10:11:13 - progress_bar.py[line:274] - INFO: epoch 001:  25883 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.92, wpb=112.1, bsz=40, num_updates=25850, lr=4.20341e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=74726
2023-02-21 10:11:24 - progress_bar.py[line:274] - INFO: epoch 001:  25893 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.1, bsz=40, num_updates=25860, lr=4.20305e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=74737
2023-02-21 10:11:35 - progress_bar.py[line:274] - INFO: epoch 001:  25903 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.2, bsz=40, num_updates=25870, lr=4.20269e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74748
2023-02-21 10:11:47 - progress_bar.py[line:274] - INFO: epoch 001:  25913 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=25880, lr=4.20232e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74760
2023-02-21 10:11:58 - progress_bar.py[line:274] - INFO: epoch 001:  25923 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.7, bsz=40, num_updates=25890, lr=4.20196e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74771
2023-02-21 10:12:10 - progress_bar.py[line:274] - INFO: epoch 001:  25933 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.5, ups=0.85, wpb=112, bsz=40, num_updates=25900, lr=4.2016e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=74783
2023-02-21 10:12:21 - progress_bar.py[line:274] - INFO: epoch 001:  25943 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.88, wpb=111.9, bsz=40, num_updates=25910, lr=4.20124e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74794
2023-02-21 10:12:33 - progress_bar.py[line:274] - INFO: epoch 001:  25953 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.86, wpb=111.9, bsz=40, num_updates=25920, lr=4.20088e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=74806
2023-02-21 10:12:44 - progress_bar.py[line:274] - INFO: epoch 001:  25963 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.5, bsz=40, num_updates=25930, lr=4.20052e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74817
2023-02-21 10:12:55 - progress_bar.py[line:274] - INFO: epoch 001:  25973 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.89, wpb=112.7, bsz=40, num_updates=25940, lr=4.20015e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74828
2023-02-21 10:13:06 - progress_bar.py[line:274] - INFO: epoch 001:  25983 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=111.2, bsz=40, num_updates=25950, lr=4.19979e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74839
2023-02-21 10:13:18 - progress_bar.py[line:274] - INFO: epoch 001:  25993 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.7, ups=0.85, wpb=110.1, bsz=40, num_updates=25960, lr=4.19943e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=74851
2023-02-21 10:13:29 - progress_bar.py[line:274] - INFO: epoch 001:  26003 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.9, wpb=109.6, bsz=40, num_updates=25970, lr=4.19907e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74862
2023-02-21 10:13:41 - progress_bar.py[line:274] - INFO: epoch 001:  26013 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.5, bsz=40, num_updates=25980, lr=4.19871e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74873
2023-02-21 10:13:52 - progress_bar.py[line:274] - INFO: epoch 001:  26023 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.86, wpb=112.1, bsz=40, num_updates=25990, lr=4.19834e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=74885
2023-02-21 10:13:57 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 10:14:04 - progress_bar.py[line:274] - INFO: epoch 001:  26034 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.1, ups=0.83, wpb=111.4, bsz=40, num_updates=26000, lr=4.19798e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=74897
2023-02-21 10:14:04 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 10:14:06 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 10:14:06 - train.py[line:551] - INFO: load:0.99 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 10:16:10 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 10:16:10 - train.py[line:551] - INFO: load:1.02 valid_run:124.28 task_valid:120.69 collect_output:2.29
2023-02-21 10:18:12 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 10:18:12 - train.py[line:551] - INFO: load:1.06 valid_run:246.44 task_valid:238.21 collect_output:5.67
2023-02-21 10:20:16 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 10:20:16 - train.py[line:551] - INFO: load:1.11 valid_run:370.62 task_valid:356.80 collect_output:9.97
2023-02-21 10:22:21 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 10:22:21 - train.py[line:551] - INFO: load:1.14 valid_run:495.15 task_valid:472.50 collect_output:17.49
2023-02-21 10:24:24 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 10:24:24 - train.py[line:551] - INFO: load:1.17 valid_run:617.83 task_valid:591.66 collect_output:19.72
2023-02-21 10:26:29 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 10:26:29 - train.py[line:551] - INFO: load:1.19 valid_run:743.38 task_valid:712.39 collect_output:23.30
2023-02-21 10:28:35 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 10:28:35 - train.py[line:551] - INFO: load:1.22 valid_run:868.76 task_valid:832.44 collect_output:27.41
2023-02-21 10:30:39 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 10:30:39 - train.py[line:551] - INFO: load:1.25 valid_run:992.85 task_valid:950.80 collect_output:31.90
2023-02-21 10:32:45 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 10:32:45 - train.py[line:551] - INFO: load:1.28 valid_run:1118.64 task_valid:1069.93 collect_output:37.36
2023-02-21 10:34:49 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 10:34:49 - train.py[line:551] - INFO: load:1.31 valid_run:1242.46 task_valid:1184.41 collect_output:45.52
2023-02-21 10:36:51 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 10:36:51 - train.py[line:551] - INFO: load:1.34 valid_run:1365.04 task_valid:1302.26 collect_output:48.91
2023-02-21 10:38:55 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 10:38:55 - train.py[line:551] - INFO: load:1.36 valid_run:1488.99 task_valid:1421.28 collect_output:52.56
2023-02-21 10:40:56 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 10:40:56 - train.py[line:551] - INFO: load:1.39 valid_run:1609.95 task_valid:1536.47 collect_output:57.12
2023-02-21 10:43:00 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 10:43:00 - train.py[line:551] - INFO: load:1.43 valid_run:1733.04 task_valid:1656.01 collect_output:59.47
2023-02-21 10:45:03 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 10:45:03 - train.py[line:551] - INFO: load:1.45 valid_run:1856.49 task_valid:1774.38 collect_output:63.31
2023-02-21 10:47:06 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 10:47:06 - train.py[line:551] - INFO: load:1.48 valid_run:1979.68 task_valid:1890.30 collect_output:69.30
2023-02-21 10:49:10 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 10:49:10 - train.py[line:551] - INFO: load:1.51 valid_run:2102.97 task_valid:2008.12 collect_output:73.56
2023-02-21 10:51:13 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 10:51:13 - train.py[line:551] - INFO: load:1.54 valid_run:2225.87 task_valid:2127.96 collect_output:75.37
2023-02-21 10:53:17 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 10:53:17 - train.py[line:551] - INFO: load:1.57 valid_run:2349.74 task_valid:2246.84 collect_output:79.08
2023-02-21 10:55:20 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 10:55:20 - train.py[line:551] - INFO: load:1.59 valid_run:2472.83 task_valid:2365.44 collect_output:82.32
2023-02-21 10:57:24 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 10:57:24 - train.py[line:551] - INFO: load:1.63 valid_run:2596.68 task_valid:2483.51 collect_output:86.89
2023-02-21 10:59:28 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 10:59:28 - train.py[line:551] - INFO: load:1.65 valid_run:2721.17 task_valid:2604.14 collect_output:89.41
2023-02-21 11:01:31 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 11:01:31 - train.py[line:551] - INFO: load:1.68 valid_run:2843.88 task_valid:2720.52 collect_output:94.50
2023-02-21 11:03:33 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 11:03:33 - train.py[line:551] - INFO: load:1.71 valid_run:2966.22 task_valid:2838.89 collect_output:97.24
2023-02-21 11:05:37 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 11:05:37 - train.py[line:551] - INFO: load:1.74 valid_run:3090.17 task_valid:2957.35 collect_output:101.43
2023-02-21 11:07:43 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 11:07:43 - train.py[line:551] - INFO: load:1.77 valid_run:3215.34 task_valid:3075.61 collect_output:107.08
2023-02-21 11:09:45 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 11:09:45 - train.py[line:551] - INFO: load:1.80 valid_run:3337.28 task_valid:3191.84 collect_output:111.46
2023-02-21 11:11:49 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 11:11:49 - train.py[line:551] - INFO: load:1.83 valid_run:3461.39 task_valid:3313.00 collect_output:113.23
2023-02-21 11:13:53 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 11:13:53 - train.py[line:551] - INFO: load:1.85 valid_run:3585.55 task_valid:3430.58 collect_output:118.53
2023-02-21 11:15:58 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 11:15:58 - train.py[line:551] - INFO: load:1.89 valid_run:3710.54 task_valid:3551.02 collect_output:121.84
2023-02-21 11:18:02 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 11:18:02 - train.py[line:551] - INFO: load:1.91 valid_run:3834.17 task_valid:3671.51 collect_output:123.75

====================================================================================================
SGG eval:     R @ 50: 0.6035;     R @ 100: 0.6338;     R @ 500: 0.6553;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3561;    mR @ 100: 0.3896;    mR @ 500: 0.4231;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4194) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9304) (says:0.0000) (sitting on:0.6939) (standing on:0.3893) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================

2023-02-21 11:18:33 - train.py[line:487] - INFO: 0.6337624649859945
2023-02-21 11:18:34 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.6035;     R @ 100: 0.6338;     R @ 500: 0.6553;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3561;    mR @ 100: 0.3896;    mR @ 500: 0.4231;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4194) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9304) (says:0.0000) (sitting on:0.6939) (standing on:0.3893) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================

2023-02-21 11:18:34 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.218 | loss_v1 0 | loss_v2 0 | nll_loss 0.05 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.633762 | ppl 1.04 | vqa_score 0.2995 | wps 116 | wpb 72 | bsz 24 | num_updates 26000 | best_R@100 0.693596
2023-02-21 11:18:34 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 26000 updates
2023-02-21 11:18:34 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_26000.pt
2023-02-21 11:18:40 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_26000.pt
2023-02-21 11:18:43 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_26000.pt (epoch 1 @ 26000 updates, score 0.6337624649859945) (writing took 9.225752720609307 seconds)
2023-02-21 11:18:54 - progress_bar.py[line:274] - INFO: epoch 001:  26044 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=110.8, bsz=40, num_updates=26010, lr=4.19762e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78787
2023-02-21 11:19:05 - progress_bar.py[line:274] - INFO: epoch 001:  26054 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.3, bsz=40, num_updates=26020, lr=4.19726e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=78798
2023-02-21 11:19:16 - progress_bar.py[line:274] - INFO: epoch 001:  26064 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=26030, lr=4.1969e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78809
2023-02-21 11:19:28 - progress_bar.py[line:274] - INFO: epoch 001:  26074 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.9, bsz=40, num_updates=26040, lr=4.19654e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78821
2023-02-21 11:19:39 - progress_bar.py[line:274] - INFO: epoch 001:  26084 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=111.2, bsz=40, num_updates=26050, lr=4.19617e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=78832
2023-02-21 11:19:50 - progress_bar.py[line:274] - INFO: epoch 001:  26094 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.5, bsz=40, num_updates=26060, lr=4.19581e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=78843
2023-02-21 11:20:01 - progress_bar.py[line:274] - INFO: epoch 001:  26104 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.8, bsz=40, num_updates=26070, lr=4.19545e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=78854
2023-02-21 11:20:13 - progress_bar.py[line:274] - INFO: epoch 001:  26114 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112.4, bsz=40, num_updates=26080, lr=4.19509e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78866
2023-02-21 11:20:24 - progress_bar.py[line:274] - INFO: epoch 001:  26124 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=26090, lr=4.19473e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78877
2023-02-21 11:20:35 - progress_bar.py[line:274] - INFO: epoch 001:  26134 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=112, bsz=40, num_updates=26100, lr=4.19436e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=78888
2023-02-21 11:20:47 - progress_bar.py[line:274] - INFO: epoch 001:  26144 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.8, bsz=40, num_updates=26110, lr=4.194e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78900
2023-02-21 11:20:58 - progress_bar.py[line:274] - INFO: epoch 001:  26154 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=26120, lr=4.19364e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78911
2023-02-21 11:21:09 - progress_bar.py[line:274] - INFO: epoch 001:  26164 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=26130, lr=4.19328e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=78922
2023-02-21 11:21:21 - progress_bar.py[line:274] - INFO: epoch 001:  26174 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.4, ups=0.86, wpb=109.4, bsz=40, num_updates=26140, lr=4.19292e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=78934
2023-02-21 11:21:32 - progress_bar.py[line:274] - INFO: epoch 001:  26184 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.87, wpb=110, bsz=40, num_updates=26150, lr=4.19256e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=78945
2023-02-21 11:21:43 - progress_bar.py[line:274] - INFO: epoch 001:  26194 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112, bsz=40, num_updates=26160, lr=4.19219e-05, gnorm=0.049, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78956
2023-02-21 11:21:55 - progress_bar.py[line:274] - INFO: epoch 001:  26204 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.89, wpb=112.2, bsz=40, num_updates=26170, lr=4.19183e-05, gnorm=0.045, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78967
2023-02-21 11:22:06 - progress_bar.py[line:274] - INFO: epoch 001:  26214 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.9, bsz=40, num_updates=26180, lr=4.19147e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78979
2023-02-21 11:22:17 - progress_bar.py[line:274] - INFO: epoch 001:  26224 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=111.1, bsz=40, num_updates=26190, lr=4.19111e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78990
2023-02-21 11:22:28 - progress_bar.py[line:274] - INFO: epoch 001:  26234 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.1, bsz=40, num_updates=26200, lr=4.19075e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79001
2023-02-21 11:22:40 - progress_bar.py[line:274] - INFO: epoch 001:  26244 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=110.7, bsz=40, num_updates=26210, lr=4.19038e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79012
2023-02-21 11:22:51 - progress_bar.py[line:274] - INFO: epoch 001:  26254 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.86, wpb=111.3, bsz=40, num_updates=26220, lr=4.19002e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=79024
2023-02-21 11:23:03 - progress_bar.py[line:274] - INFO: epoch 001:  26264 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.7, ups=0.86, wpb=110.4, bsz=40, num_updates=26230, lr=4.18966e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=79036
2023-02-21 11:23:14 - progress_bar.py[line:274] - INFO: epoch 001:  26274 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.89, wpb=109.9, bsz=40, num_updates=26240, lr=4.1893e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79047
2023-02-21 11:23:25 - progress_bar.py[line:274] - INFO: epoch 001:  26284 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=110.9, bsz=40, num_updates=26250, lr=4.18894e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79058
2023-02-21 11:23:37 - progress_bar.py[line:274] - INFO: epoch 001:  26294 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.4, bsz=40, num_updates=26260, lr=4.18858e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79070
2023-02-21 11:23:48 - progress_bar.py[line:274] - INFO: epoch 001:  26304 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.5, bsz=40, num_updates=26270, lr=4.18821e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79081
2023-02-21 11:24:00 - progress_bar.py[line:274] - INFO: epoch 001:  26314 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111, bsz=40, num_updates=26280, lr=4.18785e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79092
2023-02-21 11:24:11 - progress_bar.py[line:274] - INFO: epoch 001:  26324 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.1, bsz=40, num_updates=26290, lr=4.18749e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79104
2023-02-21 11:24:22 - progress_bar.py[line:274] - INFO: epoch 001:  26334 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.3, ups=0.87, wpb=109.7, bsz=40, num_updates=26300, lr=4.18713e-05, gnorm=0.095, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79115
2023-02-21 11:24:34 - progress_bar.py[line:274] - INFO: epoch 001:  26344 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=113.2, bsz=40, num_updates=26310, lr=4.18677e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79127
2023-02-21 11:24:45 - progress_bar.py[line:274] - INFO: epoch 001:  26354 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.88, wpb=112.6, bsz=40, num_updates=26320, lr=4.1864e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79138
2023-02-21 11:24:56 - progress_bar.py[line:274] - INFO: epoch 001:  26364 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.92, wpb=112.1, bsz=40, num_updates=26330, lr=4.18604e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79149
2023-02-21 11:25:07 - progress_bar.py[line:274] - INFO: epoch 001:  26374 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.3, bsz=40, num_updates=26340, lr=4.18568e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79160
2023-02-21 11:25:18 - progress_bar.py[line:274] - INFO: epoch 001:  26384 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.89, wpb=111.2, bsz=40, num_updates=26350, lr=4.18532e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79171
2023-02-21 11:25:29 - progress_bar.py[line:274] - INFO: epoch 001:  26394 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.5, bsz=40, num_updates=26360, lr=4.18496e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79182
2023-02-21 11:25:40 - progress_bar.py[line:274] - INFO: epoch 001:  26404 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=111.1, bsz=40, num_updates=26370, lr=4.1846e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79193
2023-02-21 11:25:52 - progress_bar.py[line:274] - INFO: epoch 001:  26414 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.7, ups=0.86, wpb=109.9, bsz=40, num_updates=26380, lr=4.18423e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=79205
2023-02-21 11:26:03 - progress_bar.py[line:274] - INFO: epoch 001:  26424 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.5, bsz=40, num_updates=26390, lr=4.18387e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=79216
2023-02-21 11:26:15 - progress_bar.py[line:274] - INFO: epoch 001:  26434 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.87, wpb=112, bsz=40, num_updates=26400, lr=4.18351e-05, gnorm=0.094, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79228
2023-02-21 11:26:26 - progress_bar.py[line:274] - INFO: epoch 001:  26444 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=110.8, bsz=40, num_updates=26410, lr=4.18315e-05, gnorm=0.081, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=79239
2023-02-21 11:26:37 - progress_bar.py[line:274] - INFO: epoch 001:  26454 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.5, bsz=40, num_updates=26420, lr=4.18279e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79250
2023-02-21 11:26:48 - progress_bar.py[line:274] - INFO: epoch 001:  26464 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=111.2, bsz=40, num_updates=26430, lr=4.18242e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=79261
2023-02-21 11:26:59 - progress_bar.py[line:274] - INFO: epoch 001:  26474 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=26440, lr=4.18206e-05, gnorm=0.046, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79272
2023-02-21 11:27:11 - progress_bar.py[line:274] - INFO: epoch 001:  26484 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.7, ups=0.88, wpb=109.1, bsz=40, num_updates=26450, lr=4.1817e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79284
2023-02-21 11:27:22 - progress_bar.py[line:274] - INFO: epoch 001:  26494 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.1, bsz=40, num_updates=26460, lr=4.18134e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79295
2023-02-21 11:27:34 - progress_bar.py[line:274] - INFO: epoch 001:  26504 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96, ups=0.87, wpb=110.7, bsz=40, num_updates=26470, lr=4.18098e-05, gnorm=0.084, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79306
2023-02-21 11:27:45 - progress_bar.py[line:274] - INFO: epoch 001:  26514 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.5, ups=0.86, wpb=111.4, bsz=40, num_updates=26480, lr=4.18061e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=79318
2023-02-21 11:27:57 - progress_bar.py[line:274] - INFO: epoch 001:  26524 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=26490, lr=4.18025e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79330
2023-02-21 11:28:08 - progress_bar.py[line:274] - INFO: epoch 001:  26534 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=111.2, bsz=40, num_updates=26500, lr=4.17989e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79341
2023-02-21 11:28:19 - progress_bar.py[line:274] - INFO: epoch 001:  26544 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=110.7, bsz=40, num_updates=26510, lr=4.17953e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79352
2023-02-21 11:28:31 - progress_bar.py[line:274] - INFO: epoch 001:  26554 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.9, bsz=40, num_updates=26520, lr=4.17917e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79364
2023-02-21 11:28:42 - progress_bar.py[line:274] - INFO: epoch 001:  26564 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=111.7, bsz=40, num_updates=26530, lr=4.17881e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79374
2023-02-21 11:28:53 - progress_bar.py[line:274] - INFO: epoch 001:  26574 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.87, wpb=111.4, bsz=40, num_updates=26540, lr=4.17844e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79386
2023-02-21 11:29:04 - progress_bar.py[line:274] - INFO: epoch 001:  26584 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.8, bsz=40, num_updates=26550, lr=4.17808e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79397
2023-02-21 11:29:16 - progress_bar.py[line:274] - INFO: epoch 001:  26594 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.2, ups=0.87, wpb=110, bsz=40, num_updates=26560, lr=4.17772e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79409
2023-02-21 11:29:27 - progress_bar.py[line:274] - INFO: epoch 001:  26604 / 142023 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.92, wpb=111.5, bsz=40, num_updates=26570, lr=4.17736e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79420
2023-02-21 11:29:38 - progress_bar.py[line:274] - INFO: epoch 001:  26614 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=26580, lr=4.177e-05, gnorm=0.086, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79431
2023-02-21 11:29:50 - progress_bar.py[line:274] - INFO: epoch 001:  26624 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=110.5, bsz=40, num_updates=26590, lr=4.17663e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79442
2023-02-21 11:30:01 - progress_bar.py[line:274] - INFO: epoch 001:  26634 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=26600, lr=4.17627e-05, gnorm=0.038, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79454
2023-02-21 11:30:12 - progress_bar.py[line:274] - INFO: epoch 001:  26644 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.5, bsz=40, num_updates=26610, lr=4.17591e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10, ema_decay=0.9999, wall=79465
2023-02-21 11:30:23 - progress_bar.py[line:274] - INFO: epoch 001:  26654 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.9, bsz=40, num_updates=26620, lr=4.17555e-05, gnorm=0.077, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79476
2023-02-21 11:30:34 - progress_bar.py[line:274] - INFO: epoch 001:  26664 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.2, bsz=40, num_updates=26630, lr=4.17519e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79487
2023-02-21 11:30:45 - progress_bar.py[line:274] - INFO: epoch 001:  26674 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.6, bsz=40, num_updates=26640, lr=4.17483e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79498
2023-02-21 11:30:57 - progress_bar.py[line:274] - INFO: epoch 001:  26684 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.2, bsz=40, num_updates=26650, lr=4.17446e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79510
2023-02-21 11:31:08 - progress_bar.py[line:274] - INFO: epoch 001:  26694 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.7, bsz=40, num_updates=26660, lr=4.1741e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10, ema_decay=0.9999, wall=79521
2023-02-21 11:31:19 - progress_bar.py[line:274] - INFO: epoch 001:  26704 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.89, wpb=110.1, bsz=40, num_updates=26670, lr=4.17374e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=79532
2023-02-21 11:31:30 - progress_bar.py[line:274] - INFO: epoch 001:  26714 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=110.7, bsz=40, num_updates=26680, lr=4.17338e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79543
2023-02-21 11:31:41 - progress_bar.py[line:274] - INFO: epoch 001:  26724 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.9, wpb=110, bsz=40, num_updates=26690, lr=4.17302e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79554
2023-02-21 11:31:53 - progress_bar.py[line:274] - INFO: epoch 001:  26734 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111.1, bsz=40, num_updates=26700, lr=4.17265e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79566
2023-02-21 11:32:04 - progress_bar.py[line:274] - INFO: epoch 001:  26744 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.8, bsz=40, num_updates=26710, lr=4.17229e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79577
2023-02-21 11:32:16 - progress_bar.py[line:274] - INFO: epoch 001:  26754 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=111.1, bsz=40, num_updates=26720, lr=4.17193e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79589
2023-02-21 11:32:27 - progress_bar.py[line:274] - INFO: epoch 001:  26764 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.89, wpb=110.1, bsz=40, num_updates=26730, lr=4.17157e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79600
2023-02-21 11:32:39 - progress_bar.py[line:274] - INFO: epoch 001:  26774 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.5, ups=0.87, wpb=109, bsz=40, num_updates=26740, lr=4.17121e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79611
2023-02-21 11:32:50 - progress_bar.py[line:274] - INFO: epoch 001:  26784 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111, bsz=40, num_updates=26750, lr=4.17085e-05, gnorm=0.046, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79623
2023-02-21 11:33:01 - progress_bar.py[line:274] - INFO: epoch 001:  26794 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.3, bsz=40, num_updates=26760, lr=4.17048e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79634
2023-02-21 11:33:12 - progress_bar.py[line:274] - INFO: epoch 001:  26804 / 142023 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=110.7, bsz=40, num_updates=26770, lr=4.17012e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79645
2023-02-21 11:33:24 - progress_bar.py[line:274] - INFO: epoch 001:  26814 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.4, ups=0.86, wpb=110.8, bsz=40, num_updates=26780, lr=4.16976e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=79656
2023-02-21 11:33:35 - progress_bar.py[line:274] - INFO: epoch 001:  26824 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.4, ups=0.86, wpb=110.5, bsz=40, num_updates=26790, lr=4.1694e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=79668
2023-02-21 11:33:47 - progress_bar.py[line:274] - INFO: epoch 001:  26834 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=112.1, bsz=40, num_updates=26800, lr=4.16904e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79679
2023-02-21 11:33:57 - progress_bar.py[line:274] - INFO: epoch 001:  26844 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.92, wpb=108.9, bsz=40, num_updates=26810, lr=4.16867e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79690
2023-02-21 11:34:07 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 11:34:10 - progress_bar.py[line:274] - INFO: epoch 001:  26855 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.2, ups=0.81, wpb=110, bsz=40, num_updates=26820, lr=4.16831e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=79703
2023-02-21 11:34:21 - progress_bar.py[line:274] - INFO: epoch 001:  26865 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.9, wpb=110.1, bsz=40, num_updates=26830, lr=4.16795e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79714
2023-02-21 11:34:32 - progress_bar.py[line:274] - INFO: epoch 001:  26875 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.89, wpb=109.7, bsz=40, num_updates=26840, lr=4.16759e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79725
2023-02-21 11:34:43 - progress_bar.py[line:274] - INFO: epoch 001:  26885 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.8, bsz=40, num_updates=26850, lr=4.16723e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79736
2023-02-21 11:34:55 - progress_bar.py[line:274] - INFO: epoch 001:  26895 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.89, wpb=110.1, bsz=40, num_updates=26860, lr=4.16687e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79747
2023-02-21 11:35:06 - progress_bar.py[line:274] - INFO: epoch 001:  26905 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.88, wpb=110.4, bsz=40, num_updates=26870, lr=4.1665e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79759
2023-02-21 11:35:17 - progress_bar.py[line:274] - INFO: epoch 001:  26915 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.89, wpb=111.4, bsz=40, num_updates=26880, lr=4.16614e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79770
2023-02-21 11:35:29 - progress_bar.py[line:274] - INFO: epoch 001:  26925 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.6, bsz=40, num_updates=26890, lr=4.16578e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79781
2023-02-21 11:35:40 - progress_bar.py[line:274] - INFO: epoch 001:  26935 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=26900, lr=4.16542e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79793
2023-02-21 11:35:51 - progress_bar.py[line:274] - INFO: epoch 001:  26945 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.91, wpb=109.6, bsz=40, num_updates=26910, lr=4.16506e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79804
2023-02-21 11:36:02 - progress_bar.py[line:274] - INFO: epoch 001:  26955 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.6, bsz=40, num_updates=26920, lr=4.16469e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10, ema_decay=0.9999, wall=79815
2023-02-21 11:36:13 - progress_bar.py[line:274] - INFO: epoch 001:  26965 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.6, bsz=40, num_updates=26930, lr=4.16433e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79826
2023-02-21 11:36:24 - progress_bar.py[line:274] - INFO: epoch 001:  26975 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.2, bsz=40, num_updates=26940, lr=4.16397e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79837
2023-02-21 11:36:36 - progress_bar.py[line:274] - INFO: epoch 001:  26985 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.7, ups=0.83, wpb=111.5, bsz=40, num_updates=26950, lr=4.16361e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=79849
2023-02-21 11:36:48 - progress_bar.py[line:274] - INFO: epoch 001:  26995 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.87, wpb=111.1, bsz=40, num_updates=26960, lr=4.16325e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=79861
2023-02-21 11:36:59 - progress_bar.py[line:274] - INFO: epoch 001:  27005 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.9, wpb=110.4, bsz=40, num_updates=26970, lr=4.16289e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79872
2023-02-21 11:37:11 - progress_bar.py[line:274] - INFO: epoch 001:  27015 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=26980, lr=4.16252e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79883
2023-02-21 11:37:22 - progress_bar.py[line:274] - INFO: epoch 001:  27025 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=112, bsz=40, num_updates=26990, lr=4.16216e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79895
2023-02-21 11:37:34 - progress_bar.py[line:274] - INFO: epoch 001:  27035 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=111.5, bsz=40, num_updates=27000, lr=4.1618e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79906
2023-02-21 11:37:45 - progress_bar.py[line:274] - INFO: epoch 001:  27045 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.87, wpb=112.4, bsz=40, num_updates=27010, lr=4.16144e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79918
2023-02-21 11:37:56 - progress_bar.py[line:274] - INFO: epoch 001:  27055 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.4, bsz=40, num_updates=27020, lr=4.16108e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79929
2023-02-21 11:38:08 - progress_bar.py[line:274] - INFO: epoch 001:  27065 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.88, wpb=112.6, bsz=40, num_updates=27030, lr=4.16071e-05, gnorm=0.046, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79941
2023-02-21 11:38:19 - progress_bar.py[line:274] - INFO: epoch 001:  27075 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.1, ups=0.87, wpb=111, bsz=40, num_updates=27040, lr=4.16035e-05, gnorm=0.087, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79952
2023-02-21 11:38:31 - progress_bar.py[line:274] - INFO: epoch 001:  27085 / 142023 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.88, wpb=112.3, bsz=40, num_updates=27050, lr=4.15999e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79963
2023-02-21 11:38:42 - progress_bar.py[line:274] - INFO: epoch 001:  27095 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110, bsz=40, num_updates=27060, lr=4.15963e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=79975
2023-02-21 11:38:53 - progress_bar.py[line:274] - INFO: epoch 001:  27105 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=27070, lr=4.15927e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79986
2023-02-21 11:39:04 - progress_bar.py[line:274] - INFO: epoch 001:  27115 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=111.5, bsz=40, num_updates=27080, lr=4.15891e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79997
2023-02-21 11:39:16 - progress_bar.py[line:274] - INFO: epoch 001:  27125 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.87, wpb=111, bsz=40, num_updates=27090, lr=4.15854e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80009
2023-02-21 11:39:27 - progress_bar.py[line:274] - INFO: epoch 001:  27135 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.8, bsz=40, num_updates=27100, lr=4.15818e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80020
2023-02-21 11:39:39 - progress_bar.py[line:274] - INFO: epoch 001:  27145 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.86, wpb=111.2, bsz=40, num_updates=27110, lr=4.15782e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=80031
2023-02-21 11:39:50 - progress_bar.py[line:274] - INFO: epoch 001:  27155 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.87, wpb=112, bsz=40, num_updates=27120, lr=4.15746e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80043
2023-02-21 11:40:01 - progress_bar.py[line:274] - INFO: epoch 001:  27165 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.4, bsz=40, num_updates=27130, lr=4.1571e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=80054
2023-02-21 11:40:13 - progress_bar.py[line:274] - INFO: epoch 001:  27175 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=110.3, bsz=40, num_updates=27140, lr=4.15673e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80065
2023-02-21 11:40:24 - progress_bar.py[line:274] - INFO: epoch 001:  27185 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=111, bsz=40, num_updates=27150, lr=4.15637e-05, gnorm=0.035, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80077
2023-02-21 11:40:35 - progress_bar.py[line:274] - INFO: epoch 001:  27195 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.7, bsz=40, num_updates=27160, lr=4.15601e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=80088
2023-02-21 11:40:46 - progress_bar.py[line:274] - INFO: epoch 001:  27205 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.9, wpb=109.8, bsz=40, num_updates=27170, lr=4.15565e-05, gnorm=0.048, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=80099
2023-02-21 11:40:58 - progress_bar.py[line:274] - INFO: epoch 001:  27215 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.87, wpb=113.3, bsz=40, num_updates=27180, lr=4.15529e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80111
2023-02-21 11:41:08 - progress_bar.py[line:274] - INFO: epoch 001:  27225 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.94, wpb=111.4, bsz=40, num_updates=27190, lr=4.15493e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80121
2023-02-21 11:41:20 - progress_bar.py[line:274] - INFO: epoch 001:  27235 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=111.5, bsz=40, num_updates=27200, lr=4.15456e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80133
2023-02-21 11:41:31 - progress_bar.py[line:274] - INFO: epoch 001:  27245 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=111.1, bsz=40, num_updates=27210, lr=4.1542e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80144
2023-02-21 11:41:43 - progress_bar.py[line:274] - INFO: epoch 001:  27255 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.1, ups=0.87, wpb=109.4, bsz=40, num_updates=27220, lr=4.15384e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=80156
2023-02-21 11:41:55 - progress_bar.py[line:274] - INFO: epoch 001:  27265 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.86, wpb=112.7, bsz=40, num_updates=27230, lr=4.15348e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=12, gb_free=11, ema_decay=0.9999, wall=80167
2023-02-21 11:42:06 - progress_bar.py[line:274] - INFO: epoch 001:  27275 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.3, ups=0.86, wpb=110.8, bsz=40, num_updates=27240, lr=4.15312e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=80179
2023-02-21 11:42:18 - progress_bar.py[line:274] - INFO: epoch 001:  27285 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=111.2, bsz=40, num_updates=27250, lr=4.15275e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80190
2023-02-21 11:42:29 - progress_bar.py[line:274] - INFO: epoch 001:  27295 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.3, bsz=40, num_updates=27260, lr=4.15239e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80202
2023-02-21 11:42:40 - progress_bar.py[line:274] - INFO: epoch 001:  27305 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.87, wpb=111.2, bsz=40, num_updates=27270, lr=4.15203e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80213
2023-02-21 11:42:51 - progress_bar.py[line:274] - INFO: epoch 001:  27315 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111, bsz=40, num_updates=27280, lr=4.15167e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80224
2023-02-21 11:43:03 - progress_bar.py[line:274] - INFO: epoch 001:  27325 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.8, ups=0.87, wpb=111.3, bsz=40, num_updates=27290, lr=4.15131e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=80236
2023-02-21 11:43:14 - progress_bar.py[line:274] - INFO: epoch 001:  27335 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.89, wpb=110, bsz=40, num_updates=27300, lr=4.15095e-05, gnorm=0.083, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80247
2023-02-21 11:43:25 - progress_bar.py[line:274] - INFO: epoch 001:  27345 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.87, wpb=112.1, bsz=40, num_updates=27310, lr=4.15058e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=80258
2023-02-21 11:43:37 - progress_bar.py[line:274] - INFO: epoch 001:  27355 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.89, wpb=109.4, bsz=40, num_updates=27320, lr=4.15022e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80270
2023-02-21 11:43:48 - progress_bar.py[line:274] - INFO: epoch 001:  27365 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=27330, lr=4.14986e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80281
2023-02-21 11:44:00 - progress_bar.py[line:274] - INFO: epoch 001:  27375 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.8, bsz=40, num_updates=27340, lr=4.1495e-05, gnorm=0.042, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80292
2023-02-21 11:44:11 - progress_bar.py[line:274] - INFO: epoch 001:  27385 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.3, bsz=40, num_updates=27350, lr=4.14914e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80304
2023-02-21 11:44:22 - progress_bar.py[line:274] - INFO: epoch 001:  27395 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=110.9, bsz=40, num_updates=27360, lr=4.14877e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=80315
2023-02-21 11:44:33 - progress_bar.py[line:274] - INFO: epoch 001:  27405 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=27370, lr=4.14841e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80326
2023-02-21 11:44:44 - progress_bar.py[line:274] - INFO: epoch 001:  27415 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=110.9, bsz=40, num_updates=27380, lr=4.14805e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=80337
2023-02-21 11:44:56 - progress_bar.py[line:274] - INFO: epoch 001:  27425 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.2, ups=0.86, wpb=110.9, bsz=40, num_updates=27390, lr=4.14769e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=80349
2023-02-21 11:45:07 - progress_bar.py[line:274] - INFO: epoch 001:  27435 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=110.4, bsz=40, num_updates=27400, lr=4.14733e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80360
2023-02-21 11:45:18 - progress_bar.py[line:274] - INFO: epoch 001:  27445 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.3, bsz=40, num_updates=27410, lr=4.14697e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=80371
2023-02-21 11:45:29 - progress_bar.py[line:274] - INFO: epoch 001:  27455 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.88, wpb=109.6, bsz=40, num_updates=27420, lr=4.1466e-05, gnorm=0.04, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=80382
2023-02-21 11:45:41 - progress_bar.py[line:274] - INFO: epoch 001:  27465 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=110.8, bsz=40, num_updates=27430, lr=4.14624e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80394
2023-02-21 11:45:52 - progress_bar.py[line:274] - INFO: epoch 001:  27475 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=27440, lr=4.14588e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=80405
2023-02-21 11:46:04 - progress_bar.py[line:274] - INFO: epoch 001:  27485 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.87, wpb=112.3, bsz=40, num_updates=27450, lr=4.14552e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80416
2023-02-21 11:46:15 - progress_bar.py[line:274] - INFO: epoch 001:  27495 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.89, wpb=110.4, bsz=40, num_updates=27460, lr=4.14516e-05, gnorm=0.076, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80428
2023-02-21 11:46:26 - progress_bar.py[line:274] - INFO: epoch 001:  27505 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.9, wpb=110.3, bsz=40, num_updates=27470, lr=4.14479e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80439
2023-02-21 11:46:37 - progress_bar.py[line:274] - INFO: epoch 001:  27515 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.9, wpb=109.8, bsz=40, num_updates=27480, lr=4.14443e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=80450
2023-02-21 11:46:48 - progress_bar.py[line:274] - INFO: epoch 001:  27525 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=111.3, bsz=40, num_updates=27490, lr=4.14407e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80461
2023-02-21 11:46:59 - progress_bar.py[line:274] - INFO: epoch 001:  27535 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.89, wpb=110.5, bsz=40, num_updates=27500, lr=4.14371e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80472
2023-02-21 11:47:11 - progress_bar.py[line:274] - INFO: epoch 001:  27545 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.9, wpb=110.9, bsz=40, num_updates=27510, lr=4.14335e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80483
2023-02-21 11:47:22 - progress_bar.py[line:274] - INFO: epoch 001:  27555 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=111, bsz=40, num_updates=27520, lr=4.14299e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80495
2023-02-21 11:47:33 - progress_bar.py[line:274] - INFO: epoch 001:  27565 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=110.7, bsz=40, num_updates=27530, lr=4.14262e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80506
2023-02-21 11:47:44 - progress_bar.py[line:274] - INFO: epoch 001:  27575 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=111.2, bsz=40, num_updates=27540, lr=4.14226e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80517
2023-02-21 11:47:56 - progress_bar.py[line:274] - INFO: epoch 001:  27585 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.86, wpb=111.7, bsz=40, num_updates=27550, lr=4.1419e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=80529
2023-02-21 11:48:07 - progress_bar.py[line:274] - INFO: epoch 001:  27595 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=27560, lr=4.14154e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80540
2023-02-21 11:48:18 - progress_bar.py[line:274] - INFO: epoch 001:  27605 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.5, bsz=40, num_updates=27570, lr=4.14118e-05, gnorm=0.047, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80551
2023-02-21 11:48:29 - progress_bar.py[line:274] - INFO: epoch 001:  27615 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.9, bsz=40, num_updates=27580, lr=4.14081e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80562
2023-02-21 11:48:41 - progress_bar.py[line:274] - INFO: epoch 001:  27625 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=27590, lr=4.14045e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=80574
2023-02-21 11:48:52 - progress_bar.py[line:274] - INFO: epoch 001:  27635 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111.6, bsz=40, num_updates=27600, lr=4.14009e-05, gnorm=0.044, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80585
2023-02-21 11:49:03 - progress_bar.py[line:274] - INFO: epoch 001:  27645 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.6, bsz=40, num_updates=27610, lr=4.13973e-05, gnorm=0.036, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=80596
2023-02-21 11:49:15 - progress_bar.py[line:274] - INFO: epoch 001:  27655 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.9, ups=0.86, wpb=110.8, bsz=40, num_updates=27620, lr=4.13937e-05, gnorm=0.037, clip=0, loss_scale=8192, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=80608
2023-02-21 11:49:26 - progress_bar.py[line:274] - INFO: epoch 001:  27665 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.92, wpb=111.5, bsz=40, num_updates=27630, lr=4.13901e-05, gnorm=0.045, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80619
2023-02-21 11:49:37 - progress_bar.py[line:274] - INFO: epoch 001:  27675 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=27640, lr=4.13864e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=80630
2023-02-21 11:49:48 - progress_bar.py[line:274] - INFO: epoch 001:  27685 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.88, wpb=112.4, bsz=40, num_updates=27650, lr=4.13828e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80641
2023-02-21 11:50:00 - progress_bar.py[line:274] - INFO: epoch 001:  27695 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.3, bsz=40, num_updates=27660, lr=4.13792e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80652
2023-02-21 11:50:11 - progress_bar.py[line:274] - INFO: epoch 001:  27705 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.88, wpb=111.8, bsz=40, num_updates=27670, lr=4.13756e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80664
2023-02-21 11:50:22 - progress_bar.py[line:274] - INFO: epoch 001:  27715 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.6, bsz=40, num_updates=27680, lr=4.1372e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80675
2023-02-21 11:50:33 - progress_bar.py[line:274] - INFO: epoch 001:  27725 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.7, bsz=40, num_updates=27690, lr=4.13683e-05, gnorm=0.044, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80686
2023-02-21 11:50:44 - progress_bar.py[line:274] - INFO: epoch 001:  27735 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=111.2, bsz=40, num_updates=27700, lr=4.13647e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80697
2023-02-21 11:50:56 - progress_bar.py[line:274] - INFO: epoch 001:  27745 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=27710, lr=4.13611e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80708
2023-02-21 11:51:07 - progress_bar.py[line:274] - INFO: epoch 001:  27755 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=27720, lr=4.13575e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80720
2023-02-21 11:51:18 - progress_bar.py[line:274] - INFO: epoch 001:  27765 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.2, bsz=40, num_updates=27730, lr=4.13539e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80731
2023-02-21 11:51:29 - progress_bar.py[line:274] - INFO: epoch 001:  27775 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=27740, lr=4.13503e-05, gnorm=0.046, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80742
2023-02-21 11:51:40 - progress_bar.py[line:274] - INFO: epoch 001:  27785 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.5, bsz=40, num_updates=27750, lr=4.13466e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80753
2023-02-21 11:51:51 - progress_bar.py[line:274] - INFO: epoch 001:  27795 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112, bsz=40, num_updates=27760, lr=4.1343e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80764
2023-02-21 11:51:52 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 11:52:03 - progress_bar.py[line:274] - INFO: epoch 001:  27806 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.2, ups=0.86, wpb=110.8, bsz=40, num_updates=27770, lr=4.13394e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=80776
2023-02-21 11:52:14 - progress_bar.py[line:274] - INFO: epoch 001:  27816 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=111.3, bsz=40, num_updates=27780, lr=4.13358e-05, gnorm=0.047, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80787
2023-02-21 11:52:25 - progress_bar.py[line:274] - INFO: epoch 001:  27826 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.93, wpb=110.5, bsz=40, num_updates=27790, lr=4.13322e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80798
2023-02-21 11:52:36 - progress_bar.py[line:274] - INFO: epoch 001:  27836 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=110.7, bsz=40, num_updates=27800, lr=4.13285e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=80809
2023-02-21 11:52:48 - progress_bar.py[line:274] - INFO: epoch 001:  27846 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.7, bsz=40, num_updates=27810, lr=4.13249e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80820
2023-02-21 11:52:59 - progress_bar.py[line:274] - INFO: epoch 001:  27856 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.4, bsz=40, num_updates=27820, lr=4.13213e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80832
2023-02-21 11:53:10 - progress_bar.py[line:274] - INFO: epoch 001:  27866 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.7, bsz=40, num_updates=27830, lr=4.13177e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80843
2023-02-21 11:53:21 - progress_bar.py[line:274] - INFO: epoch 001:  27876 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111.1, bsz=40, num_updates=27840, lr=4.13141e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80854
2023-02-21 11:53:32 - progress_bar.py[line:274] - INFO: epoch 001:  27886 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=27850, lr=4.13105e-05, gnorm=0.036, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80865
2023-02-21 11:53:43 - progress_bar.py[line:274] - INFO: epoch 001:  27896 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.7, bsz=40, num_updates=27860, lr=4.13068e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=80876
2023-02-21 11:53:55 - progress_bar.py[line:274] - INFO: epoch 001:  27906 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.2, bsz=40, num_updates=27870, lr=4.13032e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=80887
2023-02-21 11:54:06 - progress_bar.py[line:274] - INFO: epoch 001:  27916 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=112, bsz=40, num_updates=27880, lr=4.12996e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=80899
2023-02-21 11:54:17 - progress_bar.py[line:274] - INFO: epoch 001:  27926 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=112.4, bsz=40, num_updates=27890, lr=4.1296e-05, gnorm=0.042, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=80910
2023-02-21 11:54:27 - progress_bar.py[line:274] - INFO: epoch 001:  27936 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105, ups=0.94, wpb=111.3, bsz=40, num_updates=27900, lr=4.12924e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80920
2023-02-21 11:54:39 - progress_bar.py[line:274] - INFO: epoch 001:  27946 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=27910, lr=4.12887e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80931
2023-02-21 11:54:50 - progress_bar.py[line:274] - INFO: epoch 001:  27956 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.89, wpb=110.5, bsz=40, num_updates=27920, lr=4.12851e-05, gnorm=0.049, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80943
2023-02-21 11:55:01 - progress_bar.py[line:274] - INFO: epoch 001:  27966 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=111.3, bsz=40, num_updates=27930, lr=4.12815e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=80954
2023-02-21 11:55:13 - progress_bar.py[line:274] - INFO: epoch 001:  27976 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.87, wpb=111.7, bsz=40, num_updates=27940, lr=4.12779e-05, gnorm=0.047, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=80966
2023-02-21 11:55:24 - progress_bar.py[line:274] - INFO: epoch 001:  27986 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=111, bsz=40, num_updates=27950, lr=4.12743e-05, gnorm=0.043, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80977
2023-02-21 11:55:35 - progress_bar.py[line:274] - INFO: epoch 001:  27996 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.91, wpb=112, bsz=40, num_updates=27960, lr=4.12707e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=80988
2023-02-21 11:55:46 - progress_bar.py[line:274] - INFO: epoch 001:  28006 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.9, bsz=40, num_updates=27970, lr=4.1267e-05, gnorm=0.046, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80999
2023-02-21 11:55:57 - progress_bar.py[line:274] - INFO: epoch 001:  28016 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.4, bsz=40, num_updates=27980, lr=4.12634e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=81010
2023-02-21 11:56:08 - progress_bar.py[line:274] - INFO: epoch 001:  28026 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.9, wpb=109, bsz=40, num_updates=27990, lr=4.12598e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=81021
2023-02-21 11:56:20 - progress_bar.py[line:274] - INFO: epoch 001:  28036 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=28000, lr=4.12562e-05, gnorm=0.04, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=81033
2023-02-21 11:56:20 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 11:56:21 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 11:56:21 - train.py[line:551] - INFO: load:1.19 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 11:58:23 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 11:58:23 - train.py[line:551] - INFO: load:1.21 valid_run:121.89 task_valid:119.09 collect_output:1.78
2023-02-21 12:00:23 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 12:00:23 - train.py[line:551] - INFO: load:1.24 valid_run:241.94 task_valid:235.11 collect_output:4.80
2023-02-21 12:02:25 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 12:02:25 - train.py[line:551] - INFO: load:1.26 valid_run:364.00 task_valid:351.77 collect_output:9.22
2023-02-21 12:04:28 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 12:04:28 - train.py[line:551] - INFO: load:1.29 valid_run:486.23 task_valid:465.83 collect_output:16.39
2023-02-21 12:06:28 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 12:06:28 - train.py[line:551] - INFO: load:1.31 valid_run:606.89 task_valid:583.22 collect_output:18.67
2023-02-21 12:08:32 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 12:08:32 - train.py[line:551] - INFO: load:1.33 valid_run:730.24 task_valid:702.19 collect_output:22.04
2023-02-21 12:10:35 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 12:10:35 - train.py[line:551] - INFO: load:1.36 valid_run:853.43 task_valid:820.57 collect_output:25.84
2023-02-21 12:12:37 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 12:12:37 - train.py[line:551] - INFO: load:1.38 valid_run:975.87 task_valid:937.80 collect_output:30.03
2023-02-21 12:14:41 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 12:14:41 - train.py[line:551] - INFO: load:1.40 valid_run:1099.78 task_valid:1055.17 collect_output:35.59
2023-02-21 12:16:43 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 12:16:43 - train.py[line:551] - INFO: load:1.43 valid_run:1221.65 task_valid:1168.12 collect_output:43.49
2023-02-21 12:18:44 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 12:18:44 - train.py[line:551] - INFO: load:1.45 valid_run:1342.21 task_valid:1284.08 collect_output:47.09
2023-02-21 12:20:46 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 12:20:46 - train.py[line:551] - INFO: load:1.48 valid_run:1464.20 task_valid:1401.46 collect_output:50.66
2023-02-21 12:22:45 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 12:22:45 - train.py[line:551] - INFO: load:1.50 valid_run:1583.47 task_valid:1515.58 collect_output:54.79
2023-02-21 12:24:47 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 12:24:47 - train.py[line:551] - INFO: load:1.53 valid_run:1704.77 task_valid:1633.50 collect_output:57.16
2023-02-21 12:26:48 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 12:26:48 - train.py[line:551] - INFO: load:1.55 valid_run:1825.95 task_valid:1749.82 collect_output:61.02
2023-02-21 12:28:49 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 12:28:49 - train.py[line:551] - INFO: load:1.57 valid_run:1947.30 task_valid:1864.09 collect_output:67.10
2023-02-21 12:30:51 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 12:30:51 - train.py[line:551] - INFO: load:1.60 valid_run:2069.02 task_valid:1980.39 collect_output:71.50
2023-02-21 12:32:52 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 12:32:52 - train.py[line:551] - INFO: load:1.62 valid_run:2189.95 task_valid:2098.50 collect_output:73.31
2023-02-21 12:34:54 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 12:34:54 - train.py[line:551] - INFO: load:1.65 valid_run:2311.60 task_valid:2215.86 collect_output:76.54
2023-02-21 12:36:54 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 12:36:54 - train.py[line:551] - INFO: load:1.67 valid_run:2432.19 task_valid:2332.55 collect_output:79.44
2023-02-21 12:38:56 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 12:38:56 - train.py[line:551] - INFO: load:1.69 valid_run:2554.04 task_valid:2449.41 collect_output:83.43
2023-02-21 12:40:59 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 12:40:59 - train.py[line:551] - INFO: load:1.72 valid_run:2676.34 task_valid:2568.61 collect_output:85.51
2023-02-21 12:42:59 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 12:42:59 - train.py[line:551] - INFO: load:1.74 valid_run:2796.96 task_valid:2683.11 collect_output:90.65
2023-02-21 12:45:00 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 12:45:00 - train.py[line:551] - INFO: load:1.77 valid_run:2917.08 task_valid:2799.43 collect_output:93.44
2023-02-21 12:47:02 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 12:47:02 - train.py[line:551] - INFO: load:1.79 valid_run:3038.99 task_valid:2915.90 collect_output:97.86
2023-02-21 12:49:05 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 12:49:05 - train.py[line:551] - INFO: load:1.82 valid_run:3162.12 task_valid:3032.11 collect_output:103.77
2023-02-21 12:51:05 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 12:51:05 - train.py[line:551] - INFO: load:1.84 valid_run:3282.08 task_valid:3146.38 collect_output:108.45
2023-02-21 12:53:07 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 12:53:07 - train.py[line:551] - INFO: load:1.87 valid_run:3404.09 task_valid:3265.87 collect_output:109.97
2023-02-21 12:55:09 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 12:55:09 - train.py[line:551] - INFO: load:1.89 valid_run:3526.03 task_valid:3381.71 collect_output:115.05
2023-02-21 12:57:11 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 12:57:11 - train.py[line:551] - INFO: load:1.92 valid_run:3648.20 task_valid:3500.43 collect_output:117.49
2023-02-21 12:59:12 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 12:59:12 - train.py[line:551] - INFO: load:1.94 valid_run:3769.48 task_valid:3618.97 collect_output:119.23

====================================================================================================
SGG eval:     R @ 50: 0.6002;     R @ 100: 0.6279;     R @ 500: 0.6520;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3631;    mR @ 100: 0.3961;    mR @ 500: 0.4302;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3548) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.9108) (says:0.0000) (sitting on:0.6939) (standing on:0.3943) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6002;     R @ 100: 0.6279;     R @ 500: 0.6520;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3631;    mR @ 100: 0.3961;    mR @ 500: 0.4302;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3548) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.9108) (says:0.0000) (sitting on:0.6939) (standing on:0.3943) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================

2023-02-21 12:59:43 - train.py[line:487] - INFO: 0.6279291316526611
2023-02-21 12:59:43 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 12:59:43 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.217 | loss_v1 0 | loss_v2 0 | nll_loss 0.045 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.627929 | ppl 1.03 | vqa_score 0.2928 | wps 118 | wpb 72 | bsz 24 | num_updates 28000 | best_R@100 0.693596
2023-02-21 12:59:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 28000 updates
2023-02-21 12:59:44 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_28000.pt
2023-02-21 12:59:49 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_28000.pt
2023-02-21 12:59:51 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_28000.pt (epoch 1 @ 28000 updates, score 0.6279291316526611) (writing took 7.980816720053554 seconds)
2023-02-21 13:00:03 - progress_bar.py[line:274] - INFO: epoch 001:  28046 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=28010, lr=4.12526e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84856
2023-02-21 13:00:14 - progress_bar.py[line:274] - INFO: epoch 001:  28056 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=110.4, bsz=40, num_updates=28020, lr=4.12489e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84867
2023-02-21 13:00:25 - progress_bar.py[line:274] - INFO: epoch 001:  28066 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.9, ups=0.93, wpb=110.8, bsz=40, num_updates=28030, lr=4.12453e-05, gnorm=0.049, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84878
2023-02-21 13:00:36 - progress_bar.py[line:274] - INFO: epoch 001:  28076 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.6, bsz=40, num_updates=28040, lr=4.12417e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=84889
2023-02-21 13:00:47 - progress_bar.py[line:274] - INFO: epoch 001:  28086 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.8, bsz=40, num_updates=28050, lr=4.12381e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84900
2023-02-21 13:00:57 - progress_bar.py[line:274] - INFO: epoch 001:  28096 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.7, ups=0.94, wpb=111.1, bsz=40, num_updates=28060, lr=4.12345e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84910
2023-02-21 13:01:09 - progress_bar.py[line:274] - INFO: epoch 001:  28106 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=28070, lr=4.12309e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84921
2023-02-21 13:01:20 - progress_bar.py[line:274] - INFO: epoch 001:  28116 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111.1, bsz=40, num_updates=28080, lr=4.12272e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84932
2023-02-21 13:01:30 - progress_bar.py[line:274] - INFO: epoch 001:  28126 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.93, wpb=111.2, bsz=40, num_updates=28090, lr=4.12236e-05, gnorm=0.044, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84943
2023-02-21 13:01:42 - progress_bar.py[line:274] - INFO: epoch 001:  28136 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.89, wpb=112.3, bsz=40, num_updates=28100, lr=4.122e-05, gnorm=0.047, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84954
2023-02-21 13:01:53 - progress_bar.py[line:274] - INFO: epoch 001:  28146 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=28110, lr=4.12164e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84965
2023-02-21 13:02:04 - progress_bar.py[line:274] - INFO: epoch 001:  28156 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=28120, lr=4.12128e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84977
2023-02-21 13:02:15 - progress_bar.py[line:274] - INFO: epoch 001:  28166 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=28130, lr=4.12091e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84988
2023-02-21 13:02:26 - progress_bar.py[line:274] - INFO: epoch 001:  28176 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.91, wpb=111.4, bsz=40, num_updates=28140, lr=4.12055e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84999
2023-02-21 13:02:37 - progress_bar.py[line:274] - INFO: epoch 001:  28186 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.92, wpb=109.7, bsz=40, num_updates=28150, lr=4.12019e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85010
2023-02-21 13:02:49 - progress_bar.py[line:274] - INFO: epoch 001:  28196 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=111.3, bsz=40, num_updates=28160, lr=4.11983e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85021
2023-02-21 13:03:00 - progress_bar.py[line:274] - INFO: epoch 001:  28206 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=28170, lr=4.11947e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85033
2023-02-21 13:03:11 - progress_bar.py[line:274] - INFO: epoch 001:  28216 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=111.8, bsz=40, num_updates=28180, lr=4.1191e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85044
2023-02-21 13:03:22 - progress_bar.py[line:274] - INFO: epoch 001:  28226 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.4, bsz=40, num_updates=28190, lr=4.11874e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85055
2023-02-21 13:03:33 - progress_bar.py[line:274] - INFO: epoch 001:  28236 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.89, wpb=112.4, bsz=40, num_updates=28200, lr=4.11838e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85066
2023-02-21 13:03:45 - progress_bar.py[line:274] - INFO: epoch 001:  28246 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=28210, lr=4.11802e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85077
2023-02-21 13:03:56 - progress_bar.py[line:274] - INFO: epoch 001:  28256 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=28220, lr=4.11766e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85089
2023-02-21 13:04:07 - progress_bar.py[line:274] - INFO: epoch 001:  28266 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112, bsz=40, num_updates=28230, lr=4.1173e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85100
2023-02-21 13:04:18 - progress_bar.py[line:274] - INFO: epoch 001:  28276 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=28240, lr=4.11693e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85111
2023-02-21 13:04:29 - progress_bar.py[line:274] - INFO: epoch 001:  28286 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.2, bsz=40, num_updates=28250, lr=4.11657e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85122
2023-02-21 13:04:40 - progress_bar.py[line:274] - INFO: epoch 001:  28296 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=28260, lr=4.11621e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85133
2023-02-21 13:04:51 - progress_bar.py[line:274] - INFO: epoch 001:  28306 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.5, ups=0.92, wpb=112.7, bsz=40, num_updates=28270, lr=4.11585e-05, gnorm=0.047, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85144
2023-02-21 13:05:03 - progress_bar.py[line:274] - INFO: epoch 001:  28316 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110.1, bsz=40, num_updates=28280, lr=4.11549e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85155
2023-02-21 13:05:14 - progress_bar.py[line:274] - INFO: epoch 001:  28326 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=28290, lr=4.11512e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10, ema_decay=0.9999, wall=85167
2023-02-21 13:05:25 - progress_bar.py[line:274] - INFO: epoch 001:  28336 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=28300, lr=4.11476e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85178
2023-02-21 13:05:36 - progress_bar.py[line:274] - INFO: epoch 001:  28346 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=28310, lr=4.1144e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85189
2023-02-21 13:05:47 - progress_bar.py[line:274] - INFO: epoch 001:  28356 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=28320, lr=4.11404e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85200
2023-02-21 13:05:58 - progress_bar.py[line:274] - INFO: epoch 001:  28366 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=110.6, bsz=40, num_updates=28330, lr=4.11368e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85211
2023-02-21 13:06:09 - progress_bar.py[line:274] - INFO: epoch 001:  28376 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=28340, lr=4.11332e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85222
2023-02-21 13:06:21 - progress_bar.py[line:274] - INFO: epoch 001:  28386 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.9, wpb=110.5, bsz=40, num_updates=28350, lr=4.11295e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85233
2023-02-21 13:06:32 - progress_bar.py[line:274] - INFO: epoch 001:  28396 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.89, wpb=112.5, bsz=40, num_updates=28360, lr=4.11259e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85245
2023-02-21 13:06:43 - progress_bar.py[line:274] - INFO: epoch 001:  28406 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=28370, lr=4.11223e-05, gnorm=0.094, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85256
2023-02-21 13:06:54 - progress_bar.py[line:274] - INFO: epoch 001:  28416 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=111.1, bsz=40, num_updates=28380, lr=4.11187e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85267
2023-02-21 13:07:05 - progress_bar.py[line:274] - INFO: epoch 001:  28426 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.8, bsz=40, num_updates=28390, lr=4.11151e-05, gnorm=0.041, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85278
2023-02-21 13:07:16 - progress_bar.py[line:274] - INFO: epoch 001:  28436 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=111.9, bsz=40, num_updates=28400, lr=4.11114e-05, gnorm=0.035, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85289
2023-02-21 13:07:27 - progress_bar.py[line:274] - INFO: epoch 001:  28446 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=112.3, bsz=40, num_updates=28410, lr=4.11078e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85300
2023-02-21 13:07:38 - progress_bar.py[line:274] - INFO: epoch 001:  28456 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.5, ups=0.94, wpb=111.7, bsz=40, num_updates=28420, lr=4.11042e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85311
2023-02-21 13:07:49 - progress_bar.py[line:274] - INFO: epoch 001:  28466 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.5, bsz=40, num_updates=28430, lr=4.11006e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85322
2023-02-21 13:08:00 - progress_bar.py[line:274] - INFO: epoch 001:  28476 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=28440, lr=4.1097e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85333
2023-02-21 13:08:11 - progress_bar.py[line:274] - INFO: epoch 001:  28486 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.4, bsz=40, num_updates=28450, lr=4.10934e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85344
2023-02-21 13:08:22 - progress_bar.py[line:274] - INFO: epoch 001:  28496 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.3, bsz=40, num_updates=28460, lr=4.10897e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85355
2023-02-21 13:08:33 - progress_bar.py[line:274] - INFO: epoch 001:  28506 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.3, ups=0.93, wpb=111.1, bsz=40, num_updates=28470, lr=4.10861e-05, gnorm=0.077, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85366
2023-02-21 13:08:44 - progress_bar.py[line:274] - INFO: epoch 001:  28516 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.9, wpb=111.3, bsz=40, num_updates=28480, lr=4.10825e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85377
2023-02-21 13:08:56 - progress_bar.py[line:274] - INFO: epoch 001:  28526 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.2, ups=0.85, wpb=110.4, bsz=40, num_updates=28490, lr=4.10789e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=85388
2023-02-21 13:09:06 - progress_bar.py[line:274] - INFO: epoch 001:  28536 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.8, ups=0.93, wpb=111.7, bsz=40, num_updates=28500, lr=4.10753e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85399
2023-02-21 13:09:18 - progress_bar.py[line:274] - INFO: epoch 001:  28546 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=28510, lr=4.10716e-05, gnorm=0.086, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85410
2023-02-21 13:09:28 - progress_bar.py[line:274] - INFO: epoch 001:  28556 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.6, ups=0.93, wpb=112.4, bsz=40, num_updates=28520, lr=4.1068e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85421
2023-02-21 13:09:39 - progress_bar.py[line:274] - INFO: epoch 001:  28566 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111.1, bsz=40, num_updates=28530, lr=4.10644e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85432
2023-02-21 13:09:50 - progress_bar.py[line:274] - INFO: epoch 001:  28576 / 142023 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.92, wpb=109.9, bsz=40, num_updates=28540, lr=4.10608e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85443
2023-02-21 13:10:01 - progress_bar.py[line:274] - INFO: epoch 001:  28586 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=28550, lr=4.10572e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85454
2023-02-21 13:10:13 - progress_bar.py[line:274] - INFO: epoch 001:  28596 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=28560, lr=4.10536e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85465
2023-02-21 13:10:24 - progress_bar.py[line:274] - INFO: epoch 001:  28606 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.91, wpb=109.4, bsz=40, num_updates=28570, lr=4.10499e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85476
2023-02-21 13:10:35 - progress_bar.py[line:274] - INFO: epoch 001:  28616 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=28580, lr=4.10463e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85488
2023-02-21 13:10:46 - progress_bar.py[line:274] - INFO: epoch 001:  28626 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=28590, lr=4.10427e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85499
2023-02-21 13:10:58 - progress_bar.py[line:274] - INFO: epoch 001:  28636 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=110.6, bsz=40, num_updates=28600, lr=4.10391e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85510
2023-02-21 13:11:09 - progress_bar.py[line:274] - INFO: epoch 001:  28646 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=110.4, bsz=40, num_updates=28610, lr=4.10355e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85521
2023-02-21 13:11:20 - progress_bar.py[line:274] - INFO: epoch 001:  28656 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.2, bsz=40, num_updates=28620, lr=4.10318e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85532
2023-02-21 13:11:31 - progress_bar.py[line:274] - INFO: epoch 001:  28666 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=28630, lr=4.10282e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85544
2023-02-21 13:11:42 - progress_bar.py[line:274] - INFO: epoch 001:  28676 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.9, wpb=109.8, bsz=40, num_updates=28640, lr=4.10246e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85555
2023-02-21 13:11:53 - progress_bar.py[line:274] - INFO: epoch 001:  28686 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=28650, lr=4.1021e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85566
2023-02-21 13:12:05 - progress_bar.py[line:274] - INFO: epoch 001:  28696 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.89, wpb=112.6, bsz=40, num_updates=28660, lr=4.10174e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85577
2023-02-21 13:12:15 - progress_bar.py[line:274] - INFO: epoch 001:  28706 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.5, bsz=40, num_updates=28670, lr=4.10138e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85588
2023-02-21 13:12:27 - progress_bar.py[line:274] - INFO: epoch 001:  28716 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=28680, lr=4.10101e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85599
2023-02-21 13:12:38 - progress_bar.py[line:274] - INFO: epoch 001:  28726 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.8, bsz=40, num_updates=28690, lr=4.10065e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=85610
2023-02-21 13:12:49 - progress_bar.py[line:274] - INFO: epoch 001:  28736 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.5, bsz=40, num_updates=28700, lr=4.10029e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85621
2023-02-21 13:13:00 - progress_bar.py[line:274] - INFO: epoch 001:  28746 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.6, ups=0.91, wpb=111.8, bsz=40, num_updates=28710, lr=4.09993e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85632
2023-02-21 13:13:11 - progress_bar.py[line:274] - INFO: epoch 001:  28756 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=28720, lr=4.09957e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85644
2023-02-21 13:13:22 - progress_bar.py[line:274] - INFO: epoch 001:  28766 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112, bsz=40, num_updates=28730, lr=4.0992e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85655
2023-02-21 13:13:33 - progress_bar.py[line:274] - INFO: epoch 001:  28776 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=28740, lr=4.09884e-05, gnorm=0.046, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85666
2023-02-21 13:13:44 - progress_bar.py[line:274] - INFO: epoch 001:  28786 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.92, wpb=112.5, bsz=40, num_updates=28750, lr=4.09848e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=85677
2023-02-21 13:13:55 - progress_bar.py[line:274] - INFO: epoch 001:  28796 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=28760, lr=4.09812e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85688
2023-02-21 13:14:06 - progress_bar.py[line:274] - INFO: epoch 001:  28806 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=28770, lr=4.09776e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85699
2023-02-21 13:14:17 - progress_bar.py[line:274] - INFO: epoch 001:  28816 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.5, bsz=40, num_updates=28780, lr=4.0974e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85710
2023-02-21 13:14:28 - progress_bar.py[line:274] - INFO: epoch 001:  28826 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.9, wpb=112, bsz=40, num_updates=28790, lr=4.09703e-05, gnorm=0.081, clip=0, loss_scale=16384, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85721
2023-02-21 13:14:32 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8192.0
2023-02-21 13:14:41 - progress_bar.py[line:274] - INFO: epoch 001:  28837 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.5, ups=0.83, wpb=109.6, bsz=40, num_updates=28800, lr=4.09667e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=85733
2023-02-21 13:14:52 - progress_bar.py[line:274] - INFO: epoch 001:  28847 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.91, wpb=112.4, bsz=40, num_updates=28810, lr=4.09631e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85744
2023-02-21 13:15:03 - progress_bar.py[line:274] - INFO: epoch 001:  28857 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.3, bsz=40, num_updates=28820, lr=4.09595e-05, gnorm=0.077, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85756
2023-02-21 13:15:14 - progress_bar.py[line:274] - INFO: epoch 001:  28867 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=28830, lr=4.09559e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85767
2023-02-21 13:15:25 - progress_bar.py[line:274] - INFO: epoch 001:  28877 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=28840, lr=4.09522e-05, gnorm=0.043, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85778
2023-02-21 13:15:37 - progress_bar.py[line:274] - INFO: epoch 001:  28887 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.87, wpb=110.3, bsz=40, num_updates=28850, lr=4.09486e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85790
2023-02-21 13:15:48 - progress_bar.py[line:274] - INFO: epoch 001:  28897 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.7, bsz=40, num_updates=28860, lr=4.0945e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85800
2023-02-21 13:15:59 - progress_bar.py[line:274] - INFO: epoch 001:  28907 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.88, wpb=112, bsz=40, num_updates=28870, lr=4.09414e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85812
2023-02-21 13:16:10 - progress_bar.py[line:274] - INFO: epoch 001:  28917 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=28880, lr=4.09378e-05, gnorm=0.046, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85823
2023-02-21 13:16:21 - progress_bar.py[line:274] - INFO: epoch 001:  28927 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.89, wpb=111.1, bsz=40, num_updates=28890, lr=4.09342e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85834
2023-02-21 13:16:32 - progress_bar.py[line:274] - INFO: epoch 001:  28937 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.2, bsz=40, num_updates=28900, lr=4.09305e-05, gnorm=0.049, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85845
2023-02-21 13:16:44 - progress_bar.py[line:274] - INFO: epoch 001:  28947 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=28910, lr=4.09269e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85856
2023-02-21 13:16:55 - progress_bar.py[line:274] - INFO: epoch 001:  28957 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.1, bsz=40, num_updates=28920, lr=4.09233e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85868
2023-02-21 13:17:06 - progress_bar.py[line:274] - INFO: epoch 001:  28967 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=111.5, bsz=40, num_updates=28930, lr=4.09197e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85879
2023-02-21 13:17:17 - progress_bar.py[line:274] - INFO: epoch 001:  28977 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111, bsz=40, num_updates=28940, lr=4.09161e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85890
2023-02-21 13:17:28 - progress_bar.py[line:274] - INFO: epoch 001:  28987 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.4, bsz=40, num_updates=28950, lr=4.09124e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85901
2023-02-21 13:17:39 - progress_bar.py[line:274] - INFO: epoch 001:  28997 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.6, bsz=40, num_updates=28960, lr=4.09088e-05, gnorm=0.046, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85912
2023-02-21 13:17:50 - progress_bar.py[line:274] - INFO: epoch 001:  29007 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.8, bsz=40, num_updates=28970, lr=4.09052e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85923
2023-02-21 13:18:01 - progress_bar.py[line:274] - INFO: epoch 001:  29017 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.2, ups=0.92, wpb=112.5, bsz=40, num_updates=28980, lr=4.09016e-05, gnorm=0.063, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85934
2023-02-21 13:18:09 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 13:18:13 - progress_bar.py[line:274] - INFO: epoch 001:  29028 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=92.5, ups=0.84, wpb=110.4, bsz=40, num_updates=28990, lr=4.0898e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=85946
2023-02-21 13:18:24 - progress_bar.py[line:274] - INFO: epoch 001:  29038 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.9, wpb=111.2, bsz=40, num_updates=29000, lr=4.08944e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85957
2023-02-21 13:18:35 - progress_bar.py[line:274] - INFO: epoch 001:  29048 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.5, bsz=40, num_updates=29010, lr=4.08907e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85968
2023-02-21 13:18:47 - progress_bar.py[line:274] - INFO: epoch 001:  29058 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.7, bsz=40, num_updates=29020, lr=4.08871e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85979
2023-02-21 13:18:58 - progress_bar.py[line:274] - INFO: epoch 001:  29068 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112, bsz=40, num_updates=29030, lr=4.08835e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85991
2023-02-21 13:19:09 - progress_bar.py[line:274] - INFO: epoch 001:  29078 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=29040, lr=4.08799e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86002
2023-02-21 13:19:20 - progress_bar.py[line:274] - INFO: epoch 001:  29088 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=112.1, bsz=40, num_updates=29050, lr=4.08763e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86013
2023-02-21 13:19:31 - progress_bar.py[line:274] - INFO: epoch 001:  29098 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=29060, lr=4.08726e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86024
2023-02-21 13:19:43 - progress_bar.py[line:274] - INFO: epoch 001:  29108 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.6, bsz=40, num_updates=29070, lr=4.0869e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86035
2023-02-21 13:19:54 - progress_bar.py[line:274] - INFO: epoch 001:  29118 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=29080, lr=4.08654e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86046
2023-02-21 13:20:05 - progress_bar.py[line:274] - INFO: epoch 001:  29128 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.3, bsz=40, num_updates=29090, lr=4.08618e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=86057
2023-02-21 13:20:16 - progress_bar.py[line:274] - INFO: epoch 001:  29138 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=29100, lr=4.08582e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86069
2023-02-21 13:20:27 - progress_bar.py[line:274] - INFO: epoch 001:  29148 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.91, wpb=109.7, bsz=40, num_updates=29110, lr=4.08546e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=86080
2023-02-21 13:20:38 - progress_bar.py[line:274] - INFO: epoch 001:  29158 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=29120, lr=4.08509e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86091
2023-02-21 13:20:50 - progress_bar.py[line:274] - INFO: epoch 001:  29168 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=111.4, bsz=40, num_updates=29130, lr=4.08473e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86102
2023-02-21 13:21:01 - progress_bar.py[line:274] - INFO: epoch 001:  29178 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111.3, bsz=40, num_updates=29140, lr=4.08437e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86114
2023-02-21 13:21:12 - progress_bar.py[line:274] - INFO: epoch 001:  29188 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.92, wpb=110.5, bsz=40, num_updates=29150, lr=4.08401e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86125
2023-02-21 13:21:23 - progress_bar.py[line:274] - INFO: epoch 001:  29198 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.92, wpb=109.7, bsz=40, num_updates=29160, lr=4.08365e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86135
2023-02-21 13:21:34 - progress_bar.py[line:274] - INFO: epoch 001:  29208 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=29170, lr=4.08328e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86146
2023-02-21 13:21:45 - progress_bar.py[line:274] - INFO: epoch 001:  29218 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=29180, lr=4.08292e-05, gnorm=0.044, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86158
2023-02-21 13:21:56 - progress_bar.py[line:274] - INFO: epoch 001:  29228 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=29190, lr=4.08256e-05, gnorm=0.048, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86169
2023-02-21 13:22:07 - progress_bar.py[line:274] - INFO: epoch 001:  29238 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=29200, lr=4.0822e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=86180
2023-02-21 13:22:18 - progress_bar.py[line:274] - INFO: epoch 001:  29248 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.6, bsz=40, num_updates=29210, lr=4.08184e-05, gnorm=0.045, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86191
2023-02-21 13:22:29 - progress_bar.py[line:274] - INFO: epoch 001:  29258 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=29220, lr=4.08148e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86202
2023-02-21 13:22:41 - progress_bar.py[line:274] - INFO: epoch 001:  29268 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.7, bsz=40, num_updates=29230, lr=4.08111e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86214
2023-02-21 13:22:52 - progress_bar.py[line:274] - INFO: epoch 001:  29278 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.88, wpb=111, bsz=40, num_updates=29240, lr=4.08075e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86225
2023-02-21 13:23:03 - progress_bar.py[line:274] - INFO: epoch 001:  29288 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=29250, lr=4.08039e-05, gnorm=0.049, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=86236
2023-02-21 13:23:15 - progress_bar.py[line:274] - INFO: epoch 001:  29298 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.2, ups=0.87, wpb=110.4, bsz=40, num_updates=29260, lr=4.08003e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86248
2023-02-21 13:23:26 - progress_bar.py[line:274] - INFO: epoch 001:  29308 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=110.7, bsz=40, num_updates=29270, lr=4.07967e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86259
2023-02-21 13:23:37 - progress_bar.py[line:274] - INFO: epoch 001:  29318 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112.2, bsz=40, num_updates=29280, lr=4.0793e-05, gnorm=0.042, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86270
2023-02-21 13:23:49 - progress_bar.py[line:274] - INFO: epoch 001:  29328 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.87, wpb=111.9, bsz=40, num_updates=29290, lr=4.07894e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86281
2023-02-21 13:24:00 - progress_bar.py[line:274] - INFO: epoch 001:  29338 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.91, wpb=109.7, bsz=40, num_updates=29300, lr=4.07858e-05, gnorm=0.103, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86293
2023-02-21 13:24:11 - progress_bar.py[line:274] - INFO: epoch 001:  29348 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=96.9, ups=0.87, wpb=111.8, bsz=40, num_updates=29310, lr=4.07822e-05, gnorm=0.036, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86304
2023-02-21 13:24:22 - progress_bar.py[line:274] - INFO: epoch 001:  29358 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.9, wpb=112.8, bsz=40, num_updates=29320, lr=4.07786e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86315
2023-02-21 13:24:34 - progress_bar.py[line:274] - INFO: epoch 001:  29368 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.88, wpb=111.2, bsz=40, num_updates=29330, lr=4.0775e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86326
2023-02-21 13:24:45 - progress_bar.py[line:274] - INFO: epoch 001:  29378 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=29340, lr=4.07713e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=86338
2023-02-21 13:24:56 - progress_bar.py[line:274] - INFO: epoch 001:  29388 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=29350, lr=4.07677e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86349
2023-02-21 13:25:07 - progress_bar.py[line:274] - INFO: epoch 001:  29398 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.6, bsz=40, num_updates=29360, lr=4.07641e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86360
2023-02-21 13:25:18 - progress_bar.py[line:274] - INFO: epoch 001:  29408 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.1, ups=0.93, wpb=110.9, bsz=40, num_updates=29370, lr=4.07605e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86370
2023-02-21 13:25:29 - progress_bar.py[line:274] - INFO: epoch 001:  29418 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=29380, lr=4.07569e-05, gnorm=0.066, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86382
2023-02-21 13:25:40 - progress_bar.py[line:274] - INFO: epoch 001:  29428 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.7, bsz=40, num_updates=29390, lr=4.07532e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86393
2023-02-21 13:25:51 - progress_bar.py[line:274] - INFO: epoch 001:  29438 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.6, ups=0.92, wpb=111.9, bsz=40, num_updates=29400, lr=4.07496e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=86404
2023-02-21 13:26:02 - progress_bar.py[line:274] - INFO: epoch 001:  29448 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.3, ups=0.87, wpb=110.5, bsz=40, num_updates=29410, lr=4.0746e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86415
2023-02-21 13:26:13 - progress_bar.py[line:274] - INFO: epoch 001:  29458 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.1, ups=0.91, wpb=112.8, bsz=40, num_updates=29420, lr=4.07424e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86426
2023-02-21 13:26:24 - progress_bar.py[line:274] - INFO: epoch 001:  29468 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=29430, lr=4.07388e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86437
2023-02-21 13:26:36 - progress_bar.py[line:274] - INFO: epoch 001:  29478 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=29440, lr=4.07352e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86448
2023-02-21 13:26:47 - progress_bar.py[line:274] - INFO: epoch 001:  29488 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=109.8, bsz=40, num_updates=29450, lr=4.07315e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=86460
2023-02-21 13:26:58 - progress_bar.py[line:274] - INFO: epoch 001:  29498 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.9, wpb=109.9, bsz=40, num_updates=29460, lr=4.07279e-05, gnorm=0.085, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86471
2023-02-21 13:27:09 - progress_bar.py[line:274] - INFO: epoch 001:  29508 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=112.3, bsz=40, num_updates=29470, lr=4.07243e-05, gnorm=0.069, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86482
2023-02-21 13:27:20 - progress_bar.py[line:274] - INFO: epoch 001:  29518 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.5, bsz=40, num_updates=29480, lr=4.07207e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86493
2023-02-21 13:27:32 - progress_bar.py[line:274] - INFO: epoch 001:  29528 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.91, wpb=109.1, bsz=40, num_updates=29490, lr=4.07171e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86504
2023-02-21 13:27:43 - progress_bar.py[line:274] - INFO: epoch 001:  29538 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=29500, lr=4.07134e-05, gnorm=0.09, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86516
2023-02-21 13:27:54 - progress_bar.py[line:274] - INFO: epoch 001:  29548 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.91, wpb=109.6, bsz=40, num_updates=29510, lr=4.07098e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86527
2023-02-21 13:28:05 - progress_bar.py[line:274] - INFO: epoch 001:  29558 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112.1, bsz=40, num_updates=29520, lr=4.07062e-05, gnorm=0.076, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86538
2023-02-21 13:28:16 - progress_bar.py[line:274] - INFO: epoch 001:  29568 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=112.2, bsz=40, num_updates=29530, lr=4.07026e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86549
2023-02-21 13:28:27 - progress_bar.py[line:274] - INFO: epoch 001:  29578 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=112, bsz=40, num_updates=29540, lr=4.0699e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86560
2023-02-21 13:28:39 - progress_bar.py[line:274] - INFO: epoch 001:  29588 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.87, wpb=112.2, bsz=40, num_updates=29550, lr=4.06954e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86571
2023-02-21 13:28:50 - progress_bar.py[line:274] - INFO: epoch 001:  29598 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.6, bsz=40, num_updates=29560, lr=4.06917e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86583
2023-02-21 13:29:01 - progress_bar.py[line:274] - INFO: epoch 001:  29608 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=110.9, bsz=40, num_updates=29570, lr=4.06881e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86594
2023-02-21 13:29:12 - progress_bar.py[line:274] - INFO: epoch 001:  29618 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.88, wpb=110, bsz=40, num_updates=29580, lr=4.06845e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86605
2023-02-21 13:29:23 - progress_bar.py[line:274] - INFO: epoch 001:  29628 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.2, bsz=40, num_updates=29590, lr=4.06809e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86616
2023-02-21 13:29:34 - progress_bar.py[line:274] - INFO: epoch 001:  29638 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.2, bsz=40, num_updates=29600, lr=4.06773e-05, gnorm=0.06, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86627
2023-02-21 13:29:46 - progress_bar.py[line:274] - INFO: epoch 001:  29648 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=29610, lr=4.06736e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86638
2023-02-21 13:29:57 - progress_bar.py[line:274] - INFO: epoch 001:  29658 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=111.6, bsz=40, num_updates=29620, lr=4.067e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86650
2023-02-21 13:30:08 - progress_bar.py[line:274] - INFO: epoch 001:  29668 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=112.2, bsz=40, num_updates=29630, lr=4.06664e-05, gnorm=0.089, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86661
2023-02-21 13:30:19 - progress_bar.py[line:274] - INFO: epoch 001:  29678 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=29640, lr=4.06628e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86672
2023-02-21 13:30:30 - progress_bar.py[line:274] - INFO: epoch 001:  29688 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=112.3, bsz=40, num_updates=29650, lr=4.06592e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86683
2023-02-21 13:30:42 - progress_bar.py[line:274] - INFO: epoch 001:  29698 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.7, ups=0.88, wpb=111, bsz=40, num_updates=29660, lr=4.06556e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86695
2023-02-21 13:30:52 - progress_bar.py[line:274] - INFO: epoch 001:  29708 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104.4, ups=0.94, wpb=111.7, bsz=40, num_updates=29670, lr=4.06519e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=86705
2023-02-21 13:31:04 - progress_bar.py[line:274] - INFO: epoch 001:  29718 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.91, wpb=109.1, bsz=40, num_updates=29680, lr=4.06483e-05, gnorm=0.076, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86716
2023-02-21 13:31:14 - progress_bar.py[line:274] - INFO: epoch 001:  29728 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.92, wpb=111.4, bsz=40, num_updates=29690, lr=4.06447e-05, gnorm=0.041, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86727
2023-02-21 13:31:26 - progress_bar.py[line:274] - INFO: epoch 001:  29738 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=111.6, bsz=40, num_updates=29700, lr=4.06411e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86738
2023-02-21 13:31:37 - progress_bar.py[line:274] - INFO: epoch 001:  29748 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.91, wpb=109.8, bsz=40, num_updates=29710, lr=4.06375e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86749
2023-02-21 13:31:48 - progress_bar.py[line:274] - INFO: epoch 001:  29758 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.8, bsz=40, num_updates=29720, lr=4.06338e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86761
2023-02-21 13:31:59 - progress_bar.py[line:274] - INFO: epoch 001:  29768 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=29730, lr=4.06302e-05, gnorm=0.045, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86772
2023-02-21 13:32:10 - progress_bar.py[line:274] - INFO: epoch 001:  29778 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=29740, lr=4.06266e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86783
2023-02-21 13:32:21 - progress_bar.py[line:274] - INFO: epoch 001:  29788 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.1, bsz=40, num_updates=29750, lr=4.0623e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86794
2023-02-21 13:32:32 - progress_bar.py[line:274] - INFO: epoch 001:  29798 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=112, bsz=40, num_updates=29760, lr=4.06194e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86805
2023-02-21 13:32:44 - progress_bar.py[line:274] - INFO: epoch 001:  29808 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=111.2, bsz=40, num_updates=29770, lr=4.06158e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86817
2023-02-21 13:32:56 - progress_bar.py[line:274] - INFO: epoch 001:  29818 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.5, ups=0.86, wpb=111.6, bsz=40, num_updates=29780, lr=4.06121e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=86828
2023-02-21 13:33:07 - progress_bar.py[line:274] - INFO: epoch 001:  29828 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=29790, lr=4.06085e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86840
2023-02-21 13:33:18 - progress_bar.py[line:274] - INFO: epoch 001:  29838 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=29800, lr=4.06049e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86851
2023-02-21 13:33:29 - progress_bar.py[line:274] - INFO: epoch 001:  29848 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105, ups=0.94, wpb=111.2, bsz=40, num_updates=29810, lr=4.06013e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86861
2023-02-21 13:33:40 - progress_bar.py[line:274] - INFO: epoch 001:  29858 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.2, bsz=40, num_updates=29820, lr=4.05977e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86873
2023-02-21 13:33:51 - progress_bar.py[line:274] - INFO: epoch 001:  29868 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=29830, lr=4.0594e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86884
2023-02-21 13:34:02 - progress_bar.py[line:274] - INFO: epoch 001:  29878 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=29840, lr=4.05904e-05, gnorm=0.052, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86895
2023-02-21 13:34:13 - progress_bar.py[line:274] - INFO: epoch 001:  29888 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=29850, lr=4.05868e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86906
2023-02-21 13:34:24 - progress_bar.py[line:274] - INFO: epoch 001:  29898 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=111.6, bsz=40, num_updates=29860, lr=4.05832e-05, gnorm=0.062, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86917
2023-02-21 13:34:35 - progress_bar.py[line:274] - INFO: epoch 001:  29908 / 142023 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=29870, lr=4.05796e-05, gnorm=0.039, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86928
2023-02-21 13:34:46 - progress_bar.py[line:274] - INFO: epoch 001:  29918 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=29880, lr=4.0576e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86939
2023-02-21 13:34:57 - progress_bar.py[line:274] - INFO: epoch 001:  29928 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=29890, lr=4.05723e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86950
2023-02-21 13:35:09 - progress_bar.py[line:274] - INFO: epoch 001:  29938 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=29900, lr=4.05687e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=86962
2023-02-21 13:35:20 - progress_bar.py[line:274] - INFO: epoch 001:  29948 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.88, wpb=109.7, bsz=40, num_updates=29910, lr=4.05651e-05, gnorm=0.08, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=86973
2023-02-21 13:35:31 - progress_bar.py[line:274] - INFO: epoch 001:  29958 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=29920, lr=4.05615e-05, gnorm=0.07, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86984
2023-02-21 13:35:42 - progress_bar.py[line:274] - INFO: epoch 001:  29968 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.4, ups=0.93, wpb=111.2, bsz=40, num_updates=29930, lr=4.05579e-05, gnorm=0.042, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86995
2023-02-21 13:35:53 - progress_bar.py[line:274] - INFO: epoch 001:  29978 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=29940, lr=4.05542e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87006
2023-02-21 13:36:04 - progress_bar.py[line:274] - INFO: epoch 001:  29988 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.88, wpb=112.4, bsz=40, num_updates=29950, lr=4.05506e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=87017
2023-02-21 13:36:16 - progress_bar.py[line:274] - INFO: epoch 001:  29998 / 142023 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=29960, lr=4.0547e-05, gnorm=0.048, clip=0, loss_scale=8192, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=87029
2023-02-21 13:36:27 - progress_bar.py[line:274] - INFO: epoch 001:  30008 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.89, wpb=111.7, bsz=40, num_updates=29970, lr=4.05434e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=87040
2023-02-21 13:36:38 - progress_bar.py[line:274] - INFO: epoch 001:  30018 / 142023 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.88, wpb=112.3, bsz=40, num_updates=29980, lr=4.05398e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=87051
2023-02-21 13:36:49 - progress_bar.py[line:274] - INFO: epoch 001:  30028 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.91, wpb=112.1, bsz=40, num_updates=29990, lr=4.05361e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=87062
2023-02-21 13:37:00 - progress_bar.py[line:274] - INFO: epoch 001:  30038 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=30000, lr=4.05325e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=87073
2023-02-21 13:37:00 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-02-21 13:37:01 - train.py[line:549] - INFO: 0 / 6234
2023-02-21 13:37:01 - train.py[line:551] - INFO: load:0.95 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-02-21 13:39:04 - train.py[line:549] - INFO: 200 / 6234
2023-02-21 13:39:04 - train.py[line:551] - INFO: load:0.97 valid_run:122.20 task_valid:119.13 collect_output:2.05
2023-02-21 13:41:04 - train.py[line:549] - INFO: 400 / 6234
2023-02-21 13:41:04 - train.py[line:551] - INFO: load:1.00 valid_run:242.39 task_valid:235.29 collect_output:5.05
2023-02-21 13:43:06 - train.py[line:549] - INFO: 600 / 6234
2023-02-21 13:43:06 - train.py[line:551] - INFO: load:1.02 valid_run:364.73 task_valid:352.19 collect_output:9.46
2023-02-21 13:45:09 - train.py[line:549] - INFO: 800 / 6234
2023-02-21 13:45:09 - train.py[line:551] - INFO: load:1.04 valid_run:486.86 task_valid:466.30 collect_output:16.47
2023-02-21 13:47:10 - train.py[line:549] - INFO: 1000 / 6234
2023-02-21 13:47:10 - train.py[line:551] - INFO: load:1.07 valid_run:607.74 task_valid:583.96 collect_output:18.66
2023-02-21 13:49:13 - train.py[line:549] - INFO: 1200 / 6234
2023-02-21 13:49:13 - train.py[line:551] - INFO: load:1.09 valid_run:730.77 task_valid:702.81 collect_output:21.83
2023-02-21 13:51:16 - train.py[line:549] - INFO: 1400 / 6234
2023-02-21 13:51:16 - train.py[line:551] - INFO: load:1.11 valid_run:853.97 task_valid:821.07 collect_output:25.74
2023-02-21 13:53:18 - train.py[line:549] - INFO: 1600 / 6234
2023-02-21 13:53:18 - train.py[line:551] - INFO: load:1.14 valid_run:976.09 task_valid:938.06 collect_output:29.88
2023-02-21 13:55:22 - train.py[line:549] - INFO: 1800 / 6234
2023-02-21 13:55:22 - train.py[line:551] - INFO: load:1.16 valid_run:1100.14 task_valid:1055.64 collect_output:35.34
2023-02-21 13:57:24 - train.py[line:549] - INFO: 2000 / 6234
2023-02-21 13:57:24 - train.py[line:551] - INFO: load:1.18 valid_run:1221.95 task_valid:1168.59 collect_output:43.21
2023-02-21 13:59:25 - train.py[line:549] - INFO: 2200 / 6234
2023-02-21 13:59:25 - train.py[line:551] - INFO: load:1.21 valid_run:1342.43 task_valid:1284.51 collect_output:46.76
2023-02-21 14:01:26 - train.py[line:549] - INFO: 2400 / 6234
2023-02-21 14:01:26 - train.py[line:551] - INFO: load:1.23 valid_run:1464.28 task_valid:1401.82 collect_output:50.30
2023-02-21 14:03:26 - train.py[line:549] - INFO: 2600 / 6234
2023-02-21 14:03:26 - train.py[line:551] - INFO: load:1.26 valid_run:1583.48 task_valid:1515.97 collect_output:54.34
2023-02-21 14:05:27 - train.py[line:549] - INFO: 2800 / 6234
2023-02-21 14:05:27 - train.py[line:551] - INFO: load:1.28 valid_run:1705.02 task_valid:1634.31 collect_output:56.48
2023-02-21 14:07:28 - train.py[line:549] - INFO: 3000 / 6234
2023-02-21 14:07:28 - train.py[line:551] - INFO: load:1.30 valid_run:1826.00 task_valid:1750.52 collect_output:60.25
2023-02-21 14:09:30 - train.py[line:549] - INFO: 3200 / 6234
2023-02-21 14:09:30 - train.py[line:551] - INFO: load:1.33 valid_run:1947.16 task_valid:1864.59 collect_output:66.31
2023-02-21 14:11:31 - train.py[line:549] - INFO: 3400 / 6234
2023-02-21 14:11:31 - train.py[line:551] - INFO: load:1.35 valid_run:2068.67 task_valid:1980.91 collect_output:70.49
2023-02-21 14:13:32 - train.py[line:549] - INFO: 3600 / 6234
2023-02-21 14:13:32 - train.py[line:551] - INFO: load:1.38 valid_run:2189.43 task_valid:2098.96 collect_output:72.17
2023-02-21 14:15:33 - train.py[line:549] - INFO: 3800 / 6234
2023-02-21 14:15:33 - train.py[line:551] - INFO: load:1.40 valid_run:2310.78 task_valid:2216.13 collect_output:75.34
2023-02-21 14:17:34 - train.py[line:549] - INFO: 4000 / 6234
2023-02-21 14:17:34 - train.py[line:551] - INFO: load:1.42 valid_run:2431.42 task_valid:2332.94 collect_output:78.16
2023-02-21 14:19:36 - train.py[line:549] - INFO: 4200 / 6234
2023-02-21 14:19:36 - train.py[line:551] - INFO: load:1.45 valid_run:2553.15 task_valid:2449.72 collect_output:82.13
2023-02-21 14:21:38 - train.py[line:549] - INFO: 4400 / 6234
2023-02-21 14:21:38 - train.py[line:551] - INFO: load:1.47 valid_run:2675.46 task_valid:2569.04 collect_output:84.11
2023-02-21 14:23:39 - train.py[line:549] - INFO: 4600 / 6234
2023-02-21 14:23:39 - train.py[line:551] - INFO: load:1.49 valid_run:2795.89 task_valid:2683.48 collect_output:89.10
2023-02-21 14:25:39 - train.py[line:549] - INFO: 4800 / 6234
2023-02-21 14:25:39 - train.py[line:551] - INFO: load:1.52 valid_run:2916.23 task_valid:2800.23 collect_output:91.65
2023-02-21 14:27:41 - train.py[line:549] - INFO: 5000 / 6234
2023-02-21 14:27:41 - train.py[line:551] - INFO: load:1.54 valid_run:3038.04 task_valid:2916.66 collect_output:96.01
2023-02-21 14:29:44 - train.py[line:549] - INFO: 5200 / 6234
2023-02-21 14:29:44 - train.py[line:551] - INFO: load:1.56 valid_run:3161.14 task_valid:3032.91 collect_output:101.86
2023-02-21 14:31:44 - train.py[line:549] - INFO: 5400 / 6234
2023-02-21 14:31:44 - train.py[line:551] - INFO: load:1.59 valid_run:3280.95 task_valid:3147.25 collect_output:106.34
2023-02-21 14:33:46 - train.py[line:549] - INFO: 5600 / 6234
2023-02-21 14:33:46 - train.py[line:551] - INFO: load:1.61 valid_run:3403.09 task_valid:3266.99 collect_output:107.75
2023-02-21 14:35:48 - train.py[line:549] - INFO: 5800 / 6234
2023-02-21 14:35:48 - train.py[line:551] - INFO: load:1.64 valid_run:3525.14 task_valid:3382.97 collect_output:112.80
2023-02-21 14:37:50 - train.py[line:549] - INFO: 6000 / 6234
2023-02-21 14:37:50 - train.py[line:551] - INFO: load:1.66 valid_run:3647.13 task_valid:3501.56 collect_output:115.22
2023-02-21 14:39:52 - train.py[line:549] - INFO: 6200 / 6234
2023-02-21 14:39:52 - train.py[line:551] - INFO: load:1.68 valid_run:3768.40 task_valid:3620.15 collect_output:116.90

====================================================================================================
SGG eval:     R @ 50: 0.5965;     R @ 100: 0.6216;     R @ 500: 0.6467;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3591;    mR @ 100: 0.3857;    mR @ 500: 0.4207;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.3750) (hanging from:0.3548) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.9118) (says:0.0000) (sitting on:0.6842) (standing on:0.3977) (using:0.5500) (walking in:0.0000) (walking on:0.6757) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5965;     R @ 100: 0.6216;     R @ 500: 0.6467;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3591;    mR @ 100: 0.3857;    mR @ 500: 0.4207;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.6875) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.3750) (hanging from:0.3548) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.9118) (says:0.0000) (sitting on:0.6842) (standing on:0.3977) (using:0.5500) (walking in:0.0000) (walking on:0.6757) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================

2023-02-21 14:40:22 - train.py[line:487] - INFO: 0.6216291316526611
2023-02-21 14:40:22 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-02-21 14:40:23 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.217 | loss_v1 0 | loss_v2 0 | nll_loss 0.046 | ntokens 71.953 | nsentences 24 | sample_size 71.953 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.621629 | ppl 1.03 | vqa_score 0.2917 | wps 118 | wpb 72 | bsz 24 | num_updates 30000 | best_R@100 0.693596
2023-02-21 14:40:23 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 30000 updates
2023-02-21 14:40:23 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_30000.pt
2023-02-21 14:40:29 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_30000.pt
2023-02-21 14:40:32 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_same_step_optNew_caption_trained_visual_DS_contrastive-k100alpha1.0_/1_B20_A1_E1_0.027_5e-5_480/checkpoint_1_30000.pt (epoch 1 @ 30000 updates, score 0.6216291316526611) (writing took 9.091864226385951 seconds)
2023-02-21 14:40:43 - progress_bar.py[line:274] - INFO: epoch 001:  30048 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=0.3, ups=0, wpb=111.8, bsz=40, num_updates=30010, lr=4.05289e-05, gnorm=0.078, clip=0, loss_scale=16384, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=90896
2023-02-21 14:40:55 - progress_bar.py[line:274] - INFO: epoch 001:  30058 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=111.1, bsz=40, num_updates=30020, lr=4.05253e-05, gnorm=0.058, clip=0, loss_scale=16384, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90907
2023-02-21 14:41:05 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8192.0
2023-02-21 14:41:07 - progress_bar.py[line:274] - INFO: epoch 001:  30069 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.7, ups=0.82, wpb=109.9, bsz=40, num_updates=30030, lr=4.05217e-05, gnorm=0.049, clip=0, loss_scale=8192, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=90920
2023-02-21 14:41:18 - progress_bar.py[line:274] - INFO: epoch 001:  30079 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=110.9, bsz=40, num_updates=30040, lr=4.05181e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90931
2023-02-21 14:41:29 - progress_bar.py[line:274] - INFO: epoch 001:  30089 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.92, wpb=111.1, bsz=40, num_updates=30050, lr=4.05144e-05, gnorm=0.045, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90942
2023-02-21 14:41:40 - progress_bar.py[line:274] - INFO: epoch 001:  30099 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.8, bsz=40, num_updates=30060, lr=4.05108e-05, gnorm=0.075, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=90953
2023-02-21 14:41:52 - progress_bar.py[line:274] - INFO: epoch 001:  30109 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=30070, lr=4.05072e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90964
2023-02-21 14:42:03 - progress_bar.py[line:274] - INFO: epoch 001:  30119 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=30080, lr=4.05036e-05, gnorm=0.081, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=90976
2023-02-21 14:42:14 - progress_bar.py[line:274] - INFO: epoch 001:  30129 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.92, wpb=110.5, bsz=40, num_updates=30090, lr=4.05e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=90987
2023-02-21 14:42:25 - progress_bar.py[line:274] - INFO: epoch 001:  30139 / 142023 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.8, ups=0.89, wpb=109.4, bsz=40, num_updates=30100, lr=4.04963e-05, gnorm=0.072, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=90998
2023-02-21 14:42:36 - progress_bar.py[line:274] - INFO: epoch 001:  30149 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=30110, lr=4.04927e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91009
2023-02-21 14:42:48 - progress_bar.py[line:274] - INFO: epoch 001:  30159 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=111.1, bsz=40, num_updates=30120, lr=4.04891e-05, gnorm=0.047, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=91020
2023-02-21 14:42:59 - progress_bar.py[line:274] - INFO: epoch 001:  30169 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=30130, lr=4.04855e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91031
2023-02-21 14:43:10 - progress_bar.py[line:274] - INFO: epoch 001:  30179 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.9, bsz=40, num_updates=30140, lr=4.04819e-05, gnorm=0.039, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91043
2023-02-21 14:43:21 - progress_bar.py[line:274] - INFO: epoch 001:  30189 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=30150, lr=4.04783e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91054
2023-02-21 14:43:32 - progress_bar.py[line:274] - INFO: epoch 001:  30199 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.91, wpb=111.9, bsz=40, num_updates=30160, lr=4.04746e-05, gnorm=0.056, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91065
2023-02-21 14:43:43 - progress_bar.py[line:274] - INFO: epoch 001:  30209 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.91, wpb=110.5, bsz=40, num_updates=30170, lr=4.0471e-05, gnorm=0.071, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91076
2023-02-21 14:43:54 - progress_bar.py[line:274] - INFO: epoch 001:  30219 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112.3, bsz=40, num_updates=30180, lr=4.04674e-05, gnorm=0.067, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91087
2023-02-21 14:44:05 - progress_bar.py[line:274] - INFO: epoch 001:  30229 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=111.2, bsz=40, num_updates=30190, lr=4.04638e-05, gnorm=0.095, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91098
2023-02-21 14:44:16 - progress_bar.py[line:274] - INFO: epoch 001:  30239 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.9, wpb=111.3, bsz=40, num_updates=30200, lr=4.04602e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=91109
2023-02-21 14:44:27 - progress_bar.py[line:274] - INFO: epoch 001:  30249 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=30210, lr=4.04565e-05, gnorm=0.047, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=91120
2023-02-21 14:44:38 - progress_bar.py[line:274] - INFO: epoch 001:  30259 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.91, wpb=109.8, bsz=40, num_updates=30220, lr=4.04529e-05, gnorm=0.069, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=91131
2023-02-21 14:44:49 - progress_bar.py[line:274] - INFO: epoch 001:  30269 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=30230, lr=4.04493e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91142
2023-02-21 14:45:01 - progress_bar.py[line:274] - INFO: epoch 001:  30279 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.2, bsz=40, num_updates=30240, lr=4.04457e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91153
2023-02-21 14:45:12 - progress_bar.py[line:274] - INFO: epoch 001:  30289 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=112.6, bsz=40, num_updates=30250, lr=4.04421e-05, gnorm=0.039, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91165
2023-02-21 14:45:23 - progress_bar.py[line:274] - INFO: epoch 001:  30299 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110, bsz=40, num_updates=30260, lr=4.04385e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=91176
2023-02-21 14:45:33 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 14:45:35 - progress_bar.py[line:274] - INFO: epoch 001:  30310 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.8, ups=0.82, wpb=111.3, bsz=40, num_updates=30270, lr=4.04348e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=91188
2023-02-21 14:45:47 - progress_bar.py[line:274] - INFO: epoch 001:  30320 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.5, ups=0.87, wpb=110.9, bsz=40, num_updates=30280, lr=4.04312e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=91200
2023-02-21 14:45:58 - progress_bar.py[line:274] - INFO: epoch 001:  30330 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.89, wpb=111.8, bsz=40, num_updates=30290, lr=4.04276e-05, gnorm=0.048, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91211
2023-02-21 14:46:10 - progress_bar.py[line:274] - INFO: epoch 001:  30340 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.87, wpb=111.8, bsz=40, num_updates=30300, lr=4.0424e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=91222
2023-02-21 14:46:21 - progress_bar.py[line:274] - INFO: epoch 001:  30350 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=113.7, nsentences=40, sample_size=113.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.89, wpb=113.7, bsz=40, num_updates=30310, lr=4.04204e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91234
2023-02-21 14:46:32 - progress_bar.py[line:274] - INFO: epoch 001:  30360 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.88, wpb=112.4, bsz=40, num_updates=30320, lr=4.04167e-05, gnorm=0.052, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=91245
2023-02-21 14:46:43 - progress_bar.py[line:274] - INFO: epoch 001:  30370 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.035, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.02, wps=101.1, ups=0.9, wpb=112.3, bsz=40, num_updates=30330, lr=4.04131e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91256
2023-02-21 14:46:54 - progress_bar.py[line:274] - INFO: epoch 001:  30380 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=30340, lr=4.04095e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91267
2023-02-21 14:47:06 - progress_bar.py[line:274] - INFO: epoch 001:  30390 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=30350, lr=4.04059e-05, gnorm=0.065, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91278
2023-02-21 14:47:16 - progress_bar.py[line:274] - INFO: epoch 001:  30400 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.92, wpb=110.8, bsz=40, num_updates=30360, lr=4.04023e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91289
2023-02-21 14:47:28 - progress_bar.py[line:274] - INFO: epoch 001:  30410 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.91, wpb=109.7, bsz=40, num_updates=30370, lr=4.03987e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91300
2023-02-21 14:47:39 - progress_bar.py[line:274] - INFO: epoch 001:  30420 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=30380, lr=4.0395e-05, gnorm=0.047, clip=0, loss_scale=4096, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=91312
2023-02-21 14:47:50 - progress_bar.py[line:274] - INFO: epoch 001:  30430 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=110.4, bsz=40, num_updates=30390, lr=4.03914e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91323
2023-02-21 14:48:01 - progress_bar.py[line:274] - INFO: epoch 001:  30440 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=30400, lr=4.03878e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91334
2023-02-21 14:48:13 - progress_bar.py[line:274] - INFO: epoch 001:  30450 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.87, wpb=110.6, bsz=40, num_updates=30410, lr=4.03842e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91345
2023-02-21 14:48:24 - progress_bar.py[line:274] - INFO: epoch 001:  30460 / 142023 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.4, bsz=40, num_updates=30420, lr=4.03806e-05, gnorm=0.073, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=91357
2023-02-21 14:48:35 - progress_bar.py[line:274] - INFO: epoch 001:  30470 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.91, wpb=111.9, bsz=40, num_updates=30430, lr=4.03769e-05, gnorm=0.038, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=91368
2023-02-21 14:48:46 - progress_bar.py[line:274] - INFO: epoch 001:  30480 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=30440, lr=4.03733e-05, gnorm=0.043, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91379
2023-02-21 14:48:57 - progress_bar.py[line:274] - INFO: epoch 001:  30490 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.3, ups=0.88, wpb=110.1, bsz=40, num_updates=30450, lr=4.03697e-05, gnorm=0.064, clip=0, loss_scale=4096, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=91390
2023-02-21 14:49:09 - progress_bar.py[line:274] - INFO: epoch 001:  30500 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.87, wpb=112.7, bsz=40, num_updates=30460, lr=4.03661e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91402
2023-02-21 14:49:20 - progress_bar.py[line:274] - INFO: epoch 001:  30510 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.9, ups=0.86, wpb=111.8, bsz=40, num_updates=30470, lr=4.03625e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=91413
2023-02-21 14:49:32 - progress_bar.py[line:274] - INFO: epoch 001:  30520 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.9, wpb=108.9, bsz=40, num_updates=30480, lr=4.03589e-05, gnorm=0.048, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91424
2023-02-21 14:49:43 - progress_bar.py[line:274] - INFO: epoch 001:  30530 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.8, bsz=40, num_updates=30490, lr=4.03552e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91436
2023-02-21 14:49:54 - progress_bar.py[line:274] - INFO: epoch 001:  30540 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.2, ups=0.93, wpb=110.2, bsz=40, num_updates=30500, lr=4.03516e-05, gnorm=0.089, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91447
2023-02-21 14:50:05 - progress_bar.py[line:274] - INFO: epoch 001:  30550 / 142023 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=104, ups=0.93, wpb=111.9, bsz=40, num_updates=30510, lr=4.0348e-05, gnorm=0.048, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91457
2023-02-21 14:50:15 - progress_bar.py[line:274] - INFO: epoch 001:  30560 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103, ups=0.92, wpb=112.4, bsz=40, num_updates=30520, lr=4.03444e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91468
2023-02-21 14:50:27 - progress_bar.py[line:274] - INFO: epoch 001:  30570 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=30530, lr=4.03408e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91479
2023-02-21 14:50:38 - progress_bar.py[line:274] - INFO: epoch 001:  30580 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=30540, lr=4.03371e-05, gnorm=0.048, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=91490
2023-02-21 14:50:49 - progress_bar.py[line:274] - INFO: epoch 001:  30590 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.3, bsz=40, num_updates=30550, lr=4.03335e-05, gnorm=0.048, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91501
2023-02-21 14:51:00 - progress_bar.py[line:274] - INFO: epoch 001:  30600 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.7, ups=0.87, wpb=110.9, bsz=40, num_updates=30560, lr=4.03299e-05, gnorm=0.077, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91513
2023-02-21 14:51:11 - progress_bar.py[line:274] - INFO: epoch 001:  30610 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=30570, lr=4.03263e-05, gnorm=0.044, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=91524
2023-02-21 14:51:23 - progress_bar.py[line:274] - INFO: epoch 001:  30620 / 142023 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.8, ups=0.88, wpb=110.9, bsz=40, num_updates=30580, lr=4.03227e-05, gnorm=0.093, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91536
2023-02-21 14:51:34 - progress_bar.py[line:274] - INFO: epoch 001:  30630 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.92, wpb=110.5, bsz=40, num_updates=30590, lr=4.03191e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91546
2023-02-21 14:51:44 - progress_bar.py[line:274] - INFO: epoch 001:  30640 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.9, ups=0.93, wpb=112, bsz=40, num_updates=30600, lr=4.03154e-05, gnorm=0.056, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91557
2023-02-21 14:51:56 - progress_bar.py[line:274] - INFO: epoch 001:  30650 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.5, ups=0.88, wpb=111, bsz=40, num_updates=30610, lr=4.03118e-05, gnorm=0.074, clip=0, loss_scale=4096, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=91569
2023-02-21 14:52:07 - progress_bar.py[line:274] - INFO: epoch 001:  30660 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=110.8, bsz=40, num_updates=30620, lr=4.03082e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91580
2023-02-21 14:52:18 - progress_bar.py[line:274] - INFO: epoch 001:  30670 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.88, wpb=111.4, bsz=40, num_updates=30630, lr=4.03046e-05, gnorm=0.08, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91591
2023-02-21 14:52:30 - progress_bar.py[line:274] - INFO: epoch 001:  30680 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.7, ups=0.87, wpb=110.6, bsz=40, num_updates=30640, lr=4.0301e-05, gnorm=0.097, clip=0, loss_scale=4096, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=91603
2023-02-21 14:52:41 - progress_bar.py[line:274] - INFO: epoch 001:  30690 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.9, bsz=40, num_updates=30650, lr=4.02973e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91614
2023-02-21 14:52:52 - progress_bar.py[line:274] - INFO: epoch 001:  30700 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=110.6, bsz=40, num_updates=30660, lr=4.02937e-05, gnorm=0.055, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91625
2023-02-21 14:53:03 - progress_bar.py[line:274] - INFO: epoch 001:  30710 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=103.7, ups=0.92, wpb=112.9, bsz=40, num_updates=30670, lr=4.02901e-05, gnorm=0.068, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91636
2023-02-21 14:53:14 - progress_bar.py[line:274] - INFO: epoch 001:  30720 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=30680, lr=4.02865e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=91647
2023-02-21 14:53:25 - progress_bar.py[line:274] - INFO: epoch 001:  30730 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=111.8, bsz=40, num_updates=30690, lr=4.02829e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91658
2023-02-21 14:53:36 - progress_bar.py[line:274] - INFO: epoch 001:  30740 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.9, ups=0.91, wpb=109.2, bsz=40, num_updates=30700, lr=4.02793e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91669
2023-02-21 14:53:47 - progress_bar.py[line:274] - INFO: epoch 001:  30750 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.9, wpb=111.9, bsz=40, num_updates=30710, lr=4.02756e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91680
2023-02-21 14:53:59 - progress_bar.py[line:274] - INFO: epoch 001:  30760 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.7, ups=0.9, wpb=110.3, bsz=40, num_updates=30720, lr=4.0272e-05, gnorm=0.096, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91691
2023-02-21 14:54:09 - progress_bar.py[line:274] - INFO: epoch 001:  30770 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.92, wpb=110.5, bsz=40, num_updates=30730, lr=4.02684e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91702
2023-02-21 14:54:20 - progress_bar.py[line:274] - INFO: epoch 001:  30780 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.8, ups=0.91, wpb=111.3, bsz=40, num_updates=30740, lr=4.02648e-05, gnorm=0.053, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91713
2023-02-21 14:54:32 - progress_bar.py[line:274] - INFO: epoch 001:  30790 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.89, wpb=112.1, bsz=40, num_updates=30750, lr=4.02612e-05, gnorm=0.051, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91724
2023-02-21 14:54:42 - progress_bar.py[line:274] - INFO: epoch 001:  30800 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.92, wpb=111.5, bsz=40, num_updates=30760, lr=4.02575e-05, gnorm=0.101, clip=0, loss_scale=4096, train_wall=11, gb_free=11, ema_decay=0.9999, wall=91735
2023-02-21 14:54:54 - progress_bar.py[line:274] - INFO: epoch 001:  30810 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.4, ups=0.88, wpb=109.6, bsz=40, num_updates=30770, lr=4.02539e-05, gnorm=0.06, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91747
2023-02-21 14:55:05 - progress_bar.py[line:274] - INFO: epoch 001:  30820 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.7, ups=0.87, wpb=109.8, bsz=40, num_updates=30780, lr=4.02503e-05, gnorm=0.084, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91758
2023-02-21 14:55:16 - progress_bar.py[line:274] - INFO: epoch 001:  30830 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=30790, lr=4.02467e-05, gnorm=0.104, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91769
2023-02-21 14:55:28 - progress_bar.py[line:274] - INFO: epoch 001:  30840 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.7, ups=0.86, wpb=111.5, bsz=40, num_updates=30800, lr=4.02431e-05, gnorm=0.082, clip=0, loss_scale=8192, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=91781
2023-02-21 14:55:39 - progress_bar.py[line:274] - INFO: epoch 001:  30850 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.5, ups=0.9, wpb=112.2, bsz=40, num_updates=30810, lr=4.02395e-05, gnorm=0.083, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91792
2023-02-21 14:55:50 - progress_bar.py[line:274] - INFO: epoch 001:  30860 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.3, ups=0.9, wpb=109, bsz=40, num_updates=30820, lr=4.02358e-05, gnorm=0.095, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91803
2023-02-21 14:56:01 - progress_bar.py[line:274] - INFO: epoch 001:  30870 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.5, ups=0.89, wpb=112.4, bsz=40, num_updates=30830, lr=4.02322e-05, gnorm=0.079, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91814
2023-02-21 14:56:13 - progress_bar.py[line:274] - INFO: epoch 001:  30880 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=30840, lr=4.02286e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91825
2023-02-21 14:56:24 - progress_bar.py[line:274] - INFO: epoch 001:  30890 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111.4, bsz=40, num_updates=30850, lr=4.0225e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=91837
2023-02-21 14:56:35 - progress_bar.py[line:274] - INFO: epoch 001:  30900 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=30860, lr=4.02214e-05, gnorm=0.078, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91848
2023-02-21 14:56:46 - progress_bar.py[line:274] - INFO: epoch 001:  30910 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.92, wpb=109.2, bsz=40, num_updates=30870, lr=4.02177e-05, gnorm=0.051, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=91859
2023-02-21 14:56:57 - progress_bar.py[line:274] - INFO: epoch 001:  30920 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=30880, lr=4.02141e-05, gnorm=0.065, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91870
2023-02-21 14:57:09 - progress_bar.py[line:274] - INFO: epoch 001:  30930 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.4, ups=0.88, wpb=110.6, bsz=40, num_updates=30890, lr=4.02105e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91881
2023-02-21 14:57:20 - progress_bar.py[line:274] - INFO: epoch 001:  30940 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.2, bsz=40, num_updates=30900, lr=4.02069e-05, gnorm=0.057, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91893
2023-02-21 14:57:31 - progress_bar.py[line:274] - INFO: epoch 001:  30950 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=112.1, bsz=40, num_updates=30910, lr=4.02033e-05, gnorm=0.074, clip=0, loss_scale=8192, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=91904
2023-02-21 14:57:42 - progress_bar.py[line:274] - INFO: epoch 001:  30960 / 142023 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=109.7, bsz=40, num_updates=30920, lr=4.01997e-05, gnorm=0.055, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91915
2023-02-21 14:57:54 - progress_bar.py[line:274] - INFO: epoch 001:  30970 / 142023 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.88, wpb=112.6, bsz=40, num_updates=30930, lr=4.0196e-05, gnorm=0.068, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91927
2023-02-21 14:58:05 - progress_bar.py[line:274] - INFO: epoch 001:  30980 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=111, bsz=40, num_updates=30940, lr=4.01924e-05, gnorm=0.064, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91938
2023-02-21 14:58:17 - progress_bar.py[line:274] - INFO: epoch 001:  30990 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.6, bsz=40, num_updates=30950, lr=4.01888e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=91949
2023-02-21 14:58:28 - progress_bar.py[line:274] - INFO: epoch 001:  31000 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.04, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.85, wpb=112.4, bsz=40, num_updates=30960, lr=4.01852e-05, gnorm=0.046, clip=0, loss_scale=8192, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=91961
2023-02-21 14:58:39 - progress_bar.py[line:274] - INFO: epoch 001:  31010 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.92, wpb=110, bsz=40, num_updates=30970, lr=4.01816e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=91972
2023-02-21 14:58:51 - progress_bar.py[line:274] - INFO: epoch 001:  31020 / 142023 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.1, ups=0.87, wpb=110.8, bsz=40, num_updates=30980, lr=4.01779e-05, gnorm=0.042, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=91983
2023-02-21 14:59:02 - progress_bar.py[line:274] - INFO: epoch 001:  31030 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.1, ups=0.9, wpb=111.9, bsz=40, num_updates=30990, lr=4.01743e-05, gnorm=0.066, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=91995
2023-02-21 14:59:13 - progress_bar.py[line:274] - INFO: epoch 001:  31040 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.038, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=111.2, bsz=40, num_updates=31000, lr=4.01707e-05, gnorm=0.049, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92006
2023-02-21 14:59:24 - progress_bar.py[line:274] - INFO: epoch 001:  31050 / 142023 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.9, ups=0.9, wpb=110.9, bsz=40, num_updates=31010, lr=4.01671e-05, gnorm=0.046, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92017
2023-02-21 14:59:35 - progress_bar.py[line:274] - INFO: epoch 001:  31060 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.91, wpb=113.1, bsz=40, num_updates=31020, lr=4.01635e-05, gnorm=0.059, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92028
2023-02-21 14:59:47 - progress_bar.py[line:274] - INFO: epoch 001:  31070 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.87, wpb=111.5, bsz=40, num_updates=31030, lr=4.01599e-05, gnorm=0.058, clip=0, loss_scale=8192, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=92040
2023-02-21 14:59:58 - progress_bar.py[line:274] - INFO: epoch 001:  31080 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.89, wpb=112.5, bsz=40, num_updates=31040, lr=4.01562e-05, gnorm=0.073, clip=0, loss_scale=8192, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=92051
2023-02-21 15:00:09 - progress_bar.py[line:274] - INFO: epoch 001:  31090 / 142023 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.037, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=31050, lr=4.01526e-05, gnorm=0.061, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92062
2023-02-21 15:00:21 - progress_bar.py[line:274] - INFO: epoch 001:  31100 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.6, ups=0.88, wpb=111.8, bsz=40, num_updates=31060, lr=4.0149e-05, gnorm=0.054, clip=0, loss_scale=8192, train_wall=11, gb_free=11, ema_decay=0.9999, wall=92074
2023-02-21 15:00:32 - progress_bar.py[line:274] - INFO: epoch 001:  31110 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=31070, lr=4.01454e-05, gnorm=0.05, clip=0, loss_scale=8192, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92085
2023-02-21 15:00:43 - progress_bar.py[line:274] - INFO: epoch 001:  31120 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.9, ups=0.87, wpb=111.6, bsz=40, num_updates=31080, lr=4.01418e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92096
2023-02-21 15:00:54 - progress_bar.py[line:274] - INFO: epoch 001:  31130 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.9, wpb=110.3, bsz=40, num_updates=31090, lr=4.01381e-05, gnorm=0.053, clip=0, loss_scale=8192, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92107
2023-02-21 15:00:59 - trainer.py[line:1007] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2023-02-21 15:01:06 - progress_bar.py[line:274] - INFO: epoch 001:  31141 / 142023 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.041, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.6, ups=0.85, wpb=110.5, bsz=40, num_updates=31100, lr=4.01345e-05, gnorm=0.05, clip=0, loss_scale=4096, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=92119
2023-02-21 15:01:17 - progress_bar.py[line:274] - INFO: epoch 001:  31151 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.91, wpb=111.5, bsz=40, num_updates=31110, lr=4.01309e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92130
2023-02-21 15:01:28 - progress_bar.py[line:274] - INFO: epoch 001:  31161 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.3, ups=0.9, wpb=112.2, bsz=40, num_updates=31120, lr=4.01273e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92141
2023-02-21 15:01:39 - progress_bar.py[line:274] - INFO: epoch 001:  31171 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=31130, lr=4.01237e-05, gnorm=0.062, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92152
2023-02-21 15:01:51 - progress_bar.py[line:274] - INFO: epoch 001:  31181 / 142023 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=31140, lr=4.01201e-05, gnorm=0.067, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92163
2023-02-21 15:02:02 - progress_bar.py[line:274] - INFO: epoch 001:  31191 / 142023 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.1, ups=0.89, wpb=111.9, bsz=40, num_updates=31150, lr=4.01164e-05, gnorm=0.071, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92175
2023-02-21 15:02:13 - progress_bar.py[line:274] - INFO: epoch 001:  31201 / 142023 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.7, ups=0.87, wpb=113.2, bsz=40, num_updates=31160, lr=4.01128e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92186
2023-02-21 15:02:24 - progress_bar.py[line:274] - INFO: epoch 001:  31211 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.4, ups=0.9, wpb=111, bsz=40, num_updates=31170, lr=4.01092e-05, gnorm=0.07, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92197
2023-02-21 15:02:35 - progress_bar.py[line:274] - INFO: epoch 001:  31221 / 142023 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=31180, lr=4.01056e-05, gnorm=0.058, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=92208
2023-02-21 15:02:46 - progress_bar.py[line:274] - INFO: epoch 001:  31231 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=110.3, bsz=40, num_updates=31190, lr=4.0102e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92219
2023-02-21 15:02:58 - progress_bar.py[line:274] - INFO: epoch 001:  31241 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.8, bsz=40, num_updates=31200, lr=4.00983e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92231
2023-02-21 15:03:09 - progress_bar.py[line:274] - INFO: epoch 001:  31251 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=31210, lr=4.00947e-05, gnorm=0.059, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92242
2023-02-21 15:03:20 - progress_bar.py[line:274] - INFO: epoch 001:  31261 / 142023 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=31220, lr=4.00911e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92253
2023-02-21 15:03:31 - progress_bar.py[line:274] - INFO: epoch 001:  31271 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.036, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.6, bsz=40, num_updates=31230, lr=4.00875e-05, gnorm=0.042, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92264
2023-02-21 15:03:42 - progress_bar.py[line:274] - INFO: epoch 001:  31281 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.039, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=31240, lr=4.00839e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92275
2023-02-21 15:03:54 - progress_bar.py[line:274] - INFO: epoch 001:  31291 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.89, wpb=112, bsz=40, num_updates=31250, lr=4.00803e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92286
2023-02-21 15:04:04 - progress_bar.py[line:274] - INFO: epoch 001:  31301 / 142023 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.4, ups=0.93, wpb=110.1, bsz=40, num_updates=31260, lr=4.00766e-05, gnorm=0.057, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92297
2023-02-21 15:04:16 - progress_bar.py[line:274] - INFO: epoch 001:  31311 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.89, wpb=111, bsz=40, num_updates=31270, lr=4.0073e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92309
2023-02-21 15:04:27 - progress_bar.py[line:274] - INFO: epoch 001:  31321 / 142023 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.92, wpb=112.1, bsz=40, num_updates=31280, lr=4.00694e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92319
2023-02-21 15:04:38 - progress_bar.py[line:274] - INFO: epoch 001:  31331 / 142023 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=111.2, bsz=40, num_updates=31290, lr=4.00658e-05, gnorm=0.079, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92331
2023-02-21 15:04:49 - progress_bar.py[line:274] - INFO: epoch 001:  31341 / 142023 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.3, ups=0.91, wpb=110.6, bsz=40, num_updates=31300, lr=4.00622e-05, gnorm=0.063, clip=0, loss_scale=4096, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=92342
2023-02-21 15:05:00 - progress_bar.py[line:274] - INFO: epoch 001:  31351 / 142023 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.6, ups=0.87, wpb=111.3, bsz=40, num_updates=31310, lr=4.00585e-05, gnorm=0.061, clip=0, loss_scale=4096, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=92353
2023-02-21 15:05:11 - progress_bar.py[line:274] - INFO: epoch 001:  31361 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.89, wpb=110.9, bsz=40, num_updates=31320, lr=4.00549e-05, gnorm=0.054, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92364
2023-02-21 15:05:22 - progress_bar.py[line:274] - INFO: epoch 001:  31371 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=110.9, bsz=40, num_updates=31330, lr=4.00513e-05, gnorm=0.075, clip=0, loss_scale=4096, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=92375
2023-02-21 15:05:34 - progress_bar.py[line:274] - INFO: epoch 001:  31381 / 142023 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=31340, lr=4.00477e-05, gnorm=0.088, clip=0, loss_scale=4096, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=92386
2023-02-21 15:05:44 - progress_bar.py[line:274] - INFO: epoch 001:  31391 / 142023 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.93, wpb=109.9, bsz=40, num_updates=31350, lr=4.00441e-05, gnorm=0.076, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92397
2023-02-21 15:05:55 - progress_bar.py[line:274] - INFO: epoch 001:  31401 / 142023 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=31360, lr=4.00405e-05, gnorm=0.072, clip=0, loss_scale=4096, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=92408
2023-02-21 15:06:06 - progress_bar.py[line:274] - INFO: epoch 001:  31411 / 142023 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.3, ups=0.93, wpb=109.9, bsz=40, num_updates=31370, lr=4.00368e-05, gnorm=0.078, clip=0, loss_scale=4096, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=92419
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 3570689
Killing subprocess 3570690
Main process received SIGINT, exiting
