2022-10-12 15:34:18 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-12 15:34:18 - utils.py[line:261] - INFO: Start init
2022-10-12 15:34:18 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-12 15:34:18 - utils.py[line:261] - INFO: Start init
2022-10-12 15:34:19 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-12 15:34:19 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-12 15:34:19 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-12 15:34:19 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-12 15:34:24 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 4, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=4, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480', save_interval=10, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=1000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-12 15:34:24 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-12 15:34:24 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-10-12 15:34:29 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-10-12 15:34:29 - train.py[line:118] - INFO: task: VqaGenTask
2022-10-12 15:34:29 - train.py[line:119] - INFO: model: OFAModel
2022-10-12 15:34:29 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-10-12 15:34:29 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-10-12 15:34:29 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-12 15:34:29 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-10-12 15:34:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-10-12 15:34:30 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-12 15:34:30 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-12 15:34:30 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-12 15:34:30 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-12 15:34:30 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-10-12 15:34:30 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-10-12 15:34:30 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt
2022-10-12 15:35:00 - trainer.py[line:605] - INFO: Loading EMA from checkpoint
2022-10-12 15:35:00 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-10-12 15:35:00 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-10-12 15:35:01 - trainer.py[line:612] - INFO: Loading EMA fp32 params from checkpoint
2022-10-12 15:35:01 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt (epoch 8 @ 0 updates)
2022-10-12 15:35:01 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv slice_id 1 row count 578200 total row count 1156400
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv slice_id 0 row count 578200 total row count 1156400
2022-10-12 15:35:03 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 115640, warmup steps 4625, warmup_factor 0.00021621621621621621
Total steps 115640, warmup steps 4625, warmup_factor 0.00021621621621621621
2022-10-12 15:35:04 - trainer.py[line:707] - INFO: begin training epoch 1
2022-10-12 15:35:04 - train.py[line:312] - INFO: Start iterating over samples
2022-10-12 15:35:26 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 28910 loss=0.765, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=90.2, ups=0.81, wpb=110.8, bsz=40, num_updates=10, lr=1.08108e-07, gnorm=2.465, clip=100, loss_scale=128, train_wall=18, gb_free=10.6, ema_decay=0.9999, wall=55
2022-10-12 15:35:37 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 28910 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=92.2, ups=0.84, wpb=109.6, bsz=40, num_updates=20, lr=2.16216e-07, gnorm=2.535, clip=100, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=67
2022-10-12 15:35:49 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 28910 loss=0.792, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=96.5, ups=0.87, wpb=111.1, bsz=40, num_updates=30, lr=3.24324e-07, gnorm=2.476, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79
2022-10-12 15:36:00 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 28910 loss=0.755, loss_v1=0, loss_v2=0, nll_loss=0.654, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=40, lr=4.32432e-07, gnorm=2.302, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=90
2022-10-12 15:36:13 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 28910 loss=0.754, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=93.7, ups=0.86, wpb=109.4, bsz=40, num_updates=50, lr=5.40541e-07, gnorm=2.597, clip=100, loss_scale=128, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=102
2022-10-12 15:36:24 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 28910 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.635, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=96.4, ups=0.87, wpb=111.1, bsz=40, num_updates=60, lr=6.48649e-07, gnorm=2.288, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=114
2022-10-12 15:36:36 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 28910 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.6, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=94.8, ups=0.86, wpb=109.8, bsz=40, num_updates=70, lr=7.56757e-07, gnorm=2.205, clip=100, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=126
2022-10-12 15:36:47 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 28910 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=80, lr=8.64865e-07, gnorm=2.11, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137
2022-10-12 15:36:59 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 28910 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=98.3, ups=0.89, wpb=111, bsz=40, num_updates=90, lr=9.72973e-07, gnorm=1.894, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=148
2022-10-12 15:37:10 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 28910 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=97.2, ups=0.88, wpb=110.1, bsz=40, num_updates=100, lr=1.08108e-06, gnorm=2.318, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=160
2022-10-12 15:37:21 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 28910 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98.9, ups=0.9, wpb=110, bsz=40, num_updates=110, lr=1.18919e-06, gnorm=2.256, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=171
2022-10-12 15:37:33 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 28910 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=96.6, ups=0.87, wpb=111.2, bsz=40, num_updates=120, lr=1.2973e-06, gnorm=1.683, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=182
2022-10-12 15:37:44 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 28910 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.627, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=130, lr=1.40541e-06, gnorm=1.834, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=194
2022-10-12 15:37:55 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 28910 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=140, lr=1.51351e-06, gnorm=1.682, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=205
2022-10-12 15:38:07 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 28910 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=150, lr=1.62162e-06, gnorm=1.412, clip=90, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=216
2022-10-12 15:38:18 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 28910 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=101.2, ups=0.92, wpb=110.5, bsz=40, num_updates=160, lr=1.72973e-06, gnorm=1.383, clip=90, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=227
2022-10-12 15:38:29 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 28910 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=170, lr=1.83784e-06, gnorm=1.494, clip=90, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=239
2022-10-12 15:38:40 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 28910 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100, ups=0.9, wpb=111.4, bsz=40, num_updates=180, lr=1.94595e-06, gnorm=1.165, clip=70, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=250
2022-10-12 15:38:51 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 28910 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=102.1, ups=0.91, wpb=111.8, bsz=40, num_updates=190, lr=2.05405e-06, gnorm=1.286, clip=80, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=261
2022-10-12 15:39:02 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 28910 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.6, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=200, lr=2.16216e-06, gnorm=1.347, clip=70, loss_scale=128, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=272
2022-10-12 15:39:14 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 28910 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=210, lr=2.27027e-06, gnorm=1.12, clip=70, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=283
2022-10-12 15:39:25 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 28910 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.6, ups=0.9, wpb=109.8, bsz=40, num_updates=220, lr=2.37838e-06, gnorm=1.317, clip=70, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=294
2022-10-12 15:39:36 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 28910 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=230, lr=2.48649e-06, gnorm=1.315, clip=80, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=306
2022-10-12 15:39:47 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.3, ups=0.9, wpb=111.4, bsz=40, num_updates=240, lr=2.59459e-06, gnorm=0.944, clip=40, loss_scale=128, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=317
2022-10-12 15:39:58 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 28910 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.2, ups=0.9, wpb=109.5, bsz=40, num_updates=250, lr=2.7027e-06, gnorm=1.058, clip=50, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=328
2022-10-12 15:40:09 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 28910 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=102.3, ups=0.93, wpb=110.5, bsz=40, num_updates=260, lr=2.81081e-06, gnorm=1.305, clip=80, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=339
2022-10-12 15:40:20 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 28910 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.3, ups=0.9, wpb=108.9, bsz=40, num_updates=270, lr=2.91892e-06, gnorm=1.33, clip=80, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=350
2022-10-12 15:40:31 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 28910 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=280, lr=3.02703e-06, gnorm=1.133, clip=80, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=361
2022-10-12 15:40:43 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 28910 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.6, ups=0.88, wpb=110, bsz=40, num_updates=290, lr=3.13514e-06, gnorm=1.06, clip=50, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=372
2022-10-12 15:40:54 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 28910 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99, ups=0.9, wpb=109.8, bsz=40, num_updates=300, lr=3.24324e-06, gnorm=1.154, clip=70, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=383
2022-10-12 15:41:05 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.7, ups=0.88, wpb=110.2, bsz=40, num_updates=310, lr=3.35135e-06, gnorm=1.22, clip=70, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=395
2022-10-12 15:41:16 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 28910 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=320, lr=3.45946e-06, gnorm=1.278, clip=70, loss_scale=128, train_wall=11, gb_free=11, ema_decay=0.9999, wall=406
2022-10-12 15:41:27 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 28910 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=330, lr=3.56757e-06, gnorm=1.177, clip=80, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=417
2022-10-12 15:41:38 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=104.2, ups=0.94, wpb=111.2, bsz=40, num_updates=340, lr=3.67568e-06, gnorm=1.104, clip=60, loss_scale=128, train_wall=11, gb_free=11, ema_decay=0.9999, wall=428
2022-10-12 15:41:49 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.9, ups=0.9, wpb=111.8, bsz=40, num_updates=350, lr=3.78378e-06, gnorm=1.043, clip=50, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=439
2022-10-12 15:42:00 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=360, lr=3.89189e-06, gnorm=1.139, clip=80, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=450
2022-10-12 15:42:11 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 28910 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=370, lr=4e-06, gnorm=1.23, clip=90, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=461
2022-10-12 15:42:23 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 28910 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=380, lr=4.10811e-06, gnorm=1.063, clip=70, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=472
2022-10-12 15:42:34 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 28910 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=390, lr=4.21622e-06, gnorm=1.142, clip=90, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=483
2022-10-12 15:42:45 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 28910 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=400, lr=4.32432e-06, gnorm=0.975, clip=50, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=494
2022-10-12 15:42:56 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.4, ups=0.88, wpb=109.5, bsz=40, num_updates=410, lr=4.43243e-06, gnorm=1.032, clip=50, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=506
2022-10-12 15:43:07 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.9, ups=0.91, wpb=110.4, bsz=40, num_updates=420, lr=4.54054e-06, gnorm=1.147, clip=80, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=517
2022-10-12 15:43:18 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.2, ups=0.9, wpb=111.3, bsz=40, num_updates=430, lr=4.64865e-06, gnorm=1.081, clip=60, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=528
2022-10-12 15:43:30 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 28910 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.1, ups=0.89, wpb=109.6, bsz=40, num_updates=440, lr=4.75676e-06, gnorm=1.182, clip=90, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=539
2022-10-12 15:43:41 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.4, ups=0.87, wpb=110.8, bsz=40, num_updates=450, lr=4.86486e-06, gnorm=1.019, clip=40, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=551
2022-10-12 15:43:52 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 28910 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=460, lr=4.97297e-06, gnorm=1.219, clip=80, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=562
2022-10-12 15:44:04 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.8, ups=0.88, wpb=110.3, bsz=40, num_updates=470, lr=5.08108e-06, gnorm=1.006, clip=40, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=573
2022-10-12 15:44:15 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 28910 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.9, ups=0.91, wpb=109.2, bsz=40, num_updates=480, lr=5.18919e-06, gnorm=1.144, clip=80, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=584
2022-10-12 15:44:26 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97, ups=0.88, wpb=110.4, bsz=40, num_updates=490, lr=5.2973e-06, gnorm=1.013, clip=50, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=596
2022-10-12 15:44:37 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 28910 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.2, ups=0.88, wpb=110, bsz=40, num_updates=500, lr=5.40541e-06, gnorm=1, clip=50, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=607
2022-10-12 15:44:48 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 28910 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.1, ups=0.89, wpb=108.7, bsz=40, num_updates=510, lr=5.51351e-06, gnorm=1.068, clip=50, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=618
2022-10-12 15:45:00 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.4, ups=0.9, wpb=111.5, bsz=40, num_updates=520, lr=5.62162e-06, gnorm=0.978, clip=40, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=629
2022-10-12 15:45:10 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.9, ups=0.93, wpb=111, bsz=40, num_updates=530, lr=5.72973e-06, gnorm=0.95, clip=20, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=640
2022-10-12 15:45:21 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.2, ups=0.9, wpb=110.1, bsz=40, num_updates=540, lr=5.83784e-06, gnorm=0.985, clip=40, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=651
2022-10-12 15:45:33 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 28910 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.7, ups=0.91, wpb=110.9, bsz=40, num_updates=550, lr=5.94595e-06, gnorm=1.072, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=662
2022-10-12 15:45:43 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 28910 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102, ups=0.93, wpb=110.1, bsz=40, num_updates=560, lr=6.05405e-06, gnorm=1.068, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=673
2022-10-12 15:45:55 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=570, lr=6.16216e-06, gnorm=1.046, clip=60, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=684
2022-10-12 15:46:06 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.3, ups=0.88, wpb=111.1, bsz=40, num_updates=580, lr=6.27027e-06, gnorm=1.116, clip=70, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=696
2022-10-12 15:46:17 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.1, ups=0.9, wpb=112.1, bsz=40, num_updates=590, lr=6.37838e-06, gnorm=1.143, clip=90, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=707
2022-10-12 15:46:28 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 28910 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.2, ups=0.87, wpb=110.4, bsz=40, num_updates=600, lr=6.48649e-06, gnorm=1.133, clip=90, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=718
2022-10-12 15:46:40 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.9, ups=0.89, wpb=109.4, bsz=40, num_updates=610, lr=6.59459e-06, gnorm=1.023, clip=50, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=729
2022-10-12 15:46:51 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.2, ups=0.9, wpb=109.6, bsz=40, num_updates=620, lr=6.7027e-06, gnorm=0.967, clip=30, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=740
2022-10-12 15:47:02 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.5, ups=0.88, wpb=111.7, bsz=40, num_updates=630, lr=6.81081e-06, gnorm=1.039, clip=70, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=752
2022-10-12 15:47:14 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 28910 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.5, ups=0.87, wpb=109.8, bsz=40, num_updates=640, lr=6.91892e-06, gnorm=1.191, clip=80, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=763
2022-10-12 15:47:25 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.7, ups=0.88, wpb=110.1, bsz=40, num_updates=650, lr=7.02703e-06, gnorm=1.17, clip=70, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=775
2022-10-12 15:47:37 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.5, ups=0.87, wpb=110.6, bsz=40, num_updates=660, lr=7.13514e-06, gnorm=0.944, clip=40, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=786
2022-10-12 15:47:48 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.6, ups=0.91, wpb=109.8, bsz=40, num_updates=670, lr=7.24324e-06, gnorm=1.098, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=797
2022-10-12 15:47:59 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 28910 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.7, ups=0.89, wpb=109.6, bsz=40, num_updates=680, lr=7.35135e-06, gnorm=1.093, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=808
2022-10-12 15:48:10 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102, ups=0.93, wpb=109.9, bsz=40, num_updates=690, lr=7.45946e-06, gnorm=1.176, clip=90, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=819
2022-10-12 15:48:20 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=105.5, ups=0.94, wpb=112.4, bsz=40, num_updates=700, lr=7.56757e-06, gnorm=1.029, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=830
2022-10-12 15:48:31 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=710, lr=7.67568e-06, gnorm=1.126, clip=60, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=841
2022-10-12 15:48:43 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=720, lr=7.78378e-06, gnorm=1.081, clip=70, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=852
2022-10-12 15:48:54 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 28910 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.8, ups=0.88, wpb=110.5, bsz=40, num_updates=730, lr=7.89189e-06, gnorm=1.179, clip=80, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=864
2022-10-12 15:49:05 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=740, lr=8e-06, gnorm=1.138, clip=70, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=875
2022-10-12 15:49:16 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=101, ups=0.91, wpb=111.6, bsz=40, num_updates=750, lr=8.10811e-06, gnorm=1.059, clip=60, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=886
2022-10-12 15:49:27 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.7, ups=0.92, wpb=109.4, bsz=40, num_updates=760, lr=8.21622e-06, gnorm=1.138, clip=80, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=897
2022-10-12 15:49:39 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.3, ups=0.87, wpb=111.8, bsz=40, num_updates=770, lr=8.32432e-06, gnorm=1.131, clip=70, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=908
2022-10-12 15:49:50 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.7, ups=0.89, wpb=111.6, bsz=40, num_updates=780, lr=8.43243e-06, gnorm=1.189, clip=90, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=920
2022-10-12 15:50:01 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 28910 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.3, ups=0.91, wpb=110.5, bsz=40, num_updates=790, lr=8.54054e-06, gnorm=1.123, clip=60, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=931
2022-10-12 15:50:13 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.2, ups=0.9, wpb=108.7, bsz=40, num_updates=800, lr=8.64865e-06, gnorm=1.096, clip=70, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=942
2022-10-12 15:50:23 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=101, ups=0.92, wpb=110.1, bsz=40, num_updates=810, lr=8.75676e-06, gnorm=0.979, clip=40, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=953
2022-10-12 15:50:34 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=104.2, ups=0.94, wpb=110.3, bsz=40, num_updates=820, lr=8.86486e-06, gnorm=1.004, clip=40, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=964
2022-10-12 15:50:45 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.3, ups=0.89, wpb=111.5, bsz=40, num_updates=830, lr=8.97297e-06, gnorm=1.172, clip=90, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=975
2022-10-12 15:50:56 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=840, lr=9.08108e-06, gnorm=0.974, clip=50, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=986
2022-10-12 15:51:08 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.7, ups=0.87, wpb=109.9, bsz=40, num_updates=850, lr=9.18919e-06, gnorm=1.098, clip=70, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=997
2022-10-12 15:51:19 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=860, lr=9.2973e-06, gnorm=1.08, clip=70, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1009
2022-10-12 15:51:30 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.4, ups=0.89, wpb=109.8, bsz=40, num_updates=870, lr=9.40541e-06, gnorm=1.048, clip=70, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1020
2022-10-12 15:51:42 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=880, lr=9.51351e-06, gnorm=1.144, clip=70, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1031
2022-10-12 15:51:53 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.7, ups=0.88, wpb=112.1, bsz=40, num_updates=890, lr=9.62162e-06, gnorm=1.06, clip=80, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1043
2022-10-12 15:52:04 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.2, ups=0.9, wpb=110.2, bsz=40, num_updates=900, lr=9.72973e-06, gnorm=1.009, clip=60, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1054
2022-10-12 15:52:16 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.4, ups=0.88, wpb=110.6, bsz=40, num_updates=910, lr=9.83784e-06, gnorm=1.043, clip=40, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1065
2022-10-12 15:52:27 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.4, ups=0.89, wpb=111.7, bsz=40, num_updates=920, lr=9.94595e-06, gnorm=1.057, clip=50, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1076
2022-10-12 15:52:38 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98, ups=0.88, wpb=111.3, bsz=40, num_updates=930, lr=1.00541e-05, gnorm=1.091, clip=60, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1088
2022-10-12 15:52:49 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=940, lr=1.01622e-05, gnorm=1.007, clip=50, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=1099
2022-10-12 15:53:00 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.5, ups=0.92, wpb=109.8, bsz=40, num_updates=950, lr=1.02703e-05, gnorm=1.036, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1110
2022-10-12 15:53:11 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.3, ups=0.88, wpb=109, bsz=40, num_updates=960, lr=1.03784e-05, gnorm=1.098, clip=80, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=1121
2022-10-12 15:53:23 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.6, ups=0.87, wpb=110.6, bsz=40, num_updates=970, lr=1.04865e-05, gnorm=1.129, clip=90, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1133
2022-10-12 15:53:34 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.4, ups=0.87, wpb=109.6, bsz=40, num_updates=980, lr=1.05946e-05, gnorm=1.177, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1144
2022-10-12 15:53:45 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=103.1, ups=0.93, wpb=111.3, bsz=40, num_updates=990, lr=1.07027e-05, gnorm=1.053, clip=40, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1155
2022-10-12 15:53:56 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=101, ups=0.9, wpb=112.1, bsz=40, num_updates=1000, lr=1.08108e-05, gnorm=1.032, clip=60, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1166
2022-10-12 15:53:56 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 15:53:56 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-12 15:53:58 - train.py[line:549] - INFO: 0 / 4988
2022-10-12 15:53:58 - train.py[line:551] - INFO: load:1.16 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 15:56:33 - train.py[line:549] - INFO: 200 / 4988
2022-10-12 15:56:33 - train.py[line:551] - INFO: load:1.18 valid_run:154.40 task_valid:150.17 collect_output:3.15
2022-10-12 15:59:01 - train.py[line:549] - INFO: 400 / 4988
2022-10-12 15:59:01 - train.py[line:551] - INFO: load:1.21 valid_run:302.84 task_valid:293.03 collect_output:7.71
2022-10-12 16:01:34 - train.py[line:549] - INFO: 600 / 4988
2022-10-12 16:01:34 - train.py[line:551] - INFO: load:1.23 valid_run:455.75 task_valid:435.75 collect_output:16.88
2022-10-12 16:04:03 - train.py[line:549] - INFO: 800 / 4988
2022-10-12 16:04:03 - train.py[line:551] - INFO: load:1.26 valid_run:604.49 task_valid:580.48 collect_output:19.86
2022-10-12 16:06:35 - train.py[line:549] - INFO: 1000 / 4988
2022-10-12 16:06:35 - train.py[line:551] - INFO: load:1.28 valid_run:756.45 task_valid:727.53 collect_output:23.77
2022-10-12 16:09:06 - train.py[line:549] - INFO: 1200 / 4988
2022-10-12 16:09:06 - train.py[line:551] - INFO: load:1.31 valid_run:907.82 task_valid:872.64 collect_output:29.03
2022-10-12 16:11:40 - train.py[line:549] - INFO: 1400 / 4988
2022-10-12 16:11:40 - train.py[line:551] - INFO: load:1.33 valid_run:1060.84 task_valid:1018.19 collect_output:35.51
2022-10-12 16:14:10 - train.py[line:549] - INFO: 1600 / 4988
2022-10-12 16:14:10 - train.py[line:551] - INFO: load:1.36 valid_run:1211.65 task_valid:1158.86 collect_output:44.63
2022-10-12 16:16:40 - train.py[line:549] - INFO: 1800 / 4988
2022-10-12 16:16:40 - train.py[line:551] - INFO: load:1.38 valid_run:1361.08 task_valid:1303.31 collect_output:48.58
2022-10-12 16:19:08 - train.py[line:549] - INFO: 2000 / 4988
2022-10-12 16:19:08 - train.py[line:551] - INFO: load:1.41 valid_run:1509.35 task_valid:1446.01 collect_output:53.16
2022-10-12 16:21:38 - train.py[line:549] - INFO: 2200 / 4988
2022-10-12 16:21:38 - train.py[line:551] - INFO: load:1.43 valid_run:1658.60 task_valid:1590.41 collect_output:57.02
2022-10-12 16:24:07 - train.py[line:549] - INFO: 2400 / 4988
2022-10-12 16:24:07 - train.py[line:551] - INFO: load:1.46 valid_run:1808.44 task_valid:1735.18 collect_output:61.07
2022-10-12 16:26:37 - train.py[line:549] - INFO: 2600 / 4988
2022-10-12 16:26:37 - train.py[line:551] - INFO: load:1.48 valid_run:1958.04 task_valid:1876.67 collect_output:68.17
2022-10-12 16:29:07 - train.py[line:549] - INFO: 2800 / 4988
2022-10-12 16:29:07 - train.py[line:551] - INFO: load:1.51 valid_run:2108.23 task_valid:2021.72 collect_output:72.29
2022-10-12 16:31:37 - train.py[line:549] - INFO: 3000 / 4988
2022-10-12 16:31:37 - train.py[line:551] - INFO: load:1.53 valid_run:2257.88 task_valid:2167.78 collect_output:74.87
2022-10-12 16:34:07 - train.py[line:549] - INFO: 3200 / 4988
2022-10-12 16:34:07 - train.py[line:551] - INFO: load:1.56 valid_run:2407.90 task_valid:2311.69 collect_output:79.96
2022-10-12 16:36:39 - train.py[line:549] - INFO: 3400 / 4988
2022-10-12 16:36:39 - train.py[line:551] - INFO: load:1.58 valid_run:2559.18 task_valid:2456.81 collect_output:85.11
2022-10-12 16:39:09 - train.py[line:549] - INFO: 3600 / 4988
2022-10-12 16:39:09 - train.py[line:551] - INFO: load:1.61 valid_run:2709.21 task_valid:2603.25 collect_output:87.65
2022-10-12 16:41:37 - train.py[line:549] - INFO: 3800 / 4988
2022-10-12 16:41:37 - train.py[line:551] - INFO: load:1.63 valid_run:2857.91 task_valid:2744.86 collect_output:93.67
2022-10-12 16:44:08 - train.py[line:549] - INFO: 4000 / 4988
2022-10-12 16:44:08 - train.py[line:551] - INFO: load:1.66 valid_run:3008.23 task_valid:2889.90 collect_output:97.88
2022-10-12 16:46:40 - train.py[line:549] - INFO: 4200 / 4988
2022-10-12 16:46:40 - train.py[line:551] - INFO: load:1.68 valid_run:3160.32 task_valid:3034.50 collect_output:104.17
2022-10-12 16:49:09 - train.py[line:549] - INFO: 4400 / 4988
2022-10-12 16:49:09 - train.py[line:551] - INFO: load:1.71 valid_run:3309.77 task_valid:3179.10 collect_output:107.90
2022-10-12 16:51:41 - train.py[line:549] - INFO: 4600 / 4988
2022-10-12 16:51:41 - train.py[line:551] - INFO: load:1.73 valid_run:3461.51 task_valid:3325.43 collect_output:112.19
2022-10-12 16:54:13 - train.py[line:549] - INFO: 4800 / 4988
2022-10-12 16:54:13 - train.py[line:551] - INFO: load:1.76 valid_run:3613.00 task_valid:3471.93 collect_output:116.14

====================================================================================================
SGG eval:     R @ 50: 0.6480;     R @ 100: 0.6865;     R @ 500: 0.7171;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4334;    mR @ 100: 0.4951;    mR @ 500: 0.5302;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.4375) (covering:0.5143) (eating:0.7647) (flying in:1.0000) (growing on:0.3750) (hanging from:0.5000) (lying on:0.5000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9624) (says:0.0000) (sitting on:0.6888) (standing on:0.5013) (using:0.4500) (walking in:0.0000) (walking on:0.6351) (watching:0.5625) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6480;     R @ 100: 0.6865;     R @ 500: 0.7171;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4334;    mR @ 100: 0.4951;    mR @ 500: 0.5302;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.4375) (covering:0.5143) (eating:0.7647) (flying in:1.0000) (growing on:0.3750) (hanging from:0.5000) (lying on:0.5000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9624) (says:0.0000) (sitting on:0.6888) (standing on:0.5013) (using:0.4500) (walking in:0.0000) (walking on:0.6351) (watching:0.5625) 
--------------------------------------------------------
====================================================================================================

2022-10-12 16:56:44 - train.py[line:487] - INFO: 0.6864801120448178
2022-10-12 16:56:44 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 16:56:44 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.339 | loss_v1 0 | loss_v2 0 | nll_loss 0.193 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.68648 | ppl 1.14 | vqa_score 0.4842 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 1000
2022-10-12 16:56:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1000 updates
2022-10-12 16:56:44 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-12 16:56:50 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-12 16:56:58 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 0.6864801120448178) (writing took 13.543367548845708 seconds)
2022-10-12 16:57:09 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=0.3, ups=0, wpb=109.3, bsz=40, num_updates=1010, lr=1.09189e-05, gnorm=1.131, clip=80, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4958
2022-10-12 16:57:20 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96.9, ups=0.88, wpb=110.6, bsz=40, num_updates=1020, lr=1.1027e-05, gnorm=1.043, clip=80, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=4970
2022-10-12 16:57:31 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.7, ups=0.88, wpb=111.2, bsz=40, num_updates=1030, lr=1.11351e-05, gnorm=1.077, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4981
2022-10-12 16:57:43 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.4, ups=0.88, wpb=110.8, bsz=40, num_updates=1040, lr=1.12432e-05, gnorm=1.102, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4992
2022-10-12 16:57:54 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.8, ups=0.89, wpb=111.2, bsz=40, num_updates=1050, lr=1.13514e-05, gnorm=1.061, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5004
2022-10-12 16:58:05 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.2, ups=0.9, wpb=108.6, bsz=40, num_updates=1060, lr=1.14595e-05, gnorm=1.066, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5015
2022-10-12 16:58:17 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=96.5, ups=0.87, wpb=111, bsz=40, num_updates=1070, lr=1.15676e-05, gnorm=1.143, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5026
2022-10-12 16:58:28 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.4, ups=0.87, wpb=110.8, bsz=40, num_updates=1080, lr=1.16757e-05, gnorm=1.056, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5038
2022-10-12 16:58:39 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.6, ups=0.92, wpb=109.7, bsz=40, num_updates=1090, lr=1.17838e-05, gnorm=1.082, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5049
2022-10-12 16:58:50 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.1, ups=0.9, wpb=110.4, bsz=40, num_updates=1100, lr=1.18919e-05, gnorm=1.1, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5060
2022-10-12 16:59:02 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96.7, ups=0.88, wpb=110.4, bsz=40, num_updates=1110, lr=1.2e-05, gnorm=1.385, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5071
2022-10-12 16:59:13 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=1120, lr=1.21081e-05, gnorm=1.185, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5083
2022-10-12 16:59:24 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=102.2, ups=0.92, wpb=110.7, bsz=40, num_updates=1130, lr=1.22162e-05, gnorm=1.197, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5093
2022-10-12 16:59:35 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.5, ups=0.9, wpb=110.6, bsz=40, num_updates=1140, lr=1.23243e-05, gnorm=1.041, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5105
2022-10-12 16:59:46 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.8, ups=0.89, wpb=110, bsz=40, num_updates=1150, lr=1.24324e-05, gnorm=1.133, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5116
2022-10-12 16:59:57 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=101.9, ups=0.93, wpb=110, bsz=40, num_updates=1160, lr=1.25405e-05, gnorm=1.112, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5127
2022-10-12 17:00:08 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.2, ups=0.89, wpb=110.3, bsz=40, num_updates=1170, lr=1.26486e-05, gnorm=1.068, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5138
2022-10-12 17:00:20 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=1180, lr=1.27568e-05, gnorm=1.182, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5149
2022-10-12 17:00:31 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=94.7, ups=0.87, wpb=108.9, bsz=40, num_updates=1190, lr=1.28649e-05, gnorm=1.092, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5161
2022-10-12 17:00:42 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.7, ups=0.9, wpb=109.8, bsz=40, num_updates=1200, lr=1.2973e-05, gnorm=1.245, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5172
2022-10-12 17:00:53 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.6, ups=0.89, wpb=109.1, bsz=40, num_updates=1210, lr=1.30811e-05, gnorm=1.113, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5183
2022-10-12 17:01:05 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.5, ups=0.88, wpb=110.1, bsz=40, num_updates=1220, lr=1.31892e-05, gnorm=1.127, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5194
2022-10-12 17:01:16 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98, ups=0.88, wpb=111.3, bsz=40, num_updates=1230, lr=1.32973e-05, gnorm=1.084, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5206
2022-10-12 17:01:27 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.8, ups=0.89, wpb=108.6, bsz=40, num_updates=1240, lr=1.34054e-05, gnorm=1.196, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5217
2022-10-12 17:01:39 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.2, ups=0.88, wpb=108.5, bsz=40, num_updates=1250, lr=1.35135e-05, gnorm=1.2, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5228
2022-10-12 17:01:50 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.3, ups=0.86, wpb=109.5, bsz=40, num_updates=1260, lr=1.36216e-05, gnorm=1.242, clip=90, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=5240
2022-10-12 17:02:01 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.1, ups=0.91, wpb=110.2, bsz=40, num_updates=1270, lr=1.37297e-05, gnorm=1.126, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5251
2022-10-12 17:02:13 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97, ups=0.88, wpb=110, bsz=40, num_updates=1280, lr=1.38378e-05, gnorm=1.107, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5262
2022-10-12 17:02:24 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=1290, lr=1.39459e-05, gnorm=1.044, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5274
2022-10-12 17:02:36 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.6, ups=0.86, wpb=111.9, bsz=40, num_updates=1300, lr=1.40541e-05, gnorm=1.091, clip=50, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5285
2022-10-12 17:02:47 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=1310, lr=1.41622e-05, gnorm=1.064, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5297
2022-10-12 17:02:58 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=1320, lr=1.42703e-05, gnorm=1.04, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5308
2022-10-12 17:03:09 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.2, ups=0.91, wpb=110.8, bsz=40, num_updates=1330, lr=1.43784e-05, gnorm=1.058, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5319
2022-10-12 17:03:20 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.8, ups=0.89, wpb=112.1, bsz=40, num_updates=1340, lr=1.44865e-05, gnorm=1.033, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5330
2022-10-12 17:03:31 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=1350, lr=1.45946e-05, gnorm=1.068, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5341
2022-10-12 17:03:42 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=101.7, ups=0.92, wpb=111, bsz=40, num_updates=1360, lr=1.47027e-05, gnorm=1.108, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5352
2022-10-12 17:03:54 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.2, ups=0.9, wpb=109.7, bsz=40, num_updates=1370, lr=1.48108e-05, gnorm=1.13, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5363
2022-10-12 17:04:04 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=103.5, ups=0.94, wpb=110.2, bsz=40, num_updates=1380, lr=1.49189e-05, gnorm=1.065, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5374
2022-10-12 17:04:16 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.1, ups=0.88, wpb=109.7, bsz=40, num_updates=1390, lr=1.5027e-05, gnorm=1.167, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5385
2022-10-12 17:04:27 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=95.8, ups=0.88, wpb=109.3, bsz=40, num_updates=1400, lr=1.51351e-05, gnorm=1.046, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5397
2022-10-12 17:04:38 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.8, ups=0.9, wpb=110.9, bsz=40, num_updates=1410, lr=1.52432e-05, gnorm=1.158, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5408
2022-10-12 17:04:49 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99, ups=0.9, wpb=110.2, bsz=40, num_updates=1420, lr=1.53514e-05, gnorm=1.205, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5419
2022-10-12 17:05:00 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=102, ups=0.93, wpb=109.8, bsz=40, num_updates=1430, lr=1.54595e-05, gnorm=1.231, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5430
2022-10-12 17:05:11 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.1, ups=0.9, wpb=108.6, bsz=40, num_updates=1440, lr=1.55676e-05, gnorm=1.224, clip=80, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=5441
2022-10-12 17:05:22 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.8, ups=0.9, wpb=110.9, bsz=40, num_updates=1450, lr=1.56757e-05, gnorm=1.006, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5452
2022-10-12 17:05:33 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=1460, lr=1.57838e-05, gnorm=1.14, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5463
2022-10-12 17:05:45 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.4, ups=0.9, wpb=110.7, bsz=40, num_updates=1470, lr=1.58919e-05, gnorm=1.198, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5474
2022-10-12 17:05:56 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=1480, lr=1.6e-05, gnorm=1.046, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5485
2022-10-12 17:06:07 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101, ups=0.91, wpb=110.8, bsz=40, num_updates=1490, lr=1.61081e-05, gnorm=1.061, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5496
2022-10-12 17:06:18 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.1, ups=0.87, wpb=111.8, bsz=40, num_updates=1500, lr=1.62162e-05, gnorm=1.041, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5508
2022-10-12 17:06:30 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.8, ups=0.88, wpb=110.6, bsz=40, num_updates=1510, lr=1.63243e-05, gnorm=1.14, clip=80, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5519
2022-10-12 17:06:40 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101.4, ups=0.92, wpb=110.1, bsz=40, num_updates=1520, lr=1.64324e-05, gnorm=1.157, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5530
2022-10-12 17:06:51 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=103.1, ups=0.92, wpb=111.6, bsz=40, num_updates=1530, lr=1.65405e-05, gnorm=1.017, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5541
2022-10-12 17:07:00 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 17:07:04 - progress_bar.py[line:274] - INFO: epoch 001:   1541 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=88, ups=0.8, wpb=110.5, bsz=40, num_updates=1540, lr=1.66486e-05, gnorm=1.088, clip=60, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=5554
2022-10-12 17:07:15 - progress_bar.py[line:274] - INFO: epoch 001:   1551 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101.2, ups=0.91, wpb=110.9, bsz=40, num_updates=1550, lr=1.67568e-05, gnorm=1.157, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5565
2022-10-12 17:07:26 - progress_bar.py[line:274] - INFO: epoch 001:   1561 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.9, ups=0.9, wpb=109.5, bsz=40, num_updates=1560, lr=1.68649e-05, gnorm=1.109, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5576
2022-10-12 17:07:37 - progress_bar.py[line:274] - INFO: epoch 001:   1571 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=1570, lr=1.6973e-05, gnorm=1.175, clip=90, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5587
2022-10-12 17:07:48 - progress_bar.py[line:274] - INFO: epoch 001:   1581 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100, ups=0.9, wpb=111.3, bsz=40, num_updates=1580, lr=1.70811e-05, gnorm=1.105, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5598
2022-10-12 17:07:59 - progress_bar.py[line:274] - INFO: epoch 001:   1591 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.9, ups=0.9, wpb=111.4, bsz=40, num_updates=1590, lr=1.71892e-05, gnorm=1.015, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5609
2022-10-12 17:08:11 - progress_bar.py[line:274] - INFO: epoch 001:   1601 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.3, ups=0.87, wpb=111, bsz=40, num_updates=1600, lr=1.72973e-05, gnorm=1.071, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5621
2022-10-12 17:08:22 - progress_bar.py[line:274] - INFO: epoch 001:   1611 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96, ups=0.88, wpb=109.4, bsz=40, num_updates=1610, lr=1.74054e-05, gnorm=1.172, clip=80, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5632
2022-10-12 17:08:34 - progress_bar.py[line:274] - INFO: epoch 001:   1621 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.3, ups=0.88, wpb=110, bsz=40, num_updates=1620, lr=1.75135e-05, gnorm=1.137, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5643
2022-10-12 17:08:45 - progress_bar.py[line:274] - INFO: epoch 001:   1631 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.4, ups=0.9, wpb=111.3, bsz=40, num_updates=1630, lr=1.76216e-05, gnorm=0.954, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5654
2022-10-12 17:08:56 - progress_bar.py[line:274] - INFO: epoch 001:   1641 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.8, ups=0.91, wpb=110.6, bsz=40, num_updates=1640, lr=1.77297e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5665
2022-10-12 17:09:07 - progress_bar.py[line:274] - INFO: epoch 001:   1651 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.7, ups=0.91, wpb=110.5, bsz=40, num_updates=1650, lr=1.78378e-05, gnorm=1.095, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5676
2022-10-12 17:09:18 - progress_bar.py[line:274] - INFO: epoch 001:   1661 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.1, ups=0.88, wpb=110.8, bsz=40, num_updates=1660, lr=1.79459e-05, gnorm=1.056, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5688
2022-10-12 17:09:29 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.8, ups=0.88, wpb=110.6, bsz=40, num_updates=1670, lr=1.80541e-05, gnorm=0.998, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5699
2022-10-12 17:09:41 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.2, ups=0.89, wpb=109.6, bsz=40, num_updates=1680, lr=1.81622e-05, gnorm=1.143, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5710
2022-10-12 17:09:52 - progress_bar.py[line:274] - INFO: epoch 001:   1691 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.5, ups=0.87, wpb=110.2, bsz=40, num_updates=1690, lr=1.82703e-05, gnorm=1.106, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5722
2022-10-12 17:10:03 - progress_bar.py[line:274] - INFO: epoch 001:   1701 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.9, ups=0.91, wpb=109.2, bsz=40, num_updates=1700, lr=1.83784e-05, gnorm=1.085, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5733
2022-10-12 17:10:14 - progress_bar.py[line:274] - INFO: epoch 001:   1711 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.8, ups=0.91, wpb=109.8, bsz=40, num_updates=1710, lr=1.84865e-05, gnorm=1.243, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5744
2022-10-12 17:10:25 - progress_bar.py[line:274] - INFO: epoch 001:   1721 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=102.1, ups=0.92, wpb=110.6, bsz=40, num_updates=1720, lr=1.85946e-05, gnorm=1.044, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5755
2022-10-12 17:10:36 - progress_bar.py[line:274] - INFO: epoch 001:   1731 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=1730, lr=1.87027e-05, gnorm=1.064, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5766
2022-10-12 17:10:48 - progress_bar.py[line:274] - INFO: epoch 001:   1741 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.1, ups=0.88, wpb=110.1, bsz=40, num_updates=1740, lr=1.88108e-05, gnorm=1.003, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5777
2022-10-12 17:10:59 - progress_bar.py[line:274] - INFO: epoch 001:   1751 / 28910 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.1, ups=0.89, wpb=110.6, bsz=40, num_updates=1750, lr=1.89189e-05, gnorm=1.119, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5789
2022-10-12 17:11:10 - progress_bar.py[line:274] - INFO: epoch 001:   1761 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.3, ups=0.88, wpb=111.2, bsz=40, num_updates=1760, lr=1.9027e-05, gnorm=1.028, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5800
2022-10-12 17:11:21 - progress_bar.py[line:274] - INFO: epoch 001:   1771 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=103.1, ups=0.93, wpb=110.3, bsz=40, num_updates=1770, lr=1.91351e-05, gnorm=1.038, clip=60, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=5811
2022-10-12 17:11:33 - progress_bar.py[line:274] - INFO: epoch 001:   1781 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=95.4, ups=0.86, wpb=110.6, bsz=40, num_updates=1780, lr=1.92432e-05, gnorm=1.01, clip=50, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=5822
2022-10-12 17:11:44 - progress_bar.py[line:274] - INFO: epoch 001:   1791 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.1, ups=0.87, wpb=111.2, bsz=40, num_updates=1790, lr=1.93514e-05, gnorm=0.985, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5834
2022-10-12 17:11:55 - progress_bar.py[line:274] - INFO: epoch 001:   1801 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.4, ups=0.88, wpb=109.6, bsz=40, num_updates=1800, lr=1.94595e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5845
2022-10-12 17:12:07 - progress_bar.py[line:274] - INFO: epoch 001:   1811 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.3, ups=0.89, wpb=108.4, bsz=40, num_updates=1810, lr=1.95676e-05, gnorm=1.026, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5856
2022-10-12 17:12:18 - progress_bar.py[line:274] - INFO: epoch 001:   1821 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.4, ups=0.9, wpb=110.3, bsz=40, num_updates=1820, lr=1.96757e-05, gnorm=0.996, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5867
2022-10-12 17:12:29 - progress_bar.py[line:274] - INFO: epoch 001:   1831 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97, ups=0.9, wpb=108.3, bsz=40, num_updates=1830, lr=1.97838e-05, gnorm=1.067, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5879
2022-10-12 17:12:41 - progress_bar.py[line:274] - INFO: epoch 001:   1841 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.6, ups=0.87, wpb=110.4, bsz=40, num_updates=1840, lr=1.98919e-05, gnorm=1.066, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5890
2022-10-12 17:12:51 - progress_bar.py[line:274] - INFO: epoch 001:   1851 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=103.3, ups=0.92, wpb=111.9, bsz=40, num_updates=1850, lr=2e-05, gnorm=1.01, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5901
2022-10-12 17:13:03 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.1, ups=0.89, wpb=109, bsz=40, num_updates=1860, lr=2.01081e-05, gnorm=1.04, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5912
2022-10-12 17:13:14 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.5, ups=0.89, wpb=111.8, bsz=40, num_updates=1870, lr=2.02162e-05, gnorm=0.923, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5924
2022-10-12 17:13:25 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.6, ups=0.91, wpb=110.4, bsz=40, num_updates=1880, lr=2.03243e-05, gnorm=0.96, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5935
2022-10-12 17:13:36 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.2, ups=0.9, wpb=111.1, bsz=40, num_updates=1890, lr=2.04324e-05, gnorm=1.118, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5946
2022-10-12 17:13:47 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.3, ups=0.89, wpb=109.2, bsz=40, num_updates=1900, lr=2.05405e-05, gnorm=1.114, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5957
2022-10-12 17:13:58 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97, ups=0.89, wpb=109.2, bsz=40, num_updates=1910, lr=2.06486e-05, gnorm=1.086, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5968
2022-10-12 17:14:10 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.5, ups=0.91, wpb=110.9, bsz=40, num_updates=1920, lr=2.07568e-05, gnorm=1.032, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5979
2022-10-12 17:14:21 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.8, ups=0.89, wpb=110, bsz=40, num_updates=1930, lr=2.08649e-05, gnorm=1.11, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5990
2022-10-12 17:14:32 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97, ups=0.88, wpb=110.4, bsz=40, num_updates=1940, lr=2.0973e-05, gnorm=1.058, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6002
2022-10-12 17:14:43 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.1, ups=0.9, wpb=110.2, bsz=40, num_updates=1950, lr=2.10811e-05, gnorm=1.035, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6013
2022-10-12 17:14:54 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.1, ups=0.92, wpb=108.9, bsz=40, num_updates=1960, lr=2.11892e-05, gnorm=1.039, clip=60, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=6024
2022-10-12 17:15:06 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.9, ups=0.88, wpb=110.3, bsz=40, num_updates=1970, lr=2.12973e-05, gnorm=1.176, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6035
2022-10-12 17:15:17 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.1, ups=0.88, wpb=111.8, bsz=40, num_updates=1980, lr=2.14054e-05, gnorm=0.961, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6047
2022-10-12 17:15:28 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=104.4, ups=0.94, wpb=111.2, bsz=40, num_updates=1990, lr=2.15135e-05, gnorm=1.04, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6057
2022-10-12 17:15:39 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.5, ups=0.89, wpb=109.5, bsz=40, num_updates=2000, lr=2.16216e-05, gnorm=1.002, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6069
2022-10-12 17:15:39 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 17:15:40 - train.py[line:549] - INFO: 0 / 4988
2022-10-12 17:15:40 - train.py[line:551] - INFO: load:1.14 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 17:15:41 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.87 GiB already allocated; 3.18 GiB free; 33.92 GiB reserved in total by PyTorch)
2022-10-12 17:15:41 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-12 17:15:41 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9078 MB |   10302 MB |     880 TB |     880 TB |
|       from large pool |    8933 MB |   10157 MB |     879 TB |     879 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9078 MB |   10302 MB |     880 TB |     880 TB |
|       from large pool |    8933 MB |   10157 MB |     879 TB |     879 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   34738 MB |   36468 MB |  129810 MB |   95072 MB |
|       from large pool |   34592 MB |   36316 MB |  129554 MB |   94962 MB |
|       from small pool |     146 MB |     152 MB |     256 MB |     110 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   25659 MB |   25659 MB |     953 TB |     953 TB |
|       from large pool |   25658 MB |   25658 MB |     952 TB |     952 TB |
|       from small pool |       1 MB |       1 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |   38496 K  |   38492 K  |
|       from large pool |     563    |     575    |   13267 K  |   13266 K  |
|       from small pool |    3095    |    3114    |   25228 K  |   25225 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |   38496 K  |   38492 K  |
|       from large pool |     563    |     575    |   13267 K  |   13266 K  |
|       from small pool |    3095    |    3114    |   25228 K  |   25225 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     196    |     205    |     456    |     260    |
|       from large pool |     123    |     129    |     328    |     205    |
|       from small pool |      73    |      76    |     128    |      55    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     139    |     145    |   26718 K  |   26718 K  |
|       from large pool |      95    |      97    |    5381 K  |    5381 K  |
|       from small pool |      44    |      52    |   21336 K  |   21336 K  |
|===========================================================================|

2022-10-12 17:15:41 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-12 17:18:14 - train.py[line:549] - INFO: 200 / 4988
2022-10-12 17:18:14 - train.py[line:551] - INFO: load:1.16 valid_run:153.22 task_valid:148.17 collect_output:3.97
2022-10-12 17:20:42 - train.py[line:549] - INFO: 400 / 4988
2022-10-12 17:20:42 - train.py[line:551] - INFO: load:1.19 valid_run:301.82 task_valid:291.16 collect_output:8.54
2022-10-12 17:23:15 - train.py[line:549] - INFO: 600 / 4988
2022-10-12 17:23:15 - train.py[line:551] - INFO: load:1.21 valid_run:454.13 task_valid:434.22 collect_output:16.75
2022-10-12 17:25:44 - train.py[line:549] - INFO: 800 / 4988
2022-10-12 17:25:44 - train.py[line:551] - INFO: load:1.24 valid_run:602.94 task_valid:578.99 collect_output:19.76
2022-10-12 17:28:16 - train.py[line:549] - INFO: 1000 / 4988
2022-10-12 17:28:16 - train.py[line:551] - INFO: load:1.26 valid_run:755.07 task_valid:726.34 collect_output:23.49
2022-10-12 17:30:47 - train.py[line:549] - INFO: 1200 / 4988
2022-10-12 17:30:47 - train.py[line:551] - INFO: load:1.29 valid_run:906.76 task_valid:871.99 collect_output:28.47
2022-10-12 17:33:21 - train.py[line:549] - INFO: 1400 / 4988
2022-10-12 17:33:21 - train.py[line:551] - INFO: load:1.31 valid_run:1059.78 task_valid:1017.63 collect_output:34.80
2022-10-12 17:35:52 - train.py[line:549] - INFO: 1600 / 4988
2022-10-12 17:35:52 - train.py[line:551] - INFO: load:1.34 valid_run:1210.75 task_valid:1158.49 collect_output:43.87
2022-10-12 17:38:21 - train.py[line:549] - INFO: 1800 / 4988
2022-10-12 17:38:21 - train.py[line:551] - INFO: load:1.37 valid_run:1360.44 task_valid:1303.27 collect_output:47.72
2022-10-12 17:40:50 - train.py[line:549] - INFO: 2000 / 4988
2022-10-12 17:40:50 - train.py[line:551] - INFO: load:1.39 valid_run:1508.66 task_valid:1446.12 collect_output:52.09
2022-10-12 17:43:19 - train.py[line:549] - INFO: 2200 / 4988
2022-10-12 17:43:19 - train.py[line:551] - INFO: load:1.41 valid_run:1658.09 task_valid:1590.76 collect_output:55.82
2022-10-12 17:45:49 - train.py[line:549] - INFO: 2400 / 4988
2022-10-12 17:45:49 - train.py[line:551] - INFO: load:1.44 valid_run:1807.87 task_valid:1735.30 collect_output:60.04
2022-10-12 17:48:19 - train.py[line:549] - INFO: 2600 / 4988
2022-10-12 17:48:19 - train.py[line:551] - INFO: load:1.46 valid_run:1957.63 task_valid:1876.98 collect_output:67.08
2022-10-12 17:50:49 - train.py[line:549] - INFO: 2800 / 4988
2022-10-12 17:50:49 - train.py[line:551] - INFO: load:1.49 valid_run:2108.26 task_valid:2022.92 collect_output:70.67
2022-10-12 17:53:20 - train.py[line:549] - INFO: 3000 / 4988
2022-10-12 17:53:20 - train.py[line:551] - INFO: load:1.53 valid_run:2259.02 task_valid:2170.13 collect_output:73.01
2022-10-12 17:55:51 - train.py[line:549] - INFO: 3200 / 4988
2022-10-12 17:55:51 - train.py[line:551] - INFO: load:1.56 valid_run:2410.08 task_valid:2315.51 collect_output:77.47
2022-10-12 17:58:23 - train.py[line:549] - INFO: 3400 / 4988
2022-10-12 17:58:23 - train.py[line:551] - INFO: load:1.59 valid_run:2562.06 task_valid:2461.66 collect_output:82.17
2022-10-12 18:00:55 - train.py[line:549] - INFO: 3600 / 4988
2022-10-12 18:00:55 - train.py[line:551] - INFO: load:1.62 valid_run:2713.27 task_valid:2609.52 collect_output:84.29
2022-10-12 18:03:24 - train.py[line:549] - INFO: 3800 / 4988
2022-10-12 18:03:24 - train.py[line:551] - INFO: load:1.65 valid_run:2862.40 task_valid:2752.32 collect_output:89.42
2022-10-12 18:05:55 - train.py[line:549] - INFO: 4000 / 4988
2022-10-12 18:05:55 - train.py[line:551] - INFO: load:1.67 valid_run:3013.27 task_valid:2898.37 collect_output:93.13
2022-10-12 18:08:27 - train.py[line:549] - INFO: 4200 / 4988
2022-10-12 18:08:27 - train.py[line:551] - INFO: load:1.70 valid_run:3165.63 task_valid:3043.58 collect_output:99.13
2022-10-12 18:10:57 - train.py[line:549] - INFO: 4400 / 4988
2022-10-12 18:10:57 - train.py[line:551] - INFO: load:1.73 valid_run:3315.65 task_valid:3189.01 collect_output:102.50
2022-10-12 18:13:29 - train.py[line:549] - INFO: 4600 / 4988
2022-10-12 18:13:29 - train.py[line:551] - INFO: load:1.76 valid_run:3467.65 task_valid:3336.33 collect_output:106.08
2022-10-12 18:16:01 - train.py[line:549] - INFO: 4800 / 4988
2022-10-12 18:16:01 - train.py[line:551] - INFO: load:1.78 valid_run:3619.29 task_valid:3483.53 collect_output:109.37

====================================================================================================
SGG eval:     R @ 50: 0.6692;     R @ 100: 0.7035;     R @ 500: 0.7303;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4662;    mR @ 100: 0.5182;    mR @ 500: 0.5464;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.5143) (eating:0.8235) (flying in:1.0000) (growing on:0.3750) (hanging from:0.5000) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:1.0000) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7236) (standing on:0.4663) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6692;     R @ 100: 0.7035;     R @ 500: 0.7303;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4662;    mR @ 100: 0.5182;    mR @ 500: 0.5464;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.5143) (eating:0.8235) (flying in:1.0000) (growing on:0.3750) (hanging from:0.5000) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:1.0000) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7236) (standing on:0.4663) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2022-10-12 18:18:32 - train.py[line:487] - INFO: 0.703480112044818
2022-10-12 18:18:33 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 18:18:33 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.31 | loss_v1 0 | loss_v2 0 | nll_loss 0.148 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.70348 | ppl 1.11 | vqa_score 0.5293 | wps 119 | wpb 89.9 | bsz 30 | num_updates 2000 | best_R@100 0.70348
2022-10-12 18:18:33 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2022-10-12 18:18:33 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-12 18:18:39 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-12 18:18:44 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.703480112044818) (writing took 11.383517316076905 seconds)
2022-10-12 18:18:55 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=2010, lr=2.17297e-05, gnorm=0.998, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=9865
2022-10-12 18:19:06 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.5, ups=0.88, wpb=109.3, bsz=40, num_updates=2020, lr=2.18378e-05, gnorm=1.01, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=9876
2022-10-12 18:19:18 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=2030, lr=2.19459e-05, gnorm=1.091, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9887
2022-10-12 18:19:29 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.7, ups=0.92, wpb=109.7, bsz=40, num_updates=2040, lr=2.20541e-05, gnorm=1.045, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=9898
2022-10-12 18:19:40 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=2050, lr=2.21622e-05, gnorm=0.994, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=9910
2022-10-12 18:19:51 - progress_bar.py[line:274] - INFO: epoch 001:   2061 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=2060, lr=2.22703e-05, gnorm=1.087, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9921
2022-10-12 18:20:02 - progress_bar.py[line:274] - INFO: epoch 001:   2071 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.2, ups=0.9, wpb=108.5, bsz=40, num_updates=2070, lr=2.23784e-05, gnorm=0.987, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9932
2022-10-12 18:20:14 - progress_bar.py[line:274] - INFO: epoch 001:   2081 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=2080, lr=2.24865e-05, gnorm=0.906, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9943
2022-10-12 18:20:25 - progress_bar.py[line:274] - INFO: epoch 001:   2091 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.1, ups=0.89, wpb=109.8, bsz=40, num_updates=2090, lr=2.25946e-05, gnorm=0.941, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9954
2022-10-12 18:20:36 - progress_bar.py[line:274] - INFO: epoch 001:   2101 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.8, ups=0.88, wpb=111.1, bsz=40, num_updates=2100, lr=2.27027e-05, gnorm=1.071, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=9966
2022-10-12 18:20:47 - progress_bar.py[line:274] - INFO: epoch 001:   2111 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=2110, lr=2.28108e-05, gnorm=0.989, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=9977
2022-10-12 18:20:48 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 18:21:00 - progress_bar.py[line:274] - INFO: epoch 001:   2122 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=89.2, ups=0.82, wpb=108.9, bsz=40, num_updates=2120, lr=2.29189e-05, gnorm=0.975, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=9989
2022-10-12 18:21:11 - progress_bar.py[line:274] - INFO: epoch 001:   2132 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.1, ups=0.88, wpb=108.7, bsz=40, num_updates=2130, lr=2.3027e-05, gnorm=1.055, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10001
2022-10-12 18:21:22 - progress_bar.py[line:274] - INFO: epoch 001:   2142 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=95.8, ups=0.88, wpb=108.3, bsz=40, num_updates=2140, lr=2.31351e-05, gnorm=1.134, clip=60, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10012
2022-10-12 18:21:33 - progress_bar.py[line:274] - INFO: epoch 001:   2152 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=2150, lr=2.32432e-05, gnorm=1.076, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10023
2022-10-12 18:21:45 - progress_bar.py[line:274] - INFO: epoch 001:   2162 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=2160, lr=2.33514e-05, gnorm=1.166, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10034
2022-10-12 18:21:55 - progress_bar.py[line:274] - INFO: epoch 001:   2172 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101.5, ups=0.93, wpb=109.2, bsz=40, num_updates=2170, lr=2.34595e-05, gnorm=1.195, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10045
2022-10-12 18:22:07 - progress_bar.py[line:274] - INFO: epoch 001:   2182 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=2180, lr=2.35676e-05, gnorm=0.999, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10056
2022-10-12 18:22:18 - progress_bar.py[line:274] - INFO: epoch 001:   2192 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.8, ups=0.89, wpb=110.4, bsz=40, num_updates=2190, lr=2.36757e-05, gnorm=1.051, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10067
2022-10-12 18:22:29 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.5, ups=0.92, wpb=109.4, bsz=40, num_updates=2200, lr=2.37838e-05, gnorm=1.12, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10078
2022-10-12 18:22:40 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.8, ups=0.87, wpb=111.2, bsz=40, num_updates=2210, lr=2.38919e-05, gnorm=0.976, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10090
2022-10-12 18:22:51 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=2220, lr=2.4e-05, gnorm=1.009, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10101
2022-10-12 18:23:03 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=2230, lr=2.41081e-05, gnorm=1.114, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10112
2022-10-12 18:23:14 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=94.9, ups=0.87, wpb=109.2, bsz=40, num_updates=2240, lr=2.42162e-05, gnorm=1.024, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10124
2022-10-12 18:23:25 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.7, ups=0.89, wpb=110.4, bsz=40, num_updates=2250, lr=2.43243e-05, gnorm=0.969, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10135
2022-10-12 18:23:37 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=2260, lr=2.44324e-05, gnorm=0.982, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10146
2022-10-12 18:23:48 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.4, ups=0.9, wpb=111.1, bsz=40, num_updates=2270, lr=2.45405e-05, gnorm=0.961, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10158
2022-10-12 18:23:59 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=2280, lr=2.46486e-05, gnorm=1.037, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10169
2022-10-12 18:24:10 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=2290, lr=2.47568e-05, gnorm=0.954, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10180
2022-10-12 18:24:21 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=95.2, ups=0.87, wpb=109.4, bsz=40, num_updates=2300, lr=2.48649e-05, gnorm=1.02, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=10191
2022-10-12 18:24:33 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=2310, lr=2.4973e-05, gnorm=1.005, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10202
2022-10-12 18:24:44 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.6, ups=0.9, wpb=108.9, bsz=40, num_updates=2320, lr=2.50811e-05, gnorm=1.055, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10213
2022-10-12 18:24:55 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.7, ups=0.89, wpb=109.3, bsz=40, num_updates=2330, lr=2.51892e-05, gnorm=1.13, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10225
2022-10-12 18:25:06 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=102.8, ups=0.93, wpb=110.4, bsz=40, num_updates=2340, lr=2.52973e-05, gnorm=1.032, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10235
2022-10-12 18:25:17 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96, ups=0.87, wpb=110.2, bsz=40, num_updates=2350, lr=2.54054e-05, gnorm=1.008, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10247
2022-10-12 18:25:28 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=2360, lr=2.55135e-05, gnorm=1.02, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10258
2022-10-12 18:25:40 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=2370, lr=2.56216e-05, gnorm=0.895, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10269
2022-10-12 18:25:51 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=2380, lr=2.57297e-05, gnorm=1.034, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10280
2022-10-12 18:26:02 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96, ups=0.87, wpb=110.1, bsz=40, num_updates=2390, lr=2.58378e-05, gnorm=0.985, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10292
2022-10-12 18:26:13 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98, ups=0.9, wpb=109.5, bsz=40, num_updates=2400, lr=2.59459e-05, gnorm=1.001, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10303
2022-10-12 18:26:24 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.9, ups=0.91, wpb=110.2, bsz=40, num_updates=2410, lr=2.60541e-05, gnorm=1.005, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10314
2022-10-12 18:26:35 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.2, ups=0.92, wpb=110.2, bsz=40, num_updates=2420, lr=2.61622e-05, gnorm=1.099, clip=80, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10325
2022-10-12 18:26:46 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100, ups=0.9, wpb=110.9, bsz=40, num_updates=2430, lr=2.62703e-05, gnorm=1.009, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10336
2022-10-12 18:26:57 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=101, ups=0.9, wpb=111.9, bsz=40, num_updates=2440, lr=2.63784e-05, gnorm=1.051, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10347
2022-10-12 18:27:08 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.9, ups=0.9, wpb=109.5, bsz=40, num_updates=2450, lr=2.64865e-05, gnorm=0.963, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10358
2022-10-12 18:27:19 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=103.3, ups=0.93, wpb=110.9, bsz=40, num_updates=2460, lr=2.65946e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10369
2022-10-12 18:27:30 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=101, ups=0.9, wpb=111.8, bsz=40, num_updates=2470, lr=2.67027e-05, gnorm=0.935, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10380
2022-10-12 18:27:41 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 28910 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98, ups=0.89, wpb=109.5, bsz=40, num_updates=2480, lr=2.68108e-05, gnorm=1.019, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10391
2022-10-12 18:27:53 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.3, ups=0.86, wpb=111.5, bsz=40, num_updates=2490, lr=2.69189e-05, gnorm=0.977, clip=40, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=10403
2022-10-12 18:28:04 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=2500, lr=2.7027e-05, gnorm=0.988, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10414
2022-10-12 18:28:16 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.2, ups=0.89, wpb=110.3, bsz=40, num_updates=2510, lr=2.71351e-05, gnorm=1.009, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10425
2022-10-12 18:28:27 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=2520, lr=2.72432e-05, gnorm=1.001, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10437
2022-10-12 18:28:38 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.8, ups=0.89, wpb=110.4, bsz=40, num_updates=2530, lr=2.73514e-05, gnorm=1.071, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10448
2022-10-12 18:28:49 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=103.3, ups=0.93, wpb=111, bsz=40, num_updates=2540, lr=2.74595e-05, gnorm=1.006, clip=50, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10458
2022-10-12 18:29:00 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.1, ups=0.92, wpb=108.7, bsz=40, num_updates=2550, lr=2.75676e-05, gnorm=1.005, clip=50, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10469
2022-10-12 18:29:11 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.6, ups=0.88, wpb=111.7, bsz=40, num_updates=2560, lr=2.76757e-05, gnorm=1.029, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10481
2022-10-12 18:29:22 - progress_bar.py[line:274] - INFO: epoch 001:   2572 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=2570, lr=2.77838e-05, gnorm=1.056, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10492
2022-10-12 18:29:34 - progress_bar.py[line:274] - INFO: epoch 001:   2582 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.3, ups=0.88, wpb=110, bsz=40, num_updates=2580, lr=2.78919e-05, gnorm=0.975, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10503
2022-10-12 18:29:45 - progress_bar.py[line:274] - INFO: epoch 001:   2592 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.3, ups=0.9, wpb=109.8, bsz=40, num_updates=2590, lr=2.8e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10514
2022-10-12 18:29:56 - progress_bar.py[line:274] - INFO: epoch 001:   2602 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.8, ups=0.87, wpb=111.2, bsz=40, num_updates=2600, lr=2.81081e-05, gnorm=0.958, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=10526
2022-10-12 18:30:08 - progress_bar.py[line:274] - INFO: epoch 001:   2612 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.2, ups=0.87, wpb=111.2, bsz=40, num_updates=2610, lr=2.82162e-05, gnorm=0.928, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10537
2022-10-12 18:30:19 - progress_bar.py[line:274] - INFO: epoch 001:   2622 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.6, ups=0.88, wpb=111.9, bsz=40, num_updates=2620, lr=2.83243e-05, gnorm=0.945, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10549
2022-10-12 18:30:30 - progress_bar.py[line:274] - INFO: epoch 001:   2632 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.4, ups=0.88, wpb=109.6, bsz=40, num_updates=2630, lr=2.84324e-05, gnorm=1.136, clip=70, loss_scale=1024, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=10560
2022-10-12 18:30:42 - progress_bar.py[line:274] - INFO: epoch 001:   2642 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=2640, lr=2.85405e-05, gnorm=0.925, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10571
2022-10-12 18:30:53 - progress_bar.py[line:274] - INFO: epoch 001:   2652 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.9, ups=0.89, wpb=110.7, bsz=40, num_updates=2650, lr=2.86486e-05, gnorm=1.134, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10583
2022-10-12 18:31:04 - progress_bar.py[line:274] - INFO: epoch 001:   2662 / 28910 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.6, ups=0.91, wpb=109.8, bsz=40, num_updates=2660, lr=2.87568e-05, gnorm=1.063, clip=60, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10594
2022-10-12 18:31:15 - progress_bar.py[line:274] - INFO: epoch 001:   2672 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.3, ups=0.93, wpb=107.3, bsz=40, num_updates=2670, lr=2.88649e-05, gnorm=1.024, clip=50, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10604
2022-10-12 18:31:26 - progress_bar.py[line:274] - INFO: epoch 001:   2682 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.6, ups=0.88, wpb=110.4, bsz=40, num_updates=2680, lr=2.8973e-05, gnorm=0.925, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10616
2022-10-12 18:31:38 - progress_bar.py[line:274] - INFO: epoch 001:   2692 / 28910 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.5, ups=0.87, wpb=110.4, bsz=40, num_updates=2690, lr=2.90811e-05, gnorm=1.045, clip=40, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10627
2022-10-12 18:31:49 - progress_bar.py[line:274] - INFO: epoch 001:   2702 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.1, ups=0.89, wpb=110.7, bsz=40, num_updates=2700, lr=2.91892e-05, gnorm=0.944, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10638
2022-10-12 18:31:57 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 18:32:01 - progress_bar.py[line:274] - INFO: epoch 001:   2713 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=90.3, ups=0.82, wpb=110, bsz=40, num_updates=2710, lr=2.92973e-05, gnorm=0.965, clip=40, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=10651
2022-10-12 18:32:12 - progress_bar.py[line:274] - INFO: epoch 001:   2723 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.3, ups=0.92, wpb=110.5, bsz=40, num_updates=2720, lr=2.94054e-05, gnorm=1.106, clip=50, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10662
2022-10-12 18:32:23 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=94.3, ups=0.87, wpb=108.2, bsz=40, num_updates=2730, lr=2.95135e-05, gnorm=1, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10673
2022-10-12 18:32:35 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=2740, lr=2.96216e-05, gnorm=1.045, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10684
2022-10-12 18:32:46 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.6, ups=0.9, wpb=110.1, bsz=40, num_updates=2750, lr=2.97297e-05, gnorm=0.99, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10695
2022-10-12 18:32:57 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98, ups=0.89, wpb=109.6, bsz=40, num_updates=2760, lr=2.98378e-05, gnorm=0.926, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10707
2022-10-12 18:33:08 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.1, ups=0.91, wpb=110.2, bsz=40, num_updates=2770, lr=2.99459e-05, gnorm=1.068, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10718
2022-10-12 18:33:19 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.1, ups=0.91, wpb=110.4, bsz=40, num_updates=2780, lr=3.00541e-05, gnorm=1.101, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10729
2022-10-12 18:33:30 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=2790, lr=3.01622e-05, gnorm=0.87, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10740
2022-10-12 18:33:41 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.8, ups=0.9, wpb=111.5, bsz=40, num_updates=2800, lr=3.02703e-05, gnorm=0.933, clip=30, loss_scale=512, train_wall=11, gb_free=11.4, ema_decay=0.9999, wall=10751
2022-10-12 18:33:52 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=2810, lr=3.03784e-05, gnorm=0.924, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10762
2022-10-12 18:34:03 - progress_bar.py[line:274] - INFO: epoch 001:   2823 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101.8, ups=0.92, wpb=111.1, bsz=40, num_updates=2820, lr=3.04865e-05, gnorm=1.054, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10773
2022-10-12 18:34:14 - progress_bar.py[line:274] - INFO: epoch 001:   2833 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=102.5, ups=0.93, wpb=110.1, bsz=40, num_updates=2830, lr=3.05946e-05, gnorm=0.852, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10784
2022-10-12 18:34:25 - progress_bar.py[line:274] - INFO: epoch 001:   2843 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=101.4, ups=0.91, wpb=111.7, bsz=40, num_updates=2840, lr=3.07027e-05, gnorm=0.912, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10795
2022-10-12 18:34:36 - progress_bar.py[line:274] - INFO: epoch 001:   2853 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=103.4, ups=0.94, wpb=110.4, bsz=40, num_updates=2850, lr=3.08108e-05, gnorm=1.029, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10805
2022-10-12 18:34:47 - progress_bar.py[line:274] - INFO: epoch 001:   2863 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.1, ups=0.88, wpb=109, bsz=40, num_updates=2860, lr=3.09189e-05, gnorm=0.91, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10817
2022-10-12 18:34:58 - progress_bar.py[line:274] - INFO: epoch 001:   2873 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99, ups=0.9, wpb=109.7, bsz=40, num_updates=2870, lr=3.1027e-05, gnorm=0.918, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10828
2022-10-12 18:35:10 - progress_bar.py[line:274] - INFO: epoch 001:   2883 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.6, ups=0.87, wpb=110.6, bsz=40, num_updates=2880, lr=3.11351e-05, gnorm=0.946, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10839
2022-10-12 18:35:21 - progress_bar.py[line:274] - INFO: epoch 001:   2893 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.8, ups=0.88, wpb=109.6, bsz=40, num_updates=2890, lr=3.12432e-05, gnorm=1.018, clip=50, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10851
2022-10-12 18:35:32 - progress_bar.py[line:274] - INFO: epoch 001:   2903 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100, ups=0.89, wpb=111.7, bsz=40, num_updates=2900, lr=3.13514e-05, gnorm=0.956, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10862
2022-10-12 18:35:44 - progress_bar.py[line:274] - INFO: epoch 001:   2913 / 28910 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.4, ups=0.87, wpb=110.9, bsz=40, num_updates=2910, lr=3.14595e-05, gnorm=1.126, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10873
2022-10-12 18:35:55 - progress_bar.py[line:274] - INFO: epoch 001:   2923 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.4, ups=0.92, wpb=110.6, bsz=40, num_updates=2920, lr=3.15676e-05, gnorm=0.886, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10884
2022-10-12 18:36:05 - progress_bar.py[line:274] - INFO: epoch 001:   2933 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.2, ups=0.92, wpb=110.5, bsz=40, num_updates=2930, lr=3.16757e-05, gnorm=0.915, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10895
2022-10-12 18:36:16 - progress_bar.py[line:274] - INFO: epoch 001:   2943 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.3, ups=0.91, wpb=110.5, bsz=40, num_updates=2940, lr=3.17838e-05, gnorm=0.969, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10906
2022-10-12 18:36:28 - progress_bar.py[line:274] - INFO: epoch 001:   2953 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.7, ups=0.9, wpb=111.3, bsz=40, num_updates=2950, lr=3.18919e-05, gnorm=0.994, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10917
2022-10-12 18:36:39 - progress_bar.py[line:274] - INFO: epoch 001:   2963 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.4, ups=0.87, wpb=110.2, bsz=40, num_updates=2960, lr=3.2e-05, gnorm=0.998, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10929
2022-10-12 18:36:50 - progress_bar.py[line:274] - INFO: epoch 001:   2973 / 28910 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.8, ups=0.9, wpb=109.3, bsz=40, num_updates=2970, lr=3.21081e-05, gnorm=0.972, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10940
2022-10-12 18:37:01 - progress_bar.py[line:274] - INFO: epoch 001:   2983 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=2980, lr=3.22162e-05, gnorm=0.894, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10951
2022-10-12 18:37:13 - progress_bar.py[line:274] - INFO: epoch 001:   2993 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=2990, lr=3.23243e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10962
2022-10-12 18:37:24 - progress_bar.py[line:274] - INFO: epoch 001:   3003 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=3000, lr=3.24324e-05, gnorm=0.968, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10974
2022-10-12 18:37:24 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 18:37:25 - train.py[line:549] - INFO: 0 / 4988
2022-10-12 18:37:26 - train.py[line:551] - INFO: load:1.30 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 18:39:57 - train.py[line:549] - INFO: 200 / 4988
2022-10-12 18:39:57 - train.py[line:551] - INFO: load:1.33 valid_run:151.35 task_valid:147.54 collect_output:2.76
2022-10-12 18:42:26 - train.py[line:549] - INFO: 400 / 4988
2022-10-12 18:42:26 - train.py[line:551] - INFO: load:1.36 valid_run:300.09 task_valid:290.33 collect_output:7.68
2022-10-12 18:44:58 - train.py[line:549] - INFO: 600 / 4988
2022-10-12 18:44:58 - train.py[line:551] - INFO: load:1.38 valid_run:452.80 task_valid:433.17 collect_output:16.53
2022-10-12 18:47:28 - train.py[line:549] - INFO: 800 / 4988
2022-10-12 18:47:28 - train.py[line:551] - INFO: load:1.41 valid_run:601.78 task_valid:577.92 collect_output:19.72
2022-10-12 18:50:00 - train.py[line:549] - INFO: 1000 / 4988
2022-10-12 18:50:00 - train.py[line:551] - INFO: load:1.43 valid_run:753.91 task_valid:725.06 collect_output:23.67
2022-10-12 18:52:31 - train.py[line:549] - INFO: 1200 / 4988
2022-10-12 18:52:31 - train.py[line:551] - INFO: load:1.46 valid_run:905.46 task_valid:870.37 collect_output:28.87
2022-10-12 18:55:05 - train.py[line:549] - INFO: 1400 / 4988
2022-10-12 18:55:05 - train.py[line:551] - INFO: load:1.48 valid_run:1058.69 task_valid:1016.17 collect_output:35.29
2022-10-12 18:57:36 - train.py[line:549] - INFO: 1600 / 4988
2022-10-12 18:57:36 - train.py[line:551] - INFO: load:1.51 valid_run:1209.71 task_valid:1156.90 collect_output:44.55
2022-10-12 19:00:05 - train.py[line:549] - INFO: 1800 / 4988
2022-10-12 19:00:05 - train.py[line:551] - INFO: load:1.53 valid_run:1359.35 task_valid:1301.49 collect_output:48.57
2022-10-12 19:02:35 - train.py[line:549] - INFO: 2000 / 4988
2022-10-12 19:02:35 - train.py[line:551] - INFO: load:1.56 valid_run:1508.61 task_valid:1445.56 collect_output:52.55
2022-10-12 19:05:05 - train.py[line:549] - INFO: 2200 / 4988
2022-10-12 19:05:05 - train.py[line:551] - INFO: load:1.59 valid_run:1658.71 task_valid:1591.08 collect_output:56.02
2022-10-12 19:07:35 - train.py[line:549] - INFO: 2400 / 4988
2022-10-12 19:07:35 - train.py[line:551] - INFO: load:1.62 valid_run:1809.20 task_valid:1736.87 collect_output:59.61
2022-10-12 19:10:06 - train.py[line:549] - INFO: 2600 / 4988
2022-10-12 19:10:06 - train.py[line:551] - INFO: load:1.65 valid_run:1959.72 task_valid:1879.89 collect_output:65.90
2022-10-12 19:12:37 - train.py[line:549] - INFO: 2800 / 4988
2022-10-12 19:12:37 - train.py[line:551] - INFO: load:1.69 valid_run:2110.97 task_valid:2026.32 collect_output:69.59
2022-10-12 19:15:08 - train.py[line:549] - INFO: 3000 / 4988
2022-10-12 19:15:08 - train.py[line:551] - INFO: load:1.72 valid_run:2261.57 task_valid:2173.40 collect_output:71.95
2022-10-12 19:17:38 - train.py[line:549] - INFO: 3200 / 4988
2022-10-12 19:17:38 - train.py[line:551] - INFO: load:1.75 valid_run:2411.94 task_valid:2318.13 collect_output:76.45
2022-10-12 19:20:11 - train.py[line:549] - INFO: 3400 / 4988
2022-10-12 19:20:11 - train.py[line:551] - INFO: load:1.77 valid_run:2564.28 task_valid:2464.88 collect_output:80.92
2022-10-12 19:22:42 - train.py[line:549] - INFO: 3600 / 4988
2022-10-12 19:22:42 - train.py[line:551] - INFO: load:1.80 valid_run:2715.48 task_valid:2612.67 collect_output:83.20
2022-10-12 19:25:11 - train.py[line:549] - INFO: 3800 / 4988
2022-10-12 19:25:11 - train.py[line:551] - INFO: load:1.82 valid_run:2864.15 task_valid:2755.00 collect_output:88.44
2022-10-12 19:27:41 - train.py[line:549] - INFO: 4000 / 4988
2022-10-12 19:27:41 - train.py[line:551] - INFO: load:1.85 valid_run:3014.56 task_valid:2900.32 collect_output:92.47
2022-10-12 19:30:13 - train.py[line:549] - INFO: 4200 / 4988
2022-10-12 19:30:13 - train.py[line:551] - INFO: load:1.88 valid_run:3166.47 task_valid:3044.78 collect_output:98.85
2022-10-12 19:32:42 - train.py[line:549] - INFO: 4400 / 4988
2022-10-12 19:32:42 - train.py[line:551] - INFO: load:1.90 valid_run:3315.56 task_valid:3189.08 collect_output:102.60
2022-10-12 19:35:14 - train.py[line:549] - INFO: 4600 / 4988
2022-10-12 19:35:14 - train.py[line:551] - INFO: load:1.93 valid_run:3466.74 task_valid:3334.94 collect_output:106.89
2022-10-12 19:37:45 - train.py[line:549] - INFO: 4800 / 4988
2022-10-12 19:37:45 - train.py[line:551] - INFO: load:1.95 valid_run:3618.18 task_valid:3481.42 collect_output:110.80

====================================================================================================
SGG eval:     R @ 50: 0.6705;     R @ 100: 0.7086;     R @ 500: 0.7291;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4676;    mR @ 100: 0.5147;    mR @ 500: 0.5517;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.6875) (covering:0.4429) (eating:0.8235) (flying in:0.8636) (growing on:0.5000) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7585) (standing on:0.4443) (using:0.6000) (walking in:0.0000) (walking on:0.7297) (watching:0.5556) 
--------------------------------------------------------
====================================================================================================

2022-10-12 19:40:17 - train.py[line:487] - INFO: 0.7086346574993634

====================================================================================================
SGG eval:     R @ 50: 0.6705;     R @ 100: 0.7086;     R @ 500: 0.7291;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4676;    mR @ 100: 0.5147;    mR @ 500: 0.5517;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.6875) (covering:0.4429) (eating:0.8235) (flying in:0.8636) (growing on:0.5000) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7585) (standing on:0.4443) (using:0.6000) (walking in:0.0000) (walking on:0.7297) (watching:0.5556) 
--------------------------------------------------------
====================================================================================================

2022-10-12 19:40:17 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 19:40:18 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.349 | loss_v1 0 | loss_v2 0 | nll_loss 0.198 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.708635 | ppl 1.15 | vqa_score 0.5586 | wps 118.9 | wpb 89.9 | bsz 30 | num_updates 3000 | best_R@100 0.708635
2022-10-12 19:40:18 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3000 updates
2022-10-12 19:40:18 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-12 19:40:23 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-12 19:40:28 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 0.7086346574993634) (writing took 10.608778314199299 seconds)
2022-10-12 19:40:39 - progress_bar.py[line:274] - INFO: epoch 001:   3013 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=3010, lr=3.25405e-05, gnorm=0.971, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14769
2022-10-12 19:40:50 - progress_bar.py[line:274] - INFO: epoch 001:   3023 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=3020, lr=3.26486e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14780
2022-10-12 19:41:01 - progress_bar.py[line:274] - INFO: epoch 001:   3033 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=102.1, ups=0.92, wpb=111.5, bsz=40, num_updates=3030, lr=3.27568e-05, gnorm=0.841, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14791
2022-10-12 19:41:12 - progress_bar.py[line:274] - INFO: epoch 001:   3043 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.7, ups=0.91, wpb=109, bsz=40, num_updates=3040, lr=3.28649e-05, gnorm=0.946, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14802
2022-10-12 19:41:23 - progress_bar.py[line:274] - INFO: epoch 001:   3053 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=102.6, ups=0.93, wpb=110.5, bsz=40, num_updates=3050, lr=3.2973e-05, gnorm=0.938, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=14813
2022-10-12 19:41:34 - progress_bar.py[line:274] - INFO: epoch 001:   3063 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.7, ups=0.89, wpb=111.4, bsz=40, num_updates=3060, lr=3.30811e-05, gnorm=0.908, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14824
2022-10-12 19:41:45 - progress_bar.py[line:274] - INFO: epoch 001:   3073 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.7, ups=0.92, wpb=109.5, bsz=40, num_updates=3070, lr=3.31892e-05, gnorm=0.882, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14835
2022-10-12 19:41:56 - progress_bar.py[line:274] - INFO: epoch 001:   3083 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=3080, lr=3.32973e-05, gnorm=0.851, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14846
2022-10-12 19:42:07 - progress_bar.py[line:274] - INFO: epoch 001:   3093 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.7, ups=0.91, wpb=110.1, bsz=40, num_updates=3090, lr=3.34054e-05, gnorm=0.94, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14857
2022-10-12 19:42:18 - progress_bar.py[line:274] - INFO: epoch 001:   3103 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.1, ups=0.9, wpb=109.7, bsz=40, num_updates=3100, lr=3.35135e-05, gnorm=1.004, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14868
2022-10-12 19:42:30 - progress_bar.py[line:274] - INFO: epoch 001:   3113 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.4, ups=0.89, wpb=109, bsz=40, num_updates=3110, lr=3.36216e-05, gnorm=0.86, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=14879
2022-10-12 19:42:41 - progress_bar.py[line:274] - INFO: epoch 001:   3123 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.5, ups=0.87, wpb=111.1, bsz=40, num_updates=3120, lr=3.37297e-05, gnorm=0.939, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14891
2022-10-12 19:42:52 - progress_bar.py[line:274] - INFO: epoch 001:   3133 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=103.1, ups=0.93, wpb=111.2, bsz=40, num_updates=3130, lr=3.38378e-05, gnorm=0.858, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14902
2022-10-12 19:43:03 - progress_bar.py[line:274] - INFO: epoch 001:   3143 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=95.9, ups=0.87, wpb=109.8, bsz=40, num_updates=3140, lr=3.39459e-05, gnorm=0.879, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14913
2022-10-12 19:43:14 - progress_bar.py[line:274] - INFO: epoch 001:   3153 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.9, ups=0.92, wpb=109.9, bsz=40, num_updates=3150, lr=3.40541e-05, gnorm=0.838, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14924
2022-10-12 19:43:26 - progress_bar.py[line:274] - INFO: epoch 001:   3163 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=95.1, ups=0.87, wpb=109.5, bsz=40, num_updates=3160, lr=3.41622e-05, gnorm=1.041, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14935
2022-10-12 19:43:37 - progress_bar.py[line:274] - INFO: epoch 001:   3173 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=3170, lr=3.42703e-05, gnorm=0.908, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14947
2022-10-12 19:43:48 - progress_bar.py[line:274] - INFO: epoch 001:   3183 / 28910 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=3180, lr=3.43784e-05, gnorm=0.958, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14958
2022-10-12 19:43:59 - progress_bar.py[line:274] - INFO: epoch 001:   3193 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.3, ups=0.92, wpb=109.4, bsz=40, num_updates=3190, lr=3.44865e-05, gnorm=0.83, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=14969
2022-10-12 19:44:10 - progress_bar.py[line:274] - INFO: epoch 001:   3203 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.7, ups=0.92, wpb=109.6, bsz=40, num_updates=3200, lr=3.45946e-05, gnorm=0.972, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=14980
2022-10-12 19:44:21 - progress_bar.py[line:274] - INFO: epoch 001:   3213 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.6, ups=0.88, wpb=109.4, bsz=40, num_updates=3210, lr=3.47027e-05, gnorm=1.085, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14991
2022-10-12 19:44:33 - progress_bar.py[line:274] - INFO: epoch 001:   3223 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.8, ups=0.89, wpb=108.4, bsz=40, num_updates=3220, lr=3.48108e-05, gnorm=1.023, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15002
2022-10-12 19:44:44 - progress_bar.py[line:274] - INFO: epoch 001:   3233 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=3230, lr=3.49189e-05, gnorm=0.963, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15013
2022-10-12 19:44:55 - progress_bar.py[line:274] - INFO: epoch 001:   3243 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.2, ups=0.89, wpb=109.3, bsz=40, num_updates=3240, lr=3.5027e-05, gnorm=0.982, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15024
2022-10-12 19:45:06 - progress_bar.py[line:274] - INFO: epoch 001:   3253 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.4, ups=0.88, wpb=110.2, bsz=40, num_updates=3250, lr=3.51351e-05, gnorm=0.974, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15036
2022-10-12 19:45:17 - progress_bar.py[line:274] - INFO: epoch 001:   3263 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.8, ups=0.89, wpb=109.3, bsz=40, num_updates=3260, lr=3.52432e-05, gnorm=0.873, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15047
2022-10-12 19:45:28 - progress_bar.py[line:274] - INFO: epoch 001:   3273 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.9, ups=0.92, wpb=109.8, bsz=40, num_updates=3270, lr=3.53514e-05, gnorm=1.041, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15058
2022-10-12 19:45:39 - progress_bar.py[line:274] - INFO: epoch 001:   3283 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=3280, lr=3.54595e-05, gnorm=0.913, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15069
2022-10-12 19:45:50 - progress_bar.py[line:274] - INFO: epoch 001:   3293 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=104.8, ups=0.96, wpb=109.5, bsz=40, num_updates=3290, lr=3.55676e-05, gnorm=0.845, clip=10, loss_scale=1024, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=15080
2022-10-12 19:46:01 - progress_bar.py[line:274] - INFO: epoch 001:   3303 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.4, ups=0.91, wpb=110.6, bsz=40, num_updates=3300, lr=3.56757e-05, gnorm=0.904, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15091
2022-10-12 19:46:12 - progress_bar.py[line:274] - INFO: epoch 001:   3313 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=3310, lr=3.57838e-05, gnorm=0.953, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15102
2022-10-12 19:46:22 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 19:46:24 - progress_bar.py[line:274] - INFO: epoch 001:   3324 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=90.4, ups=0.82, wpb=110.4, bsz=40, num_updates=3320, lr=3.58919e-05, gnorm=0.959, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=15114
2022-10-12 19:46:35 - progress_bar.py[line:274] - INFO: epoch 001:   3334 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.6, ups=0.91, wpb=111.1, bsz=40, num_updates=3330, lr=3.6e-05, gnorm=0.98, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15125
2022-10-12 19:46:47 - progress_bar.py[line:274] - INFO: epoch 001:   3344 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.4, ups=0.88, wpb=109.5, bsz=40, num_updates=3340, lr=3.61081e-05, gnorm=0.928, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15136
2022-10-12 19:46:58 - progress_bar.py[line:274] - INFO: epoch 001:   3354 / 28910 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.5, ups=0.89, wpb=111.6, bsz=40, num_updates=3350, lr=3.62162e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15148
2022-10-12 19:47:09 - progress_bar.py[line:274] - INFO: epoch 001:   3364 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=3360, lr=3.63243e-05, gnorm=0.867, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15159
2022-10-12 19:47:20 - progress_bar.py[line:274] - INFO: epoch 001:   3374 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.8, ups=0.9, wpb=110, bsz=40, num_updates=3370, lr=3.64324e-05, gnorm=0.909, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15170
2022-10-12 19:47:31 - progress_bar.py[line:274] - INFO: epoch 001:   3384 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.3, ups=0.9, wpb=109, bsz=40, num_updates=3380, lr=3.65405e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15181
2022-10-12 19:47:43 - progress_bar.py[line:274] - INFO: epoch 001:   3394 / 28910 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.1, ups=0.89, wpb=111.4, bsz=40, num_updates=3390, lr=3.66486e-05, gnorm=0.77, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15192
2022-10-12 19:47:54 - progress_bar.py[line:274] - INFO: epoch 001:   3404 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98, ups=0.9, wpb=109.5, bsz=40, num_updates=3400, lr=3.67568e-05, gnorm=0.932, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15203
2022-10-12 19:48:05 - progress_bar.py[line:274] - INFO: epoch 001:   3414 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.5, ups=0.89, wpb=111.7, bsz=40, num_updates=3410, lr=3.68649e-05, gnorm=0.874, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15215
2022-10-12 19:48:16 - progress_bar.py[line:274] - INFO: epoch 001:   3424 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.8, ups=0.89, wpb=109.7, bsz=40, num_updates=3420, lr=3.6973e-05, gnorm=1.064, clip=60, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15226
2022-10-12 19:48:27 - progress_bar.py[line:274] - INFO: epoch 001:   3434 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=3430, lr=3.70811e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15237
2022-10-12 19:48:38 - progress_bar.py[line:274] - INFO: epoch 001:   3444 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.9, ups=0.92, wpb=111.1, bsz=40, num_updates=3440, lr=3.71892e-05, gnorm=0.834, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15248
2022-10-12 19:48:50 - progress_bar.py[line:274] - INFO: epoch 001:   3454 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.7, ups=0.88, wpb=109.7, bsz=40, num_updates=3450, lr=3.72973e-05, gnorm=0.848, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15259
2022-10-12 19:49:00 - progress_bar.py[line:274] - INFO: epoch 001:   3464 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=102.3, ups=0.93, wpb=109.8, bsz=40, num_updates=3460, lr=3.74054e-05, gnorm=0.855, clip=10, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=15270
2022-10-12 19:49:11 - progress_bar.py[line:274] - INFO: epoch 001:   3474 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=3470, lr=3.75135e-05, gnorm=0.988, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15281
2022-10-12 19:49:23 - progress_bar.py[line:274] - INFO: epoch 001:   3484 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.9, ups=0.89, wpb=111.9, bsz=40, num_updates=3480, lr=3.76216e-05, gnorm=0.863, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15292
2022-10-12 19:49:34 - progress_bar.py[line:274] - INFO: epoch 001:   3494 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=95.8, ups=0.86, wpb=111.2, bsz=40, num_updates=3490, lr=3.77297e-05, gnorm=0.887, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=15304
2022-10-12 19:49:45 - progress_bar.py[line:274] - INFO: epoch 001:   3504 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=101.4, ups=0.93, wpb=109.2, bsz=40, num_updates=3500, lr=3.78378e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15315
2022-10-12 19:49:56 - progress_bar.py[line:274] - INFO: epoch 001:   3514 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.8, ups=0.88, wpb=109.4, bsz=40, num_updates=3510, lr=3.79459e-05, gnorm=0.991, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15326
2022-10-12 19:50:07 - progress_bar.py[line:274] - INFO: epoch 001:   3524 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.4, ups=0.91, wpb=108.7, bsz=40, num_updates=3520, lr=3.80541e-05, gnorm=0.821, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15337
2022-10-12 19:50:18 - progress_bar.py[line:274] - INFO: epoch 001:   3534 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.9, ups=0.91, wpb=110.1, bsz=40, num_updates=3530, lr=3.81622e-05, gnorm=0.85, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15348
2022-10-12 19:50:30 - progress_bar.py[line:274] - INFO: epoch 001:   3544 / 28910 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=96.6, ups=0.88, wpb=109.3, bsz=40, num_updates=3540, lr=3.82703e-05, gnorm=0.796, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15359
2022-10-12 19:50:41 - progress_bar.py[line:274] - INFO: epoch 001:   3554 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.2, ups=0.9, wpb=110.8, bsz=40, num_updates=3550, lr=3.83784e-05, gnorm=0.879, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15371
2022-10-12 19:50:52 - progress_bar.py[line:274] - INFO: epoch 001:   3564 / 28910 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=3560, lr=3.84865e-05, gnorm=0.822, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15382
2022-10-12 19:51:03 - progress_bar.py[line:274] - INFO: epoch 001:   3574 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.6, ups=0.9, wpb=111.2, bsz=40, num_updates=3570, lr=3.85946e-05, gnorm=0.927, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15393
2022-10-12 19:51:14 - progress_bar.py[line:274] - INFO: epoch 001:   3584 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=3580, lr=3.87027e-05, gnorm=0.959, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15404
2022-10-12 19:51:26 - progress_bar.py[line:274] - INFO: epoch 001:   3594 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.6, ups=0.89, wpb=111.4, bsz=40, num_updates=3590, lr=3.88108e-05, gnorm=1.028, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15415
2022-10-12 19:51:37 - progress_bar.py[line:274] - INFO: epoch 001:   3604 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=3600, lr=3.89189e-05, gnorm=0.98, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15427
2022-10-12 19:51:48 - progress_bar.py[line:274] - INFO: epoch 001:   3614 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.2, ups=0.88, wpb=110.1, bsz=40, num_updates=3610, lr=3.9027e-05, gnorm=0.84, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15438
2022-10-12 19:52:00 - progress_bar.py[line:274] - INFO: epoch 001:   3624 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.4, ups=0.88, wpb=109, bsz=40, num_updates=3620, lr=3.91351e-05, gnorm=0.842, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15449
2022-10-12 19:52:11 - progress_bar.py[line:274] - INFO: epoch 001:   3634 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=3630, lr=3.92432e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15460
2022-10-12 19:52:22 - progress_bar.py[line:274] - INFO: epoch 001:   3644 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.8, ups=0.87, wpb=112.2, bsz=40, num_updates=3640, lr=3.93514e-05, gnorm=0.787, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15472
2022-10-12 19:52:34 - progress_bar.py[line:274] - INFO: epoch 001:   3654 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.7, ups=0.89, wpb=111.7, bsz=40, num_updates=3650, lr=3.94595e-05, gnorm=0.914, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15483
2022-10-12 19:52:44 - progress_bar.py[line:274] - INFO: epoch 001:   3664 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=102.3, ups=0.92, wpb=111.4, bsz=40, num_updates=3660, lr=3.95676e-05, gnorm=0.809, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15494
2022-10-12 19:52:56 - progress_bar.py[line:274] - INFO: epoch 001:   3674 / 28910 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=3670, lr=3.96757e-05, gnorm=0.789, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15505
2022-10-12 19:53:07 - progress_bar.py[line:274] - INFO: epoch 001:   3684 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97, ups=0.88, wpb=110, bsz=40, num_updates=3680, lr=3.97838e-05, gnorm=0.92, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15517
2022-10-12 19:53:18 - progress_bar.py[line:274] - INFO: epoch 001:   3694 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.2, ups=0.91, wpb=111.2, bsz=40, num_updates=3690, lr=3.98919e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15528
2022-10-12 19:53:29 - progress_bar.py[line:274] - INFO: epoch 001:   3704 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101, ups=0.91, wpb=110.6, bsz=40, num_updates=3700, lr=4e-05, gnorm=0.784, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15539
2022-10-12 19:53:40 - progress_bar.py[line:274] - INFO: epoch 001:   3714 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.7, ups=0.88, wpb=110.6, bsz=40, num_updates=3710, lr=4.01081e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15550
2022-10-12 19:53:51 - progress_bar.py[line:274] - INFO: epoch 001:   3724 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.7, ups=0.91, wpb=110.8, bsz=40, num_updates=3720, lr=4.02162e-05, gnorm=0.865, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15561
2022-10-12 19:54:03 - progress_bar.py[line:274] - INFO: epoch 001:   3734 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96, ups=0.87, wpb=110.3, bsz=40, num_updates=3730, lr=4.03243e-05, gnorm=0.917, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15573
2022-10-12 19:54:14 - progress_bar.py[line:274] - INFO: epoch 001:   3744 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=102.2, ups=0.92, wpb=111.1, bsz=40, num_updates=3740, lr=4.04324e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15583
2022-10-12 19:54:25 - progress_bar.py[line:274] - INFO: epoch 001:   3754 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=3750, lr=4.05405e-05, gnorm=0.821, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15595
2022-10-12 19:54:36 - progress_bar.py[line:274] - INFO: epoch 001:   3764 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97, ups=0.89, wpb=109.6, bsz=40, num_updates=3760, lr=4.06486e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15606
2022-10-12 19:54:48 - progress_bar.py[line:274] - INFO: epoch 001:   3774 / 28910 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.4, ups=0.9, wpb=111, bsz=40, num_updates=3770, lr=4.07568e-05, gnorm=0.796, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15617
2022-10-12 19:54:59 - progress_bar.py[line:274] - INFO: epoch 001:   3784 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99, ups=0.9, wpb=110.5, bsz=40, num_updates=3780, lr=4.08649e-05, gnorm=0.812, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15628
2022-10-12 19:55:10 - progress_bar.py[line:274] - INFO: epoch 001:   3794 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.7, ups=0.88, wpb=109.8, bsz=40, num_updates=3790, lr=4.0973e-05, gnorm=0.735, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15640
2022-10-12 19:55:21 - progress_bar.py[line:274] - INFO: epoch 001:   3804 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.9, ups=0.92, wpb=111.2, bsz=40, num_updates=3800, lr=4.10811e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15651
2022-10-12 19:55:33 - progress_bar.py[line:274] - INFO: epoch 001:   3814 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=95.4, ups=0.87, wpb=109, bsz=40, num_updates=3810, lr=4.11892e-05, gnorm=0.918, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15662
2022-10-12 19:55:43 - progress_bar.py[line:274] - INFO: epoch 001:   3824 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=102.9, ups=0.93, wpb=110.8, bsz=40, num_updates=3820, lr=4.12973e-05, gnorm=0.881, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15673
2022-10-12 19:55:55 - progress_bar.py[line:274] - INFO: epoch 001:   3834 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=3830, lr=4.14054e-05, gnorm=0.762, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15684
2022-10-12 19:56:06 - progress_bar.py[line:274] - INFO: epoch 001:   3844 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=95.5, ups=0.87, wpb=110.2, bsz=40, num_updates=3840, lr=4.15135e-05, gnorm=0.804, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15696
2022-10-12 19:56:18 - progress_bar.py[line:274] - INFO: epoch 001:   3854 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=95.7, ups=0.87, wpb=109.7, bsz=40, num_updates=3850, lr=4.16216e-05, gnorm=0.778, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15707
2022-10-12 19:56:29 - progress_bar.py[line:274] - INFO: epoch 001:   3864 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.8, ups=0.9, wpb=109.3, bsz=40, num_updates=3860, lr=4.17297e-05, gnorm=0.963, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15718
2022-10-12 19:56:40 - progress_bar.py[line:274] - INFO: epoch 001:   3874 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.2, ups=0.88, wpb=110.2, bsz=40, num_updates=3870, lr=4.18378e-05, gnorm=0.838, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=15730
2022-10-12 19:56:51 - progress_bar.py[line:274] - INFO: epoch 001:   3884 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.7, ups=0.91, wpb=109.8, bsz=40, num_updates=3880, lr=4.19459e-05, gnorm=0.756, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15741
2022-10-12 19:57:02 - progress_bar.py[line:274] - INFO: epoch 001:   3894 / 28910 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.8, ups=0.9, wpb=112.7, bsz=40, num_updates=3890, lr=4.20541e-05, gnorm=0.699, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15752
2022-10-12 19:57:13 - progress_bar.py[line:274] - INFO: epoch 001:   3904 / 28910 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.9, ups=0.91, wpb=110.1, bsz=40, num_updates=3900, lr=4.21622e-05, gnorm=0.816, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15763
2022-10-12 19:57:24 - progress_bar.py[line:274] - INFO: epoch 001:   3914 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.1, ups=0.91, wpb=109.5, bsz=40, num_updates=3910, lr=4.22703e-05, gnorm=0.825, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15774
2022-10-12 19:57:35 - progress_bar.py[line:274] - INFO: epoch 001:   3924 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=103.1, ups=0.93, wpb=110.9, bsz=40, num_updates=3920, lr=4.23784e-05, gnorm=0.836, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15785
2022-10-12 19:57:46 - progress_bar.py[line:274] - INFO: epoch 001:   3934 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.1, ups=0.88, wpb=110, bsz=40, num_updates=3930, lr=4.24865e-05, gnorm=0.877, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15796
2022-10-12 19:57:57 - progress_bar.py[line:274] - INFO: epoch 001:   3944 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.9, ups=0.91, wpb=112.1, bsz=40, num_updates=3940, lr=4.25946e-05, gnorm=0.841, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15807
2022-10-12 19:58:08 - progress_bar.py[line:274] - INFO: epoch 001:   3954 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=102.1, ups=0.92, wpb=110.9, bsz=40, num_updates=3950, lr=4.27027e-05, gnorm=0.912, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15818
2022-10-12 19:58:14 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 19:58:20 - progress_bar.py[line:274] - INFO: epoch 001:   3965 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=93.3, ups=0.85, wpb=109.6, bsz=40, num_updates=3960, lr=4.28108e-05, gnorm=0.895, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=15830
2022-10-12 19:58:31 - progress_bar.py[line:274] - INFO: epoch 001:   3975 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.2, ups=0.88, wpb=110.2, bsz=40, num_updates=3970, lr=4.29189e-05, gnorm=0.756, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15841
2022-10-12 19:58:43 - progress_bar.py[line:274] - INFO: epoch 001:   3985 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.1, ups=0.89, wpb=108.6, bsz=40, num_updates=3980, lr=4.3027e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=15852
2022-10-12 19:58:54 - progress_bar.py[line:274] - INFO: epoch 001:   3995 / 28910 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=3990, lr=4.31351e-05, gnorm=0.711, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15864
2022-10-12 19:59:05 - progress_bar.py[line:274] - INFO: epoch 001:   4005 / 28910 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=102.4, ups=0.93, wpb=109.7, bsz=40, num_updates=4000, lr=4.32432e-05, gnorm=0.727, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=15874
2022-10-12 19:59:05 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 19:59:06 - train.py[line:549] - INFO: 0 / 4988
2022-10-12 19:59:06 - train.py[line:551] - INFO: load:1.21 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 20:01:37 - train.py[line:549] - INFO: 200 / 4988
2022-10-12 20:01:37 - train.py[line:551] - INFO: load:1.25 valid_run:151.18 task_valid:147.73 collect_output:2.39
2022-10-12 20:04:07 - train.py[line:549] - INFO: 400 / 4988
2022-10-12 20:04:07 - train.py[line:551] - INFO: load:1.28 valid_run:300.50 task_valid:292.31 collect_output:6.05
2022-10-12 20:06:39 - train.py[line:549] - INFO: 600 / 4988
2022-10-12 20:06:39 - train.py[line:551] - INFO: load:1.30 valid_run:452.57 task_valid:435.39 collect_output:13.98
2022-10-12 20:09:09 - train.py[line:549] - INFO: 800 / 4988
2022-10-12 20:09:09 - train.py[line:551] - INFO: load:1.33 valid_run:602.25 task_valid:581.25 collect_output:16.70
2022-10-12 20:11:41 - train.py[line:549] - INFO: 1000 / 4988
2022-10-12 20:11:41 - train.py[line:551] - INFO: load:1.35 valid_run:754.71 task_valid:729.13 collect_output:20.24
2022-10-12 20:14:14 - train.py[line:549] - INFO: 1200 / 4988
2022-10-12 20:14:14 - train.py[line:551] - INFO: load:1.38 valid_run:907.22 task_valid:875.60 collect_output:25.12
2022-10-12 20:16:48 - train.py[line:549] - INFO: 1400 / 4988
2022-10-12 20:16:48 - train.py[line:551] - INFO: load:1.41 valid_run:1061.18 task_valid:1023.30 collect_output:30.21
2022-10-12 20:19:20 - train.py[line:549] - INFO: 1600 / 4988
2022-10-12 20:19:20 - train.py[line:551] - INFO: load:1.43 valid_run:1213.62 task_valid:1166.84 collect_output:37.84
2022-10-12 20:21:51 - train.py[line:549] - INFO: 1800 / 4988
2022-10-12 20:21:51 - train.py[line:551] - INFO: load:1.46 valid_run:1363.93 task_valid:1312.60 collect_output:41.22
2022-10-12 20:24:20 - train.py[line:549] - INFO: 2000 / 4988
2022-10-12 20:24:20 - train.py[line:551] - INFO: load:1.48 valid_run:1513.24 task_valid:1456.79 collect_output:45.18
2022-10-12 20:26:51 - train.py[line:549] - INFO: 2200 / 4988
2022-10-12 20:26:51 - train.py[line:551] - INFO: load:1.51 valid_run:1663.79 task_valid:1603.02 collect_output:48.33
2022-10-12 20:29:22 - train.py[line:549] - INFO: 2400 / 4988
2022-10-12 20:29:22 - train.py[line:551] - INFO: load:1.54 valid_run:1814.80 task_valid:1749.36 collect_output:51.83
2022-10-12 20:31:53 - train.py[line:549] - INFO: 2600 / 4988
2022-10-12 20:31:53 - train.py[line:551] - INFO: load:1.56 valid_run:1965.59 task_valid:1892.73 collect_output:58.04
2022-10-12 20:34:24 - train.py[line:549] - INFO: 2800 / 4988
2022-10-12 20:34:24 - train.py[line:551] - INFO: load:1.61 valid_run:2116.87 task_valid:2039.23 collect_output:61.65
2022-10-12 20:36:55 - train.py[line:549] - INFO: 3000 / 4988
2022-10-12 20:36:55 - train.py[line:551] - INFO: load:1.64 valid_run:2267.95 task_valid:2186.95 collect_output:63.89
2022-10-12 20:39:26 - train.py[line:549] - INFO: 3200 / 4988
2022-10-12 20:39:26 - train.py[line:551] - INFO: load:1.67 valid_run:2418.86 task_valid:2331.84 collect_output:68.81
2022-10-12 20:41:58 - train.py[line:549] - INFO: 3400 / 4988
2022-10-12 20:41:58 - train.py[line:551] - INFO: load:1.69 valid_run:2570.53 task_valid:2477.64 collect_output:73.59
2022-10-12 20:44:32 - train.py[line:549] - INFO: 3600 / 4988
2022-10-12 20:44:32 - train.py[line:551] - INFO: load:1.72 valid_run:2724.94 task_valid:2626.46 collect_output:77.97
2022-10-12 20:47:01 - train.py[line:549] - INFO: 3800 / 4988
2022-10-12 20:47:01 - train.py[line:551] - INFO: load:1.74 valid_run:2873.64 task_valid:2768.17 collect_output:83.86
2022-10-12 20:49:34 - train.py[line:549] - INFO: 4000 / 4988
2022-10-12 20:49:34 - train.py[line:551] - INFO: load:1.77 valid_run:3026.85 task_valid:2915.01 collect_output:89.07
2022-10-12 20:52:08 - train.py[line:549] - INFO: 4200 / 4988
2022-10-12 20:52:08 - train.py[line:551] - INFO: load:1.80 valid_run:3180.83 task_valid:3061.30 collect_output:95.51
2022-10-12 20:54:41 - train.py[line:549] - INFO: 4400 / 4988
2022-10-12 20:54:41 - train.py[line:551] - INFO: load:1.84 valid_run:3333.44 task_valid:3208.51 collect_output:99.64
2022-10-12 20:57:17 - train.py[line:549] - INFO: 4600 / 4988
2022-10-12 20:57:17 - train.py[line:551] - INFO: load:1.87 valid_run:3488.93 task_valid:3358.67 collect_output:103.69
2022-10-12 20:59:49 - train.py[line:549] - INFO: 4800 / 4988
2022-10-12 20:59:49 - train.py[line:551] - INFO: load:1.91 valid_run:3641.32 task_valid:3506.00 collect_output:107.62

====================================================================================================
SGG eval:     R @ 50: 0.6748;     R @ 100: 0.7039;     R @ 500: 0.7218;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4719;    mR @ 100: 0.5022;    mR @ 500: 0.5440;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.4429) (eating:0.8235) (flying in:0.5909) (growing on:0.5000) (hanging from:0.4032) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7619) (standing on:0.4393) (using:0.6000) (walking in:0.0000) (walking on:0.7027) (watching:0.5556) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6748;     R @ 100: 0.7039;     R @ 500: 0.7218;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4719;    mR @ 100: 0.5022;    mR @ 500: 0.5440;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.4429) (eating:0.8235) (flying in:0.5909) (growing on:0.5000) (hanging from:0.4032) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7619) (standing on:0.4393) (using:0.6000) (walking in:0.0000) (walking on:0.7027) (watching:0.5556) 
--------------------------------------------------------
====================================================================================================

2022-10-12 21:02:20 - train.py[line:487] - INFO: 0.7039261013496309
2022-10-12 21:02:21 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 21:02:21 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.339 | loss_v1 0 | loss_v2 0 | nll_loss 0.185 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.703926 | ppl 1.14 | vqa_score 0.5755 | wps 118.2 | wpb 89.9 | bsz 30 | num_updates 4000 | best_R@100 0.708635
2022-10-12 21:02:21 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2022-10-12 21:02:21 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_4000.pt
2022-10-12 21:02:26 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_4000.pt
2022-10-12 21:02:29 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.7039261013496309) (writing took 8.356861428823322 seconds)
2022-10-12 21:02:40 - progress_bar.py[line:274] - INFO: epoch 001:   4015 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=0.3, ups=0, wpb=109.2, bsz=40, num_updates=4010, lr=4.33514e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19690
2022-10-12 21:02:51 - progress_bar.py[line:274] - INFO: epoch 001:   4025 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.1, ups=0.9, wpb=111.1, bsz=40, num_updates=4020, lr=4.34595e-05, gnorm=0.917, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19701
2022-10-12 21:03:02 - progress_bar.py[line:274] - INFO: epoch 001:   4035 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.4, ups=0.91, wpb=111.2, bsz=40, num_updates=4030, lr=4.35676e-05, gnorm=0.801, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=19712
2022-10-12 21:03:14 - progress_bar.py[line:274] - INFO: epoch 001:   4045 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.5, ups=0.88, wpb=111.1, bsz=40, num_updates=4040, lr=4.36757e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19723
2022-10-12 21:03:24 - progress_bar.py[line:274] - INFO: epoch 001:   4055 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=104.1, ups=0.94, wpb=110.7, bsz=40, num_updates=4050, lr=4.37838e-05, gnorm=0.724, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19734
2022-10-12 21:03:35 - progress_bar.py[line:274] - INFO: epoch 001:   4065 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=4060, lr=4.38919e-05, gnorm=0.727, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19745
2022-10-12 21:03:46 - progress_bar.py[line:274] - INFO: epoch 001:   4075 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=102.9, ups=0.93, wpb=110.6, bsz=40, num_updates=4070, lr=4.4e-05, gnorm=0.799, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19756
2022-10-12 21:03:57 - progress_bar.py[line:274] - INFO: epoch 001:   4085 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.1, ups=0.92, wpb=110.1, bsz=40, num_updates=4080, lr=4.41081e-05, gnorm=0.772, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19767
2022-10-12 21:04:09 - progress_bar.py[line:274] - INFO: epoch 001:   4095 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=95.5, ups=0.87, wpb=109.3, bsz=40, num_updates=4090, lr=4.42162e-05, gnorm=0.844, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19778
2022-10-12 21:04:20 - progress_bar.py[line:274] - INFO: epoch 001:   4105 / 28910 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=4100, lr=4.43243e-05, gnorm=0.867, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19789
2022-10-12 21:04:31 - progress_bar.py[line:274] - INFO: epoch 001:   4115 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=4110, lr=4.44324e-05, gnorm=0.932, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19800
2022-10-12 21:04:42 - progress_bar.py[line:274] - INFO: epoch 001:   4125 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.1, ups=0.88, wpb=109.8, bsz=40, num_updates=4120, lr=4.45405e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19812
2022-10-12 21:04:53 - progress_bar.py[line:274] - INFO: epoch 001:   4135 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=4130, lr=4.46486e-05, gnorm=0.758, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=19823
2022-10-12 21:05:04 - progress_bar.py[line:274] - INFO: epoch 001:   4145 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.8, ups=0.92, wpb=110, bsz=40, num_updates=4140, lr=4.47568e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19834
2022-10-12 21:05:15 - progress_bar.py[line:274] - INFO: epoch 001:   4155 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.8, ups=0.92, wpb=111, bsz=40, num_updates=4150, lr=4.48649e-05, gnorm=0.765, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19845
2022-10-12 21:05:26 - progress_bar.py[line:274] - INFO: epoch 001:   4165 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.7, ups=0.92, wpb=109.7, bsz=40, num_updates=4160, lr=4.4973e-05, gnorm=0.91, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=19856
2022-10-12 21:05:37 - progress_bar.py[line:274] - INFO: epoch 001:   4175 / 28910 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.5, ups=0.89, wpb=109, bsz=40, num_updates=4170, lr=4.50811e-05, gnorm=0.773, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19867
2022-10-12 21:05:49 - progress_bar.py[line:274] - INFO: epoch 001:   4185 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=4180, lr=4.51892e-05, gnorm=0.735, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19878
2022-10-12 21:06:00 - progress_bar.py[line:274] - INFO: epoch 001:   4195 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.7, ups=0.88, wpb=110.6, bsz=40, num_updates=4190, lr=4.52973e-05, gnorm=0.802, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19890
2022-10-12 21:06:11 - progress_bar.py[line:274] - INFO: epoch 001:   4205 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=4200, lr=4.54054e-05, gnorm=0.777, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19901
2022-10-12 21:06:22 - progress_bar.py[line:274] - INFO: epoch 001:   4215 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=4210, lr=4.55135e-05, gnorm=0.799, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19912
2022-10-12 21:06:33 - progress_bar.py[line:274] - INFO: epoch 001:   4225 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.6, ups=0.92, wpb=110.9, bsz=40, num_updates=4220, lr=4.56216e-05, gnorm=0.842, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=19923
2022-10-12 21:06:44 - progress_bar.py[line:274] - INFO: epoch 001:   4235 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.5, ups=0.88, wpb=110.3, bsz=40, num_updates=4230, lr=4.57297e-05, gnorm=0.798, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=19934
2022-10-12 21:06:55 - progress_bar.py[line:274] - INFO: epoch 001:   4245 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.7, ups=0.9, wpb=111.3, bsz=40, num_updates=4240, lr=4.58378e-05, gnorm=0.742, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19945
2022-10-12 21:07:06 - progress_bar.py[line:274] - INFO: epoch 001:   4255 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=4250, lr=4.59459e-05, gnorm=0.797, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19956
2022-10-12 21:07:18 - progress_bar.py[line:274] - INFO: epoch 001:   4265 / 28910 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=4260, lr=4.60541e-05, gnorm=0.795, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19967
2022-10-12 21:07:29 - progress_bar.py[line:274] - INFO: epoch 001:   4275 / 28910 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.2, ups=0.91, wpb=109.3, bsz=40, num_updates=4270, lr=4.61622e-05, gnorm=0.754, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19978
2022-10-12 21:07:40 - progress_bar.py[line:274] - INFO: epoch 001:   4285 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.4, ups=0.91, wpb=108.4, bsz=40, num_updates=4280, lr=4.62703e-05, gnorm=0.752, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19989
2022-10-12 21:07:50 - progress_bar.py[line:274] - INFO: epoch 001:   4295 / 28910 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=103.3, ups=0.93, wpb=110.9, bsz=40, num_updates=4290, lr=4.63784e-05, gnorm=0.828, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20000
2022-10-12 21:08:02 - progress_bar.py[line:274] - INFO: epoch 001:   4305 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=4300, lr=4.64865e-05, gnorm=0.848, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20011
2022-10-12 21:08:13 - progress_bar.py[line:274] - INFO: epoch 001:   4315 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=4310, lr=4.65946e-05, gnorm=0.843, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20023
2022-10-12 21:08:25 - progress_bar.py[line:274] - INFO: epoch 001:   4325 / 28910 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=93.9, ups=0.85, wpb=110.2, bsz=40, num_updates=4320, lr=4.67027e-05, gnorm=0.772, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=20034
2022-10-12 21:08:37 - progress_bar.py[line:274] - INFO: epoch 001:   4335 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=89.2, ups=0.82, wpb=109, bsz=40, num_updates=4330, lr=4.68108e-05, gnorm=0.765, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20046
2022-10-12 21:08:49 - progress_bar.py[line:274] - INFO: epoch 001:   4345 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=89.3, ups=0.81, wpb=110.9, bsz=40, num_updates=4340, lr=4.69189e-05, gnorm=0.809, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=20059
2022-10-12 21:09:01 - progress_bar.py[line:274] - INFO: epoch 001:   4355 / 28910 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=96, ups=0.86, wpb=111.5, bsz=40, num_updates=4350, lr=4.7027e-05, gnorm=0.727, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20071
2022-10-12 21:09:12 - progress_bar.py[line:274] - INFO: epoch 001:   4365 / 28910 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.4, ups=0.91, wpb=110.6, bsz=40, num_updates=4360, lr=4.71351e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20082
2022-10-12 21:09:23 - progress_bar.py[line:274] - INFO: epoch 001:   4375 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.7, ups=0.89, wpb=110.3, bsz=40, num_updates=4370, lr=4.72432e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20093
2022-10-12 21:09:34 - progress_bar.py[line:274] - INFO: epoch 001:   4385 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.7, ups=0.88, wpb=110.7, bsz=40, num_updates=4380, lr=4.73514e-05, gnorm=0.899, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20104
2022-10-12 21:09:46 - progress_bar.py[line:274] - INFO: epoch 001:   4395 / 28910 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=4390, lr=4.74595e-05, gnorm=0.672, clip=0, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=20115
2022-10-12 21:09:56 - progress_bar.py[line:274] - INFO: epoch 001:   4405 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=105.5, ups=0.95, wpb=110.9, bsz=40, num_updates=4400, lr=4.75676e-05, gnorm=0.748, clip=10, loss_scale=512, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=20126
2022-10-12 21:10:07 - progress_bar.py[line:274] - INFO: epoch 001:   4415 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.2, ups=0.91, wpb=110.6, bsz=40, num_updates=4410, lr=4.76757e-05, gnorm=0.712, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20137
2022-10-12 21:10:19 - progress_bar.py[line:274] - INFO: epoch 001:   4425 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.4, ups=0.86, wpb=112, bsz=40, num_updates=4420, lr=4.77838e-05, gnorm=0.754, clip=0, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=20148
2022-10-12 21:10:30 - progress_bar.py[line:274] - INFO: epoch 001:   4435 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.9, ups=0.88, wpb=110.6, bsz=40, num_updates=4430, lr=4.78919e-05, gnorm=0.744, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20160
2022-10-12 21:10:41 - progress_bar.py[line:274] - INFO: epoch 001:   4445 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=4440, lr=4.8e-05, gnorm=0.837, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20171
2022-10-12 21:10:52 - progress_bar.py[line:274] - INFO: epoch 001:   4455 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.3, ups=0.9, wpb=110.9, bsz=40, num_updates=4450, lr=4.81081e-05, gnorm=0.715, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20182
2022-10-12 21:11:04 - progress_bar.py[line:274] - INFO: epoch 001:   4465 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=4460, lr=4.82162e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20193
2022-10-12 21:11:14 - progress_bar.py[line:274] - INFO: epoch 001:   4475 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.7, ups=0.93, wpb=109.6, bsz=40, num_updates=4470, lr=4.83243e-05, gnorm=0.847, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20204
2022-10-12 21:11:26 - progress_bar.py[line:274] - INFO: epoch 001:   4485 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=4480, lr=4.84324e-05, gnorm=0.796, clip=0, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=20215
2022-10-12 21:11:37 - progress_bar.py[line:274] - INFO: epoch 001:   4495 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=4490, lr=4.85405e-05, gnorm=0.779, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20226
2022-10-12 21:11:48 - progress_bar.py[line:274] - INFO: epoch 001:   4505 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.5, ups=0.89, wpb=109.5, bsz=40, num_updates=4500, lr=4.86486e-05, gnorm=0.831, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20238
2022-10-12 21:11:59 - progress_bar.py[line:274] - INFO: epoch 001:   4515 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.7, ups=0.9, wpb=110.2, bsz=40, num_updates=4510, lr=4.87568e-05, gnorm=0.671, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20249
2022-10-12 21:12:11 - progress_bar.py[line:274] - INFO: epoch 001:   4525 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=95.8, ups=0.88, wpb=109.5, bsz=40, num_updates=4520, lr=4.88649e-05, gnorm=0.78, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20260
2022-10-12 21:12:22 - progress_bar.py[line:274] - INFO: epoch 001:   4535 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97, ups=0.89, wpb=108.4, bsz=40, num_updates=4530, lr=4.8973e-05, gnorm=0.832, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20271
2022-10-12 21:12:33 - progress_bar.py[line:274] - INFO: epoch 001:   4545 / 28910 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=4540, lr=4.90811e-05, gnorm=0.776, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20283
2022-10-12 21:12:44 - progress_bar.py[line:274] - INFO: epoch 001:   4555 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.7, ups=0.9, wpb=110.2, bsz=40, num_updates=4550, lr=4.91892e-05, gnorm=0.869, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20294
2022-10-12 21:12:45 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 21:12:57 - progress_bar.py[line:274] - INFO: epoch 001:   4566 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=89.2, ups=0.81, wpb=109.9, bsz=40, num_updates=4560, lr=4.92973e-05, gnorm=0.83, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=20306
2022-10-12 21:13:08 - progress_bar.py[line:274] - INFO: epoch 001:   4576 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=4570, lr=4.94054e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20318
2022-10-12 21:13:19 - progress_bar.py[line:274] - INFO: epoch 001:   4586 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=4580, lr=4.95135e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20329
2022-10-12 21:13:31 - progress_bar.py[line:274] - INFO: epoch 001:   4596 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.3, ups=0.88, wpb=110.3, bsz=40, num_updates=4590, lr=4.96216e-05, gnorm=0.895, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20340
2022-10-12 21:13:42 - progress_bar.py[line:274] - INFO: epoch 001:   4606 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.1, ups=0.91, wpb=108.4, bsz=40, num_updates=4600, lr=4.97297e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20351
2022-10-12 21:13:53 - progress_bar.py[line:274] - INFO: epoch 001:   4616 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=4610, lr=4.98378e-05, gnorm=0.814, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20362
2022-10-12 21:14:04 - progress_bar.py[line:274] - INFO: epoch 001:   4626 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.9, ups=0.89, wpb=108.3, bsz=40, num_updates=4620, lr=4.99459e-05, gnorm=0.796, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20374
2022-10-12 21:14:15 - progress_bar.py[line:274] - INFO: epoch 001:   4636 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99, ups=0.91, wpb=109.3, bsz=40, num_updates=4630, lr=4.99977e-05, gnorm=0.872, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20385
2022-10-12 21:14:26 - progress_bar.py[line:274] - INFO: epoch 001:   4646 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.7, ups=0.91, wpb=109.5, bsz=40, num_updates=4640, lr=4.99932e-05, gnorm=0.735, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20396
2022-10-12 21:14:37 - progress_bar.py[line:274] - INFO: epoch 001:   4656 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.2, ups=0.87, wpb=110.1, bsz=40, num_updates=4650, lr=4.99887e-05, gnorm=0.762, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20407
2022-10-12 21:14:49 - progress_bar.py[line:274] - INFO: epoch 001:   4666 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.2, ups=0.87, wpb=112.5, bsz=40, num_updates=4660, lr=4.99842e-05, gnorm=0.731, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20419
2022-10-12 21:15:00 - progress_bar.py[line:274] - INFO: epoch 001:   4676 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=4670, lr=4.99797e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20430
2022-10-12 21:15:11 - progress_bar.py[line:274] - INFO: epoch 001:   4686 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.2, ups=0.9, wpb=110.8, bsz=40, num_updates=4680, lr=4.99752e-05, gnorm=0.775, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20441
2022-10-12 21:15:22 - progress_bar.py[line:274] - INFO: epoch 001:   4696 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.1, ups=0.89, wpb=109.7, bsz=40, num_updates=4690, lr=4.99707e-05, gnorm=0.69, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20452
2022-10-12 21:15:34 - progress_bar.py[line:274] - INFO: epoch 001:   4706 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=4700, lr=4.99662e-05, gnorm=0.723, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=20463
2022-10-12 21:15:45 - progress_bar.py[line:274] - INFO: epoch 001:   4716 / 28910 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=4710, lr=4.99617e-05, gnorm=0.706, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20475
2022-10-12 21:15:56 - progress_bar.py[line:274] - INFO: epoch 001:   4726 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.4, ups=0.88, wpb=110.3, bsz=40, num_updates=4720, lr=4.99572e-05, gnorm=0.918, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20486
2022-10-12 21:16:07 - progress_bar.py[line:274] - INFO: epoch 001:   4736 / 28910 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.5, ups=0.89, wpb=110.1, bsz=40, num_updates=4730, lr=4.99527e-05, gnorm=0.742, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20497
2022-10-12 21:16:19 - progress_bar.py[line:274] - INFO: epoch 001:   4746 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=4740, lr=4.99482e-05, gnorm=0.826, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20508
2022-10-12 21:16:30 - progress_bar.py[line:274] - INFO: epoch 001:   4756 / 28910 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100, ups=0.91, wpb=110.5, bsz=40, num_updates=4750, lr=4.99437e-05, gnorm=0.788, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20519
2022-10-12 21:16:41 - progress_bar.py[line:274] - INFO: epoch 001:   4766 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.6, ups=0.91, wpb=110.7, bsz=40, num_updates=4760, lr=4.99392e-05, gnorm=0.799, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20530
2022-10-12 21:16:52 - progress_bar.py[line:274] - INFO: epoch 001:   4776 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.6, ups=0.88, wpb=110.3, bsz=40, num_updates=4770, lr=4.99347e-05, gnorm=0.773, clip=10, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=20542
2022-10-12 21:17:03 - progress_bar.py[line:274] - INFO: epoch 001:   4786 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.3, ups=0.9, wpb=108.6, bsz=40, num_updates=4780, lr=4.99302e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20553
2022-10-12 21:17:14 - progress_bar.py[line:274] - INFO: epoch 001:   4796 / 28910 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.3, ups=0.89, wpb=112.4, bsz=40, num_updates=4790, lr=4.99257e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20564
2022-10-12 21:17:25 - progress_bar.py[line:274] - INFO: epoch 001:   4806 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.5, ups=0.91, wpb=110.7, bsz=40, num_updates=4800, lr=4.99212e-05, gnorm=0.84, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20575
2022-10-12 21:17:36 - progress_bar.py[line:274] - INFO: epoch 001:   4816 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101.1, ups=0.91, wpb=110.5, bsz=40, num_updates=4810, lr=4.99167e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=20586
2022-10-12 21:17:47 - progress_bar.py[line:274] - INFO: epoch 001:   4826 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.7, ups=0.92, wpb=108.4, bsz=40, num_updates=4820, lr=4.99122e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20597
2022-10-12 21:17:59 - progress_bar.py[line:274] - INFO: epoch 001:   4836 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=4830, lr=4.99077e-05, gnorm=0.797, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20608
2022-10-12 21:18:09 - progress_bar.py[line:274] - INFO: epoch 001:   4846 / 28910 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=103, ups=0.91, wpb=112.9, bsz=40, num_updates=4840, lr=4.99032e-05, gnorm=0.702, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20619
2022-10-12 21:18:20 - progress_bar.py[line:274] - INFO: epoch 001:   4856 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=102, ups=0.93, wpb=109.7, bsz=40, num_updates=4850, lr=4.98987e-05, gnorm=0.705, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20630
2022-10-12 21:18:31 - progress_bar.py[line:274] - INFO: epoch 001:   4866 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.6, ups=0.93, wpb=109.8, bsz=40, num_updates=4860, lr=4.98942e-05, gnorm=0.895, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20641
2022-10-12 21:18:43 - progress_bar.py[line:274] - INFO: epoch 001:   4876 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=96.3, ups=0.87, wpb=110.6, bsz=40, num_updates=4870, lr=4.98897e-05, gnorm=0.794, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20652
2022-10-12 21:18:54 - progress_bar.py[line:274] - INFO: epoch 001:   4886 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=4880, lr=4.98852e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20663
2022-10-12 21:19:05 - progress_bar.py[line:274] - INFO: epoch 001:   4896 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.8, ups=0.88, wpb=111, bsz=40, num_updates=4890, lr=4.98806e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20675
2022-10-12 21:19:16 - progress_bar.py[line:274] - INFO: epoch 001:   4906 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=103.5, ups=0.94, wpb=110.4, bsz=40, num_updates=4900, lr=4.98761e-05, gnorm=0.792, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20685
2022-10-12 21:19:27 - progress_bar.py[line:274] - INFO: epoch 001:   4916 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=4910, lr=4.98716e-05, gnorm=0.764, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20696
2022-10-12 21:19:38 - progress_bar.py[line:274] - INFO: epoch 001:   4926 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=102.3, ups=0.91, wpb=112.2, bsz=40, num_updates=4920, lr=4.98671e-05, gnorm=0.717, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20707
2022-10-12 21:19:49 - progress_bar.py[line:274] - INFO: epoch 001:   4936 / 28910 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.7, ups=0.89, wpb=110.2, bsz=40, num_updates=4930, lr=4.98626e-05, gnorm=0.672, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20719
2022-10-12 21:20:00 - progress_bar.py[line:274] - INFO: epoch 001:   4946 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.3, ups=0.9, wpb=109.8, bsz=40, num_updates=4940, lr=4.98581e-05, gnorm=0.863, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20730
2022-10-12 21:20:11 - progress_bar.py[line:274] - INFO: epoch 001:   4956 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.4, ups=0.89, wpb=111.1, bsz=40, num_updates=4950, lr=4.98536e-05, gnorm=0.884, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20741
2022-10-12 21:20:23 - progress_bar.py[line:274] - INFO: epoch 001:   4966 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98, ups=0.89, wpb=109.5, bsz=40, num_updates=4960, lr=4.98491e-05, gnorm=0.822, clip=20, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=20752
2022-10-12 21:20:34 - progress_bar.py[line:274] - INFO: epoch 001:   4976 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=95.7, ups=0.88, wpb=108.7, bsz=40, num_updates=4970, lr=4.98446e-05, gnorm=0.739, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20764
2022-10-12 21:20:45 - progress_bar.py[line:274] - INFO: epoch 001:   4986 / 28910 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=4980, lr=4.98401e-05, gnorm=0.72, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20775
2022-10-12 21:20:56 - progress_bar.py[line:274] - INFO: epoch 001:   4996 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.2, ups=0.92, wpb=109.3, bsz=40, num_updates=4990, lr=4.98356e-05, gnorm=0.835, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20786
2022-10-12 21:21:07 - progress_bar.py[line:274] - INFO: epoch 001:   5006 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.1, ups=0.89, wpb=112.3, bsz=40, num_updates=5000, lr=4.98311e-05, gnorm=0.853, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20797
2022-10-12 21:21:07 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 21:21:09 - train.py[line:549] - INFO: 0 / 4988
2022-10-12 21:21:09 - train.py[line:551] - INFO: load:1.25 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 21:23:42 - train.py[line:549] - INFO: 200 / 4988
2022-10-12 21:23:42 - train.py[line:551] - INFO: load:1.28 valid_run:152.85 task_valid:149.47 collect_output:2.21
2022-10-12 21:26:12 - train.py[line:549] - INFO: 400 / 4988
2022-10-12 21:26:12 - train.py[line:551] - INFO: load:1.31 valid_run:302.59 task_valid:294.08 collect_output:6.24
2022-10-12 21:28:45 - train.py[line:549] - INFO: 600 / 4988
2022-10-12 21:28:45 - train.py[line:551] - INFO: load:1.34 valid_run:456.08 task_valid:438.58 collect_output:14.10
2022-10-12 21:31:16 - train.py[line:549] - INFO: 800 / 4988
2022-10-12 21:31:16 - train.py[line:551] - INFO: load:1.36 valid_run:607.02 task_valid:585.65 collect_output:16.82
2022-10-12 21:33:50 - train.py[line:549] - INFO: 1000 / 4988
2022-10-12 21:33:50 - train.py[line:551] - INFO: load:1.39 valid_run:761.02 task_valid:734.23 collect_output:21.16
2022-10-12 21:36:23 - train.py[line:549] - INFO: 1200 / 4988
2022-10-12 21:36:23 - train.py[line:551] - INFO: load:1.42 valid_run:914.11 task_valid:881.31 collect_output:26.06
2022-10-12 21:38:58 - train.py[line:549] - INFO: 1400 / 4988
2022-10-12 21:38:58 - train.py[line:551] - INFO: load:1.44 valid_run:1068.85 task_valid:1029.53 collect_output:31.48
2022-10-12 21:41:31 - train.py[line:549] - INFO: 1600 / 4988
2022-10-12 21:41:31 - train.py[line:551] - INFO: load:1.47 valid_run:1221.43 task_valid:1172.83 collect_output:39.60
2022-10-12 21:44:03 - train.py[line:549] - INFO: 1800 / 4988
2022-10-12 21:44:03 - train.py[line:551] - INFO: load:1.50 valid_run:1373.14 task_valid:1319.91 collect_output:43.06
2022-10-12 21:46:32 - train.py[line:549] - INFO: 2000 / 4988
2022-10-12 21:46:32 - train.py[line:551] - INFO: load:1.53 valid_run:1522.88 task_valid:1464.45 collect_output:47.19
2022-10-12 21:49:03 - train.py[line:549] - INFO: 2200 / 4988
2022-10-12 21:49:03 - train.py[line:551] - INFO: load:1.58 valid_run:1673.08 task_valid:1610.15 collect_output:50.61
2022-10-12 21:51:33 - train.py[line:549] - INFO: 2400 / 4988
2022-10-12 21:51:33 - train.py[line:551] - INFO: load:1.60 valid_run:1823.23 task_valid:1755.27 collect_output:54.59
2022-10-12 21:54:03 - train.py[line:549] - INFO: 2600 / 4988
2022-10-12 21:54:03 - train.py[line:551] - INFO: load:1.62 valid_run:1973.10 task_valid:1897.07 collect_output:61.64
2022-10-12 21:56:33 - train.py[line:549] - INFO: 2800 / 4988
2022-10-12 21:56:33 - train.py[line:551] - INFO: load:1.65 valid_run:2123.56 task_valid:2042.49 collect_output:65.66
2022-10-12 21:59:03 - train.py[line:549] - INFO: 3000 / 4988
2022-10-12 21:59:03 - train.py[line:551] - INFO: load:1.67 valid_run:2273.46 task_valid:2188.90 collect_output:68.10
2022-10-12 22:01:33 - train.py[line:549] - INFO: 3200 / 4988
2022-10-12 22:01:33 - train.py[line:551] - INFO: load:1.70 valid_run:2423.22 task_valid:2332.95 collect_output:72.80
2022-10-12 22:04:18 - train.py[line:549] - INFO: 3400 / 4988
2022-10-12 22:04:18 - train.py[line:551] - INFO: load:1.75 valid_run:2587.82 task_valid:2490.18 collect_output:78.91
2022-10-12 22:07:20 - train.py[line:549] - INFO: 3600 / 4988
2022-10-12 22:07:20 - train.py[line:551] - INFO: load:1.86 valid_run:2770.26 task_valid:2667.51 collect_output:82.33
2022-10-12 22:09:52 - train.py[line:549] - INFO: 3800 / 4988
2022-10-12 22:09:52 - train.py[line:551] - INFO: load:1.89 valid_run:2921.22 task_valid:2811.61 collect_output:88.08
2022-10-12 22:12:22 - train.py[line:549] - INFO: 4000 / 4988
2022-10-12 22:12:22 - train.py[line:551] - INFO: load:1.91 valid_run:3071.44 task_valid:2956.53 collect_output:92.33
2022-10-12 22:14:54 - train.py[line:549] - INFO: 4200 / 4988
2022-10-12 22:14:54 - train.py[line:551] - INFO: load:1.94 valid_run:3223.32 task_valid:3101.10 collect_output:98.57
2022-10-12 22:17:23 - train.py[line:549] - INFO: 4400 / 4988
2022-10-12 22:17:23 - train.py[line:551] - INFO: load:1.96 valid_run:3372.55 task_valid:3245.59 collect_output:102.29
2022-10-12 22:19:54 - train.py[line:549] - INFO: 4600 / 4988
2022-10-12 22:19:54 - train.py[line:551] - INFO: load:1.99 valid_run:3523.72 task_valid:3391.68 collect_output:106.35
2022-10-12 22:22:26 - train.py[line:549] - INFO: 4800 / 4988
2022-10-12 22:22:26 - train.py[line:551] - INFO: load:2.01 valid_run:3675.13 task_valid:3538.36 collect_output:110.03

====================================================================================================
SGG eval:     R @ 50: 0.6741;     R @ 100: 0.6943;     R @ 500: 0.7159;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4772;    mR @ 100: 0.4967;    mR @ 500: 0.5441;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.6818) (growing on:0.5000) (hanging from:0.4032) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7568) (standing on:0.3893) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.5556) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6741;     R @ 100: 0.6943;     R @ 500: 0.7159;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4772;    mR @ 100: 0.4967;    mR @ 500: 0.5441;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.6818) (growing on:0.5000) (hanging from:0.4032) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7568) (standing on:0.3893) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.5556) 
--------------------------------------------------------
====================================================================================================

2022-10-12 22:24:57 - train.py[line:487] - INFO: 0.6943230710466004
2022-10-12 22:24:57 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 22:24:57 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.354 | loss_v1 0 | loss_v2 0 | nll_loss 0.206 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.694323 | ppl 1.15 | vqa_score 0.5856 | wps 117.2 | wpb 89.9 | bsz 30 | num_updates 5000 | best_R@100 0.708635
2022-10-12 22:24:57 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 5000 updates
2022-10-12 22:24:57 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-12 22:25:03 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-12 22:25:05 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 0.6943230710466004) (writing took 8.065909889061004 seconds)
2022-10-12 22:25:16 - progress_bar.py[line:274] - INFO: epoch 001:   5016 / 28910 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=0.3, ups=0, wpb=109.8, bsz=40, num_updates=5010, lr=4.98266e-05, gnorm=0.808, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24646
2022-10-12 22:25:27 - progress_bar.py[line:274] - INFO: epoch 001:   5026 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=5020, lr=4.98221e-05, gnorm=0.802, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24657
2022-10-12 22:25:39 - progress_bar.py[line:274] - INFO: epoch 001:   5036 / 28910 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.3, ups=0.88, wpb=112.1, bsz=40, num_updates=5030, lr=4.98176e-05, gnorm=0.696, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24668
2022-10-12 22:25:50 - progress_bar.py[line:274] - INFO: epoch 001:   5046 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=5040, lr=4.98131e-05, gnorm=0.726, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24679
2022-10-12 22:26:01 - progress_bar.py[line:274] - INFO: epoch 001:   5056 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=5050, lr=4.98086e-05, gnorm=0.8, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24691
2022-10-12 22:26:12 - progress_bar.py[line:274] - INFO: epoch 001:   5066 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=102.3, ups=0.92, wpb=111.3, bsz=40, num_updates=5060, lr=4.98041e-05, gnorm=0.889, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24701
2022-10-12 22:26:21 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 22:26:24 - progress_bar.py[line:274] - INFO: epoch 001:   5077 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=90.7, ups=0.81, wpb=111.6, bsz=40, num_updates=5070, lr=4.97996e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=24714
2022-10-12 22:26:35 - progress_bar.py[line:274] - INFO: epoch 001:   5087 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.7, ups=0.88, wpb=109.6, bsz=40, num_updates=5080, lr=4.97951e-05, gnorm=0.734, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24725
2022-10-12 22:26:46 - progress_bar.py[line:274] - INFO: epoch 001:   5097 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=102.5, ups=0.93, wpb=110.1, bsz=40, num_updates=5090, lr=4.97906e-05, gnorm=0.804, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24736
2022-10-12 22:26:57 - progress_bar.py[line:274] - INFO: epoch 001:   5107 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=102.7, ups=0.93, wpb=110.5, bsz=40, num_updates=5100, lr=4.97861e-05, gnorm=0.809, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=24747
2022-10-12 22:27:09 - progress_bar.py[line:274] - INFO: epoch 001:   5117 / 28910 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=5110, lr=4.97816e-05, gnorm=0.786, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24758
2022-10-12 22:27:20 - progress_bar.py[line:274] - INFO: epoch 001:   5127 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.5, ups=0.9, wpb=110.3, bsz=40, num_updates=5120, lr=4.97771e-05, gnorm=0.71, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24769
2022-10-12 22:27:31 - progress_bar.py[line:274] - INFO: epoch 001:   5137 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=5130, lr=4.97726e-05, gnorm=0.707, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24780
2022-10-12 22:27:42 - progress_bar.py[line:274] - INFO: epoch 001:   5147 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97, ups=0.89, wpb=109, bsz=40, num_updates=5140, lr=4.9768e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=24792
2022-10-12 22:27:53 - progress_bar.py[line:274] - INFO: epoch 001:   5157 / 28910 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.8, ups=0.89, wpb=110.2, bsz=40, num_updates=5150, lr=4.97635e-05, gnorm=0.754, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24803
2022-10-12 22:28:05 - progress_bar.py[line:274] - INFO: epoch 001:   5167 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.9, ups=0.9, wpb=109.7, bsz=40, num_updates=5160, lr=4.9759e-05, gnorm=0.75, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24814
2022-10-12 22:28:15 - progress_bar.py[line:274] - INFO: epoch 001:   5177 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=101, ups=0.92, wpb=110.2, bsz=40, num_updates=5170, lr=4.97545e-05, gnorm=0.73, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24825
2022-10-12 22:28:27 - progress_bar.py[line:274] - INFO: epoch 001:   5187 / 28910 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.4, ups=0.89, wpb=110.9, bsz=40, num_updates=5180, lr=4.975e-05, gnorm=0.77, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24836
2022-10-12 22:28:38 - progress_bar.py[line:274] - INFO: epoch 001:   5197 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98, ups=0.89, wpb=110.6, bsz=40, num_updates=5190, lr=4.97455e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24848
2022-10-12 22:28:49 - progress_bar.py[line:274] - INFO: epoch 001:   5207 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.9, ups=0.93, wpb=109.7, bsz=40, num_updates=5200, lr=4.9741e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24859
2022-10-12 22:29:00 - progress_bar.py[line:274] - INFO: epoch 001:   5217 / 28910 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.3, ups=0.9, wpb=112.1, bsz=40, num_updates=5210, lr=4.97365e-05, gnorm=0.689, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24870
2022-10-12 22:29:11 - progress_bar.py[line:274] - INFO: epoch 001:   5227 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.6, ups=0.91, wpb=110.4, bsz=40, num_updates=5220, lr=4.9732e-05, gnorm=0.85, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24881
2022-10-12 22:29:23 - progress_bar.py[line:274] - INFO: epoch 001:   5237 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=95.8, ups=0.87, wpb=109.9, bsz=40, num_updates=5230, lr=4.97275e-05, gnorm=0.749, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24892
2022-10-12 22:29:34 - progress_bar.py[line:274] - INFO: epoch 001:   5247 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.5, ups=0.9, wpb=108.8, bsz=40, num_updates=5240, lr=4.9723e-05, gnorm=0.756, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24903
2022-10-12 22:29:45 - progress_bar.py[line:274] - INFO: epoch 001:   5257 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99, ups=0.91, wpb=109.2, bsz=40, num_updates=5250, lr=4.97185e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24914
2022-10-12 22:29:56 - progress_bar.py[line:274] - INFO: epoch 001:   5267 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=5260, lr=4.9714e-05, gnorm=0.823, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24926
2022-10-12 22:30:08 - progress_bar.py[line:274] - INFO: epoch 001:   5277 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.2, ups=0.88, wpb=109.9, bsz=40, num_updates=5270, lr=4.97095e-05, gnorm=0.854, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24937
2022-10-12 22:30:19 - progress_bar.py[line:274] - INFO: epoch 001:   5287 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=95.3, ups=0.88, wpb=108.5, bsz=40, num_updates=5280, lr=4.9705e-05, gnorm=0.74, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24949
2022-10-12 22:30:30 - progress_bar.py[line:274] - INFO: epoch 001:   5297 / 28910 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=102.6, ups=0.93, wpb=110.5, bsz=40, num_updates=5290, lr=4.97005e-05, gnorm=0.724, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24959
2022-10-12 22:30:41 - progress_bar.py[line:274] - INFO: epoch 001:   5307 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.7, ups=0.93, wpb=109.9, bsz=40, num_updates=5300, lr=4.9696e-05, gnorm=0.842, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24970
2022-10-12 22:30:52 - progress_bar.py[line:274] - INFO: epoch 001:   5317 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.2, ups=0.9, wpb=108.8, bsz=40, num_updates=5310, lr=4.96915e-05, gnorm=0.751, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24981
2022-10-12 22:31:03 - progress_bar.py[line:274] - INFO: epoch 001:   5327 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=5320, lr=4.9687e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24993
2022-10-12 22:31:14 - progress_bar.py[line:274] - INFO: epoch 001:   5337 / 28910 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101.5, ups=0.92, wpb=110.7, bsz=40, num_updates=5330, lr=4.96825e-05, gnorm=0.655, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25004
2022-10-12 22:31:25 - progress_bar.py[line:274] - INFO: epoch 001:   5347 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=96.9, ups=0.89, wpb=108.9, bsz=40, num_updates=5340, lr=4.9678e-05, gnorm=0.826, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25015
2022-10-12 22:31:37 - progress_bar.py[line:274] - INFO: epoch 001:   5357 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.9, ups=0.9, wpb=112.4, bsz=40, num_updates=5350, lr=4.96735e-05, gnorm=0.788, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=25026
2022-10-12 22:31:48 - progress_bar.py[line:274] - INFO: epoch 001:   5367 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.4, ups=0.91, wpb=111.8, bsz=40, num_updates=5360, lr=4.9669e-05, gnorm=0.894, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25037
2022-10-12 22:31:59 - progress_bar.py[line:274] - INFO: epoch 001:   5377 / 28910 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=5370, lr=4.96645e-05, gnorm=0.683, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25048
2022-10-12 22:32:10 - progress_bar.py[line:274] - INFO: epoch 001:   5387 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97, ups=0.87, wpb=111.2, bsz=40, num_updates=5380, lr=4.966e-05, gnorm=0.713, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25060
2022-10-12 22:32:22 - progress_bar.py[line:274] - INFO: epoch 001:   5397 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97, ups=0.87, wpb=111.1, bsz=40, num_updates=5390, lr=4.96555e-05, gnorm=0.74, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25071
2022-10-12 22:32:33 - progress_bar.py[line:274] - INFO: epoch 001:   5407 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.9, ups=0.89, wpb=109.4, bsz=40, num_updates=5400, lr=4.96509e-05, gnorm=0.776, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=25083
2022-10-12 22:32:44 - progress_bar.py[line:274] - INFO: epoch 001:   5417 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.5, ups=0.91, wpb=109.6, bsz=40, num_updates=5410, lr=4.96464e-05, gnorm=0.733, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=25094
2022-10-12 22:32:55 - progress_bar.py[line:274] - INFO: epoch 001:   5427 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.5, ups=0.9, wpb=111.4, bsz=40, num_updates=5420, lr=4.96419e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25105
2022-10-12 22:33:06 - progress_bar.py[line:274] - INFO: epoch 001:   5437 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.6, ups=0.89, wpb=109.3, bsz=40, num_updates=5430, lr=4.96374e-05, gnorm=0.773, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=25116
2022-10-12 22:33:18 - progress_bar.py[line:274] - INFO: epoch 001:   5447 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=5440, lr=4.96329e-05, gnorm=0.865, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25127
2022-10-12 22:33:29 - progress_bar.py[line:274] - INFO: epoch 001:   5457 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=5450, lr=4.96284e-05, gnorm=0.737, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25138
2022-10-12 22:33:40 - progress_bar.py[line:274] - INFO: epoch 001:   5467 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.5, ups=0.89, wpb=109.1, bsz=40, num_updates=5460, lr=4.96239e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25150
2022-10-12 22:33:51 - progress_bar.py[line:274] - INFO: epoch 001:   5477 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.5, ups=0.9, wpb=111.5, bsz=40, num_updates=5470, lr=4.96194e-05, gnorm=0.747, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25161
2022-10-12 22:34:02 - progress_bar.py[line:274] - INFO: epoch 001:   5487 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.6, ups=0.89, wpb=109.2, bsz=40, num_updates=5480, lr=4.96149e-05, gnorm=0.749, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25172
2022-10-12 22:34:14 - progress_bar.py[line:274] - INFO: epoch 001:   5497 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.5, ups=0.9, wpb=110.9, bsz=40, num_updates=5490, lr=4.96104e-05, gnorm=0.751, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25183
2022-10-12 22:34:25 - progress_bar.py[line:274] - INFO: epoch 001:   5507 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.5, ups=0.88, wpb=111.1, bsz=40, num_updates=5500, lr=4.96059e-05, gnorm=0.728, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25195
2022-10-12 22:34:36 - progress_bar.py[line:274] - INFO: epoch 001:   5517 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.2, ups=0.89, wpb=109.2, bsz=40, num_updates=5510, lr=4.96014e-05, gnorm=0.778, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25206
2022-10-12 22:34:48 - progress_bar.py[line:274] - INFO: epoch 001:   5527 / 28910 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.2, ups=0.88, wpb=111.2, bsz=40, num_updates=5520, lr=4.95969e-05, gnorm=0.769, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25217
2022-10-12 22:34:59 - progress_bar.py[line:274] - INFO: epoch 001:   5537 / 28910 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=5530, lr=4.95924e-05, gnorm=0.657, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=25229
2022-10-12 22:35:11 - progress_bar.py[line:274] - INFO: epoch 001:   5547 / 28910 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=95.5, ups=0.87, wpb=109.7, bsz=40, num_updates=5540, lr=4.95879e-05, gnorm=0.707, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25240
2022-10-12 22:35:22 - progress_bar.py[line:274] - INFO: epoch 001:   5557 / 28910 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=5550, lr=4.95834e-05, gnorm=0.745, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25251
2022-10-12 22:35:33 - progress_bar.py[line:274] - INFO: epoch 001:   5567 / 28910 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.8, ups=0.88, wpb=110.6, bsz=40, num_updates=5560, lr=4.95789e-05, gnorm=0.757, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25263
2022-10-12 22:35:44 - progress_bar.py[line:274] - INFO: epoch 001:   5577 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=5570, lr=4.95744e-05, gnorm=0.798, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25274
2022-10-12 22:35:55 - progress_bar.py[line:274] - INFO: epoch 001:   5587 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=5580, lr=4.95699e-05, gnorm=0.804, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25285
2022-10-12 22:36:07 - progress_bar.py[line:274] - INFO: epoch 001:   5597 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=5590, lr=4.95654e-05, gnorm=0.707, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25296
2022-10-12 22:36:15 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 22:36:19 - progress_bar.py[line:274] - INFO: epoch 001:   5608 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=92.1, ups=0.83, wpb=111.4, bsz=40, num_updates=5600, lr=4.95609e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=25308
2022-10-12 22:36:30 - progress_bar.py[line:274] - INFO: epoch 001:   5618 / 28910 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.9, ups=0.9, wpb=110.7, bsz=40, num_updates=5610, lr=4.95564e-05, gnorm=0.732, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=25319
2022-10-12 22:36:41 - progress_bar.py[line:274] - INFO: epoch 001:   5628 / 28910 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.1, ups=0.9, wpb=111.1, bsz=40, num_updates=5620, lr=4.95519e-05, gnorm=0.715, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25331
2022-10-12 22:36:52 - progress_bar.py[line:274] - INFO: epoch 001:   5638 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=102.4, ups=0.93, wpb=110.1, bsz=40, num_updates=5630, lr=4.95474e-05, gnorm=0.811, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25341
2022-10-12 22:37:03 - progress_bar.py[line:274] - INFO: epoch 001:   5648 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=5640, lr=4.95429e-05, gnorm=0.775, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25353
2022-10-12 22:37:14 - progress_bar.py[line:274] - INFO: epoch 001:   5658 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=5650, lr=4.95384e-05, gnorm=0.786, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25364
2022-10-12 22:37:25 - progress_bar.py[line:274] - INFO: epoch 001:   5668 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.8, ups=0.9, wpb=110, bsz=40, num_updates=5660, lr=4.95338e-05, gnorm=0.64, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25375
2022-10-12 22:37:37 - progress_bar.py[line:274] - INFO: epoch 001:   5678 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.1, ups=0.9, wpb=109.9, bsz=40, num_updates=5670, lr=4.95293e-05, gnorm=0.739, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25386
2022-10-12 22:37:48 - progress_bar.py[line:274] - INFO: epoch 001:   5688 / 28910 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=100.1, ups=0.9, wpb=110.9, bsz=40, num_updates=5680, lr=4.95248e-05, gnorm=0.666, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25397
2022-10-12 22:37:59 - progress_bar.py[line:274] - INFO: epoch 001:   5698 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.9, ups=0.89, wpb=111.6, bsz=40, num_updates=5690, lr=4.95203e-05, gnorm=0.71, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25408
2022-10-12 22:38:10 - progress_bar.py[line:274] - INFO: epoch 001:   5708 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=5700, lr=4.95158e-05, gnorm=0.787, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25420
2022-10-12 22:38:21 - progress_bar.py[line:274] - INFO: epoch 001:   5718 / 28910 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.9, ups=0.9, wpb=110.7, bsz=40, num_updates=5710, lr=4.95113e-05, gnorm=0.718, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25431
2022-10-12 22:38:32 - progress_bar.py[line:274] - INFO: epoch 001:   5728 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.5, ups=0.9, wpb=110.3, bsz=40, num_updates=5720, lr=4.95068e-05, gnorm=0.764, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25442
2022-10-12 22:38:43 - progress_bar.py[line:274] - INFO: epoch 001:   5738 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101.6, ups=0.92, wpb=111, bsz=40, num_updates=5730, lr=4.95023e-05, gnorm=0.779, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25453
2022-10-12 22:38:55 - progress_bar.py[line:274] - INFO: epoch 001:   5748 / 28910 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98, ups=0.89, wpb=109.6, bsz=40, num_updates=5740, lr=4.94978e-05, gnorm=0.863, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25464
2022-10-12 22:39:06 - progress_bar.py[line:274] - INFO: epoch 001:   5758 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97, ups=0.88, wpb=110, bsz=40, num_updates=5750, lr=4.94933e-05, gnorm=0.839, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25476
2022-10-12 22:39:17 - progress_bar.py[line:274] - INFO: epoch 001:   5768 / 28910 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=5760, lr=4.94888e-05, gnorm=0.637, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25487
2022-10-12 22:39:28 - progress_bar.py[line:274] - INFO: epoch 001:   5778 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=5770, lr=4.94843e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25498
2022-10-12 22:39:40 - progress_bar.py[line:274] - INFO: epoch 001:   5788 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=96.9, ups=0.88, wpb=109.5, bsz=40, num_updates=5780, lr=4.94798e-05, gnorm=0.75, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25509
2022-10-12 22:39:51 - progress_bar.py[line:274] - INFO: epoch 001:   5798 / 28910 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100, ups=0.89, wpb=112.1, bsz=40, num_updates=5790, lr=4.94753e-05, gnorm=0.787, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25521
2022-10-12 22:40:02 - progress_bar.py[line:274] - INFO: epoch 001:   5808 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.1, ups=0.91, wpb=107.7, bsz=40, num_updates=5800, lr=4.94708e-05, gnorm=0.713, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25532
2022-10-12 22:40:13 - progress_bar.py[line:274] - INFO: epoch 001:   5818 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=102.3, ups=0.92, wpb=111.3, bsz=40, num_updates=5810, lr=4.94663e-05, gnorm=0.688, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25543
2022-10-12 22:40:24 - progress_bar.py[line:274] - INFO: epoch 001:   5828 / 28910 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=5820, lr=4.94618e-05, gnorm=0.698, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25554
2022-10-12 22:40:35 - progress_bar.py[line:274] - INFO: epoch 001:   5838 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=5830, lr=4.94573e-05, gnorm=0.766, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25565
2022-10-12 22:40:46 - progress_bar.py[line:274] - INFO: epoch 001:   5848 / 28910 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=100.1, ups=0.91, wpb=110.4, bsz=40, num_updates=5840, lr=4.94528e-05, gnorm=0.632, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25576
2022-10-12 22:40:58 - progress_bar.py[line:274] - INFO: epoch 001:   5858 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.2, ups=0.88, wpb=109.9, bsz=40, num_updates=5850, lr=4.94483e-05, gnorm=0.747, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25587
2022-10-12 22:41:09 - progress_bar.py[line:274] - INFO: epoch 001:   5868 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.2, ups=0.91, wpb=110.6, bsz=40, num_updates=5860, lr=4.94438e-05, gnorm=0.66, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25599
2022-10-12 22:41:20 - progress_bar.py[line:274] - INFO: epoch 001:   5878 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.1, ups=0.9, wpb=109.8, bsz=40, num_updates=5870, lr=4.94393e-05, gnorm=0.655, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25610
2022-10-12 22:41:31 - progress_bar.py[line:274] - INFO: epoch 001:   5888 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=5880, lr=4.94348e-05, gnorm=0.766, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25621
2022-10-12 22:41:42 - progress_bar.py[line:274] - INFO: epoch 001:   5898 / 28910 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.2, ups=0.91, wpb=111.2, bsz=40, num_updates=5890, lr=4.94303e-05, gnorm=0.76, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25632
2022-10-12 22:41:54 - progress_bar.py[line:274] - INFO: epoch 001:   5908 / 28910 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96.7, ups=0.88, wpb=110.1, bsz=40, num_updates=5900, lr=4.94258e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25643
2022-10-12 22:42:05 - progress_bar.py[line:274] - INFO: epoch 001:   5918 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=103.3, ups=0.92, wpb=112.5, bsz=40, num_updates=5910, lr=4.94212e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25654
2022-10-12 22:42:16 - progress_bar.py[line:274] - INFO: epoch 001:   5928 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99, ups=0.9, wpb=109.5, bsz=40, num_updates=5920, lr=4.94167e-05, gnorm=0.649, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25665
2022-10-12 22:42:27 - progress_bar.py[line:274] - INFO: epoch 001:   5938 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.7, ups=0.89, wpb=110.7, bsz=40, num_updates=5930, lr=4.94122e-05, gnorm=0.746, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25677
2022-10-12 22:42:38 - progress_bar.py[line:274] - INFO: epoch 001:   5948 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=96.3, ups=0.88, wpb=109.2, bsz=40, num_updates=5940, lr=4.94077e-05, gnorm=0.76, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25688
2022-10-12 22:42:50 - progress_bar.py[line:274] - INFO: epoch 001:   5958 / 28910 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=95.7, ups=0.87, wpb=109.7, bsz=40, num_updates=5950, lr=4.94032e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25699
2022-10-12 22:43:01 - progress_bar.py[line:274] - INFO: epoch 001:   5968 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.8, ups=0.91, wpb=109.1, bsz=40, num_updates=5960, lr=4.93987e-05, gnorm=0.907, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25711
2022-10-12 22:43:12 - progress_bar.py[line:274] - INFO: epoch 001:   5978 / 28910 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=5970, lr=4.93942e-05, gnorm=0.689, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25722
2022-10-12 22:43:23 - progress_bar.py[line:274] - INFO: epoch 001:   5988 / 28910 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.9, ups=0.9, wpb=109.4, bsz=40, num_updates=5980, lr=4.93897e-05, gnorm=0.69, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=25733
2022-10-12 22:43:35 - progress_bar.py[line:274] - INFO: epoch 001:   5998 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=5990, lr=4.93852e-05, gnorm=0.796, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25744
2022-10-12 22:43:46 - progress_bar.py[line:274] - INFO: epoch 001:   6008 / 28910 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.6, ups=0.91, wpb=109.8, bsz=40, num_updates=6000, lr=4.93807e-05, gnorm=0.75, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25755
2022-10-12 22:43:46 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 22:43:47 - train.py[line:549] - INFO: 0 / 4988
2022-10-12 22:43:47 - train.py[line:551] - INFO: load:1.30 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 22:46:19 - train.py[line:549] - INFO: 200 / 4988
2022-10-12 22:46:19 - train.py[line:551] - INFO: load:1.32 valid_run:151.58 task_valid:148.13 collect_output:2.37
2022-10-12 22:48:47 - train.py[line:549] - INFO: 400 / 4988
2022-10-12 22:48:47 - train.py[line:551] - INFO: load:1.35 valid_run:299.97 task_valid:291.25 collect_output:6.63
2022-10-12 22:51:19 - train.py[line:549] - INFO: 600 / 4988
2022-10-12 22:51:19 - train.py[line:551] - INFO: load:1.37 valid_run:451.89 task_valid:434.11 collect_output:14.66
2022-10-12 22:53:49 - train.py[line:549] - INFO: 800 / 4988
2022-10-12 22:53:49 - train.py[line:551] - INFO: load:1.39 valid_run:601.05 task_valid:579.14 collect_output:17.78
2022-10-12 22:56:21 - train.py[line:549] - INFO: 1000 / 4988
2022-10-12 22:56:21 - train.py[line:551] - INFO: load:1.42 valid_run:753.32 task_valid:726.53 collect_output:21.63
2022-10-12 22:58:52 - train.py[line:549] - INFO: 1200 / 4988
2022-10-12 22:58:52 - train.py[line:551] - INFO: load:1.44 valid_run:904.75 task_valid:871.87 collect_output:26.71
2022-10-12 23:01:26 - train.py[line:549] - INFO: 1400 / 4988
2022-10-12 23:01:26 - train.py[line:551] - INFO: load:1.47 valid_run:1057.83 task_valid:1017.93 collect_output:32.70
2022-10-12 23:03:57 - train.py[line:549] - INFO: 1600 / 4988
2022-10-12 23:03:57 - train.py[line:551] - INFO: load:1.49 valid_run:1208.91 task_valid:1159.32 collect_output:41.33
2022-10-12 23:06:26 - train.py[line:549] - INFO: 1800 / 4988
2022-10-12 23:06:26 - train.py[line:551] - INFO: load:1.52 valid_run:1358.45 task_valid:1304.21 collect_output:44.95
2022-10-12 23:08:55 - train.py[line:549] - INFO: 2000 / 4988
2022-10-12 23:08:55 - train.py[line:551] - INFO: load:1.54 valid_run:1506.88 task_valid:1447.41 collect_output:49.16
2022-10-12 23:11:25 - train.py[line:549] - INFO: 2200 / 4988
2022-10-12 23:11:25 - train.py[line:551] - INFO: load:1.57 valid_run:1656.53 task_valid:1592.50 collect_output:52.65
2022-10-12 23:13:54 - train.py[line:549] - INFO: 2400 / 4988
2022-10-12 23:13:54 - train.py[line:551] - INFO: load:1.59 valid_run:1806.22 task_valid:1737.39 collect_output:56.41
2022-10-12 23:16:24 - train.py[line:549] - INFO: 2600 / 4988
2022-10-12 23:16:24 - train.py[line:551] - INFO: load:1.61 valid_run:1956.14 task_valid:1879.45 collect_output:63.19
2022-10-12 23:18:55 - train.py[line:549] - INFO: 2800 / 4988
2022-10-12 23:18:55 - train.py[line:551] - INFO: load:1.64 valid_run:2106.56 task_valid:2024.99 collect_output:67.03
2022-10-12 23:21:25 - train.py[line:549] - INFO: 3000 / 4988
2022-10-12 23:21:25 - train.py[line:551] - INFO: load:1.66 valid_run:2257.05 task_valid:2171.99 collect_output:69.43
2022-10-12 23:23:56 - train.py[line:549] - INFO: 3200 / 4988
2022-10-12 23:23:56 - train.py[line:551] - INFO: load:1.70 valid_run:2408.09 task_valid:2317.36 collect_output:73.89
2022-10-12 23:26:29 - train.py[line:549] - INFO: 3400 / 4988
2022-10-12 23:26:29 - train.py[line:551] - INFO: load:1.72 valid_run:2560.44 task_valid:2463.82 collect_output:78.63
2022-10-12 23:29:00 - train.py[line:549] - INFO: 3600 / 4988
2022-10-12 23:29:00 - train.py[line:551] - INFO: load:1.75 valid_run:2712.05 task_valid:2611.78 collect_output:81.08
2022-10-12 23:31:30 - train.py[line:549] - INFO: 3800 / 4988
2022-10-12 23:31:30 - train.py[line:551] - INFO: load:1.77 valid_run:2861.26 task_valid:2754.55 collect_output:86.29
2022-10-12 23:34:01 - train.py[line:549] - INFO: 4000 / 4988
2022-10-12 23:34:01 - train.py[line:551] - INFO: load:1.80 valid_run:3012.84 task_valid:2901.23 collect_output:90.04
2022-10-12 23:36:34 - train.py[line:549] - INFO: 4200 / 4988
2022-10-12 23:36:34 - train.py[line:551] - INFO: load:1.82 valid_run:3165.63 task_valid:3046.89 collect_output:96.03
2022-10-12 23:39:05 - train.py[line:549] - INFO: 4400 / 4988
2022-10-12 23:39:05 - train.py[line:551] - INFO: load:1.85 valid_run:3316.16 task_valid:3192.75 collect_output:99.53
2022-10-12 23:41:37 - train.py[line:549] - INFO: 4600 / 4988
2022-10-12 23:41:37 - train.py[line:551] - INFO: load:1.88 valid_run:3468.76 task_valid:3340.96 collect_output:102.74
2022-10-12 23:44:10 - train.py[line:549] - INFO: 4800 / 4988
2022-10-12 23:44:10 - train.py[line:551] - INFO: load:1.90 valid_run:3621.37 task_valid:3489.15 collect_output:106.00

====================================================================================================
SGG eval:     R @ 50: 0.6579;     R @ 100: 0.6890;     R @ 500: 0.7072;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4494;    mR @ 100: 0.4677;    mR @ 500: 0.5209;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8659) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.5000) (hanging from:0.4871) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9565) (says:0.0000) (sitting on:0.7432) (standing on:0.3743) (using:0.6000) (walking in:0.0000) (walking on:0.7027) (watching:0.5556) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6579;     R @ 100: 0.6890;     R @ 500: 0.7072;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4494;    mR @ 100: 0.4677;    mR @ 500: 0.5209;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8659) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.5000) (hanging from:0.4871) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9565) (says:0.0000) (sitting on:0.7432) (standing on:0.3743) (using:0.6000) (walking in:0.0000) (walking on:0.7027) (watching:0.5556) 
--------------------------------------------------------
====================================================================================================

2022-10-12 23:46:43 - train.py[line:487] - INFO: 0.6889624649859943
2022-10-12 23:46:43 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 23:46:43 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.34 | loss_v1 0 | loss_v2 0 | nll_loss 0.187 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.688962 | ppl 1.14 | vqa_score 0.5856 | wps 118.8 | wpb 89.9 | bsz 30 | num_updates 6000 | best_R@100 0.708635
2022-10-12 23:46:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2022-10-12 23:46:43 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-12 23:46:49 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-12 23:46:51 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.6889624649859943) (writing took 8.163881587795913 seconds)
2022-10-12 23:47:06 - progress_bar.py[line:274] - INFO: epoch 001:   6018 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=0.3, ups=0, wpb=110.7, bsz=40, num_updates=6010, lr=4.93762e-05, gnorm=0.641, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29552
2022-10-12 23:47:17 - progress_bar.py[line:274] - INFO: epoch 001:   6028 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.6, ups=0.91, wpb=109.4, bsz=40, num_updates=6020, lr=4.93717e-05, gnorm=0.704, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29567
2022-10-12 23:47:28 - progress_bar.py[line:274] - INFO: epoch 001:   6038 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=6030, lr=4.93672e-05, gnorm=0.871, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29578
2022-10-12 23:47:39 - progress_bar.py[line:274] - INFO: epoch 001:   6048 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.2, ups=0.91, wpb=111.6, bsz=40, num_updates=6040, lr=4.93627e-05, gnorm=0.724, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29589
2022-10-12 23:47:50 - progress_bar.py[line:274] - INFO: epoch 001:   6058 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.4, ups=0.91, wpb=109.6, bsz=40, num_updates=6050, lr=4.93582e-05, gnorm=0.786, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29600
2022-10-12 23:48:01 - progress_bar.py[line:274] - INFO: epoch 001:   6068 / 28910 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=6060, lr=4.93537e-05, gnorm=0.608, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29611
2022-10-12 23:48:13 - progress_bar.py[line:274] - INFO: epoch 001:   6078 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=94.3, ups=0.86, wpb=109.2, bsz=40, num_updates=6070, lr=4.93492e-05, gnorm=0.764, clip=20, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=29623
2022-10-12 23:48:24 - progress_bar.py[line:274] - INFO: epoch 001:   6088 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.6, ups=0.91, wpb=111.6, bsz=40, num_updates=6080, lr=4.93447e-05, gnorm=0.739, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29634
2022-10-12 23:48:35 - progress_bar.py[line:274] - INFO: epoch 001:   6098 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=101.5, ups=0.92, wpb=110.6, bsz=40, num_updates=6090, lr=4.93402e-05, gnorm=0.679, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29645
2022-10-12 23:48:46 - progress_bar.py[line:274] - INFO: epoch 001:   6108 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=103.1, ups=0.93, wpb=111, bsz=40, num_updates=6100, lr=4.93357e-05, gnorm=0.713, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29655
2022-10-12 23:48:57 - progress_bar.py[line:274] - INFO: epoch 001:   6118 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.7, ups=0.9, wpb=109.4, bsz=40, num_updates=6110, lr=4.93312e-05, gnorm=0.635, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29666
2022-10-12 23:49:08 - progress_bar.py[line:274] - INFO: epoch 001:   6128 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=6120, lr=4.93267e-05, gnorm=0.708, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29678
2022-10-12 23:49:19 - progress_bar.py[line:274] - INFO: epoch 001:   6138 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=6130, lr=4.93222e-05, gnorm=0.603, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29689
2022-10-12 23:49:30 - progress_bar.py[line:274] - INFO: epoch 001:   6148 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.9, ups=0.88, wpb=111, bsz=40, num_updates=6140, lr=4.93177e-05, gnorm=0.68, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29700
2022-10-12 23:49:42 - progress_bar.py[line:274] - INFO: epoch 001:   6158 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=6150, lr=4.93132e-05, gnorm=0.608, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=29711
2022-10-12 23:49:52 - progress_bar.py[line:274] - INFO: epoch 001:   6168 / 28910 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=104.2, ups=0.94, wpb=110.8, bsz=40, num_updates=6160, lr=4.93087e-05, gnorm=0.61, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=29722
2022-10-12 23:50:04 - progress_bar.py[line:274] - INFO: epoch 001:   6178 / 28910 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=6170, lr=4.93041e-05, gnorm=0.686, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29733
2022-10-12 23:50:15 - progress_bar.py[line:274] - INFO: epoch 001:   6188 / 28910 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.4, ups=0.88, wpb=110.1, bsz=40, num_updates=6180, lr=4.92996e-05, gnorm=0.686, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=29745
2022-10-12 23:50:26 - progress_bar.py[line:274] - INFO: epoch 001:   6198 / 28910 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=95.5, ups=0.87, wpb=109.2, bsz=40, num_updates=6190, lr=4.92951e-05, gnorm=0.696, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29756
2022-10-12 23:50:38 - progress_bar.py[line:274] - INFO: epoch 001:   6208 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=96.7, ups=0.88, wpb=110.5, bsz=40, num_updates=6200, lr=4.92906e-05, gnorm=0.681, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29768
2022-10-12 23:50:49 - progress_bar.py[line:274] - INFO: epoch 001:   6218 / 28910 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=6210, lr=4.92861e-05, gnorm=0.7, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29779
2022-10-12 23:51:00 - progress_bar.py[line:274] - INFO: epoch 001:   6228 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=6220, lr=4.92816e-05, gnorm=0.62, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29790
2022-10-12 23:51:09 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 23:51:13 - progress_bar.py[line:274] - INFO: epoch 001:   6239 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=90.1, ups=0.82, wpb=109.8, bsz=40, num_updates=6230, lr=4.92771e-05, gnorm=0.711, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=29802
2022-10-12 23:51:24 - progress_bar.py[line:274] - INFO: epoch 001:   6249 / 28910 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=95.2, ups=0.87, wpb=109.3, bsz=40, num_updates=6240, lr=4.92726e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29814
2022-10-12 23:51:35 - progress_bar.py[line:274] - INFO: epoch 001:   6259 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.5, ups=0.9, wpb=109.7, bsz=40, num_updates=6250, lr=4.92681e-05, gnorm=0.696, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29825
2022-10-12 23:51:47 - progress_bar.py[line:274] - INFO: epoch 001:   6269 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=95.9, ups=0.88, wpb=109.2, bsz=40, num_updates=6260, lr=4.92636e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29836
2022-10-12 23:51:58 - progress_bar.py[line:274] - INFO: epoch 001:   6279 / 28910 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.2, ups=0.9, wpb=111.5, bsz=40, num_updates=6270, lr=4.92591e-05, gnorm=0.665, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29847
2022-10-12 23:52:09 - progress_bar.py[line:274] - INFO: epoch 001:   6289 / 28910 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.7, ups=0.89, wpb=110.7, bsz=40, num_updates=6280, lr=4.92546e-05, gnorm=0.626, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29859
2022-10-12 23:52:21 - progress_bar.py[line:274] - INFO: epoch 001:   6299 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=95.5, ups=0.87, wpb=109.3, bsz=40, num_updates=6290, lr=4.92501e-05, gnorm=0.687, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=29870
2022-10-12 23:52:32 - progress_bar.py[line:274] - INFO: epoch 001:   6309 / 28910 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=96.6, ups=0.88, wpb=109.6, bsz=40, num_updates=6300, lr=4.92456e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29882
2022-10-12 23:52:43 - progress_bar.py[line:274] - INFO: epoch 001:   6319 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.5, ups=0.91, wpb=109.4, bsz=40, num_updates=6310, lr=4.92411e-05, gnorm=0.8, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29893
2022-10-12 23:52:54 - progress_bar.py[line:274] - INFO: epoch 001:   6329 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=6320, lr=4.92366e-05, gnorm=0.673, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29904
2022-10-12 23:53:05 - progress_bar.py[line:274] - INFO: epoch 001:   6339 / 28910 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.1, ups=0.88, wpb=110.1, bsz=40, num_updates=6330, lr=4.92321e-05, gnorm=0.622, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=29915
2022-10-12 23:53:17 - progress_bar.py[line:274] - INFO: epoch 001:   6349 / 28910 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=6340, lr=4.92276e-05, gnorm=0.617, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29926
2022-10-12 23:53:28 - progress_bar.py[line:274] - INFO: epoch 001:   6359 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.6, ups=0.9, wpb=109.1, bsz=40, num_updates=6350, lr=4.92231e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29937
2022-10-12 23:53:39 - progress_bar.py[line:274] - INFO: epoch 001:   6369 / 28910 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=96.9, ups=0.88, wpb=109.7, bsz=40, num_updates=6360, lr=4.92186e-05, gnorm=0.689, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29949
2022-10-12 23:53:50 - progress_bar.py[line:274] - INFO: epoch 001:   6379 / 28910 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=6370, lr=4.92141e-05, gnorm=0.735, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29960
2022-10-12 23:54:02 - progress_bar.py[line:274] - INFO: epoch 001:   6389 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=96.3, ups=0.88, wpb=109.3, bsz=40, num_updates=6380, lr=4.92096e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29971
2022-10-12 23:54:13 - progress_bar.py[line:274] - INFO: epoch 001:   6399 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=6390, lr=4.92051e-05, gnorm=0.693, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29982
2022-10-12 23:54:24 - progress_bar.py[line:274] - INFO: epoch 001:   6409 / 28910 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.6, ups=0.9, wpb=110.7, bsz=40, num_updates=6400, lr=4.92006e-05, gnorm=0.713, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29993
2022-10-12 23:54:35 - progress_bar.py[line:274] - INFO: epoch 001:   6419 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=6410, lr=4.91961e-05, gnorm=0.736, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30004
2022-10-12 23:54:46 - progress_bar.py[line:274] - INFO: epoch 001:   6429 / 28910 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.8, ups=0.89, wpb=111.2, bsz=40, num_updates=6420, lr=4.91916e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30016
2022-10-12 23:54:58 - progress_bar.py[line:274] - INFO: epoch 001:   6439 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.2, ups=0.89, wpb=109.8, bsz=40, num_updates=6430, lr=4.9187e-05, gnorm=0.716, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30027
2022-10-12 23:55:08 - progress_bar.py[line:274] - INFO: epoch 001:   6449 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.3, ups=0.92, wpb=110.6, bsz=40, num_updates=6440, lr=4.91825e-05, gnorm=0.713, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30038
2022-10-12 23:55:20 - progress_bar.py[line:274] - INFO: epoch 001:   6459 / 28910 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=95.8, ups=0.88, wpb=108.7, bsz=40, num_updates=6450, lr=4.9178e-05, gnorm=0.66, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30049
2022-10-12 23:55:31 - progress_bar.py[line:274] - INFO: epoch 001:   6469 / 28910 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=101.3, ups=0.91, wpb=111.9, bsz=40, num_updates=6460, lr=4.91735e-05, gnorm=0.643, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30060
2022-10-12 23:55:42 - progress_bar.py[line:274] - INFO: epoch 001:   6479 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=6470, lr=4.9169e-05, gnorm=0.837, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30072
2022-10-12 23:55:54 - progress_bar.py[line:274] - INFO: epoch 001:   6489 / 28910 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.9, ups=0.89, wpb=111.9, bsz=40, num_updates=6480, lr=4.91645e-05, gnorm=0.643, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30083
2022-10-12 23:56:05 - progress_bar.py[line:274] - INFO: epoch 001:   6499 / 28910 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.1, ups=0.9, wpb=109.6, bsz=40, num_updates=6490, lr=4.916e-05, gnorm=0.625, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30094
2022-10-12 23:56:16 - progress_bar.py[line:274] - INFO: epoch 001:   6509 / 28910 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.6, ups=0.91, wpb=110, bsz=40, num_updates=6500, lr=4.91555e-05, gnorm=0.753, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30105
2022-10-12 23:56:27 - progress_bar.py[line:274] - INFO: epoch 001:   6519 / 28910 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=101.7, ups=0.92, wpb=110.9, bsz=40, num_updates=6510, lr=4.9151e-05, gnorm=0.633, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30116
2022-10-12 23:56:38 - progress_bar.py[line:274] - INFO: epoch 001:   6529 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=6520, lr=4.91465e-05, gnorm=0.715, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30127
2022-10-12 23:56:49 - progress_bar.py[line:274] - INFO: epoch 001:   6539 / 28910 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.4, ups=0.89, wpb=110, bsz=40, num_updates=6530, lr=4.9142e-05, gnorm=0.689, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30138
2022-10-12 23:57:00 - progress_bar.py[line:274] - INFO: epoch 001:   6549 / 28910 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=95.8, ups=0.88, wpb=109.4, bsz=40, num_updates=6540, lr=4.91375e-05, gnorm=0.725, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30150
2022-10-12 23:57:12 - progress_bar.py[line:274] - INFO: epoch 001:   6559 / 28910 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.4, ups=0.88, wpb=110.6, bsz=40, num_updates=6550, lr=4.9133e-05, gnorm=0.745, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30161
2022-10-12 23:57:23 - progress_bar.py[line:274] - INFO: epoch 001:   6569 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.3, ups=0.91, wpb=109.4, bsz=40, num_updates=6560, lr=4.91285e-05, gnorm=0.742, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30172
2022-10-12 23:57:34 - progress_bar.py[line:274] - INFO: epoch 001:   6579 / 28910 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=6570, lr=4.9124e-05, gnorm=0.699, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=30184
2022-10-12 23:57:45 - progress_bar.py[line:274] - INFO: epoch 001:   6589 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=6580, lr=4.91195e-05, gnorm=0.735, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30195
2022-10-12 23:57:56 - progress_bar.py[line:274] - INFO: epoch 001:   6599 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.5, ups=0.89, wpb=109.2, bsz=40, num_updates=6590, lr=4.9115e-05, gnorm=0.72, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30206
2022-10-12 23:58:07 - progress_bar.py[line:274] - INFO: epoch 001:   6609 / 28910 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=6600, lr=4.91105e-05, gnorm=0.695, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30217
2022-10-12 23:58:19 - progress_bar.py[line:274] - INFO: epoch 001:   6619 / 28910 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=6610, lr=4.9106e-05, gnorm=0.674, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30228
2022-10-12 23:58:30 - progress_bar.py[line:274] - INFO: epoch 001:   6629 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.2, ups=0.91, wpb=110.6, bsz=40, num_updates=6620, lr=4.91015e-05, gnorm=0.721, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30239
2022-10-12 23:58:41 - progress_bar.py[line:274] - INFO: epoch 001:   6639 / 28910 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=96.6, ups=0.89, wpb=108.9, bsz=40, num_updates=6630, lr=4.9097e-05, gnorm=0.716, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30251
2022-10-12 23:58:52 - progress_bar.py[line:274] - INFO: epoch 001:   6649 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.9, ups=0.89, wpb=110.5, bsz=40, num_updates=6640, lr=4.90925e-05, gnorm=0.668, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30262
2022-10-12 23:59:03 - progress_bar.py[line:274] - INFO: epoch 001:   6659 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.4, ups=0.9, wpb=109.9, bsz=40, num_updates=6650, lr=4.9088e-05, gnorm=0.709, clip=0, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=30273
2022-10-12 23:59:14 - progress_bar.py[line:274] - INFO: epoch 001:   6669 / 28910 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.3, ups=0.92, wpb=109.4, bsz=40, num_updates=6660, lr=4.90835e-05, gnorm=0.712, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30284
2022-10-12 23:59:25 - progress_bar.py[line:274] - INFO: epoch 001:   6679 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100, ups=0.91, wpb=110.5, bsz=40, num_updates=6670, lr=4.9079e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30295
2022-10-12 23:59:36 - progress_bar.py[line:274] - INFO: epoch 001:   6689 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=102, ups=0.92, wpb=111.1, bsz=40, num_updates=6680, lr=4.90744e-05, gnorm=0.663, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30306
2022-10-12 23:59:48 - progress_bar.py[line:274] - INFO: epoch 001:   6699 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.1, ups=0.89, wpb=108.7, bsz=40, num_updates=6690, lr=4.90699e-05, gnorm=0.698, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30317
2022-10-12 23:59:59 - progress_bar.py[line:274] - INFO: epoch 001:   6709 / 28910 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.1, ups=0.89, wpb=110.8, bsz=40, num_updates=6700, lr=4.90654e-05, gnorm=0.808, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30329
2022-10-13 00:00:10 - progress_bar.py[line:274] - INFO: epoch 001:   6719 / 28910 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97, ups=0.88, wpb=110.1, bsz=40, num_updates=6710, lr=4.90609e-05, gnorm=0.762, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30340
2022-10-13 00:00:21 - progress_bar.py[line:274] - INFO: epoch 001:   6729 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=103, ups=0.93, wpb=110.9, bsz=40, num_updates=6720, lr=4.90564e-05, gnorm=0.706, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30351
2022-10-13 00:00:32 - progress_bar.py[line:274] - INFO: epoch 001:   6739 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.3, ups=0.9, wpb=109.7, bsz=40, num_updates=6730, lr=4.90519e-05, gnorm=0.676, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30362
2022-10-13 00:00:43 - progress_bar.py[line:274] - INFO: epoch 001:   6749 / 28910 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=6740, lr=4.90474e-05, gnorm=0.66, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30373
2022-10-13 00:00:54 - progress_bar.py[line:274] - INFO: epoch 001:   6759 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.8, ups=0.92, wpb=110.4, bsz=40, num_updates=6750, lr=4.90429e-05, gnorm=0.741, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30384
2022-10-13 00:01:05 - progress_bar.py[line:274] - INFO: epoch 001:   6769 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.7, ups=0.89, wpb=110.3, bsz=40, num_updates=6760, lr=4.90384e-05, gnorm=0.544, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30395
2022-10-13 00:01:17 - progress_bar.py[line:274] - INFO: epoch 001:   6779 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=6770, lr=4.90339e-05, gnorm=0.754, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30406
2022-10-13 00:01:28 - progress_bar.py[line:274] - INFO: epoch 001:   6789 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98, ups=0.9, wpb=108.5, bsz=40, num_updates=6780, lr=4.90294e-05, gnorm=0.657, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30417
2022-10-13 00:01:39 - progress_bar.py[line:274] - INFO: epoch 001:   6799 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=6790, lr=4.90249e-05, gnorm=0.622, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30428
2022-10-13 00:01:50 - progress_bar.py[line:274] - INFO: epoch 001:   6809 / 28910 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.2, ups=0.88, wpb=110.2, bsz=40, num_updates=6800, lr=4.90204e-05, gnorm=0.671, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30440
2022-10-13 00:01:51 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 00:02:02 - progress_bar.py[line:274] - INFO: epoch 001:   6820 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=91.2, ups=0.83, wpb=109.7, bsz=40, num_updates=6810, lr=4.90159e-05, gnorm=0.593, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=30452
2022-10-13 00:02:13 - progress_bar.py[line:274] - INFO: epoch 001:   6830 / 28910 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=96.5, ups=0.88, wpb=109.2, bsz=40, num_updates=6820, lr=4.90114e-05, gnorm=0.732, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30463
2022-10-13 00:02:24 - progress_bar.py[line:274] - INFO: epoch 001:   6840 / 28910 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.5, ups=0.91, wpb=109.7, bsz=40, num_updates=6830, lr=4.90069e-05, gnorm=0.766, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30474
2022-10-13 00:02:36 - progress_bar.py[line:274] - INFO: epoch 001:   6850 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=6840, lr=4.90024e-05, gnorm=0.69, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30485
2022-10-13 00:02:46 - progress_bar.py[line:274] - INFO: epoch 001:   6860 / 28910 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=102.6, ups=0.93, wpb=110.4, bsz=40, num_updates=6850, lr=4.89979e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30496
2022-10-13 00:02:57 - progress_bar.py[line:274] - INFO: epoch 001:   6870 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=6860, lr=4.89934e-05, gnorm=0.745, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30507
2022-10-13 00:03:08 - progress_bar.py[line:274] - INFO: epoch 001:   6880 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.5, ups=0.91, wpb=110.4, bsz=40, num_updates=6870, lr=4.89889e-05, gnorm=0.787, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30518
2022-10-13 00:03:20 - progress_bar.py[line:274] - INFO: epoch 001:   6890 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.5, ups=0.88, wpb=111.7, bsz=40, num_updates=6880, lr=4.89844e-05, gnorm=0.619, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30529
2022-10-13 00:03:31 - progress_bar.py[line:274] - INFO: epoch 001:   6900 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97, ups=0.88, wpb=110.4, bsz=40, num_updates=6890, lr=4.89799e-05, gnorm=0.608, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30541
2022-10-13 00:03:42 - progress_bar.py[line:274] - INFO: epoch 001:   6910 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=6900, lr=4.89754e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30552
2022-10-13 00:03:53 - progress_bar.py[line:274] - INFO: epoch 001:   6920 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=6910, lr=4.89709e-05, gnorm=0.656, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30563
2022-10-13 00:04:05 - progress_bar.py[line:274] - INFO: epoch 001:   6930 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=6920, lr=4.89664e-05, gnorm=0.7, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30574
2022-10-13 00:04:16 - progress_bar.py[line:274] - INFO: epoch 001:   6940 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.3, ups=0.9, wpb=110.9, bsz=40, num_updates=6930, lr=4.89619e-05, gnorm=0.672, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30585
2022-10-13 00:04:27 - progress_bar.py[line:274] - INFO: epoch 001:   6950 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.8, ups=0.91, wpb=109.9, bsz=40, num_updates=6940, lr=4.89573e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30596
2022-10-13 00:04:38 - progress_bar.py[line:274] - INFO: epoch 001:   6960 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=96.5, ups=0.87, wpb=110.9, bsz=40, num_updates=6950, lr=4.89528e-05, gnorm=0.702, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30608
2022-10-13 00:04:49 - progress_bar.py[line:274] - INFO: epoch 001:   6970 / 28910 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101.7, ups=0.91, wpb=112.2, bsz=40, num_updates=6960, lr=4.89483e-05, gnorm=0.579, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30619
2022-10-13 00:05:00 - progress_bar.py[line:274] - INFO: epoch 001:   6980 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.3, ups=0.91, wpb=110.8, bsz=40, num_updates=6970, lr=4.89438e-05, gnorm=0.608, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30630
2022-10-13 00:05:11 - progress_bar.py[line:274] - INFO: epoch 001:   6990 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=6980, lr=4.89393e-05, gnorm=0.68, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30641
2022-10-13 00:05:22 - progress_bar.py[line:274] - INFO: epoch 001:   7000 / 28910 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.7, ups=0.92, wpb=109.9, bsz=40, num_updates=6990, lr=4.89348e-05, gnorm=0.574, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30652
2022-10-13 00:05:33 - progress_bar.py[line:274] - INFO: epoch 001:   7010 / 28910 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=102.1, ups=0.92, wpb=111.1, bsz=40, num_updates=7000, lr=4.89303e-05, gnorm=0.631, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30663
2022-10-13 00:05:33 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 00:05:35 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 00:05:35 - train.py[line:551] - INFO: load:1.26 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 00:05:36 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.51 GiB (GPU 0; 39.59 GiB total capacity; 8.50 GiB already allocated; 1.72 GiB free; 35.39 GiB reserved in total by PyTorch)
2022-10-13 00:05:36 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 8         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8705 MB |   14124 MB |    4420 TB |    4420 TB |
|       from large pool |    8560 MB |   13979 MB |    4418 TB |    4418 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8705 MB |   14124 MB |    4420 TB |    4420 TB |
|       from large pool |    8560 MB |   13979 MB |    4418 TB |    4418 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36242 MB |   37150 MB |  120646 MB |   84404 MB |
|       from large pool |   36096 MB |   36998 MB |  120384 MB |   84288 MB |
|       from small pool |     146 MB |     152 MB |     262 MB |     116 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   27536 MB |   27536 MB |    4382 TB |    4382 TB |
|       from large pool |   27535 MB |   27535 MB |    4380 TB |    4380 TB |
|       from small pool |       1 MB |       1 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3668    |    3682    |  204393 K  |  204390 K  |
|       from large pool |     563    |     575    |   66102 K  |   66101 K  |
|       from small pool |    3105    |    3114    |  138291 K  |  138288 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3668    |    3682    |  204393 K  |  204390 K  |
|       from large pool |     563    |     575    |   66102 K  |   66101 K  |
|       from small pool |    3105    |    3114    |  138291 K  |  138288 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     195    |     199    |     448    |     253    |
|       from large pool |     122    |     123    |     317    |     195    |
|       from small pool |      73    |      76    |     131    |      58    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     125    |     136    |  145148 K  |  145148 K  |
|       from large pool |      89    |      90    |   24914 K  |   24914 K  |
|       from small pool |      36    |      49    |  120233 K  |  120233 K  |
|===========================================================================|

2022-10-13 00:05:36 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-13 00:05:36 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-13 00:08:08 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 00:08:08 - train.py[line:551] - INFO: load:1.29 valid_run:153.26 task_valid:148.11 collect_output:2.51
2022-10-13 00:10:36 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 00:10:36 - train.py[line:551] - INFO: load:1.31 valid_run:301.18 task_valid:290.74 collect_output:6.81
2022-10-13 00:13:08 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 00:13:08 - train.py[line:551] - INFO: load:1.33 valid_run:453.02 task_valid:433.40 collect_output:14.99
2022-10-13 00:15:37 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 00:15:37 - train.py[line:551] - INFO: load:1.36 valid_run:601.97 task_valid:578.13 collect_output:18.24
2022-10-13 00:18:09 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 00:18:09 - train.py[line:551] - INFO: load:1.38 valid_run:753.87 task_valid:725.14 collect_output:22.09
2022-10-13 00:20:40 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 00:20:40 - train.py[line:551] - INFO: load:1.41 valid_run:905.13 task_valid:870.36 collect_output:27.12
2022-10-13 00:23:13 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 00:23:13 - train.py[line:551] - INFO: load:1.43 valid_run:1058.32 task_valid:1016.19 collect_output:33.50
2022-10-13 00:25:44 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 00:25:44 - train.py[line:551] - INFO: load:1.46 valid_run:1209.15 task_valid:1157.05 collect_output:42.45
2022-10-13 00:28:14 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 00:28:14 - train.py[line:551] - INFO: load:1.48 valid_run:1358.51 task_valid:1301.67 collect_output:46.17
2022-10-13 00:30:42 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 00:30:42 - train.py[line:551] - INFO: load:1.51 valid_run:1506.85 task_valid:1444.82 collect_output:50.34
2022-10-13 00:33:12 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 00:33:12 - train.py[line:551] - INFO: load:1.53 valid_run:1656.27 task_valid:1589.46 collect_output:54.11
2022-10-13 00:35:41 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 00:35:41 - train.py[line:551] - INFO: load:1.56 valid_run:1805.83 task_valid:1734.12 collect_output:57.99
2022-10-13 00:38:11 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 00:38:11 - train.py[line:551] - INFO: load:1.58 valid_run:1955.38 task_valid:1875.69 collect_output:64.95
2022-10-13 00:40:41 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 00:40:41 - train.py[line:551] - INFO: load:1.61 valid_run:2105.60 task_valid:2020.74 collect_output:69.11
2022-10-13 00:43:11 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 00:43:11 - train.py[line:551] - INFO: load:1.63 valid_run:2255.19 task_valid:2166.79 collect_output:71.62
2022-10-13 00:45:40 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 00:45:40 - train.py[line:551] - INFO: load:1.66 valid_run:2404.74 task_valid:2310.65 collect_output:76.30
2022-10-13 00:48:12 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 00:48:12 - train.py[line:551] - INFO: load:1.68 valid_run:2556.11 task_valid:2455.85 collect_output:81.45
2022-10-13 00:50:42 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 00:50:42 - train.py[line:551] - INFO: load:1.71 valid_run:2706.34 task_valid:2602.50 collect_output:84.02
2022-10-13 00:53:10 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 00:53:10 - train.py[line:551] - INFO: load:1.73 valid_run:2854.24 task_valid:2743.63 collect_output:89.79
2022-10-13 00:55:40 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 00:55:40 - train.py[line:551] - INFO: load:1.76 valid_run:3004.10 task_valid:2888.28 collect_output:93.98
2022-10-13 00:58:12 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 00:58:12 - train.py[line:551] - INFO: load:1.78 valid_run:3155.96 task_valid:3032.78 collect_output:100.32
2022-10-13 01:00:41 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 01:00:41 - train.py[line:551] - INFO: load:1.81 valid_run:3304.85 task_valid:3177.03 collect_output:103.94
2022-10-13 01:03:12 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 01:03:12 - train.py[line:551] - INFO: load:1.83 valid_run:3455.60 task_valid:3322.80 collect_output:107.91
2022-10-13 01:05:43 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 01:05:43 - train.py[line:551] - INFO: load:1.86 valid_run:3606.60 task_valid:3468.91 collect_output:111.79

====================================================================================================
SGG eval:     R @ 50: 0.6450;     R @ 100: 0.6816;     R @ 500: 0.7038;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4477;    mR @ 100: 0.4717;    mR @ 500: 0.5277;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.5000) (hanging from:0.4839) (lying on:0.3000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9565) (says:0.0000) (sitting on:0.7307) (standing on:0.3793) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.5556) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6450;     R @ 100: 0.6816;     R @ 500: 0.7038;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4477;    mR @ 100: 0.4717;    mR @ 500: 0.5277;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.5000) (hanging from:0.4839) (lying on:0.3000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9565) (says:0.0000) (sitting on:0.7307) (standing on:0.3793) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.5556) 
--------------------------------------------------------
====================================================================================================

2022-10-13 01:08:14 - train.py[line:487] - INFO: 0.6815624649859945
2022-10-13 01:08:14 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 01:08:14 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.32 | loss_v1 0 | loss_v2 0 | nll_loss 0.152 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.681562 | ppl 1.11 | vqa_score 0.5833 | wps 119.3 | wpb 89.9 | bsz 30 | num_updates 7000 | best_R@100 0.708635
2022-10-13 01:08:14 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 7000 updates
2022-10-13 01:08:14 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-13 01:08:20 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-13 01:08:22 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 0.6815624649859945) (writing took 8.203861836809665 seconds)
2022-10-13 01:08:33 - progress_bar.py[line:274] - INFO: epoch 001:   7020 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=0.3, ups=0, wpb=111.8, bsz=40, num_updates=7010, lr=4.89258e-05, gnorm=0.699, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34443
2022-10-13 01:08:45 - progress_bar.py[line:274] - INFO: epoch 001:   7030 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=7020, lr=4.89213e-05, gnorm=0.729, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34454
2022-10-13 01:08:56 - progress_bar.py[line:274] - INFO: epoch 001:   7040 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.6, ups=0.89, wpb=108.3, bsz=40, num_updates=7030, lr=4.89168e-05, gnorm=0.724, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34466
2022-10-13 01:09:07 - progress_bar.py[line:274] - INFO: epoch 001:   7050 / 28910 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.2, ups=0.88, wpb=110.2, bsz=40, num_updates=7040, lr=4.89123e-05, gnorm=0.598, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34477
2022-10-13 01:09:18 - progress_bar.py[line:274] - INFO: epoch 001:   7060 / 28910 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=103.2, ups=0.93, wpb=111.4, bsz=40, num_updates=7050, lr=4.89078e-05, gnorm=0.583, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34488
2022-10-13 01:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   7070 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.3, ups=0.88, wpb=110.3, bsz=40, num_updates=7060, lr=4.89033e-05, gnorm=0.624, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34499
2022-10-13 01:09:41 - progress_bar.py[line:274] - INFO: epoch 001:   7080 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=101.5, ups=0.9, wpb=112.2, bsz=40, num_updates=7070, lr=4.88988e-05, gnorm=0.63, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34510
2022-10-13 01:09:52 - progress_bar.py[line:274] - INFO: epoch 001:   7090 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.9, ups=0.89, wpb=110.6, bsz=40, num_updates=7080, lr=4.88943e-05, gnorm=0.65, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34522
2022-10-13 01:10:03 - progress_bar.py[line:274] - INFO: epoch 001:   7100 / 28910 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=7090, lr=4.88898e-05, gnorm=0.599, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34533
2022-10-13 01:10:14 - progress_bar.py[line:274] - INFO: epoch 001:   7110 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.9, ups=0.9, wpb=109.4, bsz=40, num_updates=7100, lr=4.88853e-05, gnorm=0.684, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34544
2022-10-13 01:10:25 - progress_bar.py[line:274] - INFO: epoch 001:   7120 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.4, ups=0.91, wpb=109.7, bsz=40, num_updates=7110, lr=4.88808e-05, gnorm=0.662, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34555
2022-10-13 01:10:40 - progress_bar.py[line:274] - INFO: epoch 001:   7130 / 28910 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.4, ups=0.88, wpb=110.2, bsz=40, num_updates=7120, lr=4.88763e-05, gnorm=0.606, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34566
2022-10-13 01:10:51 - progress_bar.py[line:274] - INFO: epoch 001:   7140 / 28910 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.6, ups=0.9, wpb=110, bsz=40, num_updates=7130, lr=4.88718e-05, gnorm=0.658, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34581
2022-10-13 01:11:02 - progress_bar.py[line:274] - INFO: epoch 001:   7150 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.5, ups=0.9, wpb=108.9, bsz=40, num_updates=7140, lr=4.88673e-05, gnorm=0.776, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34592
2022-10-13 01:11:13 - progress_bar.py[line:274] - INFO: epoch 001:   7160 / 28910 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101.9, ups=0.91, wpb=111.4, bsz=40, num_updates=7150, lr=4.88628e-05, gnorm=0.641, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34603
2022-10-13 01:11:24 - progress_bar.py[line:274] - INFO: epoch 001:   7170 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.3, ups=0.88, wpb=110, bsz=40, num_updates=7160, lr=4.88583e-05, gnorm=0.733, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34614
2022-10-13 01:11:36 - progress_bar.py[line:274] - INFO: epoch 001:   7180 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.4, ups=0.89, wpb=111.1, bsz=40, num_updates=7170, lr=4.88538e-05, gnorm=0.693, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34625
2022-10-13 01:11:47 - progress_bar.py[line:274] - INFO: epoch 001:   7190 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.1, ups=0.91, wpb=111.4, bsz=40, num_updates=7180, lr=4.88493e-05, gnorm=0.709, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34636
2022-10-13 01:11:58 - progress_bar.py[line:274] - INFO: epoch 001:   7200 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.1, ups=0.87, wpb=111.2, bsz=40, num_updates=7190, lr=4.88448e-05, gnorm=0.612, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34648
2022-10-13 01:12:09 - progress_bar.py[line:274] - INFO: epoch 001:   7210 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.4, ups=0.91, wpb=109.7, bsz=40, num_updates=7200, lr=4.88402e-05, gnorm=0.688, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34659
2022-10-13 01:12:20 - progress_bar.py[line:274] - INFO: epoch 001:   7220 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101.8, ups=0.92, wpb=111.1, bsz=40, num_updates=7210, lr=4.88357e-05, gnorm=0.728, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34670
2022-10-13 01:12:31 - progress_bar.py[line:274] - INFO: epoch 001:   7230 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.6, ups=0.92, wpb=110.7, bsz=40, num_updates=7220, lr=4.88312e-05, gnorm=0.63, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34681
2022-10-13 01:12:42 - progress_bar.py[line:274] - INFO: epoch 001:   7240 / 28910 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.8, ups=0.91, wpb=109.2, bsz=40, num_updates=7230, lr=4.88267e-05, gnorm=0.662, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34692
2022-10-13 01:12:53 - progress_bar.py[line:274] - INFO: epoch 001:   7250 / 28910 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=103, ups=0.92, wpb=111.7, bsz=40, num_updates=7240, lr=4.88222e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34703
2022-10-13 01:13:04 - progress_bar.py[line:274] - INFO: epoch 001:   7260 / 28910 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=99.7, ups=0.9, wpb=111.2, bsz=40, num_updates=7250, lr=4.88177e-05, gnorm=0.621, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34714
2022-10-13 01:13:16 - progress_bar.py[line:274] - INFO: epoch 001:   7270 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=7260, lr=4.88132e-05, gnorm=0.588, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34725
2022-10-13 01:13:27 - progress_bar.py[line:274] - INFO: epoch 001:   7280 / 28910 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=7270, lr=4.88087e-05, gnorm=0.654, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34736
2022-10-13 01:13:38 - progress_bar.py[line:274] - INFO: epoch 001:   7290 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.1, ups=0.92, wpb=109.2, bsz=40, num_updates=7280, lr=4.88042e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34747
2022-10-13 01:13:49 - progress_bar.py[line:274] - INFO: epoch 001:   7300 / 28910 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=96.4, ups=0.88, wpb=110.2, bsz=40, num_updates=7290, lr=4.87997e-05, gnorm=0.673, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34759
2022-10-13 01:14:00 - progress_bar.py[line:274] - INFO: epoch 001:   7310 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=7300, lr=4.87952e-05, gnorm=0.748, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34770
2022-10-13 01:14:12 - progress_bar.py[line:274] - INFO: epoch 001:   7320 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.5, ups=0.9, wpb=110.6, bsz=40, num_updates=7310, lr=4.87907e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34781
2022-10-13 01:14:23 - progress_bar.py[line:274] - INFO: epoch 001:   7330 / 28910 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=7320, lr=4.87862e-05, gnorm=0.654, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34792
2022-10-13 01:14:34 - progress_bar.py[line:274] - INFO: epoch 001:   7340 / 28910 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=7330, lr=4.87817e-05, gnorm=0.656, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=34804
2022-10-13 01:14:45 - progress_bar.py[line:274] - INFO: epoch 001:   7350 / 28910 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.4, ups=0.9, wpb=110.9, bsz=40, num_updates=7340, lr=4.87772e-05, gnorm=0.657, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34815
2022-10-13 01:14:56 - progress_bar.py[line:274] - INFO: epoch 001:   7360 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=7350, lr=4.87727e-05, gnorm=0.62, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34826
2022-10-13 01:15:08 - progress_bar.py[line:274] - INFO: epoch 001:   7370 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.8, ups=0.88, wpb=112.3, bsz=40, num_updates=7360, lr=4.87682e-05, gnorm=0.603, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34837
2022-10-13 01:15:19 - progress_bar.py[line:274] - INFO: epoch 001:   7380 / 28910 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=7370, lr=4.87637e-05, gnorm=0.586, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34848
2022-10-13 01:15:30 - progress_bar.py[line:274] - INFO: epoch 001:   7390 / 28910 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=7380, lr=4.87592e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=34860
2022-10-13 01:15:36 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 01:15:42 - progress_bar.py[line:274] - INFO: epoch 001:   7401 / 28910 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=89.7, ups=0.81, wpb=110.4, bsz=40, num_updates=7390, lr=4.87547e-05, gnorm=0.756, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=34872
2022-10-13 01:15:53 - progress_bar.py[line:274] - INFO: epoch 001:   7411 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101.7, ups=0.91, wpb=111.2, bsz=40, num_updates=7400, lr=4.87502e-05, gnorm=0.631, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34883
2022-10-13 01:16:05 - progress_bar.py[line:274] - INFO: epoch 001:   7421 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.3, ups=0.91, wpb=110.8, bsz=40, num_updates=7410, lr=4.87457e-05, gnorm=0.642, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34894
2022-10-13 01:16:16 - progress_bar.py[line:274] - INFO: epoch 001:   7431 / 28910 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.5, ups=0.9, wpb=109.5, bsz=40, num_updates=7420, lr=4.87412e-05, gnorm=0.545, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34905
2022-10-13 01:16:27 - progress_bar.py[line:274] - INFO: epoch 001:   7441 / 28910 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=95.5, ups=0.86, wpb=110.6, bsz=40, num_updates=7430, lr=4.87367e-05, gnorm=0.626, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=34917
2022-10-13 01:16:39 - progress_bar.py[line:274] - INFO: epoch 001:   7451 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.7, ups=0.89, wpb=109.2, bsz=40, num_updates=7440, lr=4.87322e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=34928
2022-10-13 01:16:49 - progress_bar.py[line:274] - INFO: epoch 001:   7461 / 28910 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=103.6, ups=0.94, wpb=110.6, bsz=40, num_updates=7450, lr=4.87276e-05, gnorm=0.663, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=34939
2022-10-13 01:17:00 - progress_bar.py[line:274] - INFO: epoch 001:   7471 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=7460, lr=4.87231e-05, gnorm=0.665, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34950
2022-10-13 01:17:12 - progress_bar.py[line:274] - INFO: epoch 001:   7481 / 28910 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=7470, lr=4.87186e-05, gnorm=0.629, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=34961
2022-10-13 01:17:23 - progress_bar.py[line:274] - INFO: epoch 001:   7491 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.3, ups=0.9, wpb=111, bsz=40, num_updates=7480, lr=4.87141e-05, gnorm=0.623, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34973
2022-10-13 01:17:34 - progress_bar.py[line:274] - INFO: epoch 001:   7501 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=101.8, ups=0.92, wpb=110.4, bsz=40, num_updates=7490, lr=4.87096e-05, gnorm=0.617, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34984
2022-10-13 01:17:45 - progress_bar.py[line:274] - INFO: epoch 001:   7511 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.2, ups=0.88, wpb=110.2, bsz=40, num_updates=7500, lr=4.87051e-05, gnorm=0.627, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34995
2022-10-13 01:17:57 - progress_bar.py[line:274] - INFO: epoch 001:   7521 / 28910 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=96.8, ups=0.89, wpb=109.2, bsz=40, num_updates=7510, lr=4.87006e-05, gnorm=0.706, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35006
2022-10-13 01:18:08 - progress_bar.py[line:274] - INFO: epoch 001:   7531 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101, ups=0.92, wpb=110.2, bsz=40, num_updates=7520, lr=4.86961e-05, gnorm=0.85, clip=20, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=35017
2022-10-13 01:18:19 - progress_bar.py[line:274] - INFO: epoch 001:   7541 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.9, ups=0.89, wpb=111.8, bsz=40, num_updates=7530, lr=4.86916e-05, gnorm=0.68, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=35029
2022-10-13 01:18:30 - progress_bar.py[line:274] - INFO: epoch 001:   7551 / 28910 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.6, ups=0.92, wpb=109.6, bsz=40, num_updates=7540, lr=4.86871e-05, gnorm=0.624, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35040
2022-10-13 01:18:41 - progress_bar.py[line:274] - INFO: epoch 001:   7561 / 28910 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.3, ups=0.9, wpb=108.4, bsz=40, num_updates=7550, lr=4.86826e-05, gnorm=0.627, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35051
2022-10-13 01:18:52 - progress_bar.py[line:274] - INFO: epoch 001:   7571 / 28910 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.6, ups=0.92, wpb=110.8, bsz=40, num_updates=7560, lr=4.86781e-05, gnorm=0.74, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35062
2022-10-13 01:19:03 - progress_bar.py[line:274] - INFO: epoch 001:   7581 / 28910 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96.9, ups=0.88, wpb=109.7, bsz=40, num_updates=7570, lr=4.86736e-05, gnorm=0.694, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35073
2022-10-13 01:19:14 - progress_bar.py[line:274] - INFO: epoch 001:   7591 / 28910 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.8, ups=0.92, wpb=109.7, bsz=40, num_updates=7580, lr=4.86691e-05, gnorm=0.642, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35084
2022-10-13 01:19:26 - progress_bar.py[line:274] - INFO: epoch 001:   7601 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=95.7, ups=0.87, wpb=109.7, bsz=40, num_updates=7590, lr=4.86646e-05, gnorm=0.723, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35095
2022-10-13 01:19:37 - progress_bar.py[line:274] - INFO: epoch 001:   7611 / 28910 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.6, ups=0.89, wpb=110.6, bsz=40, num_updates=7600, lr=4.86601e-05, gnorm=0.744, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35107
2022-10-13 01:19:48 - progress_bar.py[line:274] - INFO: epoch 001:   7621 / 28910 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.7, ups=0.89, wpb=110.2, bsz=40, num_updates=7610, lr=4.86556e-05, gnorm=0.583, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35118
2022-10-13 01:20:00 - progress_bar.py[line:274] - INFO: epoch 001:   7631 / 28910 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.4, ups=0.89, wpb=109.8, bsz=40, num_updates=7620, lr=4.86511e-05, gnorm=0.659, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35129
2022-10-13 01:20:11 - progress_bar.py[line:274] - INFO: epoch 001:   7641 / 28910 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.9, ups=0.9, wpb=111.5, bsz=40, num_updates=7630, lr=4.86466e-05, gnorm=0.677, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35141
2022-10-13 01:20:22 - progress_bar.py[line:274] - INFO: epoch 001:   7651 / 28910 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.9, ups=0.91, wpb=111.5, bsz=40, num_updates=7640, lr=4.86421e-05, gnorm=0.689, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35152
2022-10-13 01:20:34 - progress_bar.py[line:274] - INFO: epoch 001:   7661 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=94.9, ups=0.87, wpb=109.2, bsz=40, num_updates=7650, lr=4.86376e-05, gnorm=0.626, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=35163
2022-10-13 01:20:45 - progress_bar.py[line:274] - INFO: epoch 001:   7671 / 28910 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=101.2, ups=0.9, wpb=111.9, bsz=40, num_updates=7660, lr=4.86331e-05, gnorm=0.611, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35174
2022-10-13 01:20:56 - progress_bar.py[line:274] - INFO: epoch 001:   7681 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98, ups=0.89, wpb=110.7, bsz=40, num_updates=7670, lr=4.86286e-05, gnorm=0.614, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35186
2022-10-13 01:21:07 - progress_bar.py[line:274] - INFO: epoch 001:   7691 / 28910 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=96.8, ups=0.88, wpb=109.7, bsz=40, num_updates=7680, lr=4.86241e-05, gnorm=0.484, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35197
2022-10-13 01:21:19 - progress_bar.py[line:274] - INFO: epoch 001:   7701 / 28910 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=99.9, ups=0.91, wpb=110.1, bsz=40, num_updates=7690, lr=4.86196e-05, gnorm=0.645, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=35208
2022-10-13 01:21:30 - progress_bar.py[line:274] - INFO: epoch 001:   7711 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.5, ups=0.92, wpb=109.5, bsz=40, num_updates=7700, lr=4.86151e-05, gnorm=0.716, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=35219
2022-10-13 01:21:41 - progress_bar.py[line:274] - INFO: epoch 001:   7721 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.1, ups=0.9, wpb=109.3, bsz=40, num_updates=7710, lr=4.86105e-05, gnorm=0.585, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35231
2022-10-13 01:21:53 - progress_bar.py[line:274] - INFO: epoch 001:   7731 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=96.8, ups=0.87, wpb=111.3, bsz=40, num_updates=7720, lr=4.8606e-05, gnorm=0.589, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35242
2022-10-13 01:22:04 - progress_bar.py[line:274] - INFO: epoch 001:   7741 / 28910 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.2, ups=0.9, wpb=110.7, bsz=40, num_updates=7730, lr=4.86015e-05, gnorm=0.646, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35253
2022-10-13 01:22:15 - progress_bar.py[line:274] - INFO: epoch 001:   7751 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=7740, lr=4.8597e-05, gnorm=0.581, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35265
2022-10-13 01:22:26 - progress_bar.py[line:274] - INFO: epoch 001:   7761 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=103.3, ups=0.92, wpb=111.9, bsz=40, num_updates=7750, lr=4.85925e-05, gnorm=0.607, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35276
2022-10-13 01:22:37 - progress_bar.py[line:274] - INFO: epoch 001:   7771 / 28910 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=7760, lr=4.8588e-05, gnorm=0.597, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35287
2022-10-13 01:22:49 - progress_bar.py[line:274] - INFO: epoch 001:   7781 / 28910 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=94.4, ups=0.87, wpb=108.4, bsz=40, num_updates=7770, lr=4.85835e-05, gnorm=0.832, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35298
2022-10-13 01:23:00 - progress_bar.py[line:274] - INFO: epoch 001:   7791 / 28910 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.1, ups=0.91, wpb=109.8, bsz=40, num_updates=7780, lr=4.8579e-05, gnorm=0.6, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35309
2022-10-13 01:23:11 - progress_bar.py[line:274] - INFO: epoch 001:   7801 / 28910 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.8, ups=0.89, wpb=111, bsz=40, num_updates=7790, lr=4.85745e-05, gnorm=0.513, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35320
2022-10-13 01:23:22 - progress_bar.py[line:274] - INFO: epoch 001:   7811 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=7800, lr=4.857e-05, gnorm=0.676, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35332
2022-10-13 01:23:33 - progress_bar.py[line:274] - INFO: epoch 001:   7821 / 28910 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=103.2, ups=0.93, wpb=111, bsz=40, num_updates=7810, lr=4.85655e-05, gnorm=0.637, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35343
2022-10-13 01:23:44 - progress_bar.py[line:274] - INFO: epoch 001:   7831 / 28910 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.2, ups=0.88, wpb=112, bsz=40, num_updates=7820, lr=4.8561e-05, gnorm=0.676, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=35354
2022-10-13 01:23:56 - progress_bar.py[line:274] - INFO: epoch 001:   7841 / 28910 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=7830, lr=4.85565e-05, gnorm=0.646, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35365
2022-10-13 01:24:07 - progress_bar.py[line:274] - INFO: epoch 001:   7851 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=95.7, ups=0.87, wpb=109.8, bsz=40, num_updates=7840, lr=4.8552e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35377
2022-10-13 01:24:18 - progress_bar.py[line:274] - INFO: epoch 001:   7861 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.1, ups=0.9, wpb=110, bsz=40, num_updates=7850, lr=4.85475e-05, gnorm=0.641, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35388
2022-10-13 01:24:30 - progress_bar.py[line:274] - INFO: epoch 001:   7871 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=94.6, ups=0.87, wpb=109.1, bsz=40, num_updates=7860, lr=4.8543e-05, gnorm=0.632, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35399
2022-10-13 01:24:41 - progress_bar.py[line:274] - INFO: epoch 001:   7881 / 28910 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=95.7, ups=0.88, wpb=108.7, bsz=40, num_updates=7870, lr=4.85385e-05, gnorm=0.604, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35411
2022-10-13 01:24:52 - progress_bar.py[line:274] - INFO: epoch 001:   7891 / 28910 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=102.1, ups=0.93, wpb=110.1, bsz=40, num_updates=7880, lr=4.8534e-05, gnorm=0.667, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35422
2022-10-13 01:25:03 - progress_bar.py[line:274] - INFO: epoch 001:   7901 / 28910 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.2, ups=0.89, wpb=111.6, bsz=40, num_updates=7890, lr=4.85295e-05, gnorm=0.671, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35433
2022-10-13 01:25:14 - progress_bar.py[line:274] - INFO: epoch 001:   7911 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.5, ups=0.9, wpb=109.7, bsz=40, num_updates=7900, lr=4.8525e-05, gnorm=0.64, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35444
2022-10-13 01:25:26 - progress_bar.py[line:274] - INFO: epoch 001:   7921 / 28910 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100, ups=0.9, wpb=111.1, bsz=40, num_updates=7910, lr=4.85205e-05, gnorm=0.569, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35455
2022-10-13 01:25:37 - progress_bar.py[line:274] - INFO: epoch 001:   7931 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=7920, lr=4.8516e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35466
2022-10-13 01:25:48 - progress_bar.py[line:274] - INFO: epoch 001:   7941 / 28910 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.2, ups=0.9, wpb=110.3, bsz=40, num_updates=7930, lr=4.85115e-05, gnorm=0.717, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35478
2022-10-13 01:25:59 - progress_bar.py[line:274] - INFO: epoch 001:   7951 / 28910 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.1, ups=0.88, wpb=110, bsz=40, num_updates=7940, lr=4.8507e-05, gnorm=0.661, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35489
2022-10-13 01:26:10 - progress_bar.py[line:274] - INFO: epoch 001:   7961 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.5, ups=0.92, wpb=109.3, bsz=40, num_updates=7950, lr=4.85025e-05, gnorm=0.682, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35500
2022-10-13 01:26:21 - progress_bar.py[line:274] - INFO: epoch 001:   7971 / 28910 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=7960, lr=4.8498e-05, gnorm=0.638, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35511
2022-10-13 01:26:32 - progress_bar.py[line:274] - INFO: epoch 001:   7981 / 28910 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101, ups=0.91, wpb=111.5, bsz=40, num_updates=7970, lr=4.84934e-05, gnorm=0.613, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35522
2022-10-13 01:26:43 - progress_bar.py[line:274] - INFO: epoch 001:   7991 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=7980, lr=4.84889e-05, gnorm=0.566, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35533
2022-10-13 01:26:55 - progress_bar.py[line:274] - INFO: epoch 001:   8001 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.8, ups=0.88, wpb=111.2, bsz=40, num_updates=7990, lr=4.84844e-05, gnorm=0.638, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35544
2022-10-13 01:27:06 - progress_bar.py[line:274] - INFO: epoch 001:   8011 / 28910 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=8000, lr=4.84799e-05, gnorm=0.715, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35556
2022-10-13 01:27:06 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 01:27:07 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 01:27:07 - train.py[line:551] - INFO: load:1.32 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 01:27:29 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.35 GiB (GPU 0; 39.59 GiB total capacity; 8.96 GiB already allocated; 3.65 GiB free; 33.46 GiB reserved in total by PyTorch)
2022-10-13 01:27:29 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 12        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9180 MB |   15568 MB |    5131 TB |    5131 TB |
|       from large pool |    9035 MB |   15423 MB |    5129 TB |    5129 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9180 MB |   15568 MB |    5131 TB |    5131 TB |
|       from large pool |    9035 MB |   15423 MB |    5129 TB |    5129 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   34260 MB |   36952 MB |  163420 MB |  129160 MB |
|       from large pool |   34114 MB |   36806 MB |  163128 MB |  129014 MB |
|       from small pool |     146 MB |     148 MB |     292 MB |     146 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   25079 MB |   25079 MB |    5073 TB |    5073 TB |
|       from large pool |   25078 MB |   25078 MB |    5072 TB |    5072 TB |
|       from small pool |       1 MB |       2 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |  237717 K  |  237713 K  |
|       from large pool |     563    |     575    |   76709 K  |   76708 K  |
|       from small pool |    3106    |    3116    |  161007 K  |  161004 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |  237717 K  |  237713 K  |
|       from large pool |     563    |     575    |   76709 K  |   76708 K  |
|       from small pool |    3106    |    3116    |  161007 K  |  161004 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     164    |     171    |     501    |     337    |
|       from large pool |      91    |      98    |     355    |     264    |
|       from small pool |      73    |      74    |     146    |      73    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      92    |     103    |  171574 K  |  171574 K  |
|       from large pool |      61    |      67    |   31674 K  |   31674 K  |
|       from small pool |      31    |      42    |  139899 K  |  139899 K  |
|===========================================================================|

2022-10-13 01:27:29 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-13 01:27:29 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-13 01:29:41 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 01:29:41 - train.py[line:551] - INFO: load:1.35 valid_run:153.77 task_valid:149.39 collect_output:2.42
2022-10-13 01:32:10 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 01:32:10 - train.py[line:551] - INFO: load:1.37 valid_run:302.76 task_valid:293.09 collect_output:6.57
2022-10-13 01:34:43 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 01:34:43 - train.py[line:551] - INFO: load:1.40 valid_run:455.65 task_valid:436.78 collect_output:14.73
2022-10-13 01:37:13 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 01:37:13 - train.py[line:551] - INFO: load:1.44 valid_run:605.11 task_valid:582.07 collect_output:17.83
2022-10-13 01:39:46 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 01:39:46 - train.py[line:551] - INFO: load:1.47 valid_run:758.04 task_valid:730.38 collect_output:21.33
2022-10-13 01:42:18 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 01:42:18 - train.py[line:551] - INFO: load:1.50 valid_run:909.84 task_valid:876.18 collect_output:26.27
2022-10-13 01:44:51 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 01:44:51 - train.py[line:551] - INFO: load:1.52 valid_run:1063.50 task_valid:1022.58 collect_output:32.46
2022-10-13 01:47:23 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 01:47:23 - train.py[line:551] - INFO: load:1.55 valid_run:1214.91 task_valid:1163.91 collect_output:41.48
2022-10-13 01:49:53 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 01:49:53 - train.py[line:551] - INFO: load:1.58 valid_run:1364.90 task_valid:1309.34 collect_output:44.96
2022-10-13 01:52:22 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 01:52:22 - train.py[line:551] - INFO: load:1.61 valid_run:1513.66 task_valid:1453.35 collect_output:48.63
2022-10-13 01:54:51 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 01:54:51 - train.py[line:551] - INFO: load:1.63 valid_run:1663.21 task_valid:1597.90 collect_output:52.59
2022-10-13 01:57:21 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 01:57:21 - train.py[line:551] - INFO: load:1.66 valid_run:1812.90 task_valid:1742.60 collect_output:56.56
2022-10-13 01:59:51 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 01:59:51 - train.py[line:551] - INFO: load:1.68 valid_run:1962.61 task_valid:1884.31 collect_output:63.55
2022-10-13 02:02:21 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 02:02:21 - train.py[line:551] - INFO: load:1.71 valid_run:2112.91 task_valid:2029.44 collect_output:67.67
2022-10-13 02:04:51 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 02:04:51 - train.py[line:551] - INFO: load:1.73 valid_run:2262.40 task_valid:2175.26 collect_output:70.34
2022-10-13 02:07:20 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 02:07:20 - train.py[line:551] - INFO: load:1.76 valid_run:2411.99 task_valid:2318.93 collect_output:75.24
2022-10-13 02:09:52 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 02:09:52 - train.py[line:551] - INFO: load:1.78 valid_run:2563.29 task_valid:2464.06 collect_output:80.38
2022-10-13 02:12:22 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 02:12:22 - train.py[line:551] - INFO: load:1.81 valid_run:2713.24 task_valid:2610.38 collect_output:83.02
2022-10-13 02:14:50 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 02:14:50 - train.py[line:551] - INFO: load:1.83 valid_run:2861.27 task_valid:2751.62 collect_output:88.80
2022-10-13 02:17:20 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 02:17:20 - train.py[line:551] - INFO: load:1.86 valid_run:3011.27 task_valid:2896.49 collect_output:92.89
2022-10-13 02:19:52 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 02:19:52 - train.py[line:551] - INFO: load:1.88 valid_run:3162.85 task_valid:3040.70 collect_output:99.22
2022-10-13 02:22:21 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 02:22:21 - train.py[line:551] - INFO: load:1.90 valid_run:3311.76 task_valid:3185.03 collect_output:102.76
2022-10-13 02:24:51 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 02:24:51 - train.py[line:551] - INFO: load:1.93 valid_run:3462.57 task_valid:3330.96 collect_output:106.64
2022-10-13 02:27:23 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 02:27:23 - train.py[line:551] - INFO: load:1.95 valid_run:3613.74 task_valid:3477.33 collect_output:110.41

====================================================================================================
SGG eval:     R @ 50: 0.6343;     R @ 100: 0.6710;     R @ 500: 0.6978;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4286;    mR @ 100: 0.4619;    mR @ 500: 0.5097;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:1.0000) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.3750) (hanging from:0.4839) (lying on:0.3000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9565) (says:0.0000) (sitting on:0.7163) (standing on:0.3693) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.5556) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6343;     R @ 100: 0.6710;     R @ 500: 0.6978;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4286;    mR @ 100: 0.4619;    mR @ 500: 0.5097;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:1.0000) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.3750) (hanging from:0.4839) (lying on:0.3000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9565) (says:0.0000) (sitting on:0.7163) (standing on:0.3693) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.5556) 
--------------------------------------------------------
====================================================================================================

2022-10-13 02:29:53 - train.py[line:487] - INFO: 0.670981512605042
2022-10-13 02:29:53 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 02:29:54 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.347 | loss_v1 0 | loss_v2 0 | nll_loss 0.192 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.670982 | ppl 1.14 | vqa_score 0.5845 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 8000 | best_R@100 0.708635
2022-10-13 02:29:54 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2022-10-13 02:29:54 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-13 02:29:59 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-13 02:30:02 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.670981512605042) (writing took 8.25890989555046 seconds)
2022-10-13 02:30:13 - progress_bar.py[line:274] - INFO: epoch 001:   8021 / 28910 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=0.3, ups=0, wpb=110.9, bsz=40, num_updates=8010, lr=4.84754e-05, gnorm=0.651, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39343
2022-10-13 02:30:25 - progress_bar.py[line:274] - INFO: epoch 001:   8031 / 28910 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=94.3, ups=0.87, wpb=108.3, bsz=40, num_updates=8020, lr=4.84709e-05, gnorm=0.633, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39354
2022-10-13 02:30:36 - progress_bar.py[line:274] - INFO: epoch 001:   8041 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=8030, lr=4.84664e-05, gnorm=0.605, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39365
2022-10-13 02:30:47 - progress_bar.py[line:274] - INFO: epoch 001:   8051 / 28910 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=100, ups=0.89, wpb=112.1, bsz=40, num_updates=8040, lr=4.84619e-05, gnorm=0.678, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39377
2022-10-13 02:30:58 - progress_bar.py[line:274] - INFO: epoch 001:   8061 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.3, ups=0.88, wpb=110.3, bsz=40, num_updates=8050, lr=4.84574e-05, gnorm=0.779, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39388
2022-10-13 02:31:10 - progress_bar.py[line:274] - INFO: epoch 001:   8071 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=96.6, ups=0.88, wpb=109.8, bsz=40, num_updates=8060, lr=4.84529e-05, gnorm=0.644, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39399
2022-10-13 02:31:21 - progress_bar.py[line:274] - INFO: epoch 001:   8081 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.1, ups=0.91, wpb=110.6, bsz=40, num_updates=8070, lr=4.84484e-05, gnorm=0.736, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39410
2022-10-13 02:31:32 - progress_bar.py[line:274] - INFO: epoch 001:   8091 / 28910 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.2, ups=0.92, wpb=110.1, bsz=40, num_updates=8080, lr=4.84439e-05, gnorm=0.669, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39421
2022-10-13 02:31:43 - progress_bar.py[line:274] - INFO: epoch 001:   8101 / 28910 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=8090, lr=4.84394e-05, gnorm=0.713, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39433
2022-10-13 02:31:54 - progress_bar.py[line:274] - INFO: epoch 001:   8111 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=103.5, ups=0.93, wpb=110.9, bsz=40, num_updates=8100, lr=4.84349e-05, gnorm=0.708, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39443
2022-10-13 02:32:04 - progress_bar.py[line:274] - INFO: epoch 001:   8121 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=102, ups=0.93, wpb=109.2, bsz=40, num_updates=8110, lr=4.84304e-05, gnorm=0.767, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39454
2022-10-13 02:32:15 - progress_bar.py[line:274] - INFO: epoch 001:   8131 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.7, ups=0.91, wpb=110.8, bsz=40, num_updates=8120, lr=4.84259e-05, gnorm=0.636, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39465
2022-10-13 02:32:27 - progress_bar.py[line:274] - INFO: epoch 001:   8141 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=96.8, ups=0.87, wpb=110.6, bsz=40, num_updates=8130, lr=4.84214e-05, gnorm=0.705, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39477
2022-10-13 02:32:38 - progress_bar.py[line:274] - INFO: epoch 001:   8151 / 28910 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=8140, lr=4.84169e-05, gnorm=0.625, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39488
2022-10-13 02:32:49 - progress_bar.py[line:274] - INFO: epoch 001:   8161 / 28910 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.2, ups=0.92, wpb=109.3, bsz=40, num_updates=8150, lr=4.84124e-05, gnorm=0.719, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39499
2022-10-13 02:32:57 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 02:33:01 - progress_bar.py[line:274] - INFO: epoch 001:   8172 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=90.2, ups=0.83, wpb=108.6, bsz=40, num_updates=8160, lr=4.84079e-05, gnorm=0.664, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=39511
2022-10-13 02:33:12 - progress_bar.py[line:274] - INFO: epoch 001:   8182 / 28910 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=99.6, ups=0.9, wpb=110.1, bsz=40, num_updates=8170, lr=4.84034e-05, gnorm=0.769, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=39522
2022-10-13 02:33:23 - progress_bar.py[line:274] - INFO: epoch 001:   8192 / 28910 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=101.2, ups=0.92, wpb=110.2, bsz=40, num_updates=8180, lr=4.83989e-05, gnorm=0.582, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39533
2022-10-13 02:33:35 - progress_bar.py[line:274] - INFO: epoch 001:   8202 / 28910 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.3, ups=0.9, wpb=109.6, bsz=40, num_updates=8190, lr=4.83944e-05, gnorm=0.702, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39544
2022-10-13 02:33:46 - progress_bar.py[line:274] - INFO: epoch 001:   8212 / 28910 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=8200, lr=4.83899e-05, gnorm=0.607, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39555
2022-10-13 02:33:57 - progress_bar.py[line:274] - INFO: epoch 001:   8222 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101.8, ups=0.91, wpb=112.3, bsz=40, num_updates=8210, lr=4.83854e-05, gnorm=0.744, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39566
2022-10-13 02:34:08 - progress_bar.py[line:274] - INFO: epoch 001:   8232 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=96.5, ups=0.87, wpb=111.1, bsz=40, num_updates=8220, lr=4.83808e-05, gnorm=0.705, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39578
2022-10-13 02:34:20 - progress_bar.py[line:274] - INFO: epoch 001:   8242 / 28910 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=8230, lr=4.83763e-05, gnorm=0.623, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39589
2022-10-13 02:34:31 - progress_bar.py[line:274] - INFO: epoch 001:   8252 / 28910 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=96.6, ups=0.87, wpb=110.6, bsz=40, num_updates=8240, lr=4.83718e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39601
2022-10-13 02:34:42 - progress_bar.py[line:274] - INFO: epoch 001:   8262 / 28910 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=8250, lr=4.83673e-05, gnorm=0.583, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39612
2022-10-13 02:34:54 - progress_bar.py[line:274] - INFO: epoch 001:   8272 / 28910 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=99.7, ups=0.9, wpb=110.9, bsz=40, num_updates=8260, lr=4.83628e-05, gnorm=0.603, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39623
2022-10-13 02:35:05 - progress_bar.py[line:274] - INFO: epoch 001:   8282 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.2, ups=0.91, wpb=109.5, bsz=40, num_updates=8270, lr=4.83583e-05, gnorm=0.746, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39634
2022-10-13 02:35:16 - progress_bar.py[line:274] - INFO: epoch 001:   8292 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.4, ups=0.89, wpb=109, bsz=40, num_updates=8280, lr=4.83538e-05, gnorm=0.704, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39645
2022-10-13 02:35:27 - progress_bar.py[line:274] - INFO: epoch 001:   8302 / 28910 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.7, ups=0.9, wpb=110.1, bsz=40, num_updates=8290, lr=4.83493e-05, gnorm=0.671, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39657
2022-10-13 02:35:38 - progress_bar.py[line:274] - INFO: epoch 001:   8312 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=8300, lr=4.83448e-05, gnorm=0.662, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39668
2022-10-13 02:35:49 - progress_bar.py[line:274] - INFO: epoch 001:   8322 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.7, ups=0.9, wpb=109.1, bsz=40, num_updates=8310, lr=4.83403e-05, gnorm=0.656, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39679
2022-10-13 02:36:01 - progress_bar.py[line:274] - INFO: epoch 001:   8332 / 28910 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.1, ups=0.88, wpb=111, bsz=40, num_updates=8320, lr=4.83358e-05, gnorm=0.732, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=39690
2022-10-13 02:36:12 - progress_bar.py[line:274] - INFO: epoch 001:   8342 / 28910 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=8330, lr=4.83313e-05, gnorm=0.577, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39701
2022-10-13 02:36:23 - progress_bar.py[line:274] - INFO: epoch 001:   8352 / 28910 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=102, ups=0.92, wpb=111.2, bsz=40, num_updates=8340, lr=4.83268e-05, gnorm=0.673, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39712
2022-10-13 02:36:34 - progress_bar.py[line:274] - INFO: epoch 001:   8362 / 28910 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.3, ups=0.88, wpb=111.7, bsz=40, num_updates=8350, lr=4.83223e-05, gnorm=0.698, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39724
2022-10-13 02:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   8372 / 28910 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96.3, ups=0.88, wpb=109, bsz=40, num_updates=8360, lr=4.83178e-05, gnorm=0.718, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39735
2022-10-13 02:36:57 - progress_bar.py[line:274] - INFO: epoch 001:   8382 / 28910 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.6, ups=0.91, wpb=109.9, bsz=40, num_updates=8370, lr=4.83133e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39746
2022-10-13 02:37:08 - progress_bar.py[line:274] - INFO: epoch 001:   8392 / 28910 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=8380, lr=4.83088e-05, gnorm=0.753, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39758
2022-10-13 02:37:19 - progress_bar.py[line:274] - INFO: epoch 001:   8402 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=99, ups=0.92, wpb=107.8, bsz=40, num_updates=8390, lr=4.83043e-05, gnorm=0.697, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=39768
2022-10-13 02:37:30 - progress_bar.py[line:274] - INFO: epoch 001:   8412 / 28910 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=101.5, ups=0.92, wpb=109.8, bsz=40, num_updates=8400, lr=4.82998e-05, gnorm=0.699, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39779
2022-10-13 02:37:41 - progress_bar.py[line:274] - INFO: epoch 001:   8422 / 28910 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96.2, ups=0.87, wpb=110.5, bsz=40, num_updates=8410, lr=4.82953e-05, gnorm=0.646, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39791
2022-10-13 02:37:52 - progress_bar.py[line:274] - INFO: epoch 001:   8432 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.7, ups=0.92, wpb=109.9, bsz=40, num_updates=8420, lr=4.82908e-05, gnorm=0.741, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39802
2022-10-13 02:38:03 - progress_bar.py[line:274] - INFO: epoch 001:   8442 / 28910 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100, ups=0.91, wpb=109.4, bsz=40, num_updates=8430, lr=4.82863e-05, gnorm=0.716, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39813
2022-10-13 02:38:14 - progress_bar.py[line:274] - INFO: epoch 001:   8452 / 28910 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=99.8, ups=0.89, wpb=112, bsz=40, num_updates=8440, lr=4.82818e-05, gnorm=0.602, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39824
2022-10-13 02:38:26 - progress_bar.py[line:274] - INFO: epoch 001:   8462 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=95.7, ups=0.88, wpb=108.1, bsz=40, num_updates=8450, lr=4.82773e-05, gnorm=0.737, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39835
2022-10-13 02:38:37 - progress_bar.py[line:274] - INFO: epoch 001:   8472 / 28910 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.6, ups=0.88, wpb=110.4, bsz=40, num_updates=8460, lr=4.82728e-05, gnorm=0.784, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39847
2022-10-13 02:38:48 - progress_bar.py[line:274] - INFO: epoch 001:   8482 / 28910 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=102.3, ups=0.91, wpb=111.9, bsz=40, num_updates=8470, lr=4.82683e-05, gnorm=0.708, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39858
2022-10-13 02:38:59 - progress_bar.py[line:274] - INFO: epoch 001:   8492 / 28910 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96.9, ups=0.89, wpb=109.4, bsz=40, num_updates=8480, lr=4.82637e-05, gnorm=0.729, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39869
2022-10-13 02:39:11 - progress_bar.py[line:274] - INFO: epoch 001:   8502 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=99.1, ups=0.88, wpb=112.2, bsz=40, num_updates=8490, lr=4.82592e-05, gnorm=0.644, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39880
2022-10-13 02:39:22 - progress_bar.py[line:274] - INFO: epoch 001:   8512 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96.9, ups=0.87, wpb=111.1, bsz=40, num_updates=8500, lr=4.82547e-05, gnorm=0.674, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39892
2022-10-13 02:39:33 - progress_bar.py[line:274] - INFO: epoch 001:   8522 / 28910 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=104.3, ups=0.94, wpb=111, bsz=40, num_updates=8510, lr=4.82502e-05, gnorm=0.768, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39902
2022-10-13 02:39:44 - progress_bar.py[line:274] - INFO: epoch 001:   8532 / 28910 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.9, ups=0.92, wpb=110, bsz=40, num_updates=8520, lr=4.82457e-05, gnorm=0.678, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39913
2022-10-13 02:39:55 - progress_bar.py[line:274] - INFO: epoch 001:   8542 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101.1, ups=0.91, wpb=111.3, bsz=40, num_updates=8530, lr=4.82412e-05, gnorm=0.594, clip=10, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=39924
2022-10-13 02:40:06 - progress_bar.py[line:274] - INFO: epoch 001:   8552 / 28910 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=8540, lr=4.82367e-05, gnorm=0.651, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39936
2022-10-13 02:40:17 - progress_bar.py[line:274] - INFO: epoch 001:   8562 / 28910 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=99.1, ups=0.89, wpb=111.4, bsz=40, num_updates=8550, lr=4.82322e-05, gnorm=0.629, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39947
2022-10-13 02:40:29 - progress_bar.py[line:274] - INFO: epoch 001:   8572 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=94.9, ups=0.87, wpb=109.3, bsz=40, num_updates=8560, lr=4.82277e-05, gnorm=0.702, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39958
2022-10-13 02:40:40 - progress_bar.py[line:274] - INFO: epoch 001:   8582 / 28910 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.3, ups=0.88, wpb=110.9, bsz=40, num_updates=8570, lr=4.82232e-05, gnorm=0.686, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39970
2022-10-13 02:40:51 - progress_bar.py[line:274] - INFO: epoch 001:   8592 / 28910 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101.4, ups=0.91, wpb=111.4, bsz=40, num_updates=8580, lr=4.82187e-05, gnorm=0.759, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39981
2022-10-13 02:41:02 - progress_bar.py[line:274] - INFO: epoch 001:   8602 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.5, ups=0.88, wpb=110.3, bsz=40, num_updates=8590, lr=4.82142e-05, gnorm=0.613, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39992
2022-10-13 02:41:14 - progress_bar.py[line:274] - INFO: epoch 001:   8612 / 28910 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=99.1, ups=0.91, wpb=109.5, bsz=40, num_updates=8600, lr=4.82097e-05, gnorm=0.686, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40003
2022-10-13 02:41:25 - progress_bar.py[line:274] - INFO: epoch 001:   8622 / 28910 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.7, ups=0.89, wpb=110.7, bsz=40, num_updates=8610, lr=4.82052e-05, gnorm=0.598, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40014
2022-10-13 02:41:36 - progress_bar.py[line:274] - INFO: epoch 001:   8632 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.9, ups=0.9, wpb=110.4, bsz=40, num_updates=8620, lr=4.82007e-05, gnorm=0.674, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40026
2022-10-13 02:41:47 - progress_bar.py[line:274] - INFO: epoch 001:   8642 / 28910 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=8630, lr=4.81962e-05, gnorm=0.567, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40037
2022-10-13 02:41:58 - progress_bar.py[line:274] - INFO: epoch 001:   8652 / 28910 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=99.4, ups=0.89, wpb=111.5, bsz=40, num_updates=8640, lr=4.81917e-05, gnorm=0.521, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40048
2022-10-13 02:42:10 - progress_bar.py[line:274] - INFO: epoch 001:   8662 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=8650, lr=4.81872e-05, gnorm=0.656, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=40059
2022-10-13 02:42:21 - progress_bar.py[line:274] - INFO: epoch 001:   8672 / 28910 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=8660, lr=4.81827e-05, gnorm=0.612, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40071
2022-10-13 02:42:32 - progress_bar.py[line:274] - INFO: epoch 001:   8682 / 28910 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=8670, lr=4.81782e-05, gnorm=0.626, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40082
2022-10-13 02:42:43 - progress_bar.py[line:274] - INFO: epoch 001:   8692 / 28910 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=102.9, ups=0.93, wpb=111, bsz=40, num_updates=8680, lr=4.81737e-05, gnorm=0.616, clip=0, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=40092
2022-10-13 02:42:54 - progress_bar.py[line:274] - INFO: epoch 001:   8702 / 28910 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.1, ups=0.89, wpb=109.6, bsz=40, num_updates=8690, lr=4.81692e-05, gnorm=0.709, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40104
2022-10-13 02:43:05 - progress_bar.py[line:274] - INFO: epoch 001:   8712 / 28910 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=95.8, ups=0.88, wpb=108.5, bsz=40, num_updates=8700, lr=4.81647e-05, gnorm=0.603, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40115
2022-10-13 02:43:17 - progress_bar.py[line:274] - INFO: epoch 001:   8722 / 28910 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=8710, lr=4.81602e-05, gnorm=0.545, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40126
2022-10-13 02:43:28 - progress_bar.py[line:274] - INFO: epoch 001:   8732 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=102.7, ups=0.94, wpb=109.3, bsz=40, num_updates=8720, lr=4.81557e-05, gnorm=0.71, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40137
2022-10-13 02:43:39 - progress_bar.py[line:274] - INFO: epoch 001:   8742 / 28910 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=100.8, ups=0.9, wpb=111.7, bsz=40, num_updates=8730, lr=4.81512e-05, gnorm=0.594, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40148
2022-10-13 02:43:50 - progress_bar.py[line:274] - INFO: epoch 001:   8752 / 28910 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96.8, ups=0.89, wpb=109.3, bsz=40, num_updates=8740, lr=4.81466e-05, gnorm=0.761, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40160
2022-10-13 02:44:01 - progress_bar.py[line:274] - INFO: epoch 001:   8762 / 28910 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=99.3, ups=0.89, wpb=111.3, bsz=40, num_updates=8750, lr=4.81421e-05, gnorm=0.694, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40171
2022-10-13 02:44:13 - progress_bar.py[line:274] - INFO: epoch 001:   8772 / 28910 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=96.8, ups=0.88, wpb=109.8, bsz=40, num_updates=8760, lr=4.81376e-05, gnorm=0.652, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40182
2022-10-13 02:44:24 - progress_bar.py[line:274] - INFO: epoch 001:   8782 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.2, ups=0.89, wpb=109, bsz=40, num_updates=8770, lr=4.81331e-05, gnorm=0.739, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40194
2022-10-13 02:44:35 - progress_bar.py[line:274] - INFO: epoch 001:   8792 / 28910 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=8780, lr=4.81286e-05, gnorm=0.758, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40205
2022-10-13 02:44:47 - progress_bar.py[line:274] - INFO: epoch 001:   8802 / 28910 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=96.1, ups=0.89, wpb=108.3, bsz=40, num_updates=8790, lr=4.81241e-05, gnorm=0.708, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40216
2022-10-13 02:44:58 - progress_bar.py[line:274] - INFO: epoch 001:   8812 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.7, ups=0.88, wpb=111, bsz=40, num_updates=8800, lr=4.81196e-05, gnorm=0.673, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40228
2022-10-13 02:45:09 - progress_bar.py[line:274] - INFO: epoch 001:   8822 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.5, ups=0.9, wpb=109.5, bsz=40, num_updates=8810, lr=4.81151e-05, gnorm=0.607, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40239
2022-10-13 02:45:20 - progress_bar.py[line:274] - INFO: epoch 001:   8832 / 28910 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=104.2, ups=0.94, wpb=111.2, bsz=40, num_updates=8820, lr=4.81106e-05, gnorm=0.612, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=40249
2022-10-13 02:45:31 - progress_bar.py[line:274] - INFO: epoch 001:   8842 / 28910 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96, ups=0.87, wpb=110, bsz=40, num_updates=8830, lr=4.81061e-05, gnorm=0.666, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40261
2022-10-13 02:45:43 - progress_bar.py[line:274] - INFO: epoch 001:   8852 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96.5, ups=0.88, wpb=109.1, bsz=40, num_updates=8840, lr=4.81016e-05, gnorm=0.728, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40272
2022-10-13 02:45:54 - progress_bar.py[line:274] - INFO: epoch 001:   8862 / 28910 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=8850, lr=4.80971e-05, gnorm=0.671, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40283
2022-10-13 02:46:05 - progress_bar.py[line:274] - INFO: epoch 001:   8872 / 28910 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=8860, lr=4.80926e-05, gnorm=0.727, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40295
2022-10-13 02:46:17 - progress_bar.py[line:274] - INFO: epoch 001:   8882 / 28910 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=94.8, ups=0.87, wpb=109, bsz=40, num_updates=8870, lr=4.80881e-05, gnorm=0.805, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40306
2022-10-13 02:46:28 - progress_bar.py[line:274] - INFO: epoch 001:   8892 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.4, ups=0.89, wpb=111.4, bsz=40, num_updates=8880, lr=4.80836e-05, gnorm=0.685, clip=10, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=40317
2022-10-13 02:46:39 - progress_bar.py[line:274] - INFO: epoch 001:   8902 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=102.7, ups=0.92, wpb=112.1, bsz=40, num_updates=8890, lr=4.80791e-05, gnorm=0.709, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40328
2022-10-13 02:46:50 - progress_bar.py[line:274] - INFO: epoch 001:   8912 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97, ups=0.88, wpb=109.9, bsz=40, num_updates=8900, lr=4.80746e-05, gnorm=0.66, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40340
2022-10-13 02:47:01 - progress_bar.py[line:274] - INFO: epoch 001:   8922 / 28910 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=8910, lr=4.80701e-05, gnorm=0.556, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40351
2022-10-13 02:47:13 - progress_bar.py[line:274] - INFO: epoch 001:   8932 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=99.4, ups=0.9, wpb=111.1, bsz=40, num_updates=8920, lr=4.80656e-05, gnorm=0.618, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40362
2022-10-13 02:47:24 - progress_bar.py[line:274] - INFO: epoch 001:   8942 / 28910 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=101.8, ups=0.92, wpb=110.9, bsz=40, num_updates=8930, lr=4.80611e-05, gnorm=0.63, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40373
2022-10-13 02:47:35 - progress_bar.py[line:274] - INFO: epoch 001:   8952 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.2, ups=0.9, wpb=110.7, bsz=40, num_updates=8940, lr=4.80566e-05, gnorm=0.654, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40384
2022-10-13 02:47:46 - progress_bar.py[line:274] - INFO: epoch 001:   8962 / 28910 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=8950, lr=4.80521e-05, gnorm=0.67, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40396
2022-10-13 02:47:57 - progress_bar.py[line:274] - INFO: epoch 001:   8972 / 28910 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=8960, lr=4.80476e-05, gnorm=0.664, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40407
2022-10-13 02:48:08 - progress_bar.py[line:274] - INFO: epoch 001:   8982 / 28910 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100, ups=0.91, wpb=109.5, bsz=40, num_updates=8970, lr=4.80431e-05, gnorm=0.677, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40418
2022-10-13 02:48:19 - progress_bar.py[line:274] - INFO: epoch 001:   8992 / 28910 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.9, ups=0.9, wpb=109.8, bsz=40, num_updates=8980, lr=4.80386e-05, gnorm=0.644, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40429
2022-10-13 02:48:30 - progress_bar.py[line:274] - INFO: epoch 001:   9002 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=101.1, ups=0.93, wpb=109.2, bsz=40, num_updates=8990, lr=4.8034e-05, gnorm=0.763, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40440
2022-10-13 02:48:41 - progress_bar.py[line:274] - INFO: epoch 001:   9012 / 28910 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.1, ups=0.89, wpb=110.6, bsz=40, num_updates=9000, lr=4.80295e-05, gnorm=0.763, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40451
2022-10-13 02:48:41 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 02:48:43 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 02:48:43 - train.py[line:551] - INFO: load:1.35 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 02:48:59 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 8.88 GiB already allocated; 1.24 GiB free; 35.86 GiB reserved in total by PyTorch)
2022-10-13 02:48:59 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 14        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9091 MB |   14321 MB |    5838 TB |    5838 TB |
|       from large pool |    8946 MB |   14176 MB |    5836 TB |    5836 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9091 MB |   14321 MB |    5838 TB |    5838 TB |
|       from large pool |    8946 MB |   14176 MB |    5836 TB |    5836 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36722 MB |   36722 MB |  181094 MB |  144372 MB |
|       from large pool |   36576 MB |   36576 MB |  180778 MB |  144202 MB |
|       from small pool |     146 MB |     146 MB |     316 MB |     170 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   27630 MB |   27630 MB |    6047 TB |    6047 TB |
|       from large pool |   27629 MB |   27629 MB |    6046 TB |    6046 TB |
|       from small pool |       1 MB |       1 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |  270855 K  |  270852 K  |
|       from large pool |     563    |     575    |   87264 K  |   87263 K  |
|       from small pool |    3106    |    3116    |  183591 K  |  183588 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |  270855 K  |  270852 K  |
|       from large pool |     563    |     575    |   87264 K  |   87263 K  |
|       from small pool |    3106    |    3116    |  183591 K  |  183588 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     135    |     135    |     516    |     381    |
|       from large pool |      62    |      62    |     358    |     296    |
|       from small pool |      73    |      73    |     158    |      85    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      86    |      94    |  196661 K  |  196661 K  |
|       from large pool |      51    |      54    |   37360 K  |   37360 K  |
|       from small pool |      35    |      46    |  159300 K  |  159300 K  |
|===========================================================================|

2022-10-13 02:48:59 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-13 02:48:59 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-13 02:51:16 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 02:51:16 - train.py[line:551] - INFO: load:1.37 valid_run:152.77 task_valid:148.44 collect_output:2.42
2022-10-13 02:53:45 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 02:53:45 - train.py[line:551] - INFO: load:1.40 valid_run:302.00 task_valid:292.47 collect_output:6.51
2022-10-13 02:56:18 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 02:56:18 - train.py[line:551] - INFO: load:1.43 valid_run:454.78 task_valid:436.12 collect_output:14.48
2022-10-13 02:58:47 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 02:58:47 - train.py[line:551] - INFO: load:1.46 valid_run:604.14 task_valid:581.30 collect_output:17.56
2022-10-13 03:01:20 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 03:01:20 - train.py[line:551] - INFO: load:1.48 valid_run:757.13 task_valid:729.31 collect_output:21.44
2022-10-13 03:03:53 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 03:03:53 - train.py[line:551] - INFO: load:1.51 valid_run:909.38 task_valid:875.83 collect_output:26.00
2022-10-13 03:06:26 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 03:06:26 - train.py[line:551] - INFO: load:1.54 valid_run:1062.74 task_valid:1021.87 collect_output:32.23
2022-10-13 03:08:57 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 03:08:57 - train.py[line:551] - INFO: load:1.56 valid_run:1213.84 task_valid:1162.54 collect_output:41.64
2022-10-13 03:11:27 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 03:11:27 - train.py[line:551] - INFO: load:1.59 valid_run:1363.13 task_valid:1306.84 collect_output:45.60
2022-10-13 03:13:55 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 03:13:55 - train.py[line:551] - INFO: load:1.61 valid_run:1511.35 task_valid:1449.73 collect_output:49.90
2022-10-13 03:16:24 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 03:16:24 - train.py[line:551] - INFO: load:1.64 valid_run:1660.73 task_valid:1594.01 collect_output:53.99
2022-10-13 03:18:54 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 03:18:54 - train.py[line:551] - INFO: load:1.67 valid_run:1810.36 task_valid:1738.60 collect_output:58.01
2022-10-13 03:21:24 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 03:21:24 - train.py[line:551] - INFO: load:1.69 valid_run:1959.94 task_valid:1880.05 collect_output:65.12
2022-10-13 03:23:54 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 03:23:54 - train.py[line:551] - INFO: load:1.72 valid_run:2109.99 task_valid:2025.02 collect_output:69.17
2022-10-13 03:26:24 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 03:26:24 - train.py[line:551] - INFO: load:1.74 valid_run:2259.61 task_valid:2170.88 collect_output:71.91
2022-10-13 03:28:53 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 03:28:53 - train.py[line:551] - INFO: load:1.77 valid_run:2409.19 task_valid:2314.63 collect_output:76.73
2022-10-13 03:31:25 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 03:31:25 - train.py[line:551] - INFO: load:1.79 valid_run:2560.48 task_valid:2459.48 collect_output:82.16
2022-10-13 03:33:55 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 03:33:55 - train.py[line:551] - INFO: load:1.82 valid_run:2710.56 task_valid:2605.70 collect_output:85.01
2022-10-13 03:36:23 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 03:36:23 - train.py[line:551] - INFO: load:1.84 valid_run:2858.88 task_valid:2746.76 collect_output:91.24
2022-10-13 03:38:53 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 03:38:53 - train.py[line:551] - INFO: load:1.87 valid_run:3008.75 task_valid:2891.30 collect_output:95.55
2022-10-13 03:41:25 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 03:41:25 - train.py[line:551] - INFO: load:1.89 valid_run:3160.26 task_valid:3035.23 collect_output:102.11
2022-10-13 03:43:53 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 03:43:53 - train.py[line:551] - INFO: load:1.92 valid_run:3309.16 task_valid:3179.32 collect_output:105.91
2022-10-13 03:46:24 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 03:46:24 - train.py[line:551] - INFO: load:1.94 valid_run:3459.96 task_valid:3324.91 collect_output:110.09
2022-10-13 03:48:55 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 03:48:55 - train.py[line:551] - INFO: load:1.97 valid_run:3610.90 task_valid:3471.00 collect_output:113.94

====================================================================================================
SGG eval:     R @ 50: 0.6207;     R @ 100: 0.6559;     R @ 500: 0.6878;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4040;    mR @ 100: 0.4480;    mR @ 500: 0.4935;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:1.0000) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.2500) (hanging from:0.3935) (lying on:0.3000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9516) (says:0.0000) (sitting on:0.7027) (standing on:0.3693) (using:0.6500) (walking in:0.0000) (walking on:0.6757) (watching:0.4931) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6207;     R @ 100: 0.6559;     R @ 500: 0.6878;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4040;    mR @ 100: 0.4480;    mR @ 500: 0.4935;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:1.0000) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.2500) (hanging from:0.3935) (lying on:0.3000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9516) (says:0.0000) (sitting on:0.7027) (standing on:0.3693) (using:0.6500) (walking in:0.0000) (walking on:0.6757) (watching:0.4931) 
--------------------------------------------------------
====================================================================================================

2022-10-13 03:51:27 - train.py[line:487] - INFO: 0.6559148459383752
2022-10-13 03:51:27 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 03:51:27 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.345 | loss_v1 0 | loss_v2 0 | nll_loss 0.19 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.655915 | ppl 1.14 | vqa_score 0.5878 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 9000 | best_R@100 0.708635
2022-10-13 03:51:27 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 9000 updates
2022-10-13 03:51:27 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_9000.pt
2022-10-13 03:51:33 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_9000.pt
2022-10-13 03:51:35 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_9000.pt (epoch 1 @ 9000 updates, score 0.6559148459383752) (writing took 8.297690447885543 seconds)
2022-10-13 03:51:44 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 03:51:47 - progress_bar.py[line:274] - INFO: epoch 001:   9023 / 28910 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=0.3, ups=0, wpb=110.6, bsz=40, num_updates=9010, lr=4.8025e-05, gnorm=0.681, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=44237
2022-10-13 03:51:59 - progress_bar.py[line:274] - INFO: epoch 001:   9033 / 28910 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.3, ups=0.89, wpb=110.7, bsz=40, num_updates=9020, lr=4.80205e-05, gnorm=0.749, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44248
2022-10-13 03:52:10 - progress_bar.py[line:274] - INFO: epoch 001:   9043 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.4, ups=0.91, wpb=111.1, bsz=40, num_updates=9030, lr=4.8016e-05, gnorm=0.783, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44259
2022-10-13 03:52:21 - progress_bar.py[line:274] - INFO: epoch 001:   9053 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.2, ups=0.88, wpb=110.1, bsz=40, num_updates=9040, lr=4.80115e-05, gnorm=0.664, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44271
2022-10-13 03:52:32 - progress_bar.py[line:274] - INFO: epoch 001:   9063 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=9050, lr=4.8007e-05, gnorm=0.601, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44282
2022-10-13 03:52:44 - progress_bar.py[line:274] - INFO: epoch 001:   9073 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=96.1, ups=0.88, wpb=109, bsz=40, num_updates=9060, lr=4.80025e-05, gnorm=0.562, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44293
2022-10-13 03:52:55 - progress_bar.py[line:274] - INFO: epoch 001:   9083 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.5, ups=0.89, wpb=109.3, bsz=40, num_updates=9070, lr=4.7998e-05, gnorm=0.654, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44304
2022-10-13 03:53:06 - progress_bar.py[line:274] - INFO: epoch 001:   9093 / 28910 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.7, ups=0.88, wpb=110.7, bsz=40, num_updates=9080, lr=4.79935e-05, gnorm=0.648, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44316
2022-10-13 03:53:17 - progress_bar.py[line:274] - INFO: epoch 001:   9103 / 28910 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.6, ups=0.9, wpb=108.9, bsz=40, num_updates=9090, lr=4.7989e-05, gnorm=0.706, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44327
2022-10-13 03:53:29 - progress_bar.py[line:274] - INFO: epoch 001:   9113 / 28910 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=95, ups=0.87, wpb=108.8, bsz=40, num_updates=9100, lr=4.79845e-05, gnorm=0.746, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44338
2022-10-13 03:53:40 - progress_bar.py[line:274] - INFO: epoch 001:   9123 / 28910 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97, ups=0.88, wpb=109.9, bsz=40, num_updates=9110, lr=4.798e-05, gnorm=0.655, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44350
2022-10-13 03:53:51 - progress_bar.py[line:274] - INFO: epoch 001:   9133 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=9120, lr=4.79755e-05, gnorm=0.807, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44361
2022-10-13 03:54:02 - progress_bar.py[line:274] - INFO: epoch 001:   9143 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101.1, ups=0.9, wpb=112.2, bsz=40, num_updates=9130, lr=4.7971e-05, gnorm=0.818, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44372
2022-10-13 03:54:13 - progress_bar.py[line:274] - INFO: epoch 001:   9153 / 28910 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=101.2, ups=0.91, wpb=110.7, bsz=40, num_updates=9140, lr=4.79665e-05, gnorm=0.741, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44383
2022-10-13 03:54:24 - progress_bar.py[line:274] - INFO: epoch 001:   9163 / 28910 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=102.2, ups=0.93, wpb=110.2, bsz=40, num_updates=9150, lr=4.7962e-05, gnorm=0.71, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44394
2022-10-13 03:54:36 - progress_bar.py[line:274] - INFO: epoch 001:   9173 / 28910 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=96.2, ups=0.87, wpb=111, bsz=40, num_updates=9160, lr=4.79575e-05, gnorm=0.69, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44405
2022-10-13 03:54:47 - progress_bar.py[line:274] - INFO: epoch 001:   9183 / 28910 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=94.7, ups=0.87, wpb=109.2, bsz=40, num_updates=9170, lr=4.7953e-05, gnorm=0.684, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44417
2022-10-13 03:54:59 - progress_bar.py[line:274] - INFO: epoch 001:   9193 / 28910 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=99.3, ups=0.9, wpb=110.3, bsz=40, num_updates=9180, lr=4.79485e-05, gnorm=0.605, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44428
2022-10-13 03:55:10 - progress_bar.py[line:274] - INFO: epoch 001:   9203 / 28910 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=99.3, ups=0.9, wpb=110.5, bsz=40, num_updates=9190, lr=4.7944e-05, gnorm=0.745, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44440
2022-10-13 03:55:21 - progress_bar.py[line:274] - INFO: epoch 001:   9213 / 28910 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.7, ups=0.89, wpb=109.9, bsz=40, num_updates=9200, lr=4.79395e-05, gnorm=0.625, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=44451
2022-10-13 03:55:32 - progress_bar.py[line:274] - INFO: epoch 001:   9223 / 28910 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.7, ups=0.9, wpb=109.1, bsz=40, num_updates=9210, lr=4.7935e-05, gnorm=0.807, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44462
2022-10-13 03:55:43 - progress_bar.py[line:274] - INFO: epoch 001:   9233 / 28910 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=101.9, ups=0.93, wpb=110.1, bsz=40, num_updates=9220, lr=4.79305e-05, gnorm=0.772, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44473
2022-10-13 03:55:54 - progress_bar.py[line:274] - INFO: epoch 001:   9243 / 28910 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=103.4, ups=0.92, wpb=112, bsz=40, num_updates=9230, lr=4.7926e-05, gnorm=0.643, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44484
2022-10-13 03:56:05 - progress_bar.py[line:274] - INFO: epoch 001:   9253 / 28910 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=96.9, ups=0.87, wpb=111, bsz=40, num_updates=9240, lr=4.79215e-05, gnorm=0.711, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44495
2022-10-13 03:56:17 - progress_bar.py[line:274] - INFO: epoch 001:   9263 / 28910 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.2, ups=0.88, wpb=109.9, bsz=40, num_updates=9250, lr=4.79169e-05, gnorm=0.658, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=44506
2022-10-13 03:56:28 - progress_bar.py[line:274] - INFO: epoch 001:   9273 / 28910 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=101.2, ups=0.91, wpb=110.8, bsz=40, num_updates=9260, lr=4.79124e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44517
2022-10-13 03:56:39 - progress_bar.py[line:274] - INFO: epoch 001:   9283 / 28910 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=9270, lr=4.79079e-05, gnorm=0.583, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44529
2022-10-13 03:56:50 - progress_bar.py[line:274] - INFO: epoch 001:   9293 / 28910 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=97.8, ups=0.9, wpb=109.2, bsz=40, num_updates=9280, lr=4.79034e-05, gnorm=0.707, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44540
2022-10-13 03:57:02 - progress_bar.py[line:274] - INFO: epoch 001:   9303 / 28910 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.4, ups=0.88, wpb=110.1, bsz=40, num_updates=9290, lr=4.78989e-05, gnorm=0.785, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44551
2022-10-13 03:57:13 - progress_bar.py[line:274] - INFO: epoch 001:   9313 / 28910 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.7, ups=0.88, wpb=110.6, bsz=40, num_updates=9300, lr=4.78944e-05, gnorm=0.756, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44562
2022-10-13 03:57:24 - progress_bar.py[line:274] - INFO: epoch 001:   9323 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=9310, lr=4.78899e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44574
2022-10-13 03:57:36 - progress_bar.py[line:274] - INFO: epoch 001:   9333 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.1, ups=0.87, wpb=111.7, bsz=40, num_updates=9320, lr=4.78854e-05, gnorm=0.562, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44585
2022-10-13 03:57:46 - progress_bar.py[line:274] - INFO: epoch 001:   9343 / 28910 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=101.2, ups=0.92, wpb=110.6, bsz=40, num_updates=9330, lr=4.78809e-05, gnorm=0.796, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44596
2022-10-13 03:57:58 - progress_bar.py[line:274] - INFO: epoch 001:   9353 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.5, ups=0.88, wpb=111, bsz=40, num_updates=9340, lr=4.78764e-05, gnorm=0.707, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=44608
2022-10-13 03:58:09 - progress_bar.py[line:274] - INFO: epoch 001:   9363 / 28910 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=9350, lr=4.78719e-05, gnorm=0.725, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44619
2022-10-13 03:58:20 - progress_bar.py[line:274] - INFO: epoch 001:   9373 / 28910 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=97.9, ups=0.89, wpb=110.4, bsz=40, num_updates=9360, lr=4.78674e-05, gnorm=0.664, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44630
2022-10-13 03:58:31 - progress_bar.py[line:274] - INFO: epoch 001:   9383 / 28910 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=101.2, ups=0.91, wpb=110.7, bsz=40, num_updates=9370, lr=4.78629e-05, gnorm=0.755, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44641
2022-10-13 03:58:43 - progress_bar.py[line:274] - INFO: epoch 001:   9393 / 28910 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=9380, lr=4.78584e-05, gnorm=0.672, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44652
2022-10-13 03:58:54 - progress_bar.py[line:274] - INFO: epoch 001:   9403 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.1, ups=0.9, wpb=109.5, bsz=40, num_updates=9390, lr=4.78539e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44663
2022-10-13 03:59:05 - progress_bar.py[line:274] - INFO: epoch 001:   9413 / 28910 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=9400, lr=4.78494e-05, gnorm=0.659, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44675
2022-10-13 03:59:16 - progress_bar.py[line:274] - INFO: epoch 001:   9423 / 28910 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.9, ups=0.92, wpb=109.2, bsz=40, num_updates=9410, lr=4.78449e-05, gnorm=0.818, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44685
2022-10-13 03:59:27 - progress_bar.py[line:274] - INFO: epoch 001:   9433 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96.6, ups=0.88, wpb=109.4, bsz=40, num_updates=9420, lr=4.78404e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44697
2022-10-13 03:59:38 - progress_bar.py[line:274] - INFO: epoch 001:   9443 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=100.1, ups=0.89, wpb=112.2, bsz=40, num_updates=9430, lr=4.78359e-05, gnorm=0.682, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=44708
2022-10-13 03:59:50 - progress_bar.py[line:274] - INFO: epoch 001:   9453 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=95.9, ups=0.87, wpb=110.2, bsz=40, num_updates=9440, lr=4.78314e-05, gnorm=0.833, clip=20, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=44720
2022-10-13 04:00:01 - progress_bar.py[line:274] - INFO: epoch 001:   9463 / 28910 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=9450, lr=4.78269e-05, gnorm=0.717, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44731
2022-10-13 04:00:12 - progress_bar.py[line:274] - INFO: epoch 001:   9473 / 28910 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=9460, lr=4.78224e-05, gnorm=0.73, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44742
2022-10-13 04:00:23 - progress_bar.py[line:274] - INFO: epoch 001:   9483 / 28910 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.6, ups=0.89, wpb=109.3, bsz=40, num_updates=9470, lr=4.78179e-05, gnorm=0.707, clip=0, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=44753
2022-10-13 04:00:35 - progress_bar.py[line:274] - INFO: epoch 001:   9493 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=95.9, ups=0.87, wpb=110, bsz=40, num_updates=9480, lr=4.78134e-05, gnorm=0.734, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44764
2022-10-13 04:00:46 - progress_bar.py[line:274] - INFO: epoch 001:   9503 / 28910 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.4, ups=0.89, wpb=110.7, bsz=40, num_updates=9490, lr=4.78089e-05, gnorm=0.762, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44776
2022-10-13 04:00:57 - progress_bar.py[line:274] - INFO: epoch 001:   9513 / 28910 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=101.8, ups=0.92, wpb=111.1, bsz=40, num_updates=9500, lr=4.78044e-05, gnorm=0.712, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44787
2022-10-13 04:01:08 - progress_bar.py[line:274] - INFO: epoch 001:   9523 / 28910 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=100.1, ups=0.92, wpb=109.2, bsz=40, num_updates=9510, lr=4.77998e-05, gnorm=0.678, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44798
2022-10-13 04:01:19 - progress_bar.py[line:274] - INFO: epoch 001:   9533 / 28910 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=9520, lr=4.77953e-05, gnorm=0.653, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44809
2022-10-13 04:01:30 - progress_bar.py[line:274] - INFO: epoch 001:   9543 / 28910 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=99, ups=0.89, wpb=111.1, bsz=40, num_updates=9530, lr=4.77908e-05, gnorm=0.725, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44820
2022-10-13 04:01:42 - progress_bar.py[line:274] - INFO: epoch 001:   9553 / 28910 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.5, ups=0.88, wpb=111, bsz=40, num_updates=9540, lr=4.77863e-05, gnorm=0.71, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44831
2022-10-13 04:01:53 - progress_bar.py[line:274] - INFO: epoch 001:   9563 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=102.1, ups=0.92, wpb=110.6, bsz=40, num_updates=9550, lr=4.77818e-05, gnorm=0.791, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44842
2022-10-13 04:02:04 - progress_bar.py[line:274] - INFO: epoch 001:   9573 / 28910 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.2, ups=0.9, wpb=109.6, bsz=40, num_updates=9560, lr=4.77773e-05, gnorm=0.812, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44853
2022-10-13 04:02:15 - progress_bar.py[line:274] - INFO: epoch 001:   9583 / 28910 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=9570, lr=4.77728e-05, gnorm=0.649, clip=0, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=44865
2022-10-13 04:02:27 - progress_bar.py[line:274] - INFO: epoch 001:   9593 / 28910 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=94.7, ups=0.87, wpb=109.1, bsz=40, num_updates=9580, lr=4.77683e-05, gnorm=0.74, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44876
2022-10-13 04:02:38 - progress_bar.py[line:274] - INFO: epoch 001:   9603 / 28910 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=95.4, ups=0.86, wpb=110.8, bsz=40, num_updates=9590, lr=4.77638e-05, gnorm=0.637, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=44888
2022-10-13 04:02:44 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 04:02:50 - progress_bar.py[line:274] - INFO: epoch 001:   9614 / 28910 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=91.2, ups=0.83, wpb=110, bsz=40, num_updates=9600, lr=4.77593e-05, gnorm=0.711, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=44900
2022-10-13 04:03:01 - progress_bar.py[line:274] - INFO: epoch 001:   9624 / 28910 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=9610, lr=4.77548e-05, gnorm=0.849, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44911
2022-10-13 04:03:12 - progress_bar.py[line:274] - INFO: epoch 001:   9634 / 28910 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=103.5, ups=0.94, wpb=110, bsz=40, num_updates=9620, lr=4.77503e-05, gnorm=0.764, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44922
2022-10-13 04:03:23 - progress_bar.py[line:274] - INFO: epoch 001:   9644 / 28910 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=9630, lr=4.77458e-05, gnorm=0.607, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44933
2022-10-13 04:03:35 - progress_bar.py[line:274] - INFO: epoch 001:   9654 / 28910 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=9640, lr=4.77413e-05, gnorm=0.613, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44944
2022-10-13 04:03:46 - progress_bar.py[line:274] - INFO: epoch 001:   9664 / 28910 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=95.4, ups=0.88, wpb=108.6, bsz=40, num_updates=9650, lr=4.77368e-05, gnorm=0.739, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=44956
2022-10-13 04:03:57 - progress_bar.py[line:274] - INFO: epoch 001:   9674 / 28910 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.7, ups=0.89, wpb=110.7, bsz=40, num_updates=9660, lr=4.77323e-05, gnorm=0.767, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44967
2022-10-13 04:04:09 - progress_bar.py[line:274] - INFO: epoch 001:   9684 / 28910 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=9670, lr=4.77278e-05, gnorm=0.856, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44978
2022-10-13 04:04:20 - progress_bar.py[line:274] - INFO: epoch 001:   9694 / 28910 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=98.7, ups=0.91, wpb=108.2, bsz=40, num_updates=9680, lr=4.77233e-05, gnorm=0.681, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44989
2022-10-13 04:04:31 - progress_bar.py[line:274] - INFO: epoch 001:   9704 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.8, ups=0.91, wpb=110.4, bsz=40, num_updates=9690, lr=4.77188e-05, gnorm=0.751, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45000
2022-10-13 04:04:41 - progress_bar.py[line:274] - INFO: epoch 001:   9714 / 28910 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=102.3, ups=0.93, wpb=110.4, bsz=40, num_updates=9700, lr=4.77143e-05, gnorm=0.522, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45011
2022-10-13 04:04:53 - progress_bar.py[line:274] - INFO: epoch 001:   9724 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=99.7, ups=0.9, wpb=111.2, bsz=40, num_updates=9710, lr=4.77098e-05, gnorm=0.656, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45022
2022-10-13 04:05:03 - progress_bar.py[line:274] - INFO: epoch 001:   9734 / 28910 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.9, ups=0.92, wpb=108.7, bsz=40, num_updates=9720, lr=4.77053e-05, gnorm=0.695, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45033
2022-10-13 04:05:15 - progress_bar.py[line:274] - INFO: epoch 001:   9744 / 28910 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=95.4, ups=0.88, wpb=108.4, bsz=40, num_updates=9730, lr=4.77008e-05, gnorm=0.637, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=45044
2022-10-13 04:05:26 - progress_bar.py[line:274] - INFO: epoch 001:   9754 / 28910 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=9740, lr=4.76963e-05, gnorm=0.657, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=45056
2022-10-13 04:05:37 - progress_bar.py[line:274] - INFO: epoch 001:   9764 / 28910 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.5, ups=0.89, wpb=109.6, bsz=40, num_updates=9750, lr=4.76918e-05, gnorm=0.621, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45067
2022-10-13 04:05:48 - progress_bar.py[line:274] - INFO: epoch 001:   9774 / 28910 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=100.8, ups=0.91, wpb=110.3, bsz=40, num_updates=9760, lr=4.76872e-05, gnorm=0.662, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45078
2022-10-13 04:06:00 - progress_bar.py[line:274] - INFO: epoch 001:   9784 / 28910 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96.5, ups=0.88, wpb=109.5, bsz=40, num_updates=9770, lr=4.76827e-05, gnorm=0.706, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45089
2022-10-13 04:06:11 - progress_bar.py[line:274] - INFO: epoch 001:   9794 / 28910 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=100.1, ups=0.91, wpb=110.6, bsz=40, num_updates=9780, lr=4.76782e-05, gnorm=0.754, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45100
2022-10-13 04:06:21 - progress_bar.py[line:274] - INFO: epoch 001:   9804 / 28910 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=103.6, ups=0.93, wpb=111.9, bsz=40, num_updates=9790, lr=4.76737e-05, gnorm=0.736, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45111
2022-10-13 04:06:33 - progress_bar.py[line:274] - INFO: epoch 001:   9814 / 28910 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=9800, lr=4.76692e-05, gnorm=0.6, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45122
2022-10-13 04:06:44 - progress_bar.py[line:274] - INFO: epoch 001:   9824 / 28910 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=9810, lr=4.76647e-05, gnorm=0.655, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45133
2022-10-13 04:06:55 - progress_bar.py[line:274] - INFO: epoch 001:   9834 / 28910 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=9820, lr=4.76602e-05, gnorm=0.681, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45145
2022-10-13 04:07:06 - progress_bar.py[line:274] - INFO: epoch 001:   9844 / 28910 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.1, ups=0.89, wpb=109.7, bsz=40, num_updates=9830, lr=4.76557e-05, gnorm=0.637, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45156
2022-10-13 04:07:17 - progress_bar.py[line:274] - INFO: epoch 001:   9854 / 28910 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.4, ups=0.9, wpb=108.7, bsz=40, num_updates=9840, lr=4.76512e-05, gnorm=0.802, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45167
2022-10-13 04:07:28 - progress_bar.py[line:274] - INFO: epoch 001:   9864 / 28910 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=102.4, ups=0.92, wpb=111.8, bsz=40, num_updates=9850, lr=4.76467e-05, gnorm=0.681, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45178
2022-10-13 04:07:39 - progress_bar.py[line:274] - INFO: epoch 001:   9874 / 28910 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=101, ups=0.91, wpb=111.5, bsz=40, num_updates=9860, lr=4.76422e-05, gnorm=0.704, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45189
2022-10-13 04:07:51 - progress_bar.py[line:274] - INFO: epoch 001:   9884 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96.7, ups=0.89, wpb=108.7, bsz=40, num_updates=9870, lr=4.76377e-05, gnorm=0.67, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45200
2022-10-13 04:08:02 - progress_bar.py[line:274] - INFO: epoch 001:   9894 / 28910 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=102.7, ups=0.92, wpb=111.9, bsz=40, num_updates=9880, lr=4.76332e-05, gnorm=0.707, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45211
2022-10-13 04:08:13 - progress_bar.py[line:274] - INFO: epoch 001:   9904 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=9890, lr=4.76287e-05, gnorm=0.791, clip=10, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=45222
2022-10-13 04:08:24 - progress_bar.py[line:274] - INFO: epoch 001:   9914 / 28910 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=9900, lr=4.76242e-05, gnorm=0.627, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45233
2022-10-13 04:08:35 - progress_bar.py[line:274] - INFO: epoch 001:   9924 / 28910 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.3, ups=0.89, wpb=109, bsz=40, num_updates=9910, lr=4.76197e-05, gnorm=0.617, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45245
2022-10-13 04:08:46 - progress_bar.py[line:274] - INFO: epoch 001:   9934 / 28910 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.2, ups=0.88, wpb=110, bsz=40, num_updates=9920, lr=4.76152e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45256
2022-10-13 04:08:58 - progress_bar.py[line:274] - INFO: epoch 001:   9944 / 28910 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96.8, ups=0.87, wpb=111.2, bsz=40, num_updates=9930, lr=4.76107e-05, gnorm=0.664, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45267
2022-10-13 04:09:09 - progress_bar.py[line:274] - INFO: epoch 001:   9954 / 28910 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=95.3, ups=0.87, wpb=109.5, bsz=40, num_updates=9940, lr=4.76062e-05, gnorm=0.674, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45279
2022-10-13 04:09:21 - progress_bar.py[line:274] - INFO: epoch 001:   9964 / 28910 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=96.1, ups=0.87, wpb=110.5, bsz=40, num_updates=9950, lr=4.76017e-05, gnorm=0.673, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45290
2022-10-13 04:09:32 - progress_bar.py[line:274] - INFO: epoch 001:   9974 / 28910 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=9960, lr=4.75972e-05, gnorm=0.595, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45302
2022-10-13 04:09:43 - progress_bar.py[line:274] - INFO: epoch 001:   9984 / 28910 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=101.1, ups=0.92, wpb=110.1, bsz=40, num_updates=9970, lr=4.75927e-05, gnorm=0.626, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45313
2022-10-13 04:09:54 - progress_bar.py[line:274] - INFO: epoch 001:   9994 / 28910 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=98.2, ups=0.89, wpb=110.3, bsz=40, num_updates=9980, lr=4.75882e-05, gnorm=0.657, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=45324
2022-10-13 04:10:05 - progress_bar.py[line:274] - INFO: epoch 001:  10004 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.9, ups=0.9, wpb=109.7, bsz=40, num_updates=9990, lr=4.75837e-05, gnorm=0.717, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45335
2022-10-13 04:10:16 - progress_bar.py[line:274] - INFO: epoch 001:  10014 / 28910 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.7, ups=0.9, wpb=109.4, bsz=40, num_updates=10000, lr=4.75792e-05, gnorm=0.575, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45346
2022-10-13 04:10:16 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 04:10:18 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 04:10:18 - train.py[line:551] - INFO: load:1.30 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 04:12:50 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 04:12:50 - train.py[line:551] - INFO: load:1.32 valid_run:152.19 task_valid:148.64 collect_output:2.43
2022-10-13 04:15:19 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 04:15:19 - train.py[line:551] - INFO: load:1.35 valid_run:301.26 task_valid:292.40 collect_output:6.61
2022-10-13 04:17:52 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 04:17:52 - train.py[line:551] - INFO: load:1.37 valid_run:453.63 task_valid:435.89 collect_output:14.37
2022-10-13 04:20:21 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 04:20:21 - train.py[line:551] - INFO: load:1.40 valid_run:602.31 task_valid:580.55 collect_output:17.41
2022-10-13 04:22:53 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 04:22:53 - train.py[line:551] - INFO: load:1.42 valid_run:754.45 task_valid:727.79 collect_output:21.28
2022-10-13 04:25:24 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 04:25:24 - train.py[line:551] - INFO: load:1.45 valid_run:905.79 task_valid:872.89 collect_output:26.55
2022-10-13 04:27:57 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 04:27:57 - train.py[line:551] - INFO: load:1.47 valid_run:1058.63 task_valid:1018.55 collect_output:32.71
2022-10-13 04:30:28 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 04:30:28 - train.py[line:551] - INFO: load:1.49 valid_run:1209.47 task_valid:1159.40 collect_output:41.70
2022-10-13 04:32:57 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 04:32:57 - train.py[line:551] - INFO: load:1.52 valid_run:1358.91 task_valid:1303.82 collect_output:45.71
2022-10-13 04:35:26 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 04:35:26 - train.py[line:551] - INFO: load:1.54 valid_run:1507.12 task_valid:1446.57 collect_output:50.18
2022-10-13 04:37:55 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 04:37:55 - train.py[line:551] - INFO: load:1.57 valid_run:1656.27 task_valid:1590.96 collect_output:53.94
2022-10-13 04:40:25 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 04:40:25 - train.py[line:551] - INFO: load:1.59 valid_run:1805.94 task_valid:1735.62 collect_output:57.94
2022-10-13 04:42:54 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 04:42:54 - train.py[line:551] - INFO: load:1.61 valid_run:1955.30 task_valid:1876.85 collect_output:65.09
2022-10-13 04:45:24 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 04:45:24 - train.py[line:551] - INFO: load:1.64 valid_run:2105.23 task_valid:2021.79 collect_output:69.09
2022-10-13 04:47:54 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 04:47:54 - train.py[line:551] - INFO: load:1.66 valid_run:2254.89 task_valid:2167.86 collect_output:71.68
2022-10-13 04:50:24 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 04:50:24 - train.py[line:551] - INFO: load:1.69 valid_run:2404.68 task_valid:2311.72 collect_output:76.60
2022-10-13 04:52:55 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 04:52:55 - train.py[line:551] - INFO: load:1.71 valid_run:2555.83 task_valid:2456.75 collect_output:81.70
2022-10-13 04:55:25 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 04:55:25 - train.py[line:551] - INFO: load:1.74 valid_run:2706.01 task_valid:2603.42 collect_output:84.20
2022-10-13 04:57:53 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 04:57:53 - train.py[line:551] - INFO: load:1.77 valid_run:2854.27 task_valid:2744.87 collect_output:89.98
2022-10-13 05:00:24 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 05:00:24 - train.py[line:551] - INFO: load:1.79 valid_run:3004.34 task_valid:2889.69 collect_output:94.24
2022-10-13 05:02:56 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 05:02:56 - train.py[line:551] - INFO: load:1.82 valid_run:3156.26 task_valid:3034.30 collect_output:100.50
2022-10-13 05:05:25 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 05:05:25 - train.py[line:551] - INFO: load:1.84 valid_run:3306.14 task_valid:3179.28 collect_output:104.32
2022-10-13 05:07:57 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 05:07:57 - train.py[line:551] - INFO: load:1.87 valid_run:3457.88 task_valid:3326.35 collect_output:107.95
2022-10-13 05:10:29 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 05:10:29 - train.py[line:551] - INFO: load:1.90 valid_run:3609.69 task_valid:3473.32 collect_output:111.71

====================================================================================================
SGG eval:     R @ 50: 0.6075;     R @ 100: 0.6521;     R @ 500: 0.6809;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3958;    mR @ 100: 0.4382;    mR @ 500: 0.4817;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.8750) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.2500) (hanging from:0.3871) (lying on:0.3000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9588) (says:0.0000) (sitting on:0.6925) (standing on:0.3843) (using:0.6500) (walking in:0.0000) (walking on:0.6486) (watching:0.4444) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6075;     R @ 100: 0.6521;     R @ 500: 0.6809;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3958;    mR @ 100: 0.4382;    mR @ 500: 0.4817;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.8750) (covering:0.3000) (eating:0.7647) (flying in:0.0000) (growing on:0.2500) (hanging from:0.3871) (lying on:0.3000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9588) (says:0.0000) (sitting on:0.6925) (standing on:0.3843) (using:0.6500) (walking in:0.0000) (walking on:0.6486) (watching:0.4444) 
--------------------------------------------------------
====================================================================================================

2022-10-13 05:13:01 - train.py[line:487] - INFO: 0.6521481792717087
2022-10-13 05:13:01 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 05:13:01 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.312 | loss_v1 0 | loss_v2 0 | nll_loss 0.154 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.652148 | ppl 1.11 | vqa_score 0.5867 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 10000 | best_R@100 0.708635
2022-10-13 05:13:01 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 10000 updates
2022-10-13 05:13:01 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_10000.pt
2022-10-13 05:13:07 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_10000.pt
2022-10-13 05:13:09 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 0.6521481792717087) (writing took 8.166924783028662 seconds)
2022-10-13 05:13:21 - progress_bar.py[line:274] - INFO: epoch 001:  10024 / 28910 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=0.3, ups=0, wpb=109.5, bsz=40, num_updates=10010, lr=4.75747e-05, gnorm=0.614, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49130
2022-10-13 05:13:32 - progress_bar.py[line:274] - INFO: epoch 001:  10034 / 28910 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=97.8, ups=0.88, wpb=110.5, bsz=40, num_updates=10020, lr=4.75701e-05, gnorm=0.695, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49142
2022-10-13 05:13:43 - progress_bar.py[line:274] - INFO: epoch 001:  10044 / 28910 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=10030, lr=4.75656e-05, gnorm=0.768, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49153
2022-10-13 05:13:54 - progress_bar.py[line:274] - INFO: epoch 001:  10054 / 28910 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=10040, lr=4.75611e-05, gnorm=0.652, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49164
2022-10-13 05:14:06 - progress_bar.py[line:274] - INFO: epoch 001:  10064 / 28910 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=98, ups=0.88, wpb=111.1, bsz=40, num_updates=10050, lr=4.75566e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49175
2022-10-13 05:14:17 - progress_bar.py[line:274] - INFO: epoch 001:  10074 / 28910 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=97.3, ups=0.89, wpb=109, bsz=40, num_updates=10060, lr=4.75521e-05, gnorm=0.731, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=49187
2022-10-13 05:14:28 - progress_bar.py[line:274] - INFO: epoch 001:  10084 / 28910 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=99.8, ups=0.9, wpb=110.9, bsz=40, num_updates=10070, lr=4.75476e-05, gnorm=0.565, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49198
2022-10-13 05:14:40 - progress_bar.py[line:274] - INFO: epoch 001:  10094 / 28910 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.3, ups=0.88, wpb=110.3, bsz=40, num_updates=10080, lr=4.75431e-05, gnorm=0.582, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49209
2022-10-13 05:14:50 - progress_bar.py[line:274] - INFO: epoch 001:  10104 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.9, ups=0.93, wpb=109.2, bsz=40, num_updates=10090, lr=4.75386e-05, gnorm=0.801, clip=20, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=49220
2022-10-13 05:15:01 - progress_bar.py[line:274] - INFO: epoch 001:  10114 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.5, ups=0.9, wpb=109, bsz=40, num_updates=10100, lr=4.75341e-05, gnorm=0.553, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49231
2022-10-13 05:15:12 - progress_bar.py[line:274] - INFO: epoch 001:  10124 / 28910 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=100.5, ups=0.92, wpb=109.5, bsz=40, num_updates=10110, lr=4.75296e-05, gnorm=0.741, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49242
2022-10-13 05:15:24 - progress_bar.py[line:274] - INFO: epoch 001:  10134 / 28910 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.12, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=10120, lr=4.75251e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49253
2022-10-13 05:15:35 - progress_bar.py[line:274] - INFO: epoch 001:  10144 / 28910 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=10130, lr=4.75206e-05, gnorm=0.655, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49264
2022-10-13 05:15:46 - progress_bar.py[line:274] - INFO: epoch 001:  10154 / 28910 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=10140, lr=4.75161e-05, gnorm=0.739, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49275
2022-10-13 05:15:57 - progress_bar.py[line:274] - INFO: epoch 001:  10164 / 28910 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=103.5, ups=0.93, wpb=111.8, bsz=40, num_updates=10150, lr=4.75116e-05, gnorm=0.638, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49286
2022-10-13 05:16:07 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 05:16:09 - progress_bar.py[line:274] - INFO: epoch 001:  10175 / 28910 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=89.1, ups=0.81, wpb=110.5, bsz=40, num_updates=10160, lr=4.75071e-05, gnorm=0.777, clip=10, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=49299
2022-10-13 05:16:20 - progress_bar.py[line:274] - INFO: epoch 001:  10185 / 28910 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=100.1, ups=0.91, wpb=110.1, bsz=40, num_updates=10170, lr=4.75026e-05, gnorm=0.599, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49310
2022-10-13 05:16:32 - progress_bar.py[line:274] - INFO: epoch 001:  10195 / 28910 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=96.4, ups=0.86, wpb=111.5, bsz=40, num_updates=10180, lr=4.74981e-05, gnorm=0.663, clip=0, loss_scale=512, train_wall=12, gb_free=11.2, ema_decay=0.9999, wall=49321
2022-10-13 05:16:43 - progress_bar.py[line:274] - INFO: epoch 001:  10205 / 28910 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=99.1, ups=0.89, wpb=111.5, bsz=40, num_updates=10190, lr=4.74936e-05, gnorm=0.631, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49333
2022-10-13 05:16:54 - progress_bar.py[line:274] - INFO: epoch 001:  10215 / 28910 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=10200, lr=4.74891e-05, gnorm=0.858, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49344
2022-10-13 05:17:06 - progress_bar.py[line:274] - INFO: epoch 001:  10225 / 28910 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=95.7, ups=0.87, wpb=110.1, bsz=40, num_updates=10210, lr=4.74846e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49355
2022-10-13 05:17:17 - progress_bar.py[line:274] - INFO: epoch 001:  10235 / 28910 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.8, ups=0.9, wpb=110.3, bsz=40, num_updates=10220, lr=4.74801e-05, gnorm=0.702, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49367
2022-10-13 05:17:29 - progress_bar.py[line:274] - INFO: epoch 001:  10245 / 28910 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=10230, lr=4.74756e-05, gnorm=0.648, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=49378
2022-10-13 05:17:40 - progress_bar.py[line:274] - INFO: epoch 001:  10255 / 28910 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=97.7, ups=0.88, wpb=110.7, bsz=40, num_updates=10240, lr=4.74711e-05, gnorm=0.57, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49390
2022-10-13 05:17:51 - progress_bar.py[line:274] - INFO: epoch 001:  10265 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=100.4, ups=0.91, wpb=110.4, bsz=40, num_updates=10250, lr=4.74666e-05, gnorm=0.682, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49401
2022-10-13 05:18:02 - progress_bar.py[line:274] - INFO: epoch 001:  10275 / 28910 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=100.7, ups=0.92, wpb=109, bsz=40, num_updates=10260, lr=4.74621e-05, gnorm=0.642, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49412
2022-10-13 05:18:13 - progress_bar.py[line:274] - INFO: epoch 001:  10285 / 28910 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=10270, lr=4.74576e-05, gnorm=0.607, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49423
2022-10-13 05:18:24 - progress_bar.py[line:274] - INFO: epoch 001:  10295 / 28910 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=102.3, ups=0.92, wpb=110.6, bsz=40, num_updates=10280, lr=4.7453e-05, gnorm=0.631, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49434
2022-10-13 05:18:35 - progress_bar.py[line:274] - INFO: epoch 001:  10305 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=10290, lr=4.74485e-05, gnorm=0.697, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49445
2022-10-13 05:18:46 - progress_bar.py[line:274] - INFO: epoch 001:  10315 / 28910 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=100.2, ups=0.91, wpb=110.3, bsz=40, num_updates=10300, lr=4.7444e-05, gnorm=0.655, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49456
2022-10-13 05:18:57 - progress_bar.py[line:274] - INFO: epoch 001:  10325 / 28910 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=99.4, ups=0.9, wpb=110.9, bsz=40, num_updates=10310, lr=4.74395e-05, gnorm=0.673, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49467
2022-10-13 05:19:09 - progress_bar.py[line:274] - INFO: epoch 001:  10335 / 28910 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.4, ups=0.88, wpb=112, bsz=40, num_updates=10320, lr=4.7435e-05, gnorm=0.647, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=49478
2022-10-13 05:19:20 - progress_bar.py[line:274] - INFO: epoch 001:  10345 / 28910 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.6, ups=0.89, wpb=110.6, bsz=40, num_updates=10330, lr=4.74305e-05, gnorm=0.671, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49490
2022-10-13 05:19:31 - progress_bar.py[line:274] - INFO: epoch 001:  10355 / 28910 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.5, ups=0.89, wpb=110.1, bsz=40, num_updates=10340, lr=4.7426e-05, gnorm=0.605, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=49501
2022-10-13 05:19:42 - progress_bar.py[line:274] - INFO: epoch 001:  10365 / 28910 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=100.6, ups=0.92, wpb=109.6, bsz=40, num_updates=10350, lr=4.74215e-05, gnorm=0.602, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49512
2022-10-13 05:19:53 - progress_bar.py[line:274] - INFO: epoch 001:  10375 / 28910 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=99, ups=0.91, wpb=108.6, bsz=40, num_updates=10360, lr=4.7417e-05, gnorm=0.584, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49523
2022-10-13 05:20:05 - progress_bar.py[line:274] - INFO: epoch 001:  10385 / 28910 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=96.8, ups=0.87, wpb=111.2, bsz=40, num_updates=10370, lr=4.74125e-05, gnorm=0.676, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49534
2022-10-13 05:20:16 - progress_bar.py[line:274] - INFO: epoch 001:  10395 / 28910 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=102.8, ups=0.93, wpb=110.7, bsz=40, num_updates=10380, lr=4.7408e-05, gnorm=0.758, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49545
2022-10-13 05:20:27 - progress_bar.py[line:274] - INFO: epoch 001:  10405 / 28910 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=96, ups=0.88, wpb=109.1, bsz=40, num_updates=10390, lr=4.74035e-05, gnorm=0.685, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49557
2022-10-13 05:20:38 - progress_bar.py[line:274] - INFO: epoch 001:  10415 / 28910 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=10400, lr=4.7399e-05, gnorm=0.657, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49568
2022-10-13 05:20:49 - progress_bar.py[line:274] - INFO: epoch 001:  10425 / 28910 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=99.9, ups=0.9, wpb=110.4, bsz=40, num_updates=10410, lr=4.73945e-05, gnorm=0.661, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49579
2022-10-13 05:21:00 - progress_bar.py[line:274] - INFO: epoch 001:  10435 / 28910 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=10420, lr=4.739e-05, gnorm=0.611, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49590
2022-10-13 05:21:11 - progress_bar.py[line:274] - INFO: epoch 001:  10445 / 28910 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=101.2, ups=0.91, wpb=111.6, bsz=40, num_updates=10430, lr=4.73855e-05, gnorm=0.571, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49601
2022-10-13 05:21:23 - progress_bar.py[line:274] - INFO: epoch 001:  10455 / 28910 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=97.2, ups=0.89, wpb=109.7, bsz=40, num_updates=10440, lr=4.7381e-05, gnorm=0.611, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49612
2022-10-13 05:21:34 - progress_bar.py[line:274] - INFO: epoch 001:  10465 / 28910 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=100.1, ups=0.9, wpb=110.8, bsz=40, num_updates=10450, lr=4.73765e-05, gnorm=0.726, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49623
2022-10-13 05:21:45 - progress_bar.py[line:274] - INFO: epoch 001:  10475 / 28910 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.7, ups=0.89, wpb=110, bsz=40, num_updates=10460, lr=4.7372e-05, gnorm=0.728, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49635
2022-10-13 05:21:56 - progress_bar.py[line:274] - INFO: epoch 001:  10485 / 28910 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=100.1, ups=0.91, wpb=109.7, bsz=40, num_updates=10470, lr=4.73675e-05, gnorm=0.559, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49646
2022-10-13 05:22:07 - progress_bar.py[line:274] - INFO: epoch 001:  10495 / 28910 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=99.7, ups=0.9, wpb=110.7, bsz=40, num_updates=10480, lr=4.7363e-05, gnorm=0.53, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49657
2022-10-13 05:22:18 - progress_bar.py[line:274] - INFO: epoch 001:  10505 / 28910 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=100.4, ups=0.9, wpb=111, bsz=40, num_updates=10490, lr=4.73585e-05, gnorm=0.644, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=49668
2022-10-13 05:22:29 - progress_bar.py[line:274] - INFO: epoch 001:  10515 / 28910 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=101, ups=0.93, wpb=108.8, bsz=40, num_updates=10500, lr=4.7354e-05, gnorm=0.599, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49679
2022-10-13 05:22:40 - progress_bar.py[line:274] - INFO: epoch 001:  10525 / 28910 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=10510, lr=4.73495e-05, gnorm=0.775, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=49690
2022-10-13 05:22:52 - progress_bar.py[line:274] - INFO: epoch 001:  10535 / 28910 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=10520, lr=4.7345e-05, gnorm=0.706, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49701
2022-10-13 05:23:03 - progress_bar.py[line:274] - INFO: epoch 001:  10545 / 28910 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=98.5, ups=0.91, wpb=108.6, bsz=40, num_updates=10530, lr=4.73404e-05, gnorm=0.821, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49712
2022-10-13 05:23:14 - progress_bar.py[line:274] - INFO: epoch 001:  10555 / 28910 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.9, ups=0.91, wpb=110.2, bsz=40, num_updates=10540, lr=4.73359e-05, gnorm=0.749, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49723
2022-10-13 05:23:25 - progress_bar.py[line:274] - INFO: epoch 001:  10565 / 28910 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=100.7, ups=0.91, wpb=111.3, bsz=40, num_updates=10550, lr=4.73314e-05, gnorm=0.647, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49734
2022-10-13 05:23:36 - progress_bar.py[line:274] - INFO: epoch 001:  10575 / 28910 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=96, ups=0.87, wpb=110.7, bsz=40, num_updates=10560, lr=4.73269e-05, gnorm=0.677, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49746
2022-10-13 05:23:47 - progress_bar.py[line:274] - INFO: epoch 001:  10585 / 28910 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=99.4, ups=0.91, wpb=109.2, bsz=40, num_updates=10570, lr=4.73224e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49757
2022-10-13 05:23:59 - progress_bar.py[line:274] - INFO: epoch 001:  10595 / 28910 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=100.5, ups=0.9, wpb=111.6, bsz=40, num_updates=10580, lr=4.73179e-05, gnorm=0.623, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49768
2022-10-13 05:24:10 - progress_bar.py[line:274] - INFO: epoch 001:  10605 / 28910 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=100.5, ups=0.91, wpb=110.6, bsz=40, num_updates=10590, lr=4.73134e-05, gnorm=0.687, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=49779
2022-10-13 05:24:20 - progress_bar.py[line:274] - INFO: epoch 001:  10615 / 28910 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=106.5, ups=0.96, wpb=111, bsz=40, num_updates=10600, lr=4.73089e-05, gnorm=0.706, clip=10, loss_scale=512, train_wall=10, gb_free=10.7, ema_decay=0.9999, wall=49790
2022-10-13 05:24:31 - progress_bar.py[line:274] - INFO: epoch 001:  10625 / 28910 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=100.4, ups=0.92, wpb=109.6, bsz=40, num_updates=10610, lr=4.73044e-05, gnorm=0.691, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49801
2022-10-13 05:24:43 - progress_bar.py[line:274] - INFO: epoch 001:  10635 / 28910 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=95.2, ups=0.87, wpb=109.2, bsz=40, num_updates=10620, lr=4.72999e-05, gnorm=0.715, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49812
2022-10-13 05:24:54 - progress_bar.py[line:274] - INFO: epoch 001:  10645 / 28910 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=10630, lr=4.72954e-05, gnorm=0.688, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49823
2022-10-13 05:25:05 - progress_bar.py[line:274] - INFO: epoch 001:  10655 / 28910 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=102.9, ups=0.92, wpb=112, bsz=40, num_updates=10640, lr=4.72909e-05, gnorm=0.708, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49834
2022-10-13 05:25:16 - progress_bar.py[line:274] - INFO: epoch 001:  10665 / 28910 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=10650, lr=4.72864e-05, gnorm=0.53, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49846
2022-10-13 05:25:27 - progress_bar.py[line:274] - INFO: epoch 001:  10675 / 28910 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=98.2, ups=0.9, wpb=109.7, bsz=40, num_updates=10660, lr=4.72819e-05, gnorm=0.665, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49857
2022-10-13 05:25:38 - progress_bar.py[line:274] - INFO: epoch 001:  10685 / 28910 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=10670, lr=4.72774e-05, gnorm=0.644, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49868
2022-10-13 05:25:50 - progress_bar.py[line:274] - INFO: epoch 001:  10695 / 28910 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=10680, lr=4.72729e-05, gnorm=0.642, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49879
2022-10-13 05:26:01 - progress_bar.py[line:274] - INFO: epoch 001:  10705 / 28910 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=98.1, ups=0.89, wpb=110.8, bsz=40, num_updates=10690, lr=4.72684e-05, gnorm=0.609, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49891
2022-10-13 05:26:12 - progress_bar.py[line:274] - INFO: epoch 001:  10715 / 28910 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.114, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=98.6, ups=0.89, wpb=111, bsz=40, num_updates=10700, lr=4.72639e-05, gnorm=0.578, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=49902
2022-10-13 05:26:24 - progress_bar.py[line:274] - INFO: epoch 001:  10725 / 28910 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.4, ups=0.9, wpb=109.6, bsz=40, num_updates=10710, lr=4.72594e-05, gnorm=0.679, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49913
2022-10-13 05:26:35 - progress_bar.py[line:274] - INFO: epoch 001:  10735 / 28910 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=10720, lr=4.72549e-05, gnorm=0.594, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49924
2022-10-13 05:26:46 - progress_bar.py[line:274] - INFO: epoch 001:  10745 / 28910 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=97.8, ups=0.88, wpb=110.7, bsz=40, num_updates=10730, lr=4.72504e-05, gnorm=0.679, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49936
2022-10-13 05:26:57 - progress_bar.py[line:274] - INFO: epoch 001:  10755 / 28910 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=101.3, ups=0.9, wpb=112, bsz=40, num_updates=10740, lr=4.72459e-05, gnorm=0.517, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49947
2022-10-13 05:27:09 - progress_bar.py[line:274] - INFO: epoch 001:  10765 / 28910 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=97.8, ups=0.89, wpb=110, bsz=40, num_updates=10750, lr=4.72414e-05, gnorm=0.545, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49958
2022-10-13 05:27:20 - progress_bar.py[line:274] - INFO: epoch 001:  10775 / 28910 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=10760, lr=4.72369e-05, gnorm=0.592, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49970
2022-10-13 05:27:31 - progress_bar.py[line:274] - INFO: epoch 001:  10785 / 28910 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=10770, lr=4.72324e-05, gnorm=0.738, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49981
2022-10-13 05:27:34 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 05:27:43 - progress_bar.py[line:274] - INFO: epoch 001:  10796 / 28910 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=88.5, ups=0.81, wpb=108.8, bsz=40, num_updates=10780, lr=4.72279e-05, gnorm=0.664, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=49993
2022-10-13 05:27:55 - progress_bar.py[line:274] - INFO: epoch 001:  10806 / 28910 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=97.7, ups=0.88, wpb=110.8, bsz=40, num_updates=10790, lr=4.72233e-05, gnorm=0.611, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=50004
2022-10-13 05:28:06 - progress_bar.py[line:274] - INFO: epoch 001:  10816 / 28910 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=97.7, ups=0.89, wpb=109.6, bsz=40, num_updates=10800, lr=4.72188e-05, gnorm=0.696, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50016
2022-10-13 05:28:17 - progress_bar.py[line:274] - INFO: epoch 001:  10826 / 28910 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=99.1, ups=0.9, wpb=110.3, bsz=40, num_updates=10810, lr=4.72143e-05, gnorm=0.738, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50027
2022-10-13 05:28:28 - progress_bar.py[line:274] - INFO: epoch 001:  10836 / 28910 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=10820, lr=4.72098e-05, gnorm=0.648, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=50038
2022-10-13 05:28:39 - progress_bar.py[line:274] - INFO: epoch 001:  10846 / 28910 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=101.8, ups=0.92, wpb=110.8, bsz=40, num_updates=10830, lr=4.72053e-05, gnorm=0.655, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50049
2022-10-13 05:28:50 - progress_bar.py[line:274] - INFO: epoch 001:  10856 / 28910 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=100.7, ups=0.9, wpb=111.7, bsz=40, num_updates=10840, lr=4.72008e-05, gnorm=0.685, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50060
2022-10-13 05:29:02 - progress_bar.py[line:274] - INFO: epoch 001:  10866 / 28910 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=100.5, ups=0.9, wpb=111.5, bsz=40, num_updates=10850, lr=4.71963e-05, gnorm=0.659, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=50071
2022-10-13 05:29:13 - progress_bar.py[line:274] - INFO: epoch 001:  10876 / 28910 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=10860, lr=4.71918e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50082
2022-10-13 05:29:24 - progress_bar.py[line:274] - INFO: epoch 001:  10886 / 28910 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=10870, lr=4.71873e-05, gnorm=0.68, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50094
2022-10-13 05:29:35 - progress_bar.py[line:274] - INFO: epoch 001:  10896 / 28910 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.5, ups=0.9, wpb=109.2, bsz=40, num_updates=10880, lr=4.71828e-05, gnorm=0.673, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50105
2022-10-13 05:29:47 - progress_bar.py[line:274] - INFO: epoch 001:  10906 / 28910 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=96.6, ups=0.87, wpb=110.5, bsz=40, num_updates=10890, lr=4.71783e-05, gnorm=0.569, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50116
2022-10-13 05:29:58 - progress_bar.py[line:274] - INFO: epoch 001:  10916 / 28910 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=10900, lr=4.71738e-05, gnorm=0.637, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=50128
2022-10-13 05:30:10 - progress_bar.py[line:274] - INFO: epoch 001:  10926 / 28910 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.12, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=95.5, ups=0.86, wpb=111.1, bsz=40, num_updates=10910, lr=4.71693e-05, gnorm=0.683, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=50139
2022-10-13 05:30:21 - progress_bar.py[line:274] - INFO: epoch 001:  10936 / 28910 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=97.4, ups=0.88, wpb=110.2, bsz=40, num_updates=10920, lr=4.71648e-05, gnorm=0.717, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50150
2022-10-13 05:30:32 - progress_bar.py[line:274] - INFO: epoch 001:  10946 / 28910 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=101, ups=0.9, wpb=112, bsz=40, num_updates=10930, lr=4.71603e-05, gnorm=0.803, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50162
2022-10-13 05:30:43 - progress_bar.py[line:274] - INFO: epoch 001:  10956 / 28910 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=10940, lr=4.71558e-05, gnorm=0.58, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50173
2022-10-13 05:30:54 - progress_bar.py[line:274] - INFO: epoch 001:  10966 / 28910 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.118, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=10950, lr=4.71513e-05, gnorm=0.578, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50184
2022-10-13 05:31:06 - progress_bar.py[line:274] - INFO: epoch 001:  10976 / 28910 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=10960, lr=4.71468e-05, gnorm=0.607, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50195
2022-10-13 05:31:17 - progress_bar.py[line:274] - INFO: epoch 001:  10986 / 28910 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=10970, lr=4.71423e-05, gnorm=0.535, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50207
2022-10-13 05:31:28 - progress_bar.py[line:274] - INFO: epoch 001:  10996 / 28910 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=101.6, ups=0.92, wpb=110.7, bsz=40, num_updates=10980, lr=4.71378e-05, gnorm=0.631, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=50217
2022-10-13 05:31:39 - progress_bar.py[line:274] - INFO: epoch 001:  11006 / 28910 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=99.4, ups=0.92, wpb=108.4, bsz=40, num_updates=10990, lr=4.71333e-05, gnorm=0.631, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=50228
2022-10-13 05:31:50 - progress_bar.py[line:274] - INFO: epoch 001:  11016 / 28910 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=101.9, ups=0.92, wpb=110.8, bsz=40, num_updates=11000, lr=4.71288e-05, gnorm=0.656, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=50239
2022-10-13 05:31:50 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 05:31:51 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 05:31:51 - train.py[line:551] - INFO: load:1.18 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 05:32:07 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 8.88 GiB already allocated; 5.81 GiB free; 31.30 GiB reserved in total by PyTorch)
2022-10-13 05:32:07 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 4            |        cudaMalloc retries: 18        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9096 MB |   14326 MB |    7254 TB |    7254 TB |
|       from large pool |    8951 MB |   14181 MB |    7252 TB |    7252 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9096 MB |   14326 MB |    7254 TB |    7254 TB |
|       from large pool |    8951 MB |   14181 MB |    7252 TB |    7252 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32050 MB |   37698 MB |  213818 MB |  181768 MB |
|       from large pool |   31904 MB |   37550 MB |  213470 MB |  181566 MB |
|       from small pool |     146 MB |     152 MB |     348 MB |     202 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22953 MB |   27584 MB |    8264 TB |    8264 TB |
|       from large pool |   22952 MB |   27582 MB |    8262 TB |    8262 TB |
|       from small pool |       1 MB |       2 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |  337217 K  |  337213 K  |
|       from large pool |     563    |     575    |  108400 K  |  108399 K  |
|       from small pool |    3106    |    3116    |  228816 K  |  228813 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |  337217 K  |  337213 K  |
|       from large pool |     563    |     575    |  108400 K  |  108399 K  |
|       from small pool |    3106    |    3116    |  228816 K  |  228813 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     135    |     139    |     541    |     406    |
|       from large pool |      62    |      63    |     367    |     305    |
|       from small pool |      73    |      76    |     174    |     101    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     100    |     107    |  244313 K  |  244313 K  |
|       from large pool |      63    |      66    |   45676 K  |   45676 K  |
|       from small pool |      37    |      48    |  198636 K  |  198636 K  |
|===========================================================================|

2022-10-13 05:32:07 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-13 05:32:07 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-13 05:34:24 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 05:34:24 - train.py[line:551] - INFO: load:1.21 valid_run:152.50 task_valid:147.86 collect_output:2.54
2022-10-13 05:36:52 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 05:36:52 - train.py[line:551] - INFO: load:1.23 valid_run:300.53 task_valid:290.55 collect_output:6.87
2022-10-13 05:39:24 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 05:39:24 - train.py[line:551] - INFO: load:1.26 valid_run:452.58 task_valid:433.38 collect_output:15.09
2022-10-13 05:41:53 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 05:41:53 - train.py[line:551] - INFO: load:1.28 valid_run:601.39 task_valid:578.05 collect_output:18.20
2022-10-13 05:44:25 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 05:44:25 - train.py[line:551] - INFO: load:1.31 valid_run:753.24 task_valid:724.99 collect_output:22.09
2022-10-13 05:46:56 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 05:46:56 - train.py[line:551] - INFO: load:1.33 valid_run:904.35 task_valid:869.95 collect_output:27.23
2022-10-13 05:49:29 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 05:49:29 - train.py[line:551] - INFO: load:1.36 valid_run:1057.35 task_valid:1015.56 collect_output:33.57
2022-10-13 05:52:00 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 05:52:00 - train.py[line:551] - INFO: load:1.39 valid_run:1208.43 task_valid:1156.42 collect_output:42.76
2022-10-13 05:54:29 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 05:54:29 - train.py[line:551] - INFO: load:1.41 valid_run:1357.67 task_valid:1300.67 collect_output:46.73
2022-10-13 05:56:57 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 05:56:57 - train.py[line:551] - INFO: load:1.44 valid_run:1505.80 task_valid:1443.47 collect_output:51.04
2022-10-13 05:59:27 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 05:59:27 - train.py[line:551] - INFO: load:1.46 valid_run:1655.30 task_valid:1588.16 collect_output:54.83
2022-10-13 06:01:57 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 06:01:57 - train.py[line:551] - INFO: load:1.49 valid_run:1804.84 task_valid:1732.59 collect_output:58.91
2022-10-13 06:04:26 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 06:04:26 - train.py[line:551] - INFO: load:1.51 valid_run:1954.42 task_valid:1873.93 collect_output:66.12
2022-10-13 06:06:56 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 06:06:56 - train.py[line:551] - INFO: load:1.54 valid_run:2104.51 task_valid:2019.00 collect_output:70.12
2022-10-13 06:09:26 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 06:09:26 - train.py[line:551] - INFO: load:1.56 valid_run:2254.25 task_valid:2164.99 collect_output:72.85
2022-10-13 06:11:56 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 06:11:56 - train.py[line:551] - INFO: load:1.59 valid_run:2403.76 task_valid:2308.52 collect_output:77.82
2022-10-13 06:14:27 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 06:14:27 - train.py[line:551] - INFO: load:1.61 valid_run:2554.96 task_valid:2453.42 collect_output:83.10
2022-10-13 06:16:58 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 06:16:58 - train.py[line:551] - INFO: load:1.64 valid_run:2706.33 task_valid:2600.99 collect_output:85.81
2022-10-13 06:19:27 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 06:19:27 - train.py[line:551] - INFO: load:1.67 valid_run:2854.73 task_valid:2742.72 collect_output:91.42
2022-10-13 06:21:57 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 06:21:57 - train.py[line:551] - INFO: load:1.69 valid_run:3005.12 task_valid:2887.74 collect_output:95.75
2022-10-13 06:24:29 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 06:24:29 - train.py[line:551] - INFO: load:1.73 valid_run:3157.05 task_valid:3032.44 collect_output:101.92
2022-10-13 06:26:59 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 06:26:59 - train.py[line:551] - INFO: load:1.76 valid_run:3306.53 task_valid:3177.05 collect_output:105.72
2022-10-13 06:29:30 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 06:29:30 - train.py[line:551] - INFO: load:1.79 valid_run:3457.96 task_valid:3323.49 collect_output:109.67
2022-10-13 06:32:02 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 06:32:02 - train.py[line:551] - INFO: load:1.81 valid_run:3609.70 task_valid:3470.51 collect_output:113.32

====================================================================================================
SGG eval:     R @ 50: 0.5951;     R @ 100: 0.6457;     R @ 500: 0.6774;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3819;    mR @ 100: 0.4303;    mR @ 500: 0.4783;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.8750) (covering:0.3000) (eating:0.7353) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4194) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9578) (says:0.0000) (sitting on:0.6755) (standing on:0.3923) (using:0.6500) (walking in:0.0000) (walking on:0.6216) (watching:0.4028) 
--------------------------------------------------------
====================================================================================================

2022-10-13 06:34:34 - train.py[line:487] - INFO: 0.6456638655462184

====================================================================================================
SGG eval:     R @ 50: 0.5951;     R @ 100: 0.6457;     R @ 500: 0.6774;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3819;    mR @ 100: 0.4303;    mR @ 500: 0.4783;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.8750) (covering:0.3000) (eating:0.7353) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4194) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9578) (says:0.0000) (sitting on:0.6755) (standing on:0.3923) (using:0.6500) (walking in:0.0000) (walking on:0.6216) (watching:0.4028) 
--------------------------------------------------------
====================================================================================================

2022-10-13 06:34:34 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 06:34:34 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.34 | loss_v1 0 | loss_v2 0 | nll_loss 0.179 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.645664 | ppl 1.13 | vqa_score 0.5856 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 11000 | best_R@100 0.708635
2022-10-13 06:34:34 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 11000 updates
2022-10-13 06:34:34 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_11000.pt
2022-10-13 06:34:40 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_11000.pt
2022-10-13 06:34:42 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.2/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_11000.pt (epoch 1 @ 11000 updates, score 0.6456638655462184) (writing took 8.359630892984569 seconds)
2022-10-13 06:34:53 - progress_bar.py[line:274] - INFO: epoch 001:  11026 / 28910 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=0.3, ups=0, wpb=109.4, bsz=40, num_updates=11010, lr=4.71243e-05, gnorm=0.655, clip=0, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=54023
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 2592154
Killing subprocess 2592155
Main process received SIGINT, exiting
