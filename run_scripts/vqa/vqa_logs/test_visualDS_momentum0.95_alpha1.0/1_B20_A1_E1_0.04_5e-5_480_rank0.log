2023-01-07 22:48:32 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2023-01-07 22:48:32 - utils.py[line:261] - INFO: Start init
2023-01-07 22:48:32 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2023-01-07 22:48:32 - utils.py[line:261] - INFO: Start init
2023-01-07 22:48:32 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-01-07 22:48:32 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-01-07 22:48:32 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2023-01-07 22:48:32 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2023-01-07 22:48:38 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_visualDS_momentum0.95_alpha1.0', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 2000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 2000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=1, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480', save_interval=10, save_interval_updates=2000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_visualDS_momentum0.95_alpha1.0', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=2000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-01-07 22:48:38 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-01-07 22:48:38 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2023-01-07 22:48:43 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-01-07 22:48:43 - train.py[line:118] - INFO: task: VqaGenTask
2023-01-07 22:48:43 - train.py[line:119] - INFO: model: OFAModel
2023-01-07 22:48:43 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-01-07 22:48:43 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-01-07 22:48:43 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2023-01-07 22:48:43 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-01-07 22:48:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-01-07 22:48:44 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-01-07 22:48:44 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-01-07 22:48:44 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-01-07 22:48:44 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
Done 0.95 cuda cpu, cpu
2023-01-07 22:48:45 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2023-01-07 22:48:45 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2023-01-07 22:48:45 - trainer.py[line:499] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
Done 0.95 cuda cpu, cpu
2023-01-07 22:48:55 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-01-07 22:48:56 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-01-07 22:48:56 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-01-07 22:48:56 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-01-07 22:48:56 - trainer.py[line:314] - INFO: Exponential Moving Average Shadow Model is initialized.
2023-01-07 22:48:57 - trainer.py[line:674] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2023-01-07 22:48:57 - trainer.py[line:694] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv slice_id 1 row count 2316893 total row count 4633786
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv slice_id 0 row count 2316893 total row count 4633786
Total steps 115845, warmup steps 4633, warmup_factor 0.0002158428663932657
2023-01-07 22:49:01 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 115845, warmup steps 4633, warmup_factor 0.0002158428663932657
2023-01-07 22:49:01 - trainer.py[line:758] - INFO: begin training epoch 1
2023-01-07 22:49:01 - train.py[line:312] - INFO: Start iterating over samples
From cpu to cuda:1
From cpu to cuda:0
2023-01-07 22:49:39 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 115845 loss=0.977, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, vqa_score=0.0363, wps=70.4, ups=0.32, wpb=109.9, bsz=40, num_updates=10, lr=1.07921e-07, gnorm=7.483, clip=100, loss_scale=128, train_wall=36, gb_free=10.4, ema_decay=0.9999, wall=55
2023-01-07 22:50:10 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 115845 loss=1.01, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, vqa_score=0.0308, wps=71.3, ups=0.33, wpb=109.6, bsz=40, num_updates=20, lr=2.15843e-07, gnorm=8.013, clip=100, loss_scale=128, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=86
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 3302965
Killing subprocess 3302966
Main process received SIGINT, exiting
2023-01-07 22:50:33 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2023-01-07 22:50:33 - utils.py[line:261] - INFO: Start init
2023-01-07 22:50:33 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2023-01-07 22:50:33 - utils.py[line:261] - INFO: Start init
2023-01-07 22:50:33 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-01-07 22:50:33 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-01-07 22:50:33 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2023-01-07 22:50:33 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2023-01-07 22:50:38 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_visualDS_momentum0.95_alpha1.0', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 2000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 2000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=1, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480', save_interval=10, save_interval_updates=2000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_visualDS_momentum0.95_alpha1.0', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=2000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-01-07 22:50:39 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-01-07 22:50:39 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2023-01-07 22:50:43 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-01-07 22:50:43 - train.py[line:118] - INFO: task: VqaGenTask
2023-01-07 22:50:43 - train.py[line:119] - INFO: model: OFAModel
2023-01-07 22:50:43 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-01-07 22:50:43 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-01-07 22:50:43 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2023-01-07 22:50:43 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-01-07 22:50:43 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-01-07 22:50:44 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-01-07 22:50:44 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-01-07 22:50:44 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-01-07 22:50:44 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
2023-01-07 22:50:45 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2023-01-07 22:50:45 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2023-01-07 22:50:45 - trainer.py[line:499] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2023-01-07 22:50:48 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-01-07 22:50:48 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-01-07 22:50:48 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-01-07 22:50:49 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-01-07 22:50:49 - trainer.py[line:314] - INFO: Exponential Moving Average Shadow Model is initialized.
2023-01-07 22:50:49 - trainer.py[line:674] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2023-01-07 22:50:49 - trainer.py[line:694] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv slice_id 1 row count 2316893 total row count 4633786
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv slice_id 0 row count 2316893 total row count 4633786
2023-01-07 22:50:53 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 115845, warmup steps 4633, warmup_factor 0.0002158428663932657
Total steps 115845, warmup steps 4633, warmup_factor 0.0002158428663932657
2023-01-07 22:50:53 - trainer.py[line:758] - INFO: begin training epoch 1
2023-01-07 22:50:53 - train.py[line:312] - INFO: Start iterating over samples
From cpu to cuda:1
From cpu to cuda:0
2023-01-07 22:51:22 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 115845 loss=0.977, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, vqa_score=0.0363, wps=94.2, ups=0.43, wpb=109.9, bsz=40, num_updates=10, lr=1.07921e-07, gnorm=7.485, clip=100, loss_scale=128, train_wall=26, gb_free=10.3, ema_decay=0.9999, wall=38
2023-01-07 22:51:44 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 115845 loss=1.01, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, vqa_score=0.0308, wps=100.3, ups=0.46, wpb=109.6, bsz=40, num_updates=20, lr=2.15843e-07, gnorm=8.049, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60
2023-01-07 22:52:06 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0245, wps=102.2, ups=0.47, wpb=109, bsz=40, num_updates=30, lr=3.23764e-07, gnorm=9.005, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=81
2023-01-07 22:52:27 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 115845 loss=1.005, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, vqa_score=0.0263, wps=101.7, ups=0.47, wpb=108.7, bsz=40, num_updates=40, lr=4.31686e-07, gnorm=7.736, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=103
2023-01-07 22:52:49 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0297, wps=102.2, ups=0.47, wpb=108.8, bsz=40, num_updates=50, lr=5.39607e-07, gnorm=7.321, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=125
2023-01-07 22:53:10 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 115845 loss=1.084, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, vqa_score=0.0332, wps=101.5, ups=0.47, wpb=108.3, bsz=40, num_updates=60, lr=6.47529e-07, gnorm=8.556, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=146
2023-01-07 22:53:33 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 115845 loss=1.035, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, vqa_score=0.0283, wps=98.1, ups=0.45, wpb=109.6, bsz=40, num_updates=70, lr=7.5545e-07, gnorm=7.209, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=169
2023-01-07 22:53:55 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 115845 loss=0.99, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, vqa_score=0.0287, wps=98.2, ups=0.45, wpb=108.3, bsz=40, num_updates=80, lr=8.63371e-07, gnorm=6.796, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=191
2023-01-07 22:54:17 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 115845 loss=0.891, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.7, vqa_score=0.0291, wps=101, ups=0.46, wpb=109.4, bsz=40, num_updates=90, lr=9.71293e-07, gnorm=5.618, clip=100, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=213
2023-01-07 22:54:38 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 115845 loss=0.867, loss_v1=0, loss_v2=0, nll_loss=0.75, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.68, vqa_score=0.0205, wps=104.1, ups=0.48, wpb=109, bsz=40, num_updates=100, lr=1.07921e-06, gnorm=5.199, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=234
2023-01-07 22:55:01 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 115845 loss=0.883, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, vqa_score=0.0321, wps=94.4, ups=0.44, wpb=108.4, bsz=40, num_updates=110, lr=1.18714e-06, gnorm=5.239, clip=100, loss_scale=128, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=257
2023-01-07 22:55:23 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 115845 loss=0.797, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, vqa_score=0.0412, wps=100.8, ups=0.46, wpb=109.9, bsz=40, num_updates=120, lr=1.29506e-06, gnorm=4.552, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=279
2023-01-07 22:55:45 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 115845 loss=0.751, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, vqa_score=0.0217, wps=101.2, ups=0.46, wpb=109.7, bsz=40, num_updates=130, lr=1.40298e-06, gnorm=3.778, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=301
2023-01-07 22:56:07 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0457, wps=99.7, ups=0.46, wpb=108.1, bsz=40, num_updates=140, lr=1.5109e-06, gnorm=3.875, clip=100, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=323
2023-01-07 22:56:30 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0337, wps=101.2, ups=0.47, wpb=108.7, bsz=40, num_updates=150, lr=1.61882e-06, gnorm=3.664, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=345
2023-01-07 22:56:51 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 115845 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.56, vqa_score=0.0195, wps=102.4, ups=0.47, wpb=110, bsz=40, num_updates=160, lr=1.72674e-06, gnorm=3.27, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=367
2023-01-07 22:57:13 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0263, wps=104.5, ups=0.47, wpb=110.4, bsz=40, num_updates=170, lr=1.83466e-06, gnorm=2.667, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=389
2023-01-07 22:57:35 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 115845 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, vqa_score=0.0048, wps=97.9, ups=0.46, wpb=107.2, bsz=40, num_updates=180, lr=1.94259e-06, gnorm=3.183, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=411
2023-01-07 22:57:57 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 115845 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, vqa_score=0.0243, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=190, lr=2.05051e-06, gnorm=2.94, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=432
2023-01-07 22:58:19 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 115845 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, vqa_score=0.0187, wps=99.6, ups=0.46, wpb=108.6, bsz=40, num_updates=200, lr=2.15843e-06, gnorm=2.618, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=455
2023-01-07 22:58:40 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 115845 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.615, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, vqa_score=0.0147, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=210, lr=2.26635e-06, gnorm=2.544, clip=100, loss_scale=128, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=476
2023-01-07 22:59:03 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 115845 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, vqa_score=0.0194, wps=98.3, ups=0.45, wpb=110.1, bsz=40, num_updates=220, lr=2.37427e-06, gnorm=2.392, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=499
2023-01-07 22:59:25 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 115845 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, vqa_score=0.0303, wps=98.9, ups=0.45, wpb=109.2, bsz=40, num_updates=230, lr=2.48219e-06, gnorm=2.252, clip=100, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=521
2023-01-07 22:59:47 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0156, wps=101, ups=0.46, wpb=108.8, bsz=40, num_updates=240, lr=2.59011e-06, gnorm=2.135, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=543
2023-01-07 23:00:09 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.8, nsentences=40, sample_size=106.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0431, wps=99.4, ups=0.47, wpb=106.8, bsz=40, num_updates=250, lr=2.69804e-06, gnorm=2.067, clip=100, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=565
2023-01-07 23:00:31 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.04, wps=101.3, ups=0.47, wpb=108.1, bsz=40, num_updates=260, lr=2.80596e-06, gnorm=2.202, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=586
2023-01-07 23:00:52 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 115845 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, vqa_score=0.011, wps=106.2, ups=0.48, wpb=110.3, bsz=40, num_updates=270, lr=2.91388e-06, gnorm=2.07, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=607
2023-01-07 23:01:13 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 115845 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, vqa_score=0.0047, wps=101.2, ups=0.47, wpb=107.1, bsz=40, num_updates=280, lr=3.0218e-06, gnorm=1.945, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=629
2023-01-07 23:01:35 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 115845 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0269, wps=102, ups=0.47, wpb=109.5, bsz=40, num_updates=290, lr=3.12972e-06, gnorm=1.646, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=651
2023-01-07 23:01:56 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0052, wps=102.9, ups=0.47, wpb=109.2, bsz=40, num_updates=300, lr=3.23764e-06, gnorm=1.808, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=672
2023-01-07 23:02:18 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 115845 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, vqa_score=0.0348, wps=101.1, ups=0.46, wpb=110.3, bsz=40, num_updates=310, lr=3.34556e-06, gnorm=1.691, clip=100, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=694
2023-01-07 23:02:40 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0146, wps=99.5, ups=0.46, wpb=107.3, bsz=40, num_updates=320, lr=3.45349e-06, gnorm=1.699, clip=100, loss_scale=128, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=716
2023-01-07 23:03:02 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0047, wps=100.9, ups=0.46, wpb=108.5, bsz=40, num_updates=330, lr=3.56141e-06, gnorm=1.717, clip=100, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=738
2023-01-07 23:03:24 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 115845 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, vqa_score=0.0204, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=340, lr=3.66933e-06, gnorm=1.6, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=760
2023-01-07 23:03:46 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 115845 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, vqa_score=0.0317, wps=99, ups=0.45, wpb=109.1, bsz=40, num_updates=350, lr=3.77725e-06, gnorm=1.409, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=782
2023-01-07 23:04:07 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 115845 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, vqa_score=0.024, wps=102.9, ups=0.47, wpb=108.9, bsz=40, num_updates=360, lr=3.88517e-06, gnorm=1.488, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=803
2023-01-07 23:04:30 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 115845 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0156, wps=99.2, ups=0.46, wpb=108.3, bsz=40, num_updates=370, lr=3.99309e-06, gnorm=1.596, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=825
2023-01-07 23:04:51 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 115845 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0452, wps=100.3, ups=0.46, wpb=108.5, bsz=40, num_updates=380, lr=4.10101e-06, gnorm=1.416, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=847
2023-01-07 23:05:14 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 115845 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, vqa_score=0.0376, wps=100.3, ups=0.46, wpb=108.6, bsz=40, num_updates=390, lr=4.20894e-06, gnorm=1.663, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=869
2023-01-07 23:05:35 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 115845 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, vqa_score=0.0281, wps=102.5, ups=0.46, wpb=110.6, bsz=40, num_updates=400, lr=4.31686e-06, gnorm=1.622, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=891
2023-01-07 23:05:57 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0296, wps=99.3, ups=0.46, wpb=108.1, bsz=40, num_updates=410, lr=4.42478e-06, gnorm=1.539, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=913
2023-01-07 23:06:19 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 115845 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0323, wps=100.6, ups=0.46, wpb=108.4, bsz=40, num_updates=420, lr=4.5327e-06, gnorm=1.488, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=935
2023-01-07 23:06:41 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 115845 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, vqa_score=0.0309, wps=103, ups=0.47, wpb=109.4, bsz=40, num_updates=430, lr=4.64062e-06, gnorm=1.745, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=956
2023-01-07 23:07:02 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 115845 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0051, wps=100, ups=0.46, wpb=108.8, bsz=40, num_updates=440, lr=4.74854e-06, gnorm=1.533, clip=100, loss_scale=128, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=978
2023-01-07 23:07:24 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 115845 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0472, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=450, lr=4.85646e-06, gnorm=1.333, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1000
2023-01-07 23:07:46 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 115845 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, vqa_score=0.0329, wps=101.5, ups=0.47, wpb=108.3, bsz=40, num_updates=460, lr=4.96439e-06, gnorm=1.45, clip=100, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1022
2023-01-07 23:08:09 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 115845 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, vqa_score=0.0096, wps=101.2, ups=0.46, wpb=109.5, bsz=40, num_updates=470, lr=5.07231e-06, gnorm=1.253, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1044
2023-01-07 23:08:32 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 115845 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0538, wps=104.4, ups=0.47, wpb=110.5, bsz=40, num_updates=480, lr=5.18023e-06, gnorm=1.484, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1066
2023-01-07 23:08:57 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 115845 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, vqa_score=0.0242, wps=99.6, ups=0.46, wpb=108.7, bsz=40, num_updates=490, lr=5.28815e-06, gnorm=1.466, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1090
2023-01-07 23:09:20 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0266, wps=102.7, ups=0.47, wpb=109.9, bsz=40, num_updates=500, lr=5.39607e-06, gnorm=1.58, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1114
2023-01-07 23:09:43 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.058, wps=103.6, ups=0.47, wpb=109.7, bsz=40, num_updates=510, lr=5.50399e-06, gnorm=1.453, clip=90, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1137
2023-01-07 23:10:06 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 115845 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0286, wps=99, ups=0.46, wpb=107.9, bsz=40, num_updates=520, lr=5.61191e-06, gnorm=1.441, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1160
2023-01-07 23:10:29 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 115845 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0199, wps=101.4, ups=0.47, wpb=108.5, bsz=40, num_updates=530, lr=5.71984e-06, gnorm=1.423, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1184
2023-01-07 23:10:52 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 115845 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0273, wps=102.3, ups=0.47, wpb=109.5, bsz=40, num_updates=540, lr=5.82776e-06, gnorm=1.345, clip=80, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1207
2023-01-07 23:11:16 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 115845 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0294, wps=100.3, ups=0.45, wpb=110.6, bsz=40, num_updates=550, lr=5.93568e-06, gnorm=1.447, clip=90, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=1231
2023-01-07 23:11:40 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 115845 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.051, wps=100.3, ups=0.46, wpb=109.3, bsz=40, num_updates=560, lr=6.0436e-06, gnorm=1.56, clip=100, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=1254
2023-01-07 23:12:02 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 115845 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0299, wps=103.2, ups=0.47, wpb=109.5, bsz=40, num_updates=570, lr=6.15152e-06, gnorm=1.297, clip=100, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1277
2023-01-07 23:12:25 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 115845 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0469, wps=101.7, ups=0.47, wpb=108.7, bsz=40, num_updates=580, lr=6.25944e-06, gnorm=1.286, clip=70, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=1300
2023-01-07 23:12:48 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 115845 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0198, wps=102.8, ups=0.47, wpb=109.4, bsz=40, num_updates=590, lr=6.36736e-06, gnorm=1.367, clip=100, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1323
2023-01-07 23:13:11 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0153, wps=100.2, ups=0.46, wpb=109.6, bsz=40, num_updates=600, lr=6.47529e-06, gnorm=1.294, clip=90, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=1346
2023-01-07 23:13:34 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 115845 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0493, wps=101.4, ups=0.47, wpb=108.7, bsz=40, num_updates=610, lr=6.58321e-06, gnorm=1.449, clip=100, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1369
2023-01-07 23:13:57 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 115845 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, vqa_score=0.0202, wps=103.4, ups=0.47, wpb=109.6, bsz=40, num_updates=620, lr=6.69113e-06, gnorm=1.364, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1391
2023-01-07 23:14:20 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0253, wps=101.3, ups=0.46, wpb=109.9, bsz=40, num_updates=630, lr=6.79905e-06, gnorm=1.406, clip=90, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1415
2023-01-07 23:14:43 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0514, wps=103, ups=0.46, wpb=111, bsz=40, num_updates=640, lr=6.90697e-06, gnorm=1.486, clip=100, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=1438
2023-01-07 23:15:07 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0326, wps=99.1, ups=0.46, wpb=107.6, bsz=40, num_updates=650, lr=7.01489e-06, gnorm=1.503, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1461
2023-01-07 23:15:30 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 115845 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0254, wps=98.9, ups=0.45, wpb=109, bsz=40, num_updates=660, lr=7.12281e-06, gnorm=1.592, clip=100, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=1485
2023-01-07 23:15:54 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 115845 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0294, wps=103, ups=0.47, wpb=109.9, bsz=40, num_updates=670, lr=7.23074e-06, gnorm=1.22, clip=60, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1508
2023-01-07 23:16:17 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 115845 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0202, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=680, lr=7.33866e-06, gnorm=1.351, clip=90, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1531
2023-01-07 23:16:40 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0394, wps=101.8, ups=0.47, wpb=109.4, bsz=40, num_updates=690, lr=7.44658e-06, gnorm=1.444, clip=100, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1554
2023-01-07 23:17:03 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 115845 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0205, wps=101.6, ups=0.47, wpb=109.2, bsz=40, num_updates=700, lr=7.5545e-06, gnorm=1.492, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1577
2023-01-07 23:17:26 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0107, wps=104, ups=0.47, wpb=110.3, bsz=40, num_updates=710, lr=7.66242e-06, gnorm=1.333, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1600
2023-01-07 23:17:48 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0306, wps=104, ups=0.48, wpb=109.2, bsz=40, num_updates=720, lr=7.77034e-06, gnorm=1.331, clip=100, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1623
2023-01-07 23:18:11 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 115845 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0324, wps=101.5, ups=0.46, wpb=110.5, bsz=40, num_updates=730, lr=7.87826e-06, gnorm=1.304, clip=80, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=1646
2023-01-07 23:18:34 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 115845 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, vqa_score=0.0151, wps=102.3, ups=0.47, wpb=109.5, bsz=40, num_updates=740, lr=7.98619e-06, gnorm=1.313, clip=90, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1669
2023-01-07 23:18:57 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 115845 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.044, wps=103.5, ups=0.47, wpb=110.4, bsz=40, num_updates=750, lr=8.09411e-06, gnorm=1.419, clip=100, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1692
2023-01-07 23:19:20 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0107, wps=100.4, ups=0.46, wpb=109.3, bsz=40, num_updates=760, lr=8.20203e-06, gnorm=1.159, clip=80, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=1715
2023-01-07 23:19:43 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 115845 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0259, wps=104.6, ups=0.47, wpb=111.5, bsz=40, num_updates=770, lr=8.30995e-06, gnorm=1.236, clip=90, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1737
2023-01-07 23:20:06 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0203, wps=100.7, ups=0.46, wpb=108.6, bsz=40, num_updates=780, lr=8.41787e-06, gnorm=1.355, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1760
2023-01-07 23:20:28 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 115845 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0359, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=790, lr=8.52579e-06, gnorm=1.238, clip=80, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=1783
2023-01-07 23:20:51 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0294, wps=101.1, ups=0.47, wpb=108, bsz=40, num_updates=800, lr=8.63371e-06, gnorm=1.55, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1806
2023-01-07 23:21:14 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 115845 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0248, wps=101.8, ups=0.47, wpb=108.6, bsz=40, num_updates=810, lr=8.74164e-06, gnorm=1.548, clip=100, loss_scale=256, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=1829
2023-01-07 23:21:37 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 115845 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0201, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=820, lr=8.84956e-06, gnorm=1.338, clip=100, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=1851
2023-01-07 23:22:00 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 115845 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0153, wps=101.8, ups=0.47, wpb=107.8, bsz=40, num_updates=830, lr=8.95748e-06, gnorm=1.346, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1874
2023-01-07 23:22:23 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 115845 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.035, wps=100.9, ups=0.46, wpb=108.5, bsz=40, num_updates=840, lr=9.0654e-06, gnorm=1.17, clip=90, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1897
2023-01-07 23:22:46 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0239, wps=102.7, ups=0.47, wpb=109.3, bsz=40, num_updates=850, lr=9.17332e-06, gnorm=1.249, clip=80, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1920
2023-01-07 23:23:08 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 115845 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0385, wps=102.1, ups=0.46, wpb=109.9, bsz=40, num_updates=860, lr=9.28124e-06, gnorm=1.287, clip=60, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=1943
2023-01-07 23:23:31 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 115845 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0246, wps=100.1, ups=0.46, wpb=108.2, bsz=40, num_updates=870, lr=9.38916e-06, gnorm=1.31, clip=80, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1966
2023-01-07 23:23:55 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0287, wps=100.9, ups=0.46, wpb=110.8, bsz=40, num_updates=880, lr=9.49709e-06, gnorm=1.294, clip=90, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=1989
2023-01-07 23:24:18 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0153, wps=104.2, ups=0.47, wpb=111.1, bsz=40, num_updates=890, lr=9.60501e-06, gnorm=1.281, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2012
2023-01-07 23:24:41 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 115845 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0154, wps=101.3, ups=0.47, wpb=108.3, bsz=40, num_updates=900, lr=9.71293e-06, gnorm=1.383, clip=100, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2035
2023-01-07 23:25:04 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 115845 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0381, wps=100.6, ups=0.46, wpb=108.9, bsz=40, num_updates=910, lr=9.82085e-06, gnorm=1.342, clip=90, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=2059
2023-01-07 23:25:27 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 115845 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0192, wps=98.4, ups=0.46, wpb=107.9, bsz=40, num_updates=920, lr=9.92877e-06, gnorm=1.625, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2082
2023-01-07 23:25:50 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 115845 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0265, wps=99, ups=0.46, wpb=107.7, bsz=40, num_updates=930, lr=1.00367e-05, gnorm=1.418, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2105
2023-01-07 23:26:13 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 115845 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0253, wps=99.7, ups=0.46, wpb=108.5, bsz=40, num_updates=940, lr=1.01446e-05, gnorm=1.423, clip=100, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=2128
2023-01-07 23:26:35 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 115845 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0343, wps=103.9, ups=0.48, wpb=108.8, bsz=40, num_updates=950, lr=1.02525e-05, gnorm=1.375, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2150
2023-01-07 23:26:56 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0197, wps=102.1, ups=0.47, wpb=109.3, bsz=40, num_updates=960, lr=1.03605e-05, gnorm=1.232, clip=90, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2172
2023-01-07 23:27:18 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0243, wps=98.9, ups=0.46, wpb=107.9, bsz=40, num_updates=970, lr=1.04684e-05, gnorm=1.158, clip=60, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=2194
2023-01-07 23:27:40 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0146, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=980, lr=1.05763e-05, gnorm=1.349, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2216
2023-01-07 23:28:01 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 115845 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0377, wps=102.6, ups=0.47, wpb=109.5, bsz=40, num_updates=990, lr=1.06842e-05, gnorm=1.41, clip=90, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2237
2023-01-07 23:28:23 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 115845 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0296, wps=101.3, ups=0.47, wpb=107.8, bsz=40, num_updates=1000, lr=1.07921e-05, gnorm=1.417, clip=100, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=2259
2023-01-07 23:28:45 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 115845 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0242, wps=101, ups=0.47, wpb=108.4, bsz=40, num_updates=1010, lr=1.09001e-05, gnorm=1.419, clip=90, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=2281
2023-01-07 23:29:07 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 115845 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0201, wps=102.3, ups=0.46, wpb=110.2, bsz=40, num_updates=1020, lr=1.1008e-05, gnorm=1.296, clip=100, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2302
2023-01-07 23:29:28 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 115845 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0383, wps=101.5, ups=0.46, wpb=109.3, bsz=40, num_updates=1030, lr=1.11159e-05, gnorm=1.28, clip=80, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2324
2023-01-07 23:29:50 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 115845 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0195, wps=99.8, ups=0.46, wpb=108.9, bsz=40, num_updates=1040, lr=1.12238e-05, gnorm=1.384, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2346
2023-01-07 23:30:12 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0202, wps=101.5, ups=0.46, wpb=109.4, bsz=40, num_updates=1050, lr=1.13318e-05, gnorm=1.34, clip=90, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=2368
2023-01-07 23:30:34 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0321, wps=103.2, ups=0.47, wpb=110.4, bsz=40, num_updates=1060, lr=1.14397e-05, gnorm=1.053, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2390
2023-01-07 23:30:56 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 115845 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0388, wps=101.7, ups=0.47, wpb=108.7, bsz=40, num_updates=1070, lr=1.15476e-05, gnorm=1.336, clip=100, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2411
2023-01-07 23:31:17 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0421, wps=102.9, ups=0.47, wpb=110.1, bsz=40, num_updates=1080, lr=1.16555e-05, gnorm=1.303, clip=90, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=2433
2023-01-07 23:31:39 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 115845 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0258, wps=102.5, ups=0.47, wpb=109.8, bsz=40, num_updates=1090, lr=1.17634e-05, gnorm=1.318, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2455
2023-01-07 23:32:01 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0335, wps=103.2, ups=0.47, wpb=110.1, bsz=40, num_updates=1100, lr=1.18714e-05, gnorm=1.257, clip=80, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2477
2023-01-07 23:32:22 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 115845 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0154, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=1110, lr=1.19793e-05, gnorm=1.328, clip=100, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=2498
2023-01-07 23:32:44 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0048, wps=101.6, ups=0.47, wpb=108.2, bsz=40, num_updates=1120, lr=1.20872e-05, gnorm=1.359, clip=100, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2520
2023-01-07 23:33:06 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 115845 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.03, wps=100.4, ups=0.46, wpb=108.8, bsz=40, num_updates=1130, lr=1.21951e-05, gnorm=1.382, clip=100, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=2542
2023-01-07 23:33:28 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 115845 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0049, wps=101.3, ups=0.46, wpb=109.4, bsz=40, num_updates=1140, lr=1.2303e-05, gnorm=1.153, clip=80, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=2564
2023-01-07 23:33:50 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 115845 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0426, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=1150, lr=1.2411e-05, gnorm=1.268, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2585
2023-01-07 23:34:11 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 115845 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0327, wps=101.3, ups=0.47, wpb=108.3, bsz=40, num_updates=1160, lr=1.25189e-05, gnorm=1.309, clip=100, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2607
2023-01-07 23:34:33 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 115845 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0308, wps=101.1, ups=0.46, wpb=109.9, bsz=40, num_updates=1170, lr=1.26268e-05, gnorm=1.296, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2629
2023-01-07 23:34:56 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0333, wps=99.3, ups=0.46, wpb=108.8, bsz=40, num_updates=1180, lr=1.27347e-05, gnorm=1.369, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2651
2023-01-07 23:35:18 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 115845 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0242, wps=100, ups=0.46, wpb=109.1, bsz=40, num_updates=1190, lr=1.28427e-05, gnorm=1.192, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2673
2023-01-07 23:35:39 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 115845 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0234, wps=100.6, ups=0.47, wpb=107.9, bsz=40, num_updates=1200, lr=1.29506e-05, gnorm=1.233, clip=90, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=2695
2023-01-07 23:36:02 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 115845 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0431, wps=97.5, ups=0.45, wpb=108.4, bsz=40, num_updates=1210, lr=1.30585e-05, gnorm=1.359, clip=100, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=2718
2023-01-07 23:36:24 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0254, wps=102.3, ups=0.47, wpb=109.2, bsz=40, num_updates=1220, lr=1.31664e-05, gnorm=1.247, clip=80, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=2739
2023-01-07 23:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 115845 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0481, wps=99.5, ups=0.46, wpb=108.2, bsz=40, num_updates=1230, lr=1.32743e-05, gnorm=1.429, clip=90, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=2761
2023-01-07 23:37:07 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0103, wps=102.2, ups=0.47, wpb=108.5, bsz=40, num_updates=1240, lr=1.33823e-05, gnorm=1.251, clip=80, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=2783
2023-01-07 23:37:29 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 115845 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0156, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=1250, lr=1.34902e-05, gnorm=1.243, clip=70, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2805
2023-01-07 23:37:50 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0106, wps=101.9, ups=0.47, wpb=108.8, bsz=40, num_updates=1260, lr=1.35981e-05, gnorm=1.099, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2826
2023-01-07 23:38:12 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0051, wps=102, ups=0.47, wpb=108.3, bsz=40, num_updates=1270, lr=1.3706e-05, gnorm=1.211, clip=90, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=2848
2023-01-07 23:38:34 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 115845 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0207, wps=102.1, ups=0.46, wpb=110, bsz=40, num_updates=1280, lr=1.38139e-05, gnorm=1.122, clip=70, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=2869
2023-01-07 23:38:56 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 115845 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0263, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=1290, lr=1.39219e-05, gnorm=1.445, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2892
2023-01-07 23:39:17 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.01, wps=105.4, ups=0.48, wpb=109.3, bsz=40, num_updates=1300, lr=1.40298e-05, gnorm=1.207, clip=80, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2912
2023-01-07 23:39:38 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 115845 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0345, wps=102.7, ups=0.47, wpb=109.4, bsz=40, num_updates=1310, lr=1.41377e-05, gnorm=1.306, clip=90, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2934
2023-01-07 23:40:00 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0303, wps=102, ups=0.46, wpb=110.2, bsz=40, num_updates=1320, lr=1.42456e-05, gnorm=1.227, clip=90, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=2956
2023-01-07 23:40:21 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0183, wps=103.6, ups=0.48, wpb=108.3, bsz=40, num_updates=1330, lr=1.43536e-05, gnorm=1.299, clip=80, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=2977
2023-01-07 23:40:43 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 115845 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0237, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=1340, lr=1.44615e-05, gnorm=1.116, clip=70, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2999
2023-01-07 23:41:05 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 115845 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0145, wps=99.4, ups=0.46, wpb=107.3, bsz=40, num_updates=1350, lr=1.45694e-05, gnorm=1.273, clip=90, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=3021
2023-01-07 23:41:26 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 115845 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.025, wps=101.5, ups=0.47, wpb=108, bsz=40, num_updates=1360, lr=1.46773e-05, gnorm=1.456, clip=100, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3042
2023-01-07 23:41:48 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0206, wps=101.5, ups=0.47, wpb=109.1, bsz=40, num_updates=1370, lr=1.47852e-05, gnorm=1.363, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3064
2023-01-07 23:42:10 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 115845 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0097, wps=99.7, ups=0.46, wpb=108.7, bsz=40, num_updates=1380, lr=1.48932e-05, gnorm=1.148, clip=70, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3086
2023-01-07 23:42:32 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0273, wps=102.6, ups=0.47, wpb=109.4, bsz=40, num_updates=1390, lr=1.50011e-05, gnorm=1.248, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3108
2023-01-07 23:42:53 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 115845 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0185, wps=101.9, ups=0.47, wpb=108.8, bsz=40, num_updates=1400, lr=1.5109e-05, gnorm=1.127, clip=90, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3129
2023-01-07 23:43:15 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0093, wps=100.6, ups=0.46, wpb=108.6, bsz=40, num_updates=1410, lr=1.52169e-05, gnorm=1.257, clip=80, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3151
2023-01-07 23:43:37 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 115845 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0291, wps=99.7, ups=0.46, wpb=108.5, bsz=40, num_updates=1420, lr=1.53248e-05, gnorm=1.359, clip=100, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3173
2023-01-07 23:43:59 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0155, wps=101.2, ups=0.47, wpb=108.4, bsz=40, num_updates=1430, lr=1.54328e-05, gnorm=1.351, clip=90, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=3195
2023-01-07 23:44:21 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 115845 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0366, wps=101, ups=0.46, wpb=109.5, bsz=40, num_updates=1440, lr=1.55407e-05, gnorm=1.132, clip=60, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3217
2023-01-07 23:44:42 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0211, wps=104.9, ups=0.48, wpb=109.1, bsz=40, num_updates=1450, lr=1.56486e-05, gnorm=1.175, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3238
2023-01-07 23:45:04 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 115845 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0317, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=1460, lr=1.57565e-05, gnorm=1.108, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=3259
2023-01-07 23:45:25 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 115845 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0347, wps=103.4, ups=0.47, wpb=110.7, bsz=40, num_updates=1470, lr=1.58645e-05, gnorm=1.128, clip=70, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=3281
2023-01-07 23:45:47 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 115845 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0293, wps=102.5, ups=0.47, wpb=109.8, bsz=40, num_updates=1480, lr=1.59724e-05, gnorm=1.289, clip=80, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=3303
2023-01-07 23:46:08 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 115845 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0187, wps=102.3, ups=0.47, wpb=109.4, bsz=40, num_updates=1490, lr=1.60803e-05, gnorm=1.277, clip=90, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=3324
2023-01-07 23:46:31 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0235, wps=99.3, ups=0.46, wpb=108.9, bsz=40, num_updates=1500, lr=1.61882e-05, gnorm=1.23, clip=70, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3346
2023-01-07 23:46:53 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 115845 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.033, wps=98.4, ups=0.46, wpb=107.7, bsz=40, num_updates=1510, lr=1.62961e-05, gnorm=1.301, clip=80, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3369
2023-01-07 23:47:14 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0193, wps=101, ups=0.47, wpb=107.9, bsz=40, num_updates=1520, lr=1.64041e-05, gnorm=1.174, clip=80, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3390
2023-01-07 23:47:36 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0251, wps=102.4, ups=0.47, wpb=109.7, bsz=40, num_updates=1530, lr=1.6512e-05, gnorm=1.097, clip=70, loss_scale=512, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=3412
2023-01-07 23:47:58 - progress_bar.py[line:274] - INFO: epoch 001:   1540 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.033, wps=100.7, ups=0.46, wpb=109.9, bsz=40, num_updates=1540, lr=1.66199e-05, gnorm=1.25, clip=90, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3434
2023-01-07 23:48:20 - progress_bar.py[line:274] - INFO: epoch 001:   1550 / 115845 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0209, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=1550, lr=1.67278e-05, gnorm=1.183, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3456
2023-01-07 23:48:42 - progress_bar.py[line:274] - INFO: epoch 001:   1560 / 115845 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0097, wps=100.8, ups=0.46, wpb=108.8, bsz=40, num_updates=1560, lr=1.68357e-05, gnorm=1.231, clip=70, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3477
2023-01-07 23:49:03 - progress_bar.py[line:274] - INFO: epoch 001:   1570 / 115845 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.05, wps=101.7, ups=0.47, wpb=108.5, bsz=40, num_updates=1570, lr=1.69437e-05, gnorm=1.147, clip=80, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3499
2023-01-07 23:49:24 - progress_bar.py[line:274] - INFO: epoch 001:   1580 / 115845 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0207, wps=104.3, ups=0.47, wpb=110.1, bsz=40, num_updates=1580, lr=1.70516e-05, gnorm=1.158, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3520
2023-01-07 23:49:46 - progress_bar.py[line:274] - INFO: epoch 001:   1590 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0105, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=1590, lr=1.71595e-05, gnorm=0.993, clip=50, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3542
2023-01-07 23:50:08 - progress_bar.py[line:274] - INFO: epoch 001:   1600 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0335, wps=98.8, ups=0.46, wpb=107, bsz=40, num_updates=1600, lr=1.72674e-05, gnorm=1.415, clip=100, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3564
2023-01-07 23:50:30 - progress_bar.py[line:274] - INFO: epoch 001:   1610 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0095, wps=100.1, ups=0.47, wpb=107.3, bsz=40, num_updates=1610, lr=1.73754e-05, gnorm=1.228, clip=90, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3586
2023-01-07 23:50:52 - progress_bar.py[line:274] - INFO: epoch 001:   1620 / 115845 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0306, wps=102.3, ups=0.47, wpb=109.4, bsz=40, num_updates=1620, lr=1.74833e-05, gnorm=1.087, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3607
2023-01-07 23:51:13 - progress_bar.py[line:274] - INFO: epoch 001:   1630 / 115845 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0363, wps=104.1, ups=0.48, wpb=108.1, bsz=40, num_updates=1630, lr=1.75912e-05, gnorm=1.119, clip=60, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3629
2023-01-07 23:51:34 - progress_bar.py[line:274] - INFO: epoch 001:   1640 / 115845 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0149, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=1640, lr=1.76991e-05, gnorm=1.13, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3650
2023-01-07 23:51:56 - progress_bar.py[line:274] - INFO: epoch 001:   1650 / 115845 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0441, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=1650, lr=1.7807e-05, gnorm=1.117, clip=70, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=3672
2023-01-07 23:52:18 - progress_bar.py[line:274] - INFO: epoch 001:   1660 / 115845 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0251, wps=102, ups=0.47, wpb=109.3, bsz=40, num_updates=1660, lr=1.7915e-05, gnorm=1.095, clip=80, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3694
2023-01-07 23:52:39 - progress_bar.py[line:274] - INFO: epoch 001:   1670 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0357, wps=103.8, ups=0.47, wpb=109.9, bsz=40, num_updates=1670, lr=1.80229e-05, gnorm=1.164, clip=80, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=3715
2023-01-07 23:53:01 - progress_bar.py[line:274] - INFO: epoch 001:   1680 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0357, wps=103.6, ups=0.47, wpb=110, bsz=40, num_updates=1680, lr=1.81308e-05, gnorm=0.947, clip=40, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3736
2023-01-07 23:53:22 - progress_bar.py[line:274] - INFO: epoch 001:   1690 / 115845 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0287, wps=103.5, ups=0.47, wpb=109.5, bsz=40, num_updates=1690, lr=1.82387e-05, gnorm=1.001, clip=40, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=3758
2023-01-07 23:53:43 - progress_bar.py[line:274] - INFO: epoch 001:   1700 / 115845 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0114, wps=102.9, ups=0.47, wpb=109, bsz=40, num_updates=1700, lr=1.83466e-05, gnorm=1.035, clip=50, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3779
2023-01-07 23:54:05 - progress_bar.py[line:274] - INFO: epoch 001:   1710 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0259, wps=100.5, ups=0.46, wpb=109.1, bsz=40, num_updates=1710, lr=1.84546e-05, gnorm=1.209, clip=90, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=3801
2023-01-07 23:54:27 - progress_bar.py[line:274] - INFO: epoch 001:   1720 / 115845 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0515, wps=101.3, ups=0.46, wpb=110, bsz=40, num_updates=1720, lr=1.85625e-05, gnorm=1.024, clip=60, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3823
2023-01-07 23:54:49 - progress_bar.py[line:274] - INFO: epoch 001:   1730 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0378, wps=99.9, ups=0.46, wpb=109.1, bsz=40, num_updates=1730, lr=1.86704e-05, gnorm=1.003, clip=30, loss_scale=1024, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=3845
2023-01-07 23:55:11 - progress_bar.py[line:274] - INFO: epoch 001:   1740 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0212, wps=100.6, ups=0.46, wpb=109.2, bsz=40, num_updates=1740, lr=1.87783e-05, gnorm=1.182, clip=70, loss_scale=1024, train_wall=22, gb_free=9.6, ema_decay=0.9999, wall=3867
2023-01-07 23:55:33 - progress_bar.py[line:274] - INFO: epoch 001:   1750 / 115845 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0244, wps=98.8, ups=0.46, wpb=108.4, bsz=40, num_updates=1750, lr=1.88863e-05, gnorm=1.058, clip=50, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3889
2023-01-07 23:55:56 - progress_bar.py[line:274] - INFO: epoch 001:   1760 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0196, wps=99.3, ups=0.46, wpb=108.9, bsz=40, num_updates=1760, lr=1.89942e-05, gnorm=1.047, clip=60, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=3911
2023-01-07 23:56:17 - progress_bar.py[line:274] - INFO: epoch 001:   1770 / 115845 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0147, wps=103.8, ups=0.48, wpb=108.8, bsz=40, num_updates=1770, lr=1.91021e-05, gnorm=1.17, clip=80, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=3933
2023-01-07 23:56:39 - progress_bar.py[line:274] - INFO: epoch 001:   1780 / 115845 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0159, wps=100.2, ups=0.46, wpb=109.3, bsz=40, num_updates=1780, lr=1.921e-05, gnorm=1.185, clip=90, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3955
2023-01-07 23:57:01 - progress_bar.py[line:274] - INFO: epoch 001:   1790 / 115845 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0262, wps=102.4, ups=0.47, wpb=110, bsz=40, num_updates=1790, lr=1.93179e-05, gnorm=1.036, clip=60, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3977
2023-01-07 23:57:22 - progress_bar.py[line:274] - INFO: epoch 001:   1800 / 115845 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0415, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=1800, lr=1.94259e-05, gnorm=1.121, clip=60, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=3998
2023-01-07 23:57:44 - progress_bar.py[line:274] - INFO: epoch 001:   1810 / 115845 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0191, wps=102.6, ups=0.47, wpb=108.3, bsz=40, num_updates=1810, lr=1.95338e-05, gnorm=1.047, clip=60, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4020
2023-01-07 23:58:06 - progress_bar.py[line:274] - INFO: epoch 001:   1820 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0402, wps=102.5, ups=0.46, wpb=110.2, bsz=40, num_updates=1820, lr=1.96417e-05, gnorm=1.085, clip=60, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=4041
2023-01-07 23:58:28 - progress_bar.py[line:274] - INFO: epoch 001:   1830 / 115845 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.023, wps=98.5, ups=0.46, wpb=107.4, bsz=40, num_updates=1830, lr=1.97496e-05, gnorm=1.115, clip=70, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4063
2023-01-07 23:58:49 - progress_bar.py[line:274] - INFO: epoch 001:   1840 / 115845 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0294, wps=101, ups=0.46, wpb=109.3, bsz=40, num_updates=1840, lr=1.98575e-05, gnorm=1.235, clip=80, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=4085
2023-01-07 23:59:12 - progress_bar.py[line:274] - INFO: epoch 001:   1850 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0251, wps=98.8, ups=0.45, wpb=108.7, bsz=40, num_updates=1850, lr=1.99655e-05, gnorm=1.162, clip=70, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=4107
2023-01-07 23:59:14 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 23:59:35 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 115845 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=108.476, nsentences=40, sample_size=108.476, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.037, wps=96.8, ups=0.43, wpb=108.5, bsz=40, num_updates=1860, lr=2.00734e-05, gnorm=1.122, clip=70, loss_scale=512, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=4131
2023-01-07 23:59:57 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 115845 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0145, wps=100, ups=0.47, wpb=107.3, bsz=40, num_updates=1870, lr=2.01813e-05, gnorm=1.068, clip=60, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=4153
2023-01-08 00:00:19 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 115845 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0291, wps=100.1, ups=0.46, wpb=108.2, bsz=40, num_updates=1880, lr=2.02892e-05, gnorm=1.101, clip=70, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=4175
2023-01-08 00:00:40 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 115845 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.034, wps=103.8, ups=0.47, wpb=109.9, bsz=40, num_updates=1890, lr=2.03972e-05, gnorm=1.125, clip=80, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4196
2023-01-08 00:01:02 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 115845 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0243, wps=101.3, ups=0.46, wpb=109.7, bsz=40, num_updates=1900, lr=2.05051e-05, gnorm=1.143, clip=60, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4218
2023-01-08 00:01:25 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0226, wps=102.6, ups=0.46, wpb=111.5, bsz=40, num_updates=1910, lr=2.0613e-05, gnorm=1.18, clip=80, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=4240
2023-01-08 00:01:48 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 115845 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0101, wps=104.8, ups=0.48, wpb=109.2, bsz=40, num_updates=1920, lr=2.07209e-05, gnorm=1.1, clip=70, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=4262
2023-01-08 00:02:11 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0191, wps=100.4, ups=0.46, wpb=108.2, bsz=40, num_updates=1930, lr=2.08288e-05, gnorm=1.218, clip=100, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=4285
2023-01-08 00:02:34 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 115845 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0102, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=1940, lr=2.09368e-05, gnorm=1.112, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4308
2023-01-08 00:02:57 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0237, wps=99.2, ups=0.45, wpb=109.5, bsz=40, num_updates=1950, lr=2.10447e-05, gnorm=1.054, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4332
2023-01-08 00:03:20 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 115845 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0191, wps=103, ups=0.47, wpb=109.1, bsz=40, num_updates=1960, lr=2.11526e-05, gnorm=1.212, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4354
2023-01-08 00:03:43 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0243, wps=97.9, ups=0.45, wpb=108.1, bsz=40, num_updates=1970, lr=2.12605e-05, gnorm=1.141, clip=80, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=4378
2023-01-08 00:04:06 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 115845 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0208, wps=99.9, ups=0.46, wpb=108.4, bsz=40, num_updates=1980, lr=2.13684e-05, gnorm=1.016, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4401
2023-01-08 00:04:29 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0185, wps=100.3, ups=0.46, wpb=107.9, bsz=40, num_updates=1990, lr=2.14764e-05, gnorm=1.15, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4424
2023-01-08 00:04:52 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0198, wps=101.5, ups=0.47, wpb=108.7, bsz=40, num_updates=2000, lr=2.15843e-05, gnorm=1.111, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4447
2023-01-08 00:04:52 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 00:04:52 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-01-08 00:04:54 - train.py[line:549] - INFO: 0 / 4988
2023-01-08 00:04:54 - train.py[line:551] - INFO: load:1.08 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 00:04:54 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 9.27 GiB already allocated; 6.09 GiB free; 31.02 GiB reserved in total by PyTorch)
2023-01-08 00:04:54 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-08 00:04:54 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 6         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9490 MB |   10716 MB |  658053 GB |  658044 GB |
|       from large pool |    9316 MB |   10541 MB |  657608 GB |  657599 GB |
|       from small pool |     174 MB |     175 MB |     445 GB |     444 GB |
|---------------------------------------------------------------------------|
| Active memory         |    9490 MB |   10716 MB |  658053 GB |  658044 GB |
|       from large pool |    9316 MB |   10541 MB |  657608 GB |  657599 GB |
|       from small pool |     174 MB |     175 MB |     445 GB |     444 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   31764 MB |   33028 MB |  125890 MB |   94126 MB |
|       from large pool |   31588 MB |   32850 MB |  125596 MB |   94008 MB |
|       from small pool |     176 MB |     178 MB |     294 MB |     118 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22273 MB |   26724 MB |  621075 GB |  621053 GB |
|       from large pool |   22271 MB |   26722 MB |  620607 GB |  620585 GB |
|       from small pool |       1 MB |       3 MB |     467 GB |     467 GB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |   28242 K  |   28237 K  |
|       from large pool |     698    |     710    |    9340 K  |    9340 K  |
|       from small pool |    3925    |    3943    |   18901 K  |   18897 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |   28242 K  |   28237 K  |
|       from large pool |     698    |     710    |    9340 K  |    9340 K  |
|       from small pool |    3925    |    3943    |   18901 K  |   18897 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     199    |     208    |     447    |     248    |
|       from large pool |     111    |     119    |     300    |     189    |
|       from small pool |      88    |      89    |     147    |      59    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     125    |     129    |   20660 K  |   20660 K  |
|       from large pool |      66    |      68    |    5433 K  |    5433 K  |
|       from small pool |      59    |      67    |   15227 K  |   15227 K  |
|===========================================================================|

2023-01-08 00:04:54 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-08 00:07:28 - train.py[line:549] - INFO: 200 / 4988
2023-01-08 00:07:28 - train.py[line:551] - INFO: load:1.11 valid_run:153.93 task_valid:150.28 collect_output:2.52
2023-01-08 00:09:57 - train.py[line:549] - INFO: 400 / 4988
2023-01-08 00:09:57 - train.py[line:551] - INFO: load:1.13 valid_run:302.65 task_valid:293.36 collect_output:7.10
2023-01-08 00:12:29 - train.py[line:549] - INFO: 600 / 4988
2023-01-08 00:12:29 - train.py[line:551] - INFO: load:1.16 valid_run:455.15 task_valid:436.25 collect_output:15.67
2023-01-08 00:14:58 - train.py[line:549] - INFO: 800 / 4988
2023-01-08 00:14:58 - train.py[line:551] - INFO: load:1.18 valid_run:604.18 task_valid:581.02 collect_output:18.85
2023-01-08 00:17:30 - train.py[line:549] - INFO: 1000 / 4988
2023-01-08 00:17:30 - train.py[line:551] - INFO: load:1.21 valid_run:756.32 task_valid:728.29 collect_output:22.67
2023-01-08 00:20:02 - train.py[line:549] - INFO: 1200 / 4988
2023-01-08 00:20:02 - train.py[line:551] - INFO: load:1.23 valid_run:908.08 task_valid:873.81 collect_output:27.87
2023-01-08 00:22:36 - train.py[line:549] - INFO: 1400 / 4988
2023-01-08 00:22:36 - train.py[line:551] - INFO: load:1.26 valid_run:1061.75 task_valid:1019.80 collect_output:34.44
2023-01-08 00:25:07 - train.py[line:549] - INFO: 1600 / 4988
2023-01-08 00:25:07 - train.py[line:551] - INFO: load:1.28 valid_run:1213.15 task_valid:1160.86 collect_output:43.69
2023-01-08 00:27:37 - train.py[line:549] - INFO: 1800 / 4988
2023-01-08 00:27:37 - train.py[line:551] - INFO: load:1.31 valid_run:1362.75 task_valid:1305.34 collect_output:47.73
2023-01-08 00:30:06 - train.py[line:549] - INFO: 2000 / 4988
2023-01-08 00:30:06 - train.py[line:551] - INFO: load:1.34 valid_run:1511.70 task_valid:1448.78 collect_output:52.19
2023-01-08 00:32:36 - train.py[line:549] - INFO: 2200 / 4988
2023-01-08 00:32:36 - train.py[line:551] - INFO: load:1.36 valid_run:1661.81 task_valid:1593.68 collect_output:56.32
2023-01-08 00:35:07 - train.py[line:549] - INFO: 2400 / 4988
2023-01-08 00:35:07 - train.py[line:551] - INFO: load:1.39 valid_run:1812.00 task_valid:1738.75 collect_output:60.34
2023-01-08 00:37:37 - train.py[line:549] - INFO: 2600 / 4988
2023-01-08 00:37:37 - train.py[line:551] - INFO: load:1.41 valid_run:1962.24 task_valid:1880.65 collect_output:67.59
2023-01-08 00:40:08 - train.py[line:549] - INFO: 2800 / 4988
2023-01-08 00:40:08 - train.py[line:551] - INFO: load:1.44 valid_run:2112.99 task_valid:2026.25 collect_output:71.66
2023-01-08 00:42:38 - train.py[line:549] - INFO: 3000 / 4988
2023-01-08 00:42:38 - train.py[line:551] - INFO: load:1.47 valid_run:2263.28 task_valid:2172.63 collect_output:74.53
2023-01-08 00:45:08 - train.py[line:549] - INFO: 3200 / 4988
2023-01-08 00:45:08 - train.py[line:551] - INFO: load:1.49 valid_run:2413.58 task_valid:2316.91 collect_output:79.51
2023-01-08 00:47:40 - train.py[line:549] - INFO: 3400 / 4988
2023-01-08 00:47:40 - train.py[line:551] - INFO: load:1.52 valid_run:2565.55 task_valid:2462.32 collect_output:85.00
2023-01-08 00:50:11 - train.py[line:549] - INFO: 3600 / 4988
2023-01-08 00:50:11 - train.py[line:551] - INFO: load:1.54 valid_run:2716.44 task_valid:2609.45 collect_output:87.70
2023-01-08 00:52:40 - train.py[line:549] - INFO: 3800 / 4988
2023-01-08 00:52:41 - train.py[line:551] - INFO: load:1.57 valid_run:2865.44 task_valid:2751.27 collect_output:93.80
2023-01-08 00:55:11 - train.py[line:549] - INFO: 4000 / 4988
2023-01-08 00:55:11 - train.py[line:551] - INFO: load:1.60 valid_run:3016.29 task_valid:2896.76 collect_output:98.04
2023-01-08 00:57:44 - train.py[line:549] - INFO: 4200 / 4988
2023-01-08 00:57:44 - train.py[line:551] - INFO: load:1.62 valid_run:3168.68 task_valid:3041.60 collect_output:104.46
2023-01-08 01:00:14 - train.py[line:549] - INFO: 4400 / 4988
2023-01-08 01:00:14 - train.py[line:551] - INFO: load:1.65 valid_run:3318.53 task_valid:3186.38 collect_output:108.46
2023-01-08 01:02:46 - train.py[line:549] - INFO: 4600 / 4988
2023-01-08 01:02:46 - train.py[line:551] - INFO: load:1.68 valid_run:3470.21 task_valid:3332.49 collect_output:112.99
2023-01-08 01:05:17 - train.py[line:549] - INFO: 4800 / 4988
2023-01-08 01:05:17 - train.py[line:551] - INFO: load:1.70 valid_run:3621.63 task_valid:3478.75 collect_output:117.13

====================================================================================================
SGG eval:     R @ 50: 0.2795;     R @ 100: 0.3483;     R @ 500: 0.4104;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1240;    mR @ 100: 0.1823;    mR @ 500: 0.2225;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0488) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.3941) (says:0.0000) (sitting on:0.4173) (standing on:0.5283) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2795;     R @ 100: 0.3483;     R @ 500: 0.4104;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1240;    mR @ 100: 0.1823;    mR @ 500: 0.2225;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0488) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.3941) (says:0.0000) (sitting on:0.4173) (standing on:0.5283) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-01-08 01:07:48 - train.py[line:487] - INFO: 0.34826666666666667
2023-01-08 01:07:48 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 01:07:48 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.319 | loss_v1 0 | loss_v2 0 | nll_loss 0.161 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.348267 | ppl 1.12 | vqa_score 0.1745 | wps 118.9 | wpb 89.9 | bsz 30 | num_updates 2000
2023-01-08 01:07:48 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2023-01-08 01:07:48 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_2000.pt
2023-01-08 01:08:30 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_2000.pt
2023-01-08 01:11:31 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.34826666666666667) (writing took 222.25761033967137 seconds)
2023-01-08 01:11:53 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 115845 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0099, wps=0.5, ups=0, wpb=108.2, bsz=40, num_updates=2010, lr=2.16922e-05, gnorm=1.018, clip=50, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=8468
2023-01-08 01:12:15 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 115845 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0267, wps=100.8, ups=0.46, wpb=110, bsz=40, num_updates=2020, lr=2.18001e-05, gnorm=1.049, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8490
2023-01-08 01:12:37 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 115845 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0193, wps=101.4, ups=0.47, wpb=108.4, bsz=40, num_updates=2030, lr=2.19081e-05, gnorm=1.01, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8512
2023-01-08 01:12:59 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0169, wps=102.8, ups=0.47, wpb=110.2, bsz=40, num_updates=2040, lr=2.2016e-05, gnorm=1.184, clip=80, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=8535
2023-01-08 01:13:21 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0222, wps=103.2, ups=0.46, wpb=111, bsz=40, num_updates=2050, lr=2.21239e-05, gnorm=1.06, clip=50, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=8557
2023-01-08 01:13:43 - progress_bar.py[line:274] - INFO: epoch 001:   2061 / 115845 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0244, wps=103.1, ups=0.47, wpb=110, bsz=40, num_updates=2060, lr=2.22318e-05, gnorm=1.064, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=8579
2023-01-08 01:14:06 - progress_bar.py[line:274] - INFO: epoch 001:   2071 / 115845 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0287, wps=96.8, ups=0.45, wpb=108.8, bsz=40, num_updates=2070, lr=2.23397e-05, gnorm=1.045, clip=70, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8601
2023-01-08 01:14:28 - progress_bar.py[line:274] - INFO: epoch 001:   2081 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0376, wps=101.4, ups=0.46, wpb=109.8, bsz=40, num_updates=2080, lr=2.24477e-05, gnorm=1.076, clip=50, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8624
2023-01-08 01:14:50 - progress_bar.py[line:274] - INFO: epoch 001:   2091 / 115845 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0425, wps=101.1, ups=0.46, wpb=109.2, bsz=40, num_updates=2090, lr=2.25556e-05, gnorm=1.042, clip=50, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8646
2023-01-08 01:15:12 - progress_bar.py[line:274] - INFO: epoch 001:   2101 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0093, wps=103.6, ups=0.48, wpb=108, bsz=40, num_updates=2100, lr=2.26635e-05, gnorm=1.095, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8667
2023-01-08 01:15:34 - progress_bar.py[line:274] - INFO: epoch 001:   2111 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0366, wps=102.2, ups=0.47, wpb=108.9, bsz=40, num_updates=2110, lr=2.27714e-05, gnorm=0.976, clip=50, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=8689
2023-01-08 01:15:55 - progress_bar.py[line:274] - INFO: epoch 001:   2121 / 115845 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0253, wps=102.2, ups=0.47, wpb=108.4, bsz=40, num_updates=2120, lr=2.28793e-05, gnorm=1.033, clip=50, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=8711
2023-01-08 01:16:18 - progress_bar.py[line:274] - INFO: epoch 001:   2131 / 115845 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0214, wps=101.1, ups=0.46, wpb=110.1, bsz=40, num_updates=2130, lr=2.29873e-05, gnorm=1.003, clip=60, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8733
2023-01-08 01:16:40 - progress_bar.py[line:274] - INFO: epoch 001:   2141 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0215, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=2140, lr=2.30952e-05, gnorm=0.982, clip=70, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8755
2023-01-08 01:17:02 - progress_bar.py[line:274] - INFO: epoch 001:   2151 / 115845 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=106.7, nsentences=40, sample_size=106.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0185, wps=99.6, ups=0.47, wpb=106.7, bsz=40, num_updates=2150, lr=2.32031e-05, gnorm=1.028, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8777
2023-01-08 01:17:24 - progress_bar.py[line:274] - INFO: epoch 001:   2161 / 115845 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0248, wps=101.5, ups=0.47, wpb=108.6, bsz=40, num_updates=2160, lr=2.3311e-05, gnorm=1.04, clip=70, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=8799
2023-01-08 01:17:46 - progress_bar.py[line:274] - INFO: epoch 001:   2171 / 115845 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0191, wps=101.9, ups=0.47, wpb=108.4, bsz=40, num_updates=2170, lr=2.3419e-05, gnorm=0.971, clip=40, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=8821
2023-01-08 01:18:08 - progress_bar.py[line:274] - INFO: epoch 001:   2181 / 115845 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0144, wps=100.3, ups=0.46, wpb=108.6, bsz=40, num_updates=2180, lr=2.35269e-05, gnorm=1.092, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8843
2023-01-08 01:18:30 - progress_bar.py[line:274] - INFO: epoch 001:   2191 / 115845 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0239, wps=100, ups=0.46, wpb=107.8, bsz=40, num_updates=2190, lr=2.36348e-05, gnorm=1.146, clip=90, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8865
2023-01-08 01:18:52 - progress_bar.py[line:274] - INFO: epoch 001:   2201 / 115845 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.03, wps=101, ups=0.46, wpb=109.9, bsz=40, num_updates=2200, lr=2.37427e-05, gnorm=1.102, clip=80, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8888
2023-01-08 01:19:14 - progress_bar.py[line:274] - INFO: epoch 001:   2211 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0198, wps=100.7, ups=0.46, wpb=109.9, bsz=40, num_updates=2210, lr=2.38506e-05, gnorm=0.973, clip=40, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8910
2023-01-08 01:19:36 - progress_bar.py[line:274] - INFO: epoch 001:   2221 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0274, wps=102, ups=0.47, wpb=108.3, bsz=40, num_updates=2220, lr=2.39586e-05, gnorm=0.996, clip=50, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=8932
2023-01-08 01:19:58 - progress_bar.py[line:274] - INFO: epoch 001:   2231 / 115845 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0199, wps=101.4, ups=0.47, wpb=108.6, bsz=40, num_updates=2230, lr=2.40665e-05, gnorm=1.228, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8954
2023-01-08 01:20:20 - progress_bar.py[line:274] - INFO: epoch 001:   2241 / 115845 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.035, wps=100.4, ups=0.46, wpb=109.6, bsz=40, num_updates=2240, lr=2.41744e-05, gnorm=1.081, clip=40, loss_scale=512, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=8976
2023-01-08 01:20:43 - progress_bar.py[line:274] - INFO: epoch 001:   2251 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0049, wps=100.2, ups=0.46, wpb=107.9, bsz=40, num_updates=2250, lr=2.42823e-05, gnorm=0.995, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8998
2023-01-08 01:21:05 - progress_bar.py[line:274] - INFO: epoch 001:   2261 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0341, wps=100.1, ups=0.46, wpb=108.2, bsz=40, num_updates=2260, lr=2.43902e-05, gnorm=1.105, clip=70, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9020
2023-01-08 01:21:27 - progress_bar.py[line:274] - INFO: epoch 001:   2271 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0049, wps=99.4, ups=0.46, wpb=108.6, bsz=40, num_updates=2270, lr=2.44982e-05, gnorm=1.106, clip=40, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=9043
2023-01-08 01:21:49 - progress_bar.py[line:274] - INFO: epoch 001:   2281 / 115845 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0203, wps=101.1, ups=0.46, wpb=109.1, bsz=40, num_updates=2280, lr=2.46061e-05, gnorm=0.988, clip=60, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=9065
2023-01-08 01:22:11 - progress_bar.py[line:274] - INFO: epoch 001:   2291 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0159, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=2290, lr=2.4714e-05, gnorm=0.914, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9087
2023-01-08 01:22:34 - progress_bar.py[line:274] - INFO: epoch 001:   2301 / 115845 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0347, wps=98, ups=0.45, wpb=108.3, bsz=40, num_updates=2300, lr=2.48219e-05, gnorm=1.004, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9109
2023-01-08 01:22:56 - progress_bar.py[line:274] - INFO: epoch 001:   2311 / 115845 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0388, wps=99.6, ups=0.46, wpb=108.5, bsz=40, num_updates=2310, lr=2.49299e-05, gnorm=1.026, clip=30, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9132
2023-01-08 01:23:18 - progress_bar.py[line:274] - INFO: epoch 001:   2321 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0443, wps=99.9, ups=0.46, wpb=108.5, bsz=40, num_updates=2320, lr=2.50378e-05, gnorm=1.125, clip=70, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9154
2023-01-08 01:23:40 - progress_bar.py[line:274] - INFO: epoch 001:   2331 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0096, wps=101.6, ups=0.47, wpb=108.3, bsz=40, num_updates=2330, lr=2.51457e-05, gnorm=1.055, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9176
2023-01-08 01:24:03 - progress_bar.py[line:274] - INFO: epoch 001:   2341 / 115845 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0286, wps=100.6, ups=0.46, wpb=108.5, bsz=40, num_updates=2340, lr=2.52536e-05, gnorm=1.094, clip=40, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=9198
2023-01-08 01:24:25 - progress_bar.py[line:274] - INFO: epoch 001:   2351 / 115845 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0238, wps=101.9, ups=0.47, wpb=109.1, bsz=40, num_updates=2350, lr=2.53615e-05, gnorm=1.011, clip=40, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=9220
2023-01-08 01:24:46 - progress_bar.py[line:274] - INFO: epoch 001:   2361 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0278, wps=105, ups=0.47, wpb=111.2, bsz=40, num_updates=2360, lr=2.54695e-05, gnorm=0.853, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=9242
2023-01-08 01:25:09 - progress_bar.py[line:274] - INFO: epoch 001:   2371 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0266, wps=100.8, ups=0.46, wpb=109.7, bsz=40, num_updates=2370, lr=2.55774e-05, gnorm=1.04, clip=30, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9264
2023-01-08 01:25:30 - progress_bar.py[line:274] - INFO: epoch 001:   2381 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0359, wps=101.5, ups=0.47, wpb=108.4, bsz=40, num_updates=2380, lr=2.56853e-05, gnorm=1.014, clip=60, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=9286
2023-01-08 01:25:53 - progress_bar.py[line:274] - INFO: epoch 001:   2391 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0147, wps=100.5, ups=0.46, wpb=108.5, bsz=40, num_updates=2390, lr=2.57932e-05, gnorm=0.914, clip=30, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9308
2023-01-08 01:26:14 - progress_bar.py[line:274] - INFO: epoch 001:   2401 / 115845 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0206, wps=102.8, ups=0.47, wpb=109, bsz=40, num_updates=2400, lr=2.59011e-05, gnorm=0.965, clip=30, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9330
2023-01-08 01:26:37 - progress_bar.py[line:274] - INFO: epoch 001:   2411 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.041, wps=100.3, ups=0.46, wpb=108.3, bsz=40, num_updates=2410, lr=2.60091e-05, gnorm=1.073, clip=50, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9352
2023-01-08 01:26:58 - progress_bar.py[line:274] - INFO: epoch 001:   2421 / 115845 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.039, wps=102.7, ups=0.47, wpb=109.7, bsz=40, num_updates=2420, lr=2.6117e-05, gnorm=0.911, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9374
2023-01-08 01:27:20 - progress_bar.py[line:274] - INFO: epoch 001:   2431 / 115845 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0093, wps=100.3, ups=0.47, wpb=107.2, bsz=40, num_updates=2430, lr=2.62249e-05, gnorm=0.952, clip=40, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=9396
2023-01-08 01:27:42 - progress_bar.py[line:274] - INFO: epoch 001:   2441 / 115845 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0333, wps=102.5, ups=0.47, wpb=108.7, bsz=40, num_updates=2440, lr=2.63328e-05, gnorm=1.028, clip=60, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=9418
2023-01-08 01:28:04 - progress_bar.py[line:274] - INFO: epoch 001:   2451 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0372, wps=102.4, ups=0.46, wpb=110.5, bsz=40, num_updates=2450, lr=2.64408e-05, gnorm=0.941, clip=40, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9440
2023-01-08 01:28:26 - progress_bar.py[line:274] - INFO: epoch 001:   2461 / 115845 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0421, wps=101.6, ups=0.46, wpb=109.5, bsz=40, num_updates=2460, lr=2.65487e-05, gnorm=1.039, clip=50, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9462
2023-01-08 01:28:48 - progress_bar.py[line:274] - INFO: epoch 001:   2471 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0282, wps=101.2, ups=0.46, wpb=108.8, bsz=40, num_updates=2470, lr=2.66566e-05, gnorm=0.915, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=9484
2023-01-08 01:29:10 - progress_bar.py[line:274] - INFO: epoch 001:   2481 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0387, wps=102.4, ups=0.46, wpb=110.1, bsz=40, num_updates=2480, lr=2.67645e-05, gnorm=0.964, clip=50, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9506
2023-01-08 01:29:33 - progress_bar.py[line:274] - INFO: epoch 001:   2491 / 115845 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0388, wps=99.1, ups=0.46, wpb=108, bsz=40, num_updates=2490, lr=2.68724e-05, gnorm=1.044, clip=60, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9528
2023-01-08 01:29:55 - progress_bar.py[line:274] - INFO: epoch 001:   2501 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0348, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=2500, lr=2.69804e-05, gnorm=0.874, clip=20, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=9550
2023-01-08 01:30:16 - progress_bar.py[line:274] - INFO: epoch 001:   2511 / 115845 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0195, wps=102.6, ups=0.47, wpb=108.6, bsz=40, num_updates=2510, lr=2.70883e-05, gnorm=0.978, clip=60, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=9572
2023-01-08 01:30:39 - progress_bar.py[line:274] - INFO: epoch 001:   2521 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0192, wps=101.1, ups=0.46, wpb=109.8, bsz=40, num_updates=2520, lr=2.71962e-05, gnorm=0.935, clip=40, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=9594
2023-01-08 01:31:01 - progress_bar.py[line:274] - INFO: epoch 001:   2531 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0255, wps=102.6, ups=0.47, wpb=109.7, bsz=40, num_updates=2530, lr=2.73041e-05, gnorm=0.946, clip=40, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9616
2023-01-08 01:31:23 - progress_bar.py[line:274] - INFO: epoch 001:   2541 / 115845 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0392, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=2540, lr=2.7412e-05, gnorm=0.958, clip=60, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9638
2023-01-08 01:31:45 - progress_bar.py[line:274] - INFO: epoch 001:   2551 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0321, wps=102.9, ups=0.47, wpb=110.3, bsz=40, num_updates=2550, lr=2.752e-05, gnorm=0.89, clip=20, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9660
2023-01-08 01:32:07 - progress_bar.py[line:274] - INFO: epoch 001:   2561 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0248, wps=100.4, ups=0.46, wpb=108.5, bsz=40, num_updates=2560, lr=2.76279e-05, gnorm=0.91, clip=30, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9682
2023-01-08 01:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   2571 / 115845 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.039, wps=102.2, ups=0.47, wpb=108.3, bsz=40, num_updates=2570, lr=2.77358e-05, gnorm=0.894, clip=40, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9704
2023-01-08 01:32:50 - progress_bar.py[line:274] - INFO: epoch 001:   2581 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0361, wps=101, ups=0.46, wpb=110.1, bsz=40, num_updates=2580, lr=2.78437e-05, gnorm=0.97, clip=60, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9726
2023-01-08 01:33:12 - progress_bar.py[line:274] - INFO: epoch 001:   2591 / 115845 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0231, wps=97.7, ups=0.45, wpb=107.9, bsz=40, num_updates=2590, lr=2.79517e-05, gnorm=0.954, clip=40, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=9748
2023-01-08 01:33:34 - progress_bar.py[line:274] - INFO: epoch 001:   2601 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0402, wps=103.1, ups=0.47, wpb=109.3, bsz=40, num_updates=2600, lr=2.80596e-05, gnorm=0.913, clip=30, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=9770
2023-01-08 01:33:56 - progress_bar.py[line:274] - INFO: epoch 001:   2611 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0245, wps=102.6, ups=0.46, wpb=110.5, bsz=40, num_updates=2610, lr=2.81675e-05, gnorm=1.006, clip=70, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9791
2023-01-08 01:34:18 - progress_bar.py[line:274] - INFO: epoch 001:   2621 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0363, wps=100.4, ups=0.46, wpb=108.8, bsz=40, num_updates=2620, lr=2.82754e-05, gnorm=0.952, clip=50, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=9813
2023-01-08 01:34:40 - progress_bar.py[line:274] - INFO: epoch 001:   2631 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.043, wps=101, ups=0.46, wpb=109.8, bsz=40, num_updates=2630, lr=2.83833e-05, gnorm=0.85, clip=20, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9835
2023-01-08 01:35:01 - progress_bar.py[line:274] - INFO: epoch 001:   2641 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0205, wps=101.7, ups=0.47, wpb=108.1, bsz=40, num_updates=2640, lr=2.84913e-05, gnorm=0.956, clip=40, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=9857
2023-01-08 01:35:22 - progress_bar.py[line:274] - INFO: epoch 001:   2651 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0243, wps=101.6, ups=0.47, wpb=107.4, bsz=40, num_updates=2650, lr=2.85992e-05, gnorm=0.969, clip=50, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9878
2023-01-08 01:35:44 - progress_bar.py[line:274] - INFO: epoch 001:   2661 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0426, wps=102.4, ups=0.46, wpb=110.5, bsz=40, num_updates=2660, lr=2.87071e-05, gnorm=0.901, clip=20, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=9900
2023-01-08 01:36:06 - progress_bar.py[line:274] - INFO: epoch 001:   2671 / 115845 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0144, wps=101.8, ups=0.46, wpb=110, bsz=40, num_updates=2670, lr=2.8815e-05, gnorm=0.841, clip=30, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9922
2023-01-08 01:36:28 - progress_bar.py[line:274] - INFO: epoch 001:   2681 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0502, wps=99.6, ups=0.46, wpb=108.4, bsz=40, num_updates=2680, lr=2.89229e-05, gnorm=0.845, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=9944
2023-01-08 01:36:50 - progress_bar.py[line:274] - INFO: epoch 001:   2691 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0262, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=2690, lr=2.90309e-05, gnorm=0.856, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9966
2023-01-08 01:37:12 - progress_bar.py[line:274] - INFO: epoch 001:   2701 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0396, wps=100.9, ups=0.46, wpb=109.1, bsz=40, num_updates=2700, lr=2.91388e-05, gnorm=0.917, clip=30, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=9988
2023-01-08 01:37:34 - progress_bar.py[line:274] - INFO: epoch 001:   2711 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0276, wps=102.2, ups=0.46, wpb=110, bsz=40, num_updates=2710, lr=2.92467e-05, gnorm=0.818, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10009
2023-01-08 01:37:55 - progress_bar.py[line:274] - INFO: epoch 001:   2721 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0201, wps=101.8, ups=0.46, wpb=109.7, bsz=40, num_updates=2720, lr=2.93546e-05, gnorm=0.872, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=10031
2023-01-08 01:38:17 - progress_bar.py[line:274] - INFO: epoch 001:   2731 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0421, wps=101.4, ups=0.47, wpb=107.7, bsz=40, num_updates=2730, lr=2.94626e-05, gnorm=0.942, clip=30, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=10053
2023-01-08 01:38:38 - progress_bar.py[line:274] - INFO: epoch 001:   2741 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.005, wps=102.3, ups=0.47, wpb=109.3, bsz=40, num_updates=2740, lr=2.95705e-05, gnorm=0.884, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10074
2023-01-08 01:39:00 - progress_bar.py[line:274] - INFO: epoch 001:   2751 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0316, wps=100.7, ups=0.46, wpb=108.6, bsz=40, num_updates=2750, lr=2.96784e-05, gnorm=0.891, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10096
2023-01-08 01:39:21 - progress_bar.py[line:274] - INFO: epoch 001:   2761 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0251, wps=105.7, ups=0.48, wpb=110, bsz=40, num_updates=2760, lr=2.97863e-05, gnorm=0.911, clip=20, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10117
2023-01-08 01:39:43 - progress_bar.py[line:274] - INFO: epoch 001:   2771 / 115845 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0338, wps=99.3, ups=0.46, wpb=108.4, bsz=40, num_updates=2770, lr=2.98942e-05, gnorm=0.941, clip=30, loss_scale=1024, train_wall=22, gb_free=9.6, ema_decay=0.9999, wall=10139
2023-01-08 01:40:05 - progress_bar.py[line:274] - INFO: epoch 001:   2781 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0433, wps=98.8, ups=0.46, wpb=108.5, bsz=40, num_updates=2780, lr=3.00022e-05, gnorm=0.917, clip=30, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=10161
2023-01-08 01:40:27 - progress_bar.py[line:274] - INFO: epoch 001:   2791 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0526, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=2790, lr=3.01101e-05, gnorm=1.041, clip=40, loss_scale=1024, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=10183
2023-01-08 01:40:49 - progress_bar.py[line:274] - INFO: epoch 001:   2801 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0546, wps=103.3, ups=0.47, wpb=110, bsz=40, num_updates=2800, lr=3.0218e-05, gnorm=0.967, clip=50, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10205
2023-01-08 01:41:11 - progress_bar.py[line:274] - INFO: epoch 001:   2811 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0326, wps=102.3, ups=0.46, wpb=110.3, bsz=40, num_updates=2810, lr=3.03259e-05, gnorm=0.876, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10226
2023-01-08 01:41:32 - progress_bar.py[line:274] - INFO: epoch 001:   2821 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0515, wps=102.7, ups=0.47, wpb=108.9, bsz=40, num_updates=2820, lr=3.04338e-05, gnorm=0.914, clip=30, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=10248
2023-01-08 01:41:54 - progress_bar.py[line:274] - INFO: epoch 001:   2831 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0052, wps=100.5, ups=0.46, wpb=108.9, bsz=40, num_updates=2830, lr=3.05418e-05, gnorm=0.948, clip=50, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=10270
2023-01-08 01:42:16 - progress_bar.py[line:274] - INFO: epoch 001:   2841 / 115845 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0267, wps=101.9, ups=0.47, wpb=108.7, bsz=40, num_updates=2840, lr=3.06497e-05, gnorm=0.806, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10291
2023-01-08 01:42:18 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 01:42:39 - progress_bar.py[line:274] - INFO: epoch 001:   2852 / 115845 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=109.429, nsentences=40, sample_size=109.429, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0139, wps=98.8, ups=0.43, wpb=109.4, bsz=40, num_updates=2850, lr=3.07576e-05, gnorm=0.991, clip=50, loss_scale=512, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=10315
2023-01-08 01:43:01 - progress_bar.py[line:274] - INFO: epoch 001:   2862 / 115845 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.029, wps=98.7, ups=0.45, wpb=108.6, bsz=40, num_updates=2860, lr=3.08655e-05, gnorm=0.787, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10337
2023-01-08 01:43:23 - progress_bar.py[line:274] - INFO: epoch 001:   2872 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0338, wps=100.8, ups=0.46, wpb=109.3, bsz=40, num_updates=2870, lr=3.09735e-05, gnorm=0.848, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=10359
2023-01-08 01:43:45 - progress_bar.py[line:274] - INFO: epoch 001:   2882 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0203, wps=101.8, ups=0.47, wpb=109.1, bsz=40, num_updates=2880, lr=3.10814e-05, gnorm=0.856, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10381
2023-01-08 01:44:06 - progress_bar.py[line:274] - INFO: epoch 001:   2892 / 115845 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.025, wps=103.4, ups=0.47, wpb=109.3, bsz=40, num_updates=2890, lr=3.11893e-05, gnorm=0.78, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10402
2023-01-08 01:44:28 - progress_bar.py[line:274] - INFO: epoch 001:   2902 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0293, wps=102.2, ups=0.47, wpb=109.3, bsz=40, num_updates=2900, lr=3.12972e-05, gnorm=0.823, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10424
2023-01-08 01:44:49 - progress_bar.py[line:274] - INFO: epoch 001:   2912 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0303, wps=103.5, ups=0.48, wpb=108.8, bsz=40, num_updates=2910, lr=3.14051e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10445
2023-01-08 01:45:11 - progress_bar.py[line:274] - INFO: epoch 001:   2922 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0048, wps=102.8, ups=0.47, wpb=109.6, bsz=40, num_updates=2920, lr=3.15131e-05, gnorm=0.829, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10467
2023-01-08 01:45:32 - progress_bar.py[line:274] - INFO: epoch 001:   2932 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0306, wps=102.3, ups=0.47, wpb=109.1, bsz=40, num_updates=2930, lr=3.1621e-05, gnorm=1.001, clip=60, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10488
2023-01-08 01:45:54 - progress_bar.py[line:274] - INFO: epoch 001:   2942 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0243, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=2940, lr=3.17289e-05, gnorm=0.752, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10510
2023-01-08 01:46:16 - progress_bar.py[line:274] - INFO: epoch 001:   2952 / 115845 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0309, wps=100.4, ups=0.46, wpb=109.7, bsz=40, num_updates=2950, lr=3.18368e-05, gnorm=0.849, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=10532
2023-01-08 01:46:38 - progress_bar.py[line:274] - INFO: epoch 001:   2962 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.05, wps=101.2, ups=0.46, wpb=109.8, bsz=40, num_updates=2960, lr=3.19447e-05, gnorm=0.85, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10554
2023-01-08 01:46:59 - progress_bar.py[line:274] - INFO: epoch 001:   2972 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0374, wps=102.8, ups=0.47, wpb=109.4, bsz=40, num_updates=2970, lr=3.20527e-05, gnorm=0.854, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10575
2023-01-08 01:47:21 - progress_bar.py[line:274] - INFO: epoch 001:   2982 / 115845 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0248, wps=100.3, ups=0.46, wpb=108.8, bsz=40, num_updates=2980, lr=3.21606e-05, gnorm=0.9, clip=30, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10597
2023-01-08 01:47:43 - progress_bar.py[line:274] - INFO: epoch 001:   2992 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0149, wps=101.8, ups=0.47, wpb=108.7, bsz=40, num_updates=2990, lr=3.22685e-05, gnorm=0.875, clip=30, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=10619
2023-01-08 01:48:05 - progress_bar.py[line:274] - INFO: epoch 001:   3002 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0, wps=102.3, ups=0.47, wpb=109.4, bsz=40, num_updates=3000, lr=3.23764e-05, gnorm=0.753, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=10640
2023-01-08 01:48:26 - progress_bar.py[line:274] - INFO: epoch 001:   3012 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0149, wps=101.6, ups=0.46, wpb=109.4, bsz=40, num_updates=3010, lr=3.24844e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10662
2023-01-08 01:48:48 - progress_bar.py[line:274] - INFO: epoch 001:   3022 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0202, wps=100.6, ups=0.46, wpb=109, bsz=40, num_updates=3020, lr=3.25923e-05, gnorm=0.957, clip=40, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=10684
2023-01-08 01:49:10 - progress_bar.py[line:274] - INFO: epoch 001:   3032 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0196, wps=102.5, ups=0.47, wpb=109.9, bsz=40, num_updates=3030, lr=3.27002e-05, gnorm=0.827, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10706
2023-01-08 01:49:31 - progress_bar.py[line:274] - INFO: epoch 001:   3042 / 115845 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0296, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=3040, lr=3.28081e-05, gnorm=0.875, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=10727
2023-01-08 01:49:53 - progress_bar.py[line:274] - INFO: epoch 001:   3052 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.029, wps=101.3, ups=0.47, wpb=108.5, bsz=40, num_updates=3050, lr=3.2916e-05, gnorm=0.92, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10749
2023-01-08 01:50:15 - progress_bar.py[line:274] - INFO: epoch 001:   3062 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0148, wps=103.1, ups=0.47, wpb=108.9, bsz=40, num_updates=3060, lr=3.3024e-05, gnorm=0.959, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10770
2023-01-08 01:50:36 - progress_bar.py[line:274] - INFO: epoch 001:   3072 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0163, wps=102.3, ups=0.47, wpb=109.9, bsz=40, num_updates=3070, lr=3.31319e-05, gnorm=0.903, clip=40, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=10792
2023-01-08 01:50:58 - progress_bar.py[line:274] - INFO: epoch 001:   3082 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0051, wps=99.1, ups=0.46, wpb=108.2, bsz=40, num_updates=3080, lr=3.32398e-05, gnorm=0.917, clip=30, loss_scale=512, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=10814
2023-01-08 01:51:20 - progress_bar.py[line:274] - INFO: epoch 001:   3092 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0236, wps=103.8, ups=0.48, wpb=108.8, bsz=40, num_updates=3090, lr=3.33477e-05, gnorm=0.749, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=10835
2023-01-08 01:51:41 - progress_bar.py[line:274] - INFO: epoch 001:   3102 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0094, wps=103.8, ups=0.47, wpb=109.6, bsz=40, num_updates=3100, lr=3.34556e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10857
2023-01-08 01:52:03 - progress_bar.py[line:274] - INFO: epoch 001:   3112 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0323, wps=101.3, ups=0.46, wpb=110.5, bsz=40, num_updates=3110, lr=3.35636e-05, gnorm=0.803, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=10879
2023-01-08 01:52:25 - progress_bar.py[line:274] - INFO: epoch 001:   3122 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0542, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=3120, lr=3.36715e-05, gnorm=0.785, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10901
2023-01-08 01:52:46 - progress_bar.py[line:274] - INFO: epoch 001:   3132 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0236, wps=100.5, ups=0.47, wpb=107.5, bsz=40, num_updates=3130, lr=3.37794e-05, gnorm=0.832, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10922
2023-01-08 01:53:09 - progress_bar.py[line:274] - INFO: epoch 001:   3142 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0455, wps=100.3, ups=0.46, wpb=109.8, bsz=40, num_updates=3140, lr=3.38873e-05, gnorm=1.04, clip=50, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=10944
2023-01-08 01:53:31 - progress_bar.py[line:274] - INFO: epoch 001:   3152 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0052, wps=99.8, ups=0.45, wpb=109.8, bsz=40, num_updates=3150, lr=3.39953e-05, gnorm=1.085, clip=50, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10967
2023-01-08 01:53:53 - progress_bar.py[line:274] - INFO: epoch 001:   3162 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0374, wps=102, ups=0.46, wpb=109.7, bsz=40, num_updates=3160, lr=3.41032e-05, gnorm=0.962, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10988
2023-01-08 01:54:14 - progress_bar.py[line:274] - INFO: epoch 001:   3172 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.023, wps=101.5, ups=0.47, wpb=109.1, bsz=40, num_updates=3170, lr=3.42111e-05, gnorm=0.868, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11010
2023-01-08 01:54:37 - progress_bar.py[line:274] - INFO: epoch 001:   3182 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.02, wps=100, ups=0.46, wpb=109.2, bsz=40, num_updates=3180, lr=3.4319e-05, gnorm=0.88, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11032
2023-01-08 01:54:58 - progress_bar.py[line:274] - INFO: epoch 001:   3192 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0185, wps=101.4, ups=0.47, wpb=107.6, bsz=40, num_updates=3190, lr=3.44269e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=11054
2023-01-08 01:55:19 - progress_bar.py[line:274] - INFO: epoch 001:   3202 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0209, wps=103.2, ups=0.47, wpb=109.4, bsz=40, num_updates=3200, lr=3.45349e-05, gnorm=0.954, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11075
2023-01-08 01:55:41 - progress_bar.py[line:274] - INFO: epoch 001:   3212 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0201, wps=101.9, ups=0.47, wpb=108.9, bsz=40, num_updates=3210, lr=3.46428e-05, gnorm=0.858, clip=30, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=11097
2023-01-08 01:56:03 - progress_bar.py[line:274] - INFO: epoch 001:   3222 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0302, wps=98.9, ups=0.46, wpb=108.6, bsz=40, num_updates=3220, lr=3.47507e-05, gnorm=0.795, clip=30, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=11119
2023-01-08 01:56:25 - progress_bar.py[line:274] - INFO: epoch 001:   3232 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0156, wps=101.2, ups=0.47, wpb=108.3, bsz=40, num_updates=3230, lr=3.48586e-05, gnorm=0.804, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11141
2023-01-08 01:56:47 - progress_bar.py[line:274] - INFO: epoch 001:   3242 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0244, wps=102.6, ups=0.47, wpb=109.2, bsz=40, num_updates=3240, lr=3.49665e-05, gnorm=0.792, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=11162
2023-01-08 01:57:08 - progress_bar.py[line:274] - INFO: epoch 001:   3252 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0355, wps=100.9, ups=0.46, wpb=109, bsz=40, num_updates=3250, lr=3.50745e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=11184
2023-01-08 01:57:30 - progress_bar.py[line:274] - INFO: epoch 001:   3262 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0347, wps=101.9, ups=0.47, wpb=108.7, bsz=40, num_updates=3260, lr=3.51824e-05, gnorm=0.761, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=11206
2023-01-08 01:57:52 - progress_bar.py[line:274] - INFO: epoch 001:   3272 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0483, wps=100.6, ups=0.46, wpb=109, bsz=40, num_updates=3270, lr=3.52903e-05, gnorm=0.9, clip=30, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11228
2023-01-08 01:58:13 - progress_bar.py[line:274] - INFO: epoch 001:   3282 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.039, wps=105.1, ups=0.48, wpb=109.3, bsz=40, num_updates=3280, lr=3.53982e-05, gnorm=0.889, clip=30, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11249
2023-01-08 01:58:35 - progress_bar.py[line:274] - INFO: epoch 001:   3292 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.005, wps=100.3, ups=0.46, wpb=109, bsz=40, num_updates=3290, lr=3.55062e-05, gnorm=0.887, clip=30, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=11271
2023-01-08 01:58:56 - progress_bar.py[line:274] - INFO: epoch 001:   3302 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0428, wps=104.5, ups=0.48, wpb=109.6, bsz=40, num_updates=3300, lr=3.56141e-05, gnorm=0.975, clip=40, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11292
2023-01-08 01:59:19 - progress_bar.py[line:274] - INFO: epoch 001:   3312 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0493, wps=96.8, ups=0.45, wpb=108.4, bsz=40, num_updates=3310, lr=3.5722e-05, gnorm=0.696, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=11314
2023-01-08 01:59:41 - progress_bar.py[line:274] - INFO: epoch 001:   3322 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0282, wps=97.8, ups=0.45, wpb=107.5, bsz=40, num_updates=3320, lr=3.58299e-05, gnorm=0.908, clip=40, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=11337
2023-01-08 02:00:03 - progress_bar.py[line:274] - INFO: epoch 001:   3332 / 115845 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.068, wps=98.1, ups=0.46, wpb=106.9, bsz=40, num_updates=3330, lr=3.59378e-05, gnorm=0.912, clip=30, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=11359
2023-01-08 02:00:24 - progress_bar.py[line:274] - INFO: epoch 001:   3342 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0221, wps=104.3, ups=0.47, wpb=110.4, bsz=40, num_updates=3340, lr=3.60458e-05, gnorm=0.885, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11380
2023-01-08 02:00:46 - progress_bar.py[line:274] - INFO: epoch 001:   3352 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0197, wps=100.8, ups=0.46, wpb=109.7, bsz=40, num_updates=3350, lr=3.61537e-05, gnorm=0.891, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11402
2023-01-08 02:01:07 - progress_bar.py[line:274] - INFO: epoch 001:   3362 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0192, wps=104, ups=0.48, wpb=109.1, bsz=40, num_updates=3360, lr=3.62616e-05, gnorm=0.848, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11423
2023-01-08 02:01:29 - progress_bar.py[line:274] - INFO: epoch 001:   3372 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0442, wps=104.2, ups=0.48, wpb=109.5, bsz=40, num_updates=3370, lr=3.63695e-05, gnorm=0.757, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=11445
2023-01-08 02:01:51 - progress_bar.py[line:274] - INFO: epoch 001:   3382 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0688, wps=103, ups=0.47, wpb=110, bsz=40, num_updates=3380, lr=3.64774e-05, gnorm=0.751, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11466
2023-01-08 02:02:12 - progress_bar.py[line:274] - INFO: epoch 001:   3392 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0155, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=3390, lr=3.65854e-05, gnorm=0.756, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11488
2023-01-08 02:02:34 - progress_bar.py[line:274] - INFO: epoch 001:   3402 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0425, wps=100.7, ups=0.47, wpb=108.2, bsz=40, num_updates=3400, lr=3.66933e-05, gnorm=0.849, clip=30, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=11510
2023-01-08 02:02:55 - progress_bar.py[line:274] - INFO: epoch 001:   3412 / 115845 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0341, wps=101.7, ups=0.47, wpb=108.6, bsz=40, num_updates=3410, lr=3.68012e-05, gnorm=0.922, clip=40, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=11531
2023-01-08 02:03:17 - progress_bar.py[line:274] - INFO: epoch 001:   3422 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0291, wps=99.6, ups=0.46, wpb=108.4, bsz=40, num_updates=3420, lr=3.69091e-05, gnorm=0.835, clip=30, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11553
2023-01-08 02:03:39 - progress_bar.py[line:274] - INFO: epoch 001:   3432 / 115845 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0329, wps=102.7, ups=0.47, wpb=108.7, bsz=40, num_updates=3430, lr=3.70171e-05, gnorm=0.943, clip=40, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11575
2023-01-08 02:04:00 - progress_bar.py[line:274] - INFO: epoch 001:   3442 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0258, wps=103.8, ups=0.47, wpb=109.8, bsz=40, num_updates=3440, lr=3.7125e-05, gnorm=0.732, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=11596
2023-01-08 02:04:22 - progress_bar.py[line:274] - INFO: epoch 001:   3452 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0335, wps=99.7, ups=0.46, wpb=109.1, bsz=40, num_updates=3450, lr=3.72329e-05, gnorm=0.867, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11618
2023-01-08 02:04:44 - progress_bar.py[line:274] - INFO: epoch 001:   3462 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0529, wps=106, ups=0.48, wpb=111.1, bsz=40, num_updates=3460, lr=3.73408e-05, gnorm=0.654, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=11639
2023-01-08 02:05:05 - progress_bar.py[line:274] - INFO: epoch 001:   3472 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0248, wps=103, ups=0.47, wpb=109.8, bsz=40, num_updates=3470, lr=3.74487e-05, gnorm=0.75, clip=20, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11661
2023-01-08 02:05:27 - progress_bar.py[line:274] - INFO: epoch 001:   3482 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0484, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=3480, lr=3.75567e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11683
2023-01-08 02:05:48 - progress_bar.py[line:274] - INFO: epoch 001:   3492 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0492, wps=104.8, ups=0.48, wpb=108.9, bsz=40, num_updates=3490, lr=3.76646e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11704
2023-01-08 02:06:10 - progress_bar.py[line:274] - INFO: epoch 001:   3502 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0411, wps=99.9, ups=0.46, wpb=108.6, bsz=40, num_updates=3500, lr=3.77725e-05, gnorm=0.877, clip=30, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=11726
2023-01-08 02:06:31 - progress_bar.py[line:274] - INFO: epoch 001:   3512 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.032, wps=101.1, ups=0.47, wpb=107.7, bsz=40, num_updates=3510, lr=3.78804e-05, gnorm=0.878, clip=30, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=11747
2023-01-08 02:06:53 - progress_bar.py[line:274] - INFO: epoch 001:   3522 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0246, wps=99.8, ups=0.46, wpb=109.5, bsz=40, num_updates=3520, lr=3.79883e-05, gnorm=0.84, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11769
2023-01-08 02:07:15 - progress_bar.py[line:274] - INFO: epoch 001:   3532 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0333, wps=101.6, ups=0.47, wpb=108.1, bsz=40, num_updates=3530, lr=3.80963e-05, gnorm=0.853, clip=20, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11791
2023-01-08 02:07:37 - progress_bar.py[line:274] - INFO: epoch 001:   3542 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0271, wps=100.3, ups=0.46, wpb=108.3, bsz=40, num_updates=3540, lr=3.82042e-05, gnorm=0.807, clip=20, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11813
2023-01-08 02:07:59 - progress_bar.py[line:274] - INFO: epoch 001:   3552 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0265, wps=102, ups=0.46, wpb=110.8, bsz=40, num_updates=3550, lr=3.83121e-05, gnorm=0.741, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11834
2023-01-08 02:08:20 - progress_bar.py[line:274] - INFO: epoch 001:   3562 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0359, wps=102.7, ups=0.47, wpb=110, bsz=40, num_updates=3560, lr=3.842e-05, gnorm=0.794, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11856
2023-01-08 02:08:42 - progress_bar.py[line:274] - INFO: epoch 001:   3572 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0425, wps=99.7, ups=0.46, wpb=108.4, bsz=40, num_updates=3570, lr=3.8528e-05, gnorm=0.733, clip=10, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=11878
2023-01-08 02:09:04 - progress_bar.py[line:274] - INFO: epoch 001:   3582 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0294, wps=100.2, ups=0.46, wpb=108.3, bsz=40, num_updates=3580, lr=3.86359e-05, gnorm=0.911, clip=30, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11900
2023-01-08 02:09:26 - progress_bar.py[line:274] - INFO: epoch 001:   3592 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0526, wps=102.4, ups=0.47, wpb=109.4, bsz=40, num_updates=3590, lr=3.87438e-05, gnorm=0.859, clip=30, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11922
2023-01-08 02:09:48 - progress_bar.py[line:274] - INFO: epoch 001:   3602 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0347, wps=100.8, ups=0.46, wpb=109.1, bsz=40, num_updates=3600, lr=3.88517e-05, gnorm=0.813, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11944
2023-01-08 02:10:09 - progress_bar.py[line:274] - INFO: epoch 001:   3612 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.03, wps=103.5, ups=0.47, wpb=109.5, bsz=40, num_updates=3610, lr=3.89596e-05, gnorm=0.737, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=11965
2023-01-08 02:10:31 - progress_bar.py[line:274] - INFO: epoch 001:   3622 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0406, wps=100.5, ups=0.46, wpb=109.9, bsz=40, num_updates=3620, lr=3.90676e-05, gnorm=0.771, clip=10, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=11987
2023-01-08 02:10:53 - progress_bar.py[line:274] - INFO: epoch 001:   3632 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0498, wps=99, ups=0.46, wpb=107.7, bsz=40, num_updates=3630, lr=3.91755e-05, gnorm=0.745, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12009
2023-01-08 02:11:15 - progress_bar.py[line:274] - INFO: epoch 001:   3642 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0363, wps=100, ups=0.46, wpb=109.1, bsz=40, num_updates=3640, lr=3.92834e-05, gnorm=0.754, clip=10, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=12031
2023-01-08 02:11:37 - progress_bar.py[line:274] - INFO: epoch 001:   3652 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0471, wps=99.4, ups=0.46, wpb=108.1, bsz=40, num_updates=3650, lr=3.93913e-05, gnorm=0.713, clip=10, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=12053
2023-01-08 02:11:59 - progress_bar.py[line:274] - INFO: epoch 001:   3662 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0198, wps=101.3, ups=0.46, wpb=109.4, bsz=40, num_updates=3660, lr=3.94992e-05, gnorm=0.695, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12075
2023-01-08 02:12:21 - progress_bar.py[line:274] - INFO: epoch 001:   3672 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0493, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=3670, lr=3.96072e-05, gnorm=0.775, clip=20, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=12097
2023-01-08 02:12:42 - progress_bar.py[line:274] - INFO: epoch 001:   3682 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0205, wps=103.2, ups=0.47, wpb=110.3, bsz=40, num_updates=3680, lr=3.97151e-05, gnorm=0.809, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12118
2023-01-08 02:13:04 - progress_bar.py[line:274] - INFO: epoch 001:   3692 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0266, wps=103.6, ups=0.47, wpb=109.9, bsz=40, num_updates=3690, lr=3.9823e-05, gnorm=0.712, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=12140
2023-01-08 02:13:26 - progress_bar.py[line:274] - INFO: epoch 001:   3702 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.024, wps=102.2, ups=0.47, wpb=109.5, bsz=40, num_updates=3700, lr=3.99309e-05, gnorm=0.775, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12161
2023-01-08 02:13:47 - progress_bar.py[line:274] - INFO: epoch 001:   3712 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.02, wps=105.8, ups=0.48, wpb=110.1, bsz=40, num_updates=3710, lr=4.00389e-05, gnorm=0.721, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12182
2023-01-08 02:14:08 - progress_bar.py[line:274] - INFO: epoch 001:   3722 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0406, wps=102.6, ups=0.47, wpb=109.1, bsz=40, num_updates=3720, lr=4.01468e-05, gnorm=0.839, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12204
2023-01-08 02:14:30 - progress_bar.py[line:274] - INFO: epoch 001:   3732 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0366, wps=102.9, ups=0.47, wpb=110.5, bsz=40, num_updates=3730, lr=4.02547e-05, gnorm=0.636, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12226
2023-01-08 02:14:51 - progress_bar.py[line:274] - INFO: epoch 001:   3742 / 115845 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0495, wps=99.9, ups=0.47, wpb=107.3, bsz=40, num_updates=3740, lr=4.03626e-05, gnorm=0.794, clip=20, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=12247
2023-01-08 02:15:13 - progress_bar.py[line:274] - INFO: epoch 001:   3752 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0444, wps=100.9, ups=0.46, wpb=109, bsz=40, num_updates=3750, lr=4.04705e-05, gnorm=0.752, clip=20, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=12269
2023-01-08 02:15:35 - progress_bar.py[line:274] - INFO: epoch 001:   3762 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0471, wps=102.6, ups=0.47, wpb=109.9, bsz=40, num_updates=3760, lr=4.05785e-05, gnorm=0.734, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=12291
2023-01-08 02:15:56 - progress_bar.py[line:274] - INFO: epoch 001:   3772 / 115845 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0376, wps=101.4, ups=0.47, wpb=107.6, bsz=40, num_updates=3770, lr=4.06864e-05, gnorm=0.786, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12312
2023-01-08 02:16:19 - progress_bar.py[line:274] - INFO: epoch 001:   3782 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.043, wps=101, ups=0.46, wpb=110.7, bsz=40, num_updates=3780, lr=4.07943e-05, gnorm=0.624, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12334
2023-01-08 02:16:41 - progress_bar.py[line:274] - INFO: epoch 001:   3792 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0296, wps=99.2, ups=0.46, wpb=108.8, bsz=40, num_updates=3790, lr=4.09022e-05, gnorm=0.719, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12357
2023-01-08 02:17:03 - progress_bar.py[line:274] - INFO: epoch 001:   3802 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0249, wps=100.9, ups=0.46, wpb=109.1, bsz=40, num_updates=3800, lr=4.10101e-05, gnorm=0.771, clip=20, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=12378
2023-01-08 02:17:24 - progress_bar.py[line:274] - INFO: epoch 001:   3812 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0152, wps=100.2, ups=0.47, wpb=107.4, bsz=40, num_updates=3810, lr=4.11181e-05, gnorm=0.805, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12400
2023-01-08 02:17:46 - progress_bar.py[line:274] - INFO: epoch 001:   3822 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.037, wps=102.2, ups=0.46, wpb=110, bsz=40, num_updates=3820, lr=4.1226e-05, gnorm=0.574, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12422
2023-01-08 02:18:08 - progress_bar.py[line:274] - INFO: epoch 001:   3832 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=106.8, nsentences=40, sample_size=106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.04, wps=100.5, ups=0.47, wpb=106.8, bsz=40, num_updates=3830, lr=4.13339e-05, gnorm=0.783, clip=20, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=12443
2023-01-08 02:18:30 - progress_bar.py[line:274] - INFO: epoch 001:   3842 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0402, wps=99.7, ups=0.46, wpb=109.2, bsz=40, num_updates=3840, lr=4.14418e-05, gnorm=0.786, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=12466
2023-01-08 02:18:51 - progress_bar.py[line:274] - INFO: epoch 001:   3852 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0408, wps=101.8, ups=0.47, wpb=109.1, bsz=40, num_updates=3850, lr=4.15498e-05, gnorm=0.663, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=12487
2023-01-08 02:19:13 - progress_bar.py[line:274] - INFO: epoch 001:   3862 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0352, wps=101.5, ups=0.47, wpb=108.5, bsz=40, num_updates=3860, lr=4.16577e-05, gnorm=0.634, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12509
2023-01-08 02:19:35 - progress_bar.py[line:274] - INFO: epoch 001:   3872 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0427, wps=101.2, ups=0.47, wpb=108.2, bsz=40, num_updates=3870, lr=4.17656e-05, gnorm=0.643, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12530
2023-01-08 02:19:43 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-08 02:19:58 - progress_bar.py[line:274] - INFO: epoch 001:   3883 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0427, wps=99.3, ups=0.43, wpb=109, bsz=40, num_updates=3880, lr=4.18735e-05, gnorm=0.788, clip=30, loss_scale=1024, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=12554
2023-01-08 02:20:20 - progress_bar.py[line:274] - INFO: epoch 001:   3893 / 115845 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0393, wps=99.5, ups=0.46, wpb=107.1, bsz=40, num_updates=3890, lr=4.19814e-05, gnorm=0.837, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12576
2023-01-08 02:20:41 - progress_bar.py[line:274] - INFO: epoch 001:   3903 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0052, wps=102.1, ups=0.46, wpb=109.9, bsz=40, num_updates=3900, lr=4.20894e-05, gnorm=0.993, clip=40, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12597
2023-01-08 02:21:03 - progress_bar.py[line:274] - INFO: epoch 001:   3913 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0284, wps=101.7, ups=0.47, wpb=108.5, bsz=40, num_updates=3910, lr=4.21973e-05, gnorm=0.706, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12619
2023-01-08 02:21:25 - progress_bar.py[line:274] - INFO: epoch 001:   3923 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0203, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=3920, lr=4.23052e-05, gnorm=0.684, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12640
2023-01-08 02:21:46 - progress_bar.py[line:274] - INFO: epoch 001:   3933 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.02, wps=101.6, ups=0.47, wpb=108.4, bsz=40, num_updates=3930, lr=4.24131e-05, gnorm=0.779, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=12662
2023-01-08 02:22:08 - progress_bar.py[line:274] - INFO: epoch 001:   3943 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0383, wps=99.3, ups=0.46, wpb=108.7, bsz=40, num_updates=3940, lr=4.2521e-05, gnorm=0.757, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12684
2023-01-08 02:22:31 - progress_bar.py[line:274] - INFO: epoch 001:   3953 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.03, wps=100.6, ups=0.45, wpb=111.1, bsz=40, num_updates=3950, lr=4.2629e-05, gnorm=0.669, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12706
2023-01-08 02:22:52 - progress_bar.py[line:274] - INFO: epoch 001:   3963 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0406, wps=102.6, ups=0.46, wpb=110.7, bsz=40, num_updates=3960, lr=4.27369e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=12728
2023-01-08 02:23:14 - progress_bar.py[line:274] - INFO: epoch 001:   3973 / 115845 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0765, wps=101, ups=0.46, wpb=109, bsz=40, num_updates=3970, lr=4.28448e-05, gnorm=0.749, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12750
2023-01-08 02:23:36 - progress_bar.py[line:274] - INFO: epoch 001:   3983 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0311, wps=101.5, ups=0.46, wpb=109.4, bsz=40, num_updates=3980, lr=4.29527e-05, gnorm=0.618, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12772
2023-01-08 02:23:58 - progress_bar.py[line:274] - INFO: epoch 001:   3993 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0521, wps=102.2, ups=0.47, wpb=109.9, bsz=40, num_updates=3990, lr=4.30607e-05, gnorm=0.673, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12794
2023-01-08 02:24:20 - progress_bar.py[line:274] - INFO: epoch 001:   4003 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0591, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=4000, lr=4.31686e-05, gnorm=0.791, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12815
2023-01-08 02:24:20 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 02:24:21 - train.py[line:549] - INFO: 0 / 4988
2023-01-08 02:24:21 - train.py[line:551] - INFO: load:1.13 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 02:24:37 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 9.30 GiB already allocated; 5.56 GiB free; 31.54 GiB reserved in total by PyTorch)
2023-01-08 02:24:37 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 9         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9524 MB |   14755 MB |    1825 TB |    1825 TB |
|       from large pool |    9350 MB |   14580 MB |    1824 TB |    1824 TB |
|       from small pool |     174 MB |     175 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9524 MB |   14755 MB |    1825 TB |    1825 TB |
|       from large pool |    9350 MB |   14580 MB |    1824 TB |    1824 TB |
|       from small pool |     174 MB |     175 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32302 MB |   37950 MB |  156096 MB |  123794 MB |
|       from large pool |   32126 MB |   37772 MB |  155768 MB |  123642 MB |
|       from small pool |     176 MB |     178 MB |     328 MB |     152 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22777 MB |   27358 MB |    1680 TB |    1680 TB |
|       from large pool |   22775 MB |   27356 MB |    1679 TB |    1679 TB |
|       from small pool |       1 MB |       3 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4634    |    4648    |   84456 K  |   84452 K  |
|       from large pool |     698    |     710    |   26576 K  |   26575 K  |
|       from small pool |    3936    |    3946    |   57880 K  |   57876 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4634    |    4648    |   84456 K  |   84452 K  |
|       from large pool |     698    |     710    |   26576 K  |   26575 K  |
|       from small pool |    3936    |    3946    |   57880 K  |   57876 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     192    |     207    |     515    |     323    |
|       from large pool |     104    |     118    |     351    |     247    |
|       from small pool |      88    |      89    |     164    |      76    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     127    |     141    |   63063 K  |   63063 K  |
|       from large pool |      68    |      74    |   14677 K  |   14677 K  |
|       from small pool |      59    |      74    |   48385 K  |   48385 K  |
|===========================================================================|

2023-01-08 02:24:37 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-08 02:24:37 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-08 02:26:54 - train.py[line:549] - INFO: 200 / 4988
2023-01-08 02:26:54 - train.py[line:551] - INFO: load:1.15 valid_run:153.10 task_valid:148.05 collect_output:3.04
2023-01-08 02:29:23 - train.py[line:549] - INFO: 400 / 4988
2023-01-08 02:29:23 - train.py[line:551] - INFO: load:1.18 valid_run:301.94 task_valid:290.68 collect_output:8.24
2023-01-08 02:31:56 - train.py[line:549] - INFO: 600 / 4988
2023-01-08 02:31:56 - train.py[line:551] - INFO: load:1.20 valid_run:455.19 task_valid:433.26 collect_output:17.89
2023-01-08 02:34:25 - train.py[line:549] - INFO: 800 / 4988
2023-01-08 02:34:25 - train.py[line:551] - INFO: load:1.23 valid_run:604.07 task_valid:577.62 collect_output:21.42
2023-01-08 02:36:58 - train.py[line:549] - INFO: 1000 / 4988
2023-01-08 02:36:58 - train.py[line:551] - INFO: load:1.26 valid_run:756.38 task_valid:724.70 collect_output:25.64
2023-01-08 02:39:30 - train.py[line:549] - INFO: 1200 / 4988
2023-01-08 02:39:30 - train.py[line:551] - INFO: load:1.28 valid_run:908.20 task_valid:869.70 collect_output:31.46
2023-01-08 02:42:03 - train.py[line:549] - INFO: 1400 / 4988
2023-01-08 02:42:03 - train.py[line:551] - INFO: load:1.31 valid_run:1061.86 task_valid:1015.05 collect_output:38.76
2023-01-08 02:44:35 - train.py[line:549] - INFO: 1600 / 4988
2023-01-08 02:44:35 - train.py[line:551] - INFO: load:1.33 valid_run:1213.42 task_valid:1155.63 collect_output:48.73
2023-01-08 02:47:05 - train.py[line:549] - INFO: 1800 / 4988
2023-01-08 02:47:05 - train.py[line:551] - INFO: load:1.36 valid_run:1363.07 task_valid:1299.91 collect_output:53.08
2023-01-08 02:49:33 - train.py[line:549] - INFO: 2000 / 4988
2023-01-08 02:49:33 - train.py[line:551] - INFO: load:1.39 valid_run:1511.79 task_valid:1442.46 collect_output:58.22
2023-01-08 02:52:03 - train.py[line:549] - INFO: 2200 / 4988
2023-01-08 02:52:03 - train.py[line:551] - INFO: load:1.42 valid_run:1661.35 task_valid:1586.73 collect_output:62.51
2023-01-08 02:54:33 - train.py[line:549] - INFO: 2400 / 4988
2023-01-08 02:54:33 - train.py[line:551] - INFO: load:1.44 valid_run:1811.33 task_valid:1731.22 collect_output:66.96
2023-01-08 02:57:03 - train.py[line:549] - INFO: 2600 / 4988
2023-01-08 02:57:03 - train.py[line:551] - INFO: load:1.47 valid_run:1961.58 task_valid:1872.58 collect_output:74.84
2023-01-08 02:59:34 - train.py[line:549] - INFO: 2800 / 4988
2023-01-08 02:59:34 - train.py[line:551] - INFO: load:1.50 valid_run:2112.10 task_valid:2017.47 collect_output:79.47
2023-01-08 03:02:04 - train.py[line:549] - INFO: 3000 / 4988
2023-01-08 03:02:04 - train.py[line:551] - INFO: load:1.53 valid_run:2261.98 task_valid:2163.36 collect_output:82.44
2023-01-08 03:04:34 - train.py[line:549] - INFO: 3200 / 4988
2023-01-08 03:04:34 - train.py[line:551] - INFO: load:1.55 valid_run:2411.96 task_valid:2306.90 collect_output:87.88
2023-01-08 03:07:06 - train.py[line:549] - INFO: 3400 / 4988
2023-01-08 03:07:06 - train.py[line:551] - INFO: load:1.58 valid_run:2563.89 task_valid:2452.12 collect_output:93.59
2023-01-08 03:09:37 - train.py[line:549] - INFO: 3600 / 4988
2023-01-08 03:09:37 - train.py[line:551] - INFO: load:1.61 valid_run:2714.34 task_valid:2598.42 collect_output:96.74
2023-01-08 03:12:05 - train.py[line:549] - INFO: 3800 / 4988
2023-01-08 03:12:05 - train.py[line:551] - INFO: load:1.63 valid_run:2862.98 task_valid:2739.44 collect_output:103.35
2023-01-08 03:14:36 - train.py[line:549] - INFO: 4000 / 4988
2023-01-08 03:14:36 - train.py[line:551] - INFO: load:1.66 valid_run:3013.20 task_valid:2884.04 collect_output:107.95
2023-01-08 03:17:08 - train.py[line:549] - INFO: 4200 / 4988
2023-01-08 03:17:08 - train.py[line:551] - INFO: load:1.69 valid_run:3165.43 task_valid:3028.36 collect_output:114.83
2023-01-08 03:19:38 - train.py[line:549] - INFO: 4400 / 4988
2023-01-08 03:19:38 - train.py[line:551] - INFO: load:1.71 valid_run:3315.00 task_valid:3172.49 collect_output:119.23
2023-01-08 03:22:09 - train.py[line:549] - INFO: 4600 / 4988
2023-01-08 03:22:09 - train.py[line:551] - INFO: load:1.74 valid_run:3466.19 task_valid:3318.30 collect_output:123.58
2023-01-08 03:24:40 - train.py[line:549] - INFO: 4800 / 4988
2023-01-08 03:24:40 - train.py[line:551] - INFO: load:1.76 valid_run:3617.53 task_valid:3464.38 collect_output:127.78

====================================================================================================
SGG eval:     R @ 50: 0.5204;     R @ 100: 0.5663;     R @ 500: 0.6116;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3037;    mR @ 100: 0.3733;    mR @ 500: 0.4189;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5439) (covered in:0.1875) (covering:0.5714) (eating:0.7647) (flying in:0.6364) (growing on:0.5000) (hanging from:0.4677) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6667) (playing:0.0000) (riding:0.7663) (says:0.0000) (sitting on:0.6837) (standing on:0.3950) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================

2023-01-08 03:27:11 - train.py[line:487] - INFO: 0.566274025974026
2023-01-08 03:27:11 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.5204;     R @ 100: 0.5663;     R @ 500: 0.6116;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3037;    mR @ 100: 0.3733;    mR @ 500: 0.4189;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5439) (covered in:0.1875) (covering:0.5714) (eating:0.7647) (flying in:0.6364) (growing on:0.5000) (hanging from:0.4677) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6667) (playing:0.0000) (riding:0.7663) (says:0.0000) (sitting on:0.6837) (standing on:0.3950) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================

2023-01-08 03:27:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.353 | loss_v1 0 | loss_v2 0 | nll_loss 0.205 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.566274 | ppl 1.15 | vqa_score 0.3322 | wps 119 | wpb 89.9 | bsz 30 | num_updates 4000 | best_R@100 0.566274
2023-01-08 03:27:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2023-01-08 03:27:11 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_4000.pt
2023-01-08 03:27:54 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_4000.pt
2023-01-08 03:30:53 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.566274025974026) (writing took 221.75469040311873 seconds)
2023-01-08 03:31:16 - progress_bar.py[line:274] - INFO: epoch 001:   4013 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0327, wps=0.5, ups=0, wpb=109.1, bsz=40, num_updates=4010, lr=4.32765e-05, gnorm=0.667, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=16831
2023-01-08 03:31:37 - progress_bar.py[line:274] - INFO: epoch 001:   4023 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0202, wps=103.7, ups=0.47, wpb=109.8, bsz=40, num_updates=4020, lr=4.33844e-05, gnorm=0.832, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=16853
2023-01-08 03:31:59 - progress_bar.py[line:274] - INFO: epoch 001:   4033 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0524, wps=103, ups=0.48, wpb=108.2, bsz=40, num_updates=4030, lr=4.34923e-05, gnorm=0.668, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=16874
2023-01-08 03:32:21 - progress_bar.py[line:274] - INFO: epoch 001:   4043 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0478, wps=98.8, ups=0.45, wpb=108.9, bsz=40, num_updates=4040, lr=4.36003e-05, gnorm=0.591, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=16897
2023-01-08 03:32:44 - progress_bar.py[line:274] - INFO: epoch 001:   4053 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0398, wps=100.9, ups=0.46, wpb=109.1, bsz=40, num_updates=4050, lr=4.37082e-05, gnorm=0.774, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=16919
2023-01-08 03:33:06 - progress_bar.py[line:274] - INFO: epoch 001:   4063 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0427, wps=99.1, ups=0.46, wpb=108.2, bsz=40, num_updates=4060, lr=4.38161e-05, gnorm=0.701, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=16941
2023-01-08 03:33:28 - progress_bar.py[line:274] - INFO: epoch 001:   4073 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0314, wps=101.4, ups=0.46, wpb=110.6, bsz=40, num_updates=4070, lr=4.3924e-05, gnorm=0.751, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=16964
2023-01-08 03:33:51 - progress_bar.py[line:274] - INFO: epoch 001:   4083 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0657, wps=99.9, ups=0.46, wpb=109, bsz=40, num_updates=4080, lr=4.40319e-05, gnorm=0.821, clip=30, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=16986
2023-01-08 03:34:13 - progress_bar.py[line:274] - INFO: epoch 001:   4093 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0366, wps=99.9, ups=0.46, wpb=109.4, bsz=40, num_updates=4090, lr=4.41399e-05, gnorm=0.687, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17008
2023-01-08 03:34:34 - progress_bar.py[line:274] - INFO: epoch 001:   4103 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0428, wps=103.5, ups=0.47, wpb=109.1, bsz=40, num_updates=4100, lr=4.42478e-05, gnorm=0.682, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17030
2023-01-08 03:34:56 - progress_bar.py[line:274] - INFO: epoch 001:   4113 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0281, wps=103.2, ups=0.47, wpb=110.1, bsz=40, num_updates=4110, lr=4.43557e-05, gnorm=0.745, clip=20, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17052
2023-01-08 03:35:19 - progress_bar.py[line:274] - INFO: epoch 001:   4123 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0607, wps=98.7, ups=0.46, wpb=107.8, bsz=40, num_updates=4120, lr=4.44636e-05, gnorm=0.671, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17074
2023-01-08 03:35:41 - progress_bar.py[line:274] - INFO: epoch 001:   4133 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0398, wps=102.3, ups=0.47, wpb=109.5, bsz=40, num_updates=4130, lr=4.45716e-05, gnorm=0.711, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=17096
2023-01-08 03:36:03 - progress_bar.py[line:274] - INFO: epoch 001:   4143 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0472, wps=101.4, ups=0.46, wpb=109.6, bsz=40, num_updates=4140, lr=4.46795e-05, gnorm=0.769, clip=0, loss_scale=1024, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=17118
2023-01-08 03:36:25 - progress_bar.py[line:274] - INFO: epoch 001:   4153 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0542, wps=99.5, ups=0.45, wpb=109.4, bsz=40, num_updates=4150, lr=4.47874e-05, gnorm=0.715, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17141
2023-01-08 03:36:47 - progress_bar.py[line:274] - INFO: epoch 001:   4163 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.028, wps=100.8, ups=0.47, wpb=107.8, bsz=40, num_updates=4160, lr=4.48953e-05, gnorm=0.727, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17163
2023-01-08 03:37:09 - progress_bar.py[line:274] - INFO: epoch 001:   4173 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0101, wps=104.7, ups=0.48, wpb=109.9, bsz=40, num_updates=4170, lr=4.50032e-05, gnorm=0.737, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=17184
2023-01-08 03:37:31 - progress_bar.py[line:274] - INFO: epoch 001:   4183 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0316, wps=100.6, ups=0.46, wpb=109.3, bsz=40, num_updates=4180, lr=4.51112e-05, gnorm=0.729, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17207
2023-01-08 03:37:53 - progress_bar.py[line:274] - INFO: epoch 001:   4193 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0582, wps=101.5, ups=0.47, wpb=108.7, bsz=40, num_updates=4190, lr=4.52191e-05, gnorm=0.689, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17229
2023-01-08 03:38:15 - progress_bar.py[line:274] - INFO: epoch 001:   4203 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0553, wps=102.7, ups=0.47, wpb=108.7, bsz=40, num_updates=4200, lr=4.5327e-05, gnorm=0.669, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17250
2023-01-08 03:38:37 - progress_bar.py[line:274] - INFO: epoch 001:   4213 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0634, wps=100.8, ups=0.47, wpb=108.3, bsz=40, num_updates=4210, lr=4.54349e-05, gnorm=0.657, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17272
2023-01-08 03:38:59 - progress_bar.py[line:274] - INFO: epoch 001:   4223 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0657, wps=100, ups=0.46, wpb=108, bsz=40, num_updates=4220, lr=4.55428e-05, gnorm=0.653, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17294
2023-01-08 03:39:20 - progress_bar.py[line:274] - INFO: epoch 001:   4233 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.05, wps=103.6, ups=0.48, wpb=109, bsz=40, num_updates=4230, lr=4.56508e-05, gnorm=0.782, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17316
2023-01-08 03:39:42 - progress_bar.py[line:274] - INFO: epoch 001:   4243 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0386, wps=100.8, ups=0.47, wpb=107.8, bsz=40, num_updates=4240, lr=4.57587e-05, gnorm=0.778, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17338
2023-01-08 03:40:03 - progress_bar.py[line:274] - INFO: epoch 001:   4253 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0628, wps=103.4, ups=0.47, wpb=109.3, bsz=40, num_updates=4250, lr=4.58666e-05, gnorm=0.705, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17359
2023-01-08 03:40:25 - progress_bar.py[line:274] - INFO: epoch 001:   4263 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0613, wps=100.8, ups=0.47, wpb=108.1, bsz=40, num_updates=4260, lr=4.59745e-05, gnorm=0.756, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17381
2023-01-08 03:40:46 - progress_bar.py[line:274] - INFO: epoch 001:   4273 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0283, wps=100.8, ups=0.47, wpb=107.8, bsz=40, num_updates=4270, lr=4.60825e-05, gnorm=0.764, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17402
2023-01-08 03:41:08 - progress_bar.py[line:274] - INFO: epoch 001:   4283 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0558, wps=102.5, ups=0.47, wpb=109.7, bsz=40, num_updates=4280, lr=4.61904e-05, gnorm=0.653, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17424
2023-01-08 03:41:30 - progress_bar.py[line:274] - INFO: epoch 001:   4293 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0673, wps=101.1, ups=0.46, wpb=108.7, bsz=40, num_updates=4290, lr=4.62983e-05, gnorm=0.746, clip=10, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=17446
2023-01-08 03:41:52 - progress_bar.py[line:274] - INFO: epoch 001:   4303 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0437, wps=99.9, ups=0.46, wpb=108.4, bsz=40, num_updates=4300, lr=4.64062e-05, gnorm=0.619, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=17468
2023-01-08 03:42:14 - progress_bar.py[line:274] - INFO: epoch 001:   4313 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0532, wps=102, ups=0.46, wpb=110.3, bsz=40, num_updates=4310, lr=4.65141e-05, gnorm=0.737, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17489
2023-01-08 03:42:35 - progress_bar.py[line:274] - INFO: epoch 001:   4323 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0503, wps=100.7, ups=0.46, wpb=108.4, bsz=40, num_updates=4320, lr=4.66221e-05, gnorm=0.716, clip=10, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=17511
2023-01-08 03:42:57 - progress_bar.py[line:274] - INFO: epoch 001:   4333 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0317, wps=101.5, ups=0.46, wpb=109.6, bsz=40, num_updates=4330, lr=4.673e-05, gnorm=0.619, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17533
2023-01-08 03:43:19 - progress_bar.py[line:274] - INFO: epoch 001:   4343 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0493, wps=99.3, ups=0.46, wpb=108.1, bsz=40, num_updates=4340, lr=4.68379e-05, gnorm=0.834, clip=20, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=17555
2023-01-08 03:43:41 - progress_bar.py[line:274] - INFO: epoch 001:   4353 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0359, wps=101.2, ups=0.46, wpb=110.3, bsz=40, num_updates=4350, lr=4.69458e-05, gnorm=0.818, clip=20, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=17577
2023-01-08 03:44:03 - progress_bar.py[line:274] - INFO: epoch 001:   4363 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0348, wps=101.9, ups=0.47, wpb=108.7, bsz=40, num_updates=4360, lr=4.70537e-05, gnorm=0.657, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=17599
2023-01-08 03:44:24 - progress_bar.py[line:274] - INFO: epoch 001:   4373 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0421, wps=104.6, ups=0.48, wpb=109.3, bsz=40, num_updates=4370, lr=4.71617e-05, gnorm=0.68, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17620
2023-01-08 03:44:45 - progress_bar.py[line:274] - INFO: epoch 001:   4383 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.039, wps=106.3, ups=0.49, wpb=109.5, bsz=40, num_updates=4380, lr=4.72696e-05, gnorm=0.678, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=17641
2023-01-08 03:45:06 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-08 03:45:08 - progress_bar.py[line:274] - INFO: epoch 001:   4394 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.048, nsentences=40, sample_size=110.048, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0099, wps=99.7, ups=0.43, wpb=110, bsz=40, num_updates=4390, lr=4.73775e-05, gnorm=0.64, clip=0, loss_scale=1024, train_wall=23, gb_free=10.1, ema_decay=0.9999, wall=17664
2023-01-08 03:45:30 - progress_bar.py[line:274] - INFO: epoch 001:   4404 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0628, wps=99.5, ups=0.46, wpb=107.5, bsz=40, num_updates=4400, lr=4.74854e-05, gnorm=0.663, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=17686
2023-01-08 03:45:52 - progress_bar.py[line:274] - INFO: epoch 001:   4414 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0341, wps=99.4, ups=0.46, wpb=108.1, bsz=40, num_updates=4410, lr=4.75934e-05, gnorm=0.659, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17708
2023-01-08 03:46:14 - progress_bar.py[line:274] - INFO: epoch 001:   4424 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0394, wps=100.6, ups=0.47, wpb=108.1, bsz=40, num_updates=4420, lr=4.77013e-05, gnorm=0.602, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=17730
2023-01-08 03:46:36 - progress_bar.py[line:274] - INFO: epoch 001:   4434 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0485, wps=99.9, ups=0.46, wpb=108.3, bsz=40, num_updates=4430, lr=4.78092e-05, gnorm=0.801, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17752
2023-01-08 03:46:58 - progress_bar.py[line:274] - INFO: epoch 001:   4444 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0263, wps=100.3, ups=0.46, wpb=108.5, bsz=40, num_updates=4440, lr=4.79171e-05, gnorm=0.802, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17773
2023-01-08 03:47:20 - progress_bar.py[line:274] - INFO: epoch 001:   4454 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0211, wps=99, ups=0.45, wpb=109.6, bsz=40, num_updates=4450, lr=4.8025e-05, gnorm=0.785, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17796
2023-01-08 03:47:42 - progress_bar.py[line:274] - INFO: epoch 001:   4464 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0524, wps=99.5, ups=0.46, wpb=108.6, bsz=40, num_updates=4460, lr=4.8133e-05, gnorm=0.664, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=17818
2023-01-08 03:48:04 - progress_bar.py[line:274] - INFO: epoch 001:   4474 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0469, wps=100.4, ups=0.46, wpb=108.5, bsz=40, num_updates=4470, lr=4.82409e-05, gnorm=0.644, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17840
2023-01-08 03:48:25 - progress_bar.py[line:274] - INFO: epoch 001:   4484 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0603, wps=102, ups=0.47, wpb=108.8, bsz=40, num_updates=4480, lr=4.83488e-05, gnorm=0.628, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17861
2023-01-08 03:48:47 - progress_bar.py[line:274] - INFO: epoch 001:   4494 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.068, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=4490, lr=4.84567e-05, gnorm=0.622, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17883
2023-01-08 03:49:09 - progress_bar.py[line:274] - INFO: epoch 001:   4504 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0365, wps=103.1, ups=0.47, wpb=109, bsz=40, num_updates=4500, lr=4.85646e-05, gnorm=0.667, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17904
2023-01-08 03:49:30 - progress_bar.py[line:274] - INFO: epoch 001:   4514 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.058, wps=99.8, ups=0.46, wpb=107.8, bsz=40, num_updates=4510, lr=4.86726e-05, gnorm=0.701, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=17926
2023-01-08 03:49:52 - progress_bar.py[line:274] - INFO: epoch 001:   4524 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0398, wps=101.1, ups=0.47, wpb=108.1, bsz=40, num_updates=4520, lr=4.87805e-05, gnorm=0.598, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17948
2023-01-08 03:50:14 - progress_bar.py[line:274] - INFO: epoch 001:   4534 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0542, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=4530, lr=4.88884e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17970
2023-01-08 03:50:35 - progress_bar.py[line:274] - INFO: epoch 001:   4544 / 115845 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0288, wps=102, ups=0.47, wpb=107.8, bsz=40, num_updates=4540, lr=4.89963e-05, gnorm=0.654, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17991
2023-01-08 03:50:57 - progress_bar.py[line:274] - INFO: epoch 001:   4554 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0204, wps=99.2, ups=0.46, wpb=108.2, bsz=40, num_updates=4550, lr=4.91043e-05, gnorm=0.684, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=18013
2023-01-08 03:51:19 - progress_bar.py[line:274] - INFO: epoch 001:   4564 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0574, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=4560, lr=4.92122e-05, gnorm=0.675, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=18035
2023-01-08 03:51:41 - progress_bar.py[line:274] - INFO: epoch 001:   4574 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0459, wps=100.3, ups=0.46, wpb=109.1, bsz=40, num_updates=4570, lr=4.93201e-05, gnorm=0.705, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18057
2023-01-08 03:52:03 - progress_bar.py[line:274] - INFO: epoch 001:   4584 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.045, wps=102.6, ups=0.46, wpb=110.6, bsz=40, num_updates=4580, lr=4.9428e-05, gnorm=0.678, clip=30, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=18079
2023-01-08 03:52:24 - progress_bar.py[line:274] - INFO: epoch 001:   4594 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0437, wps=101.5, ups=0.47, wpb=108.9, bsz=40, num_updates=4590, lr=4.95359e-05, gnorm=0.639, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18100
2023-01-08 03:52:46 - progress_bar.py[line:274] - INFO: epoch 001:   4604 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0341, wps=100.7, ups=0.46, wpb=108.8, bsz=40, num_updates=4600, lr=4.96439e-05, gnorm=0.564, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18122
2023-01-08 03:53:08 - progress_bar.py[line:274] - INFO: epoch 001:   4614 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0591, wps=100.5, ups=0.47, wpb=107.1, bsz=40, num_updates=4610, lr=4.97518e-05, gnorm=0.619, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18144
2023-01-08 03:53:29 - progress_bar.py[line:274] - INFO: epoch 001:   4624 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0431, wps=102.6, ups=0.47, wpb=108.1, bsz=40, num_updates=4620, lr=4.98597e-05, gnorm=0.649, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18165
2023-01-08 03:53:51 - progress_bar.py[line:274] - INFO: epoch 001:   4634 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.025, wps=102.9, ups=0.47, wpb=109.7, bsz=40, num_updates=4630, lr=4.99676e-05, gnorm=0.583, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=18186
2023-01-08 03:54:12 - progress_bar.py[line:274] - INFO: epoch 001:   4644 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0583, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=4640, lr=4.99969e-05, gnorm=0.578, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18208
2023-01-08 03:54:34 - progress_bar.py[line:274] - INFO: epoch 001:   4654 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0615, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=4650, lr=4.99924e-05, gnorm=0.593, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=18230
2023-01-08 03:54:56 - progress_bar.py[line:274] - INFO: epoch 001:   4664 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0354, wps=103.4, ups=0.47, wpb=109.5, bsz=40, num_updates=4660, lr=4.99879e-05, gnorm=0.673, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18251
2023-01-08 03:55:17 - progress_bar.py[line:274] - INFO: epoch 001:   4674 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0686, wps=102.6, ups=0.47, wpb=109.6, bsz=40, num_updates=4670, lr=4.99834e-05, gnorm=0.586, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18273
2023-01-08 03:55:39 - progress_bar.py[line:274] - INFO: epoch 001:   4684 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0509, wps=101, ups=0.47, wpb=107.9, bsz=40, num_updates=4680, lr=4.99789e-05, gnorm=0.604, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18295
2023-01-08 03:56:01 - progress_bar.py[line:274] - INFO: epoch 001:   4694 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0308, wps=101.7, ups=0.46, wpb=109.9, bsz=40, num_updates=4690, lr=4.99744e-05, gnorm=0.705, clip=10, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=18316
2023-01-08 03:56:22 - progress_bar.py[line:274] - INFO: epoch 001:   4704 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0323, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=4700, lr=4.99699e-05, gnorm=0.648, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=18338
2023-01-08 03:56:44 - progress_bar.py[line:274] - INFO: epoch 001:   4714 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0753, wps=102, ups=0.46, wpb=110.2, bsz=40, num_updates=4710, lr=4.99654e-05, gnorm=0.624, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18360
2023-01-08 03:57:06 - progress_bar.py[line:274] - INFO: epoch 001:   4724 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0588, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=4720, lr=4.99609e-05, gnorm=0.594, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=18382
2023-01-08 03:57:27 - progress_bar.py[line:274] - INFO: epoch 001:   4734 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0611, wps=102.2, ups=0.47, wpb=108.2, bsz=40, num_updates=4730, lr=4.99564e-05, gnorm=0.715, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=18403
2023-01-08 03:57:49 - progress_bar.py[line:274] - INFO: epoch 001:   4744 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0526, wps=99.5, ups=0.46, wpb=107.7, bsz=40, num_updates=4740, lr=4.99519e-05, gnorm=0.734, clip=10, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=18425
2023-01-08 03:58:11 - progress_bar.py[line:274] - INFO: epoch 001:   4754 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0448, wps=101.1, ups=0.46, wpb=110.3, bsz=40, num_updates=4750, lr=4.99474e-05, gnorm=0.67, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18447
2023-01-08 03:58:33 - progress_bar.py[line:274] - INFO: epoch 001:   4764 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0635, wps=104.3, ups=0.47, wpb=110.3, bsz=40, num_updates=4760, lr=4.99429e-05, gnorm=0.589, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=18468
2023-01-08 03:58:54 - progress_bar.py[line:274] - INFO: epoch 001:   4774 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0649, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=4770, lr=4.99384e-05, gnorm=0.561, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=18490
2023-01-08 03:59:16 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 03:59:18 - progress_bar.py[line:274] - INFO: epoch 001:   4785 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=107.619, nsentences=40, sample_size=107.619, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0524, wps=96.8, ups=0.43, wpb=107.6, bsz=40, num_updates=4780, lr=4.99339e-05, gnorm=0.572, clip=0, loss_scale=512, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=18514
2023-01-08 03:59:40 - progress_bar.py[line:274] - INFO: epoch 001:   4795 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0271, wps=98.1, ups=0.46, wpb=107.6, bsz=40, num_updates=4790, lr=4.99294e-05, gnorm=0.565, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18536
2023-01-08 04:00:02 - progress_bar.py[line:274] - INFO: epoch 001:   4805 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.086, wps=101, ups=0.46, wpb=110.4, bsz=40, num_updates=4800, lr=4.99249e-05, gnorm=0.59, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18558
2023-01-08 04:00:24 - progress_bar.py[line:274] - INFO: epoch 001:   4815 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.081, wps=100.3, ups=0.46, wpb=109.4, bsz=40, num_updates=4810, lr=4.99204e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18580
2023-01-08 04:00:46 - progress_bar.py[line:274] - INFO: epoch 001:   4825 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0542, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=4820, lr=4.99159e-05, gnorm=0.708, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18602
2023-01-08 04:01:08 - progress_bar.py[line:274] - INFO: epoch 001:   4835 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0697, wps=100.6, ups=0.46, wpb=109.9, bsz=40, num_updates=4830, lr=4.99114e-05, gnorm=0.582, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18624
2023-01-08 04:01:29 - progress_bar.py[line:274] - INFO: epoch 001:   4845 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0674, wps=102.3, ups=0.47, wpb=108.3, bsz=40, num_updates=4840, lr=4.99069e-05, gnorm=0.702, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18645
2023-01-08 04:01:51 - progress_bar.py[line:274] - INFO: epoch 001:   4855 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0563, wps=98.9, ups=0.46, wpb=107.5, bsz=40, num_updates=4850, lr=4.99024e-05, gnorm=0.644, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18667
2023-01-08 04:02:14 - progress_bar.py[line:274] - INFO: epoch 001:   4865 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0777, wps=98.5, ups=0.45, wpb=108.3, bsz=40, num_updates=4860, lr=4.98979e-05, gnorm=0.684, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18689
2023-01-08 04:02:35 - progress_bar.py[line:274] - INFO: epoch 001:   4875 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0599, wps=99.8, ups=0.46, wpb=107.6, bsz=40, num_updates=4870, lr=4.98934e-05, gnorm=0.675, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=18711
2023-01-08 04:02:57 - progress_bar.py[line:274] - INFO: epoch 001:   4885 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.06, wps=104.5, ups=0.48, wpb=109.5, bsz=40, num_updates=4880, lr=4.9889e-05, gnorm=0.557, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=18732
2023-01-08 04:03:18 - progress_bar.py[line:274] - INFO: epoch 001:   4895 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.08, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=4890, lr=4.98845e-05, gnorm=0.62, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18754
2023-01-08 04:03:40 - progress_bar.py[line:274] - INFO: epoch 001:   4905 / 115845 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0615, wps=100.2, ups=0.46, wpb=109.6, bsz=40, num_updates=4900, lr=4.988e-05, gnorm=0.516, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=18776
2023-01-08 04:04:02 - progress_bar.py[line:274] - INFO: epoch 001:   4915 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0431, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=4910, lr=4.98755e-05, gnorm=0.721, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18798
2023-01-08 04:04:23 - progress_bar.py[line:274] - INFO: epoch 001:   4925 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0493, wps=104.5, ups=0.48, wpb=109.4, bsz=40, num_updates=4920, lr=4.9871e-05, gnorm=0.752, clip=30, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=18819
2023-01-08 04:04:45 - progress_bar.py[line:274] - INFO: epoch 001:   4935 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0881, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=4930, lr=4.98665e-05, gnorm=0.5, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18841
2023-01-08 04:05:07 - progress_bar.py[line:274] - INFO: epoch 001:   4945 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0707, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=4940, lr=4.9862e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18863
2023-01-08 04:05:30 - progress_bar.py[line:274] - INFO: epoch 001:   4955 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0426, wps=96.4, ups=0.44, wpb=108.9, bsz=40, num_updates=4950, lr=4.98575e-05, gnorm=0.682, clip=0, loss_scale=512, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=18885
2023-01-08 04:05:52 - progress_bar.py[line:274] - INFO: epoch 001:   4965 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0676, wps=99.3, ups=0.46, wpb=108.5, bsz=40, num_updates=4960, lr=4.9853e-05, gnorm=0.632, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=18908
2023-01-08 04:06:13 - progress_bar.py[line:274] - INFO: epoch 001:   4975 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0591, wps=103.5, ups=0.48, wpb=108.7, bsz=40, num_updates=4970, lr=4.98485e-05, gnorm=0.683, clip=10, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=18929
2023-01-08 04:06:35 - progress_bar.py[line:274] - INFO: epoch 001:   4985 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0704, wps=100, ups=0.46, wpb=108.2, bsz=40, num_updates=4980, lr=4.9844e-05, gnorm=0.631, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=18951
2023-01-08 04:06:57 - progress_bar.py[line:274] - INFO: epoch 001:   4995 / 115845 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0639, wps=100.4, ups=0.47, wpb=107.7, bsz=40, num_updates=4990, lr=4.98395e-05, gnorm=0.602, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18972
2023-01-08 04:07:18 - progress_bar.py[line:274] - INFO: epoch 001:   5005 / 115845 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0628, wps=101.3, ups=0.47, wpb=107.3, bsz=40, num_updates=5000, lr=4.9835e-05, gnorm=0.605, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18994
2023-01-08 04:07:40 - progress_bar.py[line:274] - INFO: epoch 001:   5015 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0542, wps=100, ups=0.46, wpb=108.5, bsz=40, num_updates=5010, lr=4.98305e-05, gnorm=0.554, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19016
2023-01-08 04:08:02 - progress_bar.py[line:274] - INFO: epoch 001:   5025 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0628, wps=99.7, ups=0.46, wpb=108.6, bsz=40, num_updates=5020, lr=4.9826e-05, gnorm=0.617, clip=0, loss_scale=512, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=19038
2023-01-08 04:08:23 - progress_bar.py[line:274] - INFO: epoch 001:   5035 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0419, wps=104.1, ups=0.48, wpb=108.9, bsz=40, num_updates=5030, lr=4.98215e-05, gnorm=0.599, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=19059
2023-01-08 04:08:44 - progress_bar.py[line:274] - INFO: epoch 001:   5045 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.05, wps=103.4, ups=0.47, wpb=109.6, bsz=40, num_updates=5040, lr=4.9817e-05, gnorm=0.575, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19080
2023-01-08 04:09:06 - progress_bar.py[line:274] - INFO: epoch 001:   5055 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0471, wps=104.3, ups=0.47, wpb=110.6, bsz=40, num_updates=5050, lr=4.98125e-05, gnorm=0.499, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19102
2023-01-08 04:09:28 - progress_bar.py[line:274] - INFO: epoch 001:   5065 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0558, wps=100.7, ups=0.46, wpb=109.4, bsz=40, num_updates=5060, lr=4.9808e-05, gnorm=0.595, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=19124
2023-01-08 04:09:50 - progress_bar.py[line:274] - INFO: epoch 001:   5075 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0657, wps=98.8, ups=0.45, wpb=108.9, bsz=40, num_updates=5070, lr=4.98035e-05, gnorm=0.601, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19146
2023-01-08 04:10:12 - progress_bar.py[line:274] - INFO: epoch 001:   5085 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0691, wps=100.7, ups=0.46, wpb=109.3, bsz=40, num_updates=5080, lr=4.9799e-05, gnorm=0.586, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19168
2023-01-08 04:10:34 - progress_bar.py[line:274] - INFO: epoch 001:   5095 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0813, wps=98.3, ups=0.45, wpb=108.2, bsz=40, num_updates=5090, lr=4.97945e-05, gnorm=0.597, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19190
2023-01-08 04:10:56 - progress_bar.py[line:274] - INFO: epoch 001:   5105 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0628, wps=99.4, ups=0.46, wpb=109.2, bsz=40, num_updates=5100, lr=4.979e-05, gnorm=0.566, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19212
2023-01-08 04:11:18 - progress_bar.py[line:274] - INFO: epoch 001:   5115 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0735, wps=103.3, ups=0.47, wpb=110.2, bsz=40, num_updates=5110, lr=4.97855e-05, gnorm=0.613, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=19234
2023-01-08 04:11:40 - progress_bar.py[line:274] - INFO: epoch 001:   5125 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0553, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=5120, lr=4.9781e-05, gnorm=0.604, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19256
2023-01-08 04:12:02 - progress_bar.py[line:274] - INFO: epoch 001:   5135 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0537, wps=100.6, ups=0.46, wpb=108.5, bsz=40, num_updates=5130, lr=4.97766e-05, gnorm=0.69, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19277
2023-01-08 04:12:24 - progress_bar.py[line:274] - INFO: epoch 001:   5145 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0567, wps=102.6, ups=0.46, wpb=111.6, bsz=40, num_updates=5140, lr=4.97721e-05, gnorm=0.589, clip=0, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=19299
2023-01-08 04:12:45 - progress_bar.py[line:274] - INFO: epoch 001:   5155 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0657, wps=103.4, ups=0.48, wpb=108.6, bsz=40, num_updates=5150, lr=4.97676e-05, gnorm=0.744, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19321
2023-01-08 04:13:07 - progress_bar.py[line:274] - INFO: epoch 001:   5165 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0781, wps=99.4, ups=0.46, wpb=108, bsz=40, num_updates=5160, lr=4.97631e-05, gnorm=0.584, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19343
2023-01-08 04:13:28 - progress_bar.py[line:274] - INFO: epoch 001:   5175 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0718, wps=101.5, ups=0.47, wpb=109.1, bsz=40, num_updates=5170, lr=4.97586e-05, gnorm=0.609, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19364
2023-01-08 04:13:51 - progress_bar.py[line:274] - INFO: epoch 001:   5185 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0773, wps=99.7, ups=0.46, wpb=109.4, bsz=40, num_updates=5180, lr=4.97541e-05, gnorm=0.548, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19387
2023-01-08 04:14:13 - progress_bar.py[line:274] - INFO: epoch 001:   5195 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0444, wps=102.2, ups=0.46, wpb=110.5, bsz=40, num_updates=5190, lr=4.97496e-05, gnorm=0.629, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19408
2023-01-08 04:14:34 - progress_bar.py[line:274] - INFO: epoch 001:   5205 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0674, wps=101.2, ups=0.46, wpb=109.1, bsz=40, num_updates=5200, lr=4.97451e-05, gnorm=0.572, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19430
2023-01-08 04:14:56 - progress_bar.py[line:274] - INFO: epoch 001:   5215 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0673, wps=100.3, ups=0.46, wpb=108.3, bsz=40, num_updates=5210, lr=4.97406e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19452
2023-01-08 04:15:18 - progress_bar.py[line:274] - INFO: epoch 001:   5225 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0744, wps=98.6, ups=0.46, wpb=107.7, bsz=40, num_updates=5220, lr=4.97361e-05, gnorm=0.628, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19474
2023-01-08 04:15:40 - progress_bar.py[line:274] - INFO: epoch 001:   5235 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0636, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=5230, lr=4.97316e-05, gnorm=0.672, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19496
2023-01-08 04:16:02 - progress_bar.py[line:274] - INFO: epoch 001:   5245 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0667, wps=100.8, ups=0.47, wpb=108, bsz=40, num_updates=5240, lr=4.97271e-05, gnorm=0.633, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19517
2023-01-08 04:16:24 - progress_bar.py[line:274] - INFO: epoch 001:   5255 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0561, wps=101.3, ups=0.47, wpb=108.8, bsz=40, num_updates=5250, lr=4.97226e-05, gnorm=0.577, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=19539
2023-01-08 04:16:45 - progress_bar.py[line:274] - INFO: epoch 001:   5265 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0945, wps=101.8, ups=0.47, wpb=109.2, bsz=40, num_updates=5260, lr=4.97181e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=19561
2023-01-08 04:17:07 - progress_bar.py[line:274] - INFO: epoch 001:   5275 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0539, wps=100.4, ups=0.46, wpb=109.7, bsz=40, num_updates=5270, lr=4.97136e-05, gnorm=0.616, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19583
2023-01-08 04:17:29 - progress_bar.py[line:274] - INFO: epoch 001:   5285 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0526, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=5280, lr=4.97091e-05, gnorm=0.714, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19605
2023-01-08 04:17:51 - progress_bar.py[line:274] - INFO: epoch 001:   5295 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0531, wps=100, ups=0.46, wpb=108.8, bsz=40, num_updates=5290, lr=4.97046e-05, gnorm=0.666, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19627
2023-01-08 04:18:14 - progress_bar.py[line:274] - INFO: epoch 001:   5305 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0891, wps=98.4, ups=0.45, wpb=108.4, bsz=40, num_updates=5300, lr=4.97001e-05, gnorm=0.554, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19649
2023-01-08 04:18:35 - progress_bar.py[line:274] - INFO: epoch 001:   5315 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0909, wps=101.9, ups=0.47, wpb=108.4, bsz=40, num_updates=5310, lr=4.96956e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19671
2023-01-08 04:18:57 - progress_bar.py[line:274] - INFO: epoch 001:   5325 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.051, wps=102.7, ups=0.47, wpb=108.8, bsz=40, num_updates=5320, lr=4.96911e-05, gnorm=0.638, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19692
2023-01-08 04:19:18 - progress_bar.py[line:274] - INFO: epoch 001:   5335 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0926, wps=102.1, ups=0.47, wpb=108.2, bsz=40, num_updates=5330, lr=4.96866e-05, gnorm=0.661, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19714
2023-01-08 04:19:40 - progress_bar.py[line:274] - INFO: epoch 001:   5345 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0905, wps=101.5, ups=0.47, wpb=109, bsz=40, num_updates=5340, lr=4.96821e-05, gnorm=0.611, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19735
2023-01-08 04:20:01 - progress_bar.py[line:274] - INFO: epoch 001:   5355 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0923, wps=100.6, ups=0.46, wpb=108.7, bsz=40, num_updates=5350, lr=4.96776e-05, gnorm=0.582, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19757
2023-01-08 04:20:23 - progress_bar.py[line:274] - INFO: epoch 001:   5365 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0633, wps=101.6, ups=0.47, wpb=108.4, bsz=40, num_updates=5360, lr=4.96731e-05, gnorm=0.547, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=19779
2023-01-08 04:20:45 - progress_bar.py[line:274] - INFO: epoch 001:   5375 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0798, wps=101.7, ups=0.46, wpb=109.8, bsz=40, num_updates=5370, lr=4.96687e-05, gnorm=0.654, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19801
2023-01-08 04:21:06 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 04:21:08 - progress_bar.py[line:274] - INFO: epoch 001:   5386 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=110.381, nsentences=40, sample_size=110.381, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.068, wps=99.1, ups=0.43, wpb=110.4, bsz=40, num_updates=5380, lr=4.96642e-05, gnorm=0.611, clip=0, loss_scale=512, train_wall=23, gb_free=9.4, ema_decay=0.9999, wall=19824
2023-01-08 04:21:30 - progress_bar.py[line:274] - INFO: epoch 001:   5396 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.122, wps=101.8, ups=0.46, wpb=109.8, bsz=40, num_updates=5390, lr=4.96597e-05, gnorm=0.589, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=19846
2023-01-08 04:21:52 - progress_bar.py[line:274] - INFO: epoch 001:   5406 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0818, wps=98, ups=0.45, wpb=107.8, bsz=40, num_updates=5400, lr=4.96552e-05, gnorm=0.689, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19868
2023-01-08 04:22:14 - progress_bar.py[line:274] - INFO: epoch 001:   5416 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0867, wps=100.6, ups=0.46, wpb=108.8, bsz=40, num_updates=5410, lr=4.96507e-05, gnorm=0.688, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19890
2023-01-08 04:22:36 - progress_bar.py[line:274] - INFO: epoch 001:   5426 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0465, wps=102.2, ups=0.47, wpb=108.6, bsz=40, num_updates=5420, lr=4.96462e-05, gnorm=0.588, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=19912
2023-01-08 04:22:57 - progress_bar.py[line:274] - INFO: epoch 001:   5436 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0753, wps=103, ups=0.47, wpb=110.2, bsz=40, num_updates=5430, lr=4.96417e-05, gnorm=0.607, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19933
2023-01-08 04:23:19 - progress_bar.py[line:274] - INFO: epoch 001:   5446 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0854, wps=99.4, ups=0.46, wpb=108.2, bsz=40, num_updates=5440, lr=4.96372e-05, gnorm=0.61, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19955
2023-01-08 04:23:41 - progress_bar.py[line:274] - INFO: epoch 001:   5456 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0874, wps=103.3, ups=0.47, wpb=109.7, bsz=40, num_updates=5450, lr=4.96327e-05, gnorm=0.741, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19977
2023-01-08 04:24:02 - progress_bar.py[line:274] - INFO: epoch 001:   5466 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0535, wps=104.3, ups=0.48, wpb=108.9, bsz=40, num_updates=5460, lr=4.96282e-05, gnorm=0.663, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=19998
2023-01-08 04:24:24 - progress_bar.py[line:274] - INFO: epoch 001:   5476 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0865, wps=99.9, ups=0.46, wpb=108.4, bsz=40, num_updates=5470, lr=4.96237e-05, gnorm=0.672, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20020
2023-01-08 04:24:46 - progress_bar.py[line:274] - INFO: epoch 001:   5486 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0511, wps=103.7, ups=0.47, wpb=111.5, bsz=40, num_updates=5480, lr=4.96192e-05, gnorm=0.646, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20041
2023-01-08 04:25:08 - progress_bar.py[line:274] - INFO: epoch 001:   5496 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0615, wps=98.9, ups=0.46, wpb=108, bsz=40, num_updates=5490, lr=4.96147e-05, gnorm=0.627, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=20064
2023-01-08 04:25:29 - progress_bar.py[line:274] - INFO: epoch 001:   5506 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0913, wps=102.8, ups=0.47, wpb=108.7, bsz=40, num_updates=5500, lr=4.96102e-05, gnorm=0.649, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20085
2023-01-08 04:25:50 - progress_bar.py[line:274] - INFO: epoch 001:   5516 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0838, wps=104, ups=0.47, wpb=110.1, bsz=40, num_updates=5510, lr=4.96057e-05, gnorm=0.626, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20106
2023-01-08 04:26:12 - progress_bar.py[line:274] - INFO: epoch 001:   5526 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0765, wps=101.8, ups=0.46, wpb=110.9, bsz=40, num_updates=5520, lr=4.96012e-05, gnorm=0.602, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20128
2023-01-08 04:26:35 - progress_bar.py[line:274] - INFO: epoch 001:   5536 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0495, wps=100.9, ups=0.46, wpb=110.1, bsz=40, num_updates=5530, lr=4.95967e-05, gnorm=0.69, clip=20, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=20150
2023-01-08 04:26:56 - progress_bar.py[line:274] - INFO: epoch 001:   5546 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.11, wps=98.7, ups=0.46, wpb=107.5, bsz=40, num_updates=5540, lr=4.95922e-05, gnorm=0.674, clip=20, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=20172
2023-01-08 04:27:18 - progress_bar.py[line:274] - INFO: epoch 001:   5556 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0498, wps=103.8, ups=0.47, wpb=110, bsz=40, num_updates=5550, lr=4.95877e-05, gnorm=0.744, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20194
2023-01-08 04:27:40 - progress_bar.py[line:274] - INFO: epoch 001:   5566 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0448, wps=101.4, ups=0.47, wpb=108.5, bsz=40, num_updates=5560, lr=4.95832e-05, gnorm=0.672, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20215
2023-01-08 04:28:02 - progress_bar.py[line:274] - INFO: epoch 001:   5576 / 115845 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0955, wps=100.9, ups=0.46, wpb=110.3, bsz=40, num_updates=5570, lr=4.95787e-05, gnorm=0.743, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20237
2023-01-08 04:28:24 - progress_bar.py[line:274] - INFO: epoch 001:   5586 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.09, wps=100.1, ups=0.46, wpb=110, bsz=40, num_updates=5580, lr=4.95742e-05, gnorm=0.552, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20260
2023-01-08 04:28:46 - progress_bar.py[line:274] - INFO: epoch 001:   5596 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0788, wps=99.9, ups=0.46, wpb=107.5, bsz=40, num_updates=5590, lr=4.95697e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20281
2023-01-08 04:29:07 - progress_bar.py[line:274] - INFO: epoch 001:   5606 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1123, wps=101.8, ups=0.46, wpb=110.6, bsz=40, num_updates=5600, lr=4.95652e-05, gnorm=0.585, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20303
2023-01-08 04:29:29 - progress_bar.py[line:274] - INFO: epoch 001:   5616 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0529, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=5610, lr=4.95607e-05, gnorm=0.579, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=20325
2023-01-08 04:29:50 - progress_bar.py[line:274] - INFO: epoch 001:   5626 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1202, wps=102.3, ups=0.47, wpb=108.3, bsz=40, num_updates=5620, lr=4.95563e-05, gnorm=0.659, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=20346
2023-01-08 04:30:12 - progress_bar.py[line:274] - INFO: epoch 001:   5636 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.087, wps=100.5, ups=0.46, wpb=108.9, bsz=40, num_updates=5630, lr=4.95518e-05, gnorm=0.817, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20368
2023-01-08 04:30:34 - progress_bar.py[line:274] - INFO: epoch 001:   5646 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0688, wps=103.5, ups=0.47, wpb=109.8, bsz=40, num_updates=5640, lr=4.95473e-05, gnorm=0.564, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=20390
2023-01-08 04:30:56 - progress_bar.py[line:274] - INFO: epoch 001:   5656 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1198, wps=99.5, ups=0.45, wpb=109.5, bsz=40, num_updates=5650, lr=4.95428e-05, gnorm=0.615, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20412
2023-01-08 04:31:18 - progress_bar.py[line:274] - INFO: epoch 001:   5666 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1117, wps=99.9, ups=0.46, wpb=109.6, bsz=40, num_updates=5660, lr=4.95383e-05, gnorm=0.53, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20434
2023-01-08 04:31:40 - progress_bar.py[line:274] - INFO: epoch 001:   5676 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0995, wps=103.9, ups=0.47, wpb=109.9, bsz=40, num_updates=5670, lr=4.95338e-05, gnorm=0.678, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=20455
2023-01-08 04:32:02 - progress_bar.py[line:274] - INFO: epoch 001:   5686 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0934, wps=100.6, ups=0.46, wpb=109.9, bsz=40, num_updates=5680, lr=4.95293e-05, gnorm=0.602, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20477
2023-01-08 04:32:24 - progress_bar.py[line:274] - INFO: epoch 001:   5696 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0682, wps=101, ups=0.46, wpb=110, bsz=40, num_updates=5690, lr=4.95248e-05, gnorm=0.579, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20499
2023-01-08 04:32:45 - progress_bar.py[line:274] - INFO: epoch 001:   5706 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0697, wps=103.6, ups=0.48, wpb=108.9, bsz=40, num_updates=5700, lr=4.95203e-05, gnorm=0.549, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20521
2023-01-08 04:33:07 - progress_bar.py[line:274] - INFO: epoch 001:   5716 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0825, wps=103, ups=0.47, wpb=110.5, bsz=40, num_updates=5710, lr=4.95158e-05, gnorm=0.644, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20542
2023-01-08 04:33:28 - progress_bar.py[line:274] - INFO: epoch 001:   5726 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1162, wps=103.6, ups=0.47, wpb=109.4, bsz=40, num_updates=5720, lr=4.95113e-05, gnorm=0.552, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20564
2023-01-08 04:33:50 - progress_bar.py[line:274] - INFO: epoch 001:   5736 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0684, wps=101.4, ups=0.46, wpb=109.6, bsz=40, num_updates=5730, lr=4.95068e-05, gnorm=0.654, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20586
2023-01-08 04:34:11 - progress_bar.py[line:274] - INFO: epoch 001:   5746 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0684, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=5740, lr=4.95023e-05, gnorm=0.832, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20607
2023-01-08 04:34:33 - progress_bar.py[line:274] - INFO: epoch 001:   5756 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1084, wps=99.5, ups=0.46, wpb=107.2, bsz=40, num_updates=5750, lr=4.94978e-05, gnorm=0.68, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=20629
2023-01-08 04:34:55 - progress_bar.py[line:274] - INFO: epoch 001:   5766 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1196, wps=102.3, ups=0.47, wpb=108.4, bsz=40, num_updates=5760, lr=4.94933e-05, gnorm=0.557, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20650
2023-01-08 04:35:16 - progress_bar.py[line:274] - INFO: epoch 001:   5776 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1156, wps=102.6, ups=0.47, wpb=108.7, bsz=40, num_updates=5770, lr=4.94888e-05, gnorm=0.615, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20672
2023-01-08 04:35:38 - progress_bar.py[line:274] - INFO: epoch 001:   5786 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1146, wps=100.1, ups=0.46, wpb=109.7, bsz=40, num_updates=5780, lr=4.94843e-05, gnorm=0.507, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20694
2023-01-08 04:36:00 - progress_bar.py[line:274] - INFO: epoch 001:   5796 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1088, wps=99.8, ups=0.46, wpb=108.4, bsz=40, num_updates=5790, lr=4.94798e-05, gnorm=0.513, clip=0, loss_scale=512, train_wall=22, gb_free=9.5, ema_decay=0.9999, wall=20716
2023-01-08 04:36:15 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 04:36:24 - progress_bar.py[line:274] - INFO: epoch 001:   5807 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.048, nsentences=40, sample_size=108.048, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0731, wps=97, ups=0.43, wpb=108, bsz=40, num_updates=5800, lr=4.94753e-05, gnorm=0.616, clip=10, loss_scale=256, train_wall=23, gb_free=9.8, ema_decay=0.9999, wall=20740
2023-01-08 04:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   5817 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0714, wps=102.5, ups=0.47, wpb=108.9, bsz=40, num_updates=5810, lr=4.94708e-05, gnorm=0.539, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20761
2023-01-08 04:37:08 - progress_bar.py[line:274] - INFO: epoch 001:   5827 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0865, wps=98.2, ups=0.45, wpb=107.9, bsz=40, num_updates=5820, lr=4.94663e-05, gnorm=0.628, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20783
2023-01-08 04:37:29 - progress_bar.py[line:274] - INFO: epoch 001:   5837 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1458, wps=100.1, ups=0.46, wpb=107.8, bsz=40, num_updates=5830, lr=4.94618e-05, gnorm=0.586, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20805
2023-01-08 04:37:51 - progress_bar.py[line:274] - INFO: epoch 001:   5847 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.089, wps=103, ups=0.47, wpb=109.9, bsz=40, num_updates=5840, lr=4.94573e-05, gnorm=0.511, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20827
2023-01-08 04:38:13 - progress_bar.py[line:274] - INFO: epoch 001:   5857 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0978, wps=101.8, ups=0.46, wpb=110, bsz=40, num_updates=5850, lr=4.94528e-05, gnorm=0.584, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20848
2023-01-08 04:38:34 - progress_bar.py[line:274] - INFO: epoch 001:   5867 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0653, wps=101.9, ups=0.47, wpb=108.2, bsz=40, num_updates=5860, lr=4.94484e-05, gnorm=0.452, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20870
2023-01-08 04:38:56 - progress_bar.py[line:274] - INFO: epoch 001:   5877 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.07, wps=102.3, ups=0.47, wpb=109.8, bsz=40, num_updates=5870, lr=4.94439e-05, gnorm=0.628, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20892
2023-01-08 04:39:17 - progress_bar.py[line:274] - INFO: epoch 001:   5887 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0923, wps=101.9, ups=0.47, wpb=108.8, bsz=40, num_updates=5880, lr=4.94394e-05, gnorm=0.56, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20913
2023-01-08 04:39:39 - progress_bar.py[line:274] - INFO: epoch 001:   5897 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0749, wps=103.6, ups=0.47, wpb=109.6, bsz=40, num_updates=5890, lr=4.94349e-05, gnorm=0.619, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20935
2023-01-08 04:40:00 - progress_bar.py[line:274] - INFO: epoch 001:   5907 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.087, wps=100.4, ups=0.46, wpb=108, bsz=40, num_updates=5900, lr=4.94304e-05, gnorm=0.856, clip=20, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=20956
2023-01-08 04:40:22 - progress_bar.py[line:274] - INFO: epoch 001:   5917 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1005, wps=102.5, ups=0.47, wpb=110, bsz=40, num_updates=5910, lr=4.94259e-05, gnorm=0.515, clip=0, loss_scale=256, train_wall=21, gb_free=9.5, ema_decay=0.9999, wall=20978
2023-01-08 04:40:44 - progress_bar.py[line:274] - INFO: epoch 001:   5927 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1005, wps=100.5, ups=0.46, wpb=110, bsz=40, num_updates=5920, lr=4.94214e-05, gnorm=0.95, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=21000
2023-01-08 04:41:06 - progress_bar.py[line:274] - INFO: epoch 001:   5937 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.11, wps=101.2, ups=0.47, wpb=108.5, bsz=40, num_updates=5930, lr=4.94169e-05, gnorm=0.618, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=21022
2023-01-08 04:41:28 - progress_bar.py[line:274] - INFO: epoch 001:   5947 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0628, wps=101.6, ups=0.46, wpb=109.8, bsz=40, num_updates=5940, lr=4.94124e-05, gnorm=0.646, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=21044
2023-01-08 04:41:50 - progress_bar.py[line:274] - INFO: epoch 001:   5957 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1368, wps=100.1, ups=0.46, wpb=109, bsz=40, num_updates=5950, lr=4.94079e-05, gnorm=0.514, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=21066
2023-01-08 04:42:11 - progress_bar.py[line:274] - INFO: epoch 001:   5967 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0948, wps=103.2, ups=0.47, wpb=108.7, bsz=40, num_updates=5960, lr=4.94034e-05, gnorm=0.608, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=21087
2023-01-08 04:42:33 - progress_bar.py[line:274] - INFO: epoch 001:   5977 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1029, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=5970, lr=4.93989e-05, gnorm=0.573, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=21109
2023-01-08 04:42:54 - progress_bar.py[line:274] - INFO: epoch 001:   5987 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1088, wps=103.9, ups=0.47, wpb=110.5, bsz=40, num_updates=5980, lr=4.93944e-05, gnorm=0.557, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=21130
2023-01-08 04:43:16 - progress_bar.py[line:274] - INFO: epoch 001:   5997 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1327, wps=101.8, ups=0.47, wpb=108.3, bsz=40, num_updates=5990, lr=4.93899e-05, gnorm=0.539, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=21152
2023-01-08 04:43:37 - progress_bar.py[line:274] - INFO: epoch 001:   6007 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0718, wps=102.8, ups=0.47, wpb=109.1, bsz=40, num_updates=6000, lr=4.93854e-05, gnorm=0.55, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=21173
2023-01-08 04:43:37 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 04:43:39 - train.py[line:549] - INFO: 0 / 4988
2023-01-08 04:43:39 - train.py[line:551] - INFO: load:1.03 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 04:46:11 - train.py[line:549] - INFO: 200 / 4988
2023-01-08 04:46:11 - train.py[line:551] - INFO: load:1.05 valid_run:152.02 task_valid:147.69 collect_output:3.25
2023-01-08 04:48:40 - train.py[line:549] - INFO: 400 / 4988
2023-01-08 04:48:40 - train.py[line:551] - INFO: load:1.08 valid_run:301.26 task_valid:290.59 collect_output:8.52
2023-01-08 04:51:13 - train.py[line:549] - INFO: 600 / 4988
2023-01-08 04:51:13 - train.py[line:551] - INFO: load:1.11 valid_run:454.61 task_valid:433.45 collect_output:17.97
2023-01-08 04:53:43 - train.py[line:549] - INFO: 800 / 4988
2023-01-08 04:53:43 - train.py[line:551] - INFO: load:1.13 valid_run:603.66 task_valid:577.95 collect_output:21.48
2023-01-08 04:56:15 - train.py[line:549] - INFO: 1000 / 4988
2023-01-08 04:56:15 - train.py[line:551] - INFO: load:1.16 valid_run:756.04 task_valid:724.98 collect_output:25.78
2023-01-08 04:58:47 - train.py[line:549] - INFO: 1200 / 4988
2023-01-08 04:58:47 - train.py[line:551] - INFO: load:1.19 valid_run:908.17 task_valid:870.45 collect_output:31.38
2023-01-08 05:01:21 - train.py[line:549] - INFO: 1400 / 4988
2023-01-08 05:01:21 - train.py[line:551] - INFO: load:1.22 valid_run:1061.98 task_valid:1016.14 collect_output:38.45
2023-01-08 05:03:53 - train.py[line:549] - INFO: 1600 / 4988
2023-01-08 05:03:53 - train.py[line:551] - INFO: load:1.24 valid_run:1213.54 task_valid:1156.97 collect_output:48.12
2023-01-08 05:06:22 - train.py[line:549] - INFO: 1800 / 4988
2023-01-08 05:06:22 - train.py[line:551] - INFO: load:1.27 valid_run:1363.14 task_valid:1301.28 collect_output:52.36
2023-01-08 05:08:51 - train.py[line:549] - INFO: 2000 / 4988
2023-01-08 05:08:51 - train.py[line:551] - INFO: load:1.30 valid_run:1512.08 task_valid:1444.24 collect_output:57.30
2023-01-08 05:11:21 - train.py[line:549] - INFO: 2200 / 4988
2023-01-08 05:11:21 - train.py[line:551] - INFO: load:1.33 valid_run:1661.89 task_valid:1588.81 collect_output:61.50
2023-01-08 05:13:52 - train.py[line:549] - INFO: 2400 / 4988
2023-01-08 05:13:52 - train.py[line:551] - INFO: load:1.36 valid_run:1811.99 task_valid:1733.55 collect_output:65.80
2023-01-08 05:16:22 - train.py[line:549] - INFO: 2600 / 4988
2023-01-08 05:16:22 - train.py[line:551] - INFO: load:1.39 valid_run:1962.24 task_valid:1875.06 collect_output:73.47
2023-01-08 05:18:53 - train.py[line:549] - INFO: 2800 / 4988
2023-01-08 05:18:53 - train.py[line:551] - INFO: load:1.41 valid_run:2112.85 task_valid:2020.34 collect_output:77.76
2023-01-08 05:21:23 - train.py[line:549] - INFO: 3000 / 4988
2023-01-08 05:21:23 - train.py[line:551] - INFO: load:1.44 valid_run:2262.82 task_valid:2166.38 collect_output:80.66
2023-01-08 05:23:53 - train.py[line:549] - INFO: 3200 / 4988
2023-01-08 05:23:53 - train.py[line:551] - INFO: load:1.47 valid_run:2412.83 task_valid:2310.09 collect_output:85.90
2023-01-08 05:26:25 - train.py[line:549] - INFO: 3400 / 4988
2023-01-08 05:26:25 - train.py[line:551] - INFO: load:1.50 valid_run:2564.64 task_valid:2455.11 collect_output:91.66
2023-01-08 05:28:55 - train.py[line:549] - INFO: 3600 / 4988
2023-01-08 05:28:55 - train.py[line:551] - INFO: load:1.53 valid_run:2715.16 task_valid:2601.73 collect_output:94.53
2023-01-08 05:31:24 - train.py[line:549] - INFO: 3800 / 4988
2023-01-08 05:31:24 - train.py[line:551] - INFO: load:1.56 valid_run:2863.86 task_valid:2742.83 collect_output:101.09
2023-01-08 05:33:54 - train.py[line:549] - INFO: 4000 / 4988
2023-01-08 05:33:54 - train.py[line:551] - INFO: load:1.58 valid_run:3014.24 task_valid:2887.52 collect_output:105.75
2023-01-08 05:36:26 - train.py[line:549] - INFO: 4200 / 4988
2023-01-08 05:36:27 - train.py[line:551] - INFO: load:1.61 valid_run:3166.33 task_valid:3031.65 collect_output:112.68
2023-01-08 05:38:56 - train.py[line:549] - INFO: 4400 / 4988
2023-01-08 05:38:56 - train.py[line:551] - INFO: load:1.64 valid_run:3315.75 task_valid:3175.87 collect_output:116.82
2023-01-08 05:41:27 - train.py[line:549] - INFO: 4600 / 4988
2023-01-08 05:41:27 - train.py[line:551] - INFO: load:1.67 valid_run:3467.09 task_valid:3321.68 collect_output:121.32
2023-01-08 05:43:59 - train.py[line:549] - INFO: 4800 / 4988
2023-01-08 05:43:59 - train.py[line:551] - INFO: load:1.70 valid_run:3618.31 task_valid:3467.76 collect_output:125.43

====================================================================================================
SGG eval:     R @ 50: 0.5941;     R @ 100: 0.6454;     R @ 500: 0.6835;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3637;    mR @ 100: 0.4518;    mR @ 500: 0.4995;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7317) (covered in:0.8125) (covering:0.3714) (eating:0.7647) (flying in:0.7273) (growing on:0.3750) (hanging from:0.4387) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.9477) (says:0.0000) (sitting on:0.7449) (standing on:0.2800) (using:0.6000) (walking in:0.0000) (walking on:0.7838) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-01-08 05:46:30 - train.py[line:487] - INFO: 0.6454205755029284

====================================================================================================
SGG eval:     R @ 50: 0.5941;     R @ 100: 0.6454;     R @ 500: 0.6835;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3637;    mR @ 100: 0.4518;    mR @ 500: 0.4995;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7317) (covered in:0.8125) (covering:0.3714) (eating:0.7647) (flying in:0.7273) (growing on:0.3750) (hanging from:0.4387) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.9477) (says:0.0000) (sitting on:0.7449) (standing on:0.2800) (using:0.6000) (walking in:0.0000) (walking on:0.7838) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-01-08 05:46:30 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 05:46:30 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.356 | loss_v1 0 | loss_v2 0 | nll_loss 0.204 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.645421 | ppl 1.15 | vqa_score 0.4775 | wps 119 | wpb 89.9 | bsz 30 | num_updates 6000 | best_R@100 0.645421
2023-01-08 05:46:30 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2023-01-08 05:46:30 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_6000.pt
2023-01-08 05:47:13 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_6000.pt
2023-01-08 05:50:07 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.6454205755029284) (writing took 217.38211485557258 seconds)
2023-01-08 05:50:29 - progress_bar.py[line:274] - INFO: epoch 001:   6017 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1156, wps=0.5, ups=0, wpb=108.3, bsz=40, num_updates=6010, lr=4.93809e-05, gnorm=0.551, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=25184
2023-01-08 05:50:50 - progress_bar.py[line:274] - INFO: epoch 001:   6027 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0833, wps=102, ups=0.47, wpb=109.1, bsz=40, num_updates=6020, lr=4.93764e-05, gnorm=0.556, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25206
2023-01-08 05:51:12 - progress_bar.py[line:274] - INFO: epoch 001:   6037 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1095, wps=99.2, ups=0.46, wpb=107.4, bsz=40, num_updates=6030, lr=4.93719e-05, gnorm=0.585, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=25228
2023-01-08 05:51:34 - progress_bar.py[line:274] - INFO: epoch 001:   6047 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0955, wps=99.9, ups=0.46, wpb=108.9, bsz=40, num_updates=6040, lr=4.93674e-05, gnorm=0.906, clip=30, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25250
2023-01-08 05:51:56 - progress_bar.py[line:274] - INFO: epoch 001:   6057 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0789, wps=100.7, ups=0.46, wpb=108.7, bsz=40, num_updates=6050, lr=4.93629e-05, gnorm=0.608, clip=10, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=25272
2023-01-08 05:52:18 - progress_bar.py[line:274] - INFO: epoch 001:   6067 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0632, wps=101.7, ups=0.47, wpb=109, bsz=40, num_updates=6060, lr=4.93584e-05, gnorm=0.586, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25294
2023-01-08 05:52:39 - progress_bar.py[line:274] - INFO: epoch 001:   6077 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1262, wps=100.9, ups=0.47, wpb=108, bsz=40, num_updates=6070, lr=4.93539e-05, gnorm=0.471, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25315
2023-01-08 05:53:02 - progress_bar.py[line:274] - INFO: epoch 001:   6087 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.096, wps=101.3, ups=0.46, wpb=110.2, bsz=40, num_updates=6080, lr=4.93494e-05, gnorm=0.58, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=25337
2023-01-08 05:53:24 - progress_bar.py[line:274] - INFO: epoch 001:   6097 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1132, wps=99.2, ups=0.46, wpb=108.1, bsz=40, num_updates=6090, lr=4.93449e-05, gnorm=0.663, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=25359
2023-01-08 05:53:45 - progress_bar.py[line:274] - INFO: epoch 001:   6107 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0876, wps=102.1, ups=0.46, wpb=109.9, bsz=40, num_updates=6100, lr=4.93404e-05, gnorm=0.553, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25381
2023-01-08 05:54:07 - progress_bar.py[line:274] - INFO: epoch 001:   6117 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0754, wps=103.8, ups=0.47, wpb=109.8, bsz=40, num_updates=6110, lr=4.9336e-05, gnorm=0.667, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=25403
2023-01-08 05:54:29 - progress_bar.py[line:274] - INFO: epoch 001:   6127 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0933, wps=100, ups=0.46, wpb=108.3, bsz=40, num_updates=6120, lr=4.93315e-05, gnorm=0.499, clip=0, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=25424
2023-01-08 05:54:50 - progress_bar.py[line:274] - INFO: epoch 001:   6137 / 115845 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1692, wps=104.3, ups=0.47, wpb=111, bsz=40, num_updates=6130, lr=4.9327e-05, gnorm=0.592, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=25446
2023-01-08 05:55:12 - progress_bar.py[line:274] - INFO: epoch 001:   6147 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0895, wps=101.1, ups=0.46, wpb=108.9, bsz=40, num_updates=6140, lr=4.93225e-05, gnorm=0.649, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=25468
2023-01-08 05:55:34 - progress_bar.py[line:274] - INFO: epoch 001:   6157 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1066, wps=102.2, ups=0.47, wpb=109.7, bsz=40, num_updates=6150, lr=4.9318e-05, gnorm=0.825, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25490
2023-01-08 05:55:56 - progress_bar.py[line:274] - INFO: epoch 001:   6167 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0846, wps=101.9, ups=0.46, wpb=109.8, bsz=40, num_updates=6160, lr=4.93135e-05, gnorm=0.576, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25511
2023-01-08 05:56:17 - progress_bar.py[line:274] - INFO: epoch 001:   6177 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1152, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=6170, lr=4.9309e-05, gnorm=0.782, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25533
2023-01-08 05:56:39 - progress_bar.py[line:274] - INFO: epoch 001:   6187 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0778, wps=104.8, ups=0.47, wpb=111.1, bsz=40, num_updates=6180, lr=4.93045e-05, gnorm=0.486, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25555
2023-01-08 05:57:01 - progress_bar.py[line:274] - INFO: epoch 001:   6197 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0619, wps=101.5, ups=0.46, wpb=109.9, bsz=40, num_updates=6190, lr=4.93e-05, gnorm=0.531, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=25576
2023-01-08 05:57:22 - progress_bar.py[line:274] - INFO: epoch 001:   6207 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1117, wps=101.3, ups=0.46, wpb=109, bsz=40, num_updates=6200, lr=4.92955e-05, gnorm=0.524, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25598
2023-01-08 05:57:44 - progress_bar.py[line:274] - INFO: epoch 001:   6217 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0876, wps=101.9, ups=0.46, wpb=109.8, bsz=40, num_updates=6210, lr=4.9291e-05, gnorm=0.479, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=25620
2023-01-08 05:58:06 - progress_bar.py[line:274] - INFO: epoch 001:   6227 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1366, wps=100.5, ups=0.46, wpb=108.5, bsz=40, num_updates=6220, lr=4.92865e-05, gnorm=0.516, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=25642
2023-01-08 05:58:27 - progress_bar.py[line:274] - INFO: epoch 001:   6237 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1429, wps=103.4, ups=0.47, wpb=109.7, bsz=40, num_updates=6230, lr=4.9282e-05, gnorm=0.751, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25663
2023-01-08 05:58:49 - progress_bar.py[line:274] - INFO: epoch 001:   6247 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1198, wps=104.4, ups=0.48, wpb=108.7, bsz=40, num_updates=6240, lr=4.92775e-05, gnorm=0.481, clip=0, loss_scale=256, train_wall=21, gb_free=9.5, ema_decay=0.9999, wall=25684
2023-01-08 05:59:10 - progress_bar.py[line:274] - INFO: epoch 001:   6257 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1042, wps=102.6, ups=0.47, wpb=109.4, bsz=40, num_updates=6250, lr=4.9273e-05, gnorm=0.708, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25706
2023-01-08 05:59:32 - progress_bar.py[line:274] - INFO: epoch 001:   6267 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0895, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=6260, lr=4.92685e-05, gnorm=0.502, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25728
2023-01-08 05:59:54 - progress_bar.py[line:274] - INFO: epoch 001:   6277 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.107, wps=102.8, ups=0.47, wpb=109.2, bsz=40, num_updates=6270, lr=4.9264e-05, gnorm=0.499, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=25749
2023-01-08 06:00:16 - progress_bar.py[line:274] - INFO: epoch 001:   6287 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1422, wps=99.4, ups=0.46, wpb=108.1, bsz=40, num_updates=6280, lr=4.92595e-05, gnorm=0.582, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=25771
2023-01-08 06:00:38 - progress_bar.py[line:274] - INFO: epoch 001:   6297 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.155, wps=100.4, ups=0.46, wpb=109.5, bsz=40, num_updates=6290, lr=4.9255e-05, gnorm=0.615, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25793
2023-01-08 06:00:59 - progress_bar.py[line:274] - INFO: epoch 001:   6307 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1505, wps=102.9, ups=0.47, wpb=109, bsz=40, num_updates=6300, lr=4.92505e-05, gnorm=0.572, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25815
2023-01-08 06:01:21 - progress_bar.py[line:274] - INFO: epoch 001:   6317 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1453, wps=102.7, ups=0.46, wpb=110.6, bsz=40, num_updates=6310, lr=4.9246e-05, gnorm=0.536, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25837
2023-01-08 06:01:42 - progress_bar.py[line:274] - INFO: epoch 001:   6327 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1034, wps=102.7, ups=0.47, wpb=108.4, bsz=40, num_updates=6320, lr=4.92415e-05, gnorm=0.519, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=25858
2023-01-08 06:02:04 - progress_bar.py[line:274] - INFO: epoch 001:   6337 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1606, wps=102.3, ups=0.47, wpb=108.6, bsz=40, num_updates=6330, lr=4.9237e-05, gnorm=0.494, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25880
2023-01-08 06:02:25 - progress_bar.py[line:274] - INFO: epoch 001:   6347 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1596, wps=103.8, ups=0.47, wpb=110.1, bsz=40, num_updates=6340, lr=4.92325e-05, gnorm=0.564, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=25901
2023-01-08 06:02:29 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 06:02:49 - progress_bar.py[line:274] - INFO: epoch 001:   6358 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.048, nsentences=40, sample_size=108.048, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1137, wps=98.4, ups=0.43, wpb=108, bsz=40, num_updates=6350, lr=4.92281e-05, gnorm=0.631, clip=10, loss_scale=256, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=25924
2023-01-08 06:03:10 - progress_bar.py[line:274] - INFO: epoch 001:   6368 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1038, wps=102.9, ups=0.47, wpb=110, bsz=40, num_updates=6360, lr=4.92236e-05, gnorm=0.536, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25946
2023-01-08 06:03:32 - progress_bar.py[line:274] - INFO: epoch 001:   6378 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0931, wps=101.7, ups=0.47, wpb=108.3, bsz=40, num_updates=6370, lr=4.92191e-05, gnorm=0.552, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=25968
2023-01-08 06:03:53 - progress_bar.py[line:274] - INFO: epoch 001:   6388 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1456, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=6380, lr=4.92146e-05, gnorm=0.511, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25989
2023-01-08 06:04:15 - progress_bar.py[line:274] - INFO: epoch 001:   6398 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1298, wps=100.3, ups=0.46, wpb=108.4, bsz=40, num_updates=6390, lr=4.92101e-05, gnorm=0.562, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26011
2023-01-08 06:04:37 - progress_bar.py[line:274] - INFO: epoch 001:   6408 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1779, wps=99.8, ups=0.46, wpb=108.3, bsz=40, num_updates=6400, lr=4.92056e-05, gnorm=0.926, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=26033
2023-01-08 06:04:59 - progress_bar.py[line:274] - INFO: epoch 001:   6418 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1225, wps=100.7, ups=0.46, wpb=109.3, bsz=40, num_updates=6410, lr=4.92011e-05, gnorm=0.553, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26055
2023-01-08 06:05:21 - progress_bar.py[line:274] - INFO: epoch 001:   6428 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0846, wps=104, ups=0.47, wpb=110.2, bsz=40, num_updates=6420, lr=4.91966e-05, gnorm=0.697, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26076
2023-01-08 06:05:42 - progress_bar.py[line:274] - INFO: epoch 001:   6438 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.18, wps=102.4, ups=0.47, wpb=109.5, bsz=40, num_updates=6430, lr=4.91921e-05, gnorm=0.747, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26098
2023-01-08 06:06:04 - progress_bar.py[line:274] - INFO: epoch 001:   6448 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1208, wps=100.7, ups=0.47, wpb=107.4, bsz=40, num_updates=6440, lr=4.91876e-05, gnorm=0.718, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26120
2023-01-08 06:06:25 - progress_bar.py[line:274] - INFO: epoch 001:   6458 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1471, wps=102.6, ups=0.47, wpb=109.5, bsz=40, num_updates=6450, lr=4.91831e-05, gnorm=0.599, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=26141
2023-01-08 06:06:47 - progress_bar.py[line:274] - INFO: epoch 001:   6468 / 115845 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1805, wps=100.4, ups=0.46, wpb=108.5, bsz=40, num_updates=6460, lr=4.91786e-05, gnorm=0.533, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26163
2023-01-08 06:07:09 - progress_bar.py[line:274] - INFO: epoch 001:   6478 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1238, wps=101, ups=0.46, wpb=109.5, bsz=40, num_updates=6470, lr=4.91741e-05, gnorm=0.626, clip=0, loss_scale=256, train_wall=22, gb_free=9.2, ema_decay=0.9999, wall=26185
2023-01-08 06:07:30 - progress_bar.py[line:274] - INFO: epoch 001:   6488 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1636, wps=103.8, ups=0.48, wpb=107.6, bsz=40, num_updates=6480, lr=4.91696e-05, gnorm=0.571, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=26206
2023-01-08 06:07:52 - progress_bar.py[line:274] - INFO: epoch 001:   6498 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1257, wps=99.9, ups=0.46, wpb=108, bsz=40, num_updates=6490, lr=4.91651e-05, gnorm=0.636, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26228
2023-01-08 06:08:14 - progress_bar.py[line:274] - INFO: epoch 001:   6508 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1364, wps=101.2, ups=0.46, wpb=109.6, bsz=40, num_updates=6500, lr=4.91606e-05, gnorm=0.444, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26250
2023-01-08 06:08:36 - progress_bar.py[line:274] - INFO: epoch 001:   6518 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1284, wps=100.8, ups=0.47, wpb=108.3, bsz=40, num_updates=6510, lr=4.91561e-05, gnorm=0.717, clip=20, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=26271
2023-01-08 06:08:57 - progress_bar.py[line:274] - INFO: epoch 001:   6528 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1414, wps=102.9, ups=0.47, wpb=109.7, bsz=40, num_updates=6520, lr=4.91516e-05, gnorm=0.719, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26293
2023-01-08 06:09:19 - progress_bar.py[line:274] - INFO: epoch 001:   6538 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.15, wps=101.9, ups=0.47, wpb=108.7, bsz=40, num_updates=6530, lr=4.91471e-05, gnorm=0.644, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26315
2023-01-08 06:09:40 - progress_bar.py[line:274] - INFO: epoch 001:   6548 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1724, wps=101.1, ups=0.47, wpb=108.5, bsz=40, num_updates=6540, lr=4.91426e-05, gnorm=0.705, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26336
2023-01-08 06:10:01 - progress_bar.py[line:274] - INFO: epoch 001:   6558 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.16, wps=105.6, ups=0.48, wpb=109.4, bsz=40, num_updates=6550, lr=4.91381e-05, gnorm=0.532, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26357
2023-01-08 06:10:23 - progress_bar.py[line:274] - INFO: epoch 001:   6568 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.195, wps=100.1, ups=0.46, wpb=109, bsz=40, num_updates=6560, lr=4.91336e-05, gnorm=0.435, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=26379
2023-01-08 06:10:45 - progress_bar.py[line:274] - INFO: epoch 001:   6578 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1754, wps=101.9, ups=0.47, wpb=107.9, bsz=40, num_updates=6570, lr=4.91291e-05, gnorm=0.556, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=26401
2023-01-08 06:11:07 - progress_bar.py[line:274] - INFO: epoch 001:   6588 / 115845 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1717, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=6580, lr=4.91246e-05, gnorm=0.551, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26422
2023-01-08 06:11:28 - progress_bar.py[line:274] - INFO: epoch 001:   6598 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.119, wps=103.1, ups=0.47, wpb=108.9, bsz=40, num_updates=6590, lr=4.91201e-05, gnorm=0.482, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26444
2023-01-08 06:11:50 - progress_bar.py[line:274] - INFO: epoch 001:   6608 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1744, wps=101.3, ups=0.46, wpb=110.3, bsz=40, num_updates=6600, lr=4.91157e-05, gnorm=0.544, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=26466
2023-01-08 06:12:12 - progress_bar.py[line:274] - INFO: epoch 001:   6618 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1466, wps=99.6, ups=0.46, wpb=108.6, bsz=40, num_updates=6610, lr=4.91112e-05, gnorm=0.55, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26488
2023-01-08 06:12:34 - progress_bar.py[line:274] - INFO: epoch 001:   6628 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0833, wps=101.6, ups=0.47, wpb=108.9, bsz=40, num_updates=6620, lr=4.91067e-05, gnorm=0.55, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26509
2023-01-08 06:12:55 - progress_bar.py[line:274] - INFO: epoch 001:   6638 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1508, wps=104.2, ups=0.48, wpb=109.5, bsz=40, num_updates=6630, lr=4.91022e-05, gnorm=0.543, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26531
2023-01-08 06:13:17 - progress_bar.py[line:274] - INFO: epoch 001:   6648 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1584, wps=99.8, ups=0.46, wpb=109, bsz=40, num_updates=6640, lr=4.90977e-05, gnorm=0.557, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=26553
2023-01-08 06:13:39 - progress_bar.py[line:274] - INFO: epoch 001:   6658 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1485, wps=103.9, ups=0.47, wpb=110.4, bsz=40, num_updates=6650, lr=4.90932e-05, gnorm=0.542, clip=0, loss_scale=256, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=26574
2023-01-08 06:14:01 - progress_bar.py[line:274] - INFO: epoch 001:   6668 / 115845 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1304, wps=100.2, ups=0.46, wpb=109.2, bsz=40, num_updates=6660, lr=4.90887e-05, gnorm=0.623, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26596
2023-01-08 06:14:22 - progress_bar.py[line:274] - INFO: epoch 001:   6678 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1357, wps=102.2, ups=0.47, wpb=108.7, bsz=40, num_updates=6670, lr=4.90842e-05, gnorm=0.606, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26618
2023-01-08 06:14:44 - progress_bar.py[line:274] - INFO: epoch 001:   6688 / 115845 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1702, wps=102.1, ups=0.47, wpb=109.6, bsz=40, num_updates=6680, lr=4.90797e-05, gnorm=0.608, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26640
2023-01-08 06:15:05 - progress_bar.py[line:274] - INFO: epoch 001:   6698 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1294, wps=102.6, ups=0.47, wpb=109.8, bsz=40, num_updates=6690, lr=4.90752e-05, gnorm=0.586, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26661
2023-01-08 06:15:27 - progress_bar.py[line:274] - INFO: epoch 001:   6708 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1755, wps=103.4, ups=0.47, wpb=110.4, bsz=40, num_updates=6700, lr=4.90707e-05, gnorm=0.465, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26683
2023-01-08 06:15:49 - progress_bar.py[line:274] - INFO: epoch 001:   6718 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1202, wps=100.1, ups=0.47, wpb=107.5, bsz=40, num_updates=6710, lr=4.90662e-05, gnorm=0.586, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=26704
2023-01-08 06:16:10 - progress_bar.py[line:274] - INFO: epoch 001:   6728 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.134, wps=104.7, ups=0.48, wpb=109.8, bsz=40, num_updates=6720, lr=4.90617e-05, gnorm=0.466, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=26726
2023-01-08 06:16:32 - progress_bar.py[line:274] - INFO: epoch 001:   6738 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1818, wps=103.2, ups=0.47, wpb=109.7, bsz=40, num_updates=6730, lr=4.90572e-05, gnorm=0.622, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26747
2023-01-08 06:16:53 - progress_bar.py[line:274] - INFO: epoch 001:   6748 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1724, wps=101.7, ups=0.47, wpb=108.8, bsz=40, num_updates=6740, lr=4.90527e-05, gnorm=0.604, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26769
2023-01-08 06:17:15 - progress_bar.py[line:274] - INFO: epoch 001:   6758 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0966, wps=101.1, ups=0.46, wpb=109.1, bsz=40, num_updates=6750, lr=4.90482e-05, gnorm=0.595, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26791
2023-01-08 06:17:37 - progress_bar.py[line:274] - INFO: epoch 001:   6768 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1546, wps=102, ups=0.46, wpb=110.7, bsz=40, num_updates=6760, lr=4.90437e-05, gnorm=0.562, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=26813
2023-01-08 06:17:59 - progress_bar.py[line:274] - INFO: epoch 001:   6778 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1453, wps=101.6, ups=0.46, wpb=109.8, bsz=40, num_updates=6770, lr=4.90392e-05, gnorm=0.491, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26835
2023-01-08 06:18:21 - progress_bar.py[line:274] - INFO: epoch 001:   6788 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1866, wps=100.6, ups=0.46, wpb=108.7, bsz=40, num_updates=6780, lr=4.90347e-05, gnorm=0.629, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26856
2023-01-08 06:18:43 - progress_bar.py[line:274] - INFO: epoch 001:   6798 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0979, wps=100.2, ups=0.46, wpb=109.1, bsz=40, num_updates=6790, lr=4.90302e-05, gnorm=0.59, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=26878
2023-01-08 06:19:04 - progress_bar.py[line:274] - INFO: epoch 001:   6808 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1707, wps=100.9, ups=0.47, wpb=108.4, bsz=40, num_updates=6800, lr=4.90257e-05, gnorm=0.559, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26900
2023-01-08 06:19:26 - progress_bar.py[line:274] - INFO: epoch 001:   6818 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1463, wps=101.1, ups=0.46, wpb=110.3, bsz=40, num_updates=6810, lr=4.90212e-05, gnorm=0.585, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26922
2023-01-08 06:19:48 - progress_bar.py[line:274] - INFO: epoch 001:   6828 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1594, wps=100.8, ups=0.46, wpb=109.7, bsz=40, num_updates=6820, lr=4.90167e-05, gnorm=0.521, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26944
2023-01-08 06:20:10 - progress_bar.py[line:274] - INFO: epoch 001:   6838 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1422, wps=99.3, ups=0.46, wpb=107.2, bsz=40, num_updates=6830, lr=4.90122e-05, gnorm=0.518, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=26966
2023-01-08 06:20:32 - progress_bar.py[line:274] - INFO: epoch 001:   6848 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1192, wps=101.1, ups=0.47, wpb=108.2, bsz=40, num_updates=6840, lr=4.90078e-05, gnorm=0.695, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26988
2023-01-08 06:20:53 - progress_bar.py[line:274] - INFO: epoch 001:   6858 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1675, wps=103, ups=0.47, wpb=109.4, bsz=40, num_updates=6850, lr=4.90033e-05, gnorm=0.455, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27009
2023-01-08 06:21:15 - progress_bar.py[line:274] - INFO: epoch 001:   6868 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1478, wps=101.8, ups=0.47, wpb=108.5, bsz=40, num_updates=6860, lr=4.89988e-05, gnorm=0.528, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=27031
2023-01-08 06:21:37 - progress_bar.py[line:274] - INFO: epoch 001:   6878 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1554, wps=100.8, ups=0.46, wpb=110, bsz=40, num_updates=6870, lr=4.89943e-05, gnorm=0.477, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27053
2023-01-08 06:21:59 - progress_bar.py[line:274] - INFO: epoch 001:   6888 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1643, wps=100, ups=0.47, wpb=107.1, bsz=40, num_updates=6880, lr=4.89898e-05, gnorm=0.467, clip=0, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=27074
2023-01-08 06:22:20 - progress_bar.py[line:274] - INFO: epoch 001:   6898 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1598, wps=101.5, ups=0.47, wpb=108.5, bsz=40, num_updates=6890, lr=4.89853e-05, gnorm=0.579, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27096
2023-01-08 06:22:41 - progress_bar.py[line:274] - INFO: epoch 001:   6908 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1451, wps=104.4, ups=0.47, wpb=110.3, bsz=40, num_updates=6900, lr=4.89808e-05, gnorm=0.526, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27117
2023-01-08 06:23:03 - progress_bar.py[line:274] - INFO: epoch 001:   6918 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1436, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=6910, lr=4.89763e-05, gnorm=0.496, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=27139
2023-01-08 06:23:25 - progress_bar.py[line:274] - INFO: epoch 001:   6928 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1706, wps=102, ups=0.47, wpb=108.9, bsz=40, num_updates=6920, lr=4.89718e-05, gnorm=0.643, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=27161
2023-01-08 06:23:46 - progress_bar.py[line:274] - INFO: epoch 001:   6938 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1324, wps=103.3, ups=0.48, wpb=108.5, bsz=40, num_updates=6930, lr=4.89673e-05, gnorm=0.623, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=27182
2023-01-08 06:24:08 - progress_bar.py[line:274] - INFO: epoch 001:   6948 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1683, wps=101.3, ups=0.46, wpb=109.9, bsz=40, num_updates=6940, lr=4.89628e-05, gnorm=0.919, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=27204
2023-01-08 06:24:30 - progress_bar.py[line:274] - INFO: epoch 001:   6958 / 115845 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1466, wps=99.7, ups=0.45, wpb=110, bsz=40, num_updates=6950, lr=4.89583e-05, gnorm=0.584, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27226
2023-01-08 06:24:52 - progress_bar.py[line:274] - INFO: epoch 001:   6968 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1691, wps=102.3, ups=0.47, wpb=109.3, bsz=40, num_updates=6960, lr=4.89538e-05, gnorm=0.523, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27248
2023-01-08 06:25:14 - progress_bar.py[line:274] - INFO: epoch 001:   6978 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.181, wps=99.7, ups=0.46, wpb=108.5, bsz=40, num_updates=6970, lr=4.89493e-05, gnorm=0.609, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=27270
2023-01-08 06:25:36 - progress_bar.py[line:274] - INFO: epoch 001:   6988 / 115845 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1594, wps=102, ups=0.47, wpb=108.8, bsz=40, num_updates=6980, lr=4.89448e-05, gnorm=0.56, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27291
2023-01-08 06:25:58 - progress_bar.py[line:274] - INFO: epoch 001:   6998 / 115845 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1784, wps=100.9, ups=0.46, wpb=109.5, bsz=40, num_updates=6990, lr=4.89403e-05, gnorm=0.484, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27313
2023-01-08 06:26:20 - progress_bar.py[line:274] - INFO: epoch 001:   7008 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1787, wps=97.7, ups=0.45, wpb=108.5, bsz=40, num_updates=7000, lr=4.89358e-05, gnorm=0.51, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=27336
2023-01-08 06:26:42 - progress_bar.py[line:274] - INFO: epoch 001:   7018 / 115845 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1327, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=7010, lr=4.89313e-05, gnorm=0.513, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27358
2023-01-08 06:27:03 - progress_bar.py[line:274] - INFO: epoch 001:   7028 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1538, wps=103.1, ups=0.47, wpb=109.8, bsz=40, num_updates=7020, lr=4.89268e-05, gnorm=0.537, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27379
2023-01-08 06:27:25 - progress_bar.py[line:274] - INFO: epoch 001:   7038 / 115845 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2086, wps=102.9, ups=0.47, wpb=109.8, bsz=40, num_updates=7030, lr=4.89223e-05, gnorm=0.569, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27401
2023-01-08 06:27:47 - progress_bar.py[line:274] - INFO: epoch 001:   7048 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1564, wps=102.2, ups=0.47, wpb=109.3, bsz=40, num_updates=7040, lr=4.89178e-05, gnorm=0.51, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27423
2023-01-08 06:28:09 - progress_bar.py[line:274] - INFO: epoch 001:   7058 / 115845 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1865, wps=102.3, ups=0.47, wpb=110, bsz=40, num_updates=7050, lr=4.89133e-05, gnorm=0.665, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27444
2023-01-08 06:28:30 - progress_bar.py[line:274] - INFO: epoch 001:   7068 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1848, wps=105.8, ups=0.48, wpb=110.2, bsz=40, num_updates=7060, lr=4.89088e-05, gnorm=0.56, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=27466
2023-01-08 06:28:52 - progress_bar.py[line:274] - INFO: epoch 001:   7078 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1846, wps=101.2, ups=0.46, wpb=110, bsz=40, num_updates=7070, lr=4.89043e-05, gnorm=0.52, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27488
2023-01-08 06:29:13 - progress_bar.py[line:274] - INFO: epoch 001:   7088 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1569, wps=101.3, ups=0.47, wpb=108.4, bsz=40, num_updates=7080, lr=4.88998e-05, gnorm=0.509, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27509
2023-01-08 06:29:35 - progress_bar.py[line:274] - INFO: epoch 001:   7098 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.13, wps=98.9, ups=0.46, wpb=107.5, bsz=40, num_updates=7090, lr=4.88954e-05, gnorm=0.603, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=27531
2023-01-08 06:29:57 - progress_bar.py[line:274] - INFO: epoch 001:   7108 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2, wps=101.2, ups=0.46, wpb=109.1, bsz=40, num_updates=7100, lr=4.88909e-05, gnorm=0.588, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=27553
2023-01-08 06:30:19 - progress_bar.py[line:274] - INFO: epoch 001:   7118 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2105, wps=103.1, ups=0.47, wpb=110, bsz=40, num_updates=7110, lr=4.88864e-05, gnorm=0.505, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27575
2023-01-08 06:30:41 - progress_bar.py[line:274] - INFO: epoch 001:   7128 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1643, wps=100.2, ups=0.46, wpb=107.8, bsz=40, num_updates=7120, lr=4.88819e-05, gnorm=0.515, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27597
2023-01-08 06:31:02 - progress_bar.py[line:274] - INFO: epoch 001:   7138 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1564, wps=101.8, ups=0.47, wpb=107.7, bsz=40, num_updates=7130, lr=4.88774e-05, gnorm=0.535, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27618
2023-01-08 06:31:24 - progress_bar.py[line:274] - INFO: epoch 001:   7148 / 115845 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.21, wps=101.4, ups=0.47, wpb=108.1, bsz=40, num_updates=7140, lr=4.88729e-05, gnorm=0.565, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27640
2023-01-08 06:31:28 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 06:31:48 - progress_bar.py[line:274] - INFO: epoch 001:   7159 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.81, nsentences=40, sample_size=110.81, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.201, wps=97.6, ups=0.42, wpb=110.8, bsz=40, num_updates=7150, lr=4.88684e-05, gnorm=0.594, clip=0, loss_scale=256, train_wall=24, gb_free=10.4, ema_decay=0.9999, wall=27664
2023-01-08 06:32:10 - progress_bar.py[line:274] - INFO: epoch 001:   7169 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1746, wps=99.7, ups=0.45, wpb=109.7, bsz=40, num_updates=7160, lr=4.88639e-05, gnorm=0.618, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27686
2023-01-08 06:32:32 - progress_bar.py[line:274] - INFO: epoch 001:   7179 / 115845 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1852, wps=102.1, ups=0.46, wpb=110.4, bsz=40, num_updates=7170, lr=4.88594e-05, gnorm=0.512, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27708
2023-01-08 06:32:54 - progress_bar.py[line:274] - INFO: epoch 001:   7189 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1624, wps=100.7, ups=0.46, wpb=109.5, bsz=40, num_updates=7180, lr=4.88549e-05, gnorm=0.559, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27730
2023-01-08 06:33:16 - progress_bar.py[line:274] - INFO: epoch 001:   7199 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2344, wps=104.2, ups=0.48, wpb=109.2, bsz=40, num_updates=7190, lr=4.88504e-05, gnorm=0.598, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27751
2023-01-08 06:33:37 - progress_bar.py[line:274] - INFO: epoch 001:   7209 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.201, wps=101.4, ups=0.47, wpb=108.9, bsz=40, num_updates=7200, lr=4.88459e-05, gnorm=0.598, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27773
2023-01-08 06:34:00 - progress_bar.py[line:274] - INFO: epoch 001:   7219 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1939, wps=99.2, ups=0.46, wpb=108.5, bsz=40, num_updates=7210, lr=4.88414e-05, gnorm=0.653, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27795
2023-01-08 06:34:21 - progress_bar.py[line:274] - INFO: epoch 001:   7229 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1809, wps=104.6, ups=0.47, wpb=110.5, bsz=40, num_updates=7220, lr=4.88369e-05, gnorm=0.59, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=27817
2023-01-08 06:34:43 - progress_bar.py[line:274] - INFO: epoch 001:   7239 / 115845 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1722, wps=101.5, ups=0.46, wpb=109.7, bsz=40, num_updates=7230, lr=4.88324e-05, gnorm=0.488, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27839
2023-01-08 06:35:04 - progress_bar.py[line:274] - INFO: epoch 001:   7249 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.2077, wps=103.8, ups=0.48, wpb=108.3, bsz=40, num_updates=7240, lr=4.88279e-05, gnorm=0.544, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=27860
2023-01-08 06:35:26 - progress_bar.py[line:274] - INFO: epoch 001:   7259 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1756, wps=100.6, ups=0.47, wpb=107.3, bsz=40, num_updates=7250, lr=4.88234e-05, gnorm=0.504, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=27881
2023-01-08 06:35:48 - progress_bar.py[line:274] - INFO: epoch 001:   7269 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2624, wps=99.1, ups=0.46, wpb=108.9, bsz=40, num_updates=7260, lr=4.88189e-05, gnorm=0.72, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27904
2023-01-08 06:36:10 - progress_bar.py[line:274] - INFO: epoch 001:   7279 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2216, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=7270, lr=4.88144e-05, gnorm=0.639, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27926
2023-01-08 06:36:33 - progress_bar.py[line:274] - INFO: epoch 001:   7289 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2118, wps=99.9, ups=0.45, wpb=110.2, bsz=40, num_updates=7280, lr=4.88099e-05, gnorm=0.738, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27949
2023-01-08 06:36:55 - progress_bar.py[line:274] - INFO: epoch 001:   7299 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2312, wps=101.3, ups=0.46, wpb=109.1, bsz=40, num_updates=7290, lr=4.88054e-05, gnorm=0.54, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=27971
2023-01-08 06:37:18 - progress_bar.py[line:274] - INFO: epoch 001:   7309 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2222, wps=99.4, ups=0.45, wpb=109.5, bsz=40, num_updates=7300, lr=4.88009e-05, gnorm=0.537, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27993
2023-01-08 06:37:40 - progress_bar.py[line:274] - INFO: epoch 001:   7319 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.153, wps=101.5, ups=0.46, wpb=109.6, bsz=40, num_updates=7310, lr=4.87964e-05, gnorm=0.469, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28015
2023-01-08 06:38:02 - progress_bar.py[line:274] - INFO: epoch 001:   7329 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2206, wps=100.8, ups=0.46, wpb=109, bsz=40, num_updates=7320, lr=4.87919e-05, gnorm=0.59, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28037
2023-01-08 06:38:24 - progress_bar.py[line:274] - INFO: epoch 001:   7339 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2512, wps=98.1, ups=0.46, wpb=107.5, bsz=40, num_updates=7330, lr=4.87875e-05, gnorm=0.604, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28060
2023-01-08 06:38:46 - progress_bar.py[line:274] - INFO: epoch 001:   7349 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.22, wps=100.9, ups=0.47, wpb=108.4, bsz=40, num_updates=7340, lr=4.8783e-05, gnorm=0.596, clip=0, loss_scale=256, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=28082
2023-01-08 06:39:08 - progress_bar.py[line:274] - INFO: epoch 001:   7359 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2563, wps=103.9, ups=0.48, wpb=109.1, bsz=40, num_updates=7350, lr=4.87785e-05, gnorm=0.561, clip=10, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=28103
2023-01-08 06:39:30 - progress_bar.py[line:274] - INFO: epoch 001:   7369 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2049, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=7360, lr=4.8774e-05, gnorm=0.463, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28126
2023-01-08 06:39:51 - progress_bar.py[line:274] - INFO: epoch 001:   7379 / 115845 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2552, wps=105.6, ups=0.48, wpb=109.7, bsz=40, num_updates=7370, lr=4.87695e-05, gnorm=0.523, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28147
2023-01-08 06:40:13 - progress_bar.py[line:274] - INFO: epoch 001:   7389 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2143, wps=103.7, ups=0.47, wpb=110.1, bsz=40, num_updates=7380, lr=4.8765e-05, gnorm=0.6, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=28168
2023-01-08 06:40:34 - progress_bar.py[line:274] - INFO: epoch 001:   7399 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2523, wps=102.3, ups=0.47, wpb=107.9, bsz=40, num_updates=7390, lr=4.87605e-05, gnorm=0.62, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28190
2023-01-08 06:40:56 - progress_bar.py[line:274] - INFO: epoch 001:   7409 / 115845 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1865, wps=101.6, ups=0.46, wpb=109.5, bsz=40, num_updates=7400, lr=4.8756e-05, gnorm=0.589, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28212
2023-01-08 06:41:18 - progress_bar.py[line:274] - INFO: epoch 001:   7419 / 115845 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2338, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=7410, lr=4.87515e-05, gnorm=0.449, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28234
2023-01-08 06:41:41 - progress_bar.py[line:274] - INFO: epoch 001:   7429 / 115845 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2105, wps=101.1, ups=0.46, wpb=109.3, bsz=40, num_updates=7420, lr=4.8747e-05, gnorm=0.544, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28256
2023-01-08 06:42:03 - progress_bar.py[line:274] - INFO: epoch 001:   7439 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2087, wps=101, ups=0.47, wpb=107.9, bsz=40, num_updates=7430, lr=4.87425e-05, gnorm=0.559, clip=10, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=28278
2023-01-08 06:42:24 - progress_bar.py[line:274] - INFO: epoch 001:   7449 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2059, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=7440, lr=4.8738e-05, gnorm=0.535, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28300
2023-01-08 06:42:46 - progress_bar.py[line:274] - INFO: epoch 001:   7459 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2228, wps=103.4, ups=0.46, wpb=111.7, bsz=40, num_updates=7450, lr=4.87335e-05, gnorm=0.499, clip=0, loss_scale=256, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=28322
2023-01-08 06:43:09 - progress_bar.py[line:274] - INFO: epoch 001:   7469 / 115845 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1869, wps=101.2, ups=0.46, wpb=110.3, bsz=40, num_updates=7460, lr=4.8729e-05, gnorm=0.518, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=28344
2023-01-08 06:43:30 - progress_bar.py[line:274] - INFO: epoch 001:   7479 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2273, wps=101.9, ups=0.47, wpb=108.1, bsz=40, num_updates=7470, lr=4.87245e-05, gnorm=0.749, clip=10, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=28366
2023-01-08 06:43:52 - progress_bar.py[line:274] - INFO: epoch 001:   7489 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2282, wps=102.9, ups=0.47, wpb=109.1, bsz=40, num_updates=7480, lr=4.872e-05, gnorm=0.64, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28388
2023-01-08 06:44:14 - progress_bar.py[line:274] - INFO: epoch 001:   7499 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2174, wps=102, ups=0.47, wpb=109, bsz=40, num_updates=7490, lr=4.87155e-05, gnorm=0.473, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28409
2023-01-08 06:44:36 - progress_bar.py[line:274] - INFO: epoch 001:   7509 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2, wps=100.2, ups=0.46, wpb=110.1, bsz=40, num_updates=7500, lr=4.8711e-05, gnorm=0.494, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28432
2023-01-08 06:44:58 - progress_bar.py[line:274] - INFO: epoch 001:   7519 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1951, wps=100.5, ups=0.46, wpb=108.7, bsz=40, num_updates=7510, lr=4.87065e-05, gnorm=0.662, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28454
2023-01-08 06:45:20 - progress_bar.py[line:274] - INFO: epoch 001:   7529 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2488, wps=101.4, ups=0.47, wpb=109, bsz=40, num_updates=7520, lr=4.8702e-05, gnorm=0.55, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=28476
2023-01-08 06:45:43 - progress_bar.py[line:274] - INFO: epoch 001:   7539 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2271, wps=100.1, ups=0.46, wpb=108.9, bsz=40, num_updates=7530, lr=4.86975e-05, gnorm=0.581, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=28498
2023-01-08 06:46:05 - progress_bar.py[line:274] - INFO: epoch 001:   7549 / 115845 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1968, wps=102.7, ups=0.46, wpb=110.8, bsz=40, num_updates=7540, lr=4.8693e-05, gnorm=0.532, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28520
2023-01-08 06:46:26 - progress_bar.py[line:274] - INFO: epoch 001:   7559 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1587, wps=101.2, ups=0.47, wpb=108.2, bsz=40, num_updates=7550, lr=4.86885e-05, gnorm=1.354, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=28542
2023-01-08 06:46:48 - progress_bar.py[line:274] - INFO: epoch 001:   7569 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2475, wps=101.5, ups=0.46, wpb=109.2, bsz=40, num_updates=7560, lr=4.8684e-05, gnorm=0.472, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28564
2023-01-08 06:47:11 - progress_bar.py[line:274] - INFO: epoch 001:   7579 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2011, wps=100.3, ups=0.46, wpb=109.2, bsz=40, num_updates=7570, lr=4.86795e-05, gnorm=0.727, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28586
2023-01-08 06:47:32 - progress_bar.py[line:274] - INFO: epoch 001:   7589 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2455, wps=104.1, ups=0.48, wpb=107.9, bsz=40, num_updates=7580, lr=4.86751e-05, gnorm=0.937, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28607
2023-01-08 06:47:54 - progress_bar.py[line:274] - INFO: epoch 001:   7599 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2591, wps=102, ups=0.46, wpb=110.7, bsz=40, num_updates=7590, lr=4.86706e-05, gnorm=0.534, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28630
2023-01-08 06:48:16 - progress_bar.py[line:274] - INFO: epoch 001:   7609 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2439, wps=99.7, ups=0.46, wpb=108.5, bsz=40, num_updates=7600, lr=4.86661e-05, gnorm=0.592, clip=20, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=28652
2023-01-08 06:48:37 - progress_bar.py[line:274] - INFO: epoch 001:   7619 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2634, wps=104.1, ups=0.48, wpb=108.1, bsz=40, num_updates=7610, lr=4.86616e-05, gnorm=0.469, clip=0, loss_scale=256, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=28673
2023-01-08 06:48:59 - progress_bar.py[line:274] - INFO: epoch 001:   7629 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2081, wps=104.2, ups=0.47, wpb=109.8, bsz=40, num_updates=7620, lr=4.86571e-05, gnorm=0.538, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=28695
2023-01-08 06:49:21 - progress_bar.py[line:274] - INFO: epoch 001:   7639 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2562, wps=101.9, ups=0.47, wpb=109.1, bsz=40, num_updates=7630, lr=4.86526e-05, gnorm=0.596, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=28716
2023-01-08 06:49:43 - progress_bar.py[line:274] - INFO: epoch 001:   7649 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1762, wps=100.3, ups=0.46, wpb=108.8, bsz=40, num_updates=7640, lr=4.86481e-05, gnorm=0.649, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28739
2023-01-08 06:50:05 - progress_bar.py[line:274] - INFO: epoch 001:   7659 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2121, wps=103.2, ups=0.47, wpb=109.4, bsz=40, num_updates=7650, lr=4.86436e-05, gnorm=0.636, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28760
2023-01-08 06:50:27 - progress_bar.py[line:274] - INFO: epoch 001:   7669 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2283, wps=100.6, ups=0.46, wpb=108.7, bsz=40, num_updates=7660, lr=4.86391e-05, gnorm=0.655, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28782
2023-01-08 06:50:48 - progress_bar.py[line:274] - INFO: epoch 001:   7679 / 115845 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1805, wps=102.6, ups=0.47, wpb=108.7, bsz=40, num_updates=7670, lr=4.86346e-05, gnorm=0.524, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28804
2023-01-08 06:51:10 - progress_bar.py[line:274] - INFO: epoch 001:   7689 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1937, wps=101.5, ups=0.46, wpb=109.9, bsz=40, num_updates=7680, lr=4.86301e-05, gnorm=0.594, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=28826
2023-01-08 06:51:32 - progress_bar.py[line:274] - INFO: epoch 001:   7699 / 115845 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2336, wps=102.3, ups=0.47, wpb=108.4, bsz=40, num_updates=7690, lr=4.86256e-05, gnorm=0.576, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28848
2023-01-08 06:51:54 - progress_bar.py[line:274] - INFO: epoch 001:   7709 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.219, wps=100.2, ups=0.46, wpb=108.4, bsz=40, num_updates=7700, lr=4.86211e-05, gnorm=0.517, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28870
2023-01-08 06:52:16 - progress_bar.py[line:274] - INFO: epoch 001:   7719 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.25, wps=100.4, ups=0.46, wpb=109.2, bsz=40, num_updates=7710, lr=4.86166e-05, gnorm=0.485, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28892
2023-01-08 06:52:39 - progress_bar.py[line:274] - INFO: epoch 001:   7729 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2249, wps=99, ups=0.46, wpb=107.9, bsz=40, num_updates=7720, lr=4.86121e-05, gnorm=0.532, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28914
2023-01-08 06:53:01 - progress_bar.py[line:274] - INFO: epoch 001:   7739 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.25, wps=100.3, ups=0.46, wpb=109, bsz=40, num_updates=7730, lr=4.86076e-05, gnorm=0.74, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28936
2023-01-08 06:53:22 - progress_bar.py[line:274] - INFO: epoch 001:   7749 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2879, wps=102.6, ups=0.47, wpb=108.6, bsz=40, num_updates=7740, lr=4.86031e-05, gnorm=0.718, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28958
2023-01-08 06:53:45 - progress_bar.py[line:274] - INFO: epoch 001:   7759 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2126, wps=99.2, ups=0.46, wpb=108.7, bsz=40, num_updates=7750, lr=4.85986e-05, gnorm=0.648, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28980
2023-01-08 06:54:06 - progress_bar.py[line:274] - INFO: epoch 001:   7769 / 115845 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2121, wps=103.4, ups=0.47, wpb=108.9, bsz=40, num_updates=7760, lr=4.85941e-05, gnorm=0.587, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29002
2023-01-08 06:54:28 - progress_bar.py[line:274] - INFO: epoch 001:   7779 / 115845 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1497, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=7770, lr=4.85896e-05, gnorm=0.621, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29024
2023-01-08 06:54:50 - progress_bar.py[line:274] - INFO: epoch 001:   7789 / 115845 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2596, wps=100.7, ups=0.46, wpb=108.7, bsz=40, num_updates=7780, lr=4.85851e-05, gnorm=0.637, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29046
2023-01-08 06:55:13 - progress_bar.py[line:274] - INFO: epoch 001:   7799 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.204, wps=98.4, ups=0.45, wpb=108.4, bsz=40, num_updates=7790, lr=4.85806e-05, gnorm=0.601, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29069
2023-01-08 06:55:35 - progress_bar.py[line:274] - INFO: epoch 001:   7809 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2053, wps=102.2, ups=0.47, wpb=108.3, bsz=40, num_updates=7800, lr=4.85761e-05, gnorm=0.603, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29090
2023-01-08 06:55:56 - progress_bar.py[line:274] - INFO: epoch 001:   7819 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2205, wps=102.7, ups=0.47, wpb=109.5, bsz=40, num_updates=7810, lr=4.85716e-05, gnorm=0.521, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29112
2023-01-08 06:56:18 - progress_bar.py[line:274] - INFO: epoch 001:   7829 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3069, wps=102.1, ups=0.46, wpb=110.1, bsz=40, num_updates=7820, lr=4.85672e-05, gnorm=0.664, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29134
2023-01-08 06:56:40 - progress_bar.py[line:274] - INFO: epoch 001:   7839 / 115845 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3026, wps=102.7, ups=0.47, wpb=109.7, bsz=40, num_updates=7830, lr=4.85627e-05, gnorm=0.82, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29156
2023-01-08 06:57:03 - progress_bar.py[line:274] - INFO: epoch 001:   7849 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2488, wps=98.3, ups=0.45, wpb=108.3, bsz=40, num_updates=7840, lr=4.85582e-05, gnorm=0.641, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29178
2023-01-08 06:57:25 - progress_bar.py[line:274] - INFO: epoch 001:   7859 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3351, wps=100.9, ups=0.46, wpb=109.5, bsz=40, num_updates=7850, lr=4.85537e-05, gnorm=0.644, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29201
2023-01-08 06:57:46 - progress_bar.py[line:274] - INFO: epoch 001:   7869 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.184, wps=102.3, ups=0.48, wpb=107.6, bsz=40, num_updates=7860, lr=4.85492e-05, gnorm=0.772, clip=20, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=29222
2023-01-08 06:58:09 - progress_bar.py[line:274] - INFO: epoch 001:   7879 / 115845 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2704, wps=99.7, ups=0.46, wpb=108.1, bsz=40, num_updates=7870, lr=4.85447e-05, gnorm=0.593, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29244
2023-01-08 06:58:31 - progress_bar.py[line:274] - INFO: epoch 001:   7889 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2238, wps=97.8, ups=0.45, wpb=107.5, bsz=40, num_updates=7880, lr=4.85402e-05, gnorm=0.69, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29267
2023-01-08 06:58:53 - progress_bar.py[line:274] - INFO: epoch 001:   7899 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.225, wps=99.2, ups=0.46, wpb=107.9, bsz=40, num_updates=7890, lr=4.85357e-05, gnorm=0.687, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=29289
2023-01-08 06:59:15 - progress_bar.py[line:274] - INFO: epoch 001:   7909 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1735, wps=99.2, ups=0.46, wpb=107.2, bsz=40, num_updates=7900, lr=4.85312e-05, gnorm=0.575, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=29311
2023-01-08 06:59:37 - progress_bar.py[line:274] - INFO: epoch 001:   7919 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1935, wps=105, ups=0.47, wpb=111.1, bsz=40, num_updates=7910, lr=4.85267e-05, gnorm=0.47, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29332
2023-01-08 06:59:59 - progress_bar.py[line:274] - INFO: epoch 001:   7929 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2251, wps=100.8, ups=0.46, wpb=110.2, bsz=40, num_updates=7920, lr=4.85222e-05, gnorm=0.617, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=29355
2023-01-08 07:00:21 - progress_bar.py[line:274] - INFO: epoch 001:   7939 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2634, wps=103.4, ups=0.47, wpb=110, bsz=40, num_updates=7930, lr=4.85177e-05, gnorm=0.552, clip=10, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=29376
2023-01-08 07:00:43 - progress_bar.py[line:274] - INFO: epoch 001:   7949 / 115845 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2344, wps=100.7, ups=0.46, wpb=108.5, bsz=40, num_updates=7940, lr=4.85132e-05, gnorm=0.562, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29398
2023-01-08 07:01:05 - progress_bar.py[line:274] - INFO: epoch 001:   7959 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2953, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=7950, lr=4.85087e-05, gnorm=0.714, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29420
2023-01-08 07:01:26 - progress_bar.py[line:274] - INFO: epoch 001:   7969 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2315, wps=103.2, ups=0.47, wpb=108.8, bsz=40, num_updates=7960, lr=4.85042e-05, gnorm=0.68, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=29442
2023-01-08 07:01:48 - progress_bar.py[line:274] - INFO: epoch 001:   7979 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2602, wps=102.1, ups=0.46, wpb=110.2, bsz=40, num_updates=7970, lr=4.84997e-05, gnorm=0.548, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29464
2023-01-08 07:02:10 - progress_bar.py[line:274] - INFO: epoch 001:   7989 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.224, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=7980, lr=4.84952e-05, gnorm=0.486, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29486
2023-01-08 07:02:33 - progress_bar.py[line:274] - INFO: epoch 001:   7999 / 115845 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2714, wps=99.7, ups=0.46, wpb=108.9, bsz=40, num_updates=7990, lr=4.84907e-05, gnorm=0.595, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29508
2023-01-08 07:02:55 - progress_bar.py[line:274] - INFO: epoch 001:   8009 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.255, wps=99.8, ups=0.46, wpb=108.9, bsz=40, num_updates=8000, lr=4.84862e-05, gnorm=0.477, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29531
2023-01-08 07:02:55 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 07:02:56 - train.py[line:549] - INFO: 0 / 4988
2023-01-08 07:02:56 - train.py[line:551] - INFO: load:1.11 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 07:05:30 - train.py[line:549] - INFO: 200 / 4988
2023-01-08 07:05:30 - train.py[line:551] - INFO: load:1.14 valid_run:153.06 task_valid:149.45 collect_output:2.44
2023-01-08 07:07:58 - train.py[line:549] - INFO: 400 / 4988
2023-01-08 07:07:58 - train.py[line:551] - INFO: load:1.17 valid_run:301.88 task_valid:292.44 collect_output:7.21
2023-01-08 07:10:31 - train.py[line:549] - INFO: 600 / 4988
2023-01-08 07:10:31 - train.py[line:551] - INFO: load:1.20 valid_run:454.53 task_valid:435.24 collect_output:16.01
2023-01-08 07:13:01 - train.py[line:549] - INFO: 800 / 4988
2023-01-08 07:13:01 - train.py[line:551] - INFO: load:1.23 valid_run:603.92 task_valid:580.23 collect_output:19.35
2023-01-08 07:15:33 - train.py[line:549] - INFO: 1000 / 4988
2023-01-08 07:15:33 - train.py[line:551] - INFO: load:1.26 valid_run:756.24 task_valid:727.46 collect_output:23.38
2023-01-08 07:18:05 - train.py[line:549] - INFO: 1200 / 4988
2023-01-08 07:18:05 - train.py[line:551] - INFO: load:1.29 valid_run:908.08 task_valid:872.70 collect_output:28.92
2023-01-08 07:20:39 - train.py[line:549] - INFO: 1400 / 4988
2023-01-08 07:20:39 - train.py[line:551] - INFO: load:1.32 valid_run:1061.64 task_valid:1018.46 collect_output:35.68
2023-01-08 07:23:10 - train.py[line:549] - INFO: 1600 / 4988
2023-01-08 07:23:10 - train.py[line:551] - INFO: load:1.35 valid_run:1213.26 task_valid:1159.51 collect_output:45.20
2023-01-08 07:25:40 - train.py[line:549] - INFO: 1800 / 4988
2023-01-08 07:25:40 - train.py[line:551] - INFO: load:1.38 valid_run:1363.02 task_valid:1303.95 collect_output:49.48
2023-01-08 07:28:09 - train.py[line:549] - INFO: 2000 / 4988
2023-01-08 07:28:09 - train.py[line:551] - INFO: load:1.41 valid_run:1511.84 task_valid:1446.77 collect_output:54.44
2023-01-08 07:30:39 - train.py[line:549] - INFO: 2200 / 4988
2023-01-08 07:30:39 - train.py[line:551] - INFO: load:1.43 valid_run:1661.61 task_valid:1591.36 collect_output:58.60
2023-01-08 07:33:09 - train.py[line:549] - INFO: 2400 / 4988
2023-01-08 07:33:09 - train.py[line:551] - INFO: load:1.46 valid_run:1811.93 task_valid:1736.23 collect_output:63.01
2023-01-08 07:35:39 - train.py[line:549] - INFO: 2600 / 4988
2023-01-08 07:35:39 - train.py[line:551] - INFO: load:1.49 valid_run:1962.16 task_valid:1877.80 collect_output:70.63
2023-01-08 07:38:10 - train.py[line:549] - INFO: 2800 / 4988
2023-01-08 07:38:10 - train.py[line:551] - INFO: load:1.52 valid_run:2113.01 task_valid:2023.04 collect_output:75.20
2023-01-08 07:40:41 - train.py[line:549] - INFO: 3000 / 4988
2023-01-08 07:40:41 - train.py[line:551] - INFO: load:1.55 valid_run:2263.02 task_valid:2169.17 collect_output:78.03
2023-01-08 07:43:11 - train.py[line:549] - INFO: 3200 / 4988
2023-01-08 07:43:11 - train.py[line:551] - INFO: load:1.58 valid_run:2413.21 task_valid:2313.17 collect_output:83.18
2023-01-08 07:45:43 - train.py[line:549] - INFO: 3400 / 4988
2023-01-08 07:45:43 - train.py[line:551] - INFO: load:1.61 valid_run:2564.99 task_valid:2458.50 collect_output:88.58
2023-01-08 07:48:13 - train.py[line:549] - INFO: 3600 / 4988
2023-01-08 07:48:13 - train.py[line:551] - INFO: load:1.64 valid_run:2715.65 task_valid:2605.17 collect_output:91.52
2023-01-08 07:50:42 - train.py[line:549] - INFO: 3800 / 4988
2023-01-08 07:50:42 - train.py[line:551] - INFO: load:1.66 valid_run:2864.31 task_valid:2746.60 collect_output:97.70
2023-01-08 07:53:13 - train.py[line:549] - INFO: 4000 / 4988
2023-01-08 07:53:13 - train.py[line:551] - INFO: load:1.69 valid_run:3014.99 task_valid:2891.72 collect_output:102.20
2023-01-08 07:55:45 - train.py[line:549] - INFO: 4200 / 4988
2023-01-08 07:55:45 - train.py[line:551] - INFO: load:1.72 valid_run:3167.24 task_valid:3036.17 collect_output:108.96
2023-01-08 07:58:15 - train.py[line:549] - INFO: 4400 / 4988
2023-01-08 07:58:15 - train.py[line:551] - INFO: load:1.75 valid_run:3317.02 task_valid:3180.61 collect_output:113.24
2023-01-08 08:00:46 - train.py[line:549] - INFO: 4600 / 4988
2023-01-08 08:00:46 - train.py[line:551] - INFO: load:1.78 valid_run:3468.25 task_valid:3326.49 collect_output:117.55
2023-01-08 08:03:18 - train.py[line:549] - INFO: 4800 / 4988
2023-01-08 08:03:18 - train.py[line:551] - INFO: load:1.81 valid_run:3619.68 task_valid:3472.92 collect_output:121.51

====================================================================================================
SGG eval:     R @ 50: 0.5608;     R @ 100: 0.6226;     R @ 500: 0.6719;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3574;    mR @ 100: 0.4052;    mR @ 500: 0.4757;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7561) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4516) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.9183) (says:0.0000) (sitting on:0.7217) (standing on:0.2433) (using:0.6000) (walking in:0.0000) (walking on:0.7838) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-08 08:05:49 - train.py[line:487] - INFO: 0.6226448179271709

====================================================================================================
SGG eval:     R @ 50: 0.5608;     R @ 100: 0.6226;     R @ 500: 0.6719;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3574;    mR @ 100: 0.4052;    mR @ 500: 0.4757;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7561) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4516) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.9183) (says:0.0000) (sitting on:0.7217) (standing on:0.2433) (using:0.6000) (walking in:0.0000) (walking on:0.7838) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-08 08:05:49 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 08:05:49 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.365 | loss_v1 0 | loss_v2 0 | nll_loss 0.213 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.622645 | ppl 1.16 | vqa_score 0.5405 | wps 118.9 | wpb 89.9 | bsz 30 | num_updates 8000 | best_R@100 0.645421
2023-01-08 08:05:49 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2023-01-08 08:05:49 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_8000.pt
2023-01-08 08:06:30 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_8000.pt
2023-01-08 08:07:57 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.6226448179271709) (writing took 127.54290731996298 seconds)
2023-01-08 08:08:19 - progress_bar.py[line:274] - INFO: epoch 001:   8019 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2452, wps=0.6, ups=0, wpb=109.4, bsz=40, num_updates=8010, lr=4.84817e-05, gnorm=0.579, clip=0, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=33455
2023-01-08 08:08:41 - progress_bar.py[line:274] - INFO: epoch 001:   8029 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.255, wps=105.1, ups=0.48, wpb=110.2, bsz=40, num_updates=8020, lr=4.84772e-05, gnorm=0.74, clip=30, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=33476
2023-01-08 08:09:03 - progress_bar.py[line:274] - INFO: epoch 001:   8039 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2059, wps=99.9, ups=0.46, wpb=109.1, bsz=40, num_updates=8030, lr=4.84727e-05, gnorm=0.473, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=33499
2023-01-08 08:09:25 - progress_bar.py[line:274] - INFO: epoch 001:   8049 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2709, wps=102.3, ups=0.47, wpb=109.2, bsz=40, num_updates=8040, lr=4.84682e-05, gnorm=0.498, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33521
2023-01-08 08:09:47 - progress_bar.py[line:274] - INFO: epoch 001:   8059 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.276, wps=103.5, ups=0.47, wpb=109.5, bsz=40, num_updates=8050, lr=4.84637e-05, gnorm=0.455, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33543
2023-01-08 08:10:09 - progress_bar.py[line:274] - INFO: epoch 001:   8069 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2222, wps=103.6, ups=0.47, wpb=109.7, bsz=40, num_updates=8060, lr=4.84592e-05, gnorm=0.5, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=33564
2023-01-08 08:10:31 - progress_bar.py[line:274] - INFO: epoch 001:   8079 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2435, wps=102.1, ups=0.47, wpb=109.2, bsz=40, num_updates=8070, lr=4.84548e-05, gnorm=0.508, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=33586
2023-01-08 08:10:53 - progress_bar.py[line:274] - INFO: epoch 001:   8089 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.274, wps=101.2, ups=0.47, wpb=108.7, bsz=40, num_updates=8080, lr=4.84503e-05, gnorm=0.483, clip=0, loss_scale=512, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=33608
2023-01-08 08:11:15 - progress_bar.py[line:274] - INFO: epoch 001:   8099 / 115845 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2277, wps=99, ups=0.46, wpb=107.5, bsz=40, num_updates=8090, lr=4.84458e-05, gnorm=0.62, clip=10, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=33631
2023-01-08 08:11:37 - progress_bar.py[line:274] - INFO: epoch 001:   8109 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.206, wps=103.9, ups=0.47, wpb=110, bsz=40, num_updates=8100, lr=4.84413e-05, gnorm=0.525, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=33652
2023-01-08 08:11:59 - progress_bar.py[line:274] - INFO: epoch 001:   8119 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2618, wps=100.8, ups=0.46, wpb=109.3, bsz=40, num_updates=8110, lr=4.84368e-05, gnorm=0.52, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=33675
2023-01-08 08:12:22 - progress_bar.py[line:274] - INFO: epoch 001:   8129 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1902, wps=101, ups=0.46, wpb=109.8, bsz=40, num_updates=8120, lr=4.84323e-05, gnorm=0.435, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=33697
2023-01-08 08:12:43 - progress_bar.py[line:274] - INFO: epoch 001:   8139 / 115845 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.23, wps=101.4, ups=0.46, wpb=109.4, bsz=40, num_updates=8130, lr=4.84278e-05, gnorm=0.54, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=33719
2023-01-08 08:13:07 - progress_bar.py[line:274] - INFO: epoch 001:   8149 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2568, wps=99.7, ups=0.46, wpb=109.5, bsz=40, num_updates=8140, lr=4.84233e-05, gnorm=0.438, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=33741
2023-01-08 08:13:30 - progress_bar.py[line:274] - INFO: epoch 001:   8159 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3125, wps=101.9, ups=0.46, wpb=109.8, bsz=40, num_updates=8150, lr=4.84188e-05, gnorm=0.674, clip=30, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=33764
2023-01-08 08:13:53 - progress_bar.py[line:274] - INFO: epoch 001:   8169 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2087, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=8160, lr=4.84143e-05, gnorm=0.618, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=33787
2023-01-08 08:14:16 - progress_bar.py[line:274] - INFO: epoch 001:   8179 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3169, wps=103.2, ups=0.47, wpb=110.6, bsz=40, num_updates=8170, lr=4.84098e-05, gnorm=0.477, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=33810
2023-01-08 08:14:20 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 08:14:41 - progress_bar.py[line:274] - INFO: epoch 001:   8190 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.905, nsentences=40, sample_size=109.905, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2731, wps=97.7, ups=0.42, wpb=109.9, bsz=40, num_updates=8180, lr=4.84053e-05, gnorm=0.554, clip=0, loss_scale=512, train_wall=24, gb_free=10.5, ema_decay=0.9999, wall=33835
2023-01-08 08:15:04 - progress_bar.py[line:274] - INFO: epoch 001:   8200 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2663, wps=102, ups=0.46, wpb=109.7, bsz=40, num_updates=8190, lr=4.84008e-05, gnorm=0.463, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=33858
2023-01-08 08:15:26 - progress_bar.py[line:274] - INFO: epoch 001:   8210 / 115845 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2727, wps=101.5, ups=0.47, wpb=108.5, bsz=40, num_updates=8200, lr=4.83963e-05, gnorm=0.537, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=33881
2023-01-08 08:15:50 - progress_bar.py[line:274] - INFO: epoch 001:   8220 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2591, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=8210, lr=4.83918e-05, gnorm=0.501, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=33904
2023-01-08 08:16:13 - progress_bar.py[line:274] - INFO: epoch 001:   8230 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2559, wps=99.6, ups=0.46, wpb=109.1, bsz=40, num_updates=8220, lr=4.83873e-05, gnorm=0.649, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=33927
2023-01-08 08:16:35 - progress_bar.py[line:274] - INFO: epoch 001:   8240 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2745, wps=101.8, ups=0.47, wpb=108.5, bsz=40, num_updates=8230, lr=4.83828e-05, gnorm=0.568, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33950
2023-01-08 08:16:58 - progress_bar.py[line:274] - INFO: epoch 001:   8250 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2562, wps=99.2, ups=0.46, wpb=108.2, bsz=40, num_updates=8240, lr=4.83783e-05, gnorm=0.51, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=33973
2023-01-08 08:17:20 - progress_bar.py[line:274] - INFO: epoch 001:   8260 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3349, wps=99, ups=0.45, wpb=109.2, bsz=40, num_updates=8250, lr=4.83738e-05, gnorm=0.546, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=33996
2023-01-08 08:17:42 - progress_bar.py[line:274] - INFO: epoch 001:   8270 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2537, wps=99.9, ups=0.46, wpb=108.2, bsz=40, num_updates=8260, lr=4.83693e-05, gnorm=0.539, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34018
2023-01-08 08:18:04 - progress_bar.py[line:274] - INFO: epoch 001:   8280 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2684, wps=100.6, ups=0.46, wpb=109, bsz=40, num_updates=8270, lr=4.83648e-05, gnorm=0.518, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=34040
2023-01-08 08:18:26 - progress_bar.py[line:274] - INFO: epoch 001:   8290 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2446, wps=100.7, ups=0.46, wpb=109.9, bsz=40, num_updates=8280, lr=4.83603e-05, gnorm=0.427, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34062
2023-01-08 08:18:48 - progress_bar.py[line:274] - INFO: epoch 001:   8300 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.216, wps=99.7, ups=0.46, wpb=108, bsz=40, num_updates=8290, lr=4.83558e-05, gnorm=0.425, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=34084
2023-01-08 08:19:11 - progress_bar.py[line:274] - INFO: epoch 001:   8310 / 115845 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3216, wps=98.9, ups=0.45, wpb=109.3, bsz=40, num_updates=8300, lr=4.83513e-05, gnorm=0.666, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=34106
2023-01-08 08:19:32 - progress_bar.py[line:274] - INFO: epoch 001:   8320 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2747, wps=102.4, ups=0.47, wpb=109.8, bsz=40, num_updates=8310, lr=4.83469e-05, gnorm=0.801, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34128
2023-01-08 08:19:53 - progress_bar.py[line:274] - INFO: epoch 001:   8330 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2705, wps=102.9, ups=0.48, wpb=108.1, bsz=40, num_updates=8320, lr=4.83424e-05, gnorm=0.424, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34149
2023-01-08 08:20:15 - progress_bar.py[line:274] - INFO: epoch 001:   8340 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2663, wps=102, ups=0.47, wpb=109.5, bsz=40, num_updates=8330, lr=4.83379e-05, gnorm=0.568, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34171
2023-01-08 08:20:37 - progress_bar.py[line:274] - INFO: epoch 001:   8350 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2806, wps=101.1, ups=0.46, wpb=109.1, bsz=40, num_updates=8340, lr=4.83334e-05, gnorm=0.677, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34193
2023-01-08 08:20:59 - progress_bar.py[line:274] - INFO: epoch 001:   8360 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2913, wps=101.2, ups=0.46, wpb=109.5, bsz=40, num_updates=8350, lr=4.83289e-05, gnorm=0.439, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34215
2023-01-08 08:21:21 - progress_bar.py[line:274] - INFO: epoch 001:   8370 / 115845 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.266, wps=100.2, ups=0.46, wpb=109.3, bsz=40, num_updates=8360, lr=4.83244e-05, gnorm=0.654, clip=20, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=34237
2023-01-08 08:21:43 - progress_bar.py[line:274] - INFO: epoch 001:   8380 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2642, wps=101, ups=0.47, wpb=108.4, bsz=40, num_updates=8370, lr=4.83199e-05, gnorm=0.677, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34258
2023-01-08 08:22:05 - progress_bar.py[line:274] - INFO: epoch 001:   8390 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.25, wps=99, ups=0.46, wpb=108.7, bsz=40, num_updates=8380, lr=4.83154e-05, gnorm=0.535, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34281
2023-01-08 08:22:27 - progress_bar.py[line:274] - INFO: epoch 001:   8400 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2694, wps=101.2, ups=0.46, wpb=110, bsz=40, num_updates=8390, lr=4.83109e-05, gnorm=0.657, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34303
2023-01-08 08:22:36 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 08:22:51 - progress_bar.py[line:274] - INFO: epoch 001:   8411 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.905, nsentences=40, sample_size=108.905, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2748, wps=95.6, ups=0.42, wpb=108.9, bsz=40, num_updates=8400, lr=4.83064e-05, gnorm=0.551, clip=0, loss_scale=256, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=34327
2023-01-08 08:23:13 - progress_bar.py[line:274] - INFO: epoch 001:   8421 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2806, wps=101.3, ups=0.47, wpb=108.4, bsz=40, num_updates=8410, lr=4.83019e-05, gnorm=0.523, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34348
2023-01-08 08:23:34 - progress_bar.py[line:274] - INFO: epoch 001:   8431 / 115845 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3095, wps=102.4, ups=0.47, wpb=108.8, bsz=40, num_updates=8420, lr=4.82974e-05, gnorm=0.667, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=34370
2023-01-08 08:23:56 - progress_bar.py[line:274] - INFO: epoch 001:   8441 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2379, wps=102.9, ups=0.47, wpb=109.2, bsz=40, num_updates=8430, lr=4.82929e-05, gnorm=0.589, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34391
2023-01-08 08:24:17 - progress_bar.py[line:274] - INFO: epoch 001:   8451 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2406, wps=106.5, ups=0.48, wpb=111, bsz=40, num_updates=8440, lr=4.82884e-05, gnorm=0.476, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34413
2023-01-08 08:24:38 - progress_bar.py[line:274] - INFO: epoch 001:   8461 / 115845 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2538, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=8450, lr=4.82839e-05, gnorm=0.587, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34434
2023-01-08 08:25:00 - progress_bar.py[line:274] - INFO: epoch 001:   8471 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2902, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=8460, lr=4.82794e-05, gnorm=0.935, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34456
2023-01-08 08:25:22 - progress_bar.py[line:274] - INFO: epoch 001:   8481 / 115845 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.28, wps=100.2, ups=0.46, wpb=107.8, bsz=40, num_updates=8470, lr=4.82749e-05, gnorm=0.531, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=34478
2023-01-08 08:25:44 - progress_bar.py[line:274] - INFO: epoch 001:   8491 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2584, wps=99.5, ups=0.46, wpb=108.3, bsz=40, num_updates=8480, lr=4.82704e-05, gnorm=0.581, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34500
2023-01-08 08:26:06 - progress_bar.py[line:274] - INFO: epoch 001:   8501 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.305, wps=103.6, ups=0.47, wpb=109.7, bsz=40, num_updates=8490, lr=4.82659e-05, gnorm=0.673, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34521
2023-01-08 08:26:27 - progress_bar.py[line:274] - INFO: epoch 001:   8511 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.31, wps=102.5, ups=0.47, wpb=109.4, bsz=40, num_updates=8500, lr=4.82614e-05, gnorm=0.509, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34543
2023-01-08 08:26:49 - progress_bar.py[line:274] - INFO: epoch 001:   8521 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2513, wps=100.6, ups=0.46, wpb=110, bsz=40, num_updates=8510, lr=4.82569e-05, gnorm=0.591, clip=0, loss_scale=256, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=34565
2023-01-08 08:27:11 - progress_bar.py[line:274] - INFO: epoch 001:   8531 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2434, wps=100.3, ups=0.46, wpb=108.7, bsz=40, num_updates=8520, lr=4.82524e-05, gnorm=0.51, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=34587
2023-01-08 08:27:33 - progress_bar.py[line:274] - INFO: epoch 001:   8541 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2892, wps=102.1, ups=0.46, wpb=109.8, bsz=40, num_updates=8530, lr=4.82479e-05, gnorm=0.515, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34609
2023-01-08 08:27:54 - progress_bar.py[line:274] - INFO: epoch 001:   8551 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3081, wps=103.9, ups=0.48, wpb=109.3, bsz=40, num_updates=8540, lr=4.82434e-05, gnorm=0.489, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34630
2023-01-08 08:28:16 - progress_bar.py[line:274] - INFO: epoch 001:   8561 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2864, wps=102.3, ups=0.47, wpb=109.9, bsz=40, num_updates=8550, lr=4.82389e-05, gnorm=0.563, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34652
2023-01-08 08:28:38 - progress_bar.py[line:274] - INFO: epoch 001:   8571 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2713, wps=100.1, ups=0.46, wpb=109.3, bsz=40, num_updates=8560, lr=4.82345e-05, gnorm=0.739, clip=20, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=34674
2023-01-08 08:29:00 - progress_bar.py[line:274] - INFO: epoch 001:   8581 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3171, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=8570, lr=4.823e-05, gnorm=0.567, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34696
2023-01-08 08:29:22 - progress_bar.py[line:274] - INFO: epoch 001:   8591 / 115845 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2549, wps=98.9, ups=0.46, wpb=107.4, bsz=40, num_updates=8580, lr=4.82255e-05, gnorm=0.556, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34718
2023-01-08 08:29:43 - progress_bar.py[line:274] - INFO: epoch 001:   8601 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2587, wps=101.8, ups=0.47, wpb=109.3, bsz=40, num_updates=8590, lr=4.8221e-05, gnorm=0.426, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34739
2023-01-08 08:30:05 - progress_bar.py[line:274] - INFO: epoch 001:   8611 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2843, wps=101.9, ups=0.47, wpb=109.1, bsz=40, num_updates=8600, lr=4.82165e-05, gnorm=0.401, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34761
2023-01-08 08:30:28 - progress_bar.py[line:274] - INFO: epoch 001:   8621 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2772, wps=99.5, ups=0.46, wpb=108.8, bsz=40, num_updates=8610, lr=4.8212e-05, gnorm=0.413, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34783
2023-01-08 08:30:49 - progress_bar.py[line:274] - INFO: epoch 001:   8631 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3173, wps=102.6, ups=0.48, wpb=107.4, bsz=40, num_updates=8620, lr=4.82075e-05, gnorm=0.587, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34804
2023-01-08 08:31:11 - progress_bar.py[line:274] - INFO: epoch 001:   8641 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2736, wps=100.1, ups=0.46, wpb=108.8, bsz=40, num_updates=8630, lr=4.8203e-05, gnorm=0.572, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34827
2023-01-08 08:31:33 - progress_bar.py[line:274] - INFO: epoch 001:   8651 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2888, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=8640, lr=4.81985e-05, gnorm=0.659, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=34849
2023-01-08 08:31:55 - progress_bar.py[line:274] - INFO: epoch 001:   8661 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2806, wps=100.7, ups=0.46, wpb=109.2, bsz=40, num_updates=8650, lr=4.8194e-05, gnorm=0.573, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34870
2023-01-08 08:32:17 - progress_bar.py[line:274] - INFO: epoch 001:   8671 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2923, wps=102.6, ups=0.47, wpb=109.9, bsz=40, num_updates=8660, lr=4.81895e-05, gnorm=0.52, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34892
2023-01-08 08:32:38 - progress_bar.py[line:274] - INFO: epoch 001:   8681 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3395, wps=100.8, ups=0.47, wpb=107.8, bsz=40, num_updates=8670, lr=4.8185e-05, gnorm=0.699, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34914
2023-01-08 08:33:01 - progress_bar.py[line:274] - INFO: epoch 001:   8691 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2595, wps=99.8, ups=0.45, wpb=109.9, bsz=40, num_updates=8680, lr=4.81805e-05, gnorm=0.702, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34936
2023-01-08 08:33:23 - progress_bar.py[line:274] - INFO: epoch 001:   8701 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3128, wps=101.4, ups=0.46, wpb=109.3, bsz=40, num_updates=8690, lr=4.8176e-05, gnorm=0.63, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=34959
2023-01-08 08:33:45 - progress_bar.py[line:274] - INFO: epoch 001:   8711 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3058, wps=102.4, ups=0.47, wpb=109.4, bsz=40, num_updates=8700, lr=4.81715e-05, gnorm=0.728, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34980
2023-01-08 08:34:07 - progress_bar.py[line:274] - INFO: epoch 001:   8721 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2577, wps=101.7, ups=0.46, wpb=109.6, bsz=40, num_updates=8710, lr=4.8167e-05, gnorm=0.573, clip=10, loss_scale=256, train_wall=22, gb_free=9.5, ema_decay=0.9999, wall=35002
2023-01-08 08:34:29 - progress_bar.py[line:274] - INFO: epoch 001:   8731 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2513, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=8720, lr=4.81625e-05, gnorm=0.464, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35024
2023-01-08 08:34:50 - progress_bar.py[line:274] - INFO: epoch 001:   8741 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2889, wps=102.2, ups=0.46, wpb=110.1, bsz=40, num_updates=8730, lr=4.8158e-05, gnorm=0.511, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35046
2023-01-08 08:35:13 - progress_bar.py[line:274] - INFO: epoch 001:   8751 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3211, wps=99.6, ups=0.45, wpb=109.6, bsz=40, num_updates=8740, lr=4.81535e-05, gnorm=0.746, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35068
2023-01-08 08:35:34 - progress_bar.py[line:274] - INFO: epoch 001:   8761 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2598, wps=106.3, ups=0.48, wpb=110.4, bsz=40, num_updates=8750, lr=4.8149e-05, gnorm=0.6, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35090
2023-01-08 08:35:56 - progress_bar.py[line:274] - INFO: epoch 001:   8771 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2917, wps=98.6, ups=0.46, wpb=107.3, bsz=40, num_updates=8760, lr=4.81445e-05, gnorm=0.672, clip=20, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=35112
2023-01-08 08:36:18 - progress_bar.py[line:274] - INFO: epoch 001:   8781 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2947, wps=100.9, ups=0.47, wpb=107.7, bsz=40, num_updates=8770, lr=4.814e-05, gnorm=0.567, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35133
2023-01-08 08:36:40 - progress_bar.py[line:274] - INFO: epoch 001:   8791 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2915, wps=99.1, ups=0.46, wpb=108.2, bsz=40, num_updates=8780, lr=4.81355e-05, gnorm=0.629, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35156
2023-01-08 08:37:02 - progress_bar.py[line:274] - INFO: epoch 001:   8801 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2371, wps=101.7, ups=0.46, wpb=109.9, bsz=40, num_updates=8790, lr=4.8131e-05, gnorm=0.601, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=35177
2023-01-08 08:37:23 - progress_bar.py[line:274] - INFO: epoch 001:   8811 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3246, wps=103.8, ups=0.48, wpb=109.2, bsz=40, num_updates=8800, lr=4.81266e-05, gnorm=0.651, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35199
2023-01-08 08:37:45 - progress_bar.py[line:274] - INFO: epoch 001:   8821 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3368, wps=103.1, ups=0.47, wpb=110.3, bsz=40, num_updates=8810, lr=4.81221e-05, gnorm=0.485, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35220
2023-01-08 08:38:06 - progress_bar.py[line:274] - INFO: epoch 001:   8831 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3122, wps=100.9, ups=0.46, wpb=109.2, bsz=40, num_updates=8820, lr=4.81176e-05, gnorm=0.497, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35242
2023-01-08 08:38:28 - progress_bar.py[line:274] - INFO: epoch 001:   8841 / 115845 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2893, wps=104.3, ups=0.48, wpb=109.1, bsz=40, num_updates=8830, lr=4.81131e-05, gnorm=0.562, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=35263
2023-01-08 08:38:50 - progress_bar.py[line:274] - INFO: epoch 001:   8851 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3073, wps=101, ups=0.46, wpb=110.3, bsz=40, num_updates=8840, lr=4.81086e-05, gnorm=1.095, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=35286
2023-01-08 08:39:11 - progress_bar.py[line:274] - INFO: epoch 001:   8861 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=106.7, nsentences=40, sample_size=106.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3142, wps=100.4, ups=0.47, wpb=106.7, bsz=40, num_updates=8850, lr=4.81041e-05, gnorm=0.469, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35307
2023-01-08 08:39:33 - progress_bar.py[line:274] - INFO: epoch 001:   8871 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3226, wps=100.9, ups=0.46, wpb=109.3, bsz=40, num_updates=8860, lr=4.80996e-05, gnorm=0.435, clip=0, loss_scale=256, train_wall=22, gb_free=9.5, ema_decay=0.9999, wall=35329
2023-01-08 08:39:55 - progress_bar.py[line:274] - INFO: epoch 001:   8881 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3571, wps=102.6, ups=0.47, wpb=108.8, bsz=40, num_updates=8870, lr=4.80951e-05, gnorm=0.429, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35350
2023-01-08 08:40:16 - progress_bar.py[line:274] - INFO: epoch 001:   8891 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3252, wps=102.1, ups=0.47, wpb=108.9, bsz=40, num_updates=8880, lr=4.80906e-05, gnorm=0.482, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=35372
2023-01-08 08:40:38 - progress_bar.py[line:274] - INFO: epoch 001:   8901 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3218, wps=103.5, ups=0.48, wpb=108.5, bsz=40, num_updates=8890, lr=4.80861e-05, gnorm=0.741, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35393
2023-01-08 08:41:00 - progress_bar.py[line:274] - INFO: epoch 001:   8911 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2414, wps=100.5, ups=0.46, wpb=109.5, bsz=40, num_updates=8900, lr=4.80816e-05, gnorm=0.461, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35415
2023-01-08 08:41:21 - progress_bar.py[line:274] - INFO: epoch 001:   8921 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2821, wps=102.5, ups=0.47, wpb=108.6, bsz=40, num_updates=8910, lr=4.80771e-05, gnorm=0.428, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35437
2023-01-08 08:41:43 - progress_bar.py[line:274] - INFO: epoch 001:   8931 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3192, wps=100.5, ups=0.46, wpb=108.1, bsz=40, num_updates=8920, lr=4.80726e-05, gnorm=0.497, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35459
2023-01-08 08:42:05 - progress_bar.py[line:274] - INFO: epoch 001:   8941 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3095, wps=100, ups=0.46, wpb=108.2, bsz=40, num_updates=8930, lr=4.80681e-05, gnorm=0.342, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35481
2023-01-08 08:42:27 - progress_bar.py[line:274] - INFO: epoch 001:   8951 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.288, wps=101, ups=0.46, wpb=110.6, bsz=40, num_updates=8940, lr=4.80636e-05, gnorm=0.564, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35503
2023-01-08 08:42:49 - progress_bar.py[line:274] - INFO: epoch 001:   8961 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3436, wps=100, ups=0.46, wpb=108.7, bsz=40, num_updates=8950, lr=4.80591e-05, gnorm=0.446, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=35525
2023-01-08 08:43:11 - progress_bar.py[line:274] - INFO: epoch 001:   8971 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3224, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=8960, lr=4.80546e-05, gnorm=0.488, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35546
2023-01-08 08:43:32 - progress_bar.py[line:274] - INFO: epoch 001:   8981 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3211, wps=104.9, ups=0.47, wpb=111, bsz=40, num_updates=8970, lr=4.80501e-05, gnorm=0.398, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35568
2023-01-08 08:43:54 - progress_bar.py[line:274] - INFO: epoch 001:   8991 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2565, wps=100.5, ups=0.46, wpb=108.3, bsz=40, num_updates=8980, lr=4.80456e-05, gnorm=0.589, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=35590
2023-01-08 08:44:15 - progress_bar.py[line:274] - INFO: epoch 001:   9001 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3125, wps=103.1, ups=0.47, wpb=109.9, bsz=40, num_updates=8990, lr=4.80411e-05, gnorm=0.496, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35611
2023-01-08 08:44:37 - progress_bar.py[line:274] - INFO: epoch 001:   9011 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3109, wps=103.9, ups=0.47, wpb=110.7, bsz=40, num_updates=9000, lr=4.80366e-05, gnorm=0.528, clip=10, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=35633
2023-01-08 08:44:59 - progress_bar.py[line:274] - INFO: epoch 001:   9021 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.299, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=9010, lr=4.80321e-05, gnorm=0.461, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35655
2023-01-08 08:45:21 - progress_bar.py[line:274] - INFO: epoch 001:   9031 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3717, wps=103.6, ups=0.47, wpb=110.5, bsz=40, num_updates=9020, lr=4.80276e-05, gnorm=0.496, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=35676
2023-01-08 08:45:43 - progress_bar.py[line:274] - INFO: epoch 001:   9041 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2843, wps=99.6, ups=0.46, wpb=108.5, bsz=40, num_updates=9030, lr=4.80231e-05, gnorm=0.645, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=35698
2023-01-08 08:46:04 - progress_bar.py[line:274] - INFO: epoch 001:   9051 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3192, wps=101, ups=0.47, wpb=108.3, bsz=40, num_updates=9040, lr=4.80186e-05, gnorm=0.522, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35720
2023-01-08 08:46:26 - progress_bar.py[line:274] - INFO: epoch 001:   9061 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.371, wps=102.6, ups=0.47, wpb=108.8, bsz=40, num_updates=9050, lr=4.80142e-05, gnorm=0.451, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35741
2023-01-08 08:46:48 - progress_bar.py[line:274] - INFO: epoch 001:   9071 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2929, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=9060, lr=4.80097e-05, gnorm=0.464, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35763
2023-01-08 08:47:09 - progress_bar.py[line:274] - INFO: epoch 001:   9081 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3614, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=9070, lr=4.80052e-05, gnorm=0.455, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=35785
2023-01-08 08:47:31 - progress_bar.py[line:274] - INFO: epoch 001:   9091 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3632, wps=100.4, ups=0.46, wpb=108.5, bsz=40, num_updates=9080, lr=4.80007e-05, gnorm=0.518, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=35807
2023-01-08 08:47:53 - progress_bar.py[line:274] - INFO: epoch 001:   9101 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2974, wps=102.9, ups=0.47, wpb=108.5, bsz=40, num_updates=9090, lr=4.79962e-05, gnorm=0.708, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=35828
2023-01-08 08:48:15 - progress_bar.py[line:274] - INFO: epoch 001:   9111 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3096, wps=101.8, ups=0.46, wpb=110.6, bsz=40, num_updates=9100, lr=4.79917e-05, gnorm=0.603, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=35850
2023-01-08 08:48:36 - progress_bar.py[line:274] - INFO: epoch 001:   9121 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3871, wps=103.2, ups=0.47, wpb=110.5, bsz=40, num_updates=9110, lr=4.79872e-05, gnorm=0.506, clip=10, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=35872
2023-01-08 08:48:58 - progress_bar.py[line:274] - INFO: epoch 001:   9131 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3247, wps=102.5, ups=0.47, wpb=109.5, bsz=40, num_updates=9120, lr=4.79827e-05, gnorm=0.524, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35894
2023-01-08 08:49:20 - progress_bar.py[line:274] - INFO: epoch 001:   9141 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2618, wps=99.1, ups=0.45, wpb=109.5, bsz=40, num_updates=9130, lr=4.79782e-05, gnorm=0.476, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35916
2023-01-08 08:49:42 - progress_bar.py[line:274] - INFO: epoch 001:   9151 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3024, wps=98.3, ups=0.45, wpb=108.2, bsz=40, num_updates=9140, lr=4.79737e-05, gnorm=0.572, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=35938
2023-01-08 08:50:04 - progress_bar.py[line:274] - INFO: epoch 001:   9161 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.29, wps=100.7, ups=0.46, wpb=108.5, bsz=40, num_updates=9150, lr=4.79692e-05, gnorm=0.53, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=35960
2023-01-08 08:50:26 - progress_bar.py[line:274] - INFO: epoch 001:   9171 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3285, wps=99.7, ups=0.46, wpb=107.4, bsz=40, num_updates=9160, lr=4.79647e-05, gnorm=0.448, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=35982
2023-01-08 08:50:47 - progress_bar.py[line:274] - INFO: epoch 001:   9181 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.341, wps=101.2, ups=0.47, wpb=108, bsz=40, num_updates=9170, lr=4.79602e-05, gnorm=0.608, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36003
2023-01-08 08:51:09 - progress_bar.py[line:274] - INFO: epoch 001:   9191 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3381, wps=100.4, ups=0.46, wpb=108.5, bsz=40, num_updates=9180, lr=4.79557e-05, gnorm=0.467, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36025
2023-01-08 08:51:31 - progress_bar.py[line:274] - INFO: epoch 001:   9201 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3135, wps=103, ups=0.47, wpb=109.9, bsz=40, num_updates=9190, lr=4.79512e-05, gnorm=0.555, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36047
2023-01-08 08:51:53 - progress_bar.py[line:274] - INFO: epoch 001:   9211 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.297, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=9200, lr=4.79467e-05, gnorm=0.53, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=36068
2023-01-08 08:52:15 - progress_bar.py[line:274] - INFO: epoch 001:   9221 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.257, wps=100.6, ups=0.46, wpb=109.5, bsz=40, num_updates=9210, lr=4.79422e-05, gnorm=0.499, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=36090
2023-01-08 08:52:37 - progress_bar.py[line:274] - INFO: epoch 001:   9231 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2935, wps=100.5, ups=0.46, wpb=110.3, bsz=40, num_updates=9220, lr=4.79377e-05, gnorm=0.543, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36113
2023-01-08 08:52:59 - progress_bar.py[line:274] - INFO: epoch 001:   9241 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3077, wps=100.3, ups=0.46, wpb=109.2, bsz=40, num_updates=9230, lr=4.79332e-05, gnorm=0.433, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36135
2023-01-08 08:53:21 - progress_bar.py[line:274] - INFO: epoch 001:   9251 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3462, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=9240, lr=4.79287e-05, gnorm=0.58, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36156
2023-01-08 08:53:42 - progress_bar.py[line:274] - INFO: epoch 001:   9261 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2708, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=9250, lr=4.79242e-05, gnorm=0.334, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36178
2023-01-08 08:54:04 - progress_bar.py[line:274] - INFO: epoch 001:   9271 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3866, wps=101.7, ups=0.47, wpb=108.6, bsz=40, num_updates=9260, lr=4.79197e-05, gnorm=0.457, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36200
2023-01-08 08:54:26 - progress_bar.py[line:274] - INFO: epoch 001:   9281 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3085, wps=102.4, ups=0.47, wpb=108.8, bsz=40, num_updates=9270, lr=4.79152e-05, gnorm=0.509, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=36221
2023-01-08 08:54:47 - progress_bar.py[line:274] - INFO: epoch 001:   9291 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3095, wps=102.1, ups=0.47, wpb=109, bsz=40, num_updates=9280, lr=4.79107e-05, gnorm=0.428, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36243
2023-01-08 08:55:09 - progress_bar.py[line:274] - INFO: epoch 001:   9301 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3177, wps=102.6, ups=0.47, wpb=108.4, bsz=40, num_updates=9290, lr=4.79063e-05, gnorm=0.495, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=36264
2023-01-08 08:55:30 - progress_bar.py[line:274] - INFO: epoch 001:   9311 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3673, wps=102, ups=0.47, wpb=109.5, bsz=40, num_updates=9300, lr=4.79018e-05, gnorm=0.504, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36286
2023-01-08 08:55:52 - progress_bar.py[line:274] - INFO: epoch 001:   9321 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3333, wps=100.6, ups=0.46, wpb=108.3, bsz=40, num_updates=9310, lr=4.78973e-05, gnorm=0.557, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36308
2023-01-08 08:56:14 - progress_bar.py[line:274] - INFO: epoch 001:   9331 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3744, wps=100.3, ups=0.46, wpb=107.9, bsz=40, num_updates=9320, lr=4.78928e-05, gnorm=0.596, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36330
2023-01-08 08:56:36 - progress_bar.py[line:274] - INFO: epoch 001:   9341 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3062, wps=101.2, ups=0.47, wpb=107.9, bsz=40, num_updates=9330, lr=4.78883e-05, gnorm=0.507, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36351
2023-01-08 08:56:58 - progress_bar.py[line:274] - INFO: epoch 001:   9351 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2959, wps=100.3, ups=0.46, wpb=108.6, bsz=40, num_updates=9340, lr=4.78838e-05, gnorm=0.395, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=36373
2023-01-08 08:57:20 - progress_bar.py[line:274] - INFO: epoch 001:   9361 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3214, wps=99.2, ups=0.46, wpb=108.7, bsz=40, num_updates=9350, lr=4.78793e-05, gnorm=0.473, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=36396
2023-01-08 08:57:42 - progress_bar.py[line:274] - INFO: epoch 001:   9371 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.402, wps=100.2, ups=0.46, wpb=109.6, bsz=40, num_updates=9360, lr=4.78748e-05, gnorm=0.684, clip=30, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=36418
2023-01-08 08:58:03 - progress_bar.py[line:274] - INFO: epoch 001:   9381 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3564, wps=101.8, ups=0.47, wpb=108.2, bsz=40, num_updates=9370, lr=4.78703e-05, gnorm=0.466, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=36439
2023-01-08 08:58:25 - progress_bar.py[line:274] - INFO: epoch 001:   9391 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3043, wps=101.5, ups=0.46, wpb=109.4, bsz=40, num_updates=9380, lr=4.78658e-05, gnorm=0.593, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=36461
2023-01-08 08:58:47 - progress_bar.py[line:274] - INFO: epoch 001:   9401 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3902, wps=100.2, ups=0.46, wpb=108.8, bsz=40, num_updates=9390, lr=4.78613e-05, gnorm=0.669, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=36483
2023-01-08 08:59:09 - progress_bar.py[line:274] - INFO: epoch 001:   9411 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3128, wps=101.3, ups=0.46, wpb=109, bsz=40, num_updates=9400, lr=4.78568e-05, gnorm=0.522, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=36505
2023-01-08 08:59:30 - progress_bar.py[line:274] - INFO: epoch 001:   9421 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2919, wps=104.4, ups=0.47, wpb=111.4, bsz=40, num_updates=9410, lr=4.78523e-05, gnorm=0.403, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36526
2023-01-08 08:59:52 - progress_bar.py[line:274] - INFO: epoch 001:   9431 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3119, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=9420, lr=4.78478e-05, gnorm=0.509, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=36548
2023-01-08 09:00:14 - progress_bar.py[line:274] - INFO: epoch 001:   9441 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.32, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=9430, lr=4.78433e-05, gnorm=0.414, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=36570
2023-01-08 09:00:35 - progress_bar.py[line:274] - INFO: epoch 001:   9451 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3317, wps=103, ups=0.47, wpb=109.1, bsz=40, num_updates=9440, lr=4.78388e-05, gnorm=0.63, clip=20, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36591
2023-01-08 09:00:56 - progress_bar.py[line:274] - INFO: epoch 001:   9461 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2843, wps=104.3, ups=0.48, wpb=109.5, bsz=40, num_updates=9450, lr=4.78343e-05, gnorm=0.593, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36612
2023-01-08 09:01:19 - progress_bar.py[line:274] - INFO: epoch 001:   9471 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2886, wps=98.4, ups=0.46, wpb=108, bsz=40, num_updates=9460, lr=4.78298e-05, gnorm=0.497, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36634
2023-01-08 09:01:41 - progress_bar.py[line:274] - INFO: epoch 001:   9481 / 115845 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3704, wps=99.6, ups=0.46, wpb=108.4, bsz=40, num_updates=9470, lr=4.78253e-05, gnorm=0.47, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=36656
2023-01-08 09:02:02 - progress_bar.py[line:274] - INFO: epoch 001:   9491 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3413, wps=101.9, ups=0.47, wpb=107.9, bsz=40, num_updates=9480, lr=4.78208e-05, gnorm=0.51, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36678
2023-01-08 09:02:23 - progress_bar.py[line:274] - INFO: epoch 001:   9501 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3403, wps=103, ups=0.47, wpb=109.1, bsz=40, num_updates=9490, lr=4.78163e-05, gnorm=0.546, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36699
2023-01-08 09:02:45 - progress_bar.py[line:274] - INFO: epoch 001:   9511 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3649, wps=101.8, ups=0.47, wpb=108.4, bsz=40, num_updates=9500, lr=4.78118e-05, gnorm=0.431, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=36721
2023-01-08 09:03:07 - progress_bar.py[line:274] - INFO: epoch 001:   9521 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3535, wps=102.1, ups=0.47, wpb=109.4, bsz=40, num_updates=9510, lr=4.78073e-05, gnorm=0.398, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36742
2023-01-08 09:03:28 - progress_bar.py[line:274] - INFO: epoch 001:   9531 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3553, wps=101.6, ups=0.47, wpb=108.7, bsz=40, num_updates=9520, lr=4.78028e-05, gnorm=0.543, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36764
2023-01-08 09:03:49 - progress_bar.py[line:274] - INFO: epoch 001:   9541 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3317, wps=103.6, ups=0.48, wpb=107.8, bsz=40, num_updates=9530, lr=4.77983e-05, gnorm=0.573, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36785
2023-01-08 09:03:58 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 09:04:13 - progress_bar.py[line:274] - INFO: epoch 001:   9552 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.667, nsentences=40, sample_size=109.667, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.344, wps=97.1, ups=0.42, wpb=109.7, bsz=40, num_updates=9540, lr=4.77939e-05, gnorm=0.431, clip=0, loss_scale=512, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=36809
2023-01-08 09:04:35 - progress_bar.py[line:274] - INFO: epoch 001:   9562 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2713, wps=101.9, ups=0.46, wpb=110.3, bsz=40, num_updates=9550, lr=4.77894e-05, gnorm=0.529, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=36831
2023-01-08 09:04:57 - progress_bar.py[line:274] - INFO: epoch 001:   9572 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3524, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=9560, lr=4.77849e-05, gnorm=0.455, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36853
2023-01-08 09:05:19 - progress_bar.py[line:274] - INFO: epoch 001:   9582 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3155, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=9570, lr=4.77804e-05, gnorm=0.504, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36874
2023-01-08 09:05:40 - progress_bar.py[line:274] - INFO: epoch 001:   9592 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3592, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=9580, lr=4.77759e-05, gnorm=0.543, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=36896
2023-01-08 09:06:02 - progress_bar.py[line:274] - INFO: epoch 001:   9602 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3022, wps=102.1, ups=0.46, wpb=110.1, bsz=40, num_updates=9590, lr=4.77714e-05, gnorm=0.369, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36918
2023-01-08 09:06:24 - progress_bar.py[line:274] - INFO: epoch 001:   9612 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3264, wps=100.3, ups=0.46, wpb=109, bsz=40, num_updates=9600, lr=4.77669e-05, gnorm=0.485, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36940
2023-01-08 09:06:45 - progress_bar.py[line:274] - INFO: epoch 001:   9622 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3069, wps=102.8, ups=0.48, wpb=107.8, bsz=40, num_updates=9610, lr=4.77624e-05, gnorm=0.563, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36961
2023-01-08 09:07:07 - progress_bar.py[line:274] - INFO: epoch 001:   9632 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3673, wps=101.6, ups=0.47, wpb=108.4, bsz=40, num_updates=9620, lr=4.77579e-05, gnorm=0.489, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=36983
2023-01-08 09:07:29 - progress_bar.py[line:274] - INFO: epoch 001:   9642 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3269, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=9630, lr=4.77534e-05, gnorm=0.415, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37005
2023-01-08 09:07:50 - progress_bar.py[line:274] - INFO: epoch 001:   9652 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3604, wps=102.9, ups=0.47, wpb=109.8, bsz=40, num_updates=9640, lr=4.77489e-05, gnorm=0.475, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=37026
2023-01-08 09:08:12 - progress_bar.py[line:274] - INFO: epoch 001:   9662 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3614, wps=102.2, ups=0.47, wpb=109.4, bsz=40, num_updates=9650, lr=4.77444e-05, gnorm=0.325, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37048
2023-01-08 09:08:34 - progress_bar.py[line:274] - INFO: epoch 001:   9672 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3128, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=9660, lr=4.77399e-05, gnorm=0.531, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37070
2023-01-08 09:08:56 - progress_bar.py[line:274] - INFO: epoch 001:   9682 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3093, wps=100.6, ups=0.46, wpb=109.5, bsz=40, num_updates=9670, lr=4.77354e-05, gnorm=0.578, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37092
2023-01-08 09:09:18 - progress_bar.py[line:274] - INFO: epoch 001:   9692 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3027, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=9680, lr=4.77309e-05, gnorm=0.574, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37113
2023-01-08 09:09:39 - progress_bar.py[line:274] - INFO: epoch 001:   9702 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3607, wps=105, ups=0.48, wpb=109.2, bsz=40, num_updates=9690, lr=4.77264e-05, gnorm=0.57, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37134
2023-01-08 09:10:00 - progress_bar.py[line:274] - INFO: epoch 001:   9712 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=101.7, ups=0.46, wpb=109.9, bsz=40, num_updates=9700, lr=4.77219e-05, gnorm=0.625, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37156
2023-01-08 09:10:23 - progress_bar.py[line:274] - INFO: epoch 001:   9722 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.393, wps=99.4, ups=0.46, wpb=109, bsz=40, num_updates=9710, lr=4.77174e-05, gnorm=0.594, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=37178
2023-01-08 09:10:45 - progress_bar.py[line:274] - INFO: epoch 001:   9732 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3271, wps=100.3, ups=0.46, wpb=108.1, bsz=40, num_updates=9720, lr=4.77129e-05, gnorm=0.455, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37200
2023-01-08 09:11:06 - progress_bar.py[line:274] - INFO: epoch 001:   9742 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3352, wps=104.1, ups=0.47, wpb=109.8, bsz=40, num_updates=9730, lr=4.77084e-05, gnorm=0.528, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37222
2023-01-08 09:11:28 - progress_bar.py[line:274] - INFO: epoch 001:   9752 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3816, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=9740, lr=4.77039e-05, gnorm=0.369, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37243
2023-01-08 09:11:49 - progress_bar.py[line:274] - INFO: epoch 001:   9762 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.352, wps=103.1, ups=0.47, wpb=110.3, bsz=40, num_updates=9750, lr=4.76994e-05, gnorm=0.468, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37265
2023-01-08 09:12:11 - progress_bar.py[line:274] - INFO: epoch 001:   9772 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.352, wps=102.1, ups=0.47, wpb=107.9, bsz=40, num_updates=9760, lr=4.76949e-05, gnorm=0.44, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37286
2023-01-08 09:12:32 - progress_bar.py[line:274] - INFO: epoch 001:   9782 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3673, wps=101.9, ups=0.47, wpb=109.2, bsz=40, num_updates=9770, lr=4.76904e-05, gnorm=0.595, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37308
2023-01-08 09:12:54 - progress_bar.py[line:274] - INFO: epoch 001:   9792 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3125, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=9780, lr=4.7686e-05, gnorm=0.422, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37330
2023-01-08 09:13:16 - progress_bar.py[line:274] - INFO: epoch 001:   9802 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3163, wps=100, ups=0.46, wpb=108.8, bsz=40, num_updates=9790, lr=4.76815e-05, gnorm=0.547, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=37352
2023-01-08 09:13:38 - progress_bar.py[line:274] - INFO: epoch 001:   9812 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4239, wps=100.7, ups=0.46, wpb=109.8, bsz=40, num_updates=9800, lr=4.7677e-05, gnorm=0.446, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=37374
2023-01-08 09:14:00 - progress_bar.py[line:274] - INFO: epoch 001:   9822 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3894, wps=102.9, ups=0.47, wpb=110.3, bsz=40, num_updates=9810, lr=4.76725e-05, gnorm=0.506, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=37396
2023-01-08 09:14:22 - progress_bar.py[line:274] - INFO: epoch 001:   9832 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3128, wps=102.1, ups=0.47, wpb=109.5, bsz=40, num_updates=9820, lr=4.7668e-05, gnorm=0.633, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37418
2023-01-08 09:14:43 - progress_bar.py[line:274] - INFO: epoch 001:   9842 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3333, wps=104.5, ups=0.47, wpb=110.3, bsz=40, num_updates=9830, lr=4.76635e-05, gnorm=0.535, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37439
2023-01-08 09:15:05 - progress_bar.py[line:274] - INFO: epoch 001:   9852 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3684, wps=101.4, ups=0.46, wpb=110, bsz=40, num_updates=9840, lr=4.7659e-05, gnorm=0.483, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37461
2023-01-08 09:15:27 - progress_bar.py[line:274] - INFO: epoch 001:   9862 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3524, wps=102, ups=0.47, wpb=108.1, bsz=40, num_updates=9850, lr=4.76545e-05, gnorm=0.367, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=37482
2023-01-08 09:15:48 - progress_bar.py[line:274] - INFO: epoch 001:   9872 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3886, wps=101.9, ups=0.47, wpb=108.5, bsz=40, num_updates=9860, lr=4.765e-05, gnorm=0.792, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37504
2023-01-08 09:16:09 - progress_bar.py[line:274] - INFO: epoch 001:   9882 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3333, wps=103.8, ups=0.48, wpb=108.8, bsz=40, num_updates=9870, lr=4.76455e-05, gnorm=0.475, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37525
2023-01-08 09:16:31 - progress_bar.py[line:274] - INFO: epoch 001:   9892 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3586, wps=101, ups=0.46, wpb=109.9, bsz=40, num_updates=9880, lr=4.7641e-05, gnorm=0.465, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37547
2023-01-08 09:16:53 - progress_bar.py[line:274] - INFO: epoch 001:   9902 / 115845 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3081, wps=103.1, ups=0.47, wpb=109.6, bsz=40, num_updates=9890, lr=4.76365e-05, gnorm=0.425, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37569
2023-01-08 09:17:14 - progress_bar.py[line:274] - INFO: epoch 001:   9912 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4019, wps=101.5, ups=0.47, wpb=108.4, bsz=40, num_updates=9900, lr=4.7632e-05, gnorm=0.485, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37590
2023-01-08 09:17:36 - progress_bar.py[line:274] - INFO: epoch 001:   9922 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.283, wps=100.2, ups=0.46, wpb=107.9, bsz=40, num_updates=9910, lr=4.76275e-05, gnorm=0.504, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37612
2023-01-08 09:17:58 - progress_bar.py[line:274] - INFO: epoch 001:   9932 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.38, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=9920, lr=4.7623e-05, gnorm=0.499, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=37634
2023-01-08 09:18:20 - progress_bar.py[line:274] - INFO: epoch 001:   9942 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3519, wps=99.8, ups=0.46, wpb=108.7, bsz=40, num_updates=9930, lr=4.76185e-05, gnorm=0.467, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=37656
2023-01-08 09:18:42 - progress_bar.py[line:274] - INFO: epoch 001:   9952 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3611, wps=100.1, ups=0.46, wpb=107.8, bsz=40, num_updates=9940, lr=4.7614e-05, gnorm=0.555, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37678
2023-01-08 09:19:04 - progress_bar.py[line:274] - INFO: epoch 001:   9962 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3459, wps=99.8, ups=0.46, wpb=109.6, bsz=40, num_updates=9950, lr=4.76095e-05, gnorm=0.514, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=37700
2023-01-08 09:19:26 - progress_bar.py[line:274] - INFO: epoch 001:   9972 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3805, wps=101.8, ups=0.47, wpb=109.2, bsz=40, num_updates=9960, lr=4.7605e-05, gnorm=0.72, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37721
2023-01-08 09:19:48 - progress_bar.py[line:274] - INFO: epoch 001:   9982 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.396, wps=101, ups=0.46, wpb=109.2, bsz=40, num_updates=9970, lr=4.76005e-05, gnorm=0.585, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37743
2023-01-08 09:20:09 - progress_bar.py[line:274] - INFO: epoch 001:   9992 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3636, wps=102.3, ups=0.47, wpb=109.1, bsz=40, num_updates=9980, lr=4.7596e-05, gnorm=0.408, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=37765
2023-01-08 09:20:31 - progress_bar.py[line:274] - INFO: epoch 001:  10002 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3421, wps=101, ups=0.46, wpb=110.7, bsz=40, num_updates=9990, lr=4.75915e-05, gnorm=0.425, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=37787
2023-01-08 09:20:53 - progress_bar.py[line:274] - INFO: epoch 001:  10012 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4091, wps=100.5, ups=0.46, wpb=109, bsz=40, num_updates=10000, lr=4.7587e-05, gnorm=0.562, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=37809
2023-01-08 09:20:53 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 09:20:55 - train.py[line:549] - INFO: 0 / 4988
2023-01-08 09:20:55 - train.py[line:551] - INFO: load:1.06 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 09:23:27 - train.py[line:549] - INFO: 200 / 4988
2023-01-08 09:23:27 - train.py[line:551] - INFO: load:1.09 valid_run:151.94 task_valid:148.20 collect_output:2.60
2023-01-08 09:25:55 - train.py[line:549] - INFO: 400 / 4988
2023-01-08 09:25:55 - train.py[line:551] - INFO: load:1.12 valid_run:300.61 task_valid:291.32 collect_output:7.08
2023-01-08 09:28:28 - train.py[line:549] - INFO: 600 / 4988
2023-01-08 09:28:28 - train.py[line:551] - INFO: load:1.15 valid_run:452.95 task_valid:434.08 collect_output:15.60
2023-01-08 09:30:57 - train.py[line:549] - INFO: 800 / 4988
2023-01-08 09:30:57 - train.py[line:551] - INFO: load:1.18 valid_run:602.18 task_valid:578.85 collect_output:19.01
2023-01-08 09:33:29 - train.py[line:549] - INFO: 1000 / 4988
2023-01-08 09:33:29 - train.py[line:551] - INFO: load:1.21 valid_run:754.45 task_valid:726.07 collect_output:23.02
2023-01-08 09:36:01 - train.py[line:549] - INFO: 1200 / 4988
2023-01-08 09:36:01 - train.py[line:551] - INFO: load:1.24 valid_run:906.35 task_valid:871.45 collect_output:28.49
2023-01-08 09:38:35 - train.py[line:549] - INFO: 1400 / 4988
2023-01-08 09:38:35 - train.py[line:551] - INFO: load:1.27 valid_run:1059.79 task_valid:1017.27 collect_output:35.04
2023-01-08 09:41:07 - train.py[line:549] - INFO: 1600 / 4988
2023-01-08 09:41:07 - train.py[line:551] - INFO: load:1.30 valid_run:1211.28 task_valid:1158.12 collect_output:44.64
2023-01-08 09:43:36 - train.py[line:549] - INFO: 1800 / 4988
2023-01-08 09:43:36 - train.py[line:551] - INFO: load:1.32 valid_run:1360.92 task_valid:1302.52 collect_output:48.82
2023-01-08 09:46:05 - train.py[line:549] - INFO: 2000 / 4988
2023-01-08 09:46:05 - train.py[line:551] - INFO: load:1.36 valid_run:1509.64 task_valid:1445.49 collect_output:53.51
2023-01-08 09:48:35 - train.py[line:549] - INFO: 2200 / 4988
2023-01-08 09:48:35 - train.py[line:551] - INFO: load:1.39 valid_run:1659.49 task_valid:1590.11 collect_output:57.68
2023-01-08 09:51:05 - train.py[line:549] - INFO: 2400 / 4988
2023-01-08 09:51:05 - train.py[line:551] - INFO: load:1.41 valid_run:1809.61 task_valid:1734.75 collect_output:62.11
2023-01-08 09:53:35 - train.py[line:549] - INFO: 2600 / 4988
2023-01-08 09:53:35 - train.py[line:551] - INFO: load:1.44 valid_run:1959.56 task_valid:1876.21 collect_output:69.57
2023-01-08 09:56:06 - train.py[line:549] - INFO: 2800 / 4988
2023-01-08 09:56:06 - train.py[line:551] - INFO: load:1.47 valid_run:2110.09 task_valid:2021.44 collect_output:73.82
2023-01-08 09:58:36 - train.py[line:549] - INFO: 3000 / 4988
2023-01-08 09:58:36 - train.py[line:551] - INFO: load:1.50 valid_run:2259.89 task_valid:2167.48 collect_output:76.52
2023-01-08 10:01:06 - train.py[line:549] - INFO: 3200 / 4988
2023-01-08 10:01:06 - train.py[line:551] - INFO: load:1.53 valid_run:2410.05 task_valid:2311.40 collect_output:81.71
2023-01-08 10:03:38 - train.py[line:549] - INFO: 3400 / 4988
2023-01-08 10:03:38 - train.py[line:551] - INFO: load:1.56 valid_run:2561.79 task_valid:2456.62 collect_output:87.18
2023-01-08 10:06:08 - train.py[line:549] - INFO: 3600 / 4988
2023-01-08 10:06:08 - train.py[line:551] - INFO: load:1.59 valid_run:2712.22 task_valid:2603.31 collect_output:89.86
2023-01-08 10:08:37 - train.py[line:549] - INFO: 3800 / 4988
2023-01-08 10:08:37 - train.py[line:551] - INFO: load:1.62 valid_run:2860.98 task_valid:2744.79 collect_output:96.08
2023-01-08 10:11:08 - train.py[line:549] - INFO: 4000 / 4988
2023-01-08 10:11:08 - train.py[line:551] - INFO: load:1.65 valid_run:3011.51 task_valid:2889.68 collect_output:100.65
2023-01-08 10:13:40 - train.py[line:549] - INFO: 4200 / 4988
2023-01-08 10:13:40 - train.py[line:551] - INFO: load:1.68 valid_run:3163.71 task_valid:3034.04 collect_output:107.46
2023-01-08 10:16:10 - train.py[line:549] - INFO: 4400 / 4988
2023-01-08 10:16:10 - train.py[line:551] - INFO: load:1.71 valid_run:3313.19 task_valid:3178.32 collect_output:111.60
2023-01-08 10:18:41 - train.py[line:549] - INFO: 4600 / 4988
2023-01-08 10:18:41 - train.py[line:551] - INFO: load:1.74 valid_run:3464.82 task_valid:3324.61 collect_output:115.88
2023-01-08 10:21:13 - train.py[line:549] - INFO: 4800 / 4988
2023-01-08 10:21:13 - train.py[line:551] - INFO: load:1.77 valid_run:3616.18 task_valid:3470.82 collect_output:119.98

====================================================================================================
SGG eval:     R @ 50: 0.5107;     R @ 100: 0.5916;     R @ 500: 0.6535;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3104;    mR @ 100: 0.3883;    mR @ 500: 0.4649;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7341) (covered in:0.8125) (covering:0.3429) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4516) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.8448) (says:0.0000) (sitting on:0.6774) (standing on:0.2183) (using:0.6500) (walking in:0.0000) (walking on:0.6486) (watching:0.3056) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5107;     R @ 100: 0.5916;     R @ 500: 0.6535;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3104;    mR @ 100: 0.3883;    mR @ 500: 0.4649;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7341) (covered in:0.8125) (covering:0.3429) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4516) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.8448) (says:0.0000) (sitting on:0.6774) (standing on:0.2183) (using:0.6500) (walking in:0.0000) (walking on:0.6486) (watching:0.3056) 
--------------------------------------------------------
====================================================================================================

2023-01-08 10:23:44 - train.py[line:487] - INFO: 0.5916095238095238
2023-01-08 10:23:44 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 10:23:44 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.369 | loss_v1 0 | loss_v2 0 | nll_loss 0.218 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.59161 | ppl 1.16 | vqa_score 0.5394 | wps 119 | wpb 89.9 | bsz 30 | num_updates 10000 | best_R@100 0.645421
2023-01-08 10:23:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 10000 updates
2023-01-08 10:23:44 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_10000.pt
2023-01-08 10:24:28 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_10000.pt
2023-01-08 10:25:56 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 0.5916095238095238) (writing took 131.34780388697982 seconds)
2023-01-08 10:26:17 - progress_bar.py[line:274] - INFO: epoch 001:  10022 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.398, wps=0.6, ups=0, wpb=108.8, bsz=40, num_updates=10010, lr=4.75825e-05, gnorm=0.501, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=41732
2023-01-08 10:26:39 - progress_bar.py[line:274] - INFO: epoch 001:  10032 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3613, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=10020, lr=4.7578e-05, gnorm=0.455, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=41755
2023-01-08 10:27:01 - progress_bar.py[line:274] - INFO: epoch 001:  10042 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.335, wps=102.1, ups=0.47, wpb=108.5, bsz=40, num_updates=10030, lr=4.75736e-05, gnorm=0.455, clip=10, loss_scale=512, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=41777
2023-01-08 10:27:23 - progress_bar.py[line:274] - INFO: epoch 001:  10052 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4315, wps=102.9, ups=0.47, wpb=108.7, bsz=40, num_updates=10040, lr=4.75691e-05, gnorm=0.519, clip=10, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=41798
2023-01-08 10:27:44 - progress_bar.py[line:274] - INFO: epoch 001:  10062 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3873, wps=100.6, ups=0.47, wpb=107.1, bsz=40, num_updates=10050, lr=4.75646e-05, gnorm=0.504, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=41820
2023-01-08 10:28:06 - progress_bar.py[line:274] - INFO: epoch 001:  10072 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3524, wps=98.7, ups=0.46, wpb=108.1, bsz=40, num_updates=10060, lr=4.75601e-05, gnorm=0.513, clip=10, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=41842
2023-01-08 10:28:28 - progress_bar.py[line:274] - INFO: epoch 001:  10082 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3131, wps=99.7, ups=0.46, wpb=107.3, bsz=40, num_updates=10070, lr=4.75556e-05, gnorm=0.532, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=41864
2023-01-08 10:28:50 - progress_bar.py[line:274] - INFO: epoch 001:  10092 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3333, wps=101.4, ups=0.46, wpb=110.5, bsz=40, num_updates=10080, lr=4.75511e-05, gnorm=0.446, clip=10, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=41886
2023-01-08 10:29:12 - progress_bar.py[line:274] - INFO: epoch 001:  10102 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.401, wps=102.2, ups=0.47, wpb=108.6, bsz=40, num_updates=10090, lr=4.75466e-05, gnorm=0.54, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=41908
2023-01-08 10:29:34 - progress_bar.py[line:274] - INFO: epoch 001:  10112 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3119, wps=100.7, ups=0.46, wpb=108.7, bsz=40, num_updates=10100, lr=4.75421e-05, gnorm=0.544, clip=10, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=41929
2023-01-08 10:29:55 - progress_bar.py[line:274] - INFO: epoch 001:  10122 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3897, wps=101, ups=0.46, wpb=109.3, bsz=40, num_updates=10110, lr=4.75376e-05, gnorm=0.468, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=41951
2023-01-08 10:30:17 - progress_bar.py[line:274] - INFO: epoch 001:  10132 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3834, wps=103.2, ups=0.47, wpb=109.5, bsz=40, num_updates=10120, lr=4.75331e-05, gnorm=0.756, clip=20, loss_scale=1024, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=41973
2023-01-08 10:30:38 - progress_bar.py[line:274] - INFO: epoch 001:  10142 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3452, wps=102.8, ups=0.47, wpb=108.9, bsz=40, num_updates=10130, lr=4.75286e-05, gnorm=0.529, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=41994
2023-01-08 10:31:00 - progress_bar.py[line:274] - INFO: epoch 001:  10152 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3873, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=10140, lr=4.75241e-05, gnorm=0.447, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=42016
2023-01-08 10:31:22 - progress_bar.py[line:274] - INFO: epoch 001:  10162 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3906, wps=100.6, ups=0.46, wpb=109.7, bsz=40, num_updates=10150, lr=4.75196e-05, gnorm=0.468, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=42038
2023-01-08 10:31:44 - progress_bar.py[line:274] - INFO: epoch 001:  10172 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3981, wps=100.1, ups=0.46, wpb=108.1, bsz=40, num_updates=10160, lr=4.75151e-05, gnorm=0.497, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42060
2023-01-08 10:32:06 - progress_bar.py[line:274] - INFO: epoch 001:  10182 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.37, wps=100.5, ups=0.46, wpb=109.5, bsz=40, num_updates=10170, lr=4.75106e-05, gnorm=0.516, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=42082
2023-01-08 10:32:28 - progress_bar.py[line:274] - INFO: epoch 001:  10192 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3878, wps=100.6, ups=0.46, wpb=109.7, bsz=40, num_updates=10180, lr=4.75061e-05, gnorm=0.535, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42104
2023-01-08 10:32:50 - progress_bar.py[line:274] - INFO: epoch 001:  10202 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3959, wps=101.1, ups=0.46, wpb=109.4, bsz=40, num_updates=10190, lr=4.75016e-05, gnorm=0.489, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42126
2023-01-08 10:33:12 - progress_bar.py[line:274] - INFO: epoch 001:  10212 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4109, wps=102.6, ups=0.47, wpb=109, bsz=40, num_updates=10200, lr=4.74971e-05, gnorm=0.443, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42147
2023-01-08 10:33:29 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 10:33:35 - progress_bar.py[line:274] - INFO: epoch 001:  10223 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.952, nsentences=40, sample_size=108.952, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3224, wps=96.7, ups=0.42, wpb=109, bsz=40, num_updates=10210, lr=4.74926e-05, gnorm=0.494, clip=0, loss_scale=512, train_wall=24, gb_free=10.5, ema_decay=0.9999, wall=42171
2023-01-08 10:33:57 - progress_bar.py[line:274] - INFO: epoch 001:  10233 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4388, wps=102.1, ups=0.47, wpb=109.1, bsz=40, num_updates=10220, lr=4.74881e-05, gnorm=0.596, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42193
2023-01-08 10:34:19 - progress_bar.py[line:274] - INFO: epoch 001:  10243 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4104, wps=101.2, ups=0.47, wpb=108.5, bsz=40, num_updates=10230, lr=4.74836e-05, gnorm=0.557, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42214
2023-01-08 10:34:40 - progress_bar.py[line:274] - INFO: epoch 001:  10253 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4, wps=99.2, ups=0.46, wpb=107.1, bsz=40, num_updates=10240, lr=4.74791e-05, gnorm=0.498, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=42236
2023-01-08 10:35:02 - progress_bar.py[line:274] - INFO: epoch 001:  10263 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.335, wps=101.4, ups=0.47, wpb=108.7, bsz=40, num_updates=10250, lr=4.74746e-05, gnorm=0.572, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=42258
2023-01-08 10:35:24 - progress_bar.py[line:274] - INFO: epoch 001:  10273 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3515, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=10260, lr=4.74701e-05, gnorm=0.593, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=42280
2023-01-08 10:35:45 - progress_bar.py[line:274] - INFO: epoch 001:  10283 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3942, wps=102.4, ups=0.47, wpb=108.3, bsz=40, num_updates=10270, lr=4.74657e-05, gnorm=0.496, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42301
2023-01-08 10:36:07 - progress_bar.py[line:274] - INFO: epoch 001:  10293 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4038, wps=102, ups=0.47, wpb=109, bsz=40, num_updates=10280, lr=4.74612e-05, gnorm=0.516, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42323
2023-01-08 10:36:29 - progress_bar.py[line:274] - INFO: epoch 001:  10303 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3902, wps=102.6, ups=0.47, wpb=109.3, bsz=40, num_updates=10290, lr=4.74567e-05, gnorm=0.586, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=42344
2023-01-08 10:36:50 - progress_bar.py[line:274] - INFO: epoch 001:  10313 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3578, wps=100.9, ups=0.46, wpb=109.5, bsz=40, num_updates=10300, lr=4.74522e-05, gnorm=0.476, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42366
2023-01-08 10:37:12 - progress_bar.py[line:274] - INFO: epoch 001:  10323 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4019, wps=102.1, ups=0.47, wpb=107.5, bsz=40, num_updates=10310, lr=4.74477e-05, gnorm=0.645, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=42388
2023-01-08 10:37:33 - progress_bar.py[line:274] - INFO: epoch 001:  10333 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3788, wps=101.7, ups=0.47, wpb=109, bsz=40, num_updates=10320, lr=4.74432e-05, gnorm=0.395, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42409
2023-01-08 10:37:55 - progress_bar.py[line:274] - INFO: epoch 001:  10343 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3594, wps=103.1, ups=0.47, wpb=110, bsz=40, num_updates=10330, lr=4.74387e-05, gnorm=0.465, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42431
2023-01-08 10:38:16 - progress_bar.py[line:274] - INFO: epoch 001:  10353 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.383, wps=103.6, ups=0.47, wpb=109.7, bsz=40, num_updates=10340, lr=4.74342e-05, gnorm=0.464, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=42452
2023-01-08 10:38:38 - progress_bar.py[line:274] - INFO: epoch 001:  10363 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3318, wps=101.1, ups=0.46, wpb=109.4, bsz=40, num_updates=10350, lr=4.74297e-05, gnorm=0.478, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42474
2023-01-08 10:39:00 - progress_bar.py[line:274] - INFO: epoch 001:  10373 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3922, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=10360, lr=4.74252e-05, gnorm=0.72, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=42496
2023-01-08 10:39:22 - progress_bar.py[line:274] - INFO: epoch 001:  10383 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.395, wps=101.4, ups=0.46, wpb=109.3, bsz=40, num_updates=10370, lr=4.74207e-05, gnorm=0.399, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42518
2023-01-08 10:39:44 - progress_bar.py[line:274] - INFO: epoch 001:  10393 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3646, wps=100.6, ups=0.46, wpb=109.5, bsz=40, num_updates=10380, lr=4.74162e-05, gnorm=0.506, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=42540
2023-01-08 10:40:05 - progress_bar.py[line:274] - INFO: epoch 001:  10403 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.435, wps=104.7, ups=0.48, wpb=109.8, bsz=40, num_updates=10390, lr=4.74117e-05, gnorm=0.504, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42561
2023-01-08 10:40:27 - progress_bar.py[line:274] - INFO: epoch 001:  10413 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3659, wps=102.6, ups=0.47, wpb=109.5, bsz=40, num_updates=10400, lr=4.74072e-05, gnorm=0.477, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=42582
2023-01-08 10:40:48 - progress_bar.py[line:274] - INFO: epoch 001:  10423 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3717, wps=102.9, ups=0.47, wpb=109.2, bsz=40, num_updates=10410, lr=4.74027e-05, gnorm=0.564, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=42604
2023-01-08 10:41:10 - progress_bar.py[line:274] - INFO: epoch 001:  10433 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3711, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=10420, lr=4.73982e-05, gnorm=0.509, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=42625
2023-01-08 10:41:31 - progress_bar.py[line:274] - INFO: epoch 001:  10443 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3782, wps=102.3, ups=0.47, wpb=108.5, bsz=40, num_updates=10430, lr=4.73937e-05, gnorm=0.566, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=42647
2023-01-08 10:41:53 - progress_bar.py[line:274] - INFO: epoch 001:  10453 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3596, wps=100.3, ups=0.46, wpb=109.3, bsz=40, num_updates=10440, lr=4.73892e-05, gnorm=0.481, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=42669
2023-01-08 10:42:15 - progress_bar.py[line:274] - INFO: epoch 001:  10463 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4216, wps=100.1, ups=0.46, wpb=108.6, bsz=40, num_updates=10450, lr=4.73847e-05, gnorm=0.6, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42691
2023-01-08 10:42:37 - progress_bar.py[line:274] - INFO: epoch 001:  10473 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3717, wps=101.2, ups=0.46, wpb=109.4, bsz=40, num_updates=10460, lr=4.73802e-05, gnorm=0.422, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42713
2023-01-08 10:42:59 - progress_bar.py[line:274] - INFO: epoch 001:  10483 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3769, wps=100.9, ups=0.46, wpb=109.3, bsz=40, num_updates=10470, lr=4.73757e-05, gnorm=0.368, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42735
2023-01-08 10:43:21 - progress_bar.py[line:274] - INFO: epoch 001:  10493 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3654, wps=100.8, ups=0.46, wpb=108.9, bsz=40, num_updates=10480, lr=4.73712e-05, gnorm=0.558, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=42756
2023-01-08 10:43:42 - progress_bar.py[line:274] - INFO: epoch 001:  10503 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3462, wps=107.3, ups=0.48, wpb=111.6, bsz=40, num_updates=10490, lr=4.73667e-05, gnorm=0.413, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=42778
2023-01-08 10:44:04 - progress_bar.py[line:274] - INFO: epoch 001:  10513 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3469, wps=103.1, ups=0.47, wpb=110.4, bsz=40, num_updates=10500, lr=4.73622e-05, gnorm=0.412, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=42799
2023-01-08 10:44:25 - progress_bar.py[line:274] - INFO: epoch 001:  10523 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4085, wps=101.3, ups=0.47, wpb=108.2, bsz=40, num_updates=10510, lr=4.73577e-05, gnorm=0.67, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42821
2023-01-08 10:44:47 - progress_bar.py[line:274] - INFO: epoch 001:  10533 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3814, wps=99.2, ups=0.46, wpb=108.2, bsz=40, num_updates=10520, lr=4.73533e-05, gnorm=0.528, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42843
2023-01-08 10:45:09 - progress_bar.py[line:274] - INFO: epoch 001:  10543 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3367, wps=100.3, ups=0.47, wpb=107.8, bsz=40, num_updates=10530, lr=4.73488e-05, gnorm=0.442, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=42865
2023-01-08 10:45:31 - progress_bar.py[line:274] - INFO: epoch 001:  10553 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3551, wps=98.8, ups=0.46, wpb=107.6, bsz=40, num_updates=10540, lr=4.73443e-05, gnorm=0.506, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=42887
2023-01-08 10:45:53 - progress_bar.py[line:274] - INFO: epoch 001:  10563 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4307, wps=100.2, ups=0.46, wpb=108.7, bsz=40, num_updates=10550, lr=4.73398e-05, gnorm=0.586, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=42909
2023-01-08 10:46:15 - progress_bar.py[line:274] - INFO: epoch 001:  10573 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3285, wps=102.3, ups=0.47, wpb=108, bsz=40, num_updates=10560, lr=4.73353e-05, gnorm=0.477, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42930
2023-01-08 10:46:36 - progress_bar.py[line:274] - INFO: epoch 001:  10583 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3819, wps=102, ups=0.47, wpb=108.8, bsz=40, num_updates=10570, lr=4.73308e-05, gnorm=0.465, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42952
2023-01-08 10:46:58 - progress_bar.py[line:274] - INFO: epoch 001:  10593 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3803, wps=103.1, ups=0.47, wpb=109.5, bsz=40, num_updates=10580, lr=4.73263e-05, gnorm=0.403, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=42974
2023-01-08 10:47:20 - progress_bar.py[line:274] - INFO: epoch 001:  10603 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3763, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=10590, lr=4.73218e-05, gnorm=0.749, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42996
2023-01-08 10:47:41 - progress_bar.py[line:274] - INFO: epoch 001:  10613 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3179, wps=101.9, ups=0.47, wpb=108.6, bsz=40, num_updates=10600, lr=4.73173e-05, gnorm=0.582, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43017
2023-01-08 10:48:03 - progress_bar.py[line:274] - INFO: epoch 001:  10623 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3656, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=10610, lr=4.73128e-05, gnorm=0.592, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43039
2023-01-08 10:48:25 - progress_bar.py[line:274] - INFO: epoch 001:  10633 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.402, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=10620, lr=4.73083e-05, gnorm=0.776, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=43061
2023-01-08 10:48:46 - progress_bar.py[line:274] - INFO: epoch 001:  10643 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3958, wps=103.9, ups=0.48, wpb=109, bsz=40, num_updates=10630, lr=4.73038e-05, gnorm=0.439, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43082
2023-01-08 10:49:08 - progress_bar.py[line:274] - INFO: epoch 001:  10653 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3737, wps=102.5, ups=0.46, wpb=110.3, bsz=40, num_updates=10640, lr=4.72993e-05, gnorm=0.491, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43104
2023-01-08 10:49:30 - progress_bar.py[line:274] - INFO: epoch 001:  10663 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.343, wps=102.3, ups=0.47, wpb=109.2, bsz=40, num_updates=10650, lr=4.72948e-05, gnorm=0.416, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=43126
2023-01-08 10:49:52 - progress_bar.py[line:274] - INFO: epoch 001:  10673 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3214, wps=101.6, ups=0.47, wpb=108.6, bsz=40, num_updates=10660, lr=4.72903e-05, gnorm=0.494, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=43147
2023-01-08 10:50:13 - progress_bar.py[line:274] - INFO: epoch 001:  10683 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4093, wps=101, ups=0.47, wpb=108.1, bsz=40, num_updates=10670, lr=4.72858e-05, gnorm=0.352, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43169
2023-01-08 10:50:35 - progress_bar.py[line:274] - INFO: epoch 001:  10693 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3785, wps=102.4, ups=0.47, wpb=109.2, bsz=40, num_updates=10680, lr=4.72813e-05, gnorm=0.477, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43191
2023-01-08 10:50:57 - progress_bar.py[line:274] - INFO: epoch 001:  10703 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4112, wps=102.9, ups=0.47, wpb=109.7, bsz=40, num_updates=10690, lr=4.72768e-05, gnorm=0.443, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43212
2023-01-08 10:51:18 - progress_bar.py[line:274] - INFO: epoch 001:  10713 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.385, wps=99.9, ups=0.46, wpb=108.5, bsz=40, num_updates=10700, lr=4.72723e-05, gnorm=0.425, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=43234
2023-01-08 10:51:41 - progress_bar.py[line:274] - INFO: epoch 001:  10723 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3529, wps=100.4, ups=0.46, wpb=110.2, bsz=40, num_updates=10710, lr=4.72678e-05, gnorm=0.425, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=43256
2023-01-08 10:52:03 - progress_bar.py[line:274] - INFO: epoch 001:  10733 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3927, wps=97.3, ups=0.45, wpb=108.1, bsz=40, num_updates=10720, lr=4.72633e-05, gnorm=0.575, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=43279
2023-01-08 10:52:25 - progress_bar.py[line:274] - INFO: epoch 001:  10743 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4211, wps=101.2, ups=0.46, wpb=109.7, bsz=40, num_updates=10730, lr=4.72588e-05, gnorm=0.511, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=43301
2023-01-08 10:52:47 - progress_bar.py[line:274] - INFO: epoch 001:  10753 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3959, wps=101.8, ups=0.46, wpb=109.9, bsz=40, num_updates=10740, lr=4.72543e-05, gnorm=0.518, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=43323
2023-01-08 10:53:09 - progress_bar.py[line:274] - INFO: epoch 001:  10763 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3641, wps=101.8, ups=0.47, wpb=108.7, bsz=40, num_updates=10750, lr=4.72498e-05, gnorm=0.557, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=43345
2023-01-08 10:53:31 - progress_bar.py[line:274] - INFO: epoch 001:  10773 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.399, wps=99.7, ups=0.46, wpb=107.9, bsz=40, num_updates=10760, lr=4.72454e-05, gnorm=0.546, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=43366
2023-01-08 10:53:52 - progress_bar.py[line:274] - INFO: epoch 001:  10783 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3689, wps=102.6, ups=0.47, wpb=108.6, bsz=40, num_updates=10770, lr=4.72409e-05, gnorm=0.524, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43388
2023-01-08 10:54:14 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 10:54:16 - progress_bar.py[line:274] - INFO: epoch 001:  10794 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.095, nsentences=40, sample_size=110.095, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3891, wps=97.7, ups=0.42, wpb=110.1, bsz=40, num_updates=10780, lr=4.72364e-05, gnorm=0.422, clip=0, loss_scale=512, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=43412
2023-01-08 10:54:37 - progress_bar.py[line:274] - INFO: epoch 001:  10804 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3967, wps=104.3, ups=0.47, wpb=110.3, bsz=40, num_updates=10790, lr=4.72319e-05, gnorm=0.505, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43433
2023-01-08 10:54:59 - progress_bar.py[line:274] - INFO: epoch 001:  10814 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.401, wps=104.4, ups=0.48, wpb=109.4, bsz=40, num_updates=10800, lr=4.72274e-05, gnorm=0.514, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=43454
2023-01-08 10:55:20 - progress_bar.py[line:274] - INFO: epoch 001:  10824 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3854, wps=100.4, ups=0.46, wpb=108.3, bsz=40, num_updates=10810, lr=4.72229e-05, gnorm=0.443, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=43476
2023-01-08 10:55:43 - progress_bar.py[line:274] - INFO: epoch 001:  10834 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.399, wps=98.3, ups=0.46, wpb=107.5, bsz=40, num_updates=10820, lr=4.72184e-05, gnorm=0.503, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=43498
2023-01-08 10:56:04 - progress_bar.py[line:274] - INFO: epoch 001:  10844 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3858, wps=105.4, ups=0.48, wpb=110.4, bsz=40, num_updates=10830, lr=4.72139e-05, gnorm=0.477, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43520
2023-01-08 10:56:25 - progress_bar.py[line:274] - INFO: epoch 001:  10854 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4091, wps=101.8, ups=0.47, wpb=108.1, bsz=40, num_updates=10840, lr=4.72094e-05, gnorm=0.461, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43541
2023-01-08 10:56:47 - progress_bar.py[line:274] - INFO: epoch 001:  10864 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.401, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=10850, lr=4.72049e-05, gnorm=0.512, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=43563
2023-01-08 10:57:09 - progress_bar.py[line:274] - INFO: epoch 001:  10874 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.425, wps=100.3, ups=0.46, wpb=109.3, bsz=40, num_updates=10860, lr=4.72004e-05, gnorm=0.411, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=43585
2023-01-08 10:57:32 - progress_bar.py[line:274] - INFO: epoch 001:  10884 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3824, wps=98.6, ups=0.46, wpb=108.3, bsz=40, num_updates=10870, lr=4.71959e-05, gnorm=0.576, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=43607
2023-01-08 10:57:53 - progress_bar.py[line:274] - INFO: epoch 001:  10894 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3904, wps=103.9, ups=0.47, wpb=110.8, bsz=40, num_updates=10880, lr=4.71914e-05, gnorm=0.481, clip=10, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=43629
2023-01-08 10:58:15 - progress_bar.py[line:274] - INFO: epoch 001:  10904 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3827, wps=101.1, ups=0.46, wpb=109.2, bsz=40, num_updates=10890, lr=4.71869e-05, gnorm=0.515, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=43651
2023-01-08 10:58:37 - progress_bar.py[line:274] - INFO: epoch 001:  10914 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4184, wps=101.1, ups=0.46, wpb=109.4, bsz=40, num_updates=10900, lr=4.71824e-05, gnorm=0.553, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=43673
2023-01-08 10:58:58 - progress_bar.py[line:274] - INFO: epoch 001:  10924 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3681, wps=103.4, ups=0.47, wpb=109.9, bsz=40, num_updates=10910, lr=4.71779e-05, gnorm=0.387, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=43694
2023-01-08 10:59:20 - progress_bar.py[line:274] - INFO: epoch 001:  10934 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4278, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=10920, lr=4.71734e-05, gnorm=0.394, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=43716
2023-01-08 10:59:42 - progress_bar.py[line:274] - INFO: epoch 001:  10944 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.402, wps=101.2, ups=0.46, wpb=109.6, bsz=40, num_updates=10930, lr=4.71689e-05, gnorm=0.409, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=43738
2023-01-08 11:00:04 - progress_bar.py[line:274] - INFO: epoch 001:  10954 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3136, wps=98.4, ups=0.46, wpb=107, bsz=40, num_updates=10940, lr=4.71644e-05, gnorm=0.455, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=43760
2023-01-08 11:00:26 - progress_bar.py[line:274] - INFO: epoch 001:  10964 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3571, wps=99.3, ups=0.46, wpb=108.2, bsz=40, num_updates=10950, lr=4.71599e-05, gnorm=0.541, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=43782
2023-01-08 11:00:48 - progress_bar.py[line:274] - INFO: epoch 001:  10974 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3883, wps=100.5, ups=0.46, wpb=108.7, bsz=40, num_updates=10960, lr=4.71554e-05, gnorm=0.544, clip=10, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=43804
2023-01-08 11:01:10 - progress_bar.py[line:274] - INFO: epoch 001:  10984 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.401, wps=101.3, ups=0.46, wpb=109, bsz=40, num_updates=10970, lr=4.71509e-05, gnorm=0.419, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43826
2023-01-08 11:01:32 - progress_bar.py[line:274] - INFO: epoch 001:  10994 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3469, wps=104, ups=0.47, wpb=110.2, bsz=40, num_updates=10980, lr=4.71464e-05, gnorm=0.489, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43847
2023-01-08 11:01:54 - progress_bar.py[line:274] - INFO: epoch 001:  11004 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.385, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=10990, lr=4.71419e-05, gnorm=0.311, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=43869
2023-01-08 11:02:15 - progress_bar.py[line:274] - INFO: epoch 001:  11014 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4124, wps=100.6, ups=0.46, wpb=108.8, bsz=40, num_updates=11000, lr=4.71374e-05, gnorm=0.379, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=43891
2023-01-08 11:02:37 - progress_bar.py[line:274] - INFO: epoch 001:  11024 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4044, wps=103.4, ups=0.47, wpb=110.2, bsz=40, num_updates=11010, lr=4.7133e-05, gnorm=0.586, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43913
2023-01-08 11:02:59 - progress_bar.py[line:274] - INFO: epoch 001:  11034 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3989, wps=100.2, ups=0.46, wpb=109.7, bsz=40, num_updates=11020, lr=4.71285e-05, gnorm=0.47, clip=0, loss_scale=512, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=43935
2023-01-08 11:03:21 - progress_bar.py[line:274] - INFO: epoch 001:  11044 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.408, wps=103.2, ups=0.47, wpb=110.5, bsz=40, num_updates=11030, lr=4.7124e-05, gnorm=0.424, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=43957
2023-01-08 11:03:43 - progress_bar.py[line:274] - INFO: epoch 001:  11054 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4049, wps=101.2, ups=0.47, wpb=108, bsz=40, num_updates=11040, lr=4.71195e-05, gnorm=0.365, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=43978
2023-01-08 11:04:04 - progress_bar.py[line:274] - INFO: epoch 001:  11064 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=11050, lr=4.7115e-05, gnorm=0.388, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44000
2023-01-08 11:04:26 - progress_bar.py[line:274] - INFO: epoch 001:  11074 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3763, wps=101.2, ups=0.46, wpb=110, bsz=40, num_updates=11060, lr=4.71105e-05, gnorm=0.474, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44022
2023-01-08 11:04:49 - progress_bar.py[line:274] - INFO: epoch 001:  11084 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.385, wps=99, ups=0.45, wpb=109, bsz=40, num_updates=11070, lr=4.7106e-05, gnorm=0.314, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=44045
2023-01-08 11:05:11 - progress_bar.py[line:274] - INFO: epoch 001:  11094 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.452, wps=101.9, ups=0.46, wpb=110.2, bsz=40, num_updates=11080, lr=4.71015e-05, gnorm=0.377, clip=0, loss_scale=512, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=44066
2023-01-08 11:05:33 - progress_bar.py[line:274] - INFO: epoch 001:  11104 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3622, wps=100, ups=0.46, wpb=108.6, bsz=40, num_updates=11090, lr=4.7097e-05, gnorm=0.557, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44088
2023-01-08 11:05:55 - progress_bar.py[line:274] - INFO: epoch 001:  11114 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.401, wps=100.1, ups=0.46, wpb=108.8, bsz=40, num_updates=11100, lr=4.70925e-05, gnorm=0.429, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=44110
2023-01-08 11:06:19 - progress_bar.py[line:274] - INFO: epoch 001:  11124 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3802, wps=101.6, ups=0.46, wpb=109.7, bsz=40, num_updates=11110, lr=4.7088e-05, gnorm=0.514, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44132
2023-01-08 11:06:41 - progress_bar.py[line:274] - INFO: epoch 001:  11134 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3235, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=11120, lr=4.70835e-05, gnorm=0.386, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44157
2023-01-08 11:07:03 - progress_bar.py[line:274] - INFO: epoch 001:  11144 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4231, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=11130, lr=4.7079e-05, gnorm=0.415, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=44179
2023-01-08 11:07:24 - progress_bar.py[line:274] - INFO: epoch 001:  11154 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4084, wps=103.1, ups=0.47, wpb=110, bsz=40, num_updates=11140, lr=4.70745e-05, gnorm=0.622, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44200
2023-01-08 11:07:46 - progress_bar.py[line:274] - INFO: epoch 001:  11164 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4093, wps=102, ups=0.47, wpb=109, bsz=40, num_updates=11150, lr=4.707e-05, gnorm=0.522, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44222
2023-01-08 11:08:08 - progress_bar.py[line:274] - INFO: epoch 001:  11174 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4091, wps=100.3, ups=0.46, wpb=109.1, bsz=40, num_updates=11160, lr=4.70655e-05, gnorm=0.405, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44244
2023-01-08 11:08:30 - progress_bar.py[line:274] - INFO: epoch 001:  11184 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.435, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=11170, lr=4.7061e-05, gnorm=0.394, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44266
2023-01-08 11:08:52 - progress_bar.py[line:274] - INFO: epoch 001:  11194 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4176, wps=101.4, ups=0.46, wpb=110.3, bsz=40, num_updates=11180, lr=4.70565e-05, gnorm=0.361, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=44288
2023-01-08 11:09:14 - progress_bar.py[line:274] - INFO: epoch 001:  11204 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4158, wps=101.7, ups=0.46, wpb=110.1, bsz=40, num_updates=11190, lr=4.7052e-05, gnorm=0.36, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44310
2023-01-08 11:09:36 - progress_bar.py[line:274] - INFO: epoch 001:  11214 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4355, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=11200, lr=4.70475e-05, gnorm=0.459, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=44331
2023-01-08 11:09:58 - progress_bar.py[line:274] - INFO: epoch 001:  11224 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4093, wps=98.3, ups=0.46, wpb=107.8, bsz=40, num_updates=11210, lr=4.7043e-05, gnorm=0.433, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44354
2023-01-08 11:10:20 - progress_bar.py[line:274] - INFO: epoch 001:  11234 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3915, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=11220, lr=4.70385e-05, gnorm=0.483, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=44376
2023-01-08 11:10:42 - progress_bar.py[line:274] - INFO: epoch 001:  11244 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3807, wps=101.2, ups=0.46, wpb=109.5, bsz=40, num_updates=11230, lr=4.7034e-05, gnorm=0.394, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44398
2023-01-08 11:11:04 - progress_bar.py[line:274] - INFO: epoch 001:  11254 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4366, wps=99, ups=0.46, wpb=107.8, bsz=40, num_updates=11240, lr=4.70295e-05, gnorm=0.371, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44420
2023-01-08 11:11:26 - progress_bar.py[line:274] - INFO: epoch 001:  11264 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4505, wps=101.9, ups=0.46, wpb=110.9, bsz=40, num_updates=11250, lr=4.70251e-05, gnorm=0.381, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=44442
2023-01-08 11:11:48 - progress_bar.py[line:274] - INFO: epoch 001:  11274 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.401, wps=103.6, ups=0.47, wpb=110.2, bsz=40, num_updates=11260, lr=4.70206e-05, gnorm=0.75, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44464
2023-01-08 11:12:11 - progress_bar.py[line:274] - INFO: epoch 001:  11284 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4074, wps=99.8, ups=0.45, wpb=109.7, bsz=40, num_updates=11270, lr=4.70161e-05, gnorm=0.428, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44486
2023-01-08 11:12:33 - progress_bar.py[line:274] - INFO: epoch 001:  11294 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4192, wps=100.4, ups=0.46, wpb=108.8, bsz=40, num_updates=11280, lr=4.70116e-05, gnorm=0.478, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44509
2023-01-08 11:12:56 - progress_bar.py[line:274] - INFO: epoch 001:  11304 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3709, wps=101.7, ups=0.47, wpb=108.6, bsz=40, num_updates=11290, lr=4.70071e-05, gnorm=0.381, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44531
2023-01-08 11:13:17 - progress_bar.py[line:274] - INFO: epoch 001:  11314 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3544, wps=103.5, ups=0.48, wpb=108.9, bsz=40, num_updates=11300, lr=4.70026e-05, gnorm=0.405, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44553
2023-01-08 11:13:39 - progress_bar.py[line:274] - INFO: epoch 001:  11324 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4084, wps=103.5, ups=0.47, wpb=110, bsz=40, num_updates=11310, lr=4.69981e-05, gnorm=0.373, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=44575
2023-01-08 11:14:02 - progress_bar.py[line:274] - INFO: epoch 001:  11334 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3952, wps=98.4, ups=0.46, wpb=107.5, bsz=40, num_updates=11320, lr=4.69936e-05, gnorm=0.577, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44597
2023-01-08 11:14:24 - progress_bar.py[line:274] - INFO: epoch 001:  11344 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.467, wps=101.5, ups=0.46, wpb=110.6, bsz=40, num_updates=11330, lr=4.69891e-05, gnorm=0.527, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=44620
2023-01-08 11:14:46 - progress_bar.py[line:274] - INFO: epoch 001:  11354 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4346, wps=100.6, ups=0.47, wpb=107.2, bsz=40, num_updates=11340, lr=4.69846e-05, gnorm=0.486, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=44642
2023-01-08 11:15:09 - progress_bar.py[line:274] - INFO: epoch 001:  11364 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4029, wps=103.1, ups=0.47, wpb=109.3, bsz=40, num_updates=11350, lr=4.69801e-05, gnorm=0.434, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44664
2023-01-08 11:15:31 - progress_bar.py[line:274] - INFO: epoch 001:  11374 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.36, wps=101.2, ups=0.47, wpb=108.4, bsz=40, num_updates=11360, lr=4.69756e-05, gnorm=0.548, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44686
2023-01-08 11:15:53 - progress_bar.py[line:274] - INFO: epoch 001:  11384 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.6, nsentences=40, sample_size=106.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4047, wps=99.2, ups=0.47, wpb=106.6, bsz=40, num_updates=11370, lr=4.69711e-05, gnorm=0.722, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44708
2023-01-08 11:15:55 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 11:16:17 - progress_bar.py[line:274] - INFO: epoch 001:  11395 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4425, wps=95.8, ups=0.42, wpb=108, bsz=40, num_updates=11380, lr=4.69666e-05, gnorm=0.456, clip=0, loss_scale=512, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=44733
2023-01-08 11:16:40 - progress_bar.py[line:274] - INFO: epoch 001:  11405 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4624, wps=100.8, ups=0.46, wpb=108.8, bsz=40, num_updates=11390, lr=4.69621e-05, gnorm=0.613, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44755
2023-01-08 11:17:02 - progress_bar.py[line:274] - INFO: epoch 001:  11415 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4734, wps=101.4, ups=0.47, wpb=109, bsz=40, num_updates=11400, lr=4.69576e-05, gnorm=0.462, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=44777
2023-01-08 11:17:25 - progress_bar.py[line:274] - INFO: epoch 001:  11425 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3646, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=11410, lr=4.69531e-05, gnorm=0.411, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44800
2023-01-08 11:17:47 - progress_bar.py[line:274] - INFO: epoch 001:  11435 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.401, wps=100.3, ups=0.46, wpb=109.2, bsz=40, num_updates=11420, lr=4.69486e-05, gnorm=0.489, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44822
2023-01-08 11:18:10 - progress_bar.py[line:274] - INFO: epoch 001:  11445 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3153, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=11430, lr=4.69441e-05, gnorm=0.539, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=44845
2023-01-08 11:18:32 - progress_bar.py[line:274] - INFO: epoch 001:  11455 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4202, wps=103.2, ups=0.47, wpb=109.1, bsz=40, num_updates=11440, lr=4.69396e-05, gnorm=0.3, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44867
2023-01-08 11:18:53 - progress_bar.py[line:274] - INFO: epoch 001:  11465 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.455, wps=103.5, ups=0.47, wpb=109, bsz=40, num_updates=11450, lr=4.69351e-05, gnorm=0.48, clip=10, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=44889
2023-01-08 11:19:10 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 11:19:18 - progress_bar.py[line:274] - INFO: epoch 001:  11476 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.286, nsentences=40, sample_size=109.286, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4414, wps=96.8, ups=0.42, wpb=109.3, bsz=40, num_updates=11460, lr=4.69306e-05, gnorm=0.393, clip=0, loss_scale=256, train_wall=24, gb_free=10.1, ema_decay=0.9999, wall=44913
2023-01-08 11:19:40 - progress_bar.py[line:274] - INFO: epoch 001:  11486 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4135, wps=102.8, ups=0.47, wpb=108.7, bsz=40, num_updates=11470, lr=4.69261e-05, gnorm=0.557, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44935
2023-01-08 11:20:02 - progress_bar.py[line:274] - INFO: epoch 001:  11496 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3769, wps=99.5, ups=0.46, wpb=108.4, bsz=40, num_updates=11480, lr=4.69216e-05, gnorm=0.497, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44957
2023-01-08 11:20:24 - progress_bar.py[line:274] - INFO: epoch 001:  11506 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3895, wps=105.9, ups=0.48, wpb=111, bsz=40, num_updates=11490, lr=4.69171e-05, gnorm=0.475, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44979
2023-01-08 11:20:46 - progress_bar.py[line:274] - INFO: epoch 001:  11516 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.419, wps=102.3, ups=0.46, wpb=111.4, bsz=40, num_updates=11500, lr=4.69127e-05, gnorm=0.489, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45001
2023-01-08 11:21:08 - progress_bar.py[line:274] - INFO: epoch 001:  11526 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4124, wps=101.8, ups=0.46, wpb=109.7, bsz=40, num_updates=11510, lr=4.69082e-05, gnorm=0.408, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=45024
2023-01-08 11:21:31 - progress_bar.py[line:274] - INFO: epoch 001:  11536 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3923, wps=102.5, ups=0.47, wpb=109.7, bsz=40, num_updates=11520, lr=4.69037e-05, gnorm=0.312, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=45046
2023-01-08 11:21:53 - progress_bar.py[line:274] - INFO: epoch 001:  11546 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4064, wps=100.1, ups=0.47, wpb=107, bsz=40, num_updates=11530, lr=4.68992e-05, gnorm=0.391, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45068
2023-01-08 11:22:15 - progress_bar.py[line:274] - INFO: epoch 001:  11556 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4293, wps=100.4, ups=0.46, wpb=109.3, bsz=40, num_updates=11540, lr=4.68947e-05, gnorm=0.657, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=45090
2023-01-08 11:22:37 - progress_bar.py[line:274] - INFO: epoch 001:  11566 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4294, wps=102.9, ups=0.46, wpb=110.8, bsz=40, num_updates=11550, lr=4.68902e-05, gnorm=0.441, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=45113
2023-01-08 11:22:59 - progress_bar.py[line:274] - INFO: epoch 001:  11576 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.439, wps=102.1, ups=0.47, wpb=108.8, bsz=40, num_updates=11560, lr=4.68857e-05, gnorm=0.492, clip=10, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=45135
2023-01-08 11:23:22 - progress_bar.py[line:274] - INFO: epoch 001:  11586 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4145, wps=101.7, ups=0.46, wpb=109.6, bsz=40, num_updates=11570, lr=4.68812e-05, gnorm=0.365, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=45157
2023-01-08 11:23:44 - progress_bar.py[line:274] - INFO: epoch 001:  11596 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3737, wps=101.9, ups=0.47, wpb=108.5, bsz=40, num_updates=11580, lr=4.68767e-05, gnorm=0.501, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45179
2023-01-08 11:24:06 - progress_bar.py[line:274] - INFO: epoch 001:  11606 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3927, wps=98.5, ups=0.46, wpb=107.2, bsz=40, num_updates=11590, lr=4.68722e-05, gnorm=0.528, clip=20, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=45202
2023-01-08 11:24:29 - progress_bar.py[line:274] - INFO: epoch 001:  11616 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3807, wps=99.6, ups=0.45, wpb=109.6, bsz=40, num_updates=11600, lr=4.68677e-05, gnorm=0.485, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=45224
2023-01-08 11:24:51 - progress_bar.py[line:274] - INFO: epoch 001:  11626 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4279, wps=99.9, ups=0.46, wpb=107.8, bsz=40, num_updates=11610, lr=4.68632e-05, gnorm=0.521, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45247
2023-01-08 11:25:14 - progress_bar.py[line:274] - INFO: epoch 001:  11636 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3632, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=11620, lr=4.68587e-05, gnorm=0.39, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45269
2023-01-08 11:25:35 - progress_bar.py[line:274] - INFO: epoch 001:  11646 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4359, wps=102.8, ups=0.47, wpb=108.5, bsz=40, num_updates=11630, lr=4.68542e-05, gnorm=0.368, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=45291
2023-01-08 11:25:58 - progress_bar.py[line:274] - INFO: epoch 001:  11656 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4286, wps=100.6, ups=0.46, wpb=108.5, bsz=40, num_updates=11640, lr=4.68497e-05, gnorm=0.491, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=45313
2023-01-08 11:26:20 - progress_bar.py[line:274] - INFO: epoch 001:  11666 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3812, wps=101.5, ups=0.46, wpb=109.2, bsz=40, num_updates=11650, lr=4.68452e-05, gnorm=0.391, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45336
2023-01-08 11:26:43 - progress_bar.py[line:274] - INFO: epoch 001:  11676 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3656, wps=101.7, ups=0.46, wpb=109.9, bsz=40, num_updates=11660, lr=4.68407e-05, gnorm=0.312, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45358
2023-01-08 11:27:05 - progress_bar.py[line:274] - INFO: epoch 001:  11686 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3786, wps=102.3, ups=0.46, wpb=110.2, bsz=40, num_updates=11670, lr=4.68362e-05, gnorm=0.306, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45380
2023-01-08 11:27:28 - progress_bar.py[line:274] - INFO: epoch 001:  11696 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4145, wps=101.5, ups=0.46, wpb=109.7, bsz=40, num_updates=11680, lr=4.68317e-05, gnorm=0.369, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=45403
2023-01-08 11:27:50 - progress_bar.py[line:274] - INFO: epoch 001:  11706 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4279, wps=99.4, ups=0.46, wpb=108.2, bsz=40, num_updates=11690, lr=4.68272e-05, gnorm=0.39, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45425
2023-01-08 11:28:13 - progress_bar.py[line:274] - INFO: epoch 001:  11716 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3963, wps=99.1, ups=0.46, wpb=107, bsz=40, num_updates=11700, lr=4.68227e-05, gnorm=0.52, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45448
2023-01-08 11:28:35 - progress_bar.py[line:274] - INFO: epoch 001:  11726 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.419, wps=98.1, ups=0.45, wpb=108.2, bsz=40, num_updates=11710, lr=4.68182e-05, gnorm=0.388, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=45471
2023-01-08 11:28:58 - progress_bar.py[line:274] - INFO: epoch 001:  11736 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.449, wps=99.9, ups=0.46, wpb=109.3, bsz=40, num_updates=11720, lr=4.68137e-05, gnorm=0.332, clip=0, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=45493
2023-01-08 11:29:20 - progress_bar.py[line:274] - INFO: epoch 001:  11746 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3556, wps=103, ups=0.47, wpb=109.3, bsz=40, num_updates=11730, lr=4.68092e-05, gnorm=0.418, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=45515
2023-01-08 11:29:42 - progress_bar.py[line:274] - INFO: epoch 001:  11756 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3925, wps=103.3, ups=0.46, wpb=111.2, bsz=40, num_updates=11740, lr=4.68048e-05, gnorm=0.342, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=45538
2023-01-08 11:30:05 - progress_bar.py[line:274] - INFO: epoch 001:  11766 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3711, wps=100.7, ups=0.46, wpb=108.6, bsz=40, num_updates=11750, lr=4.68003e-05, gnorm=0.367, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=45560
2023-01-08 11:30:27 - progress_bar.py[line:274] - INFO: epoch 001:  11776 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3907, wps=100, ups=0.46, wpb=109, bsz=40, num_updates=11760, lr=4.67958e-05, gnorm=0.53, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=45583
2023-01-08 11:30:49 - progress_bar.py[line:274] - INFO: epoch 001:  11786 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4333, wps=103.1, ups=0.47, wpb=109.3, bsz=40, num_updates=11770, lr=4.67913e-05, gnorm=0.366, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=45604
2023-01-08 11:31:12 - progress_bar.py[line:274] - INFO: epoch 001:  11796 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3814, wps=99.6, ups=0.46, wpb=107.6, bsz=40, num_updates=11780, lr=4.67868e-05, gnorm=0.383, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=45627
2023-01-08 11:31:34 - progress_bar.py[line:274] - INFO: epoch 001:  11806 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4839, wps=101.7, ups=0.46, wpb=110.7, bsz=40, num_updates=11790, lr=4.67823e-05, gnorm=0.385, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=45650
2023-01-08 11:31:56 - progress_bar.py[line:274] - INFO: epoch 001:  11816 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3846, wps=102.5, ups=0.47, wpb=108.7, bsz=40, num_updates=11800, lr=4.67778e-05, gnorm=0.355, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45672
2023-01-08 11:32:18 - progress_bar.py[line:274] - INFO: epoch 001:  11826 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4158, wps=101, ups=0.46, wpb=108.8, bsz=40, num_updates=11810, lr=4.67733e-05, gnorm=0.372, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45694
2023-01-08 11:32:40 - progress_bar.py[line:274] - INFO: epoch 001:  11836 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3981, wps=104.3, ups=0.48, wpb=108.5, bsz=40, num_updates=11820, lr=4.67688e-05, gnorm=0.336, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=45715
2023-01-08 11:33:03 - progress_bar.py[line:274] - INFO: epoch 001:  11846 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.35, wps=99.9, ups=0.46, wpb=109.2, bsz=40, num_updates=11830, lr=4.67643e-05, gnorm=0.345, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=45738
2023-01-08 11:33:25 - progress_bar.py[line:274] - INFO: epoch 001:  11856 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.346, wps=99.8, ups=0.46, wpb=108.3, bsz=40, num_updates=11840, lr=4.67598e-05, gnorm=0.65, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45760
2023-01-08 11:33:47 - progress_bar.py[line:274] - INFO: epoch 001:  11866 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.407, wps=100.5, ups=0.46, wpb=108.5, bsz=40, num_updates=11850, lr=4.67553e-05, gnorm=0.456, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=45783
2023-01-08 11:34:09 - progress_bar.py[line:274] - INFO: epoch 001:  11876 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4231, wps=101.4, ups=0.47, wpb=108.5, bsz=40, num_updates=11860, lr=4.67508e-05, gnorm=0.311, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=45805
2023-01-08 11:34:31 - progress_bar.py[line:274] - INFO: epoch 001:  11886 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4062, wps=101.5, ups=0.46, wpb=109.9, bsz=40, num_updates=11870, lr=4.67463e-05, gnorm=0.722, clip=20, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=45827
2023-01-08 11:34:53 - progress_bar.py[line:274] - INFO: epoch 001:  11896 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3472, wps=100.8, ups=0.46, wpb=109.6, bsz=40, num_updates=11880, lr=4.67418e-05, gnorm=0.638, clip=20, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=45849
2023-01-08 11:35:15 - progress_bar.py[line:274] - INFO: epoch 001:  11906 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3911, wps=103.9, ups=0.47, wpb=110.9, bsz=40, num_updates=11890, lr=4.67373e-05, gnorm=0.361, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45870
2023-01-08 11:35:36 - progress_bar.py[line:274] - INFO: epoch 001:  11916 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4211, wps=102.1, ups=0.46, wpb=110.5, bsz=40, num_updates=11900, lr=4.67328e-05, gnorm=0.438, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45892
2023-01-08 11:35:59 - progress_bar.py[line:274] - INFO: epoch 001:  11926 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4184, wps=100.2, ups=0.46, wpb=109, bsz=40, num_updates=11910, lr=4.67283e-05, gnorm=0.37, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=45914
2023-01-08 11:36:20 - progress_bar.py[line:274] - INFO: epoch 001:  11936 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4372, wps=101.6, ups=0.46, wpb=110.2, bsz=40, num_updates=11920, lr=4.67238e-05, gnorm=0.46, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45936
2023-01-08 11:36:42 - progress_bar.py[line:274] - INFO: epoch 001:  11946 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4422, wps=103.1, ups=0.47, wpb=109.3, bsz=40, num_updates=11930, lr=4.67193e-05, gnorm=0.598, clip=10, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=45958
2023-01-08 11:37:04 - progress_bar.py[line:274] - INFO: epoch 001:  11956 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3904, wps=99.2, ups=0.46, wpb=109, bsz=40, num_updates=11940, lr=4.67148e-05, gnorm=0.453, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=45980
2023-01-08 11:37:26 - progress_bar.py[line:274] - INFO: epoch 001:  11966 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4109, wps=99.9, ups=0.46, wpb=108.8, bsz=40, num_updates=11950, lr=4.67103e-05, gnorm=0.43, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=46002
2023-01-08 11:37:48 - progress_bar.py[line:274] - INFO: epoch 001:  11976 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3911, wps=100.1, ups=0.46, wpb=107.8, bsz=40, num_updates=11960, lr=4.67058e-05, gnorm=0.454, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=46024
2023-01-08 11:38:09 - progress_bar.py[line:274] - INFO: epoch 001:  11986 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4718, wps=103.7, ups=0.47, wpb=110.5, bsz=40, num_updates=11970, lr=4.67013e-05, gnorm=0.45, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=46045
2023-01-08 11:38:31 - progress_bar.py[line:274] - INFO: epoch 001:  11996 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4339, wps=100.3, ups=0.46, wpb=109.4, bsz=40, num_updates=11980, lr=4.66968e-05, gnorm=0.405, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=46067
2023-01-08 11:38:53 - progress_bar.py[line:274] - INFO: epoch 001:  12006 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4314, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=11990, lr=4.66924e-05, gnorm=0.666, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=46089
2023-01-08 11:39:15 - progress_bar.py[line:274] - INFO: epoch 001:  12016 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4667, wps=100.6, ups=0.46, wpb=108.2, bsz=40, num_updates=12000, lr=4.66879e-05, gnorm=0.558, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=46111
2023-01-08 11:39:15 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 11:39:16 - train.py[line:549] - INFO: 0 / 4988
2023-01-08 11:39:16 - train.py[line:551] - INFO: load:1.04 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 11:41:49 - train.py[line:549] - INFO: 200 / 4988
2023-01-08 11:41:49 - train.py[line:551] - INFO: load:1.07 valid_run:152.19 task_valid:147.91 collect_output:3.22
2023-01-08 11:44:18 - train.py[line:549] - INFO: 400 / 4988
2023-01-08 11:44:18 - train.py[line:551] - INFO: load:1.09 valid_run:301.39 task_valid:290.76 collect_output:8.53
2023-01-08 11:46:52 - train.py[line:549] - INFO: 600 / 4988
2023-01-08 11:46:52 - train.py[line:551] - INFO: load:1.12 valid_run:455.53 task_valid:433.50 collect_output:18.89
2023-01-08 11:49:22 - train.py[line:549] - INFO: 800 / 4988
2023-01-08 11:49:22 - train.py[line:551] - INFO: load:1.14 valid_run:604.97 task_valid:578.24 collect_output:22.58
2023-01-08 11:51:54 - train.py[line:549] - INFO: 1000 / 4988
2023-01-08 11:51:54 - train.py[line:551] - INFO: load:1.17 valid_run:757.37 task_valid:725.36 collect_output:26.86
2023-01-08 11:54:26 - train.py[line:549] - INFO: 1200 / 4988
2023-01-08 11:54:26 - train.py[line:551] - INFO: load:1.19 valid_run:909.56 task_valid:870.55 collect_output:32.84
2023-01-08 11:57:00 - train.py[line:549] - INFO: 1400 / 4988
2023-01-08 11:57:00 - train.py[line:551] - INFO: load:1.22 valid_run:1063.44 task_valid:1016.22 collect_output:40.02
2023-01-08 11:59:32 - train.py[line:549] - INFO: 1600 / 4988
2023-01-08 11:59:32 - train.py[line:551] - INFO: load:1.24 valid_run:1215.13 task_valid:1157.18 collect_output:49.74
2023-01-08 12:02:02 - train.py[line:549] - INFO: 1800 / 4988
2023-01-08 12:02:02 - train.py[line:551] - INFO: load:1.27 valid_run:1364.92 task_valid:1301.60 collect_output:54.08
2023-01-08 12:04:31 - train.py[line:549] - INFO: 2000 / 4988
2023-01-08 12:04:31 - train.py[line:551] - INFO: load:1.29 valid_run:1513.84 task_valid:1444.39 collect_output:59.19
2023-01-08 12:07:01 - train.py[line:549] - INFO: 2200 / 4988
2023-01-08 12:07:01 - train.py[line:551] - INFO: load:1.32 valid_run:1663.61 task_valid:1588.95 collect_output:63.39
2023-01-08 12:09:31 - train.py[line:549] - INFO: 2400 / 4988
2023-01-08 12:09:31 - train.py[line:551] - INFO: load:1.34 valid_run:1813.85 task_valid:1733.68 collect_output:67.88
2023-01-08 12:12:01 - train.py[line:549] - INFO: 2600 / 4988
2023-01-08 12:12:01 - train.py[line:551] - INFO: load:1.37 valid_run:1963.98 task_valid:1875.21 collect_output:75.46
2023-01-08 12:14:32 - train.py[line:549] - INFO: 2800 / 4988
2023-01-08 12:14:32 - train.py[line:551] - INFO: load:1.39 valid_run:2114.70 task_valid:2020.41 collect_output:79.96
2023-01-08 12:17:02 - train.py[line:549] - INFO: 3000 / 4988
2023-01-08 12:17:02 - train.py[line:551] - INFO: load:1.42 valid_run:2264.69 task_valid:2166.57 collect_output:82.79
2023-01-08 12:19:33 - train.py[line:549] - INFO: 3200 / 4988
2023-01-08 12:19:33 - train.py[line:551] - INFO: load:1.44 valid_run:2415.19 task_valid:2310.73 collect_output:88.12
2023-01-08 12:22:05 - train.py[line:549] - INFO: 3400 / 4988
2023-01-08 12:22:05 - train.py[line:551] - INFO: load:1.47 valid_run:2567.02 task_valid:2455.91 collect_output:93.75
2023-01-08 12:24:35 - train.py[line:549] - INFO: 3600 / 4988
2023-01-08 12:24:35 - train.py[line:551] - INFO: load:1.49 valid_run:2717.59 task_valid:2602.61 collect_output:96.59
2023-01-08 12:27:04 - train.py[line:549] - INFO: 3800 / 4988
2023-01-08 12:27:04 - train.py[line:551] - INFO: load:1.52 valid_run:2866.54 task_valid:2743.95 collect_output:103.18
2023-01-08 12:29:35 - train.py[line:549] - INFO: 4000 / 4988
2023-01-08 12:29:35 - train.py[line:551] - INFO: load:1.54 valid_run:3017.06 task_valid:2888.97 collect_output:107.69
2023-01-08 12:32:07 - train.py[line:549] - INFO: 4200 / 4988
2023-01-08 12:32:07 - train.py[line:551] - INFO: load:1.57 valid_run:3169.51 task_valid:3033.58 collect_output:114.47
2023-01-08 12:34:37 - train.py[line:549] - INFO: 4400 / 4988
2023-01-08 12:34:37 - train.py[line:551] - INFO: load:1.59 valid_run:3319.09 task_valid:3177.93 collect_output:118.68
2023-01-08 12:37:09 - train.py[line:549] - INFO: 4600 / 4988
2023-01-08 12:37:09 - train.py[line:551] - INFO: load:1.62 valid_run:3470.65 task_valid:3323.93 collect_output:123.22
2023-01-08 12:39:40 - train.py[line:549] - INFO: 4800 / 4988
2023-01-08 12:39:40 - train.py[line:551] - INFO: load:1.65 valid_run:3622.00 task_valid:3470.18 collect_output:127.32

====================================================================================================
SGG eval:     R @ 50: 0.4611;     R @ 100: 0.5498;     R @ 500: 0.6161;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2785;    mR @ 100: 0.3557;    mR @ 500: 0.4356;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6317) (covered in:0.6458) (covering:0.3429) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.3871) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.8154) (says:0.0000) (sitting on:0.6400) (standing on:0.1983) (using:0.6500) (walking in:0.0000) (walking on:0.5000) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-08 12:42:11 - train.py[line:487] - INFO: 0.5498095238095237
2023-01-08 12:42:11 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.4611;     R @ 100: 0.5498;     R @ 500: 0.6161;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2785;    mR @ 100: 0.3557;    mR @ 500: 0.4356;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6317) (covered in:0.6458) (covering:0.3429) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.3871) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.8154) (says:0.0000) (sitting on:0.6400) (standing on:0.1983) (using:0.6500) (walking in:0.0000) (walking on:0.5000) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-08 12:42:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.371 | loss_v1 0 | loss_v2 0 | nll_loss 0.221 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.54981 | ppl 1.17 | vqa_score 0.5304 | wps 118.8 | wpb 89.9 | bsz 30 | num_updates 12000 | best_R@100 0.645421
2023-01-08 12:42:12 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 12000 updates
2023-01-08 12:42:12 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_12000.pt
2023-01-08 12:42:53 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_12000.pt
2023-01-08 12:44:23 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 0.5498095238095237) (writing took 131.84068673476577 seconds)
2023-01-08 12:44:46 - progress_bar.py[line:274] - INFO: epoch 001:  12026 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4516, wps=0.6, ups=0, wpb=110.1, bsz=40, num_updates=12010, lr=4.66834e-05, gnorm=0.5, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50041
2023-01-08 12:45:08 - progress_bar.py[line:274] - INFO: epoch 001:  12036 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.425, wps=99.3, ups=0.46, wpb=108.1, bsz=40, num_updates=12020, lr=4.66789e-05, gnorm=0.437, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50064
2023-01-08 12:45:30 - progress_bar.py[line:274] - INFO: epoch 001:  12046 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.399, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=12030, lr=4.66744e-05, gnorm=0.356, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50085
2023-01-08 12:45:52 - progress_bar.py[line:274] - INFO: epoch 001:  12056 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4141, wps=99.4, ups=0.46, wpb=108.7, bsz=40, num_updates=12040, lr=4.66699e-05, gnorm=0.355, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50108
2023-01-08 12:46:14 - progress_bar.py[line:274] - INFO: epoch 001:  12066 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4483, wps=100.6, ups=0.46, wpb=108.9, bsz=40, num_updates=12050, lr=4.66654e-05, gnorm=0.375, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=50130
2023-01-08 12:46:36 - progress_bar.py[line:274] - INFO: epoch 001:  12076 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4167, wps=100.6, ups=0.46, wpb=109.3, bsz=40, num_updates=12060, lr=4.66609e-05, gnorm=0.402, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=50152
2023-01-08 12:46:58 - progress_bar.py[line:274] - INFO: epoch 001:  12086 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4162, wps=100.8, ups=0.46, wpb=109, bsz=40, num_updates=12070, lr=4.66564e-05, gnorm=0.601, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50174
2023-01-08 12:47:20 - progress_bar.py[line:274] - INFO: epoch 001:  12096 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4346, wps=101.9, ups=0.47, wpb=109.2, bsz=40, num_updates=12080, lr=4.66519e-05, gnorm=0.43, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=50196
2023-01-08 12:47:42 - progress_bar.py[line:274] - INFO: epoch 001:  12106 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4338, wps=101.5, ups=0.47, wpb=108.4, bsz=40, num_updates=12090, lr=4.66474e-05, gnorm=0.295, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=50217
2023-01-08 12:48:03 - progress_bar.py[line:274] - INFO: epoch 001:  12116 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3889, wps=103.7, ups=0.47, wpb=109.5, bsz=40, num_updates=12100, lr=4.66429e-05, gnorm=0.391, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50239
2023-01-08 12:48:25 - progress_bar.py[line:274] - INFO: epoch 001:  12126 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4486, wps=100, ups=0.46, wpb=108, bsz=40, num_updates=12110, lr=4.66384e-05, gnorm=0.544, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=50261
2023-01-08 12:48:47 - progress_bar.py[line:274] - INFO: epoch 001:  12136 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3906, wps=101.9, ups=0.46, wpb=109.8, bsz=40, num_updates=12120, lr=4.66339e-05, gnorm=0.287, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=50282
2023-01-08 12:49:08 - progress_bar.py[line:274] - INFO: epoch 001:  12146 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4242, wps=101.4, ups=0.46, wpb=109.7, bsz=40, num_updates=12130, lr=4.66294e-05, gnorm=0.413, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=50304
2023-01-08 12:49:30 - progress_bar.py[line:274] - INFO: epoch 001:  12156 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4313, wps=101.6, ups=0.47, wpb=108.9, bsz=40, num_updates=12140, lr=4.66249e-05, gnorm=0.255, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=50326
2023-01-08 12:49:52 - progress_bar.py[line:274] - INFO: epoch 001:  12166 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4293, wps=101.4, ups=0.47, wpb=108.6, bsz=40, num_updates=12150, lr=4.66204e-05, gnorm=0.341, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=50348
2023-01-08 12:50:14 - progress_bar.py[line:274] - INFO: epoch 001:  12176 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4, wps=99.4, ups=0.46, wpb=108.8, bsz=40, num_updates=12160, lr=4.66159e-05, gnorm=0.518, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=50370
2023-01-08 12:50:36 - progress_bar.py[line:274] - INFO: epoch 001:  12186 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4225, wps=99.7, ups=0.46, wpb=109.5, bsz=40, num_updates=12170, lr=4.66114e-05, gnorm=0.361, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50392
2023-01-08 12:50:58 - progress_bar.py[line:274] - INFO: epoch 001:  12196 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4706, wps=103.3, ups=0.47, wpb=109.4, bsz=40, num_updates=12180, lr=4.66069e-05, gnorm=0.369, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=50414
2023-01-08 12:51:19 - progress_bar.py[line:274] - INFO: epoch 001:  12206 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4093, wps=102.7, ups=0.47, wpb=109.9, bsz=40, num_updates=12190, lr=4.66024e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50435
2023-01-08 12:51:42 - progress_bar.py[line:274] - INFO: epoch 001:  12216 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4393, wps=98.9, ups=0.46, wpb=107.8, bsz=40, num_updates=12200, lr=4.65979e-05, gnorm=0.523, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=50457
2023-01-08 12:52:04 - progress_bar.py[line:274] - INFO: epoch 001:  12226 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3949, wps=100.7, ups=0.46, wpb=109.5, bsz=40, num_updates=12210, lr=4.65934e-05, gnorm=0.379, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=50479
2023-01-08 12:52:25 - progress_bar.py[line:274] - INFO: epoch 001:  12236 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4286, wps=102.1, ups=0.46, wpb=110.2, bsz=40, num_updates=12220, lr=4.65889e-05, gnorm=0.28, clip=0, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=50501
2023-01-08 12:52:47 - progress_bar.py[line:274] - INFO: epoch 001:  12246 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4495, wps=102.1, ups=0.47, wpb=109.4, bsz=40, num_updates=12230, lr=4.65845e-05, gnorm=0.618, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50523
2023-01-08 12:53:09 - progress_bar.py[line:274] - INFO: epoch 001:  12256 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4451, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=12240, lr=4.658e-05, gnorm=0.531, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50545
2023-01-08 12:53:30 - progress_bar.py[line:274] - INFO: epoch 001:  12266 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4143, wps=101.4, ups=0.47, wpb=108.7, bsz=40, num_updates=12250, lr=4.65755e-05, gnorm=0.587, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50566
2023-01-08 12:53:52 - progress_bar.py[line:274] - INFO: epoch 001:  12276 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.449, wps=101, ups=0.46, wpb=109.9, bsz=40, num_updates=12260, lr=4.6571e-05, gnorm=0.472, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50588
2023-01-08 12:54:14 - progress_bar.py[line:274] - INFO: epoch 001:  12286 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4093, wps=100.4, ups=0.46, wpb=109.5, bsz=40, num_updates=12270, lr=4.65665e-05, gnorm=0.346, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=50610
2023-01-08 12:54:36 - progress_bar.py[line:274] - INFO: epoch 001:  12296 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3775, wps=101.5, ups=0.47, wpb=108.1, bsz=40, num_updates=12280, lr=4.6562e-05, gnorm=0.607, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=50632
2023-01-08 12:54:58 - progress_bar.py[line:274] - INFO: epoch 001:  12306 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3944, wps=103.1, ups=0.47, wpb=109.8, bsz=40, num_updates=12290, lr=4.65575e-05, gnorm=0.629, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50653
2023-01-08 12:55:20 - progress_bar.py[line:274] - INFO: epoch 001:  12316 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4521, wps=99.5, ups=0.46, wpb=109.1, bsz=40, num_updates=12300, lr=4.6553e-05, gnorm=0.438, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=50676
2023-01-08 12:55:41 - progress_bar.py[line:274] - INFO: epoch 001:  12326 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.401, wps=103.5, ups=0.47, wpb=109.8, bsz=40, num_updates=12310, lr=4.65485e-05, gnorm=0.541, clip=10, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=50697
2023-01-08 12:56:03 - progress_bar.py[line:274] - INFO: epoch 001:  12336 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4478, wps=101.1, ups=0.47, wpb=108.3, bsz=40, num_updates=12320, lr=4.6544e-05, gnorm=0.492, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50719
2023-01-08 12:56:24 - progress_bar.py[line:274] - INFO: epoch 001:  12346 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4807, wps=104.3, ups=0.47, wpb=111.3, bsz=40, num_updates=12330, lr=4.65395e-05, gnorm=0.442, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=50740
2023-01-08 12:56:46 - progress_bar.py[line:274] - INFO: epoch 001:  12356 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4658, wps=100.4, ups=0.46, wpb=109.2, bsz=40, num_updates=12340, lr=4.6535e-05, gnorm=0.683, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=50762
2023-01-08 12:57:09 - progress_bar.py[line:274] - INFO: epoch 001:  12366 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.393, wps=97.3, ups=0.45, wpb=107.1, bsz=40, num_updates=12350, lr=4.65305e-05, gnorm=0.395, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=50784
2023-01-08 12:57:30 - progress_bar.py[line:274] - INFO: epoch 001:  12376 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4236, wps=106, ups=0.48, wpb=109.3, bsz=40, num_updates=12360, lr=4.6526e-05, gnorm=0.645, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50805
2023-01-08 12:57:52 - progress_bar.py[line:274] - INFO: epoch 001:  12386 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4348, wps=101.6, ups=0.46, wpb=110.5, bsz=40, num_updates=12370, lr=4.65215e-05, gnorm=0.293, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=50827
2023-01-08 12:58:13 - progress_bar.py[line:274] - INFO: epoch 001:  12396 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4171, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=12380, lr=4.6517e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=50849
2023-01-08 12:58:35 - progress_bar.py[line:274] - INFO: epoch 001:  12406 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3881, wps=101.8, ups=0.46, wpb=109.6, bsz=40, num_updates=12390, lr=4.65125e-05, gnorm=0.38, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50871
2023-01-08 12:58:57 - progress_bar.py[line:274] - INFO: epoch 001:  12416 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4053, wps=101.8, ups=0.47, wpb=109.4, bsz=40, num_updates=12400, lr=4.6508e-05, gnorm=0.333, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=50893
2023-01-08 12:59:19 - progress_bar.py[line:274] - INFO: epoch 001:  12426 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4692, wps=101.7, ups=0.47, wpb=108.9, bsz=40, num_updates=12410, lr=4.65035e-05, gnorm=0.371, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=50914
2023-01-08 12:59:41 - progress_bar.py[line:274] - INFO: epoch 001:  12436 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.393, wps=100.9, ups=0.46, wpb=109.7, bsz=40, num_updates=12420, lr=4.6499e-05, gnorm=0.31, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50936
2023-01-08 13:00:02 - progress_bar.py[line:274] - INFO: epoch 001:  12446 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4167, wps=103.5, ups=0.47, wpb=110.7, bsz=40, num_updates=12430, lr=4.64945e-05, gnorm=0.332, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=50958
2023-01-08 13:00:24 - progress_bar.py[line:274] - INFO: epoch 001:  12456 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4038, wps=100.5, ups=0.47, wpb=107.3, bsz=40, num_updates=12440, lr=4.649e-05, gnorm=0.35, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50980
2023-01-08 13:00:46 - progress_bar.py[line:274] - INFO: epoch 001:  12466 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4227, wps=99.7, ups=0.46, wpb=108.3, bsz=40, num_updates=12450, lr=4.64855e-05, gnorm=0.333, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=51002
2023-01-08 13:01:07 - progress_bar.py[line:274] - INFO: epoch 001:  12476 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4573, wps=101.8, ups=0.47, wpb=109.1, bsz=40, num_updates=12460, lr=4.6481e-05, gnorm=0.461, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51023
2023-01-08 13:01:29 - progress_bar.py[line:274] - INFO: epoch 001:  12486 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4472, wps=102.7, ups=0.47, wpb=108.8, bsz=40, num_updates=12470, lr=4.64765e-05, gnorm=0.366, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51045
2023-01-08 13:01:51 - progress_bar.py[line:274] - INFO: epoch 001:  12496 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3416, wps=99.7, ups=0.46, wpb=108.6, bsz=40, num_updates=12480, lr=4.64721e-05, gnorm=0.387, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51067
2023-01-08 13:02:12 - progress_bar.py[line:274] - INFO: epoch 001:  12506 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4385, wps=102.7, ups=0.47, wpb=109.8, bsz=40, num_updates=12490, lr=4.64676e-05, gnorm=0.515, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51088
2023-01-08 13:02:34 - progress_bar.py[line:274] - INFO: epoch 001:  12516 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4133, wps=103.9, ups=0.47, wpb=109.5, bsz=40, num_updates=12500, lr=4.64631e-05, gnorm=0.708, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51110
2023-01-08 13:02:56 - progress_bar.py[line:274] - INFO: epoch 001:  12526 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3981, wps=99.9, ups=0.46, wpb=109, bsz=40, num_updates=12510, lr=4.64586e-05, gnorm=0.448, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=51132
2023-01-08 13:03:18 - progress_bar.py[line:274] - INFO: epoch 001:  12536 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4706, wps=102.2, ups=0.46, wpb=110.1, bsz=40, num_updates=12520, lr=4.64541e-05, gnorm=0.345, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51154
2023-01-08 13:03:40 - progress_bar.py[line:274] - INFO: epoch 001:  12546 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4339, wps=101.2, ups=0.46, wpb=109.7, bsz=40, num_updates=12530, lr=4.64496e-05, gnorm=0.439, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=51176
2023-01-08 13:04:02 - progress_bar.py[line:274] - INFO: epoch 001:  12556 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.439, wps=100.7, ups=0.47, wpb=107.5, bsz=40, num_updates=12540, lr=4.64451e-05, gnorm=0.53, clip=10, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=51198
2023-01-08 13:04:24 - progress_bar.py[line:274] - INFO: epoch 001:  12566 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4836, wps=100.5, ups=0.46, wpb=108.1, bsz=40, num_updates=12550, lr=4.64406e-05, gnorm=0.295, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51220
2023-01-08 13:04:46 - progress_bar.py[line:274] - INFO: epoch 001:  12576 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4462, wps=102.9, ups=0.47, wpb=110.3, bsz=40, num_updates=12560, lr=4.64361e-05, gnorm=0.316, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=51242
2023-01-08 13:05:09 - progress_bar.py[line:274] - INFO: epoch 001:  12586 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3861, wps=100.3, ups=0.46, wpb=109.8, bsz=40, num_updates=12570, lr=4.64316e-05, gnorm=0.289, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=51264
2023-01-08 13:05:31 - progress_bar.py[line:274] - INFO: epoch 001:  12596 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4682, wps=99, ups=0.46, wpb=108.4, bsz=40, num_updates=12580, lr=4.64271e-05, gnorm=0.345, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51287
2023-01-08 13:05:54 - progress_bar.py[line:274] - INFO: epoch 001:  12606 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3938, wps=100.5, ups=0.46, wpb=109.1, bsz=40, num_updates=12590, lr=4.64226e-05, gnorm=0.515, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=51309
2023-01-08 13:06:16 - progress_bar.py[line:274] - INFO: epoch 001:  12616 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4225, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=12600, lr=4.64181e-05, gnorm=0.633, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51332
2023-01-08 13:06:38 - progress_bar.py[line:274] - INFO: epoch 001:  12626 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3814, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=12610, lr=4.64136e-05, gnorm=0.406, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=51354
2023-01-08 13:07:00 - progress_bar.py[line:274] - INFO: epoch 001:  12636 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4162, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=12620, lr=4.64091e-05, gnorm=0.485, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51376
2023-01-08 13:07:23 - progress_bar.py[line:274] - INFO: epoch 001:  12646 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4439, wps=101.2, ups=0.46, wpb=109.5, bsz=40, num_updates=12630, lr=4.64046e-05, gnorm=0.368, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51398
2023-01-08 13:07:45 - progress_bar.py[line:274] - INFO: epoch 001:  12656 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3854, wps=100.4, ups=0.46, wpb=108.6, bsz=40, num_updates=12640, lr=4.64001e-05, gnorm=0.434, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51420
2023-01-08 13:08:07 - progress_bar.py[line:274] - INFO: epoch 001:  12666 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3854, wps=99.7, ups=0.46, wpb=107.4, bsz=40, num_updates=12650, lr=4.63956e-05, gnorm=0.717, clip=20, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=51442
2023-01-08 13:08:30 - progress_bar.py[line:274] - INFO: epoch 001:  12676 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3838, wps=101, ups=0.46, wpb=110, bsz=40, num_updates=12660, lr=4.63911e-05, gnorm=0.316, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51465
2023-01-08 13:08:52 - progress_bar.py[line:274] - INFO: epoch 001:  12686 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.382, wps=102.4, ups=0.46, wpb=111.1, bsz=40, num_updates=12670, lr=4.63866e-05, gnorm=0.455, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51487
2023-01-08 13:09:15 - progress_bar.py[line:274] - INFO: epoch 001:  12696 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4599, wps=100.8, ups=0.46, wpb=109.7, bsz=40, num_updates=12680, lr=4.63821e-05, gnorm=0.365, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=51510
2023-01-08 13:09:37 - progress_bar.py[line:274] - INFO: epoch 001:  12706 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4049, wps=100.5, ups=0.46, wpb=108.2, bsz=40, num_updates=12690, lr=4.63776e-05, gnorm=0.348, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51532
2023-01-08 13:09:59 - progress_bar.py[line:274] - INFO: epoch 001:  12716 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4194, wps=100.8, ups=0.46, wpb=109.5, bsz=40, num_updates=12700, lr=4.63731e-05, gnorm=0.232, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51555
2023-01-08 13:10:21 - progress_bar.py[line:274] - INFO: epoch 001:  12726 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4, wps=101.1, ups=0.47, wpb=108.5, bsz=40, num_updates=12710, lr=4.63686e-05, gnorm=0.453, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51577
2023-01-08 13:10:43 - progress_bar.py[line:274] - INFO: epoch 001:  12736 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4052, wps=100.7, ups=0.47, wpb=107.5, bsz=40, num_updates=12720, lr=4.63642e-05, gnorm=0.385, clip=10, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=51599
2023-01-08 13:11:05 - progress_bar.py[line:274] - INFO: epoch 001:  12746 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4677, wps=103.5, ups=0.47, wpb=110.2, bsz=40, num_updates=12730, lr=4.63597e-05, gnorm=0.351, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=51621
2023-01-08 13:11:27 - progress_bar.py[line:274] - INFO: epoch 001:  12756 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4115, wps=104.6, ups=0.47, wpb=110.2, bsz=40, num_updates=12740, lr=4.63552e-05, gnorm=0.368, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51642
2023-01-08 13:11:49 - progress_bar.py[line:274] - INFO: epoch 001:  12766 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4385, wps=100.6, ups=0.46, wpb=109.5, bsz=40, num_updates=12750, lr=4.63507e-05, gnorm=0.381, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=51665
2023-01-08 13:12:12 - progress_bar.py[line:274] - INFO: epoch 001:  12776 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4589, wps=100.5, ups=0.46, wpb=109.4, bsz=40, num_updates=12760, lr=4.63462e-05, gnorm=0.456, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=51687
2023-01-08 13:12:33 - progress_bar.py[line:274] - INFO: epoch 001:  12786 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4468, wps=102.5, ups=0.47, wpb=108.4, bsz=40, num_updates=12770, lr=4.63417e-05, gnorm=0.564, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51709
2023-01-08 13:12:56 - progress_bar.py[line:274] - INFO: epoch 001:  12796 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4476, wps=99.8, ups=0.46, wpb=108.4, bsz=40, num_updates=12780, lr=4.63372e-05, gnorm=0.334, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=51731
2023-01-08 13:13:18 - progress_bar.py[line:274] - INFO: epoch 001:  12806 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3801, wps=98.9, ups=0.46, wpb=106.5, bsz=40, num_updates=12790, lr=4.63327e-05, gnorm=0.43, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51753
2023-01-08 13:13:40 - progress_bar.py[line:274] - INFO: epoch 001:  12816 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4216, wps=101.4, ups=0.47, wpb=108.5, bsz=40, num_updates=12800, lr=4.63282e-05, gnorm=0.402, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51775
2023-01-08 13:14:02 - progress_bar.py[line:274] - INFO: epoch 001:  12826 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4759, wps=103, ups=0.47, wpb=110.1, bsz=40, num_updates=12810, lr=4.63237e-05, gnorm=0.355, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51797
2023-01-08 13:14:24 - progress_bar.py[line:274] - INFO: epoch 001:  12836 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4129, wps=97.8, ups=0.45, wpb=108.4, bsz=40, num_updates=12820, lr=4.63192e-05, gnorm=0.253, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51820
2023-01-08 13:14:27 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 13:14:49 - progress_bar.py[line:274] - INFO: epoch 001:  12847 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.048, nsentences=40, sample_size=109.048, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3721, wps=96.2, ups=0.42, wpb=109, bsz=40, num_updates=12830, lr=4.63147e-05, gnorm=0.394, clip=0, loss_scale=512, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=51844
2023-01-08 13:15:10 - progress_bar.py[line:274] - INFO: epoch 001:  12857 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4527, wps=103.2, ups=0.48, wpb=108.6, bsz=40, num_updates=12840, lr=4.63102e-05, gnorm=0.629, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=51866
2023-01-08 13:15:32 - progress_bar.py[line:274] - INFO: epoch 001:  12867 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4868, wps=103.3, ups=0.47, wpb=110.4, bsz=40, num_updates=12850, lr=4.63057e-05, gnorm=0.787, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51888
2023-01-08 13:15:54 - progress_bar.py[line:274] - INFO: epoch 001:  12877 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4293, wps=101.8, ups=0.46, wpb=109.8, bsz=40, num_updates=12860, lr=4.63012e-05, gnorm=0.514, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=51910
2023-01-08 13:16:16 - progress_bar.py[line:274] - INFO: epoch 001:  12887 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4819, wps=102, ups=0.47, wpb=109.4, bsz=40, num_updates=12870, lr=4.62967e-05, gnorm=0.584, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=51932
2023-01-08 13:16:38 - progress_bar.py[line:274] - INFO: epoch 001:  12897 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3743, wps=103, ups=0.47, wpb=110.4, bsz=40, num_updates=12880, lr=4.62922e-05, gnorm=0.362, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51954
2023-01-08 13:17:00 - progress_bar.py[line:274] - INFO: epoch 001:  12907 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4536, wps=104.3, ups=0.47, wpb=110.2, bsz=40, num_updates=12890, lr=4.62877e-05, gnorm=0.4, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=51976
2023-01-08 13:17:22 - progress_bar.py[line:274] - INFO: epoch 001:  12917 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4265, wps=101.4, ups=0.47, wpb=108.8, bsz=40, num_updates=12900, lr=4.62832e-05, gnorm=0.274, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=51998
2023-01-08 13:17:44 - progress_bar.py[line:274] - INFO: epoch 001:  12927 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4244, wps=101.5, ups=0.47, wpb=108.5, bsz=40, num_updates=12910, lr=4.62787e-05, gnorm=0.344, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=52020
2023-01-08 13:18:07 - progress_bar.py[line:274] - INFO: epoch 001:  12937 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4368, wps=101.2, ups=0.46, wpb=109.7, bsz=40, num_updates=12920, lr=4.62742e-05, gnorm=0.353, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=52042
2023-01-08 13:18:29 - progress_bar.py[line:274] - INFO: epoch 001:  12947 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3788, wps=100, ups=0.46, wpb=109.1, bsz=40, num_updates=12930, lr=4.62697e-05, gnorm=0.312, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=52064
2023-01-08 13:18:51 - progress_bar.py[line:274] - INFO: epoch 001:  12957 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4158, wps=101.5, ups=0.46, wpb=110, bsz=40, num_updates=12940, lr=4.62652e-05, gnorm=0.354, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52087
2023-01-08 13:19:14 - progress_bar.py[line:274] - INFO: epoch 001:  12967 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4039, wps=100.4, ups=0.46, wpb=108.9, bsz=40, num_updates=12950, lr=4.62607e-05, gnorm=0.529, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52109
2023-01-08 13:19:35 - progress_bar.py[line:274] - INFO: epoch 001:  12977 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.495, wps=101.6, ups=0.47, wpb=108, bsz=40, num_updates=12960, lr=4.62562e-05, gnorm=0.316, clip=0, loss_scale=512, train_wall=21, gb_free=9.4, ema_decay=0.9999, wall=52131
2023-01-08 13:19:58 - progress_bar.py[line:274] - INFO: epoch 001:  12987 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.401, wps=101.5, ups=0.46, wpb=109.2, bsz=40, num_updates=12970, lr=4.62518e-05, gnorm=0.504, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52153
2023-01-08 13:20:19 - progress_bar.py[line:274] - INFO: epoch 001:  12997 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4774, wps=102.7, ups=0.47, wpb=108.7, bsz=40, num_updates=12980, lr=4.62473e-05, gnorm=0.625, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52175
2023-01-08 13:20:34 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 13:20:44 - progress_bar.py[line:274] - INFO: epoch 001:  13008 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.619, nsentences=40, sample_size=108.619, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4692, wps=95.7, ups=0.42, wpb=108.6, bsz=40, num_updates=12990, lr=4.62428e-05, gnorm=0.366, clip=0, loss_scale=256, train_wall=24, gb_free=9.9, ema_decay=0.9999, wall=52199
2023-01-08 13:21:06 - progress_bar.py[line:274] - INFO: epoch 001:  13018 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4231, wps=100.7, ups=0.46, wpb=108.9, bsz=40, num_updates=13000, lr=4.62383e-05, gnorm=0.344, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52221
2023-01-08 13:21:27 - progress_bar.py[line:274] - INFO: epoch 001:  13028 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4462, wps=105.8, ups=0.48, wpb=110, bsz=40, num_updates=13010, lr=4.62338e-05, gnorm=0.836, clip=30, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52243
2023-01-08 13:21:49 - progress_bar.py[line:274] - INFO: epoch 001:  13038 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3578, wps=100.2, ups=0.46, wpb=109.1, bsz=40, num_updates=13020, lr=4.62293e-05, gnorm=0.643, clip=30, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52265
2023-01-08 13:22:11 - progress_bar.py[line:274] - INFO: epoch 001:  13048 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5106, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=13030, lr=4.62248e-05, gnorm=0.513, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52287
2023-01-08 13:22:33 - progress_bar.py[line:274] - INFO: epoch 001:  13058 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.398, wps=101.3, ups=0.47, wpb=108.9, bsz=40, num_updates=13040, lr=4.62203e-05, gnorm=0.396, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=52308
2023-01-08 13:22:54 - progress_bar.py[line:274] - INFO: epoch 001:  13068 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4608, wps=100.2, ups=0.47, wpb=107.7, bsz=40, num_updates=13050, lr=4.62158e-05, gnorm=0.498, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52330
2023-01-08 13:23:16 - progress_bar.py[line:274] - INFO: epoch 001:  13078 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4359, wps=100.6, ups=0.46, wpb=108.6, bsz=40, num_updates=13060, lr=4.62113e-05, gnorm=0.423, clip=10, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=52352
2023-01-08 13:23:38 - progress_bar.py[line:274] - INFO: epoch 001:  13088 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4163, wps=98.1, ups=0.46, wpb=107.3, bsz=40, num_updates=13070, lr=4.62068e-05, gnorm=0.314, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52374
2023-01-08 13:24:00 - progress_bar.py[line:274] - INFO: epoch 001:  13098 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4301, wps=101.5, ups=0.46, wpb=110, bsz=40, num_updates=13080, lr=4.62023e-05, gnorm=0.393, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=52396
2023-01-08 13:24:22 - progress_bar.py[line:274] - INFO: epoch 001:  13108 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4213, wps=99.6, ups=0.46, wpb=108.2, bsz=40, num_updates=13090, lr=4.61978e-05, gnorm=0.402, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52418
2023-01-08 13:24:44 - progress_bar.py[line:274] - INFO: epoch 001:  13118 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4703, wps=100.4, ups=0.46, wpb=108.6, bsz=40, num_updates=13100, lr=4.61933e-05, gnorm=0.318, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=52440
2023-01-08 13:25:06 - progress_bar.py[line:274] - INFO: epoch 001:  13128 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5, wps=99.7, ups=0.46, wpb=108.2, bsz=40, num_updates=13110, lr=4.61888e-05, gnorm=0.394, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=52462
2023-01-08 13:25:27 - progress_bar.py[line:274] - INFO: epoch 001:  13138 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4592, wps=102.6, ups=0.47, wpb=109, bsz=40, num_updates=13120, lr=4.61843e-05, gnorm=0.386, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52483
2023-01-08 13:25:49 - progress_bar.py[line:274] - INFO: epoch 001:  13148 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4085, wps=101.5, ups=0.47, wpb=108.4, bsz=40, num_updates=13130, lr=4.61798e-05, gnorm=0.494, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52505
2023-01-08 13:26:11 - progress_bar.py[line:274] - INFO: epoch 001:  13158 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4481, wps=102.4, ups=0.47, wpb=109.8, bsz=40, num_updates=13140, lr=4.61753e-05, gnorm=0.285, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52526
2023-01-08 13:26:33 - progress_bar.py[line:274] - INFO: epoch 001:  13168 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4138, wps=105.8, ups=0.47, wpb=111.5, bsz=40, num_updates=13150, lr=4.61708e-05, gnorm=0.386, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=52548
2023-01-08 13:26:54 - progress_bar.py[line:274] - INFO: epoch 001:  13178 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3834, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=13160, lr=4.61663e-05, gnorm=0.497, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52570
2023-01-08 13:27:17 - progress_bar.py[line:274] - INFO: epoch 001:  13188 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3717, wps=100.1, ups=0.45, wpb=110.5, bsz=40, num_updates=13170, lr=4.61618e-05, gnorm=0.402, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=52592
2023-01-08 13:27:39 - progress_bar.py[line:274] - INFO: epoch 001:  13198 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3904, wps=100.1, ups=0.46, wpb=109.1, bsz=40, num_updates=13180, lr=4.61573e-05, gnorm=0.398, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=52615
2023-01-08 13:28:02 - progress_bar.py[line:274] - INFO: epoch 001:  13208 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4031, wps=101.6, ups=0.47, wpb=109, bsz=40, num_updates=13190, lr=4.61528e-05, gnorm=0.304, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52636
2023-01-08 13:28:24 - progress_bar.py[line:274] - INFO: epoch 001:  13218 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4264, wps=101.9, ups=0.46, wpb=111, bsz=40, num_updates=13200, lr=4.61483e-05, gnorm=0.297, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=52659
2023-01-08 13:28:45 - progress_bar.py[line:274] - INFO: epoch 001:  13228 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4263, wps=101.5, ups=0.47, wpb=108.8, bsz=40, num_updates=13210, lr=4.61439e-05, gnorm=0.357, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52681
2023-01-08 13:29:07 - progress_bar.py[line:274] - INFO: epoch 001:  13238 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=106.6, nsentences=40, sample_size=106.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3818, wps=99.8, ups=0.47, wpb=106.6, bsz=40, num_updates=13220, lr=4.61394e-05, gnorm=0.438, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52703
2023-01-08 13:29:28 - progress_bar.py[line:274] - INFO: epoch 001:  13248 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4755, wps=102.3, ups=0.47, wpb=109.1, bsz=40, num_updates=13230, lr=4.61349e-05, gnorm=0.388, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52724
2023-01-08 13:29:50 - progress_bar.py[line:274] - INFO: epoch 001:  13258 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4323, wps=100.6, ups=0.46, wpb=109.8, bsz=40, num_updates=13240, lr=4.61304e-05, gnorm=0.369, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52746
2023-01-08 13:30:12 - progress_bar.py[line:274] - INFO: epoch 001:  13268 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3602, wps=101.9, ups=0.47, wpb=108.4, bsz=40, num_updates=13250, lr=4.61259e-05, gnorm=0.356, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52768
2023-01-08 13:30:33 - progress_bar.py[line:274] - INFO: epoch 001:  13278 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4247, wps=103.7, ups=0.47, wpb=110.2, bsz=40, num_updates=13260, lr=4.61214e-05, gnorm=0.318, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52789
2023-01-08 13:30:55 - progress_bar.py[line:274] - INFO: epoch 001:  13288 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4512, wps=102.9, ups=0.47, wpb=108.7, bsz=40, num_updates=13270, lr=4.61169e-05, gnorm=0.504, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52811
2023-01-08 13:31:16 - progress_bar.py[line:274] - INFO: epoch 001:  13298 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4103, wps=103.4, ups=0.47, wpb=109.4, bsz=40, num_updates=13280, lr=4.61124e-05, gnorm=0.329, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52832
2023-01-08 13:31:38 - progress_bar.py[line:274] - INFO: epoch 001:  13308 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4706, wps=101.6, ups=0.47, wpb=108.4, bsz=40, num_updates=13290, lr=4.61079e-05, gnorm=0.494, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52854
2023-01-08 13:32:00 - progress_bar.py[line:274] - INFO: epoch 001:  13318 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4179, wps=99.8, ups=0.46, wpb=107.5, bsz=40, num_updates=13300, lr=4.61034e-05, gnorm=0.422, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52875
2023-01-08 13:32:21 - progress_bar.py[line:274] - INFO: epoch 001:  13328 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.366, wps=102.1, ups=0.46, wpb=109.8, bsz=40, num_updates=13310, lr=4.60989e-05, gnorm=0.677, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52897
2023-01-08 13:32:43 - progress_bar.py[line:274] - INFO: epoch 001:  13338 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4615, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=13320, lr=4.60944e-05, gnorm=0.35, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=52919
2023-01-08 13:33:05 - progress_bar.py[line:274] - INFO: epoch 001:  13348 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3889, wps=98.5, ups=0.46, wpb=107.8, bsz=40, num_updates=13330, lr=4.60899e-05, gnorm=0.451, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=52941
2023-01-08 13:33:27 - progress_bar.py[line:274] - INFO: epoch 001:  13358 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3952, wps=101.1, ups=0.47, wpb=107.8, bsz=40, num_updates=13340, lr=4.60854e-05, gnorm=0.374, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52963
2023-01-08 13:33:48 - progress_bar.py[line:274] - INFO: epoch 001:  13368 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4585, wps=101, ups=0.47, wpb=107.8, bsz=40, num_updates=13350, lr=4.60809e-05, gnorm=0.313, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=52984
2023-01-08 13:34:10 - progress_bar.py[line:274] - INFO: epoch 001:  13378 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4792, wps=103.7, ups=0.47, wpb=110.1, bsz=40, num_updates=13360, lr=4.60764e-05, gnorm=0.329, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53006
2023-01-08 13:34:32 - progress_bar.py[line:274] - INFO: epoch 001:  13388 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4924, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=13370, lr=4.60719e-05, gnorm=0.641, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53027
2023-01-08 13:34:53 - progress_bar.py[line:274] - INFO: epoch 001:  13398 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.407, wps=101.1, ups=0.47, wpb=108.7, bsz=40, num_updates=13380, lr=4.60674e-05, gnorm=0.308, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53049
2023-01-08 13:35:15 - progress_bar.py[line:274] - INFO: epoch 001:  13408 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4536, wps=101.1, ups=0.47, wpb=108.3, bsz=40, num_updates=13390, lr=4.60629e-05, gnorm=0.393, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53071
2023-01-08 13:35:37 - progress_bar.py[line:274] - INFO: epoch 001:  13418 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4366, wps=99.2, ups=0.46, wpb=107.4, bsz=40, num_updates=13400, lr=4.60584e-05, gnorm=0.373, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=53093
2023-01-08 13:35:58 - progress_bar.py[line:274] - INFO: epoch 001:  13428 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4158, wps=104.2, ups=0.47, wpb=110.8, bsz=40, num_updates=13410, lr=4.60539e-05, gnorm=0.383, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53114
2023-01-08 13:36:20 - progress_bar.py[line:274] - INFO: epoch 001:  13438 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.476, wps=101.6, ups=0.47, wpb=108.2, bsz=40, num_updates=13420, lr=4.60494e-05, gnorm=0.434, clip=0, loss_scale=256, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=53136
2023-01-08 13:36:41 - progress_bar.py[line:274] - INFO: epoch 001:  13448 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.412, wps=100.6, ups=0.47, wpb=108, bsz=40, num_updates=13430, lr=4.60449e-05, gnorm=0.391, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=53157
2023-01-08 13:37:03 - progress_bar.py[line:274] - INFO: epoch 001:  13458 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.445, wps=102.5, ups=0.47, wpb=108.4, bsz=40, num_updates=13440, lr=4.60404e-05, gnorm=0.293, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=53179
2023-01-08 13:37:24 - progress_bar.py[line:274] - INFO: epoch 001:  13468 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4423, wps=101.7, ups=0.47, wpb=108.9, bsz=40, num_updates=13450, lr=4.60359e-05, gnorm=0.392, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53200
2023-01-08 13:37:46 - progress_bar.py[line:274] - INFO: epoch 001:  13478 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4124, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=13460, lr=4.60315e-05, gnorm=0.268, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=53222
2023-01-08 13:38:08 - progress_bar.py[line:274] - INFO: epoch 001:  13488 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4089, wps=98.8, ups=0.46, wpb=107.5, bsz=40, num_updates=13470, lr=4.6027e-05, gnorm=0.378, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=53244
2023-01-08 13:38:30 - progress_bar.py[line:274] - INFO: epoch 001:  13498 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4316, wps=101.4, ups=0.46, wpb=109.8, bsz=40, num_updates=13480, lr=4.60225e-05, gnorm=0.325, clip=0, loss_scale=256, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=53266
2023-01-08 13:38:53 - progress_bar.py[line:274] - INFO: epoch 001:  13508 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4194, wps=99.5, ups=0.45, wpb=110, bsz=40, num_updates=13490, lr=4.6018e-05, gnorm=0.334, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=53288
2023-01-08 13:39:14 - progress_bar.py[line:274] - INFO: epoch 001:  13518 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4663, wps=101.3, ups=0.46, wpb=109.1, bsz=40, num_updates=13500, lr=4.60135e-05, gnorm=0.698, clip=30, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=53310
2023-01-08 13:39:36 - progress_bar.py[line:274] - INFO: epoch 001:  13528 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4239, wps=103.3, ups=0.47, wpb=110.7, bsz=40, num_updates=13510, lr=4.6009e-05, gnorm=0.518, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=53332
2023-01-08 13:39:58 - progress_bar.py[line:274] - INFO: epoch 001:  13538 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4767, wps=103, ups=0.47, wpb=109.6, bsz=40, num_updates=13520, lr=4.60045e-05, gnorm=0.361, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=53353
2023-01-08 13:40:19 - progress_bar.py[line:274] - INFO: epoch 001:  13548 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4109, wps=102.3, ups=0.47, wpb=109.7, bsz=40, num_updates=13530, lr=4.6e-05, gnorm=0.354, clip=0, loss_scale=512, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=53375
2023-01-08 13:40:39 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 13:40:43 - progress_bar.py[line:274] - INFO: epoch 001:  13559 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.286, nsentences=40, sample_size=108.286, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4888, wps=96.9, ups=0.43, wpb=108.3, bsz=40, num_updates=13540, lr=4.59955e-05, gnorm=0.364, clip=0, loss_scale=256, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=53399
2023-01-08 13:41:05 - progress_bar.py[line:274] - INFO: epoch 001:  13569 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4747, wps=101.2, ups=0.47, wpb=108.7, bsz=40, num_updates=13550, lr=4.5991e-05, gnorm=0.282, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53420
2023-01-08 13:41:26 - progress_bar.py[line:274] - INFO: epoch 001:  13579 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4366, wps=100, ups=0.47, wpb=107.5, bsz=40, num_updates=13560, lr=4.59865e-05, gnorm=0.295, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53442
2023-01-08 13:41:48 - progress_bar.py[line:274] - INFO: epoch 001:  13589 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4811, wps=103.4, ups=0.47, wpb=110.3, bsz=40, num_updates=13570, lr=4.5982e-05, gnorm=0.557, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53464
2023-01-08 13:42:10 - progress_bar.py[line:274] - INFO: epoch 001:  13599 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.415, wps=102, ups=0.47, wpb=108.9, bsz=40, num_updates=13580, lr=4.59775e-05, gnorm=0.37, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53485
2023-01-08 13:42:31 - progress_bar.py[line:274] - INFO: epoch 001:  13609 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=100.8, ups=0.46, wpb=109.7, bsz=40, num_updates=13590, lr=4.5973e-05, gnorm=0.447, clip=0, loss_scale=256, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=53507
2023-01-08 13:42:53 - progress_bar.py[line:274] - INFO: epoch 001:  13619 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3897, wps=100.6, ups=0.46, wpb=109.3, bsz=40, num_updates=13600, lr=4.59685e-05, gnorm=0.407, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=53529
2023-01-08 13:43:15 - progress_bar.py[line:274] - INFO: epoch 001:  13629 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3829, wps=103.5, ups=0.47, wpb=109.9, bsz=40, num_updates=13610, lr=4.5964e-05, gnorm=0.497, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=53551
2023-01-08 13:43:36 - progress_bar.py[line:274] - INFO: epoch 001:  13639 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4626, wps=100.8, ups=0.47, wpb=107.3, bsz=40, num_updates=13620, lr=4.59595e-05, gnorm=0.435, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53572
2023-01-08 13:43:58 - progress_bar.py[line:274] - INFO: epoch 001:  13649 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.393, wps=101.1, ups=0.46, wpb=109.7, bsz=40, num_updates=13630, lr=4.5955e-05, gnorm=0.429, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=53594
2023-01-08 13:44:20 - progress_bar.py[line:274] - INFO: epoch 001:  13659 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4819, wps=101.5, ups=0.46, wpb=109.8, bsz=40, num_updates=13640, lr=4.59505e-05, gnorm=0.305, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=53616
2023-01-08 13:44:42 - progress_bar.py[line:274] - INFO: epoch 001:  13669 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4162, wps=105.7, ups=0.47, wpb=112.2, bsz=40, num_updates=13650, lr=4.5946e-05, gnorm=0.298, clip=0, loss_scale=256, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=53638
2023-01-08 13:45:04 - progress_bar.py[line:274] - INFO: epoch 001:  13679 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4528, wps=99.8, ups=0.46, wpb=109.4, bsz=40, num_updates=13660, lr=4.59415e-05, gnorm=0.441, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=53660
2023-01-08 13:45:25 - progress_bar.py[line:274] - INFO: epoch 001:  13689 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3846, wps=102.8, ups=0.47, wpb=109.6, bsz=40, num_updates=13670, lr=4.5937e-05, gnorm=0.277, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=53681
2023-01-08 13:45:47 - progress_bar.py[line:274] - INFO: epoch 001:  13699 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4085, wps=100.4, ups=0.46, wpb=108.9, bsz=40, num_updates=13680, lr=4.59325e-05, gnorm=0.375, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=53703
2023-01-08 13:46:09 - progress_bar.py[line:274] - INFO: epoch 001:  13709 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4153, wps=102.9, ups=0.47, wpb=109.5, bsz=40, num_updates=13690, lr=4.5928e-05, gnorm=0.265, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53725
2023-01-08 13:46:31 - progress_bar.py[line:274] - INFO: epoch 001:  13719 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4278, wps=101.5, ups=0.46, wpb=110.8, bsz=40, num_updates=13700, lr=4.59236e-05, gnorm=0.466, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=53747
2023-01-08 13:46:53 - progress_bar.py[line:274] - INFO: epoch 001:  13729 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4627, wps=101.6, ups=0.46, wpb=109.9, bsz=40, num_updates=13710, lr=4.59191e-05, gnorm=0.5, clip=10, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=53769
2023-01-08 13:47:14 - progress_bar.py[line:274] - INFO: epoch 001:  13739 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3716, wps=103.2, ups=0.47, wpb=110.8, bsz=40, num_updates=13720, lr=4.59146e-05, gnorm=0.321, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=53790
2023-01-08 13:47:36 - progress_bar.py[line:274] - INFO: epoch 001:  13749 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3586, wps=102.2, ups=0.46, wpb=109.9, bsz=40, num_updates=13730, lr=4.59101e-05, gnorm=0.331, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53812
2023-01-08 13:47:58 - progress_bar.py[line:274] - INFO: epoch 001:  13759 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.432, wps=99.7, ups=0.46, wpb=108.8, bsz=40, num_updates=13740, lr=4.59056e-05, gnorm=0.456, clip=10, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=53834
2023-01-08 13:48:20 - progress_bar.py[line:274] - INFO: epoch 001:  13769 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.5023, wps=101.2, ups=0.47, wpb=108.5, bsz=40, num_updates=13750, lr=4.59011e-05, gnorm=0.359, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53856
2023-01-08 13:48:42 - progress_bar.py[line:274] - INFO: epoch 001:  13779 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4183, wps=100, ups=0.46, wpb=109.2, bsz=40, num_updates=13760, lr=4.58966e-05, gnorm=0.321, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=53878
2023-01-08 13:49:04 - progress_bar.py[line:274] - INFO: epoch 001:  13789 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4444, wps=103.5, ups=0.47, wpb=109.5, bsz=40, num_updates=13770, lr=4.58921e-05, gnorm=0.387, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53899
2023-01-08 13:49:25 - progress_bar.py[line:274] - INFO: epoch 001:  13799 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.451, wps=100.9, ups=0.47, wpb=108.1, bsz=40, num_updates=13780, lr=4.58876e-05, gnorm=0.32, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53921
2023-01-08 13:49:47 - progress_bar.py[line:274] - INFO: epoch 001:  13809 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.446, wps=98.4, ups=0.46, wpb=107.1, bsz=40, num_updates=13790, lr=4.58831e-05, gnorm=0.34, clip=0, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=53943
2023-01-08 13:50:08 - progress_bar.py[line:274] - INFO: epoch 001:  13819 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4158, wps=104.4, ups=0.48, wpb=109.3, bsz=40, num_updates=13800, lr=4.58786e-05, gnorm=0.384, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53964
2023-01-08 13:50:31 - progress_bar.py[line:274] - INFO: epoch 001:  13829 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4444, wps=99.2, ups=0.46, wpb=108.9, bsz=40, num_updates=13810, lr=4.58741e-05, gnorm=0.427, clip=0, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=53986
2023-01-08 13:50:52 - progress_bar.py[line:274] - INFO: epoch 001:  13839 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4167, wps=99.7, ups=0.46, wpb=107.8, bsz=40, num_updates=13820, lr=4.58696e-05, gnorm=0.352, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=54008
2023-01-08 13:51:14 - progress_bar.py[line:274] - INFO: epoch 001:  13849 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4877, wps=101.1, ups=0.46, wpb=109.1, bsz=40, num_updates=13830, lr=4.58651e-05, gnorm=0.248, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=54030
2023-01-08 13:51:36 - progress_bar.py[line:274] - INFO: epoch 001:  13859 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4136, wps=102.1, ups=0.46, wpb=110, bsz=40, num_updates=13840, lr=4.58606e-05, gnorm=0.201, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=54052
2023-01-08 13:51:58 - progress_bar.py[line:274] - INFO: epoch 001:  13869 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4069, wps=100.6, ups=0.47, wpb=107.7, bsz=40, num_updates=13850, lr=4.58561e-05, gnorm=0.413, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54073
2023-01-08 13:52:19 - progress_bar.py[line:274] - INFO: epoch 001:  13879 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4639, wps=104.4, ups=0.48, wpb=108.5, bsz=40, num_updates=13860, lr=4.58516e-05, gnorm=0.412, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54095
2023-01-08 13:52:41 - progress_bar.py[line:274] - INFO: epoch 001:  13889 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4189, wps=100.3, ups=0.47, wpb=107.8, bsz=40, num_updates=13870, lr=4.58471e-05, gnorm=0.443, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54116
2023-01-08 13:53:02 - progress_bar.py[line:274] - INFO: epoch 001:  13899 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4599, wps=103.2, ups=0.47, wpb=109.7, bsz=40, num_updates=13880, lr=4.58426e-05, gnorm=0.445, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=54138
2023-01-08 13:53:24 - progress_bar.py[line:274] - INFO: epoch 001:  13909 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4772, wps=102.3, ups=0.47, wpb=109.5, bsz=40, num_updates=13890, lr=4.58381e-05, gnorm=0.305, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54160
2023-01-08 13:53:45 - progress_bar.py[line:274] - INFO: epoch 001:  13919 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5238, wps=101.2, ups=0.47, wpb=108.6, bsz=40, num_updates=13900, lr=4.58336e-05, gnorm=0.416, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54181
2023-01-08 13:54:07 - progress_bar.py[line:274] - INFO: epoch 001:  13929 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3831, wps=101.1, ups=0.46, wpb=110, bsz=40, num_updates=13910, lr=4.58291e-05, gnorm=0.437, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=54203
2023-01-08 13:54:29 - progress_bar.py[line:274] - INFO: epoch 001:  13939 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4874, wps=102.1, ups=0.47, wpb=109.4, bsz=40, num_updates=13920, lr=4.58246e-05, gnorm=0.431, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=54225
2023-01-08 13:54:51 - progress_bar.py[line:274] - INFO: epoch 001:  13949 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.407, wps=99.6, ups=0.46, wpb=108.9, bsz=40, num_updates=13930, lr=4.58201e-05, gnorm=0.361, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=54247
2023-01-08 13:55:13 - progress_bar.py[line:274] - INFO: epoch 001:  13959 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3959, wps=103.2, ups=0.47, wpb=109.6, bsz=40, num_updates=13940, lr=4.58156e-05, gnorm=0.292, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=54268
2023-01-08 13:55:34 - progress_bar.py[line:274] - INFO: epoch 001:  13969 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4764, wps=102.1, ups=0.47, wpb=108.2, bsz=40, num_updates=13950, lr=4.58112e-05, gnorm=0.31, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=54290
2023-01-08 13:55:56 - progress_bar.py[line:274] - INFO: epoch 001:  13979 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4378, wps=103.7, ups=0.47, wpb=109.9, bsz=40, num_updates=13960, lr=4.58067e-05, gnorm=0.417, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=54311
2023-01-08 13:56:17 - progress_bar.py[line:274] - INFO: epoch 001:  13989 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4235, wps=101.5, ups=0.47, wpb=108.9, bsz=40, num_updates=13970, lr=4.58022e-05, gnorm=0.25, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=54333
2023-01-08 13:56:39 - progress_bar.py[line:274] - INFO: epoch 001:  13999 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.47, wps=101.9, ups=0.47, wpb=109.1, bsz=40, num_updates=13980, lr=4.57977e-05, gnorm=0.31, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54355
2023-01-08 13:57:01 - progress_bar.py[line:274] - INFO: epoch 001:  14009 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5183, wps=102.2, ups=0.46, wpb=110, bsz=40, num_updates=13990, lr=4.57932e-05, gnorm=0.289, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=54376
2023-01-08 13:57:22 - progress_bar.py[line:274] - INFO: epoch 001:  14019 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3906, wps=100.6, ups=0.46, wpb=108.8, bsz=40, num_updates=14000, lr=4.57887e-05, gnorm=0.555, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=54398
2023-01-08 13:57:22 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 13:57:24 - train.py[line:549] - INFO: 0 / 4988
2023-01-08 13:57:24 - train.py[line:551] - INFO: load:1.06 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 13:59:56 - train.py[line:549] - INFO: 200 / 4988
2023-01-08 13:59:56 - train.py[line:551] - INFO: load:1.09 valid_run:151.77 task_valid:147.84 collect_output:2.88
2023-01-08 14:02:24 - train.py[line:549] - INFO: 400 / 4988
2023-01-08 14:02:24 - train.py[line:551] - INFO: load:1.11 valid_run:300.30 task_valid:290.69 collect_output:7.55
2023-01-08 14:04:57 - train.py[line:549] - INFO: 600 / 4988
2023-01-08 14:04:57 - train.py[line:551] - INFO: load:1.13 valid_run:452.68 task_valid:433.45 collect_output:16.14
2023-01-08 14:07:26 - train.py[line:549] - INFO: 800 / 4988
2023-01-08 14:07:26 - train.py[line:551] - INFO: load:1.16 valid_run:601.90 task_valid:578.12 collect_output:19.70
2023-01-08 14:09:58 - train.py[line:549] - INFO: 1000 / 4988
2023-01-08 14:09:58 - train.py[line:551] - INFO: load:1.18 valid_run:754.29 task_valid:725.25 collect_output:23.94
2023-01-08 14:12:30 - train.py[line:549] - INFO: 1200 / 4988
2023-01-08 14:12:30 - train.py[line:551] - INFO: load:1.21 valid_run:906.14 task_valid:870.44 collect_output:29.57
2023-01-08 14:15:04 - train.py[line:549] - INFO: 1400 / 4988
2023-01-08 14:15:04 - train.py[line:551] - INFO: load:1.23 valid_run:1059.96 task_valid:1016.21 collect_output:36.60
2023-01-08 14:17:36 - train.py[line:549] - INFO: 1600 / 4988
2023-01-08 14:17:36 - train.py[line:551] - INFO: load:1.26 valid_run:1211.54 task_valid:1157.12 collect_output:46.26
2023-01-08 14:20:06 - train.py[line:549] - INFO: 1800 / 4988
2023-01-08 14:20:06 - train.py[line:551] - INFO: load:1.28 valid_run:1361.34 task_valid:1301.47 collect_output:50.71
2023-01-08 14:22:35 - train.py[line:549] - INFO: 2000 / 4988
2023-01-08 14:22:35 - train.py[line:551] - INFO: load:1.31 valid_run:1510.09 task_valid:1444.32 collect_output:55.59
2023-01-08 14:25:04 - train.py[line:549] - INFO: 2200 / 4988
2023-01-08 14:25:04 - train.py[line:551] - INFO: load:1.33 valid_run:1659.70 task_valid:1588.79 collect_output:59.72
2023-01-08 14:27:35 - train.py[line:549] - INFO: 2400 / 4988
2023-01-08 14:27:35 - train.py[line:551] - INFO: load:1.36 valid_run:1809.83 task_valid:1733.57 collect_output:64.04
2023-01-08 14:30:05 - train.py[line:549] - INFO: 2600 / 4988
2023-01-08 14:30:05 - train.py[line:551] - INFO: load:1.39 valid_run:1960.10 task_valid:1874.99 collect_output:71.88
2023-01-08 14:32:35 - train.py[line:549] - INFO: 2800 / 4988
2023-01-08 14:32:35 - train.py[line:551] - INFO: load:1.41 valid_run:2110.48 task_valid:2020.01 collect_output:76.23
2023-01-08 14:35:05 - train.py[line:549] - INFO: 3000 / 4988
2023-01-08 14:35:05 - train.py[line:551] - INFO: load:1.44 valid_run:2260.30 task_valid:2165.90 collect_output:79.15
2023-01-08 14:37:35 - train.py[line:549] - INFO: 3200 / 4988
2023-01-08 14:37:35 - train.py[line:551] - INFO: load:1.46 valid_run:2410.48 task_valid:2309.91 collect_output:84.29
2023-01-08 14:40:07 - train.py[line:549] - INFO: 3400 / 4988
2023-01-08 14:40:07 - train.py[line:551] - INFO: load:1.49 valid_run:2562.36 task_valid:2455.09 collect_output:89.97
2023-01-08 14:42:38 - train.py[line:549] - INFO: 3600 / 4988
2023-01-08 14:42:38 - train.py[line:551] - INFO: load:1.51 valid_run:2712.82 task_valid:2601.74 collect_output:92.77
2023-01-08 14:45:06 - train.py[line:549] - INFO: 3800 / 4988
2023-01-08 14:45:06 - train.py[line:551] - INFO: load:1.54 valid_run:2861.24 task_valid:2742.86 collect_output:99.06
2023-01-08 14:47:37 - train.py[line:549] - INFO: 4000 / 4988
2023-01-08 14:47:37 - train.py[line:551] - INFO: load:1.57 valid_run:3011.64 task_valid:2887.74 collect_output:103.56
2023-01-08 14:50:09 - train.py[line:549] - INFO: 4200 / 4988
2023-01-08 14:50:09 - train.py[line:551] - INFO: load:1.59 valid_run:3163.64 task_valid:3031.87 collect_output:110.39
2023-01-08 14:52:39 - train.py[line:549] - INFO: 4400 / 4988
2023-01-08 14:52:39 - train.py[line:551] - INFO: load:1.62 valid_run:3313.17 task_valid:3176.07 collect_output:114.67
2023-01-08 14:55:10 - train.py[line:549] - INFO: 4600 / 4988
2023-01-08 14:55:10 - train.py[line:551] - INFO: load:1.65 valid_run:3464.41 task_valid:3321.78 collect_output:119.19
2023-01-08 14:57:41 - train.py[line:549] - INFO: 4800 / 4988
2023-01-08 14:57:41 - train.py[line:551] - INFO: load:1.67 valid_run:3615.78 task_valid:3467.99 collect_output:123.33

====================================================================================================
SGG eval:     R @ 50: 0.4462;     R @ 100: 0.5444;     R @ 500: 0.6079;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2756;    mR @ 100: 0.3589;    mR @ 500: 0.4178;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6415) (covered in:0.6875) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.8839) (playing:0.0000) (riding:0.7595) (says:0.0000) (sitting on:0.6630) (standing on:0.2033) (using:0.6500) (walking in:0.0000) (walking on:0.4865) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-08 15:00:12 - train.py[line:487] - INFO: 0.5443904761904762

====================================================================================================
SGG eval:     R @ 50: 0.4462;     R @ 100: 0.5444;     R @ 500: 0.6079;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2756;    mR @ 100: 0.3589;    mR @ 500: 0.4178;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6415) (covered in:0.6875) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.8839) (playing:0.0000) (riding:0.7595) (says:0.0000) (sitting on:0.6630) (standing on:0.2033) (using:0.6500) (walking in:0.0000) (walking on:0.4865) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-08 15:00:12 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 15:00:12 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.403 | loss_v1 0 | loss_v2 0 | nll_loss 0.254 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.54439 | ppl 1.19 | vqa_score 0.5236 | wps 119 | wpb 89.9 | bsz 30 | num_updates 14000 | best_R@100 0.645421
2023-01-08 15:00:12 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 14000 updates
2023-01-08 15:00:12 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_14000.pt
2023-01-08 15:00:55 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_14000.pt
2023-01-08 15:02:27 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_14000.pt (epoch 1 @ 14000 updates, score 0.5443904761904762) (writing took 134.53561683185399 seconds)
2023-01-08 15:02:50 - progress_bar.py[line:274] - INFO: epoch 001:  14029 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4095, wps=0.6, ups=0, wpb=108, bsz=40, num_updates=14010, lr=4.57842e-05, gnorm=0.543, clip=20, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=58325
2023-01-08 15:03:12 - progress_bar.py[line:274] - INFO: epoch 001:  14039 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4247, wps=102.2, ups=0.47, wpb=109.1, bsz=40, num_updates=14020, lr=4.57797e-05, gnorm=0.503, clip=20, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=58347
2023-01-08 15:03:34 - progress_bar.py[line:274] - INFO: epoch 001:  14049 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4153, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=14030, lr=4.57752e-05, gnorm=0.385, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58369
2023-01-08 15:03:57 - progress_bar.py[line:274] - INFO: epoch 001:  14059 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.474, wps=103.2, ups=0.46, wpb=111.3, bsz=40, num_updates=14040, lr=4.57707e-05, gnorm=0.92, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58392
2023-01-08 15:04:19 - progress_bar.py[line:274] - INFO: epoch 001:  14069 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3951, wps=104, ups=0.48, wpb=109, bsz=40, num_updates=14050, lr=4.57662e-05, gnorm=0.371, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58414
2023-01-08 15:04:41 - progress_bar.py[line:274] - INFO: epoch 001:  14079 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4524, wps=102.4, ups=0.47, wpb=108.5, bsz=40, num_updates=14060, lr=4.57617e-05, gnorm=0.41, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58436
2023-01-08 15:05:03 - progress_bar.py[line:274] - INFO: epoch 001:  14089 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3779, wps=102, ups=0.48, wpb=107.1, bsz=40, num_updates=14070, lr=4.57572e-05, gnorm=0.376, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58458
2023-01-08 15:05:25 - progress_bar.py[line:274] - INFO: epoch 001:  14099 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4359, wps=103.8, ups=0.47, wpb=109.4, bsz=40, num_updates=14080, lr=4.57527e-05, gnorm=0.498, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=58481
2023-01-08 15:05:48 - progress_bar.py[line:274] - INFO: epoch 001:  14109 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4029, wps=102.6, ups=0.47, wpb=109.3, bsz=40, num_updates=14090, lr=4.57482e-05, gnorm=0.42, clip=20, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=58503
2023-01-08 15:06:10 - progress_bar.py[line:274] - INFO: epoch 001:  14119 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4415, wps=103.8, ups=0.46, wpb=111.6, bsz=40, num_updates=14100, lr=4.57437e-05, gnorm=0.466, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58525
2023-01-08 15:06:33 - progress_bar.py[line:274] - INFO: epoch 001:  14129 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4523, wps=99.1, ups=0.46, wpb=108.6, bsz=40, num_updates=14110, lr=4.57392e-05, gnorm=0.412, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58548
2023-01-08 15:06:56 - progress_bar.py[line:274] - INFO: epoch 001:  14139 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4158, wps=100.8, ups=0.46, wpb=109.5, bsz=40, num_updates=14120, lr=4.57347e-05, gnorm=0.448, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58571
2023-01-08 15:07:19 - progress_bar.py[line:274] - INFO: epoch 001:  14149 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4693, wps=102.1, ups=0.46, wpb=111.1, bsz=40, num_updates=14130, lr=4.57302e-05, gnorm=0.424, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=58594
2023-01-08 15:07:41 - progress_bar.py[line:274] - INFO: epoch 001:  14159 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4162, wps=102.4, ups=0.46, wpb=111.6, bsz=40, num_updates=14140, lr=4.57257e-05, gnorm=0.322, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58616
2023-01-08 15:08:04 - progress_bar.py[line:274] - INFO: epoch 001:  14169 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4612, wps=100.9, ups=0.47, wpb=108, bsz=40, num_updates=14150, lr=4.57212e-05, gnorm=0.322, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58639
2023-01-08 15:08:26 - progress_bar.py[line:274] - INFO: epoch 001:  14179 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3403, wps=102.4, ups=0.47, wpb=109.3, bsz=40, num_updates=14160, lr=4.57167e-05, gnorm=0.246, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=58661
2023-01-08 15:08:48 - progress_bar.py[line:274] - INFO: epoch 001:  14189 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4307, wps=106, ups=0.48, wpb=110.2, bsz=40, num_updates=14170, lr=4.57122e-05, gnorm=0.441, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=58683
2023-01-08 15:09:11 - progress_bar.py[line:274] - INFO: epoch 001:  14199 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4402, wps=101.6, ups=0.46, wpb=110.6, bsz=40, num_updates=14180, lr=4.57077e-05, gnorm=0.368, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58706
2023-01-08 15:09:33 - progress_bar.py[line:274] - INFO: epoch 001:  14209 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4187, wps=102.9, ups=0.47, wpb=109.5, bsz=40, num_updates=14190, lr=4.57033e-05, gnorm=0.266, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58728
2023-01-08 15:09:56 - progress_bar.py[line:274] - INFO: epoch 001:  14219 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4725, wps=102.4, ups=0.47, wpb=109.6, bsz=40, num_updates=14200, lr=4.56988e-05, gnorm=0.232, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58751
2023-01-08 15:10:19 - progress_bar.py[line:274] - INFO: epoch 001:  14229 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3467, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=14210, lr=4.56943e-05, gnorm=0.301, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58774
2023-01-08 15:10:42 - progress_bar.py[line:274] - INFO: epoch 001:  14239 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4566, wps=97.3, ups=0.46, wpb=106.5, bsz=40, num_updates=14220, lr=4.56898e-05, gnorm=0.362, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=58797
2023-01-08 15:11:04 - progress_bar.py[line:274] - INFO: epoch 001:  14249 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.446, wps=99.7, ups=0.46, wpb=108.2, bsz=40, num_updates=14230, lr=4.56853e-05, gnorm=0.423, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58819
2023-01-08 15:11:26 - progress_bar.py[line:274] - INFO: epoch 001:  14259 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3719, wps=102.5, ups=0.47, wpb=108.7, bsz=40, num_updates=14240, lr=4.56808e-05, gnorm=0.422, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58841
2023-01-08 15:11:49 - progress_bar.py[line:274] - INFO: epoch 001:  14269 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4213, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=14250, lr=4.56763e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58864
2023-01-08 15:12:11 - progress_bar.py[line:274] - INFO: epoch 001:  14279 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3939, wps=100.3, ups=0.46, wpb=109, bsz=40, num_updates=14260, lr=4.56718e-05, gnorm=0.311, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=58887
2023-01-08 15:12:34 - progress_bar.py[line:274] - INFO: epoch 001:  14289 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4335, wps=102.1, ups=0.47, wpb=108.2, bsz=40, num_updates=14270, lr=4.56673e-05, gnorm=0.448, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58909
2023-01-08 15:12:56 - progress_bar.py[line:274] - INFO: epoch 001:  14299 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4764, wps=102.6, ups=0.47, wpb=108.7, bsz=40, num_updates=14280, lr=4.56628e-05, gnorm=0.471, clip=10, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=58931
2023-01-08 15:13:18 - progress_bar.py[line:274] - INFO: epoch 001:  14309 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4064, wps=100.6, ups=0.47, wpb=108.2, bsz=40, num_updates=14290, lr=4.56583e-05, gnorm=0.254, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58953
2023-01-08 15:13:40 - progress_bar.py[line:274] - INFO: epoch 001:  14319 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4255, wps=103.9, ups=0.47, wpb=110, bsz=40, num_updates=14300, lr=4.56538e-05, gnorm=0.267, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58975
2023-01-08 15:14:03 - progress_bar.py[line:274] - INFO: epoch 001:  14329 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4162, wps=102.7, ups=0.47, wpb=109.5, bsz=40, num_updates=14310, lr=4.56493e-05, gnorm=0.347, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58998
2023-01-08 15:14:25 - progress_bar.py[line:274] - INFO: epoch 001:  14339 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4, wps=99.2, ups=0.46, wpb=108.2, bsz=40, num_updates=14320, lr=4.56448e-05, gnorm=0.283, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59020
2023-01-08 15:14:47 - progress_bar.py[line:274] - INFO: epoch 001:  14349 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3959, wps=103.1, ups=0.47, wpb=109.2, bsz=40, num_updates=14330, lr=4.56403e-05, gnorm=0.272, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59043
2023-01-08 15:15:10 - progress_bar.py[line:274] - INFO: epoch 001:  14359 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4689, wps=99, ups=0.46, wpb=108.6, bsz=40, num_updates=14340, lr=4.56358e-05, gnorm=0.258, clip=0, loss_scale=512, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=59065
2023-01-08 15:15:32 - progress_bar.py[line:274] - INFO: epoch 001:  14369 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4335, wps=103.3, ups=0.48, wpb=108.4, bsz=40, num_updates=14350, lr=4.56313e-05, gnorm=0.47, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=59088
2023-01-08 15:15:56 - progress_bar.py[line:274] - INFO: epoch 001:  14379 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.445, wps=99.7, ups=0.46, wpb=108.9, bsz=40, num_updates=14360, lr=4.56268e-05, gnorm=0.223, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=59110
2023-01-08 15:16:17 - progress_bar.py[line:274] - INFO: epoch 001:  14389 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4554, wps=105, ups=0.48, wpb=109.5, bsz=40, num_updates=14370, lr=4.56223e-05, gnorm=0.387, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=59132
2023-01-08 15:16:40 - progress_bar.py[line:274] - INFO: epoch 001:  14399 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4472, wps=102.8, ups=0.47, wpb=108.9, bsz=40, num_updates=14380, lr=4.56178e-05, gnorm=0.543, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59155
2023-01-08 15:17:02 - progress_bar.py[line:274] - INFO: epoch 001:  14409 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4208, wps=101.8, ups=0.47, wpb=108.3, bsz=40, num_updates=14390, lr=4.56133e-05, gnorm=0.251, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59177
2023-01-08 15:17:25 - progress_bar.py[line:274] - INFO: epoch 001:  14419 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4751, wps=101.9, ups=0.46, wpb=110.5, bsz=40, num_updates=14400, lr=4.56088e-05, gnorm=0.448, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=59200
2023-01-08 15:17:47 - progress_bar.py[line:274] - INFO: epoch 001:  14429 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4279, wps=98.8, ups=0.46, wpb=107.6, bsz=40, num_updates=14410, lr=4.56043e-05, gnorm=0.446, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=59222
2023-01-08 15:18:10 - progress_bar.py[line:274] - INFO: epoch 001:  14439 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.399, wps=100.6, ups=0.46, wpb=108.3, bsz=40, num_updates=14420, lr=4.55998e-05, gnorm=0.358, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=59245
2023-01-08 15:18:33 - progress_bar.py[line:274] - INFO: epoch 001:  14449 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4175, wps=101.3, ups=0.46, wpb=109.6, bsz=40, num_updates=14430, lr=4.55953e-05, gnorm=0.308, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59268
2023-01-08 15:18:55 - progress_bar.py[line:274] - INFO: epoch 001:  14459 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4189, wps=101.4, ups=0.47, wpb=108.2, bsz=40, num_updates=14440, lr=4.55909e-05, gnorm=0.392, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=59290
2023-01-08 15:19:18 - progress_bar.py[line:274] - INFO: epoch 001:  14469 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4831, wps=99.9, ups=0.46, wpb=108.3, bsz=40, num_updates=14450, lr=4.55864e-05, gnorm=0.45, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59313
2023-01-08 15:19:40 - progress_bar.py[line:274] - INFO: epoch 001:  14479 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4845, wps=100.2, ups=0.46, wpb=109.9, bsz=40, num_updates=14460, lr=4.55819e-05, gnorm=0.49, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=59336
2023-01-08 15:20:03 - progress_bar.py[line:274] - INFO: epoch 001:  14489 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4381, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=14470, lr=4.55774e-05, gnorm=0.413, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59358
2023-01-08 15:20:26 - progress_bar.py[line:274] - INFO: epoch 001:  14499 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4211, wps=102.3, ups=0.46, wpb=110.3, bsz=40, num_updates=14480, lr=4.55729e-05, gnorm=0.436, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=59381
2023-01-08 15:20:48 - progress_bar.py[line:274] - INFO: epoch 001:  14509 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4918, wps=104.4, ups=0.47, wpb=110, bsz=40, num_updates=14490, lr=4.55684e-05, gnorm=0.354, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59403
2023-01-08 15:21:11 - progress_bar.py[line:274] - INFO: epoch 001:  14519 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.445, wps=100.8, ups=0.47, wpb=108, bsz=40, num_updates=14500, lr=4.55639e-05, gnorm=0.367, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=59425
2023-01-08 15:21:33 - progress_bar.py[line:274] - INFO: epoch 001:  14529 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4844, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=14510, lr=4.55594e-05, gnorm=0.351, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59448
2023-01-08 15:21:56 - progress_bar.py[line:274] - INFO: epoch 001:  14539 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4503, wps=101.5, ups=0.47, wpb=108.8, bsz=40, num_updates=14520, lr=4.55549e-05, gnorm=0.518, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=59471
2023-01-08 15:22:18 - progress_bar.py[line:274] - INFO: epoch 001:  14549 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3857, wps=101, ups=0.46, wpb=108.7, bsz=40, num_updates=14530, lr=4.55504e-05, gnorm=0.448, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59493
2023-01-08 15:22:41 - progress_bar.py[line:274] - INFO: epoch 001:  14559 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4124, wps=103.5, ups=0.47, wpb=109.3, bsz=40, num_updates=14540, lr=4.55459e-05, gnorm=0.387, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59516
2023-01-08 15:23:03 - progress_bar.py[line:274] - INFO: epoch 001:  14569 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4218, wps=102.3, ups=0.46, wpb=110, bsz=40, num_updates=14550, lr=4.55414e-05, gnorm=0.367, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=59538
2023-01-08 15:23:25 - progress_bar.py[line:274] - INFO: epoch 001:  14579 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4216, wps=102.2, ups=0.47, wpb=109.1, bsz=40, num_updates=14560, lr=4.55369e-05, gnorm=0.287, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=59561
2023-01-08 15:23:48 - progress_bar.py[line:274] - INFO: epoch 001:  14589 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4335, wps=100.9, ups=0.46, wpb=108.6, bsz=40, num_updates=14570, lr=4.55324e-05, gnorm=0.287, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=59583
2023-01-08 15:24:10 - progress_bar.py[line:274] - INFO: epoch 001:  14599 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4681, wps=102.3, ups=0.47, wpb=109.6, bsz=40, num_updates=14580, lr=4.55279e-05, gnorm=0.37, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=59605
2023-01-08 15:24:33 - progress_bar.py[line:274] - INFO: epoch 001:  14609 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4619, wps=101.2, ups=0.46, wpb=108.8, bsz=40, num_updates=14590, lr=4.55234e-05, gnorm=0.284, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=59628
2023-01-08 15:24:55 - progress_bar.py[line:274] - INFO: epoch 001:  14619 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4309, wps=105.8, ups=0.48, wpb=110, bsz=40, num_updates=14600, lr=4.55189e-05, gnorm=0.309, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=59650
2023-01-08 15:25:17 - progress_bar.py[line:274] - INFO: epoch 001:  14629 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=102.2, ups=0.47, wpb=108.9, bsz=40, num_updates=14610, lr=4.55144e-05, gnorm=0.26, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59672
2023-01-08 15:25:40 - progress_bar.py[line:274] - INFO: epoch 001:  14639 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4286, wps=100.6, ups=0.45, wpb=110.6, bsz=40, num_updates=14620, lr=4.55099e-05, gnorm=0.536, clip=10, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=59695
2023-01-08 15:26:03 - progress_bar.py[line:274] - INFO: epoch 001:  14649 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.418, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=14630, lr=4.55054e-05, gnorm=0.378, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59718
2023-01-08 15:26:25 - progress_bar.py[line:274] - INFO: epoch 001:  14659 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4255, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=14640, lr=4.55009e-05, gnorm=0.27, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=59741
2023-01-08 15:26:48 - progress_bar.py[line:274] - INFO: epoch 001:  14669 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5324, wps=103.3, ups=0.47, wpb=108.8, bsz=40, num_updates=14650, lr=4.54964e-05, gnorm=0.398, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=59763
2023-01-08 15:27:10 - progress_bar.py[line:274] - INFO: epoch 001:  14679 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4309, wps=103.6, ups=0.47, wpb=109.5, bsz=40, num_updates=14660, lr=4.54919e-05, gnorm=0.252, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=59785
2023-01-08 15:27:32 - progress_bar.py[line:274] - INFO: epoch 001:  14689 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4478, wps=103.4, ups=0.47, wpb=109.7, bsz=40, num_updates=14670, lr=4.54874e-05, gnorm=0.307, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59807
2023-01-08 15:27:55 - progress_bar.py[line:274] - INFO: epoch 001:  14699 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4528, wps=98.6, ups=0.45, wpb=109.5, bsz=40, num_updates=14680, lr=4.5483e-05, gnorm=0.342, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59830
2023-01-08 15:28:18 - progress_bar.py[line:274] - INFO: epoch 001:  14709 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4195, wps=99.6, ups=0.46, wpb=108, bsz=40, num_updates=14690, lr=4.54785e-05, gnorm=0.221, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59853
2023-01-08 15:28:40 - progress_bar.py[line:274] - INFO: epoch 001:  14719 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4205, wps=102.1, ups=0.47, wpb=108.8, bsz=40, num_updates=14700, lr=4.5474e-05, gnorm=0.386, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59875
2023-01-08 15:29:03 - progress_bar.py[line:274] - INFO: epoch 001:  14729 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4439, wps=102.3, ups=0.46, wpb=110.1, bsz=40, num_updates=14710, lr=4.54695e-05, gnorm=0.334, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59898
2023-01-08 15:29:26 - progress_bar.py[line:274] - INFO: epoch 001:  14739 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4205, wps=100.3, ups=0.45, wpb=111, bsz=40, num_updates=14720, lr=4.5465e-05, gnorm=0.352, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=59921
2023-01-08 15:29:49 - progress_bar.py[line:274] - INFO: epoch 001:  14749 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5099, wps=101.6, ups=0.46, wpb=109.7, bsz=40, num_updates=14730, lr=4.54605e-05, gnorm=0.276, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59944
2023-01-08 15:30:12 - progress_bar.py[line:274] - INFO: epoch 001:  14759 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4171, wps=99.3, ups=0.46, wpb=108.3, bsz=40, num_updates=14740, lr=4.5456e-05, gnorm=0.321, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=59966
2023-01-08 15:30:34 - progress_bar.py[line:274] - INFO: epoch 001:  14769 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4108, wps=106, ups=0.48, wpb=111.1, bsz=40, num_updates=14750, lr=4.54515e-05, gnorm=0.464, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59989
2023-01-08 15:30:56 - progress_bar.py[line:274] - INFO: epoch 001:  14779 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4286, wps=103.5, ups=0.47, wpb=110.4, bsz=40, num_updates=14760, lr=4.5447e-05, gnorm=0.325, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60011
2023-01-08 15:31:19 - progress_bar.py[line:274] - INFO: epoch 001:  14789 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4802, wps=102.4, ups=0.46, wpb=110.4, bsz=40, num_updates=14770, lr=4.54425e-05, gnorm=0.36, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60034
2023-01-08 15:31:41 - progress_bar.py[line:274] - INFO: epoch 001:  14799 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4091, wps=103.7, ups=0.47, wpb=109.4, bsz=40, num_updates=14780, lr=4.5438e-05, gnorm=0.349, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=60056
2023-01-08 15:32:04 - progress_bar.py[line:274] - INFO: epoch 001:  14809 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4031, wps=99.1, ups=0.45, wpb=109.1, bsz=40, num_updates=14790, lr=4.54335e-05, gnorm=0.339, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60079
2023-01-08 15:32:27 - progress_bar.py[line:274] - INFO: epoch 001:  14819 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4828, wps=101.5, ups=0.46, wpb=109.4, bsz=40, num_updates=14800, lr=4.5429e-05, gnorm=0.501, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60101
2023-01-08 15:32:49 - progress_bar.py[line:274] - INFO: epoch 001:  14829 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4439, wps=103.6, ups=0.47, wpb=109.8, bsz=40, num_updates=14810, lr=4.54245e-05, gnorm=0.364, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60124
2023-01-08 15:33:11 - progress_bar.py[line:274] - INFO: epoch 001:  14839 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4428, wps=100.6, ups=0.46, wpb=108.9, bsz=40, num_updates=14820, lr=4.542e-05, gnorm=0.278, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=60146
2023-01-08 15:33:33 - progress_bar.py[line:274] - INFO: epoch 001:  14849 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4183, wps=102.5, ups=0.47, wpb=108.9, bsz=40, num_updates=14830, lr=4.54155e-05, gnorm=0.362, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=60169
2023-01-08 15:33:56 - progress_bar.py[line:274] - INFO: epoch 001:  14859 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4657, wps=101.8, ups=0.47, wpb=108.5, bsz=40, num_updates=14840, lr=4.5411e-05, gnorm=0.507, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60191
2023-01-08 15:34:18 - progress_bar.py[line:274] - INFO: epoch 001:  14869 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4135, wps=101.8, ups=0.47, wpb=109.3, bsz=40, num_updates=14850, lr=4.54065e-05, gnorm=0.259, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60213
2023-01-08 15:34:41 - progress_bar.py[line:274] - INFO: epoch 001:  14879 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4439, wps=103.2, ups=0.47, wpb=108.9, bsz=40, num_updates=14860, lr=4.5402e-05, gnorm=0.279, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60236
2023-01-08 15:35:03 - progress_bar.py[line:274] - INFO: epoch 001:  14889 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4358, wps=100.7, ups=0.47, wpb=107.7, bsz=40, num_updates=14870, lr=4.53975e-05, gnorm=0.336, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60258
2023-01-08 15:35:25 - progress_bar.py[line:274] - INFO: epoch 001:  14899 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5054, wps=102.2, ups=0.47, wpb=109.2, bsz=40, num_updates=14880, lr=4.5393e-05, gnorm=0.347, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60280
2023-01-08 15:35:48 - progress_bar.py[line:274] - INFO: epoch 001:  14909 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4683, wps=100, ups=0.46, wpb=108.6, bsz=40, num_updates=14890, lr=4.53885e-05, gnorm=0.502, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=60303
2023-01-08 15:36:11 - progress_bar.py[line:274] - INFO: epoch 001:  14919 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3929, wps=100.2, ups=0.46, wpb=109, bsz=40, num_updates=14900, lr=4.5384e-05, gnorm=0.294, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=60326
2023-01-08 15:36:34 - progress_bar.py[line:274] - INFO: epoch 001:  14929 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4375, wps=99.5, ups=0.46, wpb=108.2, bsz=40, num_updates=14910, lr=4.53795e-05, gnorm=0.507, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60348
2023-01-08 15:36:56 - progress_bar.py[line:274] - INFO: epoch 001:  14939 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5161, wps=102.4, ups=0.46, wpb=110.3, bsz=40, num_updates=14920, lr=4.5375e-05, gnorm=0.339, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60371
2023-01-08 15:37:19 - progress_bar.py[line:274] - INFO: epoch 001:  14949 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4943, wps=102.3, ups=0.47, wpb=110, bsz=40, num_updates=14930, lr=4.53706e-05, gnorm=0.266, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=60394
2023-01-08 15:37:42 - progress_bar.py[line:274] - INFO: epoch 001:  14959 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4388, wps=100.2, ups=0.46, wpb=109.4, bsz=40, num_updates=14940, lr=4.53661e-05, gnorm=0.283, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=60417
2023-01-08 15:38:05 - progress_bar.py[line:274] - INFO: epoch 001:  14969 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4607, wps=100.2, ups=0.46, wpb=109, bsz=40, num_updates=14950, lr=4.53616e-05, gnorm=0.375, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60440
2023-01-08 15:38:28 - progress_bar.py[line:274] - INFO: epoch 001:  14979 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3842, wps=101.8, ups=0.46, wpb=110.1, bsz=40, num_updates=14960, lr=4.53571e-05, gnorm=0.389, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=60463
2023-01-08 15:38:50 - progress_bar.py[line:274] - INFO: epoch 001:  14989 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4432, wps=103.4, ups=0.47, wpb=109.3, bsz=40, num_updates=14970, lr=4.53526e-05, gnorm=0.508, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=60485
2023-01-08 15:39:13 - progress_bar.py[line:274] - INFO: epoch 001:  14999 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3769, wps=101.7, ups=0.47, wpb=109, bsz=40, num_updates=14980, lr=4.53481e-05, gnorm=0.365, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60508
2023-01-08 15:39:35 - progress_bar.py[line:274] - INFO: epoch 001:  15009 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3445, wps=100.1, ups=0.46, wpb=108.1, bsz=40, num_updates=14990, lr=4.53436e-05, gnorm=0.447, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60530
2023-01-08 15:39:57 - progress_bar.py[line:274] - INFO: epoch 001:  15019 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4673, wps=102.2, ups=0.47, wpb=108.2, bsz=40, num_updates=15000, lr=4.53391e-05, gnorm=0.291, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60552
2023-01-08 15:40:20 - progress_bar.py[line:274] - INFO: epoch 001:  15029 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4925, wps=101, ups=0.46, wpb=110.1, bsz=40, num_updates=15010, lr=4.53346e-05, gnorm=0.525, clip=20, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60575
2023-01-08 15:40:43 - progress_bar.py[line:274] - INFO: epoch 001:  15039 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4394, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=15020, lr=4.53301e-05, gnorm=0.404, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=60598
2023-01-08 15:41:05 - progress_bar.py[line:274] - INFO: epoch 001:  15049 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4495, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=15030, lr=4.53256e-05, gnorm=0.38, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60620
2023-01-08 15:41:27 - progress_bar.py[line:274] - INFO: epoch 001:  15059 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.48, wps=102.8, ups=0.47, wpb=109.8, bsz=40, num_updates=15040, lr=4.53211e-05, gnorm=0.299, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60642
2023-01-08 15:41:50 - progress_bar.py[line:274] - INFO: epoch 001:  15069 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4213, wps=102, ups=0.46, wpb=110.1, bsz=40, num_updates=15050, lr=4.53166e-05, gnorm=0.313, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60665
2023-01-08 15:42:12 - progress_bar.py[line:274] - INFO: epoch 001:  15079 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3922, wps=101.2, ups=0.47, wpb=108.8, bsz=40, num_updates=15060, lr=4.53121e-05, gnorm=0.318, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60688
2023-01-08 15:42:35 - progress_bar.py[line:274] - INFO: epoch 001:  15089 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4258, wps=101.7, ups=0.47, wpb=108.3, bsz=40, num_updates=15070, lr=4.53076e-05, gnorm=0.248, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60710
2023-01-08 15:42:57 - progress_bar.py[line:274] - INFO: epoch 001:  15099 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4121, wps=100.6, ups=0.47, wpb=108.1, bsz=40, num_updates=15080, lr=4.53031e-05, gnorm=0.32, clip=0, loss_scale=2048, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=60732
2023-01-08 15:43:20 - progress_bar.py[line:274] - INFO: epoch 001:  15109 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.441, wps=101, ups=0.46, wpb=109.2, bsz=40, num_updates=15090, lr=4.52986e-05, gnorm=0.327, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60755
2023-01-08 15:43:24 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-08 15:43:44 - progress_bar.py[line:274] - INFO: epoch 001:  15120 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.381, nsentences=40, sample_size=109.381, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5171, wps=100.1, ups=0.44, wpb=109.4, bsz=40, num_updates=15100, lr=4.52941e-05, gnorm=0.488, clip=10, loss_scale=1024, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=60779
2023-01-08 15:44:06 - progress_bar.py[line:274] - INFO: epoch 001:  15130 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4205, wps=102.5, ups=0.47, wpb=109.2, bsz=40, num_updates=15110, lr=4.52896e-05, gnorm=0.363, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60801
2023-01-08 15:44:29 - progress_bar.py[line:274] - INFO: epoch 001:  15140 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5185, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=15120, lr=4.52851e-05, gnorm=0.477, clip=10, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=60824
2023-01-08 15:44:51 - progress_bar.py[line:274] - INFO: epoch 001:  15150 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3779, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=15130, lr=4.52806e-05, gnorm=0.276, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60846
2023-01-08 15:45:14 - progress_bar.py[line:274] - INFO: epoch 001:  15160 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4762, wps=100.8, ups=0.46, wpb=110, bsz=40, num_updates=15140, lr=4.52761e-05, gnorm=0.382, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60869
2023-01-08 15:45:36 - progress_bar.py[line:274] - INFO: epoch 001:  15170 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4109, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=15150, lr=4.52716e-05, gnorm=0.285, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=60891
2023-01-08 15:45:59 - progress_bar.py[line:274] - INFO: epoch 001:  15180 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5056, wps=102.9, ups=0.47, wpb=110.2, bsz=40, num_updates=15160, lr=4.52671e-05, gnorm=0.289, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60914
2023-01-08 15:46:21 - progress_bar.py[line:274] - INFO: epoch 001:  15190 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=106.6, nsentences=40, sample_size=106.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4306, wps=98.8, ups=0.46, wpb=106.6, bsz=40, num_updates=15170, lr=4.52627e-05, gnorm=0.359, clip=0, loss_scale=1024, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=60936
2023-01-08 15:46:44 - progress_bar.py[line:274] - INFO: epoch 001:  15200 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4948, wps=101.5, ups=0.46, wpb=110.1, bsz=40, num_updates=15180, lr=4.52582e-05, gnorm=0.263, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=60959
2023-01-08 15:47:07 - progress_bar.py[line:274] - INFO: epoch 001:  15210 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4286, wps=101.8, ups=0.46, wpb=109.8, bsz=40, num_updates=15190, lr=4.52537e-05, gnorm=0.244, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60982
2023-01-08 15:47:29 - progress_bar.py[line:274] - INFO: epoch 001:  15220 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4333, wps=101.6, ups=0.47, wpb=108.7, bsz=40, num_updates=15200, lr=4.52492e-05, gnorm=0.403, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61004
2023-01-08 15:47:51 - progress_bar.py[line:274] - INFO: epoch 001:  15230 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4294, wps=103.8, ups=0.47, wpb=110.2, bsz=40, num_updates=15210, lr=4.52447e-05, gnorm=0.336, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=61026
2023-01-08 15:48:14 - progress_bar.py[line:274] - INFO: epoch 001:  15240 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4593, wps=99.9, ups=0.46, wpb=108.2, bsz=40, num_updates=15220, lr=4.52402e-05, gnorm=0.322, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=61049
2023-01-08 15:48:37 - progress_bar.py[line:274] - INFO: epoch 001:  15250 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4728, wps=100.9, ups=0.46, wpb=109.9, bsz=40, num_updates=15230, lr=4.52357e-05, gnorm=0.236, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61072
2023-01-08 15:48:59 - progress_bar.py[line:274] - INFO: epoch 001:  15260 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5544, wps=102.5, ups=0.47, wpb=109.8, bsz=40, num_updates=15240, lr=4.52312e-05, gnorm=0.31, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61094
2023-01-08 15:49:21 - progress_bar.py[line:274] - INFO: epoch 001:  15270 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4216, wps=102.9, ups=0.47, wpb=108.6, bsz=40, num_updates=15250, lr=4.52267e-05, gnorm=0.362, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61116
2023-01-08 15:49:44 - progress_bar.py[line:274] - INFO: epoch 001:  15280 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4098, wps=101.3, ups=0.46, wpb=109.4, bsz=40, num_updates=15260, lr=4.52222e-05, gnorm=0.316, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=61139
2023-01-08 15:50:07 - progress_bar.py[line:274] - INFO: epoch 001:  15290 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4536, wps=102.6, ups=0.47, wpb=109.8, bsz=40, num_updates=15270, lr=4.52177e-05, gnorm=0.418, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61161
2023-01-08 15:50:30 - progress_bar.py[line:274] - INFO: epoch 001:  15300 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4712, wps=100, ups=0.46, wpb=108.1, bsz=40, num_updates=15280, lr=4.52132e-05, gnorm=0.385, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=61185
2023-01-08 15:50:52 - progress_bar.py[line:274] - INFO: epoch 001:  15310 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5, wps=100.6, ups=0.46, wpb=109.4, bsz=40, num_updates=15290, lr=4.52087e-05, gnorm=0.336, clip=10, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=61207
2023-01-08 15:51:15 - progress_bar.py[line:274] - INFO: epoch 001:  15320 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4271, wps=99.7, ups=0.46, wpb=108.5, bsz=40, num_updates=15300, lr=4.52042e-05, gnorm=0.29, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=61230
2023-01-08 15:51:38 - progress_bar.py[line:274] - INFO: epoch 001:  15330 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4011, wps=101, ups=0.46, wpb=109.8, bsz=40, num_updates=15310, lr=4.51997e-05, gnorm=0.272, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61253
2023-01-08 15:52:01 - progress_bar.py[line:274] - INFO: epoch 001:  15340 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4323, wps=100.1, ups=0.46, wpb=109.2, bsz=40, num_updates=15320, lr=4.51952e-05, gnorm=0.728, clip=40, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61276
2023-01-08 15:52:23 - progress_bar.py[line:274] - INFO: epoch 001:  15350 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4133, wps=103.8, ups=0.47, wpb=109.9, bsz=40, num_updates=15330, lr=4.51907e-05, gnorm=0.462, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=61298
2023-01-08 15:52:46 - progress_bar.py[line:274] - INFO: epoch 001:  15360 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4531, wps=100.6, ups=0.46, wpb=109.6, bsz=40, num_updates=15340, lr=4.51862e-05, gnorm=0.299, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61321
2023-01-08 15:53:09 - progress_bar.py[line:274] - INFO: epoch 001:  15370 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4229, wps=98, ups=0.45, wpb=108.1, bsz=40, num_updates=15350, lr=4.51817e-05, gnorm=0.314, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=61345
2023-01-08 15:53:32 - progress_bar.py[line:274] - INFO: epoch 001:  15380 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4468, wps=102.1, ups=0.46, wpb=109.9, bsz=40, num_updates=15360, lr=4.51772e-05, gnorm=0.242, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61367
2023-01-08 15:53:55 - progress_bar.py[line:274] - INFO: epoch 001:  15390 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4346, wps=103.1, ups=0.46, wpb=110.9, bsz=40, num_updates=15370, lr=4.51727e-05, gnorm=0.332, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=61390
2023-01-08 15:54:17 - progress_bar.py[line:274] - INFO: epoch 001:  15400 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4645, wps=103.6, ups=0.48, wpb=108.2, bsz=40, num_updates=15380, lr=4.51682e-05, gnorm=0.367, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61412
2023-01-08 15:54:40 - progress_bar.py[line:274] - INFO: epoch 001:  15410 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4058, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=15390, lr=4.51637e-05, gnorm=0.364, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61435
2023-01-08 15:55:03 - progress_bar.py[line:274] - INFO: epoch 001:  15420 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3721, wps=102.8, ups=0.48, wpb=107.8, bsz=40, num_updates=15400, lr=4.51592e-05, gnorm=0.241, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=61457
2023-01-08 15:55:25 - progress_bar.py[line:274] - INFO: epoch 001:  15430 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3671, wps=99.7, ups=0.46, wpb=107.7, bsz=40, num_updates=15410, lr=4.51547e-05, gnorm=0.319, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61480
2023-01-08 15:55:48 - progress_bar.py[line:274] - INFO: epoch 001:  15440 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4309, wps=101.9, ups=0.46, wpb=110.2, bsz=40, num_updates=15420, lr=4.51503e-05, gnorm=0.444, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=61503
2023-01-08 15:56:11 - progress_bar.py[line:274] - INFO: epoch 001:  15450 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4752, wps=100.2, ups=0.46, wpb=109.7, bsz=40, num_updates=15430, lr=4.51458e-05, gnorm=0.356, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=61526
2023-01-08 15:56:33 - progress_bar.py[line:274] - INFO: epoch 001:  15460 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3902, wps=102.2, ups=0.47, wpb=108, bsz=40, num_updates=15440, lr=4.51413e-05, gnorm=0.483, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61548
2023-01-08 15:56:56 - progress_bar.py[line:274] - INFO: epoch 001:  15470 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4069, wps=99.8, ups=0.46, wpb=107.8, bsz=40, num_updates=15450, lr=4.51368e-05, gnorm=0.374, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61571
2023-01-08 15:57:18 - progress_bar.py[line:274] - INFO: epoch 001:  15480 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.51, wps=102.6, ups=0.47, wpb=108.7, bsz=40, num_updates=15460, lr=4.51323e-05, gnorm=0.505, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61593
2023-01-08 15:57:40 - progress_bar.py[line:274] - INFO: epoch 001:  15490 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4656, wps=101.5, ups=0.47, wpb=108.4, bsz=40, num_updates=15470, lr=4.51278e-05, gnorm=0.377, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=61615
2023-01-08 15:58:03 - progress_bar.py[line:274] - INFO: epoch 001:  15500 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4301, wps=102.3, ups=0.46, wpb=110.2, bsz=40, num_updates=15480, lr=4.51233e-05, gnorm=0.308, clip=0, loss_scale=1024, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=61638
2023-01-08 15:58:26 - progress_bar.py[line:274] - INFO: epoch 001:  15510 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4245, wps=100.1, ups=0.46, wpb=109.4, bsz=40, num_updates=15490, lr=4.51188e-05, gnorm=0.422, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=61661
2023-01-08 15:58:49 - progress_bar.py[line:274] - INFO: epoch 001:  15520 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4412, wps=99.7, ups=0.46, wpb=108.7, bsz=40, num_updates=15500, lr=4.51143e-05, gnorm=0.288, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=61684
2023-01-08 15:59:14 - progress_bar.py[line:274] - INFO: epoch 001:  15530 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4495, wps=101.6, ups=0.46, wpb=109.7, bsz=40, num_updates=15510, lr=4.51098e-05, gnorm=0.271, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=61706
2023-01-08 15:59:40 - progress_bar.py[line:274] - INFO: epoch 001:  15540 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4372, wps=103.2, ups=0.47, wpb=110.7, bsz=40, num_updates=15520, lr=4.51053e-05, gnorm=0.266, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=61731
2023-01-08 16:00:06 - progress_bar.py[line:274] - INFO: epoch 001:  15550 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4673, wps=100.6, ups=0.46, wpb=109.1, bsz=40, num_updates=15530, lr=4.51008e-05, gnorm=0.319, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=61757
2023-01-08 16:00:31 - progress_bar.py[line:274] - INFO: epoch 001:  15560 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4537, wps=98.8, ups=0.46, wpb=107.9, bsz=40, num_updates=15540, lr=4.50963e-05, gnorm=0.418, clip=10, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=61784
2023-01-08 16:00:56 - progress_bar.py[line:274] - INFO: epoch 001:  15570 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.456, wps=101.6, ups=0.46, wpb=110.8, bsz=40, num_updates=15550, lr=4.50918e-05, gnorm=0.349, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61809
2023-01-08 16:01:19 - progress_bar.py[line:274] - INFO: epoch 001:  15580 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4195, wps=102.4, ups=0.48, wpb=107.7, bsz=40, num_updates=15560, lr=4.50873e-05, gnorm=0.24, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61833
2023-01-08 16:01:44 - progress_bar.py[line:274] - INFO: epoch 001:  15590 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4488, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=15570, lr=4.50828e-05, gnorm=0.275, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=61857
2023-01-08 16:02:09 - progress_bar.py[line:274] - INFO: epoch 001:  15600 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4576, wps=99.5, ups=0.45, wpb=109.7, bsz=40, num_updates=15580, lr=4.50783e-05, gnorm=0.263, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=61882
2023-01-08 16:02:33 - progress_bar.py[line:274] - INFO: epoch 001:  15610 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3649, wps=98.8, ups=0.46, wpb=108.1, bsz=40, num_updates=15590, lr=4.50738e-05, gnorm=0.34, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61907
2023-01-08 16:02:57 - progress_bar.py[line:274] - INFO: epoch 001:  15620 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4975, wps=103.6, ups=0.48, wpb=108.9, bsz=40, num_updates=15600, lr=4.50693e-05, gnorm=0.405, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61930
2023-01-08 16:03:21 - progress_bar.py[line:274] - INFO: epoch 001:  15630 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=98.5, ups=0.45, wpb=108.3, bsz=40, num_updates=15610, lr=4.50648e-05, gnorm=0.309, clip=0, loss_scale=2048, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=61955
2023-01-08 16:03:44 - progress_bar.py[line:274] - INFO: epoch 001:  15640 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4645, wps=102.1, ups=0.47, wpb=109, bsz=40, num_updates=15620, lr=4.50603e-05, gnorm=0.262, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61979
2023-01-08 16:03:57 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-08 16:04:08 - progress_bar.py[line:274] - INFO: epoch 001:  15651 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.81, nsentences=40, sample_size=110.81, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4433, wps=98.3, ups=0.42, wpb=110.8, bsz=40, num_updates=15630, lr=4.50558e-05, gnorm=0.401, clip=10, loss_scale=1024, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=62004
2023-01-08 16:04:31 - progress_bar.py[line:274] - INFO: epoch 001:  15661 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4792, wps=101.9, ups=0.46, wpb=110.2, bsz=40, num_updates=15640, lr=4.50513e-05, gnorm=0.199, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62026
2023-01-08 16:04:53 - progress_bar.py[line:274] - INFO: epoch 001:  15671 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4824, wps=102.8, ups=0.47, wpb=109.1, bsz=40, num_updates=15650, lr=4.50468e-05, gnorm=0.262, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62048
2023-01-08 16:05:16 - progress_bar.py[line:274] - INFO: epoch 001:  15681 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5127, wps=102.4, ups=0.47, wpb=110, bsz=40, num_updates=15660, lr=4.50424e-05, gnorm=0.324, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62071
2023-01-08 16:05:38 - progress_bar.py[line:274] - INFO: epoch 001:  15691 / 115845 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4425, wps=103.1, ups=0.46, wpb=111.1, bsz=40, num_updates=15670, lr=4.50379e-05, gnorm=0.266, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=62093
2023-01-08 16:06:01 - progress_bar.py[line:274] - INFO: epoch 001:  15701 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4398, wps=101.7, ups=0.46, wpb=110.4, bsz=40, num_updates=15680, lr=4.50334e-05, gnorm=0.235, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=62116
2023-01-08 16:06:24 - progress_bar.py[line:274] - INFO: epoch 001:  15711 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.46, wps=102, ups=0.46, wpb=109.8, bsz=40, num_updates=15690, lr=4.50289e-05, gnorm=0.408, clip=10, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=62139
2023-01-08 16:06:46 - progress_bar.py[line:274] - INFO: epoch 001:  15721 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4757, wps=100.1, ups=0.46, wpb=108.1, bsz=40, num_updates=15700, lr=4.50244e-05, gnorm=0.293, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=62161
2023-01-08 16:07:08 - progress_bar.py[line:274] - INFO: epoch 001:  15731 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4384, wps=99, ups=0.46, wpb=107.4, bsz=40, num_updates=15710, lr=4.50199e-05, gnorm=0.304, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62184
2023-01-08 16:07:30 - progress_bar.py[line:274] - INFO: epoch 001:  15741 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4526, wps=103.1, ups=0.47, wpb=109.7, bsz=40, num_updates=15720, lr=4.50154e-05, gnorm=0.294, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=62205
2023-01-08 16:07:53 - progress_bar.py[line:274] - INFO: epoch 001:  15751 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4694, wps=99.3, ups=0.46, wpb=108.8, bsz=40, num_updates=15730, lr=4.50109e-05, gnorm=0.312, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62228
2023-01-08 16:08:15 - progress_bar.py[line:274] - INFO: epoch 001:  15761 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4231, wps=101.3, ups=0.47, wpb=108.9, bsz=40, num_updates=15740, lr=4.50064e-05, gnorm=0.354, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=62250
2023-01-08 16:08:38 - progress_bar.py[line:274] - INFO: epoch 001:  15771 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4265, wps=101.2, ups=0.47, wpb=108.4, bsz=40, num_updates=15750, lr=4.50019e-05, gnorm=0.223, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=62272
2023-01-08 16:09:00 - progress_bar.py[line:274] - INFO: epoch 001:  15781 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.455, wps=102.6, ups=0.47, wpb=109.7, bsz=40, num_updates=15760, lr=4.49974e-05, gnorm=0.502, clip=10, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=62295
2023-01-08 16:09:22 - progress_bar.py[line:274] - INFO: epoch 001:  15791 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4398, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=15770, lr=4.49929e-05, gnorm=0.38, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62317
2023-01-08 16:09:45 - progress_bar.py[line:274] - INFO: epoch 001:  15801 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4265, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=15780, lr=4.49884e-05, gnorm=0.208, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=62340
2023-01-08 16:10:07 - progress_bar.py[line:274] - INFO: epoch 001:  15811 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4847, wps=102.8, ups=0.47, wpb=109.4, bsz=40, num_updates=15790, lr=4.49839e-05, gnorm=0.482, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62362
2023-01-08 16:10:29 - progress_bar.py[line:274] - INFO: epoch 001:  15821 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4836, wps=100.9, ups=0.46, wpb=109.4, bsz=40, num_updates=15800, lr=4.49794e-05, gnorm=0.225, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=62384
2023-01-08 16:10:51 - progress_bar.py[line:274] - INFO: epoch 001:  15831 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.449, wps=104, ups=0.47, wpb=109.9, bsz=40, num_updates=15810, lr=4.49749e-05, gnorm=0.386, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62406
2023-01-08 16:11:14 - progress_bar.py[line:274] - INFO: epoch 001:  15841 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.392, wps=99.3, ups=0.46, wpb=108, bsz=40, num_updates=15820, lr=4.49704e-05, gnorm=0.224, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62429
2023-01-08 16:11:36 - progress_bar.py[line:274] - INFO: epoch 001:  15851 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.395, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=15830, lr=4.49659e-05, gnorm=0.191, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=62451
2023-01-08 16:11:58 - progress_bar.py[line:274] - INFO: epoch 001:  15861 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4479, wps=106, ups=0.48, wpb=110.6, bsz=40, num_updates=15840, lr=4.49614e-05, gnorm=0.365, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=62473
2023-01-08 16:12:20 - progress_bar.py[line:274] - INFO: epoch 001:  15871 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4229, wps=101.5, ups=0.47, wpb=108.6, bsz=40, num_updates=15850, lr=4.49569e-05, gnorm=0.36, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62495
2023-01-08 16:12:42 - progress_bar.py[line:274] - INFO: epoch 001:  15881 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4369, wps=102.3, ups=0.47, wpb=109.1, bsz=40, num_updates=15860, lr=4.49524e-05, gnorm=0.283, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62518
2023-01-08 16:13:05 - progress_bar.py[line:274] - INFO: epoch 001:  15891 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.396, wps=101.9, ups=0.46, wpb=110.1, bsz=40, num_updates=15870, lr=4.49479e-05, gnorm=0.172, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=62540
2023-01-08 16:13:27 - progress_bar.py[line:274] - INFO: epoch 001:  15901 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4811, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=15880, lr=4.49434e-05, gnorm=0.348, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=62562
2023-01-08 16:13:50 - progress_bar.py[line:274] - INFO: epoch 001:  15911 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4387, wps=98.3, ups=0.46, wpb=107.7, bsz=40, num_updates=15890, lr=4.49389e-05, gnorm=0.244, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62585
2023-01-08 16:14:11 - progress_bar.py[line:274] - INFO: epoch 001:  15921 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3909, wps=101.8, ups=0.47, wpb=107.2, bsz=40, num_updates=15900, lr=4.49344e-05, gnorm=0.349, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=62607
2023-01-08 16:14:34 - progress_bar.py[line:274] - INFO: epoch 001:  15931 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4087, wps=99.1, ups=0.46, wpb=108.9, bsz=40, num_updates=15910, lr=4.493e-05, gnorm=0.364, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=62629
2023-01-08 16:14:36 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 16:14:59 - progress_bar.py[line:274] - INFO: epoch 001:  15942 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.952, nsentences=40, sample_size=110.952, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5046, wps=96.5, ups=0.41, wpb=111, bsz=40, num_updates=15920, lr=4.49255e-05, gnorm=0.294, clip=0, loss_scale=512, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=62655
2023-01-08 16:15:22 - progress_bar.py[line:274] - INFO: epoch 001:  15952 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3938, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=15930, lr=4.4921e-05, gnorm=0.565, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=62677
2023-01-08 16:15:44 - progress_bar.py[line:274] - INFO: epoch 001:  15962 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4394, wps=102.8, ups=0.47, wpb=108.9, bsz=40, num_updates=15940, lr=4.49165e-05, gnorm=0.231, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62699
2023-01-08 16:16:06 - progress_bar.py[line:274] - INFO: epoch 001:  15972 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4387, wps=102, ups=0.47, wpb=107.9, bsz=40, num_updates=15950, lr=4.4912e-05, gnorm=0.352, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=62721
2023-01-08 16:16:27 - progress_bar.py[line:274] - INFO: epoch 001:  15982 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4229, wps=102.8, ups=0.48, wpb=107.6, bsz=40, num_updates=15960, lr=4.49075e-05, gnorm=0.411, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62743
2023-01-08 16:16:50 - progress_bar.py[line:274] - INFO: epoch 001:  15992 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4208, wps=102, ups=0.46, wpb=110.9, bsz=40, num_updates=15970, lr=4.4903e-05, gnorm=0.286, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62765
2023-01-08 16:17:12 - progress_bar.py[line:274] - INFO: epoch 001:  16002 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4323, wps=102.5, ups=0.47, wpb=109.4, bsz=40, num_updates=15980, lr=4.48985e-05, gnorm=0.353, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62787
2023-01-08 16:17:34 - progress_bar.py[line:274] - INFO: epoch 001:  16012 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.398, wps=101.5, ups=0.46, wpb=109.3, bsz=40, num_updates=15990, lr=4.4894e-05, gnorm=0.244, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=62809
2023-01-08 16:17:56 - progress_bar.py[line:274] - INFO: epoch 001:  16022 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4, wps=101.9, ups=0.46, wpb=109.9, bsz=40, num_updates=16000, lr=4.48895e-05, gnorm=0.282, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62831
2023-01-08 16:17:56 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 16:17:58 - train.py[line:549] - INFO: 0 / 4988
2023-01-08 16:17:58 - train.py[line:551] - INFO: load:1.33 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 16:20:30 - train.py[line:549] - INFO: 200 / 4988
2023-01-08 16:20:30 - train.py[line:551] - INFO: load:1.35 valid_run:151.77 task_valid:148.02 collect_output:2.67
2023-01-08 16:22:58 - train.py[line:549] - INFO: 400 / 4988
2023-01-08 16:22:58 - train.py[line:551] - INFO: load:1.38 valid_run:300.38 task_valid:290.81 collect_output:7.41
2023-01-08 16:25:31 - train.py[line:549] - INFO: 600 / 4988
2023-01-08 16:25:31 - train.py[line:551] - INFO: load:1.41 valid_run:452.83 task_valid:433.57 collect_output:16.02
2023-01-08 16:28:00 - train.py[line:549] - INFO: 800 / 4988
2023-01-08 16:28:00 - train.py[line:551] - INFO: load:1.43 valid_run:601.83 task_valid:578.23 collect_output:19.30
2023-01-08 16:30:32 - train.py[line:549] - INFO: 1000 / 4988
2023-01-08 16:30:32 - train.py[line:551] - INFO: load:1.46 valid_run:754.24 task_valid:725.56 collect_output:23.34
2023-01-08 16:33:04 - train.py[line:549] - INFO: 1200 / 4988
2023-01-08 16:33:04 - train.py[line:551] - INFO: load:1.49 valid_run:906.06 task_valid:870.75 collect_output:28.91
2023-01-08 16:35:38 - train.py[line:549] - INFO: 1400 / 4988
2023-01-08 16:35:38 - train.py[line:551] - INFO: load:1.51 valid_run:1059.56 task_valid:1016.37 collect_output:35.76
2023-01-08 16:38:09 - train.py[line:549] - INFO: 1600 / 4988
2023-01-08 16:38:09 - train.py[line:551] - INFO: load:1.54 valid_run:1210.95 task_valid:1157.24 collect_output:45.25
2023-01-08 16:40:39 - train.py[line:549] - INFO: 1800 / 4988
2023-01-08 16:40:39 - train.py[line:551] - INFO: load:1.57 valid_run:1360.58 task_valid:1301.79 collect_output:49.29
2023-01-08 16:43:08 - train.py[line:549] - INFO: 2000 / 4988
2023-01-08 16:43:08 - train.py[line:551] - INFO: load:1.59 valid_run:1509.24 task_valid:1444.54 collect_output:54.19
2023-01-08 16:45:37 - train.py[line:549] - INFO: 2200 / 4988
2023-01-08 16:45:37 - train.py[line:551] - INFO: load:1.62 valid_run:1658.93 task_valid:1589.07 collect_output:58.33
2023-01-08 16:48:07 - train.py[line:549] - INFO: 2400 / 4988
2023-01-08 16:48:07 - train.py[line:551] - INFO: load:1.65 valid_run:1808.90 task_valid:1733.69 collect_output:62.65
2023-01-08 16:50:38 - train.py[line:549] - INFO: 2600 / 4988
2023-01-08 16:50:38 - train.py[line:551] - INFO: load:1.67 valid_run:1959.21 task_valid:1875.39 collect_output:70.23
2023-01-08 16:53:09 - train.py[line:549] - INFO: 2800 / 4988
2023-01-08 16:53:09 - train.py[line:551] - INFO: load:1.70 valid_run:2109.87 task_valid:2020.50 collect_output:74.72
2023-01-08 16:55:38 - train.py[line:549] - INFO: 3000 / 4988
2023-01-08 16:55:39 - train.py[line:551] - INFO: load:1.73 valid_run:2259.77 task_valid:2166.49 collect_output:77.58
2023-01-08 16:58:09 - train.py[line:549] - INFO: 3200 / 4988
2023-01-08 16:58:09 - train.py[line:551] - INFO: load:1.75 valid_run:2409.75 task_valid:2310.23 collect_output:82.80
2023-01-08 17:00:40 - train.py[line:549] - INFO: 3400 / 4988
2023-01-08 17:00:40 - train.py[line:551] - INFO: load:1.78 valid_run:2561.59 task_valid:2455.41 collect_output:88.40
2023-01-08 17:03:11 - train.py[line:549] - INFO: 3600 / 4988
2023-01-08 17:03:11 - train.py[line:551] - INFO: load:1.81 valid_run:2711.89 task_valid:2601.95 collect_output:91.12
2023-01-08 17:05:40 - train.py[line:549] - INFO: 3800 / 4988
2023-01-08 17:05:40 - train.py[line:551] - INFO: load:1.83 valid_run:2860.55 task_valid:2743.12 collect_output:97.58
2023-01-08 17:08:10 - train.py[line:549] - INFO: 4000 / 4988
2023-01-08 17:08:10 - train.py[line:551] - INFO: load:1.86 valid_run:3010.89 task_valid:2887.84 collect_output:102.14
2023-01-08 17:10:42 - train.py[line:549] - INFO: 4200 / 4988
2023-01-08 17:10:42 - train.py[line:551] - INFO: load:1.89 valid_run:3163.21 task_valid:3032.14 collect_output:109.16
2023-01-08 17:13:12 - train.py[line:549] - INFO: 4400 / 4988
2023-01-08 17:13:12 - train.py[line:551] - INFO: load:1.91 valid_run:3312.38 task_valid:3176.20 collect_output:113.25
2023-01-08 17:15:43 - train.py[line:549] - INFO: 4600 / 4988
2023-01-08 17:15:43 - train.py[line:551] - INFO: load:1.94 valid_run:3463.82 task_valid:3322.08 collect_output:117.74
2023-01-08 17:18:14 - train.py[line:549] - INFO: 4800 / 4988
2023-01-08 17:18:14 - train.py[line:551] - INFO: load:1.96 valid_run:3615.01 task_valid:3468.12 collect_output:121.87

====================================================================================================
SGG eval:     R @ 50: 0.4373;     R @ 100: 0.5208;     R @ 500: 0.5710;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2637;    mR @ 100: 0.3394;    mR @ 500: 0.3850;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6537) (covered in:0.5625) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.8006) (playing:0.0000) (riding:0.6601) (says:0.0000) (sitting on:0.6905) (standing on:0.2233) (using:0.6500) (walking in:0.0000) (walking on:0.2613) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-08 17:20:45 - train.py[line:487] - INFO: 0.5208238095238096
2023-01-08 17:20:45 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 17:20:45 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.375 | loss_v1 0 | loss_v2 0 | nll_loss 0.223 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.520824 | ppl 1.17 | vqa_score 0.473 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 16000 | best_R@100 0.645421

====================================================================================================
SGG eval:     R @ 50: 0.4373;     R @ 100: 0.5208;     R @ 500: 0.5710;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2637;    mR @ 100: 0.3394;    mR @ 500: 0.3850;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6537) (covered in:0.5625) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.8006) (playing:0.0000) (riding:0.6601) (says:0.0000) (sitting on:0.6905) (standing on:0.2233) (using:0.6500) (walking in:0.0000) (walking on:0.2613) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-08 17:20:45 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 16000 updates
2023-01-08 17:20:45 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_16000.pt
2023-01-08 17:21:25 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_16000.pt
2023-01-08 17:22:50 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_16000.pt (epoch 1 @ 16000 updates, score 0.5208238095238096) (writing took 124.27903215773404 seconds)
2023-01-08 17:23:11 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 17:23:14 - progress_bar.py[line:274] - INFO: epoch 001:  16033 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.333, nsentences=40, sample_size=109.333, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4466, wps=0.6, ups=0, wpb=109.3, bsz=40, num_updates=16010, lr=4.4885e-05, gnorm=0.39, clip=0, loss_scale=256, train_wall=24, gb_free=10.1, ema_decay=0.9999, wall=66749
2023-01-08 17:23:36 - progress_bar.py[line:274] - INFO: epoch 001:  16043 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4681, wps=100.3, ups=0.46, wpb=110.1, bsz=40, num_updates=16020, lr=4.48805e-05, gnorm=0.284, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66772
2023-01-08 17:23:58 - progress_bar.py[line:274] - INFO: epoch 001:  16053 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=100.7, ups=0.46, wpb=109.5, bsz=40, num_updates=16030, lr=4.4876e-05, gnorm=0.35, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=66794
2023-01-08 17:24:20 - progress_bar.py[line:274] - INFO: epoch 001:  16063 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4202, wps=101.6, ups=0.46, wpb=109.7, bsz=40, num_updates=16040, lr=4.48715e-05, gnorm=0.299, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66816
2023-01-08 17:24:42 - progress_bar.py[line:274] - INFO: epoch 001:  16073 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4293, wps=98.6, ups=0.46, wpb=108.1, bsz=40, num_updates=16050, lr=4.4867e-05, gnorm=0.365, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=66838
2023-01-08 17:25:03 - progress_bar.py[line:274] - INFO: epoch 001:  16083 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3939, wps=103.6, ups=0.47, wpb=109.6, bsz=40, num_updates=16060, lr=4.48625e-05, gnorm=0.301, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=66859
2023-01-08 17:25:25 - progress_bar.py[line:274] - INFO: epoch 001:  16093 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4476, wps=100.6, ups=0.46, wpb=108.2, bsz=40, num_updates=16070, lr=4.4858e-05, gnorm=0.279, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=66881
2023-01-08 17:25:47 - progress_bar.py[line:274] - INFO: epoch 001:  16103 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4308, wps=101.6, ups=0.47, wpb=109.1, bsz=40, num_updates=16080, lr=4.48535e-05, gnorm=0.467, clip=10, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=66903
2023-01-08 17:26:09 - progress_bar.py[line:274] - INFO: epoch 001:  16113 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4194, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=16090, lr=4.4849e-05, gnorm=0.241, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=66925
2023-01-08 17:26:30 - progress_bar.py[line:274] - INFO: epoch 001:  16123 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4439, wps=102.1, ups=0.47, wpb=108.2, bsz=40, num_updates=16100, lr=4.48445e-05, gnorm=0.341, clip=0, loss_scale=256, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=66946
2023-01-08 17:26:53 - progress_bar.py[line:274] - INFO: epoch 001:  16133 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4278, wps=100.8, ups=0.46, wpb=110, bsz=40, num_updates=16110, lr=4.484e-05, gnorm=0.377, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66968
2023-01-08 17:27:14 - progress_bar.py[line:274] - INFO: epoch 001:  16143 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4048, wps=101.3, ups=0.47, wpb=107.5, bsz=40, num_updates=16120, lr=4.48355e-05, gnorm=0.31, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=66990
2023-01-08 17:27:35 - progress_bar.py[line:274] - INFO: epoch 001:  16153 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4082, wps=104.5, ups=0.48, wpb=109.4, bsz=40, num_updates=16130, lr=4.4831e-05, gnorm=0.4, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67011
2023-01-08 17:27:57 - progress_bar.py[line:274] - INFO: epoch 001:  16163 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4031, wps=102.6, ups=0.47, wpb=108.8, bsz=40, num_updates=16140, lr=4.48265e-05, gnorm=0.547, clip=30, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67032
2023-01-08 17:28:19 - progress_bar.py[line:274] - INFO: epoch 001:  16173 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4433, wps=98.5, ups=0.45, wpb=108.4, bsz=40, num_updates=16150, lr=4.48221e-05, gnorm=0.395, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=67055
2023-01-08 17:28:40 - progress_bar.py[line:274] - INFO: epoch 001:  16183 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4171, wps=104.3, ups=0.47, wpb=110.4, bsz=40, num_updates=16160, lr=4.48176e-05, gnorm=0.275, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67076
2023-01-08 17:29:02 - progress_bar.py[line:274] - INFO: epoch 001:  16193 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3941, wps=100.4, ups=0.46, wpb=108, bsz=40, num_updates=16170, lr=4.48131e-05, gnorm=0.249, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=67098
2023-01-08 17:29:23 - progress_bar.py[line:274] - INFO: epoch 001:  16203 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.418, wps=103.9, ups=0.48, wpb=109.3, bsz=40, num_updates=16180, lr=4.48086e-05, gnorm=0.305, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67119
2023-01-08 17:29:45 - progress_bar.py[line:274] - INFO: epoch 001:  16213 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.457, wps=98.4, ups=0.46, wpb=107.1, bsz=40, num_updates=16190, lr=4.48041e-05, gnorm=0.412, clip=10, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=67141
2023-01-08 17:30:07 - progress_bar.py[line:274] - INFO: epoch 001:  16223 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4444, wps=100.7, ups=0.46, wpb=108.4, bsz=40, num_updates=16200, lr=4.47996e-05, gnorm=1.053, clip=20, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=67163
2023-01-08 17:30:29 - progress_bar.py[line:274] - INFO: epoch 001:  16233 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4115, wps=101.2, ups=0.46, wpb=110.6, bsz=40, num_updates=16210, lr=4.47951e-05, gnorm=0.331, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=67185
2023-01-08 17:30:51 - progress_bar.py[line:274] - INFO: epoch 001:  16243 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4593, wps=101.5, ups=0.47, wpb=107.6, bsz=40, num_updates=16220, lr=4.47906e-05, gnorm=0.307, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67206
2023-01-08 17:31:13 - progress_bar.py[line:274] - INFO: epoch 001:  16253 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4387, wps=100.1, ups=0.47, wpb=107.2, bsz=40, num_updates=16230, lr=4.47861e-05, gnorm=0.233, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67228
2023-01-08 17:31:34 - progress_bar.py[line:274] - INFO: epoch 001:  16263 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4815, wps=102.7, ups=0.47, wpb=108.9, bsz=40, num_updates=16240, lr=4.47816e-05, gnorm=0.265, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67250
2023-01-08 17:31:56 - progress_bar.py[line:274] - INFO: epoch 001:  16273 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4634, wps=100.8, ups=0.46, wpb=108.9, bsz=40, num_updates=16250, lr=4.47771e-05, gnorm=0.312, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67272
2023-01-08 17:32:18 - progress_bar.py[line:274] - INFO: epoch 001:  16283 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4948, wps=100, ups=0.46, wpb=109.2, bsz=40, num_updates=16260, lr=4.47726e-05, gnorm=0.317, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67294
2023-01-08 17:32:40 - progress_bar.py[line:274] - INFO: epoch 001:  16293 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4158, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=16270, lr=4.47681e-05, gnorm=0.269, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67316
2023-01-08 17:33:01 - progress_bar.py[line:274] - INFO: epoch 001:  16303 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4343, wps=102.2, ups=0.47, wpb=108.5, bsz=40, num_updates=16280, lr=4.47636e-05, gnorm=0.463, clip=10, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=67337
2023-01-08 17:33:24 - progress_bar.py[line:274] - INFO: epoch 001:  16313 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4726, wps=99.6, ups=0.45, wpb=109.6, bsz=40, num_updates=16290, lr=4.47591e-05, gnorm=0.239, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=67359
2023-01-08 17:33:45 - progress_bar.py[line:274] - INFO: epoch 001:  16323 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5, wps=100.7, ups=0.47, wpb=108.1, bsz=40, num_updates=16300, lr=4.47546e-05, gnorm=0.231, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67381
2023-01-08 17:34:07 - progress_bar.py[line:274] - INFO: epoch 001:  16333 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4372, wps=98.1, ups=0.46, wpb=106.9, bsz=40, num_updates=16310, lr=4.47501e-05, gnorm=0.339, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=67403
2023-01-08 17:34:30 - progress_bar.py[line:274] - INFO: epoch 001:  16343 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4381, wps=97.9, ups=0.45, wpb=107.9, bsz=40, num_updates=16320, lr=4.47456e-05, gnorm=0.304, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=67426
2023-01-08 17:34:51 - progress_bar.py[line:274] - INFO: epoch 001:  16353 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4656, wps=103, ups=0.47, wpb=110.2, bsz=40, num_updates=16330, lr=4.47411e-05, gnorm=0.559, clip=10, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=67447
2023-01-08 17:35:13 - progress_bar.py[line:274] - INFO: epoch 001:  16363 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4564, wps=101.8, ups=0.46, wpb=109.6, bsz=40, num_updates=16340, lr=4.47366e-05, gnorm=0.357, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67469
2023-01-08 17:35:35 - progress_bar.py[line:274] - INFO: epoch 001:  16373 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4619, wps=100.8, ups=0.46, wpb=108.9, bsz=40, num_updates=16350, lr=4.47321e-05, gnorm=0.367, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=67491
2023-01-08 17:35:57 - progress_bar.py[line:274] - INFO: epoch 001:  16383 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4396, wps=102.2, ups=0.47, wpb=109.3, bsz=40, num_updates=16360, lr=4.47276e-05, gnorm=0.404, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67512
2023-01-08 17:36:18 - progress_bar.py[line:274] - INFO: epoch 001:  16393 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4225, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=16370, lr=4.47231e-05, gnorm=0.249, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=67534
2023-01-08 17:36:40 - progress_bar.py[line:274] - INFO: epoch 001:  16403 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4862, wps=99.4, ups=0.46, wpb=107.5, bsz=40, num_updates=16380, lr=4.47186e-05, gnorm=0.275, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=67556
2023-01-08 17:37:02 - progress_bar.py[line:274] - INFO: epoch 001:  16413 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4, wps=100.1, ups=0.46, wpb=108.2, bsz=40, num_updates=16390, lr=4.47141e-05, gnorm=0.538, clip=20, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67578
2023-01-08 17:37:24 - progress_bar.py[line:274] - INFO: epoch 001:  16423 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4488, wps=103.2, ups=0.47, wpb=110.2, bsz=40, num_updates=16400, lr=4.47097e-05, gnorm=0.212, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=67599
2023-01-08 17:37:45 - progress_bar.py[line:274] - INFO: epoch 001:  16433 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.509, wps=104.5, ups=0.47, wpb=111.5, bsz=40, num_updates=16410, lr=4.47052e-05, gnorm=0.244, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67621
2023-01-08 17:38:07 - progress_bar.py[line:274] - INFO: epoch 001:  16443 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4824, wps=102.9, ups=0.47, wpb=110, bsz=40, num_updates=16420, lr=4.47007e-05, gnorm=0.242, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=67643
2023-01-08 17:38:29 - progress_bar.py[line:274] - INFO: epoch 001:  16453 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5245, wps=99.7, ups=0.46, wpb=108.2, bsz=40, num_updates=16430, lr=4.46962e-05, gnorm=0.348, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=67665
2023-01-08 17:38:51 - progress_bar.py[line:274] - INFO: epoch 001:  16463 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4225, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=16440, lr=4.46917e-05, gnorm=0.325, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67686
2023-01-08 17:39:12 - progress_bar.py[line:274] - INFO: epoch 001:  16473 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4466, wps=103.3, ups=0.47, wpb=110, bsz=40, num_updates=16450, lr=4.46872e-05, gnorm=0.424, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=67708
2023-01-08 17:39:33 - progress_bar.py[line:274] - INFO: epoch 001:  16483 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4595, wps=104.6, ups=0.48, wpb=109.4, bsz=40, num_updates=16460, lr=4.46827e-05, gnorm=0.446, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=67729
2023-01-08 17:39:55 - progress_bar.py[line:274] - INFO: epoch 001:  16493 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4895, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=16470, lr=4.46782e-05, gnorm=0.271, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67751
2023-01-08 17:40:16 - progress_bar.py[line:274] - INFO: epoch 001:  16503 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4415, wps=102.7, ups=0.47, wpb=110.1, bsz=40, num_updates=16480, lr=4.46737e-05, gnorm=0.344, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=67772
2023-01-08 17:40:38 - progress_bar.py[line:274] - INFO: epoch 001:  16513 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4021, wps=105.3, ups=0.48, wpb=110.6, bsz=40, num_updates=16490, lr=4.46692e-05, gnorm=0.391, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67794
2023-01-08 17:41:00 - progress_bar.py[line:274] - INFO: epoch 001:  16523 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4819, wps=100.6, ups=0.46, wpb=110, bsz=40, num_updates=16500, lr=4.46647e-05, gnorm=0.517, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67816
2023-01-08 17:41:22 - progress_bar.py[line:274] - INFO: epoch 001:  16533 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4381, wps=99.1, ups=0.46, wpb=108.6, bsz=40, num_updates=16510, lr=4.46602e-05, gnorm=0.251, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67838
2023-01-08 17:41:44 - progress_bar.py[line:274] - INFO: epoch 001:  16543 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4686, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=16520, lr=4.46557e-05, gnorm=0.282, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=67860
2023-01-08 17:42:05 - progress_bar.py[line:274] - INFO: epoch 001:  16553 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4663, wps=103.6, ups=0.47, wpb=109.2, bsz=40, num_updates=16530, lr=4.46512e-05, gnorm=0.302, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=67881
2023-01-08 17:42:27 - progress_bar.py[line:274] - INFO: epoch 001:  16563 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4279, wps=100.2, ups=0.46, wpb=110, bsz=40, num_updates=16540, lr=4.46467e-05, gnorm=0.32, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=67903
2023-01-08 17:42:49 - progress_bar.py[line:274] - INFO: epoch 001:  16573 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5068, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=16550, lr=4.46422e-05, gnorm=0.406, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=67925
2023-01-08 17:43:11 - progress_bar.py[line:274] - INFO: epoch 001:  16583 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4316, wps=103.6, ups=0.47, wpb=109.7, bsz=40, num_updates=16560, lr=4.46377e-05, gnorm=0.361, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67946
2023-01-08 17:43:32 - progress_bar.py[line:274] - INFO: epoch 001:  16593 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4049, wps=102.3, ups=0.47, wpb=108.2, bsz=40, num_updates=16570, lr=4.46332e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=67968
2023-01-08 17:43:54 - progress_bar.py[line:274] - INFO: epoch 001:  16603 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4794, wps=101.1, ups=0.46, wpb=110, bsz=40, num_updates=16580, lr=4.46287e-05, gnorm=0.297, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67990
2023-01-08 17:44:16 - progress_bar.py[line:274] - INFO: epoch 001:  16613 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4124, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=16590, lr=4.46242e-05, gnorm=0.386, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68012
2023-01-08 17:44:37 - progress_bar.py[line:274] - INFO: epoch 001:  16623 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4725, wps=102, ups=0.46, wpb=109.8, bsz=40, num_updates=16600, lr=4.46197e-05, gnorm=0.307, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68033
2023-01-08 17:44:44 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 17:45:01 - progress_bar.py[line:274] - INFO: epoch 001:  16634 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.19, nsentences=40, sample_size=109.19, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4299, wps=97.3, ups=0.42, wpb=109.2, bsz=40, num_updates=16610, lr=4.46152e-05, gnorm=0.247, clip=0, loss_scale=256, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=68057
2023-01-08 17:45:23 - progress_bar.py[line:274] - INFO: epoch 001:  16644 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4513, wps=99.7, ups=0.46, wpb=109, bsz=40, num_updates=16620, lr=4.46107e-05, gnorm=0.228, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=68079
2023-01-08 17:45:45 - progress_bar.py[line:274] - INFO: epoch 001:  16654 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4865, wps=102.6, ups=0.47, wpb=109.7, bsz=40, num_updates=16630, lr=4.46062e-05, gnorm=0.237, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68101
2023-01-08 17:46:07 - progress_bar.py[line:274] - INFO: epoch 001:  16664 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4244, wps=100.2, ups=0.46, wpb=109.1, bsz=40, num_updates=16640, lr=4.46018e-05, gnorm=0.285, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=68123
2023-01-08 17:46:28 - progress_bar.py[line:274] - INFO: epoch 001:  16674 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4439, wps=104.3, ups=0.48, wpb=108.5, bsz=40, num_updates=16650, lr=4.45973e-05, gnorm=0.474, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68144
2023-01-08 17:46:50 - progress_bar.py[line:274] - INFO: epoch 001:  16684 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4423, wps=99.1, ups=0.46, wpb=107.7, bsz=40, num_updates=16660, lr=4.45928e-05, gnorm=0.832, clip=20, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=68166
2023-01-08 17:47:12 - progress_bar.py[line:274] - INFO: epoch 001:  16694 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4413, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=16670, lr=4.45883e-05, gnorm=0.273, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68188
2023-01-08 17:47:33 - progress_bar.py[line:274] - INFO: epoch 001:  16704 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.462, wps=104.7, ups=0.48, wpb=110.2, bsz=40, num_updates=16680, lr=4.45838e-05, gnorm=0.411, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68209
2023-01-08 17:47:55 - progress_bar.py[line:274] - INFO: epoch 001:  16714 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4728, wps=102.4, ups=0.47, wpb=109.8, bsz=40, num_updates=16690, lr=4.45793e-05, gnorm=0.269, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=68231
2023-01-08 17:48:17 - progress_bar.py[line:274] - INFO: epoch 001:  16724 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4129, wps=101.2, ups=0.47, wpb=108.2, bsz=40, num_updates=16700, lr=4.45748e-05, gnorm=0.268, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68252
2023-01-08 17:48:38 - progress_bar.py[line:274] - INFO: epoch 001:  16734 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5156, wps=103.5, ups=0.47, wpb=110.4, bsz=40, num_updates=16710, lr=4.45703e-05, gnorm=0.412, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68274
2023-01-08 17:49:00 - progress_bar.py[line:274] - INFO: epoch 001:  16744 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4434, wps=98.5, ups=0.45, wpb=108.7, bsz=40, num_updates=16720, lr=4.45658e-05, gnorm=0.476, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=68296
2023-01-08 17:49:22 - progress_bar.py[line:274] - INFO: epoch 001:  16754 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4826, wps=99.1, ups=0.46, wpb=107.7, bsz=40, num_updates=16730, lr=4.45613e-05, gnorm=0.266, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=68318
2023-01-08 17:49:44 - progress_bar.py[line:274] - INFO: epoch 001:  16764 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4389, wps=101.8, ups=0.46, wpb=110.2, bsz=40, num_updates=16740, lr=4.45568e-05, gnorm=0.333, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68340
2023-01-08 17:50:06 - progress_bar.py[line:274] - INFO: epoch 001:  16774 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.43, wps=101.3, ups=0.46, wpb=109.4, bsz=40, num_updates=16750, lr=4.45523e-05, gnorm=0.353, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=68362
2023-01-08 17:50:28 - progress_bar.py[line:274] - INFO: epoch 001:  16784 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4503, wps=101.8, ups=0.46, wpb=110.2, bsz=40, num_updates=16760, lr=4.45478e-05, gnorm=0.436, clip=10, loss_scale=256, train_wall=22, gb_free=9.5, ema_decay=0.9999, wall=68384
2023-01-08 17:50:50 - progress_bar.py[line:274] - INFO: epoch 001:  16794 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3942, wps=101.3, ups=0.46, wpb=109.7, bsz=40, num_updates=16770, lr=4.45433e-05, gnorm=0.258, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=68406
2023-01-08 17:51:11 - progress_bar.py[line:274] - INFO: epoch 001:  16804 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4721, wps=102, ups=0.47, wpb=109, bsz=40, num_updates=16780, lr=4.45388e-05, gnorm=0.288, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68427
2023-01-08 17:51:33 - progress_bar.py[line:274] - INFO: epoch 001:  16814 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4577, wps=101.5, ups=0.46, wpb=109.6, bsz=40, num_updates=16790, lr=4.45343e-05, gnorm=0.302, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=68449
2023-01-08 17:51:55 - progress_bar.py[line:274] - INFO: epoch 001:  16824 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5098, wps=101.7, ups=0.46, wpb=109.9, bsz=40, num_updates=16800, lr=4.45298e-05, gnorm=0.261, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=68471
2023-01-08 17:52:17 - progress_bar.py[line:274] - INFO: epoch 001:  16834 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4084, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=16810, lr=4.45253e-05, gnorm=0.575, clip=30, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=68493
2023-01-08 17:52:39 - progress_bar.py[line:274] - INFO: epoch 001:  16844 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5234, wps=100.7, ups=0.46, wpb=108.6, bsz=40, num_updates=16820, lr=4.45208e-05, gnorm=0.276, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=68514
2023-01-08 17:53:00 - progress_bar.py[line:274] - INFO: epoch 001:  16854 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4225, wps=102.2, ups=0.47, wpb=107.9, bsz=40, num_updates=16830, lr=4.45163e-05, gnorm=0.445, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68536
2023-01-08 17:53:22 - progress_bar.py[line:274] - INFO: epoch 001:  16864 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3862, wps=100, ups=0.46, wpb=108.8, bsz=40, num_updates=16840, lr=4.45118e-05, gnorm=0.188, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=68558
2023-01-08 17:53:43 - progress_bar.py[line:274] - INFO: epoch 001:  16874 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4949, wps=106, ups=0.48, wpb=110.4, bsz=40, num_updates=16850, lr=4.45073e-05, gnorm=0.292, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=68579
2023-01-08 17:54:04 - progress_bar.py[line:274] - INFO: epoch 001:  16884 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3822, wps=103.4, ups=0.47, wpb=109.6, bsz=40, num_updates=16860, lr=4.45028e-05, gnorm=0.407, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=68600
2023-01-08 17:54:26 - progress_bar.py[line:274] - INFO: epoch 001:  16894 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4703, wps=103.8, ups=0.47, wpb=110.2, bsz=40, num_updates=16870, lr=4.44983e-05, gnorm=0.35, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=68622
2023-01-08 17:54:48 - progress_bar.py[line:274] - INFO: epoch 001:  16904 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4537, wps=101.5, ups=0.47, wpb=108.7, bsz=40, num_updates=16880, lr=4.44938e-05, gnorm=0.351, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=68643
2023-01-08 17:55:09 - progress_bar.py[line:274] - INFO: epoch 001:  16914 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4162, wps=104.2, ups=0.47, wpb=110.5, bsz=40, num_updates=16890, lr=4.44894e-05, gnorm=0.37, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68665
2023-01-08 17:55:30 - progress_bar.py[line:274] - INFO: epoch 001:  16924 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3878, wps=103.2, ups=0.47, wpb=109, bsz=40, num_updates=16900, lr=4.44849e-05, gnorm=0.355, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=68686
2023-01-08 17:55:52 - progress_bar.py[line:274] - INFO: epoch 001:  16934 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4518, wps=101, ups=0.46, wpb=109.9, bsz=40, num_updates=16910, lr=4.44804e-05, gnorm=0.268, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=68708
2023-01-08 17:56:14 - progress_bar.py[line:274] - INFO: epoch 001:  16944 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4223, wps=103.2, ups=0.47, wpb=109.1, bsz=40, num_updates=16920, lr=4.44759e-05, gnorm=0.318, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68730
2023-01-08 17:56:35 - progress_bar.py[line:274] - INFO: epoch 001:  16954 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4262, wps=104.4, ups=0.47, wpb=110.6, bsz=40, num_updates=16930, lr=4.44714e-05, gnorm=0.329, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=68751
2023-01-08 17:56:56 - progress_bar.py[line:274] - INFO: epoch 001:  16964 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4714, wps=101.9, ups=0.47, wpb=107.8, bsz=40, num_updates=16940, lr=4.44669e-05, gnorm=0.298, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=68772
2023-01-08 17:57:18 - progress_bar.py[line:274] - INFO: epoch 001:  16974 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4505, wps=101.3, ups=0.47, wpb=108.3, bsz=40, num_updates=16950, lr=4.44624e-05, gnorm=0.465, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68794
2023-01-08 17:57:40 - progress_bar.py[line:274] - INFO: epoch 001:  16984 / 115845 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4709, wps=103.2, ups=0.47, wpb=110.9, bsz=40, num_updates=16960, lr=4.44579e-05, gnorm=0.296, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68816
2023-01-08 17:58:02 - progress_bar.py[line:274] - INFO: epoch 001:  16994 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4315, wps=100.2, ups=0.46, wpb=108.2, bsz=40, num_updates=16970, lr=4.44534e-05, gnorm=0.299, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68837
2023-01-08 17:58:24 - progress_bar.py[line:274] - INFO: epoch 001:  17004 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.468, wps=101.6, ups=0.46, wpb=110, bsz=40, num_updates=16980, lr=4.44489e-05, gnorm=0.267, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=68859
2023-01-08 17:58:45 - progress_bar.py[line:274] - INFO: epoch 001:  17014 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4433, wps=102.7, ups=0.47, wpb=108.8, bsz=40, num_updates=16990, lr=4.44444e-05, gnorm=0.176, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=68881
2023-01-08 17:59:07 - progress_bar.py[line:274] - INFO: epoch 001:  17024 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.435, wps=100.7, ups=0.46, wpb=109.6, bsz=40, num_updates=17000, lr=4.44399e-05, gnorm=0.301, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68903
2023-01-08 17:59:28 - progress_bar.py[line:274] - INFO: epoch 001:  17034 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.433, wps=105.4, ups=0.48, wpb=108.8, bsz=40, num_updates=17010, lr=4.44354e-05, gnorm=0.273, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68924
2023-01-08 17:59:50 - progress_bar.py[line:274] - INFO: epoch 001:  17044 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4129, wps=99.9, ups=0.46, wpb=107.9, bsz=40, num_updates=17020, lr=4.44309e-05, gnorm=0.245, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68945
2023-01-08 18:00:12 - progress_bar.py[line:274] - INFO: epoch 001:  17054 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4242, wps=100.5, ups=0.46, wpb=109, bsz=40, num_updates=17030, lr=4.44264e-05, gnorm=0.489, clip=20, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=68967
2023-01-08 18:00:33 - progress_bar.py[line:274] - INFO: epoch 001:  17064 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4929, wps=99.5, ups=0.46, wpb=107.4, bsz=40, num_updates=17040, lr=4.44219e-05, gnorm=0.438, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68989
2023-01-08 18:00:55 - progress_bar.py[line:274] - INFO: epoch 001:  17074 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.511, wps=103.3, ups=0.47, wpb=110.5, bsz=40, num_updates=17050, lr=4.44174e-05, gnorm=0.456, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69011
2023-01-08 18:01:17 - progress_bar.py[line:274] - INFO: epoch 001:  17084 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4059, wps=101.3, ups=0.47, wpb=108.9, bsz=40, num_updates=17060, lr=4.44129e-05, gnorm=0.315, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=69033
2023-01-08 18:01:39 - progress_bar.py[line:274] - INFO: epoch 001:  17094 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4766, wps=98.5, ups=0.45, wpb=108.3, bsz=40, num_updates=17070, lr=4.44084e-05, gnorm=0.26, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69055
2023-01-08 18:02:00 - progress_bar.py[line:274] - INFO: epoch 001:  17104 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4579, wps=105.2, ups=0.48, wpb=109.2, bsz=40, num_updates=17080, lr=4.44039e-05, gnorm=0.335, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69076
2023-01-08 18:02:22 - progress_bar.py[line:274] - INFO: epoch 001:  17114 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4904, wps=100, ups=0.46, wpb=109, bsz=40, num_updates=17090, lr=4.43994e-05, gnorm=0.301, clip=0, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=69098
2023-01-08 18:02:44 - progress_bar.py[line:274] - INFO: epoch 001:  17124 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4822, wps=101.2, ups=0.46, wpb=110.2, bsz=40, num_updates=17100, lr=4.43949e-05, gnorm=0.297, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=69120
2023-01-08 18:03:06 - progress_bar.py[line:274] - INFO: epoch 001:  17134 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4721, wps=102.1, ups=0.47, wpb=109.4, bsz=40, num_updates=17110, lr=4.43904e-05, gnorm=0.346, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69141
2023-01-08 18:03:27 - progress_bar.py[line:274] - INFO: epoch 001:  17144 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.48, wps=101.4, ups=0.47, wpb=108.3, bsz=40, num_updates=17120, lr=4.43859e-05, gnorm=0.428, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69163
2023-01-08 18:03:49 - progress_bar.py[line:274] - INFO: epoch 001:  17154 / 115845 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4751, wps=104.7, ups=0.47, wpb=111.4, bsz=40, num_updates=17130, lr=4.43815e-05, gnorm=0.195, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69185
2023-01-08 18:04:11 - progress_bar.py[line:274] - INFO: epoch 001:  17164 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3776, wps=102.2, ups=0.46, wpb=110.4, bsz=40, num_updates=17140, lr=4.4377e-05, gnorm=0.293, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=69206
2023-01-08 18:04:32 - progress_bar.py[line:274] - INFO: epoch 001:  17174 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4774, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=17150, lr=4.43725e-05, gnorm=0.434, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=69228
2023-01-08 18:04:54 - progress_bar.py[line:274] - INFO: epoch 001:  17184 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5224, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=17160, lr=4.4368e-05, gnorm=0.251, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=69250
2023-01-08 18:05:16 - progress_bar.py[line:274] - INFO: epoch 001:  17194 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4478, wps=103.2, ups=0.47, wpb=109.8, bsz=40, num_updates=17170, lr=4.43635e-05, gnorm=0.403, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69271
2023-01-08 18:05:37 - progress_bar.py[line:274] - INFO: epoch 001:  17204 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4059, wps=103.1, ups=0.48, wpb=108, bsz=40, num_updates=17180, lr=4.4359e-05, gnorm=0.238, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69293
2023-01-08 18:05:58 - progress_bar.py[line:274] - INFO: epoch 001:  17214 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4947, wps=104.2, ups=0.47, wpb=110.7, bsz=40, num_updates=17190, lr=4.43545e-05, gnorm=0.276, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=69314
2023-01-08 18:06:20 - progress_bar.py[line:274] - INFO: epoch 001:  17224 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4847, wps=101.7, ups=0.47, wpb=109.3, bsz=40, num_updates=17200, lr=4.435e-05, gnorm=0.31, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69336
2023-01-08 18:06:42 - progress_bar.py[line:274] - INFO: epoch 001:  17234 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4413, wps=98.7, ups=0.45, wpb=108.7, bsz=40, num_updates=17210, lr=4.43455e-05, gnorm=0.205, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=69358
2023-01-08 18:07:04 - progress_bar.py[line:274] - INFO: epoch 001:  17244 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=99.7, ups=0.46, wpb=107.8, bsz=40, num_updates=17220, lr=4.4341e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69380
2023-01-08 18:07:26 - progress_bar.py[line:274] - INFO: epoch 001:  17254 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4467, wps=100.6, ups=0.46, wpb=108.5, bsz=40, num_updates=17230, lr=4.43365e-05, gnorm=0.203, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=69402
2023-01-08 18:07:48 - progress_bar.py[line:274] - INFO: epoch 001:  17264 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4167, wps=99.9, ups=0.46, wpb=108.8, bsz=40, num_updates=17240, lr=4.4332e-05, gnorm=0.409, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=69424
2023-01-08 18:08:10 - progress_bar.py[line:274] - INFO: epoch 001:  17274 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.41, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=17250, lr=4.43275e-05, gnorm=0.277, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69446
2023-01-08 18:08:31 - progress_bar.py[line:274] - INFO: epoch 001:  17284 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4439, wps=103.4, ups=0.47, wpb=110.4, bsz=40, num_updates=17260, lr=4.4323e-05, gnorm=0.187, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69467
2023-01-08 18:08:53 - progress_bar.py[line:274] - INFO: epoch 001:  17294 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4433, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=17270, lr=4.43185e-05, gnorm=0.276, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69489
2023-01-08 18:09:14 - progress_bar.py[line:274] - INFO: epoch 001:  17304 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4507, wps=102.3, ups=0.48, wpb=107.3, bsz=40, num_updates=17280, lr=4.4314e-05, gnorm=0.253, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=69510
2023-01-08 18:09:36 - progress_bar.py[line:274] - INFO: epoch 001:  17314 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5152, wps=101.9, ups=0.47, wpb=107.9, bsz=40, num_updates=17290, lr=4.43095e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=69531
2023-01-08 18:09:57 - progress_bar.py[line:274] - INFO: epoch 001:  17324 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4633, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=17300, lr=4.4305e-05, gnorm=0.392, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69553
2023-01-08 18:10:19 - progress_bar.py[line:274] - INFO: epoch 001:  17334 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4433, wps=103.3, ups=0.47, wpb=109.4, bsz=40, num_updates=17310, lr=4.43005e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=69575
2023-01-08 18:10:41 - progress_bar.py[line:274] - INFO: epoch 001:  17344 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4569, wps=101.6, ups=0.46, wpb=110.4, bsz=40, num_updates=17320, lr=4.4296e-05, gnorm=0.296, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69597
2023-01-08 18:11:03 - progress_bar.py[line:274] - INFO: epoch 001:  17354 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4831, wps=98.3, ups=0.46, wpb=107.9, bsz=40, num_updates=17330, lr=4.42915e-05, gnorm=0.285, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=69619
2023-01-08 18:11:25 - progress_bar.py[line:274] - INFO: epoch 001:  17364 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4591, wps=99.7, ups=0.46, wpb=108.7, bsz=40, num_updates=17340, lr=4.4287e-05, gnorm=0.264, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=69641
2023-01-08 18:11:47 - progress_bar.py[line:274] - INFO: epoch 001:  17374 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4691, wps=101.1, ups=0.46, wpb=108.9, bsz=40, num_updates=17350, lr=4.42825e-05, gnorm=0.231, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69663
2023-01-08 18:12:09 - progress_bar.py[line:274] - INFO: epoch 001:  17384 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4179, wps=102.3, ups=0.46, wpb=110, bsz=40, num_updates=17360, lr=4.4278e-05, gnorm=0.211, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=69684
2023-01-08 18:12:31 - progress_bar.py[line:274] - INFO: epoch 001:  17394 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4615, wps=100.6, ups=0.45, wpb=110.6, bsz=40, num_updates=17370, lr=4.42735e-05, gnorm=0.433, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=69707
2023-01-08 18:12:53 - progress_bar.py[line:274] - INFO: epoch 001:  17404 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4394, wps=100.1, ups=0.46, wpb=108.2, bsz=40, num_updates=17380, lr=4.42691e-05, gnorm=0.221, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69728
2023-01-08 18:13:15 - progress_bar.py[line:274] - INFO: epoch 001:  17414 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.427, wps=101.1, ups=0.46, wpb=110.2, bsz=40, num_updates=17390, lr=4.42646e-05, gnorm=0.374, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=69750
2023-01-08 18:13:37 - progress_bar.py[line:274] - INFO: epoch 001:  17424 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.433, wps=100.8, ups=0.46, wpb=108.8, bsz=40, num_updates=17400, lr=4.42601e-05, gnorm=0.292, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69772
2023-01-08 18:13:58 - progress_bar.py[line:274] - INFO: epoch 001:  17434 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4286, wps=104.8, ups=0.48, wpb=110.1, bsz=40, num_updates=17410, lr=4.42556e-05, gnorm=0.293, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69794
2023-01-08 18:14:19 - progress_bar.py[line:274] - INFO: epoch 001:  17444 / 115845 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4104, wps=104.6, ups=0.47, wpb=111.5, bsz=40, num_updates=17420, lr=4.42511e-05, gnorm=0.272, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69815
2023-01-08 18:14:41 - progress_bar.py[line:274] - INFO: epoch 001:  17454 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4485, wps=102, ups=0.46, wpb=110.1, bsz=40, num_updates=17430, lr=4.42466e-05, gnorm=0.234, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=69837
2023-01-08 18:15:03 - progress_bar.py[line:274] - INFO: epoch 001:  17464 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4098, wps=102, ups=0.47, wpb=109.1, bsz=40, num_updates=17440, lr=4.42421e-05, gnorm=0.274, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69859
2023-01-08 18:15:24 - progress_bar.py[line:274] - INFO: epoch 001:  17474 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3892, wps=100.7, ups=0.47, wpb=107.9, bsz=40, num_updates=17450, lr=4.42376e-05, gnorm=0.374, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=69880
2023-01-08 18:15:46 - progress_bar.py[line:274] - INFO: epoch 001:  17484 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4429, wps=100.1, ups=0.47, wpb=107.1, bsz=40, num_updates=17460, lr=4.42331e-05, gnorm=0.266, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69902
2023-01-08 18:16:08 - progress_bar.py[line:274] - INFO: epoch 001:  17494 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4372, wps=100.5, ups=0.47, wpb=108, bsz=40, num_updates=17470, lr=4.42286e-05, gnorm=0.237, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69924
2023-01-08 18:16:29 - progress_bar.py[line:274] - INFO: epoch 001:  17504 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4365, wps=103.6, ups=0.47, wpb=110.1, bsz=40, num_updates=17480, lr=4.42241e-05, gnorm=0.533, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69945
2023-01-08 18:16:51 - progress_bar.py[line:274] - INFO: epoch 001:  17514 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4619, wps=103, ups=0.47, wpb=108.6, bsz=40, num_updates=17490, lr=4.42196e-05, gnorm=0.482, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=69966
2023-01-08 18:17:12 - progress_bar.py[line:274] - INFO: epoch 001:  17524 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4947, wps=102.3, ups=0.47, wpb=109.6, bsz=40, num_updates=17500, lr=4.42151e-05, gnorm=0.255, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69988
2023-01-08 18:17:34 - progress_bar.py[line:274] - INFO: epoch 001:  17534 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4476, wps=101.8, ups=0.47, wpb=108.4, bsz=40, num_updates=17510, lr=4.42106e-05, gnorm=0.245, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70010
2023-01-08 18:17:56 - progress_bar.py[line:274] - INFO: epoch 001:  17544 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4293, wps=100.3, ups=0.46, wpb=109.7, bsz=40, num_updates=17520, lr=4.42061e-05, gnorm=0.193, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=70032
2023-01-08 18:18:18 - progress_bar.py[line:274] - INFO: epoch 001:  17554 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4677, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=17530, lr=4.42016e-05, gnorm=0.258, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70053
2023-01-08 18:18:40 - progress_bar.py[line:274] - INFO: epoch 001:  17564 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4155, wps=98.9, ups=0.45, wpb=108.8, bsz=40, num_updates=17540, lr=4.41971e-05, gnorm=0.22, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=70076
2023-01-08 18:19:01 - progress_bar.py[line:274] - INFO: epoch 001:  17574 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4749, wps=104.4, ups=0.47, wpb=110.9, bsz=40, num_updates=17550, lr=4.41926e-05, gnorm=0.448, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70097
2023-01-08 18:19:23 - progress_bar.py[line:274] - INFO: epoch 001:  17584 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.366, wps=99.6, ups=0.46, wpb=108.3, bsz=40, num_updates=17560, lr=4.41881e-05, gnorm=0.241, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70119
2023-01-08 18:19:45 - progress_bar.py[line:274] - INFO: epoch 001:  17594 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4562, wps=100.8, ups=0.47, wpb=107.6, bsz=40, num_updates=17570, lr=4.41836e-05, gnorm=0.3, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=70141
2023-01-08 18:20:07 - progress_bar.py[line:274] - INFO: epoch 001:  17604 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4472, wps=102.8, ups=0.47, wpb=110.2, bsz=40, num_updates=17580, lr=4.41791e-05, gnorm=0.295, clip=0, loss_scale=512, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=70162
2023-01-08 18:20:29 - progress_bar.py[line:274] - INFO: epoch 001:  17614 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.488, wps=100.1, ups=0.46, wpb=108.8, bsz=40, num_updates=17590, lr=4.41746e-05, gnorm=0.323, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70184
2023-01-08 18:20:50 - progress_bar.py[line:274] - INFO: epoch 001:  17624 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.445, wps=102.8, ups=0.47, wpb=108.8, bsz=40, num_updates=17600, lr=4.41701e-05, gnorm=0.32, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70206
2023-01-08 18:21:12 - progress_bar.py[line:274] - INFO: epoch 001:  17634 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4703, wps=100.8, ups=0.46, wpb=109.9, bsz=40, num_updates=17610, lr=4.41656e-05, gnorm=0.371, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=70228
2023-01-08 18:21:34 - progress_bar.py[line:274] - INFO: epoch 001:  17644 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.424, wps=97.9, ups=0.45, wpb=107.6, bsz=40, num_updates=17620, lr=4.41612e-05, gnorm=0.358, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=70250
2023-01-08 18:21:56 - progress_bar.py[line:274] - INFO: epoch 001:  17654 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4559, wps=100.5, ups=0.46, wpb=108.7, bsz=40, num_updates=17630, lr=4.41567e-05, gnorm=0.261, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70272
2023-01-08 18:22:18 - progress_bar.py[line:274] - INFO: epoch 001:  17664 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5104, wps=98.7, ups=0.46, wpb=107.4, bsz=40, num_updates=17640, lr=4.41522e-05, gnorm=0.4, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=70294
2023-01-08 18:22:39 - progress_bar.py[line:274] - INFO: epoch 001:  17674 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.42, wps=102.1, ups=0.47, wpb=108.1, bsz=40, num_updates=17650, lr=4.41477e-05, gnorm=0.297, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=70315
2023-01-08 18:23:01 - progress_bar.py[line:274] - INFO: epoch 001:  17684 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.487, wps=102.6, ups=0.47, wpb=109.9, bsz=40, num_updates=17660, lr=4.41432e-05, gnorm=0.317, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70337
2023-01-08 18:23:23 - progress_bar.py[line:274] - INFO: epoch 001:  17694 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4455, wps=99.6, ups=0.47, wpb=107, bsz=40, num_updates=17670, lr=4.41387e-05, gnorm=0.319, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=70359
2023-01-08 18:23:45 - progress_bar.py[line:274] - INFO: epoch 001:  17704 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4567, wps=100.3, ups=0.45, wpb=110.5, bsz=40, num_updates=17680, lr=4.41342e-05, gnorm=0.257, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70381
2023-01-08 18:24:06 - progress_bar.py[line:274] - INFO: epoch 001:  17714 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.465, wps=104.3, ups=0.47, wpb=110.2, bsz=40, num_updates=17690, lr=4.41297e-05, gnorm=0.454, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70402
2023-01-08 18:24:28 - progress_bar.py[line:274] - INFO: epoch 001:  17724 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4413, wps=102.4, ups=0.48, wpb=106.5, bsz=40, num_updates=17700, lr=4.41252e-05, gnorm=0.347, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70423
2023-01-08 18:24:49 - progress_bar.py[line:274] - INFO: epoch 001:  17734 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4179, wps=101.7, ups=0.47, wpb=108.3, bsz=40, num_updates=17710, lr=4.41207e-05, gnorm=0.309, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70445
2023-01-08 18:25:10 - progress_bar.py[line:274] - INFO: epoch 001:  17744 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4041, wps=103.7, ups=0.47, wpb=110.3, bsz=40, num_updates=17720, lr=4.41162e-05, gnorm=0.433, clip=20, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70466
2023-01-08 18:25:32 - progress_bar.py[line:274] - INFO: epoch 001:  17754 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4479, wps=104.2, ups=0.48, wpb=109.4, bsz=40, num_updates=17730, lr=4.41117e-05, gnorm=0.292, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70488
2023-01-08 18:25:54 - progress_bar.py[line:274] - INFO: epoch 001:  17764 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.5, wps=98.6, ups=0.46, wpb=107.4, bsz=40, num_updates=17740, lr=4.41072e-05, gnorm=0.292, clip=0, loss_scale=1024, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=70510
2023-01-08 18:26:16 - progress_bar.py[line:274] - INFO: epoch 001:  17774 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4427, wps=102.4, ups=0.46, wpb=111.3, bsz=40, num_updates=17750, lr=4.41027e-05, gnorm=0.209, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=70532
2023-01-08 18:26:38 - progress_bar.py[line:274] - INFO: epoch 001:  17784 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4769, wps=99.5, ups=0.46, wpb=108.2, bsz=40, num_updates=17760, lr=4.40982e-05, gnorm=0.325, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70554
2023-01-08 18:26:59 - progress_bar.py[line:274] - INFO: epoch 001:  17794 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4631, wps=102.6, ups=0.47, wpb=109.5, bsz=40, num_updates=17770, lr=4.40937e-05, gnorm=0.188, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70575
2023-01-08 18:27:21 - progress_bar.py[line:274] - INFO: epoch 001:  17804 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4365, wps=103.6, ups=0.47, wpb=110.7, bsz=40, num_updates=17780, lr=4.40892e-05, gnorm=0.335, clip=10, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=70597
2023-01-08 18:27:43 - progress_bar.py[line:274] - INFO: epoch 001:  17814 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4049, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=17790, lr=4.40847e-05, gnorm=0.251, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=70618
2023-01-08 18:28:04 - progress_bar.py[line:274] - INFO: epoch 001:  17824 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.404, wps=102.1, ups=0.46, wpb=110, bsz=40, num_updates=17800, lr=4.40802e-05, gnorm=0.181, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70640
2023-01-08 18:28:26 - progress_bar.py[line:274] - INFO: epoch 001:  17834 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4532, wps=102.3, ups=0.47, wpb=108.4, bsz=40, num_updates=17810, lr=4.40757e-05, gnorm=0.333, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70662
2023-01-08 18:28:48 - progress_bar.py[line:274] - INFO: epoch 001:  17844 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.474, wps=100.2, ups=0.46, wpb=109.4, bsz=40, num_updates=17820, lr=4.40712e-05, gnorm=0.29, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70684
2023-01-08 18:29:10 - progress_bar.py[line:274] - INFO: epoch 001:  17854 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4921, wps=101.5, ups=0.46, wpb=110.2, bsz=40, num_updates=17830, lr=4.40667e-05, gnorm=0.231, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=70706
2023-01-08 18:29:32 - progress_bar.py[line:274] - INFO: epoch 001:  17864 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4059, wps=100.4, ups=0.46, wpb=108.6, bsz=40, num_updates=17840, lr=4.40622e-05, gnorm=0.265, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=70728
2023-01-08 18:29:53 - progress_bar.py[line:274] - INFO: epoch 001:  17874 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4734, wps=102.2, ups=0.48, wpb=107.4, bsz=40, num_updates=17850, lr=4.40577e-05, gnorm=0.244, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70749
2023-01-08 18:30:15 - progress_bar.py[line:274] - INFO: epoch 001:  17884 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4505, wps=102.5, ups=0.46, wpb=110.3, bsz=40, num_updates=17860, lr=4.40532e-05, gnorm=0.279, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70771
2023-01-08 18:30:37 - progress_bar.py[line:274] - INFO: epoch 001:  17894 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4737, wps=100.9, ups=0.47, wpb=108.1, bsz=40, num_updates=17870, lr=4.40488e-05, gnorm=0.276, clip=0, loss_scale=1024, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=70792
2023-01-08 18:30:58 - progress_bar.py[line:274] - INFO: epoch 001:  17904 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4474, wps=102.6, ups=0.46, wpb=110.8, bsz=40, num_updates=17880, lr=4.40443e-05, gnorm=0.323, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=70814
2023-01-08 18:31:20 - progress_bar.py[line:274] - INFO: epoch 001:  17914 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3838, wps=101.8, ups=0.47, wpb=108.5, bsz=40, num_updates=17890, lr=4.40398e-05, gnorm=0.678, clip=20, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70836
2023-01-08 18:31:42 - progress_bar.py[line:274] - INFO: epoch 001:  17924 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4619, wps=101, ups=0.46, wpb=109.4, bsz=40, num_updates=17900, lr=4.40353e-05, gnorm=0.216, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=70858
2023-01-08 18:32:04 - progress_bar.py[line:274] - INFO: epoch 001:  17934 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4021, wps=100.5, ups=0.46, wpb=110.2, bsz=40, num_updates=17910, lr=4.40308e-05, gnorm=0.396, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70880
2023-01-08 18:32:26 - progress_bar.py[line:274] - INFO: epoch 001:  17944 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5172, wps=101.2, ups=0.47, wpb=108.8, bsz=40, num_updates=17920, lr=4.40263e-05, gnorm=0.258, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70902
2023-01-08 18:32:48 - progress_bar.py[line:274] - INFO: epoch 001:  17954 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4021, wps=101.7, ups=0.47, wpb=109.3, bsz=40, num_updates=17930, lr=4.40218e-05, gnorm=0.238, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70923
2023-01-08 18:33:10 - progress_bar.py[line:274] - INFO: epoch 001:  17964 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3961, wps=100.3, ups=0.46, wpb=108.9, bsz=40, num_updates=17940, lr=4.40173e-05, gnorm=0.244, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=70945
2023-01-08 18:33:31 - progress_bar.py[line:274] - INFO: epoch 001:  17974 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4385, wps=101, ups=0.46, wpb=110, bsz=40, num_updates=17950, lr=4.40128e-05, gnorm=0.274, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70967
2023-01-08 18:33:53 - progress_bar.py[line:274] - INFO: epoch 001:  17984 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4478, wps=99.9, ups=0.46, wpb=107.6, bsz=40, num_updates=17960, lr=4.40083e-05, gnorm=0.402, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=70989
2023-01-08 18:34:15 - progress_bar.py[line:274] - INFO: epoch 001:  17994 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5165, wps=104.5, ups=0.47, wpb=110.1, bsz=40, num_updates=17970, lr=4.40038e-05, gnorm=0.208, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=71010
2023-01-08 18:34:37 - progress_bar.py[line:274] - INFO: epoch 001:  18004 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4244, wps=99.3, ups=0.46, wpb=108.1, bsz=40, num_updates=17980, lr=4.39993e-05, gnorm=0.266, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=71032
2023-01-08 18:34:58 - progress_bar.py[line:274] - INFO: epoch 001:  18014 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.425, wps=103.9, ups=0.47, wpb=109.6, bsz=40, num_updates=17990, lr=4.39948e-05, gnorm=0.41, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=71054
2023-01-08 18:35:20 - progress_bar.py[line:274] - INFO: epoch 001:  18024 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4198, wps=100.8, ups=0.47, wpb=108.3, bsz=40, num_updates=18000, lr=4.39903e-05, gnorm=0.298, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=71075
2023-01-08 18:35:20 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 18:35:21 - train.py[line:549] - INFO: 0 / 4988
2023-01-08 18:35:21 - train.py[line:551] - INFO: load:1.03 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 18:37:53 - train.py[line:549] - INFO: 200 / 4988
2023-01-08 18:37:53 - train.py[line:551] - INFO: load:1.06 valid_run:152.32 task_valid:148.34 collect_output:2.85
2023-01-08 18:40:22 - train.py[line:549] - INFO: 400 / 4988
2023-01-08 18:40:22 - train.py[line:551] - INFO: load:1.08 valid_run:301.02 task_valid:291.18 collect_output:7.71
2023-01-08 18:42:55 - train.py[line:549] - INFO: 600 / 4988
2023-01-08 18:42:55 - train.py[line:551] - INFO: load:1.11 valid_run:453.74 task_valid:433.80 collect_output:16.80
2023-01-08 18:45:24 - train.py[line:549] - INFO: 800 / 4988
2023-01-08 18:45:24 - train.py[line:551] - INFO: load:1.13 valid_run:603.10 task_valid:578.40 collect_output:20.54
2023-01-08 18:47:57 - train.py[line:549] - INFO: 1000 / 4988
2023-01-08 18:47:57 - train.py[line:551] - INFO: load:1.16 valid_run:755.69 task_valid:725.73 collect_output:24.79
2023-01-08 18:50:29 - train.py[line:549] - INFO: 1200 / 4988
2023-01-08 18:50:29 - train.py[line:551] - INFO: load:1.19 valid_run:907.56 task_valid:871.04 collect_output:30.32
2023-01-08 18:53:03 - train.py[line:549] - INFO: 1400 / 4988
2023-01-08 18:53:03 - train.py[line:551] - INFO: load:1.21 valid_run:1061.27 task_valid:1016.62 collect_output:37.44
2023-01-08 18:55:35 - train.py[line:549] - INFO: 1600 / 4988
2023-01-08 18:55:35 - train.py[line:551] - INFO: load:1.23 valid_run:1212.98 task_valid:1157.33 collect_output:47.44
2023-01-08 18:58:05 - train.py[line:549] - INFO: 1800 / 4988
2023-01-08 18:58:05 - train.py[line:551] - INFO: load:1.26 valid_run:1362.86 task_valid:1301.79 collect_output:51.84
2023-01-08 19:00:33 - train.py[line:549] - INFO: 2000 / 4988
2023-01-08 19:00:33 - train.py[line:551] - INFO: load:1.29 valid_run:1511.55 task_valid:1444.65 collect_output:56.66
2023-01-08 19:03:03 - train.py[line:549] - INFO: 2200 / 4988
2023-01-08 19:03:03 - train.py[line:551] - INFO: load:1.31 valid_run:1661.26 task_valid:1589.11 collect_output:60.88
2023-01-08 19:05:33 - train.py[line:549] - INFO: 2400 / 4988
2023-01-08 19:05:33 - train.py[line:551] - INFO: load:1.34 valid_run:1811.28 task_valid:1733.64 collect_output:65.36
2023-01-08 19:08:04 - train.py[line:549] - INFO: 2600 / 4988
2023-01-08 19:08:04 - train.py[line:551] - INFO: load:1.36 valid_run:1961.65 task_valid:1875.15 collect_output:73.22
2023-01-08 19:10:34 - train.py[line:549] - INFO: 2800 / 4988
2023-01-08 19:10:34 - train.py[line:551] - INFO: load:1.39 valid_run:2112.10 task_valid:2020.32 collect_output:77.46
2023-01-08 19:13:04 - train.py[line:549] - INFO: 3000 / 4988
2023-01-08 19:13:04 - train.py[line:551] - INFO: load:1.41 valid_run:2262.00 task_valid:2166.42 collect_output:80.26
2023-01-08 19:15:34 - train.py[line:549] - INFO: 3200 / 4988
2023-01-08 19:15:34 - train.py[line:551] - INFO: load:1.44 valid_run:2412.29 task_valid:2310.30 collect_output:85.65
2023-01-08 19:18:06 - train.py[line:549] - INFO: 3400 / 4988
2023-01-08 19:18:06 - train.py[line:551] - INFO: load:1.47 valid_run:2564.16 task_valid:2455.54 collect_output:91.28
2023-01-08 19:20:37 - train.py[line:549] - INFO: 3600 / 4988
2023-01-08 19:20:37 - train.py[line:551] - INFO: load:1.49 valid_run:2714.57 task_valid:2602.18 collect_output:94.04
2023-01-08 19:23:06 - train.py[line:549] - INFO: 3800 / 4988
2023-01-08 19:23:06 - train.py[line:551] - INFO: load:1.52 valid_run:2863.30 task_valid:2743.37 collect_output:100.56
2023-01-08 19:25:36 - train.py[line:549] - INFO: 4000 / 4988
2023-01-08 19:25:36 - train.py[line:551] - INFO: load:1.54 valid_run:3014.06 task_valid:2888.08 collect_output:105.58
2023-01-08 19:28:09 - train.py[line:549] - INFO: 4200 / 4988
2023-01-08 19:28:09 - train.py[line:551] - INFO: load:1.57 valid_run:3166.51 task_valid:3032.29 collect_output:112.81
2023-01-08 19:30:39 - train.py[line:549] - INFO: 4400 / 4988
2023-01-08 19:30:39 - train.py[line:551] - INFO: load:1.59 valid_run:3316.12 task_valid:3176.63 collect_output:117.04
2023-01-08 19:33:10 - train.py[line:549] - INFO: 4600 / 4988
2023-01-08 19:33:10 - train.py[line:551] - INFO: load:1.62 valid_run:3467.51 task_valid:3322.57 collect_output:121.48
2023-01-08 19:35:42 - train.py[line:549] - INFO: 4800 / 4988
2023-01-08 19:35:42 - train.py[line:551] - INFO: load:1.65 valid_run:3619.11 task_valid:3468.78 collect_output:125.83

====================================================================================================
SGG eval:     R @ 50: 0.4362;     R @ 100: 0.5046;     R @ 500: 0.5474;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2711;    mR @ 100: 0.3309;    mR @ 500: 0.3657;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6488) (covered in:0.7708) (covering:0.3714) (eating:0.5882) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.7649) (playing:0.0000) (riding:0.5817) (says:0.0000) (sitting on:0.6922) (standing on:0.2433) (using:0.7000) (walking in:0.0000) (walking on:0.1937) (watching:0.2014) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4362;     R @ 100: 0.5046;     R @ 500: 0.5474;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2711;    mR @ 100: 0.3309;    mR @ 500: 0.3657;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6488) (covered in:0.7708) (covering:0.3714) (eating:0.5882) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.7649) (playing:0.0000) (riding:0.5817) (says:0.0000) (sitting on:0.6922) (standing on:0.2433) (using:0.7000) (walking in:0.0000) (walking on:0.1937) (watching:0.2014) 
--------------------------------------------------------
====================================================================================================

2023-01-08 19:38:13 - train.py[line:487] - INFO: 0.5046428571428571
2023-01-08 19:38:13 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 19:38:13 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.373 | loss_v1 0 | loss_v2 0 | nll_loss 0.223 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.504643 | ppl 1.17 | vqa_score 0.4403 | wps 118.9 | wpb 89.9 | bsz 30 | num_updates 18000 | best_R@100 0.645421
2023-01-08 19:38:13 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 18000 updates
2023-01-08 19:38:13 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_18000.pt
2023-01-08 19:38:50 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_18000.pt
2023-01-08 19:40:10 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_18000.pt (epoch 1 @ 18000 updates, score 0.5046428571428571) (writing took 116.84244368970394 seconds)
2023-01-08 19:40:32 - progress_bar.py[line:274] - INFO: epoch 001:  18034 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3939, wps=0.6, ups=0, wpb=109.3, bsz=40, num_updates=18010, lr=4.39858e-05, gnorm=0.39, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=74988
2023-01-08 19:40:54 - progress_bar.py[line:274] - INFO: epoch 001:  18044 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4109, wps=101, ups=0.46, wpb=109.4, bsz=40, num_updates=18020, lr=4.39813e-05, gnorm=0.289, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=75010
2023-01-08 19:41:16 - progress_bar.py[line:274] - INFO: epoch 001:  18054 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4555, wps=103.1, ups=0.47, wpb=109.2, bsz=40, num_updates=18030, lr=4.39768e-05, gnorm=0.319, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75031
2023-01-08 19:41:38 - progress_bar.py[line:274] - INFO: epoch 001:  18064 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4245, wps=98.4, ups=0.46, wpb=107.6, bsz=40, num_updates=18040, lr=4.39723e-05, gnorm=0.239, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75054
2023-01-08 19:41:59 - progress_bar.py[line:274] - INFO: epoch 001:  18074 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4, wps=103.4, ups=0.47, wpb=109.5, bsz=40, num_updates=18050, lr=4.39678e-05, gnorm=0.232, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75075
2023-01-08 19:42:20 - progress_bar.py[line:274] - INFO: epoch 001:  18084 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3941, wps=103.9, ups=0.47, wpb=109.4, bsz=40, num_updates=18060, lr=4.39633e-05, gnorm=0.317, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=75096
2023-01-08 19:42:42 - progress_bar.py[line:274] - INFO: epoch 001:  18094 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4663, wps=101.1, ups=0.46, wpb=109.2, bsz=40, num_updates=18070, lr=4.39588e-05, gnorm=0.301, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75118
2023-01-08 19:43:04 - progress_bar.py[line:274] - INFO: epoch 001:  18104 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4041, wps=103.5, ups=0.47, wpb=109.8, bsz=40, num_updates=18080, lr=4.39543e-05, gnorm=0.297, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=75140
2023-01-08 19:43:26 - progress_bar.py[line:274] - INFO: epoch 001:  18114 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4831, wps=100.1, ups=0.46, wpb=109.2, bsz=40, num_updates=18090, lr=4.39498e-05, gnorm=0.506, clip=20, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=75162
2023-01-08 19:43:47 - progress_bar.py[line:274] - INFO: epoch 001:  18124 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.445, wps=102.6, ups=0.47, wpb=109.5, bsz=40, num_updates=18100, lr=4.39453e-05, gnorm=0.314, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=75183
2023-01-08 19:44:10 - progress_bar.py[line:274] - INFO: epoch 001:  18134 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3812, wps=99, ups=0.45, wpb=108.9, bsz=40, num_updates=18110, lr=4.39409e-05, gnorm=0.32, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=75205
2023-01-08 19:44:31 - progress_bar.py[line:274] - INFO: epoch 001:  18144 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5023, wps=100, ups=0.46, wpb=108, bsz=40, num_updates=18120, lr=4.39364e-05, gnorm=0.347, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=75227
2023-01-08 19:44:53 - progress_bar.py[line:274] - INFO: epoch 001:  18154 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3929, wps=100.1, ups=0.46, wpb=108.6, bsz=40, num_updates=18130, lr=4.39319e-05, gnorm=0.348, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=75249
2023-01-08 19:45:15 - progress_bar.py[line:274] - INFO: epoch 001:  18164 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.432, wps=102.8, ups=0.47, wpb=109, bsz=40, num_updates=18140, lr=4.39274e-05, gnorm=0.282, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75271
2023-01-08 19:45:37 - progress_bar.py[line:274] - INFO: epoch 001:  18174 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4293, wps=103.1, ups=0.46, wpb=111.2, bsz=40, num_updates=18150, lr=4.39229e-05, gnorm=0.287, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75292
2023-01-08 19:45:59 - progress_bar.py[line:274] - INFO: epoch 001:  18184 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4859, wps=102.4, ups=0.46, wpb=111.6, bsz=40, num_updates=18160, lr=4.39184e-05, gnorm=0.41, clip=0, loss_scale=2048, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=75314
2023-01-08 19:46:20 - progress_bar.py[line:274] - INFO: epoch 001:  18194 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4412, wps=101.3, ups=0.46, wpb=109.2, bsz=40, num_updates=18170, lr=4.39139e-05, gnorm=0.389, clip=0, loss_scale=2048, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=75336
2023-01-08 19:46:43 - progress_bar.py[line:274] - INFO: epoch 001:  18204 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5308, wps=98.7, ups=0.46, wpb=107.8, bsz=40, num_updates=18180, lr=4.39094e-05, gnorm=0.297, clip=0, loss_scale=2048, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=75358
2023-01-08 19:47:04 - progress_bar.py[line:274] - INFO: epoch 001:  18214 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4892, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=18190, lr=4.39049e-05, gnorm=0.242, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75380
2023-01-08 19:47:26 - progress_bar.py[line:274] - INFO: epoch 001:  18224 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4218, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=18200, lr=4.39004e-05, gnorm=0.302, clip=0, loss_scale=2048, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=75402
2023-01-08 19:47:48 - progress_bar.py[line:274] - INFO: epoch 001:  18234 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=106.8, nsentences=40, sample_size=106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4933, wps=98.7, ups=0.46, wpb=106.8, bsz=40, num_updates=18210, lr=4.38959e-05, gnorm=0.263, clip=0, loss_scale=2048, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=75424
2023-01-08 19:48:10 - progress_bar.py[line:274] - INFO: epoch 001:  18244 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4444, wps=101.8, ups=0.46, wpb=110, bsz=40, num_updates=18220, lr=4.38914e-05, gnorm=0.277, clip=0, loss_scale=2048, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=75446
2023-01-08 19:48:25 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-08 19:48:31 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 19:48:35 - progress_bar.py[line:274] - INFO: epoch 001:  18256 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3906, wps=95.6, ups=0.4, wpb=109, bsz=40, num_updates=18230, lr=4.38869e-05, gnorm=0.305, clip=10, loss_scale=512, train_wall=25, gb_free=10.1, ema_decay=0.9999, wall=75471
2023-01-08 19:48:57 - progress_bar.py[line:274] - INFO: epoch 001:  18266 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3821, wps=102.2, ups=0.47, wpb=109.2, bsz=40, num_updates=18240, lr=4.38824e-05, gnorm=0.374, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75493
2023-01-08 19:49:19 - progress_bar.py[line:274] - INFO: epoch 001:  18276 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3971, wps=98.7, ups=0.46, wpb=107, bsz=40, num_updates=18250, lr=4.38779e-05, gnorm=0.342, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75515
2023-01-08 19:49:40 - progress_bar.py[line:274] - INFO: epoch 001:  18286 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4615, wps=102.8, ups=0.47, wpb=109.5, bsz=40, num_updates=18260, lr=4.38734e-05, gnorm=0.381, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=75536
2023-01-08 19:50:02 - progress_bar.py[line:274] - INFO: epoch 001:  18296 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4083, wps=100.5, ups=0.46, wpb=109.3, bsz=40, num_updates=18270, lr=4.38689e-05, gnorm=0.24, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=75558
2023-01-08 19:50:23 - progress_bar.py[line:274] - INFO: epoch 001:  18306 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4317, wps=106.2, ups=0.48, wpb=111.3, bsz=40, num_updates=18280, lr=4.38644e-05, gnorm=0.222, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75579
2023-01-08 19:50:45 - progress_bar.py[line:274] - INFO: epoch 001:  18316 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4898, wps=104.7, ups=0.48, wpb=109.9, bsz=40, num_updates=18290, lr=4.38599e-05, gnorm=0.403, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75601
2023-01-08 19:51:07 - progress_bar.py[line:274] - INFO: epoch 001:  18326 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4896, wps=100, ups=0.46, wpb=108.1, bsz=40, num_updates=18300, lr=4.38554e-05, gnorm=0.253, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=75622
2023-01-08 19:51:28 - progress_bar.py[line:274] - INFO: epoch 001:  18336 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4198, wps=101.4, ups=0.47, wpb=108.9, bsz=40, num_updates=18310, lr=4.38509e-05, gnorm=0.29, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75644
2023-01-08 19:51:50 - progress_bar.py[line:274] - INFO: epoch 001:  18346 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4343, wps=101.6, ups=0.46, wpb=109.9, bsz=40, num_updates=18320, lr=4.38464e-05, gnorm=0.537, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75666
2023-01-08 19:52:12 - progress_bar.py[line:274] - INFO: epoch 001:  18356 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.404, wps=100.3, ups=0.46, wpb=108.2, bsz=40, num_updates=18330, lr=4.38419e-05, gnorm=0.311, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=75688
2023-01-08 19:52:34 - progress_bar.py[line:274] - INFO: epoch 001:  18366 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4739, wps=99.8, ups=0.46, wpb=108.8, bsz=40, num_updates=18340, lr=4.38374e-05, gnorm=0.243, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=75710
2023-01-08 19:52:56 - progress_bar.py[line:274] - INFO: epoch 001:  18376 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.415, wps=102, ups=0.47, wpb=108.4, bsz=40, num_updates=18350, lr=4.38329e-05, gnorm=0.263, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=75731
2023-01-08 19:53:17 - progress_bar.py[line:274] - INFO: epoch 001:  18386 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4175, wps=100.5, ups=0.46, wpb=109, bsz=40, num_updates=18360, lr=4.38285e-05, gnorm=0.24, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75753
2023-01-08 19:53:40 - progress_bar.py[line:274] - INFO: epoch 001:  18396 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.441, wps=99.8, ups=0.46, wpb=108.4, bsz=40, num_updates=18370, lr=4.3824e-05, gnorm=0.356, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=75775
2023-01-08 19:54:01 - progress_bar.py[line:274] - INFO: epoch 001:  18406 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5078, wps=101.7, ups=0.47, wpb=108.8, bsz=40, num_updates=18380, lr=4.38195e-05, gnorm=0.259, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75797
2023-01-08 19:54:23 - progress_bar.py[line:274] - INFO: epoch 001:  18416 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4516, wps=101.1, ups=0.46, wpb=109.2, bsz=40, num_updates=18390, lr=4.3815e-05, gnorm=0.309, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75819
2023-01-08 19:54:45 - progress_bar.py[line:274] - INFO: epoch 001:  18426 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.375, wps=102.1, ups=0.47, wpb=109.2, bsz=40, num_updates=18400, lr=4.38105e-05, gnorm=0.382, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=75840
2023-01-08 19:55:06 - progress_bar.py[line:274] - INFO: epoch 001:  18436 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4565, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=18410, lr=4.3806e-05, gnorm=0.294, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=75862
2023-01-08 19:55:28 - progress_bar.py[line:274] - INFO: epoch 001:  18446 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4589, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=18420, lr=4.38015e-05, gnorm=0.296, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=75884
2023-01-08 19:55:50 - progress_bar.py[line:274] - INFO: epoch 001:  18456 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4563, wps=101.5, ups=0.47, wpb=108.2, bsz=40, num_updates=18430, lr=4.3797e-05, gnorm=0.254, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75906
2023-01-08 19:56:11 - progress_bar.py[line:274] - INFO: epoch 001:  18466 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4378, wps=102.4, ups=0.47, wpb=108.8, bsz=40, num_updates=18440, lr=4.37925e-05, gnorm=0.256, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75927
2023-01-08 19:56:33 - progress_bar.py[line:274] - INFO: epoch 001:  18476 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4129, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=18450, lr=4.3788e-05, gnorm=0.209, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75949
2023-01-08 19:56:55 - progress_bar.py[line:274] - INFO: epoch 001:  18486 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4467, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=18460, lr=4.37835e-05, gnorm=0.205, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=75971
2023-01-08 19:57:17 - progress_bar.py[line:274] - INFO: epoch 001:  18496 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.402, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=18470, lr=4.3779e-05, gnorm=0.331, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=75993
2023-01-08 19:57:39 - progress_bar.py[line:274] - INFO: epoch 001:  18506 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4365, wps=101.4, ups=0.46, wpb=109.5, bsz=40, num_updates=18480, lr=4.37745e-05, gnorm=0.259, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=76015
2023-01-08 19:58:01 - progress_bar.py[line:274] - INFO: epoch 001:  18516 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5153, wps=103.4, ups=0.47, wpb=109.9, bsz=40, num_updates=18490, lr=4.377e-05, gnorm=0.534, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=76036
2023-01-08 19:58:23 - progress_bar.py[line:274] - INFO: epoch 001:  18526 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4772, wps=100.8, ups=0.46, wpb=109.6, bsz=40, num_updates=18500, lr=4.37655e-05, gnorm=0.302, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=76058
2023-01-08 19:58:44 - progress_bar.py[line:274] - INFO: epoch 001:  18536 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3901, wps=100.4, ups=0.46, wpb=108.2, bsz=40, num_updates=18510, lr=4.3761e-05, gnorm=0.434, clip=0, loss_scale=512, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=76080
2023-01-08 19:59:06 - progress_bar.py[line:274] - INFO: epoch 001:  18546 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4505, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=18520, lr=4.37565e-05, gnorm=0.347, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=76102
2023-01-08 19:59:28 - progress_bar.py[line:274] - INFO: epoch 001:  18556 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4421, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=18530, lr=4.3752e-05, gnorm=0.337, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76124
2023-01-08 19:59:50 - progress_bar.py[line:274] - INFO: epoch 001:  18566 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3957, wps=101.9, ups=0.47, wpb=109.4, bsz=40, num_updates=18540, lr=4.37475e-05, gnorm=0.33, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=76145
2023-01-08 20:00:12 - progress_bar.py[line:274] - INFO: epoch 001:  18576 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4048, wps=98.9, ups=0.46, wpb=107.8, bsz=40, num_updates=18550, lr=4.3743e-05, gnorm=0.351, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76167
2023-01-08 20:00:33 - progress_bar.py[line:274] - INFO: epoch 001:  18586 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4731, wps=101.7, ups=0.47, wpb=109.2, bsz=40, num_updates=18560, lr=4.37385e-05, gnorm=0.369, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76189
2023-01-08 20:00:55 - progress_bar.py[line:274] - INFO: epoch 001:  18596 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4842, wps=103.1, ups=0.47, wpb=110.2, bsz=40, num_updates=18570, lr=4.3734e-05, gnorm=0.188, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76211
2023-01-08 20:01:17 - progress_bar.py[line:274] - INFO: epoch 001:  18606 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4372, wps=103.7, ups=0.47, wpb=110, bsz=40, num_updates=18580, lr=4.37295e-05, gnorm=0.272, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76232
2023-01-08 20:01:38 - progress_bar.py[line:274] - INFO: epoch 001:  18616 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4211, wps=102.5, ups=0.48, wpb=107.8, bsz=40, num_updates=18590, lr=4.3725e-05, gnorm=0.267, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=76254
2023-01-08 20:01:59 - progress_bar.py[line:274] - INFO: epoch 001:  18626 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4171, wps=102.2, ups=0.47, wpb=107.9, bsz=40, num_updates=18600, lr=4.37206e-05, gnorm=0.357, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76275
2023-01-08 20:02:21 - progress_bar.py[line:274] - INFO: epoch 001:  18636 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4091, wps=101.8, ups=0.46, wpb=110.9, bsz=40, num_updates=18610, lr=4.37161e-05, gnorm=0.225, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=76297
2023-01-08 20:02:43 - progress_bar.py[line:274] - INFO: epoch 001:  18646 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4481, wps=101.4, ups=0.47, wpb=108.1, bsz=40, num_updates=18620, lr=4.37116e-05, gnorm=0.417, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76318
2023-01-08 20:03:04 - progress_bar.py[line:274] - INFO: epoch 001:  18656 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4521, wps=100.3, ups=0.47, wpb=107.2, bsz=40, num_updates=18630, lr=4.37071e-05, gnorm=0.443, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76340
2023-01-08 20:03:26 - progress_bar.py[line:274] - INFO: epoch 001:  18666 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4138, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=18640, lr=4.37026e-05, gnorm=0.364, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76362
2023-01-08 20:03:48 - progress_bar.py[line:274] - INFO: epoch 001:  18676 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4831, wps=100.9, ups=0.47, wpb=107.2, bsz=40, num_updates=18650, lr=4.36981e-05, gnorm=0.298, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=76384
2023-01-08 20:04:10 - progress_bar.py[line:274] - INFO: epoch 001:  18686 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4683, wps=101.9, ups=0.46, wpb=109.6, bsz=40, num_updates=18660, lr=4.36936e-05, gnorm=0.47, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=76405
2023-01-08 20:04:32 - progress_bar.py[line:274] - INFO: epoch 001:  18696 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4466, wps=97.9, ups=0.45, wpb=108.5, bsz=40, num_updates=18670, lr=4.36891e-05, gnorm=0.281, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76428
2023-01-08 20:04:54 - progress_bar.py[line:274] - INFO: epoch 001:  18706 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.42, wps=100.5, ups=0.46, wpb=108.8, bsz=40, num_updates=18680, lr=4.36846e-05, gnorm=0.215, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=76450
2023-01-08 20:05:16 - progress_bar.py[line:274] - INFO: epoch 001:  18716 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4541, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=18690, lr=4.36801e-05, gnorm=0.38, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76472
2023-01-08 20:05:38 - progress_bar.py[line:274] - INFO: epoch 001:  18726 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4314, wps=100.3, ups=0.46, wpb=108, bsz=40, num_updates=18700, lr=4.36756e-05, gnorm=0.307, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76493
2023-01-08 20:05:59 - progress_bar.py[line:274] - INFO: epoch 001:  18736 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4433, wps=102.3, ups=0.46, wpb=110.8, bsz=40, num_updates=18710, lr=4.36711e-05, gnorm=0.256, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76515
2023-01-08 20:06:21 - progress_bar.py[line:274] - INFO: epoch 001:  18746 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4819, wps=103.3, ups=0.47, wpb=110.4, bsz=40, num_updates=18720, lr=4.36666e-05, gnorm=0.249, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76537
2023-01-08 20:06:43 - progress_bar.py[line:274] - INFO: epoch 001:  18756 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4574, wps=103.7, ups=0.46, wpb=111.6, bsz=40, num_updates=18730, lr=4.36621e-05, gnorm=0.206, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76559
2023-01-08 20:07:05 - progress_bar.py[line:274] - INFO: epoch 001:  18766 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4515, wps=101, ups=0.46, wpb=109.3, bsz=40, num_updates=18740, lr=4.36576e-05, gnorm=0.314, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76580
2023-01-08 20:07:26 - progress_bar.py[line:274] - INFO: epoch 001:  18776 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4798, wps=104.3, ups=0.48, wpb=109.1, bsz=40, num_updates=18750, lr=4.36531e-05, gnorm=0.325, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=76602
2023-01-08 20:07:48 - progress_bar.py[line:274] - INFO: epoch 001:  18786 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4811, wps=101.6, ups=0.47, wpb=108.9, bsz=40, num_updates=18760, lr=4.36486e-05, gnorm=0.372, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76623
2023-01-08 20:08:09 - progress_bar.py[line:274] - INFO: epoch 001:  18796 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.445, wps=101.9, ups=0.47, wpb=108.2, bsz=40, num_updates=18770, lr=4.36441e-05, gnorm=0.327, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76645
2023-01-08 20:08:31 - progress_bar.py[line:274] - INFO: epoch 001:  18806 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.433, wps=99.4, ups=0.46, wpb=107.1, bsz=40, num_updates=18780, lr=4.36396e-05, gnorm=0.295, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=76667
2023-01-08 20:08:53 - progress_bar.py[line:274] - INFO: epoch 001:  18816 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.455, wps=101.3, ups=0.46, wpb=109.9, bsz=40, num_updates=18790, lr=4.36351e-05, gnorm=0.376, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=76688
2023-01-08 20:09:14 - progress_bar.py[line:274] - INFO: epoch 001:  18826 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3978, wps=101.8, ups=0.47, wpb=109.3, bsz=40, num_updates=18800, lr=4.36306e-05, gnorm=0.166, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=76710
2023-01-08 20:09:36 - progress_bar.py[line:274] - INFO: epoch 001:  18836 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.456, wps=99.2, ups=0.46, wpb=108, bsz=40, num_updates=18810, lr=4.36261e-05, gnorm=0.483, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76732
2023-01-08 20:09:58 - progress_bar.py[line:274] - INFO: epoch 001:  18846 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4497, wps=100.7, ups=0.46, wpb=109.5, bsz=40, num_updates=18820, lr=4.36216e-05, gnorm=0.276, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=76754
2023-01-08 20:10:20 - progress_bar.py[line:274] - INFO: epoch 001:  18856 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4449, wps=99.5, ups=0.46, wpb=107, bsz=40, num_updates=18830, lr=4.36171e-05, gnorm=0.241, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76776
2023-01-08 20:10:42 - progress_bar.py[line:274] - INFO: epoch 001:  18866 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4674, wps=102.7, ups=0.47, wpb=109.7, bsz=40, num_updates=18840, lr=4.36126e-05, gnorm=0.461, clip=10, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=76798
2023-01-08 20:11:03 - progress_bar.py[line:274] - INFO: epoch 001:  18876 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5291, wps=101.2, ups=0.47, wpb=108.3, bsz=40, num_updates=18850, lr=4.36082e-05, gnorm=0.345, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=76819
2023-01-08 20:11:13 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 20:11:26 - progress_bar.py[line:274] - INFO: epoch 001:  18887 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.524, nsentences=40, sample_size=108.524, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4101, wps=100, ups=0.44, wpb=108.5, bsz=40, num_updates=18860, lr=4.36037e-05, gnorm=0.236, clip=0, loss_scale=512, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=76842
2023-01-08 20:11:48 - progress_bar.py[line:274] - INFO: epoch 001:  18897 / 115845 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5028, wps=104.1, ups=0.47, wpb=111.2, bsz=40, num_updates=18870, lr=4.35992e-05, gnorm=0.454, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=76864
2023-01-08 20:12:10 - progress_bar.py[line:274] - INFO: epoch 001:  18907 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4712, wps=101.7, ups=0.46, wpb=109.6, bsz=40, num_updates=18880, lr=4.35947e-05, gnorm=0.248, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=76886
2023-01-08 20:12:32 - progress_bar.py[line:274] - INFO: epoch 001:  18917 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4747, wps=99.7, ups=0.46, wpb=108.7, bsz=40, num_updates=18890, lr=4.35902e-05, gnorm=0.386, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76908
2023-01-08 20:12:54 - progress_bar.py[line:274] - INFO: epoch 001:  18927 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4455, wps=101.2, ups=0.46, wpb=109.9, bsz=40, num_updates=18900, lr=4.35857e-05, gnorm=0.253, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=76930
2023-01-08 20:13:16 - progress_bar.py[line:274] - INFO: epoch 001:  18937 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4444, wps=101.6, ups=0.47, wpb=108.9, bsz=40, num_updates=18910, lr=4.35812e-05, gnorm=0.253, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=76951
2023-01-08 20:13:37 - progress_bar.py[line:274] - INFO: epoch 001:  18947 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4416, wps=101.9, ups=0.47, wpb=109.2, bsz=40, num_updates=18920, lr=4.35767e-05, gnorm=0.422, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=76973
2023-01-08 20:13:59 - progress_bar.py[line:274] - INFO: epoch 001:  18957 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4573, wps=100.9, ups=0.46, wpb=109.2, bsz=40, num_updates=18930, lr=4.35722e-05, gnorm=0.405, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=76995
2023-01-08 20:14:21 - progress_bar.py[line:274] - INFO: epoch 001:  18967 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4456, wps=101.2, ups=0.46, wpb=109.5, bsz=40, num_updates=18940, lr=4.35677e-05, gnorm=0.215, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77017
2023-01-08 20:14:43 - progress_bar.py[line:274] - INFO: epoch 001:  18977 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4195, wps=100.6, ups=0.46, wpb=109.5, bsz=40, num_updates=18950, lr=4.35632e-05, gnorm=0.325, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=77039
2023-01-08 20:15:05 - progress_bar.py[line:274] - INFO: epoch 001:  18987 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4583, wps=100, ups=0.47, wpb=106.9, bsz=40, num_updates=18960, lr=4.35587e-05, gnorm=0.216, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=77060
2023-01-08 20:15:26 - progress_bar.py[line:274] - INFO: epoch 001:  18997 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5071, wps=105.3, ups=0.48, wpb=109.6, bsz=40, num_updates=18970, lr=4.35542e-05, gnorm=0.449, clip=10, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=77081
2023-01-08 20:15:47 - progress_bar.py[line:274] - INFO: epoch 001:  19007 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.44, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=18980, lr=4.35497e-05, gnorm=0.207, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=77103
2023-01-08 20:16:09 - progress_bar.py[line:274] - INFO: epoch 001:  19017 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4466, wps=99.4, ups=0.46, wpb=108.1, bsz=40, num_updates=18990, lr=4.35452e-05, gnorm=0.242, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77125
2023-01-08 20:16:31 - progress_bar.py[line:274] - INFO: epoch 001:  19027 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4839, wps=100.6, ups=0.46, wpb=108.2, bsz=40, num_updates=19000, lr=4.35407e-05, gnorm=0.473, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77147
2023-01-08 20:16:53 - progress_bar.py[line:274] - INFO: epoch 001:  19037 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5, wps=101.8, ups=0.47, wpb=108.3, bsz=40, num_updates=19010, lr=4.35362e-05, gnorm=0.236, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=77168
2023-01-08 20:17:14 - progress_bar.py[line:274] - INFO: epoch 001:  19047 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.445, wps=104.7, ups=0.48, wpb=109.9, bsz=40, num_updates=19020, lr=4.35317e-05, gnorm=0.397, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=77190
2023-01-08 20:17:35 - progress_bar.py[line:274] - INFO: epoch 001:  19057 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4555, wps=105.4, ups=0.48, wpb=109.5, bsz=40, num_updates=19030, lr=4.35272e-05, gnorm=0.27, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=77211
2023-01-08 20:17:57 - progress_bar.py[line:274] - INFO: epoch 001:  19067 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4656, wps=100.8, ups=0.46, wpb=109.1, bsz=40, num_updates=19040, lr=4.35227e-05, gnorm=0.193, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77233
2023-01-08 20:18:18 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 20:18:20 - progress_bar.py[line:274] - INFO: epoch 001:  19078 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.238, nsentences=40, sample_size=109.238, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5177, wps=97.7, ups=0.43, wpb=109.2, bsz=40, num_updates=19050, lr=4.35182e-05, gnorm=0.263, clip=0, loss_scale=256, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=77256
2023-01-08 20:18:42 - progress_bar.py[line:274] - INFO: epoch 001:  19088 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.487, wps=101.1, ups=0.47, wpb=108.7, bsz=40, num_updates=19060, lr=4.35137e-05, gnorm=0.252, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77278
2023-01-08 20:19:04 - progress_bar.py[line:274] - INFO: epoch 001:  19098 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.7, nsentences=40, sample_size=106.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4753, wps=99.5, ups=0.47, wpb=106.7, bsz=40, num_updates=19070, lr=4.35092e-05, gnorm=0.261, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=77300
2023-01-08 20:19:26 - progress_bar.py[line:274] - INFO: epoch 001:  19108 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4444, wps=102.4, ups=0.46, wpb=110.6, bsz=40, num_updates=19080, lr=4.35047e-05, gnorm=0.293, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=77321
2023-01-08 20:19:48 - progress_bar.py[line:274] - INFO: epoch 001:  19118 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4337, wps=99.4, ups=0.46, wpb=108.1, bsz=40, num_updates=19090, lr=4.35003e-05, gnorm=0.347, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=77343
2023-01-08 20:20:09 - progress_bar.py[line:274] - INFO: epoch 001:  19128 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4271, wps=101.8, ups=0.46, wpb=109.8, bsz=40, num_updates=19100, lr=4.34958e-05, gnorm=0.298, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=77365
2023-01-08 20:20:31 - progress_bar.py[line:274] - INFO: epoch 001:  19138 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4589, wps=102, ups=0.47, wpb=109.4, bsz=40, num_updates=19110, lr=4.34913e-05, gnorm=0.26, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=77387
2023-01-08 20:20:53 - progress_bar.py[line:274] - INFO: epoch 001:  19148 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.455, wps=100.2, ups=0.46, wpb=108.6, bsz=40, num_updates=19120, lr=4.34868e-05, gnorm=0.363, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=77409
2023-01-08 20:21:15 - progress_bar.py[line:274] - INFO: epoch 001:  19158 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4205, wps=101.7, ups=0.46, wpb=109.4, bsz=40, num_updates=19130, lr=4.34823e-05, gnorm=0.31, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=77431
2023-01-08 20:21:37 - progress_bar.py[line:274] - INFO: epoch 001:  19168 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4293, wps=99.2, ups=0.46, wpb=108.2, bsz=40, num_updates=19140, lr=4.34778e-05, gnorm=0.429, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77453
2023-01-08 20:21:59 - progress_bar.py[line:274] - INFO: epoch 001:  19178 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4213, wps=101.7, ups=0.46, wpb=110, bsz=40, num_updates=19150, lr=4.34733e-05, gnorm=0.302, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77475
2023-01-08 20:22:20 - progress_bar.py[line:274] - INFO: epoch 001:  19188 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4663, wps=105.8, ups=0.48, wpb=111.1, bsz=40, num_updates=19160, lr=4.34688e-05, gnorm=0.318, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77496
2023-01-08 20:22:42 - progress_bar.py[line:274] - INFO: epoch 001:  19198 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4596, wps=100, ups=0.46, wpb=107.8, bsz=40, num_updates=19170, lr=4.34643e-05, gnorm=0.299, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=77518
2023-01-08 20:23:04 - progress_bar.py[line:274] - INFO: epoch 001:  19208 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4555, wps=101, ups=0.46, wpb=109.8, bsz=40, num_updates=19180, lr=4.34598e-05, gnorm=0.22, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77539
2023-01-08 20:23:25 - progress_bar.py[line:274] - INFO: epoch 001:  19218 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4663, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=19190, lr=4.34553e-05, gnorm=0.288, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77561
2023-01-08 20:23:47 - progress_bar.py[line:274] - INFO: epoch 001:  19228 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4429, wps=101.2, ups=0.47, wpb=108.4, bsz=40, num_updates=19200, lr=4.34508e-05, gnorm=0.207, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=77583
2023-01-08 20:24:09 - progress_bar.py[line:274] - INFO: epoch 001:  19238 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4619, wps=103.2, ups=0.47, wpb=109.3, bsz=40, num_updates=19210, lr=4.34463e-05, gnorm=0.297, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=77604
2023-01-08 20:24:30 - progress_bar.py[line:274] - INFO: epoch 001:  19248 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4639, wps=102.1, ups=0.46, wpb=110.5, bsz=40, num_updates=19220, lr=4.34418e-05, gnorm=0.385, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77626
2023-01-08 20:24:52 - progress_bar.py[line:274] - INFO: epoch 001:  19258 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.392, wps=102.9, ups=0.47, wpb=109.8, bsz=40, num_updates=19230, lr=4.34373e-05, gnorm=0.365, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=77648
2023-01-08 20:25:14 - progress_bar.py[line:274] - INFO: epoch 001:  19268 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3897, wps=100.5, ups=0.46, wpb=109.5, bsz=40, num_updates=19240, lr=4.34328e-05, gnorm=0.254, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77670
2023-01-08 20:25:36 - progress_bar.py[line:274] - INFO: epoch 001:  19278 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4651, wps=98, ups=0.45, wpb=108, bsz=40, num_updates=19250, lr=4.34283e-05, gnorm=0.3, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=77692
2023-01-08 20:25:58 - progress_bar.py[line:274] - INFO: epoch 001:  19288 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4802, wps=101.3, ups=0.46, wpb=109.1, bsz=40, num_updates=19260, lr=4.34238e-05, gnorm=0.253, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=77714
2023-01-08 20:26:20 - progress_bar.py[line:274] - INFO: epoch 001:  19298 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4898, wps=102.4, ups=0.47, wpb=109.9, bsz=40, num_updates=19270, lr=4.34193e-05, gnorm=0.335, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=77736
2023-01-08 20:26:42 - progress_bar.py[line:274] - INFO: epoch 001:  19308 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4928, wps=100.8, ups=0.46, wpb=109.5, bsz=40, num_updates=19280, lr=4.34148e-05, gnorm=0.244, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=77758
2023-01-08 20:27:04 - progress_bar.py[line:274] - INFO: epoch 001:  19318 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4419, wps=101.5, ups=0.46, wpb=109.8, bsz=40, num_updates=19290, lr=4.34103e-05, gnorm=0.309, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=77780
2023-01-08 20:27:26 - progress_bar.py[line:274] - INFO: epoch 001:  19328 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4364, wps=99.4, ups=0.46, wpb=107.5, bsz=40, num_updates=19300, lr=4.34058e-05, gnorm=0.283, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77802
2023-01-08 20:27:47 - progress_bar.py[line:274] - INFO: epoch 001:  19338 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3894, wps=101.8, ups=0.47, wpb=107.5, bsz=40, num_updates=19310, lr=4.34013e-05, gnorm=0.391, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=77823
2023-01-08 20:28:09 - progress_bar.py[line:274] - INFO: epoch 001:  19348 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4589, wps=99.3, ups=0.46, wpb=108.2, bsz=40, num_updates=19320, lr=4.33968e-05, gnorm=0.187, clip=0, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=77845
2023-01-08 20:28:31 - progress_bar.py[line:274] - INFO: epoch 001:  19358 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5098, wps=99.3, ups=0.46, wpb=107.8, bsz=40, num_updates=19330, lr=4.33923e-05, gnorm=0.252, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=77867
2023-01-08 20:28:53 - progress_bar.py[line:274] - INFO: epoch 001:  19368 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4093, wps=99.9, ups=0.46, wpb=107.6, bsz=40, num_updates=19340, lr=4.33879e-05, gnorm=0.236, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77889
2023-01-08 20:29:15 - progress_bar.py[line:274] - INFO: epoch 001:  19378 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4481, wps=98.7, ups=0.46, wpb=107.6, bsz=40, num_updates=19350, lr=4.33834e-05, gnorm=0.276, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77911
2023-01-08 20:29:37 - progress_bar.py[line:274] - INFO: epoch 001:  19388 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4588, wps=101.2, ups=0.46, wpb=109.4, bsz=40, num_updates=19360, lr=4.33789e-05, gnorm=0.275, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=77933
2023-01-08 20:29:58 - progress_bar.py[line:274] - INFO: epoch 001:  19398 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4559, wps=103.2, ups=0.47, wpb=109.1, bsz=40, num_updates=19370, lr=4.33744e-05, gnorm=0.323, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=77954
2023-01-08 20:30:20 - progress_bar.py[line:274] - INFO: epoch 001:  19408 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5049, wps=99.1, ups=0.46, wpb=107.8, bsz=40, num_updates=19380, lr=4.33699e-05, gnorm=0.159, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=77976
2023-01-08 20:30:42 - progress_bar.py[line:274] - INFO: epoch 001:  19418 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4574, wps=102.4, ups=0.46, wpb=110.7, bsz=40, num_updates=19390, lr=4.33654e-05, gnorm=0.369, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77998
2023-01-08 20:31:04 - progress_bar.py[line:274] - INFO: epoch 001:  19428 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4307, wps=102.9, ups=0.47, wpb=110.1, bsz=40, num_updates=19400, lr=4.33609e-05, gnorm=0.347, clip=0, loss_scale=256, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=78019
2023-01-08 20:31:26 - progress_bar.py[line:274] - INFO: epoch 001:  19438 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4135, wps=99.3, ups=0.46, wpb=108.4, bsz=40, num_updates=19410, lr=4.33564e-05, gnorm=0.179, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=78041
2023-01-08 20:31:47 - progress_bar.py[line:274] - INFO: epoch 001:  19448 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4589, wps=101, ups=0.47, wpb=108.2, bsz=40, num_updates=19420, lr=4.33519e-05, gnorm=0.213, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78063
2023-01-08 20:32:09 - progress_bar.py[line:274] - INFO: epoch 001:  19458 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4076, wps=98.8, ups=0.46, wpb=107.3, bsz=40, num_updates=19430, lr=4.33474e-05, gnorm=0.427, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=78085
2023-01-08 20:32:32 - progress_bar.py[line:274] - INFO: epoch 001:  19468 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4126, wps=98.2, ups=0.45, wpb=108.2, bsz=40, num_updates=19440, lr=4.33429e-05, gnorm=0.443, clip=20, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=78107
2023-01-08 20:32:54 - progress_bar.py[line:274] - INFO: epoch 001:  19478 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4455, wps=99.3, ups=0.46, wpb=108.2, bsz=40, num_updates=19450, lr=4.33384e-05, gnorm=0.363, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=78129
2023-01-08 20:33:15 - progress_bar.py[line:274] - INFO: epoch 001:  19488 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3878, wps=102.1, ups=0.47, wpb=108.9, bsz=40, num_updates=19460, lr=4.33339e-05, gnorm=0.288, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=78151
2023-01-08 20:33:37 - progress_bar.py[line:274] - INFO: epoch 001:  19498 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4115, wps=99.6, ups=0.46, wpb=109.2, bsz=40, num_updates=19470, lr=4.33294e-05, gnorm=0.333, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=78173
2023-01-08 20:33:59 - progress_bar.py[line:274] - INFO: epoch 001:  19508 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4192, wps=101.3, ups=0.46, wpb=109.2, bsz=40, num_updates=19480, lr=4.33249e-05, gnorm=0.323, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=78195
2023-01-08 20:34:21 - progress_bar.py[line:274] - INFO: epoch 001:  19518 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4154, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=19490, lr=4.33204e-05, gnorm=0.286, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=78217
2023-01-08 20:34:42 - progress_bar.py[line:274] - INFO: epoch 001:  19528 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4444, wps=100.8, ups=0.47, wpb=108.4, bsz=40, num_updates=19500, lr=4.33159e-05, gnorm=0.287, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=78238
2023-01-08 20:35:04 - progress_bar.py[line:274] - INFO: epoch 001:  19538 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4185, wps=103, ups=0.47, wpb=110.1, bsz=40, num_updates=19510, lr=4.33114e-05, gnorm=0.242, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=78260
2023-01-08 20:35:26 - progress_bar.py[line:274] - INFO: epoch 001:  19548 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.47, wps=101.9, ups=0.47, wpb=108, bsz=40, num_updates=19520, lr=4.33069e-05, gnorm=0.326, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78281
2023-01-08 20:35:47 - progress_bar.py[line:274] - INFO: epoch 001:  19558 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4974, wps=100.2, ups=0.46, wpb=108.8, bsz=40, num_updates=19530, lr=4.33024e-05, gnorm=0.296, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=78303
2023-01-08 20:36:09 - progress_bar.py[line:274] - INFO: epoch 001:  19568 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4844, wps=103.6, ups=0.47, wpb=110.4, bsz=40, num_updates=19540, lr=4.32979e-05, gnorm=0.219, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=78325
2023-01-08 20:36:31 - progress_bar.py[line:274] - INFO: epoch 001:  19578 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4632, wps=101.5, ups=0.47, wpb=108.4, bsz=40, num_updates=19550, lr=4.32934e-05, gnorm=0.257, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=78346
2023-01-08 20:36:52 - progress_bar.py[line:274] - INFO: epoch 001:  19588 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4011, wps=103.1, ups=0.47, wpb=110.4, bsz=40, num_updates=19560, lr=4.32889e-05, gnorm=0.44, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=78368
2023-01-08 20:37:14 - progress_bar.py[line:274] - INFO: epoch 001:  19598 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4829, wps=102.7, ups=0.47, wpb=109.8, bsz=40, num_updates=19570, lr=4.32844e-05, gnorm=0.328, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=78390
2023-01-08 20:37:36 - progress_bar.py[line:274] - INFO: epoch 001:  19608 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.485, wps=99, ups=0.46, wpb=107.8, bsz=40, num_updates=19580, lr=4.328e-05, gnorm=0.347, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=78412
2023-01-08 20:37:58 - progress_bar.py[line:274] - INFO: epoch 001:  19618 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4472, wps=99.9, ups=0.46, wpb=109.3, bsz=40, num_updates=19590, lr=4.32755e-05, gnorm=0.236, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=78434
2023-01-08 20:38:20 - progress_bar.py[line:274] - INFO: epoch 001:  19628 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4365, wps=101.2, ups=0.46, wpb=110, bsz=40, num_updates=19600, lr=4.3271e-05, gnorm=0.258, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=78456
2023-01-08 20:38:42 - progress_bar.py[line:274] - INFO: epoch 001:  19638 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4341, wps=101.6, ups=0.46, wpb=109.9, bsz=40, num_updates=19610, lr=4.32665e-05, gnorm=0.362, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=78478
2023-01-08 20:39:04 - progress_bar.py[line:274] - INFO: epoch 001:  19648 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4478, wps=101.5, ups=0.47, wpb=108.9, bsz=40, num_updates=19620, lr=4.3262e-05, gnorm=0.179, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=78500
2023-01-08 20:39:26 - progress_bar.py[line:274] - INFO: epoch 001:  19658 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.419, wps=101.4, ups=0.47, wpb=108.8, bsz=40, num_updates=19630, lr=4.32575e-05, gnorm=0.422, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=78521
2023-01-08 20:39:48 - progress_bar.py[line:274] - INFO: epoch 001:  19668 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4677, wps=101.4, ups=0.47, wpb=107.9, bsz=40, num_updates=19640, lr=4.3253e-05, gnorm=0.392, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=78543
2023-01-08 20:40:05 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-08 20:40:11 - progress_bar.py[line:274] - INFO: epoch 001:  19679 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.476, nsentences=40, sample_size=109.476, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5187, wps=99.1, ups=0.43, wpb=109.5, bsz=40, num_updates=19650, lr=4.32485e-05, gnorm=0.239, clip=0, loss_scale=256, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=78567
2023-01-08 20:40:33 - progress_bar.py[line:274] - INFO: epoch 001:  19689 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4316, wps=101.6, ups=0.46, wpb=111.1, bsz=40, num_updates=19660, lr=4.3244e-05, gnorm=0.277, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=78589
2023-01-08 20:40:55 - progress_bar.py[line:274] - INFO: epoch 001:  19699 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4694, wps=104.6, ups=0.48, wpb=109.8, bsz=40, num_updates=19670, lr=4.32395e-05, gnorm=0.244, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=78610
2023-01-08 20:41:16 - progress_bar.py[line:274] - INFO: epoch 001:  19709 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4495, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=19680, lr=4.3235e-05, gnorm=0.203, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78632
2023-01-08 20:41:38 - progress_bar.py[line:274] - INFO: epoch 001:  19719 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.422, wps=102.2, ups=0.47, wpb=109.3, bsz=40, num_updates=19690, lr=4.32305e-05, gnorm=0.243, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=78654
2023-01-08 20:42:00 - progress_bar.py[line:274] - INFO: epoch 001:  19729 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5285, wps=100.5, ups=0.46, wpb=109.2, bsz=40, num_updates=19700, lr=4.3226e-05, gnorm=0.292, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=78676
2023-01-08 20:42:21 - progress_bar.py[line:274] - INFO: epoch 001:  19739 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4346, wps=104.6, ups=0.48, wpb=108.8, bsz=40, num_updates=19710, lr=4.32215e-05, gnorm=0.225, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78697
2023-01-08 20:42:43 - progress_bar.py[line:274] - INFO: epoch 001:  19749 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4343, wps=101.9, ups=0.46, wpb=109.6, bsz=40, num_updates=19720, lr=4.3217e-05, gnorm=0.309, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=78718
2023-01-08 20:43:04 - progress_bar.py[line:274] - INFO: epoch 001:  19759 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3881, wps=104, ups=0.48, wpb=108.7, bsz=40, num_updates=19730, lr=4.32125e-05, gnorm=0.281, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78739
2023-01-08 20:43:25 - progress_bar.py[line:274] - INFO: epoch 001:  19769 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4839, wps=101.9, ups=0.47, wpb=107.8, bsz=40, num_updates=19740, lr=4.3208e-05, gnorm=0.38, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78761
2023-01-08 20:43:47 - progress_bar.py[line:274] - INFO: epoch 001:  19779 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4667, wps=101.3, ups=0.47, wpb=108.3, bsz=40, num_updates=19750, lr=4.32035e-05, gnorm=0.21, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78782
2023-01-08 20:44:09 - progress_bar.py[line:274] - INFO: epoch 001:  19789 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4596, wps=99.7, ups=0.46, wpb=109.5, bsz=40, num_updates=19760, lr=4.3199e-05, gnorm=0.316, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=78805
2023-01-08 20:44:31 - progress_bar.py[line:274] - INFO: epoch 001:  19799 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4292, wps=99.3, ups=0.46, wpb=107.9, bsz=40, num_updates=19770, lr=4.31945e-05, gnorm=0.245, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=78827
2023-01-08 20:44:53 - progress_bar.py[line:274] - INFO: epoch 001:  19809 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4498, wps=100.6, ups=0.47, wpb=108.2, bsz=40, num_updates=19780, lr=4.319e-05, gnorm=0.33, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=78848
2023-01-08 20:45:14 - progress_bar.py[line:274] - INFO: epoch 001:  19819 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4322, wps=102.3, ups=0.47, wpb=107.9, bsz=40, num_updates=19790, lr=4.31855e-05, gnorm=0.244, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=78870
2023-01-08 20:45:36 - progress_bar.py[line:274] - INFO: epoch 001:  19829 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4724, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=19800, lr=4.3181e-05, gnorm=0.307, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78891
2023-01-08 20:45:57 - progress_bar.py[line:274] - INFO: epoch 001:  19839 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3842, wps=102.7, ups=0.47, wpb=110.2, bsz=40, num_updates=19810, lr=4.31765e-05, gnorm=0.245, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=78913
2023-01-08 20:46:19 - progress_bar.py[line:274] - INFO: epoch 001:  19849 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4579, wps=100.8, ups=0.46, wpb=109.7, bsz=40, num_updates=19820, lr=4.3172e-05, gnorm=0.204, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=78935
2023-01-08 20:46:41 - progress_bar.py[line:274] - INFO: epoch 001:  19859 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.447, wps=100.6, ups=0.46, wpb=109.2, bsz=40, num_updates=19830, lr=4.31676e-05, gnorm=0.247, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=78957
2023-01-08 20:47:03 - progress_bar.py[line:274] - INFO: epoch 001:  19869 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3969, wps=100.6, ups=0.46, wpb=108.6, bsz=40, num_updates=19840, lr=4.31631e-05, gnorm=0.183, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=78979
2023-01-08 20:47:25 - progress_bar.py[line:274] - INFO: epoch 001:  19879 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4495, wps=100.7, ups=0.46, wpb=108.4, bsz=40, num_updates=19850, lr=4.31586e-05, gnorm=0.197, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=79001
2023-01-08 20:47:47 - progress_bar.py[line:274] - INFO: epoch 001:  19889 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4417, wps=98.4, ups=0.46, wpb=107.9, bsz=40, num_updates=19860, lr=4.31541e-05, gnorm=0.285, clip=0, loss_scale=256, train_wall=22, gb_free=9.2, ema_decay=0.9999, wall=79023
2023-01-08 20:48:09 - progress_bar.py[line:274] - INFO: epoch 001:  19899 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4545, wps=100.6, ups=0.46, wpb=108.5, bsz=40, num_updates=19870, lr=4.31496e-05, gnorm=0.347, clip=10, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=79044
2023-01-08 20:48:30 - progress_bar.py[line:274] - INFO: epoch 001:  19909 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3744, wps=101.8, ups=0.46, wpb=109.6, bsz=40, num_updates=19880, lr=4.31451e-05, gnorm=0.454, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=79066
2023-01-08 20:48:52 - progress_bar.py[line:274] - INFO: epoch 001:  19919 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5155, wps=101.9, ups=0.47, wpb=109.2, bsz=40, num_updates=19890, lr=4.31406e-05, gnorm=0.351, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=79088
2023-01-08 20:49:14 - progress_bar.py[line:274] - INFO: epoch 001:  19929 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4533, wps=99.4, ups=0.46, wpb=108.1, bsz=40, num_updates=19900, lr=4.31361e-05, gnorm=0.297, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=79110
2023-01-08 20:49:36 - progress_bar.py[line:274] - INFO: epoch 001:  19939 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.46, wps=99.1, ups=0.45, wpb=108.9, bsz=40, num_updates=19910, lr=4.31316e-05, gnorm=0.294, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=79132
2023-01-08 20:49:58 - progress_bar.py[line:274] - INFO: epoch 001:  19949 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4564, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=19920, lr=4.31271e-05, gnorm=0.298, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=79154
2023-01-08 20:50:20 - progress_bar.py[line:274] - INFO: epoch 001:  19959 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4427, wps=101.9, ups=0.46, wpb=109.9, bsz=40, num_updates=19930, lr=4.31226e-05, gnorm=0.375, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=79176
2023-01-08 20:50:42 - progress_bar.py[line:274] - INFO: epoch 001:  19969 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4755, wps=101.6, ups=0.47, wpb=108.3, bsz=40, num_updates=19940, lr=4.31181e-05, gnorm=0.428, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=79197
2023-01-08 20:51:04 - progress_bar.py[line:274] - INFO: epoch 001:  19979 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4387, wps=98.4, ups=0.46, wpb=106.5, bsz=40, num_updates=19950, lr=4.31136e-05, gnorm=0.184, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=79219
2023-01-08 20:51:25 - progress_bar.py[line:274] - INFO: epoch 001:  19989 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4162, wps=102.6, ups=0.46, wpb=110.3, bsz=40, num_updates=19960, lr=4.31091e-05, gnorm=0.245, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=79241
2023-01-08 20:51:48 - progress_bar.py[line:274] - INFO: epoch 001:  19999 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4793, wps=99.1, ups=0.45, wpb=109, bsz=40, num_updates=19970, lr=4.31046e-05, gnorm=0.416, clip=10, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=79263
2023-01-08 20:52:10 - progress_bar.py[line:274] - INFO: epoch 001:  20009 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4258, wps=100.6, ups=0.46, wpb=109.4, bsz=40, num_updates=19980, lr=4.31001e-05, gnorm=0.262, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=79285
2023-01-08 20:52:32 - progress_bar.py[line:274] - INFO: epoch 001:  20019 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4571, wps=99.7, ups=0.46, wpb=109.2, bsz=40, num_updates=19990, lr=4.30956e-05, gnorm=0.372, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=79308
2023-01-08 20:52:54 - progress_bar.py[line:274] - INFO: epoch 001:  20029 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4536, wps=101.5, ups=0.46, wpb=109.8, bsz=40, num_updates=20000, lr=4.30911e-05, gnorm=0.27, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=79329
2023-01-08 20:52:54 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 20:52:55 - train.py[line:549] - INFO: 0 / 4988
2023-01-08 20:52:55 - train.py[line:551] - INFO: load:0.99 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 20:55:27 - train.py[line:549] - INFO: 200 / 4988
2023-01-08 20:55:27 - train.py[line:551] - INFO: load:1.01 valid_run:152.13 task_valid:148.10 collect_output:2.89
2023-01-08 20:57:56 - train.py[line:549] - INFO: 400 / 4988
2023-01-08 20:57:56 - train.py[line:551] - INFO: load:1.04 valid_run:300.92 task_valid:291.06 collect_output:7.70
2023-01-08 21:00:29 - train.py[line:549] - INFO: 600 / 4988
2023-01-08 21:00:29 - train.py[line:551] - INFO: load:1.06 valid_run:453.59 task_valid:433.68 collect_output:16.73
2023-01-08 21:02:58 - train.py[line:549] - INFO: 800 / 4988
2023-01-08 21:02:58 - train.py[line:551] - INFO: load:1.09 valid_run:602.61 task_valid:578.23 collect_output:20.19
2023-01-08 21:05:30 - train.py[line:549] - INFO: 1000 / 4988
2023-01-08 21:05:30 - train.py[line:551] - INFO: load:1.12 valid_run:754.92 task_valid:725.32 collect_output:24.37
2023-01-08 21:08:02 - train.py[line:549] - INFO: 1200 / 4988
2023-01-08 21:08:02 - train.py[line:551] - INFO: load:1.15 valid_run:906.84 task_valid:870.59 collect_output:30.01
2023-01-08 21:10:36 - train.py[line:549] - INFO: 1400 / 4988
2023-01-08 21:10:36 - train.py[line:551] - INFO: load:1.17 valid_run:1060.48 task_valid:1016.17 collect_output:37.05
2023-01-08 21:13:07 - train.py[line:549] - INFO: 1600 / 4988
2023-01-08 21:13:07 - train.py[line:551] - INFO: load:1.20 valid_run:1211.93 task_valid:1156.80 collect_output:46.87
2023-01-08 21:15:37 - train.py[line:549] - INFO: 1800 / 4988
2023-01-08 21:15:37 - train.py[line:551] - INFO: load:1.22 valid_run:1361.45 task_valid:1301.10 collect_output:51.07
2023-01-08 21:18:06 - train.py[line:549] - INFO: 2000 / 4988
2023-01-08 21:18:06 - train.py[line:551] - INFO: load:1.25 valid_run:1510.09 task_valid:1444.00 collect_output:55.78
2023-01-08 21:20:36 - train.py[line:549] - INFO: 2200 / 4988
2023-01-08 21:20:36 - train.py[line:551] - INFO: load:1.28 valid_run:1659.86 task_valid:1588.45 collect_output:60.10
2023-01-08 21:23:06 - train.py[line:549] - INFO: 2400 / 4988
2023-01-08 21:23:06 - train.py[line:551] - INFO: load:1.31 valid_run:1809.74 task_valid:1733.02 collect_output:64.40
2023-01-08 21:25:36 - train.py[line:549] - INFO: 2600 / 4988
2023-01-08 21:25:36 - train.py[line:551] - INFO: load:1.33 valid_run:1959.71 task_valid:1874.53 collect_output:71.84
2023-01-08 21:28:06 - train.py[line:549] - INFO: 2800 / 4988
2023-01-08 21:28:06 - train.py[line:551] - INFO: load:1.36 valid_run:2110.27 task_valid:2019.86 collect_output:76.06
2023-01-08 21:30:36 - train.py[line:549] - INFO: 3000 / 4988
2023-01-08 21:30:36 - train.py[line:551] - INFO: load:1.39 valid_run:2260.15 task_valid:2165.89 collect_output:78.89
2023-01-08 21:33:06 - train.py[line:549] - INFO: 3200 / 4988
2023-01-08 21:33:06 - train.py[line:551] - INFO: load:1.41 valid_run:2410.08 task_valid:2309.80 collect_output:83.88
2023-01-08 21:35:38 - train.py[line:549] - INFO: 3400 / 4988
2023-01-08 21:35:38 - train.py[line:551] - INFO: load:1.44 valid_run:2561.65 task_valid:2454.91 collect_output:89.32
2023-01-08 21:38:08 - train.py[line:549] - INFO: 3600 / 4988
2023-01-08 21:38:08 - train.py[line:551] - INFO: load:1.47 valid_run:2712.17 task_valid:2601.69 collect_output:92.05
2023-01-08 21:40:37 - train.py[line:549] - INFO: 3800 / 4988
2023-01-08 21:40:37 - train.py[line:551] - INFO: load:1.50 valid_run:2860.96 task_valid:2743.05 collect_output:98.43
2023-01-08 21:43:08 - train.py[line:549] - INFO: 4000 / 4988
2023-01-08 21:43:08 - train.py[line:551] - INFO: load:1.52 valid_run:3011.35 task_valid:2887.96 collect_output:102.89
2023-01-08 21:45:40 - train.py[line:549] - INFO: 4200 / 4988
2023-01-08 21:45:40 - train.py[line:551] - INFO: load:1.55 valid_run:3163.47 task_valid:3032.32 collect_output:109.61
2023-01-08 21:48:09 - train.py[line:549] - INFO: 4400 / 4988
2023-01-08 21:48:09 - train.py[line:551] - INFO: load:1.58 valid_run:3312.96 task_valid:3176.54 collect_output:113.84
2023-01-08 21:50:41 - train.py[line:549] - INFO: 4600 / 4988
2023-01-08 21:50:41 - train.py[line:551] - INFO: load:1.61 valid_run:3464.32 task_valid:3322.34 collect_output:118.39
2023-01-08 21:53:12 - train.py[line:549] - INFO: 4800 / 4988
2023-01-08 21:53:12 - train.py[line:551] - INFO: load:1.64 valid_run:3615.66 task_valid:3468.54 collect_output:122.51

====================================================================================================
SGG eval:     R @ 50: 0.4126;     R @ 100: 0.4790;     R @ 500: 0.5144;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2487;    mR @ 100: 0.3020;    mR @ 500: 0.3306;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4951) (covered in:0.5208) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.7917) (playing:0.0000) (riding:0.4935) (says:0.0000) (sitting on:0.7075) (standing on:0.2233) (using:0.7000) (walking in:0.0000) (walking on:0.2162) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4126;     R @ 100: 0.4790;     R @ 500: 0.5144;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2487;    mR @ 100: 0.3020;    mR @ 500: 0.3306;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4951) (covered in:0.5208) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.7917) (playing:0.0000) (riding:0.4935) (says:0.0000) (sitting on:0.7075) (standing on:0.2233) (using:0.7000) (walking in:0.0000) (walking on:0.2162) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-08 21:55:43 - train.py[line:487] - INFO: 0.4790285714285714
2023-01-08 21:55:43 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-08 21:55:44 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.363 | loss_v1 0 | loss_v2 0 | nll_loss 0.208 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.479029 | ppl 1.16 | vqa_score 0.4099 | wps 119 | wpb 89.9 | bsz 30 | num_updates 20000 | best_R@100 0.645421
2023-01-08 21:55:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 20000 updates
2023-01-08 21:55:44 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_20000.pt
2023-01-08 21:56:24 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_20000.pt
2023-01-08 21:57:47 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_20000.pt (epoch 1 @ 20000 updates, score 0.4790285714285714) (writing took 122.61241529881954 seconds)
2023-01-08 21:58:09 - progress_bar.py[line:274] - INFO: epoch 001:  20039 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4677, wps=0.6, ups=0, wpb=109, bsz=40, num_updates=20010, lr=4.30866e-05, gnorm=0.28, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=83244
2023-01-08 21:58:30 - progress_bar.py[line:274] - INFO: epoch 001:  20049 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4123, wps=103.5, ups=0.48, wpb=108, bsz=40, num_updates=20020, lr=4.30821e-05, gnorm=0.229, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=83266
2023-01-08 21:58:52 - progress_bar.py[line:274] - INFO: epoch 001:  20059 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4059, wps=104, ups=0.47, wpb=109.6, bsz=40, num_updates=20030, lr=4.30776e-05, gnorm=0.257, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=83287
2023-01-08 21:59:14 - progress_bar.py[line:274] - INFO: epoch 001:  20069 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.399, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=20040, lr=4.30731e-05, gnorm=0.193, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=83309
2023-01-08 21:59:36 - progress_bar.py[line:274] - INFO: epoch 001:  20079 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4064, wps=101, ups=0.46, wpb=109, bsz=40, num_updates=20050, lr=4.30686e-05, gnorm=0.418, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83332
2023-01-08 21:59:58 - progress_bar.py[line:274] - INFO: epoch 001:  20089 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4483, wps=102.2, ups=0.47, wpb=109.3, bsz=40, num_updates=20060, lr=4.30641e-05, gnorm=0.359, clip=10, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=83354
2023-01-08 22:00:21 - progress_bar.py[line:274] - INFO: epoch 001:  20099 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4466, wps=99.8, ups=0.46, wpb=108.6, bsz=40, num_updates=20070, lr=4.30597e-05, gnorm=0.267, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83376
2023-01-08 22:00:43 - progress_bar.py[line:274] - INFO: epoch 001:  20109 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4425, wps=102.3, ups=0.46, wpb=111, bsz=40, num_updates=20080, lr=4.30552e-05, gnorm=0.18, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=83398
2023-01-08 22:01:05 - progress_bar.py[line:274] - INFO: epoch 001:  20119 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4426, wps=103.5, ups=0.47, wpb=110.3, bsz=40, num_updates=20090, lr=4.30507e-05, gnorm=0.228, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=83420
2023-01-08 22:01:27 - progress_bar.py[line:274] - INFO: epoch 001:  20129 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4115, wps=102.9, ups=0.47, wpb=108.7, bsz=40, num_updates=20100, lr=4.30462e-05, gnorm=0.28, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=83442
2023-01-08 22:01:49 - progress_bar.py[line:274] - INFO: epoch 001:  20139 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4286, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=20110, lr=4.30417e-05, gnorm=0.301, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=83464
2023-01-08 22:02:11 - progress_bar.py[line:274] - INFO: epoch 001:  20149 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4249, wps=101.7, ups=0.46, wpb=109.8, bsz=40, num_updates=20120, lr=4.30372e-05, gnorm=0.252, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=83486
2023-01-08 22:02:33 - progress_bar.py[line:274] - INFO: epoch 001:  20159 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4059, wps=99.6, ups=0.46, wpb=108.5, bsz=40, num_updates=20130, lr=4.30327e-05, gnorm=0.346, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=83509
2023-01-08 22:02:56 - progress_bar.py[line:274] - INFO: epoch 001:  20169 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4635, wps=100.3, ups=0.46, wpb=109.1, bsz=40, num_updates=20140, lr=4.30282e-05, gnorm=0.31, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=83531
2023-01-08 22:03:18 - progress_bar.py[line:274] - INFO: epoch 001:  20179 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4663, wps=100.4, ups=0.46, wpb=108.7, bsz=40, num_updates=20150, lr=4.30237e-05, gnorm=0.214, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83554
2023-01-08 22:03:40 - progress_bar.py[line:274] - INFO: epoch 001:  20189 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4043, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=20160, lr=4.30192e-05, gnorm=0.355, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=83576
2023-01-08 22:04:02 - progress_bar.py[line:274] - INFO: epoch 001:  20199 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4343, wps=103.5, ups=0.47, wpb=109.1, bsz=40, num_updates=20170, lr=4.30147e-05, gnorm=0.209, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=83598
2023-01-08 22:04:25 - progress_bar.py[line:274] - INFO: epoch 001:  20209 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4762, wps=102.2, ups=0.46, wpb=110.5, bsz=40, num_updates=20180, lr=4.30102e-05, gnorm=0.341, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83620
2023-01-08 22:04:47 - progress_bar.py[line:274] - INFO: epoch 001:  20219 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4388, wps=100.8, ups=0.46, wpb=109.1, bsz=40, num_updates=20190, lr=4.30057e-05, gnorm=0.311, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=83642
2023-01-08 22:05:09 - progress_bar.py[line:274] - INFO: epoch 001:  20229 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4286, wps=101.3, ups=0.47, wpb=108, bsz=40, num_updates=20200, lr=4.30012e-05, gnorm=0.254, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=83664
2023-01-08 22:05:31 - progress_bar.py[line:274] - INFO: epoch 001:  20239 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4175, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=20210, lr=4.29967e-05, gnorm=0.336, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=83687
2023-01-08 22:05:53 - progress_bar.py[line:274] - INFO: epoch 001:  20249 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3713, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=20220, lr=4.29922e-05, gnorm=0.389, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=83709
2023-01-08 22:06:16 - progress_bar.py[line:274] - INFO: epoch 001:  20259 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5579, wps=99.8, ups=0.45, wpb=109.8, bsz=40, num_updates=20230, lr=4.29877e-05, gnorm=0.259, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=83731
2023-01-08 22:06:38 - progress_bar.py[line:274] - INFO: epoch 001:  20269 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4637, wps=101.5, ups=0.46, wpb=110.5, bsz=40, num_updates=20240, lr=4.29832e-05, gnorm=0.379, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=83754
2023-01-08 22:07:01 - progress_bar.py[line:274] - INFO: epoch 001:  20279 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.414, wps=101.3, ups=0.46, wpb=110.5, bsz=40, num_updates=20250, lr=4.29787e-05, gnorm=0.354, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=83776
2023-01-08 22:07:23 - progress_bar.py[line:274] - INFO: epoch 001:  20289 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4354, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=20260, lr=4.29742e-05, gnorm=0.309, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=83798
2023-01-08 22:07:45 - progress_bar.py[line:274] - INFO: epoch 001:  20299 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4388, wps=101.1, ups=0.46, wpb=109.5, bsz=40, num_updates=20270, lr=4.29697e-05, gnorm=0.219, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83821
2023-01-08 22:08:08 - progress_bar.py[line:274] - INFO: epoch 001:  20309 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4406, wps=98.8, ups=0.45, wpb=108.8, bsz=40, num_updates=20280, lr=4.29652e-05, gnorm=0.212, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=83843
2023-01-08 22:08:29 - progress_bar.py[line:274] - INFO: epoch 001:  20319 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4619, wps=106.3, ups=0.49, wpb=109.6, bsz=40, num_updates=20290, lr=4.29607e-05, gnorm=0.177, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=83865
2023-01-08 22:08:51 - progress_bar.py[line:274] - INFO: epoch 001:  20329 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4495, wps=102.1, ups=0.47, wpb=109.2, bsz=40, num_updates=20300, lr=4.29562e-05, gnorm=0.24, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=83887
2023-01-08 22:09:14 - progress_bar.py[line:274] - INFO: epoch 001:  20339 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4657, wps=99.4, ups=0.45, wpb=109.3, bsz=40, num_updates=20310, lr=4.29517e-05, gnorm=0.304, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83909
2023-01-08 22:09:36 - progress_bar.py[line:274] - INFO: epoch 001:  20349 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4523, wps=102.9, ups=0.48, wpb=107.4, bsz=40, num_updates=20320, lr=4.29473e-05, gnorm=0.366, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=83931
2023-01-08 22:09:58 - progress_bar.py[line:274] - INFO: epoch 001:  20359 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4372, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=20330, lr=4.29428e-05, gnorm=0.287, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83953
2023-01-08 22:10:21 - progress_bar.py[line:274] - INFO: epoch 001:  20369 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.446, wps=98.6, ups=0.46, wpb=108.3, bsz=40, num_updates=20340, lr=4.29383e-05, gnorm=0.244, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=83976
2023-01-08 22:10:44 - progress_bar.py[line:274] - INFO: epoch 001:  20379 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4608, wps=101, ups=0.46, wpb=110.4, bsz=40, num_updates=20350, lr=4.29338e-05, gnorm=0.381, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83999
2023-01-08 22:11:06 - progress_bar.py[line:274] - INFO: epoch 001:  20389 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4462, wps=102.1, ups=0.47, wpb=109.1, bsz=40, num_updates=20360, lr=4.29293e-05, gnorm=0.224, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=84021
2023-01-08 22:11:28 - progress_bar.py[line:274] - INFO: epoch 001:  20399 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4776, wps=99.5, ups=0.46, wpb=108.7, bsz=40, num_updates=20370, lr=4.29248e-05, gnorm=0.293, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=84044
2023-01-08 22:11:50 - progress_bar.py[line:274] - INFO: epoch 001:  20409 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4734, wps=102.4, ups=0.47, wpb=108.5, bsz=40, num_updates=20380, lr=4.29203e-05, gnorm=0.219, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84066
2023-01-08 22:12:12 - progress_bar.py[line:274] - INFO: epoch 001:  20419 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4261, wps=102.3, ups=0.46, wpb=110.3, bsz=40, num_updates=20390, lr=4.29158e-05, gnorm=0.184, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=84088
2023-01-08 22:12:35 - progress_bar.py[line:274] - INFO: epoch 001:  20429 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.468, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=20400, lr=4.29113e-05, gnorm=0.174, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=84110
2023-01-08 22:12:56 - progress_bar.py[line:274] - INFO: epoch 001:  20439 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4815, wps=103, ups=0.47, wpb=109, bsz=40, num_updates=20410, lr=4.29068e-05, gnorm=0.372, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84132
2023-01-08 22:13:18 - progress_bar.py[line:274] - INFO: epoch 001:  20449 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4219, wps=103.5, ups=0.47, wpb=110.2, bsz=40, num_updates=20420, lr=4.29023e-05, gnorm=0.311, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=84154
2023-01-08 22:13:40 - progress_bar.py[line:274] - INFO: epoch 001:  20459 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4734, wps=104.2, ups=0.47, wpb=110.5, bsz=40, num_updates=20430, lr=4.28978e-05, gnorm=0.153, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84176
2023-01-08 22:14:02 - progress_bar.py[line:274] - INFO: epoch 001:  20469 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4299, wps=100.9, ups=0.47, wpb=108.1, bsz=40, num_updates=20440, lr=4.28933e-05, gnorm=0.265, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=84198
2023-01-08 22:14:25 - progress_bar.py[line:274] - INFO: epoch 001:  20479 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4145, wps=101.6, ups=0.46, wpb=109.9, bsz=40, num_updates=20450, lr=4.28888e-05, gnorm=0.246, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=84220
2023-01-08 22:14:46 - progress_bar.py[line:274] - INFO: epoch 001:  20489 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4637, wps=105.1, ups=0.47, wpb=111.6, bsz=40, num_updates=20460, lr=4.28843e-05, gnorm=0.298, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=84242
2023-01-08 22:15:08 - progress_bar.py[line:274] - INFO: epoch 001:  20499 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4309, wps=103, ups=0.47, wpb=109.7, bsz=40, num_updates=20470, lr=4.28798e-05, gnorm=0.302, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=84264
2023-01-08 22:15:30 - progress_bar.py[line:274] - INFO: epoch 001:  20509 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4422, wps=101.5, ups=0.47, wpb=108.5, bsz=40, num_updates=20480, lr=4.28753e-05, gnorm=0.361, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=84286
2023-01-08 22:15:53 - progress_bar.py[line:274] - INFO: epoch 001:  20519 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5072, wps=100.8, ups=0.46, wpb=108.9, bsz=40, num_updates=20490, lr=4.28708e-05, gnorm=0.23, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=84308
2023-01-08 22:16:15 - progress_bar.py[line:274] - INFO: epoch 001:  20529 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.402, wps=101.4, ups=0.46, wpb=109.6, bsz=40, num_updates=20500, lr=4.28663e-05, gnorm=0.275, clip=0, loss_scale=512, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=84330
2023-01-08 22:16:37 - progress_bar.py[line:274] - INFO: epoch 001:  20539 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4314, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=20510, lr=4.28618e-05, gnorm=0.251, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=84353
2023-01-08 22:16:59 - progress_bar.py[line:274] - INFO: epoch 001:  20549 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4031, wps=102.6, ups=0.47, wpb=109.1, bsz=40, num_updates=20520, lr=4.28573e-05, gnorm=0.449, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=84374
2023-01-08 22:17:21 - progress_bar.py[line:274] - INFO: epoch 001:  20559 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5026, wps=102.8, ups=0.47, wpb=110.1, bsz=40, num_updates=20530, lr=4.28528e-05, gnorm=0.296, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=84396
2023-01-08 22:17:43 - progress_bar.py[line:274] - INFO: epoch 001:  20569 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4872, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=20540, lr=4.28483e-05, gnorm=0.276, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=84419
2023-01-08 22:18:06 - progress_bar.py[line:274] - INFO: epoch 001:  20579 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4581, wps=100.8, ups=0.46, wpb=108.4, bsz=40, num_updates=20550, lr=4.28438e-05, gnorm=0.332, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84441
2023-01-08 22:18:27 - progress_bar.py[line:274] - INFO: epoch 001:  20589 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4106, wps=102.6, ups=0.47, wpb=109.1, bsz=40, num_updates=20560, lr=4.28394e-05, gnorm=0.476, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84463
2023-01-08 22:18:49 - progress_bar.py[line:274] - INFO: epoch 001:  20599 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4059, wps=102.2, ups=0.47, wpb=109.4, bsz=40, num_updates=20570, lr=4.28349e-05, gnorm=0.244, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84484
2023-01-08 22:19:10 - progress_bar.py[line:274] - INFO: epoch 001:  20609 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4387, wps=101.6, ups=0.47, wpb=108.8, bsz=40, num_updates=20580, lr=4.28304e-05, gnorm=0.29, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=84506
2023-01-08 22:19:32 - progress_bar.py[line:274] - INFO: epoch 001:  20619 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=106, nsentences=40, sample_size=106, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4537, wps=98, ups=0.46, wpb=106, bsz=40, num_updates=20590, lr=4.28259e-05, gnorm=0.373, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=84528
2023-01-08 22:19:54 - progress_bar.py[line:274] - INFO: epoch 001:  20629 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4316, wps=99.6, ups=0.46, wpb=108.8, bsz=40, num_updates=20600, lr=4.28214e-05, gnorm=0.411, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=84550
2023-01-08 22:20:16 - progress_bar.py[line:274] - INFO: epoch 001:  20639 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4216, wps=101.9, ups=0.46, wpb=110, bsz=40, num_updates=20610, lr=4.28169e-05, gnorm=0.194, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=84572
2023-01-08 22:20:38 - progress_bar.py[line:274] - INFO: epoch 001:  20649 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4162, wps=102.4, ups=0.47, wpb=109.6, bsz=40, num_updates=20620, lr=4.28124e-05, gnorm=0.197, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=84594
2023-01-08 22:21:00 - progress_bar.py[line:274] - INFO: epoch 001:  20659 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5126, wps=100.9, ups=0.46, wpb=110.1, bsz=40, num_updates=20630, lr=4.28079e-05, gnorm=0.255, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=84616
2023-01-08 22:21:22 - progress_bar.py[line:274] - INFO: epoch 001:  20669 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5261, wps=101.7, ups=0.46, wpb=109.9, bsz=40, num_updates=20640, lr=4.28034e-05, gnorm=0.238, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=84638
2023-01-08 22:21:43 - progress_bar.py[line:274] - INFO: epoch 001:  20679 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4388, wps=101.7, ups=0.46, wpb=109.6, bsz=40, num_updates=20650, lr=4.27989e-05, gnorm=0.215, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=84659
2023-01-08 22:22:05 - progress_bar.py[line:274] - INFO: epoch 001:  20689 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4792, wps=101.3, ups=0.46, wpb=109.8, bsz=40, num_updates=20660, lr=4.27944e-05, gnorm=0.314, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=84681
2023-01-08 22:22:28 - progress_bar.py[line:274] - INFO: epoch 001:  20699 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4381, wps=99, ups=0.46, wpb=108, bsz=40, num_updates=20670, lr=4.27899e-05, gnorm=0.345, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=84703
2023-01-08 22:22:49 - progress_bar.py[line:274] - INFO: epoch 001:  20709 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4239, wps=101.7, ups=0.46, wpb=110.1, bsz=40, num_updates=20680, lr=4.27854e-05, gnorm=0.26, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=84725
2023-01-08 22:23:11 - progress_bar.py[line:274] - INFO: epoch 001:  20719 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4315, wps=101.5, ups=0.47, wpb=108.3, bsz=40, num_updates=20690, lr=4.27809e-05, gnorm=0.173, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=84747
2023-01-08 22:23:34 - progress_bar.py[line:274] - INFO: epoch 001:  20729 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5333, wps=99.1, ups=0.45, wpb=109.1, bsz=40, num_updates=20700, lr=4.27764e-05, gnorm=0.399, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=84769
2023-01-08 22:23:55 - progress_bar.py[line:274] - INFO: epoch 001:  20739 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.466, wps=104.3, ups=0.47, wpb=110.1, bsz=40, num_updates=20710, lr=4.27719e-05, gnorm=0.227, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=84791
2023-01-08 22:24:16 - progress_bar.py[line:274] - INFO: epoch 001:  20749 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3763, wps=101.4, ups=0.47, wpb=108.2, bsz=40, num_updates=20720, lr=4.27674e-05, gnorm=0.273, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84812
2023-01-08 22:24:38 - progress_bar.py[line:274] - INFO: epoch 001:  20759 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.432, wps=102.2, ups=0.47, wpb=108.4, bsz=40, num_updates=20730, lr=4.27629e-05, gnorm=0.523, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=84834
2023-01-08 22:25:00 - progress_bar.py[line:274] - INFO: epoch 001:  20769 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.446, wps=101.4, ups=0.47, wpb=108.8, bsz=40, num_updates=20740, lr=4.27584e-05, gnorm=0.174, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84855
2023-01-08 22:25:22 - progress_bar.py[line:274] - INFO: epoch 001:  20779 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4163, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=20750, lr=4.27539e-05, gnorm=0.315, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=84877
2023-01-08 22:25:44 - progress_bar.py[line:274] - INFO: epoch 001:  20789 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5455, wps=99.6, ups=0.45, wpb=109.7, bsz=40, num_updates=20760, lr=4.27494e-05, gnorm=0.249, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=84900
2023-01-08 22:26:06 - progress_bar.py[line:274] - INFO: epoch 001:  20799 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.365, wps=101.3, ups=0.46, wpb=109.1, bsz=40, num_updates=20770, lr=4.27449e-05, gnorm=0.29, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=84922
2023-01-08 22:26:28 - progress_bar.py[line:274] - INFO: epoch 001:  20809 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4251, wps=98.8, ups=0.46, wpb=107.7, bsz=40, num_updates=20780, lr=4.27404e-05, gnorm=0.417, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=84944
2023-01-08 22:26:51 - progress_bar.py[line:274] - INFO: epoch 001:  20819 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4402, wps=99.4, ups=0.46, wpb=108.6, bsz=40, num_updates=20790, lr=4.27359e-05, gnorm=0.214, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=84966
2023-01-08 22:27:13 - progress_bar.py[line:274] - INFO: epoch 001:  20829 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.485, wps=100.5, ups=0.46, wpb=108.7, bsz=40, num_updates=20800, lr=4.27314e-05, gnorm=0.238, clip=0, loss_scale=1024, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=84988
2023-01-08 22:27:35 - progress_bar.py[line:274] - INFO: epoch 001:  20839 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4734, wps=97.6, ups=0.46, wpb=107.2, bsz=40, num_updates=20810, lr=4.2727e-05, gnorm=0.262, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=85011
2023-01-08 22:27:57 - progress_bar.py[line:274] - INFO: epoch 001:  20849 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4335, wps=101, ups=0.47, wpb=108.6, bsz=40, num_updates=20820, lr=4.27225e-05, gnorm=0.362, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=85033
2023-01-08 22:28:19 - progress_bar.py[line:274] - INFO: epoch 001:  20859 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4901, wps=101, ups=0.46, wpb=110, bsz=40, num_updates=20830, lr=4.2718e-05, gnorm=0.4, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=85055
2023-01-08 22:28:41 - progress_bar.py[line:274] - INFO: epoch 001:  20869 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5025, wps=102.6, ups=0.47, wpb=110, bsz=40, num_updates=20840, lr=4.27135e-05, gnorm=0.257, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=85077
2023-01-08 22:29:04 - progress_bar.py[line:274] - INFO: epoch 001:  20879 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5049, wps=99.6, ups=0.46, wpb=108.6, bsz=40, num_updates=20850, lr=4.2709e-05, gnorm=0.344, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=85099
2023-01-08 22:29:26 - progress_bar.py[line:274] - INFO: epoch 001:  20889 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4256, wps=101.9, ups=0.47, wpb=108.9, bsz=40, num_updates=20860, lr=4.27045e-05, gnorm=0.25, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=85121
2023-01-08 22:29:48 - progress_bar.py[line:274] - INFO: epoch 001:  20899 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4341, wps=100.9, ups=0.46, wpb=110, bsz=40, num_updates=20870, lr=4.27e-05, gnorm=0.22, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=85143
2023-01-08 22:30:10 - progress_bar.py[line:274] - INFO: epoch 001:  20909 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4359, wps=101.8, ups=0.47, wpb=109.1, bsz=40, num_updates=20880, lr=4.26955e-05, gnorm=0.384, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85165
2023-01-08 22:30:32 - progress_bar.py[line:274] - INFO: epoch 001:  20919 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=100, ups=0.46, wpb=109, bsz=40, num_updates=20890, lr=4.2691e-05, gnorm=0.199, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=85188
2023-01-08 22:30:54 - progress_bar.py[line:274] - INFO: epoch 001:  20929 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.413, wps=101.9, ups=0.47, wpb=109.3, bsz=40, num_updates=20900, lr=4.26865e-05, gnorm=0.29, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85210
2023-01-08 22:31:16 - progress_bar.py[line:274] - INFO: epoch 001:  20939 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4428, wps=99.8, ups=0.46, wpb=108.7, bsz=40, num_updates=20910, lr=4.2682e-05, gnorm=0.317, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=85232
2023-01-08 22:31:38 - progress_bar.py[line:274] - INFO: epoch 001:  20949 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4076, wps=100.7, ups=0.47, wpb=106.9, bsz=40, num_updates=20920, lr=4.26775e-05, gnorm=0.225, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=85254
2023-01-08 22:32:00 - progress_bar.py[line:274] - INFO: epoch 001:  20959 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.401, wps=101.6, ups=0.46, wpb=109.7, bsz=40, num_updates=20930, lr=4.2673e-05, gnorm=0.247, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=85276
2023-01-08 22:32:22 - progress_bar.py[line:274] - INFO: epoch 001:  20969 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4278, wps=101.7, ups=0.47, wpb=108.6, bsz=40, num_updates=20940, lr=4.26685e-05, gnorm=0.174, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=85297
2023-01-08 22:32:44 - progress_bar.py[line:274] - INFO: epoch 001:  20979 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4925, wps=102.5, ups=0.47, wpb=109.8, bsz=40, num_updates=20950, lr=4.2664e-05, gnorm=0.262, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=85319
2023-01-08 22:33:06 - progress_bar.py[line:274] - INFO: epoch 001:  20989 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4608, wps=101.1, ups=0.47, wpb=108.4, bsz=40, num_updates=20960, lr=4.26595e-05, gnorm=0.251, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=85341
2023-01-08 22:33:27 - progress_bar.py[line:274] - INFO: epoch 001:  20999 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4307, wps=101.3, ups=0.47, wpb=108.9, bsz=40, num_updates=20970, lr=4.2655e-05, gnorm=0.195, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85363
2023-01-08 22:33:49 - progress_bar.py[line:274] - INFO: epoch 001:  21009 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4483, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=20980, lr=4.26505e-05, gnorm=0.404, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=85385
2023-01-08 22:34:11 - progress_bar.py[line:274] - INFO: epoch 001:  21019 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4398, wps=102.5, ups=0.47, wpb=109.1, bsz=40, num_updates=20990, lr=4.2646e-05, gnorm=0.437, clip=10, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=85407
2023-01-08 22:34:34 - progress_bar.py[line:274] - INFO: epoch 001:  21029 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4604, wps=99, ups=0.45, wpb=108.9, bsz=40, num_updates=21000, lr=4.26415e-05, gnorm=0.244, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=85429
2023-01-08 22:34:56 - progress_bar.py[line:274] - INFO: epoch 001:  21039 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4588, wps=100, ups=0.46, wpb=108.8, bsz=40, num_updates=21010, lr=4.2637e-05, gnorm=0.262, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=85452
2023-01-08 22:35:18 - progress_bar.py[line:274] - INFO: epoch 001:  21049 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4646, wps=101.3, ups=0.46, wpb=109.6, bsz=40, num_updates=21020, lr=4.26325e-05, gnorm=0.418, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=85474
2023-01-08 22:35:40 - progress_bar.py[line:274] - INFO: epoch 001:  21059 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.401, wps=100.4, ups=0.46, wpb=108.5, bsz=40, num_updates=21030, lr=4.2628e-05, gnorm=0.256, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=85496
2023-01-08 22:36:03 - progress_bar.py[line:274] - INFO: epoch 001:  21069 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4439, wps=99.4, ups=0.46, wpb=108.5, bsz=40, num_updates=21040, lr=4.26235e-05, gnorm=0.218, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=85518
2023-01-08 22:36:24 - progress_bar.py[line:274] - INFO: epoch 001:  21079 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4465, wps=101.6, ups=0.47, wpb=108.4, bsz=40, num_updates=21050, lr=4.26191e-05, gnorm=0.394, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=85540
2023-01-08 22:36:47 - progress_bar.py[line:274] - INFO: epoch 001:  21089 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4783, wps=100.6, ups=0.46, wpb=109.8, bsz=40, num_updates=21060, lr=4.26146e-05, gnorm=0.241, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=85562
2023-01-08 22:37:08 - progress_bar.py[line:274] - INFO: epoch 001:  21099 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4856, wps=102.9, ups=0.48, wpb=106.9, bsz=40, num_updates=21070, lr=4.26101e-05, gnorm=0.255, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85583
2023-01-08 22:37:30 - progress_bar.py[line:274] - INFO: epoch 001:  21109 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4251, wps=101.2, ups=0.46, wpb=109.2, bsz=40, num_updates=21080, lr=4.26056e-05, gnorm=0.437, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=85605
2023-01-08 22:37:52 - progress_bar.py[line:274] - INFO: epoch 001:  21119 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4834, wps=100.5, ups=0.46, wpb=108.7, bsz=40, num_updates=21090, lr=4.26011e-05, gnorm=0.343, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=85628
2023-01-08 22:38:14 - progress_bar.py[line:274] - INFO: epoch 001:  21129 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4472, wps=99.5, ups=0.46, wpb=107.7, bsz=40, num_updates=21100, lr=4.25966e-05, gnorm=0.326, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=85650
2023-01-08 22:38:36 - progress_bar.py[line:274] - INFO: epoch 001:  21139 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4757, wps=100.5, ups=0.46, wpb=108.5, bsz=40, num_updates=21110, lr=4.25921e-05, gnorm=0.21, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=85672
2023-01-08 22:38:59 - progress_bar.py[line:274] - INFO: epoch 001:  21149 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4484, wps=98.7, ups=0.45, wpb=108.5, bsz=40, num_updates=21120, lr=4.25876e-05, gnorm=0.362, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=85694
2023-01-08 22:39:21 - progress_bar.py[line:274] - INFO: epoch 001:  21159 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4375, wps=101.6, ups=0.46, wpb=109.8, bsz=40, num_updates=21130, lr=4.25831e-05, gnorm=0.269, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=85716
2023-01-08 22:39:43 - progress_bar.py[line:274] - INFO: epoch 001:  21169 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4714, wps=99.5, ups=0.46, wpb=109, bsz=40, num_updates=21140, lr=4.25786e-05, gnorm=0.168, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=85739
2023-01-08 22:40:05 - progress_bar.py[line:274] - INFO: epoch 001:  21179 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4563, wps=103.4, ups=0.48, wpb=108.5, bsz=40, num_updates=21150, lr=4.25741e-05, gnorm=0.325, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=85760
2023-01-08 22:40:27 - progress_bar.py[line:274] - INFO: epoch 001:  21189 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4684, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=21160, lr=4.25696e-05, gnorm=0.197, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=85782
2023-01-08 22:40:49 - progress_bar.py[line:274] - INFO: epoch 001:  21199 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4093, wps=99.4, ups=0.46, wpb=109.1, bsz=40, num_updates=21170, lr=4.25651e-05, gnorm=0.234, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=85805
2023-01-08 22:41:11 - progress_bar.py[line:274] - INFO: epoch 001:  21209 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4712, wps=101.9, ups=0.47, wpb=108.9, bsz=40, num_updates=21180, lr=4.25606e-05, gnorm=0.457, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85827
2023-01-08 22:41:33 - progress_bar.py[line:274] - INFO: epoch 001:  21219 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5423, wps=102.9, ups=0.47, wpb=108.8, bsz=40, num_updates=21190, lr=4.25561e-05, gnorm=0.279, clip=10, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=85848
2023-01-08 22:41:55 - progress_bar.py[line:274] - INFO: epoch 001:  21229 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4461, wps=101.5, ups=0.47, wpb=108.8, bsz=40, num_updates=21200, lr=4.25516e-05, gnorm=0.24, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=85870
2023-01-08 22:42:01 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-08 22:42:19 - progress_bar.py[line:274] - INFO: epoch 001:  21240 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.238, nsentences=40, sample_size=110.238, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5047, wps=98.2, ups=0.42, wpb=110.2, bsz=40, num_updates=21210, lr=4.25471e-05, gnorm=0.24, clip=0, loss_scale=1024, train_wall=24, gb_free=10.4, ema_decay=0.9999, wall=85894
2023-01-08 22:42:41 - progress_bar.py[line:274] - INFO: epoch 001:  21250 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4495, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=21220, lr=4.25426e-05, gnorm=0.307, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=85916
2023-01-08 22:43:03 - progress_bar.py[line:274] - INFO: epoch 001:  21260 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4197, wps=102.3, ups=0.47, wpb=109.3, bsz=40, num_updates=21230, lr=4.25381e-05, gnorm=0.311, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=85938
2023-01-08 22:43:24 - progress_bar.py[line:274] - INFO: epoch 001:  21270 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4372, wps=102.9, ups=0.47, wpb=109.8, bsz=40, num_updates=21240, lr=4.25336e-05, gnorm=0.203, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=85960
2023-01-08 22:43:46 - progress_bar.py[line:274] - INFO: epoch 001:  21280 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4928, wps=101.2, ups=0.46, wpb=109.6, bsz=40, num_updates=21250, lr=4.25291e-05, gnorm=0.208, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=85982
2023-01-08 22:44:08 - progress_bar.py[line:274] - INFO: epoch 001:  21290 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4623, wps=103.1, ups=0.47, wpb=109.9, bsz=40, num_updates=21260, lr=4.25246e-05, gnorm=0.22, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86004
2023-01-08 22:44:31 - progress_bar.py[line:274] - INFO: epoch 001:  21300 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4428, wps=97.6, ups=0.45, wpb=107.5, bsz=40, num_updates=21270, lr=4.25201e-05, gnorm=0.379, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=86026
2023-01-08 22:44:52 - progress_bar.py[line:274] - INFO: epoch 001:  21310 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3858, wps=103.8, ups=0.47, wpb=110.5, bsz=40, num_updates=21280, lr=4.25156e-05, gnorm=0.208, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86048
2023-01-08 22:45:15 - progress_bar.py[line:274] - INFO: epoch 001:  21320 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4229, wps=100.4, ups=0.46, wpb=109.9, bsz=40, num_updates=21290, lr=4.25111e-05, gnorm=0.154, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86070
2023-01-08 22:45:36 - progress_bar.py[line:274] - INFO: epoch 001:  21330 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4951, wps=102.8, ups=0.47, wpb=108.5, bsz=40, num_updates=21300, lr=4.25067e-05, gnorm=0.273, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86092
2023-01-08 22:45:59 - progress_bar.py[line:274] - INFO: epoch 001:  21340 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.456, wps=100.4, ups=0.46, wpb=108.8, bsz=40, num_updates=21310, lr=4.25022e-05, gnorm=0.41, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=86114
2023-01-08 22:46:21 - progress_bar.py[line:274] - INFO: epoch 001:  21350 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5, wps=99.9, ups=0.45, wpb=109.9, bsz=40, num_updates=21320, lr=4.24977e-05, gnorm=0.381, clip=10, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=86137
2023-01-08 22:46:43 - progress_bar.py[line:274] - INFO: epoch 001:  21360 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4729, wps=102.7, ups=0.47, wpb=108.5, bsz=40, num_updates=21330, lr=4.24932e-05, gnorm=0.19, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=86158
2023-01-08 22:47:04 - progress_bar.py[line:274] - INFO: epoch 001:  21370 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4205, wps=101.3, ups=0.47, wpb=107.9, bsz=40, num_updates=21340, lr=4.24887e-05, gnorm=0.28, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=86180
2023-01-08 22:47:26 - progress_bar.py[line:274] - INFO: epoch 001:  21380 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4817, wps=102.9, ups=0.47, wpb=110.5, bsz=40, num_updates=21350, lr=4.24842e-05, gnorm=0.34, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86202
2023-01-08 22:47:48 - progress_bar.py[line:274] - INFO: epoch 001:  21390 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3981, wps=100.2, ups=0.46, wpb=108.4, bsz=40, num_updates=21360, lr=4.24797e-05, gnorm=0.282, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=86224
2023-01-08 22:48:10 - progress_bar.py[line:274] - INFO: epoch 001:  21400 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4925, wps=103.3, ups=0.47, wpb=109.3, bsz=40, num_updates=21370, lr=4.24752e-05, gnorm=0.288, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=86246
2023-01-08 22:48:32 - progress_bar.py[line:274] - INFO: epoch 001:  21410 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4541, wps=102, ups=0.47, wpb=108.7, bsz=40, num_updates=21380, lr=4.24707e-05, gnorm=0.239, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86268
2023-01-08 22:48:54 - progress_bar.py[line:274] - INFO: epoch 001:  21420 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4685, wps=100.3, ups=0.47, wpb=107.6, bsz=40, num_updates=21390, lr=4.24662e-05, gnorm=0.3, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=86289
2023-01-08 22:49:16 - progress_bar.py[line:274] - INFO: epoch 001:  21430 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4829, wps=102.4, ups=0.46, wpb=110.5, bsz=40, num_updates=21400, lr=4.24617e-05, gnorm=0.205, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=86311
2023-01-08 22:49:37 - progress_bar.py[line:274] - INFO: epoch 001:  21440 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4861, wps=101.1, ups=0.47, wpb=108.1, bsz=40, num_updates=21410, lr=4.24572e-05, gnorm=0.219, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86333
2023-01-08 22:50:00 - progress_bar.py[line:274] - INFO: epoch 001:  21450 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4789, wps=99, ups=0.45, wpb=109.7, bsz=40, num_updates=21420, lr=4.24527e-05, gnorm=0.207, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86356
2023-01-08 22:50:22 - progress_bar.py[line:274] - INFO: epoch 001:  21460 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4455, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=21430, lr=4.24482e-05, gnorm=0.353, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=86377
2023-01-08 22:50:43 - progress_bar.py[line:274] - INFO: epoch 001:  21470 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4798, wps=103.7, ups=0.47, wpb=109.9, bsz=40, num_updates=21440, lr=4.24437e-05, gnorm=0.158, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=86399
2023-01-08 22:51:05 - progress_bar.py[line:274] - INFO: epoch 001:  21480 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4824, wps=101.5, ups=0.46, wpb=109.2, bsz=40, num_updates=21450, lr=4.24392e-05, gnorm=0.274, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86421
2023-01-08 22:51:27 - progress_bar.py[line:274] - INFO: epoch 001:  21490 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4398, wps=103.8, ups=0.48, wpb=109.1, bsz=40, num_updates=21460, lr=4.24347e-05, gnorm=0.345, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86442
2023-01-08 22:51:48 - progress_bar.py[line:274] - INFO: epoch 001:  21500 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.446, wps=100, ups=0.47, wpb=107.1, bsz=40, num_updates=21470, lr=4.24302e-05, gnorm=0.312, clip=0, loss_scale=1024, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=86464
2023-01-08 22:52:10 - progress_bar.py[line:274] - INFO: epoch 001:  21510 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.466, wps=101.9, ups=0.46, wpb=110.3, bsz=40, num_updates=21480, lr=4.24257e-05, gnorm=0.372, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86486
2023-01-08 22:52:32 - progress_bar.py[line:274] - INFO: epoch 001:  21520 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4123, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=21490, lr=4.24212e-05, gnorm=0.319, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=86508
2023-01-08 22:52:54 - progress_bar.py[line:274] - INFO: epoch 001:  21530 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4577, wps=104, ups=0.47, wpb=109.9, bsz=40, num_updates=21500, lr=4.24167e-05, gnorm=0.256, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86530
2023-01-08 22:53:16 - progress_bar.py[line:274] - INFO: epoch 001:  21540 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4467, wps=100, ups=0.46, wpb=108.3, bsz=40, num_updates=21510, lr=4.24122e-05, gnorm=0.137, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=86552
2023-01-08 22:53:38 - progress_bar.py[line:274] - INFO: epoch 001:  21550 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4714, wps=100.4, ups=0.46, wpb=108.3, bsz=40, num_updates=21520, lr=4.24077e-05, gnorm=0.344, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86574
2023-01-08 22:53:59 - progress_bar.py[line:274] - INFO: epoch 001:  21560 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4947, wps=107.3, ups=0.48, wpb=110.7, bsz=40, num_updates=21530, lr=4.24032e-05, gnorm=0.215, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=86595
2023-01-08 22:54:21 - progress_bar.py[line:274] - INFO: epoch 001:  21570 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4416, wps=101.9, ups=0.47, wpb=108.8, bsz=40, num_updates=21540, lr=4.23988e-05, gnorm=0.213, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=86616
2023-01-08 22:54:42 - progress_bar.py[line:274] - INFO: epoch 001:  21580 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4813, wps=101.8, ups=0.47, wpb=108.5, bsz=40, num_updates=21550, lr=4.23943e-05, gnorm=0.207, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86638
2023-01-08 22:55:04 - progress_bar.py[line:274] - INFO: epoch 001:  21590 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4444, wps=100.7, ups=0.46, wpb=109, bsz=40, num_updates=21560, lr=4.23898e-05, gnorm=0.181, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=86660
2023-01-08 22:55:26 - progress_bar.py[line:274] - INFO: epoch 001:  21600 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4921, wps=104.2, ups=0.47, wpb=110.1, bsz=40, num_updates=21570, lr=4.23853e-05, gnorm=0.268, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=86681
2023-01-08 22:55:47 - progress_bar.py[line:274] - INFO: epoch 001:  21610 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4526, wps=103.6, ups=0.47, wpb=110.1, bsz=40, num_updates=21580, lr=4.23808e-05, gnorm=0.324, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86703
2023-01-08 22:56:10 - progress_bar.py[line:274] - INFO: epoch 001:  21620 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4676, wps=97.3, ups=0.45, wpb=107.3, bsz=40, num_updates=21590, lr=4.23763e-05, gnorm=0.249, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=86725
2023-01-08 22:56:31 - progress_bar.py[line:274] - INFO: epoch 001:  21630 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4563, wps=101.6, ups=0.47, wpb=108.8, bsz=40, num_updates=21600, lr=4.23718e-05, gnorm=0.196, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=86747
2023-01-08 22:56:53 - progress_bar.py[line:274] - INFO: epoch 001:  21640 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4455, wps=101.1, ups=0.47, wpb=108, bsz=40, num_updates=21610, lr=4.23673e-05, gnorm=0.256, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86769
2023-01-08 22:57:15 - progress_bar.py[line:274] - INFO: epoch 001:  21650 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4588, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=21620, lr=4.23628e-05, gnorm=0.168, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86791
2023-01-08 22:57:37 - progress_bar.py[line:274] - INFO: epoch 001:  21660 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4536, wps=99.7, ups=0.46, wpb=108.7, bsz=40, num_updates=21630, lr=4.23583e-05, gnorm=0.299, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=86813
2023-01-08 22:57:59 - progress_bar.py[line:274] - INFO: epoch 001:  21670 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.41, wps=100.1, ups=0.46, wpb=107.8, bsz=40, num_updates=21640, lr=4.23538e-05, gnorm=0.257, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=86834
2023-01-08 22:58:21 - progress_bar.py[line:274] - INFO: epoch 001:  21680 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4413, wps=99.5, ups=0.46, wpb=108.4, bsz=40, num_updates=21650, lr=4.23493e-05, gnorm=0.165, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86857
2023-01-08 22:58:43 - progress_bar.py[line:274] - INFO: epoch 001:  21690 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4233, wps=101.8, ups=0.46, wpb=110.1, bsz=40, num_updates=21660, lr=4.23448e-05, gnorm=0.212, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86879
2023-01-08 22:59:05 - progress_bar.py[line:274] - INFO: epoch 001:  21700 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4227, wps=101.9, ups=0.46, wpb=110, bsz=40, num_updates=21670, lr=4.23403e-05, gnorm=0.278, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86900
2023-01-08 22:59:27 - progress_bar.py[line:274] - INFO: epoch 001:  21710 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4523, wps=98, ups=0.45, wpb=108, bsz=40, num_updates=21680, lr=4.23358e-05, gnorm=0.343, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86923
2023-01-08 22:59:48 - progress_bar.py[line:274] - INFO: epoch 001:  21720 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5123, wps=103.8, ups=0.47, wpb=109.4, bsz=40, num_updates=21690, lr=4.23313e-05, gnorm=0.249, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86944
2023-01-08 23:00:10 - progress_bar.py[line:274] - INFO: epoch 001:  21730 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.46, wps=101.2, ups=0.46, wpb=109.9, bsz=40, num_updates=21700, lr=4.23268e-05, gnorm=0.192, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=86966
2023-01-08 23:00:32 - progress_bar.py[line:274] - INFO: epoch 001:  21740 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4906, wps=101.1, ups=0.47, wpb=108.7, bsz=40, num_updates=21710, lr=4.23223e-05, gnorm=0.222, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=86988
2023-01-08 23:00:54 - progress_bar.py[line:274] - INFO: epoch 001:  21750 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4478, wps=99.8, ups=0.46, wpb=108.5, bsz=40, num_updates=21720, lr=4.23178e-05, gnorm=0.353, clip=0, loss_scale=2048, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=87010
2023-01-08 23:01:15 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-08 23:01:18 - progress_bar.py[line:274] - INFO: epoch 001:  21761 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.619, nsentences=40, sample_size=109.619, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.47, wps=97.4, ups=0.42, wpb=109.6, bsz=40, num_updates=21730, lr=4.23133e-05, gnorm=0.394, clip=10, loss_scale=1024, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=87034
2023-01-08 23:01:39 - progress_bar.py[line:274] - INFO: epoch 001:  21771 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4755, wps=102.3, ups=0.47, wpb=109.2, bsz=40, num_updates=21740, lr=4.23088e-05, gnorm=0.347, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=87055
2023-01-08 23:02:01 - progress_bar.py[line:274] - INFO: epoch 001:  21781 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4433, wps=102.3, ups=0.47, wpb=108.3, bsz=40, num_updates=21750, lr=4.23043e-05, gnorm=0.311, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=87077
2023-01-08 23:02:23 - progress_bar.py[line:274] - INFO: epoch 001:  21791 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4392, wps=101.5, ups=0.46, wpb=109.6, bsz=40, num_updates=21760, lr=4.22998e-05, gnorm=0.265, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=87098
2023-01-08 23:02:44 - progress_bar.py[line:274] - INFO: epoch 001:  21801 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4563, wps=99.9, ups=0.46, wpb=108.5, bsz=40, num_updates=21770, lr=4.22953e-05, gnorm=0.289, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=87120
2023-01-08 23:03:06 - progress_bar.py[line:274] - INFO: epoch 001:  21811 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4503, wps=103.4, ups=0.47, wpb=110.5, bsz=40, num_updates=21780, lr=4.22908e-05, gnorm=0.274, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=87142
2023-01-08 23:03:28 - progress_bar.py[line:274] - INFO: epoch 001:  21821 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4205, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=21790, lr=4.22864e-05, gnorm=0.168, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=87163
2023-01-08 23:03:49 - progress_bar.py[line:274] - INFO: epoch 001:  21831 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=102.6, ups=0.47, wpb=109.7, bsz=40, num_updates=21800, lr=4.22819e-05, gnorm=0.246, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=87185
2023-01-08 23:04:11 - progress_bar.py[line:274] - INFO: epoch 001:  21841 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4335, wps=102.5, ups=0.47, wpb=109.5, bsz=40, num_updates=21810, lr=4.22774e-05, gnorm=0.378, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=87207
2023-01-08 23:04:33 - progress_bar.py[line:274] - INFO: epoch 001:  21851 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4187, wps=99.1, ups=0.46, wpb=108.6, bsz=40, num_updates=21820, lr=4.22729e-05, gnorm=0.226, clip=0, loss_scale=1024, train_wall=22, gb_free=9.6, ema_decay=0.9999, wall=87229
2023-01-08 23:04:55 - progress_bar.py[line:274] - INFO: epoch 001:  21861 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4115, wps=101.4, ups=0.46, wpb=109.5, bsz=40, num_updates=21830, lr=4.22684e-05, gnorm=0.241, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=87251
2023-01-08 23:05:16 - progress_bar.py[line:274] - INFO: epoch 001:  21871 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4709, wps=102, ups=0.47, wpb=108.4, bsz=40, num_updates=21840, lr=4.22639e-05, gnorm=0.218, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=87272
2023-01-08 23:05:21 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-08 23:05:40 - progress_bar.py[line:274] - INFO: epoch 001:  21882 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.81, nsentences=40, sample_size=108.81, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4093, wps=98.2, ups=0.43, wpb=108.8, bsz=40, num_updates=21850, lr=4.22594e-05, gnorm=0.313, clip=10, loss_scale=512, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=87296
2023-01-08 23:06:01 - progress_bar.py[line:274] - INFO: epoch 001:  21892 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4316, wps=103.9, ups=0.47, wpb=109.5, bsz=40, num_updates=21860, lr=4.22549e-05, gnorm=0.23, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=87317
2023-01-08 23:06:23 - progress_bar.py[line:274] - INFO: epoch 001:  21902 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4523, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=21870, lr=4.22504e-05, gnorm=0.199, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=87339
2023-01-08 23:06:45 - progress_bar.py[line:274] - INFO: epoch 001:  21912 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4842, wps=101.6, ups=0.46, wpb=109.7, bsz=40, num_updates=21880, lr=4.22459e-05, gnorm=0.184, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=87361
2023-01-08 23:07:07 - progress_bar.py[line:274] - INFO: epoch 001:  21922 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4667, wps=101.1, ups=0.46, wpb=109.4, bsz=40, num_updates=21890, lr=4.22414e-05, gnorm=0.283, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=87383
2023-01-08 23:07:28 - progress_bar.py[line:274] - INFO: epoch 001:  21932 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4732, wps=105.1, ups=0.48, wpb=110.2, bsz=40, num_updates=21900, lr=4.22369e-05, gnorm=0.23, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=87404
2023-01-08 23:07:49 - progress_bar.py[line:274] - INFO: epoch 001:  21942 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4368, wps=103.1, ups=0.47, wpb=109.4, bsz=40, num_updates=21910, lr=4.22324e-05, gnorm=0.233, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=87425
2023-01-08 23:08:11 - progress_bar.py[line:274] - INFO: epoch 001:  21952 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4396, wps=104.1, ups=0.48, wpb=109, bsz=40, num_updates=21920, lr=4.22279e-05, gnorm=0.203, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=87446
2023-01-08 23:08:32 - progress_bar.py[line:274] - INFO: epoch 001:  21962 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4608, wps=100.3, ups=0.46, wpb=108.2, bsz=40, num_updates=21930, lr=4.22234e-05, gnorm=0.224, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=87468
2023-01-08 23:08:54 - progress_bar.py[line:274] - INFO: epoch 001:  21972 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.399, wps=99.9, ups=0.46, wpb=109.3, bsz=40, num_updates=21940, lr=4.22189e-05, gnorm=0.278, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=87490
2023-01-08 23:09:16 - progress_bar.py[line:274] - INFO: epoch 001:  21982 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.478, wps=102.1, ups=0.47, wpb=109.3, bsz=40, num_updates=21950, lr=4.22144e-05, gnorm=0.309, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=87512
2023-01-08 23:09:38 - progress_bar.py[line:274] - INFO: epoch 001:  21992 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4845, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=21960, lr=4.22099e-05, gnorm=0.29, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=87534
2023-01-08 23:10:00 - progress_bar.py[line:274] - INFO: epoch 001:  22002 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4899, wps=102.4, ups=0.47, wpb=109.1, bsz=40, num_updates=21970, lr=4.22054e-05, gnorm=0.325, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=87555
2023-01-08 23:10:22 - progress_bar.py[line:274] - INFO: epoch 001:  22012 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4619, wps=99.2, ups=0.46, wpb=108.1, bsz=40, num_updates=21980, lr=4.22009e-05, gnorm=0.3, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=87577
2023-01-08 23:10:44 - progress_bar.py[line:274] - INFO: epoch 001:  22022 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4356, wps=99.8, ups=0.45, wpb=109.8, bsz=40, num_updates=21990, lr=4.21964e-05, gnorm=0.457, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=87600
2023-01-08 23:11:05 - progress_bar.py[line:274] - INFO: epoch 001:  22032 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4192, wps=103.5, ups=0.48, wpb=108.8, bsz=40, num_updates=22000, lr=4.21919e-05, gnorm=0.279, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=87621
2023-01-08 23:11:05 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-08 23:11:07 - train.py[line:549] - INFO: 0 / 4988
2023-01-08 23:11:07 - train.py[line:551] - INFO: load:1.23 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-08 23:13:38 - train.py[line:549] - INFO: 200 / 4988
2023-01-08 23:13:38 - train.py[line:551] - INFO: load:1.25 valid_run:151.69 task_valid:147.91 collect_output:2.72
2023-01-08 23:16:08 - train.py[line:549] - INFO: 400 / 4988
2023-01-08 23:16:08 - train.py[line:551] - INFO: load:1.28 valid_run:300.92 task_valid:290.93 collect_output:7.91
2023-01-08 23:18:41 - train.py[line:549] - INFO: 600 / 4988
2023-01-08 23:18:41 - train.py[line:551] - INFO: load:1.30 valid_run:454.25 task_valid:433.62 collect_output:17.52
2023-01-08 23:21:11 - train.py[line:549] - INFO: 800 / 4988
2023-01-08 23:21:11 - train.py[line:551] - INFO: load:1.33 valid_run:603.66 task_valid:578.16 collect_output:21.38
2023-01-08 23:23:43 - train.py[line:549] - INFO: 1000 / 4988
2023-01-08 23:23:43 - train.py[line:551] - INFO: load:1.35 valid_run:756.11 task_valid:725.16 collect_output:25.79
2023-01-08 23:26:15 - train.py[line:549] - INFO: 1200 / 4988
2023-01-08 23:26:15 - train.py[line:551] - INFO: load:1.38 valid_run:908.28 task_valid:870.44 collect_output:31.66
2023-01-08 23:28:49 - train.py[line:549] - INFO: 1400 / 4988
2023-01-08 23:28:49 - train.py[line:551] - INFO: load:1.40 valid_run:1062.27 task_valid:1016.10 collect_output:38.96
2023-01-08 23:31:21 - train.py[line:549] - INFO: 1600 / 4988
2023-01-08 23:31:21 - train.py[line:551] - INFO: load:1.43 valid_run:1214.19 task_valid:1156.96 collect_output:48.97
2023-01-08 23:33:51 - train.py[line:549] - INFO: 1800 / 4988
2023-01-08 23:33:51 - train.py[line:551] - INFO: load:1.45 valid_run:1363.95 task_valid:1301.31 collect_output:53.36
2023-01-08 23:36:20 - train.py[line:549] - INFO: 2000 / 4988
2023-01-08 23:36:20 - train.py[line:551] - INFO: load:1.48 valid_run:1512.87 task_valid:1444.36 collect_output:58.20
2023-01-08 23:38:50 - train.py[line:549] - INFO: 2200 / 4988
2023-01-08 23:38:50 - train.py[line:551] - INFO: load:1.51 valid_run:1662.75 task_valid:1588.89 collect_output:62.52
2023-01-08 23:41:20 - train.py[line:549] - INFO: 2400 / 4988
2023-01-08 23:41:20 - train.py[line:551] - INFO: load:1.53 valid_run:1812.71 task_valid:1733.45 collect_output:66.89
2023-01-08 23:43:50 - train.py[line:549] - INFO: 2600 / 4988
2023-01-08 23:43:50 - train.py[line:551] - INFO: load:1.56 valid_run:1962.81 task_valid:1874.84 collect_output:74.58
2023-01-08 23:46:21 - train.py[line:549] - INFO: 2800 / 4988
2023-01-08 23:46:21 - train.py[line:551] - INFO: load:1.58 valid_run:2113.43 task_valid:2020.09 collect_output:78.93
2023-01-08 23:48:51 - train.py[line:549] - INFO: 3000 / 4988
2023-01-08 23:48:51 - train.py[line:551] - INFO: load:1.61 valid_run:2263.40 task_valid:2166.11 collect_output:81.87
2023-01-08 23:51:21 - train.py[line:549] - INFO: 3200 / 4988
2023-01-08 23:51:21 - train.py[line:551] - INFO: load:1.64 valid_run:2413.37 task_valid:2309.77 collect_output:87.13
2023-01-08 23:53:53 - train.py[line:549] - INFO: 3400 / 4988
2023-01-08 23:53:53 - train.py[line:551] - INFO: load:1.66 valid_run:2565.23 task_valid:2454.83 collect_output:92.92
2023-01-08 23:56:24 - train.py[line:549] - INFO: 3600 / 4988
2023-01-08 23:56:24 - train.py[line:551] - INFO: load:1.69 valid_run:2715.77 task_valid:2601.47 collect_output:95.80
2023-01-08 23:58:52 - train.py[line:549] - INFO: 3800 / 4988
2023-01-08 23:58:52 - train.py[line:551] - INFO: load:1.71 valid_run:2864.42 task_valid:2742.60 collect_output:102.31
2023-01-09 00:01:23 - train.py[line:549] - INFO: 4000 / 4988
2023-01-09 00:01:23 - train.py[line:551] - INFO: load:1.74 valid_run:3014.79 task_valid:2887.20 collect_output:107.06
2023-01-09 00:03:55 - train.py[line:549] - INFO: 4200 / 4988
2023-01-09 00:03:55 - train.py[line:551] - INFO: load:1.77 valid_run:3167.05 task_valid:3031.48 collect_output:114.02
2023-01-09 00:06:25 - train.py[line:549] - INFO: 4400 / 4988
2023-01-09 00:06:25 - train.py[line:551] - INFO: load:1.79 valid_run:3316.56 task_valid:3175.81 collect_output:118.18
2023-01-09 00:08:56 - train.py[line:549] - INFO: 4600 / 4988
2023-01-09 00:08:56 - train.py[line:551] - INFO: load:1.82 valid_run:3467.79 task_valid:3321.52 collect_output:122.69
2023-01-09 00:11:28 - train.py[line:549] - INFO: 4800 / 4988
2023-01-09 00:11:28 - train.py[line:551] - INFO: load:1.84 valid_run:3619.24 task_valid:3467.54 collect_output:127.11

====================================================================================================
SGG eval:     R @ 50: 0.3971;     R @ 100: 0.4669;     R @ 500: 0.4977;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2355;    mR @ 100: 0.2947;    mR @ 500: 0.3175;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3756) (covered in:0.5625) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8750) (playing:0.0000) (riding:0.4739) (says:0.0000) (sitting on:0.6998) (standing on:0.2100) (using:0.7000) (walking in:0.0000) (walking on:0.1892) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-09 00:13:58 - train.py[line:487] - INFO: 0.46692857142857147
2023-01-09 00:13:58 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.3971;     R @ 100: 0.4669;     R @ 500: 0.4977;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2355;    mR @ 100: 0.2947;    mR @ 500: 0.3175;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3756) (covered in:0.5625) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8750) (playing:0.0000) (riding:0.4739) (says:0.0000) (sitting on:0.6998) (standing on:0.2100) (using:0.7000) (walking in:0.0000) (walking on:0.1892) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-09 00:13:59 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.405 | loss_v1 0 | loss_v2 0 | nll_loss 0.258 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.466929 | ppl 1.2 | vqa_score 0.3919 | wps 118.9 | wpb 89.9 | bsz 30 | num_updates 22000 | best_R@100 0.645421
2023-01-09 00:13:59 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 22000 updates
2023-01-09 00:13:59 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_22000.pt
2023-01-09 00:14:43 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_22000.pt
2023-01-09 00:16:13 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_22000.pt (epoch 1 @ 22000 updates, score 0.46692857142857147) (writing took 133.95175977237523 seconds)
2023-01-09 00:16:35 - progress_bar.py[line:274] - INFO: epoch 001:  22042 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.487, wps=0.6, ups=0, wpb=109.9, bsz=40, num_updates=22010, lr=4.21874e-05, gnorm=0.363, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=91550
2023-01-09 00:16:57 - progress_bar.py[line:274] - INFO: epoch 001:  22052 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4608, wps=99, ups=0.45, wpb=109.1, bsz=40, num_updates=22020, lr=4.21829e-05, gnorm=0.223, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=91573
2023-01-09 00:17:03 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 00:17:21 - progress_bar.py[line:274] - INFO: epoch 001:  22063 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.952, nsentences=40, sample_size=109.952, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4529, wps=97.9, ups=0.42, wpb=110, bsz=40, num_updates=22030, lr=4.21785e-05, gnorm=0.291, clip=0, loss_scale=256, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=91597
2023-01-09 00:17:42 - progress_bar.py[line:274] - INFO: epoch 001:  22073 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.407, wps=102.8, ups=0.47, wpb=109.1, bsz=40, num_updates=22040, lr=4.2174e-05, gnorm=0.194, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=91618
2023-01-09 00:18:04 - progress_bar.py[line:274] - INFO: epoch 001:  22083 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4375, wps=102.4, ups=0.47, wpb=109.5, bsz=40, num_updates=22050, lr=4.21695e-05, gnorm=0.278, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=91640
2023-01-09 00:18:25 - progress_bar.py[line:274] - INFO: epoch 001:  22093 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4478, wps=102.2, ups=0.47, wpb=109.2, bsz=40, num_updates=22060, lr=4.2165e-05, gnorm=0.176, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=91661
2023-01-09 00:18:47 - progress_bar.py[line:274] - INFO: epoch 001:  22103 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4519, wps=99.8, ups=0.46, wpb=107.8, bsz=40, num_updates=22070, lr=4.21605e-05, gnorm=0.21, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=91683
2023-01-09 00:19:09 - progress_bar.py[line:274] - INFO: epoch 001:  22113 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3886, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=22080, lr=4.2156e-05, gnorm=0.228, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=91705
2023-01-09 00:19:31 - progress_bar.py[line:274] - INFO: epoch 001:  22123 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3756, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=22090, lr=4.21515e-05, gnorm=0.206, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=91726
2023-01-09 00:19:52 - progress_bar.py[line:274] - INFO: epoch 001:  22133 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4902, wps=102.5, ups=0.47, wpb=108.7, bsz=40, num_updates=22100, lr=4.2147e-05, gnorm=0.274, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=91748
2023-01-09 00:20:14 - progress_bar.py[line:274] - INFO: epoch 001:  22143 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4607, wps=103.7, ups=0.47, wpb=110.1, bsz=40, num_updates=22110, lr=4.21425e-05, gnorm=0.232, clip=0, loss_scale=256, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=91769
2023-01-09 00:20:35 - progress_bar.py[line:274] - INFO: epoch 001:  22153 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4135, wps=100.2, ups=0.46, wpb=108.4, bsz=40, num_updates=22120, lr=4.2138e-05, gnorm=0.366, clip=10, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=91791
2023-01-09 00:20:57 - progress_bar.py[line:274] - INFO: epoch 001:  22163 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4877, wps=103.8, ups=0.47, wpb=109.9, bsz=40, num_updates=22130, lr=4.21335e-05, gnorm=0.165, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=91813
2023-01-09 00:21:19 - progress_bar.py[line:274] - INFO: epoch 001:  22173 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4527, wps=100.2, ups=0.46, wpb=108.5, bsz=40, num_updates=22140, lr=4.2129e-05, gnorm=0.387, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=91835
2023-01-09 00:21:41 - progress_bar.py[line:274] - INFO: epoch 001:  22183 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4559, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=22150, lr=4.21245e-05, gnorm=0.226, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=91856
2023-01-09 00:22:02 - progress_bar.py[line:274] - INFO: epoch 001:  22193 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.515, wps=100.2, ups=0.46, wpb=108.2, bsz=40, num_updates=22160, lr=4.212e-05, gnorm=0.223, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=91878
2023-01-09 00:22:24 - progress_bar.py[line:274] - INFO: epoch 001:  22203 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4381, wps=99.4, ups=0.46, wpb=108.5, bsz=40, num_updates=22170, lr=4.21155e-05, gnorm=0.213, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=91900
2023-01-09 00:22:46 - progress_bar.py[line:274] - INFO: epoch 001:  22213 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4569, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=22180, lr=4.2111e-05, gnorm=0.193, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=91922
2023-01-09 00:23:08 - progress_bar.py[line:274] - INFO: epoch 001:  22223 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4404, wps=100.2, ups=0.46, wpb=108.4, bsz=40, num_updates=22190, lr=4.21065e-05, gnorm=0.264, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=91944
2023-01-09 00:23:30 - progress_bar.py[line:274] - INFO: epoch 001:  22233 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5078, wps=101.3, ups=0.46, wpb=109.4, bsz=40, num_updates=22200, lr=4.2102e-05, gnorm=0.215, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=91966
2023-01-09 00:23:52 - progress_bar.py[line:274] - INFO: epoch 001:  22243 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4421, wps=101.4, ups=0.46, wpb=110.3, bsz=40, num_updates=22210, lr=4.20975e-05, gnorm=0.22, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=91988
2023-01-09 00:24:13 - progress_bar.py[line:274] - INFO: epoch 001:  22253 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4633, wps=103.7, ups=0.48, wpb=108.6, bsz=40, num_updates=22220, lr=4.2093e-05, gnorm=0.179, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92009
2023-01-09 00:24:35 - progress_bar.py[line:274] - INFO: epoch 001:  22263 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4337, wps=99.8, ups=0.45, wpb=109.8, bsz=40, num_updates=22230, lr=4.20885e-05, gnorm=0.153, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=92031
2023-01-09 00:24:57 - progress_bar.py[line:274] - INFO: epoch 001:  22273 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4712, wps=101, ups=0.46, wpb=108.7, bsz=40, num_updates=22240, lr=4.2084e-05, gnorm=0.228, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=92053
2023-01-09 00:25:18 - progress_bar.py[line:274] - INFO: epoch 001:  22283 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4667, wps=104.2, ups=0.48, wpb=109.2, bsz=40, num_updates=22250, lr=4.20795e-05, gnorm=0.281, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92074
2023-01-09 00:25:40 - progress_bar.py[line:274] - INFO: epoch 001:  22293 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4667, wps=101.9, ups=0.47, wpb=109.6, bsz=40, num_updates=22260, lr=4.2075e-05, gnorm=0.189, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=92096
2023-01-09 00:26:02 - progress_bar.py[line:274] - INFO: epoch 001:  22303 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4588, wps=100.3, ups=0.46, wpb=109.6, bsz=40, num_updates=22270, lr=4.20705e-05, gnorm=0.356, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=92118
2023-01-09 00:26:23 - progress_bar.py[line:274] - INFO: epoch 001:  22313 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4831, wps=102.2, ups=0.47, wpb=108.9, bsz=40, num_updates=22280, lr=4.20661e-05, gnorm=0.835, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=92139
2023-01-09 00:26:45 - progress_bar.py[line:274] - INFO: epoch 001:  22323 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5053, wps=101.9, ups=0.47, wpb=108.8, bsz=40, num_updates=22290, lr=4.20616e-05, gnorm=0.447, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=92161
2023-01-09 00:27:07 - progress_bar.py[line:274] - INFO: epoch 001:  22333 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4681, wps=102, ups=0.47, wpb=109.4, bsz=40, num_updates=22300, lr=4.20571e-05, gnorm=0.264, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=92183
2023-01-09 00:27:29 - progress_bar.py[line:274] - INFO: epoch 001:  22343 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4293, wps=101.2, ups=0.46, wpb=109.9, bsz=40, num_updates=22310, lr=4.20526e-05, gnorm=0.23, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=92204
2023-01-09 00:27:51 - progress_bar.py[line:274] - INFO: epoch 001:  22353 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.436, wps=98.9, ups=0.46, wpb=108, bsz=40, num_updates=22320, lr=4.20481e-05, gnorm=0.287, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=92227
2023-01-09 00:28:12 - progress_bar.py[line:274] - INFO: epoch 001:  22363 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5126, wps=102.2, ups=0.46, wpb=110, bsz=40, num_updates=22330, lr=4.20436e-05, gnorm=0.281, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=92248
2023-01-09 00:28:34 - progress_bar.py[line:274] - INFO: epoch 001:  22373 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4497, wps=104.2, ups=0.47, wpb=111.1, bsz=40, num_updates=22340, lr=4.20391e-05, gnorm=0.208, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=92270
2023-01-09 00:28:55 - progress_bar.py[line:274] - INFO: epoch 001:  22383 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4286, wps=102.6, ups=0.47, wpb=108.8, bsz=40, num_updates=22350, lr=4.20346e-05, gnorm=0.149, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=92291
2023-01-09 00:29:17 - progress_bar.py[line:274] - INFO: epoch 001:  22393 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4028, wps=100.4, ups=0.46, wpb=108.3, bsz=40, num_updates=22360, lr=4.20301e-05, gnorm=0.271, clip=0, loss_scale=256, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=92313
2023-01-09 00:29:39 - progress_bar.py[line:274] - INFO: epoch 001:  22403 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4523, wps=102, ups=0.47, wpb=108.8, bsz=40, num_updates=22370, lr=4.20256e-05, gnorm=0.158, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=92335
2023-01-09 00:30:01 - progress_bar.py[line:274] - INFO: epoch 001:  22413 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4709, wps=96.1, ups=0.45, wpb=106.9, bsz=40, num_updates=22380, lr=4.20211e-05, gnorm=0.23, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=92357
2023-01-09 00:30:23 - progress_bar.py[line:274] - INFO: epoch 001:  22423 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4743, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=22390, lr=4.20166e-05, gnorm=0.191, clip=0, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=92379
2023-01-09 00:30:45 - progress_bar.py[line:274] - INFO: epoch 001:  22433 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4167, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=22400, lr=4.20121e-05, gnorm=0.288, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92400
2023-01-09 00:31:06 - progress_bar.py[line:274] - INFO: epoch 001:  22443 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4069, wps=101.4, ups=0.47, wpb=108.6, bsz=40, num_updates=22410, lr=4.20076e-05, gnorm=0.128, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92422
2023-01-09 00:31:28 - progress_bar.py[line:274] - INFO: epoch 001:  22453 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4237, wps=101.4, ups=0.46, wpb=109.4, bsz=40, num_updates=22420, lr=4.20031e-05, gnorm=0.321, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=92444
2023-01-09 00:31:50 - progress_bar.py[line:274] - INFO: epoch 001:  22463 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4976, wps=101.4, ups=0.46, wpb=110.4, bsz=40, num_updates=22430, lr=4.19986e-05, gnorm=0.226, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=92466
2023-01-09 00:32:12 - progress_bar.py[line:274] - INFO: epoch 001:  22473 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4341, wps=100.5, ups=0.46, wpb=108.6, bsz=40, num_updates=22440, lr=4.19941e-05, gnorm=0.284, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=92488
2023-01-09 00:32:34 - progress_bar.py[line:274] - INFO: epoch 001:  22483 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.392, wps=99.4, ups=0.46, wpb=107.3, bsz=40, num_updates=22450, lr=4.19896e-05, gnorm=0.182, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=92509
2023-01-09 00:32:55 - progress_bar.py[line:274] - INFO: epoch 001:  22493 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3932, wps=102.8, ups=0.47, wpb=108.5, bsz=40, num_updates=22460, lr=4.19851e-05, gnorm=0.375, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=92531
2023-01-09 00:33:17 - progress_bar.py[line:274] - INFO: epoch 001:  22503 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4497, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=22470, lr=4.19806e-05, gnorm=0.272, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=92552
2023-01-09 00:33:38 - progress_bar.py[line:274] - INFO: epoch 001:  22513 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4195, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=22480, lr=4.19761e-05, gnorm=0.254, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=92574
2023-01-09 00:34:00 - progress_bar.py[line:274] - INFO: epoch 001:  22523 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4759, wps=103, ups=0.47, wpb=110.2, bsz=40, num_updates=22490, lr=4.19716e-05, gnorm=0.347, clip=10, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=92596
2023-01-09 00:34:21 - progress_bar.py[line:274] - INFO: epoch 001:  22533 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4219, wps=104.5, ups=0.47, wpb=110.1, bsz=40, num_updates=22500, lr=4.19671e-05, gnorm=0.345, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=92617
2023-01-09 00:34:43 - progress_bar.py[line:274] - INFO: epoch 001:  22543 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.435, wps=102.3, ups=0.47, wpb=109.4, bsz=40, num_updates=22510, lr=4.19626e-05, gnorm=0.295, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=92639
2023-01-09 00:35:05 - progress_bar.py[line:274] - INFO: epoch 001:  22553 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4842, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=22520, lr=4.19582e-05, gnorm=0.454, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=92661
2023-01-09 00:35:26 - progress_bar.py[line:274] - INFO: epoch 001:  22563 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4256, wps=104.2, ups=0.48, wpb=109.2, bsz=40, num_updates=22530, lr=4.19537e-05, gnorm=0.205, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92682
2023-01-09 00:35:48 - progress_bar.py[line:274] - INFO: epoch 001:  22573 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4872, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=22540, lr=4.19492e-05, gnorm=0.142, clip=0, loss_scale=512, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=92704
2023-01-09 00:36:09 - progress_bar.py[line:274] - INFO: epoch 001:  22583 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4973, wps=104, ups=0.47, wpb=111, bsz=40, num_updates=22550, lr=4.19447e-05, gnorm=0.252, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=92725
2023-01-09 00:36:31 - progress_bar.py[line:274] - INFO: epoch 001:  22593 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4235, wps=99.9, ups=0.46, wpb=108.6, bsz=40, num_updates=22560, lr=4.19402e-05, gnorm=0.255, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=92747
2023-01-09 00:36:53 - progress_bar.py[line:274] - INFO: epoch 001:  22603 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4824, wps=100.9, ups=0.46, wpb=109.6, bsz=40, num_updates=22570, lr=4.19357e-05, gnorm=0.201, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=92769
2023-01-09 00:37:15 - progress_bar.py[line:274] - INFO: epoch 001:  22613 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4951, wps=98.3, ups=0.46, wpb=107, bsz=40, num_updates=22580, lr=4.19312e-05, gnorm=0.183, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=92791
2023-01-09 00:37:37 - progress_bar.py[line:274] - INFO: epoch 001:  22623 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4755, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=22590, lr=4.19267e-05, gnorm=0.256, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=92813
2023-01-09 00:37:59 - progress_bar.py[line:274] - INFO: epoch 001:  22633 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4091, wps=100.7, ups=0.46, wpb=109.2, bsz=40, num_updates=22600, lr=4.19222e-05, gnorm=0.27, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=92835
2023-01-09 00:38:21 - progress_bar.py[line:274] - INFO: epoch 001:  22643 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4772, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=22610, lr=4.19177e-05, gnorm=0.353, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=92856
2023-01-09 00:38:42 - progress_bar.py[line:274] - INFO: epoch 001:  22653 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4091, wps=102.8, ups=0.48, wpb=107.7, bsz=40, num_updates=22620, lr=4.19132e-05, gnorm=0.339, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92878
2023-01-09 00:39:04 - progress_bar.py[line:274] - INFO: epoch 001:  22663 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4766, wps=99.6, ups=0.46, wpb=108.1, bsz=40, num_updates=22630, lr=4.19087e-05, gnorm=0.269, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=92899
2023-01-09 00:39:25 - progress_bar.py[line:274] - INFO: epoch 001:  22673 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4188, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=22640, lr=4.19042e-05, gnorm=0.186, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92921
2023-01-09 00:39:47 - progress_bar.py[line:274] - INFO: epoch 001:  22683 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4559, wps=101.6, ups=0.46, wpb=110, bsz=40, num_updates=22650, lr=4.18997e-05, gnorm=0.211, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=92943
2023-01-09 00:40:09 - progress_bar.py[line:274] - INFO: epoch 001:  22693 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4783, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=22660, lr=4.18952e-05, gnorm=0.269, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92965
2023-01-09 00:40:30 - progress_bar.py[line:274] - INFO: epoch 001:  22703 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4462, wps=103.9, ups=0.47, wpb=110.5, bsz=40, num_updates=22670, lr=4.18907e-05, gnorm=0.22, clip=0, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=92986
2023-01-09 00:40:52 - progress_bar.py[line:274] - INFO: epoch 001:  22713 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4925, wps=101.6, ups=0.47, wpb=108.3, bsz=40, num_updates=22680, lr=4.18862e-05, gnorm=0.296, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=93008
2023-01-09 00:41:13 - progress_bar.py[line:274] - INFO: epoch 001:  22723 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4667, wps=101, ups=0.46, wpb=108.7, bsz=40, num_updates=22690, lr=4.18817e-05, gnorm=0.369, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=93029
2023-01-09 00:41:34 - progress_bar.py[line:274] - INFO: epoch 001:  22733 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4327, wps=105.2, ups=0.48, wpb=109.3, bsz=40, num_updates=22700, lr=4.18772e-05, gnorm=0.235, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=93050
2023-01-09 00:41:56 - progress_bar.py[line:274] - INFO: epoch 001:  22743 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4378, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=22710, lr=4.18727e-05, gnorm=0.364, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=93072
2023-01-09 00:42:18 - progress_bar.py[line:274] - INFO: epoch 001:  22753 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3846, wps=103.8, ups=0.47, wpb=110.7, bsz=40, num_updates=22720, lr=4.18682e-05, gnorm=0.209, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=93094
2023-01-09 00:42:39 - progress_bar.py[line:274] - INFO: epoch 001:  22763 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4545, wps=103.5, ups=0.47, wpb=110.4, bsz=40, num_updates=22730, lr=4.18637e-05, gnorm=0.175, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=93115
2023-01-09 00:43:01 - progress_bar.py[line:274] - INFO: epoch 001:  22773 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4444, wps=101.5, ups=0.46, wpb=110.1, bsz=40, num_updates=22740, lr=4.18592e-05, gnorm=0.225, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=93137
2023-01-09 00:43:23 - progress_bar.py[line:274] - INFO: epoch 001:  22783 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.486, wps=101.2, ups=0.46, wpb=109.1, bsz=40, num_updates=22750, lr=4.18547e-05, gnorm=0.259, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=93159
2023-01-09 00:43:44 - progress_bar.py[line:274] - INFO: epoch 001:  22793 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.515, wps=102.5, ups=0.47, wpb=108.5, bsz=40, num_updates=22760, lr=4.18502e-05, gnorm=0.157, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93180
2023-01-09 00:44:06 - progress_bar.py[line:274] - INFO: epoch 001:  22803 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4729, wps=100.8, ups=0.47, wpb=108.3, bsz=40, num_updates=22770, lr=4.18458e-05, gnorm=0.323, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=93202
2023-01-09 00:44:27 - progress_bar.py[line:274] - INFO: epoch 001:  22813 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4512, wps=102.4, ups=0.47, wpb=108.1, bsz=40, num_updates=22780, lr=4.18413e-05, gnorm=0.164, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=93223
2023-01-09 00:44:49 - progress_bar.py[line:274] - INFO: epoch 001:  22823 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4826, wps=102.6, ups=0.47, wpb=108.8, bsz=40, num_updates=22790, lr=4.18368e-05, gnorm=0.332, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93245
2023-01-09 00:45:11 - progress_bar.py[line:274] - INFO: epoch 001:  22833 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4694, wps=100.9, ups=0.46, wpb=109.1, bsz=40, num_updates=22800, lr=4.18323e-05, gnorm=0.189, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=93267
2023-01-09 00:45:33 - progress_bar.py[line:274] - INFO: epoch 001:  22843 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4508, wps=101.3, ups=0.46, wpb=109.9, bsz=40, num_updates=22810, lr=4.18278e-05, gnorm=0.28, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=93288
2023-01-09 00:45:54 - progress_bar.py[line:274] - INFO: epoch 001:  22853 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4726, wps=105, ups=0.48, wpb=109.4, bsz=40, num_updates=22820, lr=4.18233e-05, gnorm=0.208, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=93310
2023-01-09 00:46:15 - progress_bar.py[line:274] - INFO: epoch 001:  22863 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.375, wps=101.3, ups=0.47, wpb=108.3, bsz=40, num_updates=22830, lr=4.18188e-05, gnorm=0.205, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93331
2023-01-09 00:46:37 - progress_bar.py[line:274] - INFO: epoch 001:  22873 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4828, wps=100.5, ups=0.47, wpb=107.8, bsz=40, num_updates=22840, lr=4.18143e-05, gnorm=0.248, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93353
2023-01-09 00:46:59 - progress_bar.py[line:274] - INFO: epoch 001:  22883 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4422, wps=102.2, ups=0.47, wpb=109.3, bsz=40, num_updates=22850, lr=4.18098e-05, gnorm=0.156, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=93374
2023-01-09 00:47:20 - progress_bar.py[line:274] - INFO: epoch 001:  22893 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4238, wps=102.6, ups=0.47, wpb=109, bsz=40, num_updates=22860, lr=4.18053e-05, gnorm=0.231, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=93396
2023-01-09 00:47:41 - progress_bar.py[line:274] - INFO: epoch 001:  22903 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4416, wps=102.3, ups=0.48, wpb=107.7, bsz=40, num_updates=22870, lr=4.18008e-05, gnorm=0.199, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=93417
2023-01-09 00:48:03 - progress_bar.py[line:274] - INFO: epoch 001:  22913 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4286, wps=99.8, ups=0.46, wpb=107.4, bsz=40, num_updates=22880, lr=4.17963e-05, gnorm=0.268, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93439
2023-01-09 00:48:25 - progress_bar.py[line:274] - INFO: epoch 001:  22923 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4889, wps=102.7, ups=0.47, wpb=110.3, bsz=40, num_updates=22890, lr=4.17918e-05, gnorm=0.281, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93461
2023-01-09 00:48:47 - progress_bar.py[line:274] - INFO: epoch 001:  22933 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4891, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=22900, lr=4.17873e-05, gnorm=0.28, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=93482
2023-01-09 00:49:08 - progress_bar.py[line:274] - INFO: epoch 001:  22943 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4273, wps=102, ups=0.47, wpb=107.4, bsz=40, num_updates=22910, lr=4.17828e-05, gnorm=0.287, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93504
2023-01-09 00:49:30 - progress_bar.py[line:274] - INFO: epoch 001:  22953 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4332, wps=99.9, ups=0.46, wpb=108.2, bsz=40, num_updates=22920, lr=4.17783e-05, gnorm=0.371, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=93526
2023-01-09 00:49:51 - progress_bar.py[line:274] - INFO: epoch 001:  22963 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3673, wps=101.6, ups=0.47, wpb=108.9, bsz=40, num_updates=22930, lr=4.17738e-05, gnorm=0.141, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93547
2023-01-09 00:50:13 - progress_bar.py[line:274] - INFO: epoch 001:  22973 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4205, wps=100, ups=0.46, wpb=108.8, bsz=40, num_updates=22940, lr=4.17693e-05, gnorm=0.304, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=93569
2023-01-09 00:50:35 - progress_bar.py[line:274] - INFO: epoch 001:  22983 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.47, wps=101.4, ups=0.47, wpb=108.2, bsz=40, num_updates=22950, lr=4.17648e-05, gnorm=0.182, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93591
2023-01-09 00:50:56 - progress_bar.py[line:274] - INFO: epoch 001:  22993 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3547, wps=102.8, ups=0.48, wpb=107.9, bsz=40, num_updates=22960, lr=4.17603e-05, gnorm=0.27, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=93612
2023-01-09 00:51:18 - progress_bar.py[line:274] - INFO: epoch 001:  23003 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4072, wps=101, ups=0.46, wpb=108.7, bsz=40, num_updates=22970, lr=4.17558e-05, gnorm=0.442, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=93634
2023-01-09 00:51:40 - progress_bar.py[line:274] - INFO: epoch 001:  23013 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4752, wps=100.2, ups=0.46, wpb=109.1, bsz=40, num_updates=22980, lr=4.17513e-05, gnorm=0.226, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=93656
2023-01-09 00:52:02 - progress_bar.py[line:274] - INFO: epoch 001:  23023 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4949, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=22990, lr=4.17468e-05, gnorm=0.216, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93677
2023-01-09 00:52:23 - progress_bar.py[line:274] - INFO: epoch 001:  23033 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.365, wps=103, ups=0.48, wpb=108.1, bsz=40, num_updates=23000, lr=4.17423e-05, gnorm=0.285, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93699
2023-01-09 00:52:45 - progress_bar.py[line:274] - INFO: epoch 001:  23043 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4162, wps=101.9, ups=0.46, wpb=110.4, bsz=40, num_updates=23010, lr=4.17379e-05, gnorm=0.385, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=93721
2023-01-09 00:53:06 - progress_bar.py[line:274] - INFO: epoch 001:  23053 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4133, wps=101.4, ups=0.47, wpb=108.2, bsz=40, num_updates=23020, lr=4.17334e-05, gnorm=0.286, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=93742
2023-01-09 00:53:28 - progress_bar.py[line:274] - INFO: epoch 001:  23063 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4947, wps=100.3, ups=0.46, wpb=108.6, bsz=40, num_updates=23030, lr=4.17289e-05, gnorm=0.185, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=93764
2023-01-09 00:53:50 - progress_bar.py[line:274] - INFO: epoch 001:  23073 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4607, wps=101.7, ups=0.46, wpb=109.9, bsz=40, num_updates=23040, lr=4.17244e-05, gnorm=0.257, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=93786
2023-01-09 00:54:12 - progress_bar.py[line:274] - INFO: epoch 001:  23083 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4863, wps=99.6, ups=0.46, wpb=109, bsz=40, num_updates=23050, lr=4.17199e-05, gnorm=0.214, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=93808
2023-01-09 00:54:34 - progress_bar.py[line:274] - INFO: epoch 001:  23093 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4392, wps=101.6, ups=0.46, wpb=110.6, bsz=40, num_updates=23060, lr=4.17154e-05, gnorm=0.222, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=93830
2023-01-09 00:54:56 - progress_bar.py[line:274] - INFO: epoch 001:  23103 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4404, wps=101.7, ups=0.47, wpb=109.3, bsz=40, num_updates=23070, lr=4.17109e-05, gnorm=0.27, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=93852
2023-01-09 00:55:17 - progress_bar.py[line:274] - INFO: epoch 001:  23113 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.392, wps=102.2, ups=0.47, wpb=109.3, bsz=40, num_updates=23080, lr=4.17064e-05, gnorm=0.274, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93873
2023-01-09 00:55:39 - progress_bar.py[line:274] - INFO: epoch 001:  23123 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3952, wps=102.5, ups=0.47, wpb=108.7, bsz=40, num_updates=23090, lr=4.17019e-05, gnorm=0.24, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=93895
2023-01-09 00:56:01 - progress_bar.py[line:274] - INFO: epoch 001:  23133 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3906, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=23100, lr=4.16974e-05, gnorm=0.298, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=93916
2023-01-09 00:56:23 - progress_bar.py[line:274] - INFO: epoch 001:  23143 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4951, wps=97.9, ups=0.45, wpb=107.8, bsz=40, num_updates=23110, lr=4.16929e-05, gnorm=0.294, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=93939
2023-01-09 00:56:44 - progress_bar.py[line:274] - INFO: epoch 001:  23153 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4417, wps=103, ups=0.48, wpb=108, bsz=40, num_updates=23120, lr=4.16884e-05, gnorm=0.326, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=93960
2023-01-09 00:57:06 - progress_bar.py[line:274] - INFO: epoch 001:  23163 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4415, wps=100.7, ups=0.46, wpb=110.3, bsz=40, num_updates=23130, lr=4.16839e-05, gnorm=0.379, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=93982
2023-01-09 00:57:28 - progress_bar.py[line:274] - INFO: epoch 001:  23173 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3632, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=23140, lr=4.16794e-05, gnorm=0.172, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94004
2023-01-09 00:57:50 - progress_bar.py[line:274] - INFO: epoch 001:  23183 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.425, wps=103.1, ups=0.47, wpb=109.2, bsz=40, num_updates=23150, lr=4.16749e-05, gnorm=0.382, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=94025
2023-01-09 00:58:12 - progress_bar.py[line:274] - INFO: epoch 001:  23193 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4251, wps=99.4, ups=0.46, wpb=109.1, bsz=40, num_updates=23160, lr=4.16704e-05, gnorm=0.381, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=94047
2023-01-09 00:58:34 - progress_bar.py[line:274] - INFO: epoch 001:  23203 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5194, wps=99.1, ups=0.46, wpb=108.2, bsz=40, num_updates=23170, lr=4.16659e-05, gnorm=0.193, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=94070
2023-01-09 00:58:56 - progress_bar.py[line:274] - INFO: epoch 001:  23213 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4513, wps=100.3, ups=0.46, wpb=108.2, bsz=40, num_updates=23180, lr=4.16614e-05, gnorm=0.166, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=94091
2023-01-09 00:59:18 - progress_bar.py[line:274] - INFO: epoch 001:  23223 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.414, wps=101.1, ups=0.46, wpb=109.9, bsz=40, num_updates=23190, lr=4.16569e-05, gnorm=0.291, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=94113
2023-01-09 00:59:39 - progress_bar.py[line:274] - INFO: epoch 001:  23233 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4882, wps=100.7, ups=0.46, wpb=109.2, bsz=40, num_updates=23200, lr=4.16524e-05, gnorm=0.305, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=94135
2023-01-09 01:00:01 - progress_bar.py[line:274] - INFO: epoch 001:  23243 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.399, wps=99.1, ups=0.46, wpb=107.5, bsz=40, num_updates=23210, lr=4.16479e-05, gnorm=0.202, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=94157
2023-01-09 01:00:23 - progress_bar.py[line:274] - INFO: epoch 001:  23253 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4524, wps=100.9, ups=0.47, wpb=107.8, bsz=40, num_updates=23220, lr=4.16434e-05, gnorm=0.271, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94179
2023-01-09 01:00:38 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-09 01:00:47 - progress_bar.py[line:274] - INFO: epoch 001:  23264 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.095, nsentences=40, sample_size=108.095, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=95.4, ups=0.42, wpb=108.1, bsz=40, num_updates=23230, lr=4.16389e-05, gnorm=0.271, clip=0, loss_scale=512, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=94203
2023-01-09 01:01:08 - progress_bar.py[line:274] - INFO: epoch 001:  23274 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4043, wps=104.2, ups=0.47, wpb=110.7, bsz=40, num_updates=23240, lr=4.16344e-05, gnorm=0.241, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94224
2023-01-09 01:01:30 - progress_bar.py[line:274] - INFO: epoch 001:  23284 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4159, wps=98.5, ups=0.46, wpb=106.9, bsz=40, num_updates=23250, lr=4.163e-05, gnorm=0.261, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=94246
2023-01-09 01:01:52 - progress_bar.py[line:274] - INFO: epoch 001:  23294 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4213, wps=100, ups=0.46, wpb=108.8, bsz=40, num_updates=23260, lr=4.16255e-05, gnorm=0.268, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94268
2023-01-09 01:02:14 - progress_bar.py[line:274] - INFO: epoch 001:  23304 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.404, wps=100.5, ups=0.46, wpb=108.7, bsz=40, num_updates=23270, lr=4.1621e-05, gnorm=0.292, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=94290
2023-01-09 01:02:36 - progress_bar.py[line:274] - INFO: epoch 001:  23314 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5127, wps=100.2, ups=0.46, wpb=109.1, bsz=40, num_updates=23280, lr=4.16165e-05, gnorm=0.263, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94312
2023-01-09 01:02:58 - progress_bar.py[line:274] - INFO: epoch 001:  23324 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.441, wps=99.9, ups=0.46, wpb=108.8, bsz=40, num_updates=23290, lr=4.1612e-05, gnorm=0.383, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94334
2023-01-09 01:03:20 - progress_bar.py[line:274] - INFO: epoch 001:  23334 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4416, wps=102.9, ups=0.47, wpb=110.4, bsz=40, num_updates=23300, lr=4.16075e-05, gnorm=0.239, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=94356
2023-01-09 01:03:42 - progress_bar.py[line:274] - INFO: epoch 001:  23344 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4554, wps=98.1, ups=0.46, wpb=107.8, bsz=40, num_updates=23310, lr=4.1603e-05, gnorm=0.172, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=94378
2023-01-09 01:04:03 - progress_bar.py[line:274] - INFO: epoch 001:  23354 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4154, wps=101.3, ups=0.47, wpb=107.3, bsz=40, num_updates=23320, lr=4.15985e-05, gnorm=0.21, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94399
2023-01-09 01:04:25 - progress_bar.py[line:274] - INFO: epoch 001:  23364 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.427, wps=102.2, ups=0.46, wpb=110.1, bsz=40, num_updates=23330, lr=4.1594e-05, gnorm=0.209, clip=0, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=94421
2023-01-09 01:04:47 - progress_bar.py[line:274] - INFO: epoch 001:  23374 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4439, wps=100.4, ups=0.46, wpb=108.1, bsz=40, num_updates=23340, lr=4.15895e-05, gnorm=0.184, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94443
2023-01-09 01:05:08 - progress_bar.py[line:274] - INFO: epoch 001:  23384 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4422, wps=103, ups=0.47, wpb=109.2, bsz=40, num_updates=23350, lr=4.1585e-05, gnorm=0.267, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=94464
2023-01-09 01:05:30 - progress_bar.py[line:274] - INFO: epoch 001:  23394 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4279, wps=102.3, ups=0.47, wpb=109, bsz=40, num_updates=23360, lr=4.15805e-05, gnorm=0.337, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94486
2023-01-09 01:05:51 - progress_bar.py[line:274] - INFO: epoch 001:  23404 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4316, wps=105.9, ups=0.48, wpb=110.8, bsz=40, num_updates=23370, lr=4.1576e-05, gnorm=0.243, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=94507
2023-01-09 01:05:55 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 01:06:15 - progress_bar.py[line:274] - INFO: epoch 001:  23415 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.286, nsentences=40, sample_size=109.286, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4779, wps=97.3, ups=0.42, wpb=109.3, bsz=40, num_updates=23380, lr=4.15715e-05, gnorm=0.408, clip=10, loss_scale=256, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=94531
2023-01-09 01:06:37 - progress_bar.py[line:274] - INFO: epoch 001:  23425 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5183, wps=101.2, ups=0.47, wpb=108.3, bsz=40, num_updates=23390, lr=4.1567e-05, gnorm=0.241, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=94552
2023-01-09 01:06:59 - progress_bar.py[line:274] - INFO: epoch 001:  23435 / 115845 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.4946, wps=101.6, ups=0.46, wpb=110.4, bsz=40, num_updates=23400, lr=4.15625e-05, gnorm=0.166, clip=0, loss_scale=256, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=94574
2023-01-09 01:07:20 - progress_bar.py[line:274] - INFO: epoch 001:  23445 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4923, wps=101.3, ups=0.46, wpb=109.2, bsz=40, num_updates=23410, lr=4.1558e-05, gnorm=0.202, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94596
2023-01-09 01:07:42 - progress_bar.py[line:274] - INFO: epoch 001:  23455 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4895, wps=100, ups=0.46, wpb=108.5, bsz=40, num_updates=23420, lr=4.15535e-05, gnorm=0.207, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=94618
2023-01-09 01:08:04 - progress_bar.py[line:274] - INFO: epoch 001:  23465 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4808, wps=100.1, ups=0.46, wpb=107.7, bsz=40, num_updates=23430, lr=4.1549e-05, gnorm=0.252, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94640
2023-01-09 01:08:26 - progress_bar.py[line:274] - INFO: epoch 001:  23475 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4837, wps=99.2, ups=0.46, wpb=107.3, bsz=40, num_updates=23440, lr=4.15445e-05, gnorm=0.361, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=94662
2023-01-09 01:08:47 - progress_bar.py[line:274] - INFO: epoch 001:  23485 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4654, wps=102.5, ups=0.48, wpb=107.7, bsz=40, num_updates=23450, lr=4.154e-05, gnorm=0.187, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94683
2023-01-09 01:09:09 - progress_bar.py[line:274] - INFO: epoch 001:  23495 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.468, wps=99.9, ups=0.46, wpb=108.3, bsz=40, num_updates=23460, lr=4.15355e-05, gnorm=0.233, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94705
2023-01-09 01:09:31 - progress_bar.py[line:274] - INFO: epoch 001:  23505 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.532, wps=102.5, ups=0.47, wpb=109.5, bsz=40, num_updates=23470, lr=4.1531e-05, gnorm=0.212, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=94726
2023-01-09 01:09:52 - progress_bar.py[line:274] - INFO: epoch 001:  23515 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4493, wps=101.8, ups=0.46, wpb=109.7, bsz=40, num_updates=23480, lr=4.15265e-05, gnorm=0.195, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=94748
2023-01-09 01:10:14 - progress_bar.py[line:274] - INFO: epoch 001:  23525 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4055, wps=99.6, ups=0.46, wpb=108, bsz=40, num_updates=23490, lr=4.1522e-05, gnorm=0.441, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94770
2023-01-09 01:10:36 - progress_bar.py[line:274] - INFO: epoch 001:  23535 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4576, wps=103, ups=0.47, wpb=110.3, bsz=40, num_updates=23500, lr=4.15176e-05, gnorm=0.267, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=94792
2023-01-09 01:10:57 - progress_bar.py[line:274] - INFO: epoch 001:  23545 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4511, wps=103.7, ups=0.47, wpb=110.6, bsz=40, num_updates=23510, lr=4.15131e-05, gnorm=0.395, clip=20, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=94813
2023-01-09 01:11:20 - progress_bar.py[line:274] - INFO: epoch 001:  23555 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4558, wps=98.9, ups=0.46, wpb=108.6, bsz=40, num_updates=23520, lr=4.15086e-05, gnorm=0.262, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=94835
2023-01-09 01:11:42 - progress_bar.py[line:274] - INFO: epoch 001:  23565 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4976, wps=100.5, ups=0.46, wpb=109.3, bsz=40, num_updates=23530, lr=4.15041e-05, gnorm=0.35, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=94857
2023-01-09 01:12:03 - progress_bar.py[line:274] - INFO: epoch 001:  23575 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.412, wps=102, ups=0.48, wpb=107.1, bsz=40, num_updates=23540, lr=4.14996e-05, gnorm=0.255, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94879
2023-01-09 01:12:24 - progress_bar.py[line:274] - INFO: epoch 001:  23585 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4554, wps=104.5, ups=0.48, wpb=109.7, bsz=40, num_updates=23550, lr=4.14951e-05, gnorm=0.319, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94900
2023-01-09 01:12:46 - progress_bar.py[line:274] - INFO: epoch 001:  23595 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4608, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=23560, lr=4.14906e-05, gnorm=0.166, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94922
2023-01-09 01:13:08 - progress_bar.py[line:274] - INFO: epoch 001:  23605 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.45, wps=103, ups=0.46, wpb=110.9, bsz=40, num_updates=23570, lr=4.14861e-05, gnorm=0.132, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94944
2023-01-09 01:13:29 - progress_bar.py[line:274] - INFO: epoch 001:  23615 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4683, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=23580, lr=4.14816e-05, gnorm=0.14, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=94965
2023-01-09 01:13:51 - progress_bar.py[line:274] - INFO: epoch 001:  23625 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4894, wps=104.4, ups=0.48, wpb=109.6, bsz=40, num_updates=23590, lr=4.14771e-05, gnorm=0.284, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94987
2023-01-09 01:14:12 - progress_bar.py[line:274] - INFO: epoch 001:  23635 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5166, wps=102.7, ups=0.47, wpb=109.4, bsz=40, num_updates=23600, lr=4.14726e-05, gnorm=0.18, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=95008
2023-01-09 01:14:34 - progress_bar.py[line:274] - INFO: epoch 001:  23645 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4563, wps=99, ups=0.46, wpb=107.8, bsz=40, num_updates=23610, lr=4.14681e-05, gnorm=0.274, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=95030
2023-01-09 01:14:55 - progress_bar.py[line:274] - INFO: epoch 001:  23655 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4235, wps=103.4, ups=0.48, wpb=108.1, bsz=40, num_updates=23620, lr=4.14636e-05, gnorm=0.286, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=95051
2023-01-09 01:15:17 - progress_bar.py[line:274] - INFO: epoch 001:  23665 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4593, wps=102.6, ups=0.46, wpb=110.4, bsz=40, num_updates=23630, lr=4.14591e-05, gnorm=0.237, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=95073
2023-01-09 01:15:39 - progress_bar.py[line:274] - INFO: epoch 001:  23675 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4745, wps=98.8, ups=0.46, wpb=107.9, bsz=40, num_updates=23640, lr=4.14546e-05, gnorm=0.174, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=95095
2023-01-09 01:16:00 - progress_bar.py[line:274] - INFO: epoch 001:  23685 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4341, wps=102.8, ups=0.48, wpb=108.2, bsz=40, num_updates=23650, lr=4.14501e-05, gnorm=0.189, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=95116
2023-01-09 01:16:22 - progress_bar.py[line:274] - INFO: epoch 001:  23695 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4523, wps=100.3, ups=0.46, wpb=108.3, bsz=40, num_updates=23660, lr=4.14456e-05, gnorm=0.206, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=95138
2023-01-09 01:16:44 - progress_bar.py[line:274] - INFO: epoch 001:  23705 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4211, wps=101.3, ups=0.46, wpb=109.2, bsz=40, num_updates=23670, lr=4.14411e-05, gnorm=0.192, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=95160
2023-01-09 01:17:05 - progress_bar.py[line:274] - INFO: epoch 001:  23715 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4462, wps=103.8, ups=0.47, wpb=110, bsz=40, num_updates=23680, lr=4.14366e-05, gnorm=0.274, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=95181
2023-01-09 01:17:27 - progress_bar.py[line:274] - INFO: epoch 001:  23725 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4645, wps=100.1, ups=0.46, wpb=108.1, bsz=40, num_updates=23690, lr=4.14321e-05, gnorm=0.214, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=95203
2023-01-09 01:17:49 - progress_bar.py[line:274] - INFO: epoch 001:  23735 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4126, wps=103.7, ups=0.47, wpb=109.7, bsz=40, num_updates=23700, lr=4.14276e-05, gnorm=0.232, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=95224
2023-01-09 01:18:10 - progress_bar.py[line:274] - INFO: epoch 001:  23745 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4398, wps=104.9, ups=0.48, wpb=109.6, bsz=40, num_updates=23710, lr=4.14231e-05, gnorm=0.207, clip=0, loss_scale=256, train_wall=21, gb_free=9.5, ema_decay=0.9999, wall=95245
2023-01-09 01:18:31 - progress_bar.py[line:274] - INFO: epoch 001:  23755 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4147, wps=102, ups=0.47, wpb=107.8, bsz=40, num_updates=23720, lr=4.14186e-05, gnorm=0.369, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=95267
2023-01-09 01:18:53 - progress_bar.py[line:274] - INFO: epoch 001:  23765 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.432, wps=100.5, ups=0.47, wpb=107.2, bsz=40, num_updates=23730, lr=4.14141e-05, gnorm=0.236, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=95288
2023-01-09 01:19:14 - progress_bar.py[line:274] - INFO: epoch 001:  23775 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4121, wps=101, ups=0.46, wpb=109.2, bsz=40, num_updates=23740, lr=4.14097e-05, gnorm=0.258, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=95310
2023-01-09 01:19:37 - progress_bar.py[line:274] - INFO: epoch 001:  23785 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4581, wps=99.4, ups=0.45, wpb=109.8, bsz=40, num_updates=23750, lr=4.14052e-05, gnorm=0.283, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=95333
2023-01-09 01:19:58 - progress_bar.py[line:274] - INFO: epoch 001:  23795 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4523, wps=102.2, ups=0.47, wpb=109.2, bsz=40, num_updates=23760, lr=4.14007e-05, gnorm=0.383, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=95354
2023-01-09 01:20:20 - progress_bar.py[line:274] - INFO: epoch 001:  23805 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4657, wps=101.9, ups=0.46, wpb=109.8, bsz=40, num_updates=23770, lr=4.13962e-05, gnorm=0.378, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=95376
2023-01-09 01:20:42 - progress_bar.py[line:274] - INFO: epoch 001:  23815 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4853, wps=100.2, ups=0.46, wpb=108.1, bsz=40, num_updates=23780, lr=4.13917e-05, gnorm=0.344, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=95398
2023-01-09 01:21:04 - progress_bar.py[line:274] - INFO: epoch 001:  23825 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4428, wps=100.2, ups=0.46, wpb=108.8, bsz=40, num_updates=23790, lr=4.13872e-05, gnorm=0.226, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=95420
2023-01-09 01:21:26 - progress_bar.py[line:274] - INFO: epoch 001:  23835 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4312, wps=99.1, ups=0.46, wpb=107.2, bsz=40, num_updates=23800, lr=4.13827e-05, gnorm=0.321, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=95441
2023-01-09 01:21:48 - progress_bar.py[line:274] - INFO: epoch 001:  23845 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4225, wps=99.5, ups=0.46, wpb=108.6, bsz=40, num_updates=23810, lr=4.13782e-05, gnorm=0.193, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=95463
2023-01-09 01:22:09 - progress_bar.py[line:274] - INFO: epoch 001:  23855 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4639, wps=101.9, ups=0.46, wpb=109.8, bsz=40, num_updates=23820, lr=4.13737e-05, gnorm=0.202, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=95485
2023-01-09 01:22:31 - progress_bar.py[line:274] - INFO: epoch 001:  23865 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4767, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=23830, lr=4.13692e-05, gnorm=0.271, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=95507
2023-01-09 01:22:53 - progress_bar.py[line:274] - INFO: epoch 001:  23875 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.485, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=23840, lr=4.13647e-05, gnorm=0.345, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=95529
2023-01-09 01:23:14 - progress_bar.py[line:274] - INFO: epoch 001:  23885 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4769, wps=103, ups=0.47, wpb=109.1, bsz=40, num_updates=23850, lr=4.13602e-05, gnorm=0.799, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=95550
2023-01-09 01:23:36 - progress_bar.py[line:274] - INFO: epoch 001:  23895 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4455, wps=103.4, ups=0.47, wpb=109.6, bsz=40, num_updates=23860, lr=4.13557e-05, gnorm=0.237, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=95572
2023-01-09 01:23:57 - progress_bar.py[line:274] - INFO: epoch 001:  23905 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4697, wps=103.3, ups=0.47, wpb=109.5, bsz=40, num_updates=23870, lr=4.13512e-05, gnorm=0.263, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=95593
2023-01-09 01:24:19 - progress_bar.py[line:274] - INFO: epoch 001:  23915 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4536, wps=100.8, ups=0.46, wpb=110.2, bsz=40, num_updates=23880, lr=4.13467e-05, gnorm=0.182, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=95615
2023-01-09 01:24:41 - progress_bar.py[line:274] - INFO: epoch 001:  23925 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4419, wps=99.1, ups=0.46, wpb=108.4, bsz=40, num_updates=23890, lr=4.13422e-05, gnorm=0.223, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=95637
2023-01-09 01:25:03 - progress_bar.py[line:274] - INFO: epoch 001:  23935 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5024, wps=100.4, ups=0.46, wpb=108.2, bsz=40, num_updates=23900, lr=4.13377e-05, gnorm=0.231, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=95659
2023-01-09 01:25:25 - progress_bar.py[line:274] - INFO: epoch 001:  23945 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4286, wps=100.1, ups=0.46, wpb=109.5, bsz=40, num_updates=23910, lr=4.13332e-05, gnorm=0.315, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=95681
2023-01-09 01:25:47 - progress_bar.py[line:274] - INFO: epoch 001:  23955 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4907, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=23920, lr=4.13287e-05, gnorm=0.331, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=95703
2023-01-09 01:26:09 - progress_bar.py[line:274] - INFO: epoch 001:  23965 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4869, wps=101.2, ups=0.46, wpb=109.5, bsz=40, num_updates=23930, lr=4.13242e-05, gnorm=0.219, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=95724
2023-01-09 01:26:31 - progress_bar.py[line:274] - INFO: epoch 001:  23975 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4802, wps=99.3, ups=0.46, wpb=108, bsz=40, num_updates=23940, lr=4.13197e-05, gnorm=0.229, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=95746
2023-01-09 01:26:52 - progress_bar.py[line:274] - INFO: epoch 001:  23985 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4375, wps=102.3, ups=0.47, wpb=110, bsz=40, num_updates=23950, lr=4.13152e-05, gnorm=0.161, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=95768
2023-01-09 01:27:13 - progress_bar.py[line:274] - INFO: epoch 001:  23995 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4505, wps=105.1, ups=0.48, wpb=109.1, bsz=40, num_updates=23960, lr=4.13107e-05, gnorm=0.378, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=95789
2023-01-09 01:27:35 - progress_bar.py[line:274] - INFO: epoch 001:  24005 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4242, wps=101.9, ups=0.47, wpb=109.1, bsz=40, num_updates=23970, lr=4.13062e-05, gnorm=0.186, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=95811
2023-01-09 01:27:57 - progress_bar.py[line:274] - INFO: epoch 001:  24015 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4051, wps=101.1, ups=0.46, wpb=109.5, bsz=40, num_updates=23980, lr=4.13017e-05, gnorm=0.279, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=95833
2023-01-09 01:28:19 - progress_bar.py[line:274] - INFO: epoch 001:  24025 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.475, wps=101, ups=0.47, wpb=108.6, bsz=40, num_updates=23990, lr=4.12973e-05, gnorm=0.421, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=95854
2023-01-09 01:28:40 - progress_bar.py[line:274] - INFO: epoch 001:  24035 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5176, wps=102, ups=0.46, wpb=110.5, bsz=40, num_updates=24000, lr=4.12928e-05, gnorm=0.332, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=95876
2023-01-09 01:28:40 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-09 01:28:42 - train.py[line:549] - INFO: 0 / 4988
2023-01-09 01:28:42 - train.py[line:551] - INFO: load:1.35 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-09 01:28:43 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 9.27 GiB already allocated; 5.94 GiB free; 31.16 GiB reserved in total by PyTorch)
2023-01-09 01:28:43 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-09 01:28:43 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 29        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9490 MB |   10715 MB |   13654 TB |   13654 TB |
|       from large pool |    9315 MB |   10540 MB |   13648 TB |   13648 TB |
|       from small pool |     174 MB |     175 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9490 MB |   10715 MB |   13654 TB |   13654 TB |
|       from large pool |    9315 MB |   10540 MB |   13648 TB |   13648 TB |
|       from small pool |     174 MB |     175 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   31910 MB |   33332 MB |  335358 MB |  303448 MB |
|       from large pool |   31734 MB |   33154 MB |  334908 MB |  303174 MB |
|       from small pool |     176 MB |     178 MB |     450 MB |     274 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22419 MB |   26797 MB |   13307 TB |   13307 TB |
|       from large pool |   22418 MB |   26795 MB |   13300 TB |   13300 TB |
|       from small pool |       1 MB |       3 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  645504 K  |  645500 K  |
|       from large pool |     698    |     710    |  198636 K  |  198635 K  |
|       from small pool |    3925    |    3943    |  446868 K  |  446864 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  645504 K  |  645500 K  |
|       from large pool |     698    |     710    |  198636 K  |  198635 K  |
|       from small pool |    3925    |    3943    |  446868 K  |  446864 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     205    |     216    |     775    |     570    |
|       from large pool |     117    |     127    |     550    |     433    |
|       from small pool |      88    |      89    |     225    |     137    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     145    |     148    |  482400 K  |  482400 K  |
|       from large pool |      73    |      74    |   97586 K  |   97586 K  |
|       from small pool |      72    |      80    |  384814 K  |  384813 K  |
|===========================================================================|

2023-01-09 01:28:43 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-09 01:31:14 - train.py[line:549] - INFO: 200 / 4988
2023-01-09 01:31:15 - train.py[line:551] - INFO: load:1.37 valid_run:152.35 task_valid:147.95 collect_output:3.32
2023-01-09 01:33:43 - train.py[line:549] - INFO: 400 / 4988
2023-01-09 01:33:43 - train.py[line:551] - INFO: load:1.40 valid_run:300.72 task_valid:290.75 collect_output:7.89
2023-01-09 01:36:15 - train.py[line:549] - INFO: 600 / 4988
2023-01-09 01:36:15 - train.py[line:551] - INFO: load:1.42 valid_run:452.96 task_valid:433.57 collect_output:16.27
2023-01-09 01:38:44 - train.py[line:549] - INFO: 800 / 4988
2023-01-09 01:38:45 - train.py[line:551] - INFO: load:1.45 valid_run:602.14 task_valid:578.38 collect_output:19.63
2023-01-09 01:41:17 - train.py[line:549] - INFO: 1000 / 4988
2023-01-09 01:41:17 - train.py[line:551] - INFO: load:1.47 valid_run:754.31 task_valid:725.62 collect_output:23.56
2023-01-09 01:43:48 - train.py[line:549] - INFO: 1200 / 4988
2023-01-09 01:43:48 - train.py[line:551] - INFO: load:1.50 valid_run:905.91 task_valid:870.89 collect_output:28.88
2023-01-09 01:46:22 - train.py[line:549] - INFO: 1400 / 4988
2023-01-09 01:46:22 - train.py[line:551] - INFO: load:1.52 valid_run:1059.29 task_valid:1016.51 collect_output:35.63
2023-01-09 01:48:54 - train.py[line:549] - INFO: 1600 / 4988
2023-01-09 01:48:54 - train.py[line:551] - INFO: load:1.55 valid_run:1210.91 task_valid:1157.40 collect_output:45.36
2023-01-09 01:51:23 - train.py[line:549] - INFO: 1800 / 4988
2023-01-09 01:51:23 - train.py[line:551] - INFO: load:1.58 valid_run:1360.43 task_valid:1301.62 collect_output:49.63
2023-01-09 01:53:52 - train.py[line:549] - INFO: 2000 / 4988
2023-01-09 01:53:52 - train.py[line:551] - INFO: load:1.60 valid_run:1508.93 task_valid:1444.38 collect_output:54.36
2023-01-09 01:56:21 - train.py[line:549] - INFO: 2200 / 4988
2023-01-09 01:56:21 - train.py[line:551] - INFO: load:1.63 valid_run:1658.39 task_valid:1588.84 collect_output:58.36
2023-01-09 01:58:51 - train.py[line:549] - INFO: 2400 / 4988
2023-01-09 01:58:51 - train.py[line:551] - INFO: load:1.65 valid_run:1808.42 task_valid:1733.58 collect_output:62.63
2023-01-09 02:01:21 - train.py[line:549] - INFO: 2600 / 4988
2023-01-09 02:01:21 - train.py[line:551] - INFO: load:1.68 valid_run:1958.26 task_valid:1874.96 collect_output:70.09
2023-01-09 02:03:52 - train.py[line:549] - INFO: 2800 / 4988
2023-01-09 02:03:52 - train.py[line:551] - INFO: load:1.70 valid_run:2108.58 task_valid:2020.04 collect_output:74.32
2023-01-09 02:06:22 - train.py[line:549] - INFO: 3000 / 4988
2023-01-09 02:06:22 - train.py[line:551] - INFO: load:1.73 valid_run:2258.41 task_valid:2166.14 collect_output:77.04
2023-01-09 02:08:52 - train.py[line:549] - INFO: 3200 / 4988
2023-01-09 02:08:52 - train.py[line:551] - INFO: load:1.75 valid_run:2408.65 task_valid:2310.15 collect_output:82.26
2023-01-09 02:11:24 - train.py[line:549] - INFO: 3400 / 4988
2023-01-09 02:11:24 - train.py[line:551] - INFO: load:1.78 valid_run:2560.29 task_valid:2455.25 collect_output:87.78
2023-01-09 02:13:54 - train.py[line:549] - INFO: 3600 / 4988
2023-01-09 02:13:54 - train.py[line:551] - INFO: load:1.80 valid_run:2710.53 task_valid:2601.82 collect_output:90.44
2023-01-09 02:16:22 - train.py[line:549] - INFO: 3800 / 4988
2023-01-09 02:16:22 - train.py[line:551] - INFO: load:1.83 valid_run:2858.90 task_valid:2742.98 collect_output:96.63
2023-01-09 02:18:53 - train.py[line:549] - INFO: 4000 / 4988
2023-01-09 02:18:53 - train.py[line:551] - INFO: load:1.86 valid_run:3009.45 task_valid:2887.95 collect_output:101.18
2023-01-09 02:21:25 - train.py[line:549] - INFO: 4200 / 4988
2023-01-09 02:21:25 - train.py[line:551] - INFO: load:1.88 valid_run:3161.44 task_valid:3032.15 collect_output:107.95
2023-01-09 02:23:54 - train.py[line:549] - INFO: 4400 / 4988
2023-01-09 02:23:54 - train.py[line:551] - INFO: load:1.91 valid_run:3310.56 task_valid:3176.31 collect_output:111.90
2023-01-09 02:26:25 - train.py[line:549] - INFO: 4600 / 4988
2023-01-09 02:26:25 - train.py[line:551] - INFO: load:1.93 valid_run:3461.68 task_valid:3322.07 collect_output:116.25
2023-01-09 02:28:57 - train.py[line:549] - INFO: 4800 / 4988
2023-01-09 02:28:57 - train.py[line:551] - INFO: load:1.96 valid_run:3613.11 task_valid:3468.46 collect_output:120.28

====================================================================================================
SGG eval:     R @ 50: 0.3901;     R @ 100: 0.4586;     R @ 500: 0.4866;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2388;    mR @ 100: 0.2879;    mR @ 500: 0.3077;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3171) (covered in:0.6875) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6979) (playing:0.0000) (riding:0.5033) (says:0.0000) (sitting on:0.6970) (standing on:0.2000) (using:0.7000) (walking in:0.0000) (walking on:0.1892) (watching:0.1389) 
--------------------------------------------------------
====================================================================================================

2023-01-09 02:31:27 - train.py[line:487] - INFO: 0.4585619047619048

====================================================================================================
SGG eval:     R @ 50: 0.3901;     R @ 100: 0.4586;     R @ 500: 0.4866;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2388;    mR @ 100: 0.2879;    mR @ 500: 0.3077;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3171) (covered in:0.6875) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6979) (playing:0.0000) (riding:0.5033) (says:0.0000) (sitting on:0.6970) (standing on:0.2000) (using:0.7000) (walking in:0.0000) (walking on:0.1892) (watching:0.1389) 
--------------------------------------------------------
====================================================================================================

2023-01-09 02:31:28 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-09 02:31:28 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.396 | loss_v1 0 | loss_v2 0 | nll_loss 0.25 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.458562 | ppl 1.19 | vqa_score 0.3694 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 24000 | best_R@100 0.645421
2023-01-09 02:31:28 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 24000 updates
2023-01-09 02:31:28 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_24000.pt
2023-01-09 02:32:05 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_24000.pt
2023-01-09 02:33:23 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_24000.pt (epoch 1 @ 24000 updates, score 0.4585619047619048) (writing took 115.41830330900848 seconds)
2023-01-09 02:33:45 - progress_bar.py[line:274] - INFO: epoch 001:  24045 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4286, wps=0.6, ups=0, wpb=109.6, bsz=40, num_updates=24010, lr=4.12883e-05, gnorm=0.227, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=99781
2023-01-09 02:34:07 - progress_bar.py[line:274] - INFO: epoch 001:  24055 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5026, wps=100.9, ups=0.46, wpb=108.6, bsz=40, num_updates=24020, lr=4.12838e-05, gnorm=0.151, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=99803
2023-01-09 02:34:29 - progress_bar.py[line:274] - INFO: epoch 001:  24065 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5, wps=102.5, ups=0.47, wpb=108.2, bsz=40, num_updates=24030, lr=4.12793e-05, gnorm=0.187, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=99824
2023-01-09 02:34:50 - progress_bar.py[line:274] - INFO: epoch 001:  24075 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4563, wps=101.1, ups=0.47, wpb=108.7, bsz=40, num_updates=24040, lr=4.12748e-05, gnorm=0.193, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=99846
2023-01-09 02:35:12 - progress_bar.py[line:274] - INFO: epoch 001:  24085 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4975, wps=103.4, ups=0.47, wpb=109.6, bsz=40, num_updates=24050, lr=4.12703e-05, gnorm=0.333, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=99868
2023-01-09 02:35:34 - progress_bar.py[line:274] - INFO: epoch 001:  24095 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4589, wps=99.3, ups=0.46, wpb=108.4, bsz=40, num_updates=24060, lr=4.12658e-05, gnorm=0.222, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=99890
2023-01-09 02:35:56 - progress_bar.py[line:274] - INFO: epoch 001:  24105 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3971, wps=98.8, ups=0.46, wpb=107.3, bsz=40, num_updates=24070, lr=4.12613e-05, gnorm=0.624, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=99912
2023-01-09 02:36:17 - progress_bar.py[line:274] - INFO: epoch 001:  24115 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5126, wps=103, ups=0.47, wpb=108.4, bsz=40, num_updates=24080, lr=4.12568e-05, gnorm=0.366, clip=10, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=99933
2023-01-09 02:36:39 - progress_bar.py[line:274] - INFO: epoch 001:  24125 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3842, wps=101.5, ups=0.46, wpb=109.7, bsz=40, num_updates=24090, lr=4.12523e-05, gnorm=0.28, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=99955
2023-01-09 02:37:01 - progress_bar.py[line:274] - INFO: epoch 001:  24135 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4577, wps=101.9, ups=0.47, wpb=109.2, bsz=40, num_updates=24100, lr=4.12478e-05, gnorm=0.357, clip=10, loss_scale=512, train_wall=21, gb_free=9.3, ema_decay=0.9999, wall=99976
2023-01-09 02:37:22 - progress_bar.py[line:274] - INFO: epoch 001:  24145 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4229, wps=102.7, ups=0.47, wpb=109.7, bsz=40, num_updates=24110, lr=4.12433e-05, gnorm=0.306, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=99998
2023-01-09 02:37:45 - progress_bar.py[line:274] - INFO: epoch 001:  24155 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3365, wps=100.6, ups=0.46, wpb=109.4, bsz=40, num_updates=24120, lr=4.12388e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=100020
2023-01-09 02:38:06 - progress_bar.py[line:274] - INFO: epoch 001:  24165 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4466, wps=102.2, ups=0.47, wpb=109.3, bsz=40, num_updates=24130, lr=4.12343e-05, gnorm=0.348, clip=0, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=100042
2023-01-09 02:38:28 - progress_bar.py[line:274] - INFO: epoch 001:  24175 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3989, wps=101.4, ups=0.46, wpb=110, bsz=40, num_updates=24140, lr=4.12298e-05, gnorm=0.329, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=100064
2023-01-09 02:38:50 - progress_bar.py[line:274] - INFO: epoch 001:  24185 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.407, wps=100.3, ups=0.46, wpb=109, bsz=40, num_updates=24150, lr=4.12253e-05, gnorm=0.377, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=100086
2023-01-09 02:39:13 - progress_bar.py[line:274] - INFO: epoch 001:  24195 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4776, wps=100.1, ups=0.46, wpb=109.2, bsz=40, num_updates=24160, lr=4.12208e-05, gnorm=0.28, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=100108
2023-01-09 02:39:35 - progress_bar.py[line:274] - INFO: epoch 001:  24205 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3947, wps=102, ups=0.46, wpb=109.9, bsz=40, num_updates=24170, lr=4.12163e-05, gnorm=0.165, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=100130
2023-01-09 02:39:57 - progress_bar.py[line:274] - INFO: epoch 001:  24215 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4826, wps=100, ups=0.46, wpb=108.6, bsz=40, num_updates=24180, lr=4.12118e-05, gnorm=0.279, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=100153
2023-01-09 02:40:19 - progress_bar.py[line:274] - INFO: epoch 001:  24225 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.484, wps=103.6, ups=0.47, wpb=109.5, bsz=40, num_updates=24190, lr=4.12073e-05, gnorm=0.24, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=100174
2023-01-09 02:40:41 - progress_bar.py[line:274] - INFO: epoch 001:  24235 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4575, wps=99.7, ups=0.46, wpb=107.7, bsz=40, num_updates=24200, lr=4.12028e-05, gnorm=0.171, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=100197
2023-01-09 02:41:03 - progress_bar.py[line:274] - INFO: epoch 001:  24245 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4238, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=24210, lr=4.11983e-05, gnorm=0.217, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=100218
2023-01-09 02:41:25 - progress_bar.py[line:274] - INFO: epoch 001:  24255 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4106, wps=98.9, ups=0.45, wpb=108.7, bsz=40, num_updates=24220, lr=4.11938e-05, gnorm=0.334, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=100241
2023-01-09 02:41:47 - progress_bar.py[line:274] - INFO: epoch 001:  24265 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4585, wps=101.2, ups=0.47, wpb=108.2, bsz=40, num_updates=24230, lr=4.11894e-05, gnorm=0.354, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=100262
2023-01-09 02:42:08 - progress_bar.py[line:274] - INFO: epoch 001:  24275 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4385, wps=102.6, ups=0.46, wpb=110.8, bsz=40, num_updates=24240, lr=4.11849e-05, gnorm=0.172, clip=0, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=100284
2023-01-09 02:42:30 - progress_bar.py[line:274] - INFO: epoch 001:  24285 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4143, wps=99.8, ups=0.46, wpb=108.6, bsz=40, num_updates=24250, lr=4.11804e-05, gnorm=0.166, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=100306
2023-01-09 02:42:52 - progress_bar.py[line:274] - INFO: epoch 001:  24295 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4864, wps=98.4, ups=0.46, wpb=107.2, bsz=40, num_updates=24260, lr=4.11759e-05, gnorm=0.261, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=100328
2023-01-09 02:43:14 - progress_bar.py[line:274] - INFO: epoch 001:  24305 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4577, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=24270, lr=4.11714e-05, gnorm=0.25, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=100350
2023-01-09 02:43:31 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 02:43:38 - progress_bar.py[line:274] - INFO: epoch 001:  24316 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.095, nsentences=40, sample_size=108.095, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3982, wps=96.7, ups=0.43, wpb=108.1, bsz=40, num_updates=24280, lr=4.11669e-05, gnorm=0.197, clip=0, loss_scale=256, train_wall=23, gb_free=10.4, ema_decay=0.9999, wall=100374
2023-01-09 02:44:00 - progress_bar.py[line:274] - INFO: epoch 001:  24326 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4413, wps=102.2, ups=0.46, wpb=110.1, bsz=40, num_updates=24290, lr=4.11624e-05, gnorm=0.19, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=100396
2023-01-09 02:44:21 - progress_bar.py[line:274] - INFO: epoch 001:  24336 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3969, wps=102.1, ups=0.47, wpb=109.1, bsz=40, num_updates=24300, lr=4.11579e-05, gnorm=0.259, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=100417
2023-01-09 02:44:43 - progress_bar.py[line:274] - INFO: epoch 001:  24346 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4242, wps=103.8, ups=0.48, wpb=109, bsz=40, num_updates=24310, lr=4.11534e-05, gnorm=0.331, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=100439
2023-01-09 02:45:04 - progress_bar.py[line:274] - INFO: epoch 001:  24356 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4694, wps=105.1, ups=0.48, wpb=109.5, bsz=40, num_updates=24320, lr=4.11489e-05, gnorm=0.238, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=100460
2023-01-09 02:45:26 - progress_bar.py[line:274] - INFO: epoch 001:  24366 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4772, wps=100.4, ups=0.46, wpb=109.4, bsz=40, num_updates=24330, lr=4.11444e-05, gnorm=0.334, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=100482
2023-01-09 02:45:48 - progress_bar.py[line:274] - INFO: epoch 001:  24376 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4352, wps=101.3, ups=0.47, wpb=108.9, bsz=40, num_updates=24340, lr=4.11399e-05, gnorm=0.274, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=100503
2023-01-09 02:46:09 - progress_bar.py[line:274] - INFO: epoch 001:  24386 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4691, wps=102.9, ups=0.47, wpb=109.9, bsz=40, num_updates=24350, lr=4.11354e-05, gnorm=0.2, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=100525
2023-01-09 02:46:31 - progress_bar.py[line:274] - INFO: epoch 001:  24396 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4098, wps=101.5, ups=0.46, wpb=109.6, bsz=40, num_updates=24360, lr=4.11309e-05, gnorm=0.247, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=100547
2023-01-09 02:46:53 - progress_bar.py[line:274] - INFO: epoch 001:  24406 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3991, wps=100.2, ups=0.46, wpb=107.8, bsz=40, num_updates=24370, lr=4.11264e-05, gnorm=0.209, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=100569
2023-01-09 02:47:15 - progress_bar.py[line:274] - INFO: epoch 001:  24416 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.434, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=24380, lr=4.11219e-05, gnorm=0.148, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=100590
2023-01-09 02:47:36 - progress_bar.py[line:274] - INFO: epoch 001:  24426 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4439, wps=100.4, ups=0.46, wpb=108.2, bsz=40, num_updates=24390, lr=4.11174e-05, gnorm=0.196, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=100612
2023-01-09 02:47:58 - progress_bar.py[line:274] - INFO: epoch 001:  24436 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3951, wps=99.6, ups=0.46, wpb=107.6, bsz=40, num_updates=24400, lr=4.11129e-05, gnorm=0.286, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=100634
2023-01-09 02:48:19 - progress_bar.py[line:274] - INFO: epoch 001:  24446 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5103, wps=104.5, ups=0.48, wpb=109, bsz=40, num_updates=24410, lr=4.11084e-05, gnorm=0.296, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=100655
2023-01-09 02:48:41 - progress_bar.py[line:274] - INFO: epoch 001:  24456 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4951, wps=101.2, ups=0.46, wpb=109.1, bsz=40, num_updates=24420, lr=4.11039e-05, gnorm=0.247, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=100677
2023-01-09 02:49:03 - progress_bar.py[line:274] - INFO: epoch 001:  24466 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5102, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=24430, lr=4.10994e-05, gnorm=0.244, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=100699
2023-01-09 02:49:25 - progress_bar.py[line:274] - INFO: epoch 001:  24476 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4792, wps=101.9, ups=0.46, wpb=109.6, bsz=40, num_updates=24440, lr=4.10949e-05, gnorm=0.229, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=100721
2023-01-09 02:49:46 - progress_bar.py[line:274] - INFO: epoch 001:  24486 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4632, wps=102.4, ups=0.47, wpb=109.6, bsz=40, num_updates=24450, lr=4.10904e-05, gnorm=0.179, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=100742
2023-01-09 02:50:08 - progress_bar.py[line:274] - INFO: epoch 001:  24496 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4732, wps=99.9, ups=0.46, wpb=107.8, bsz=40, num_updates=24460, lr=4.10859e-05, gnorm=0.305, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=100764
2023-01-09 02:50:30 - progress_bar.py[line:274] - INFO: epoch 001:  24506 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4946, wps=102.5, ups=0.46, wpb=110.5, bsz=40, num_updates=24470, lr=4.10814e-05, gnorm=0.245, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=100786
2023-01-09 02:50:52 - progress_bar.py[line:274] - INFO: epoch 001:  24516 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4198, wps=100.2, ups=0.46, wpb=107.9, bsz=40, num_updates=24480, lr=4.1077e-05, gnorm=0.362, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=100808
2023-01-09 02:51:13 - progress_bar.py[line:274] - INFO: epoch 001:  24526 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4415, wps=103.8, ups=0.47, wpb=110.8, bsz=40, num_updates=24490, lr=4.10725e-05, gnorm=0.219, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=100829
2023-01-09 02:51:35 - progress_bar.py[line:274] - INFO: epoch 001:  24536 / 115845 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.5156, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=24500, lr=4.1068e-05, gnorm=0.155, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=100851
2023-01-09 02:51:57 - progress_bar.py[line:274] - INFO: epoch 001:  24546 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3838, wps=102.6, ups=0.46, wpb=110.4, bsz=40, num_updates=24510, lr=4.10635e-05, gnorm=0.173, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=100873
2023-01-09 02:52:18 - progress_bar.py[line:274] - INFO: epoch 001:  24556 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4115, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=24520, lr=4.1059e-05, gnorm=0.262, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=100894
2023-01-09 02:52:40 - progress_bar.py[line:274] - INFO: epoch 001:  24566 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3961, wps=99, ups=0.46, wpb=107.8, bsz=40, num_updates=24530, lr=4.10545e-05, gnorm=0.277, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=100916
2023-01-09 02:53:02 - progress_bar.py[line:274] - INFO: epoch 001:  24576 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.487, wps=103, ups=0.47, wpb=109, bsz=40, num_updates=24540, lr=4.105e-05, gnorm=0.216, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=100938
2023-01-09 02:53:24 - progress_bar.py[line:274] - INFO: epoch 001:  24586 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.535, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=24550, lr=4.10455e-05, gnorm=0.195, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=100960
2023-01-09 02:53:45 - progress_bar.py[line:274] - INFO: epoch 001:  24596 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4279, wps=102.8, ups=0.47, wpb=109.1, bsz=40, num_updates=24560, lr=4.1041e-05, gnorm=0.203, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=100981
2023-01-09 02:54:07 - progress_bar.py[line:274] - INFO: epoch 001:  24606 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.525, wps=102.1, ups=0.46, wpb=110.3, bsz=40, num_updates=24570, lr=4.10365e-05, gnorm=0.265, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=101003
2023-01-09 02:54:29 - progress_bar.py[line:274] - INFO: epoch 001:  24616 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4747, wps=101.2, ups=0.46, wpb=109.2, bsz=40, num_updates=24580, lr=4.1032e-05, gnorm=0.26, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=101025
2023-01-09 02:54:51 - progress_bar.py[line:274] - INFO: epoch 001:  24626 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3842, wps=101.5, ups=0.47, wpb=108.3, bsz=40, num_updates=24590, lr=4.10275e-05, gnorm=0.244, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=101047
2023-01-09 02:55:13 - progress_bar.py[line:274] - INFO: epoch 001:  24636 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4364, wps=99.1, ups=0.46, wpb=108.3, bsz=40, num_updates=24600, lr=4.1023e-05, gnorm=0.228, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=101069
2023-01-09 02:55:35 - progress_bar.py[line:274] - INFO: epoch 001:  24646 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.463, wps=100, ups=0.46, wpb=108.6, bsz=40, num_updates=24610, lr=4.10185e-05, gnorm=0.24, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=101091
2023-01-09 02:55:57 - progress_bar.py[line:274] - INFO: epoch 001:  24656 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4817, wps=98.2, ups=0.46, wpb=107, bsz=40, num_updates=24620, lr=4.1014e-05, gnorm=0.36, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=101113
2023-01-09 02:56:19 - progress_bar.py[line:274] - INFO: epoch 001:  24666 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4853, wps=99, ups=0.46, wpb=107.6, bsz=40, num_updates=24630, lr=4.10095e-05, gnorm=0.28, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=101135
2023-01-09 02:56:41 - progress_bar.py[line:274] - INFO: epoch 001:  24676 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4428, wps=100.5, ups=0.46, wpb=108.6, bsz=40, num_updates=24640, lr=4.1005e-05, gnorm=0.236, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=101157
2023-01-09 02:57:03 - progress_bar.py[line:274] - INFO: epoch 001:  24686 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4375, wps=98.5, ups=0.46, wpb=107.9, bsz=40, num_updates=24650, lr=4.10005e-05, gnorm=0.278, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=101179
2023-01-09 02:57:25 - progress_bar.py[line:274] - INFO: epoch 001:  24696 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4615, wps=102.3, ups=0.47, wpb=109.1, bsz=40, num_updates=24660, lr=4.0996e-05, gnorm=0.279, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=101201
2023-01-09 02:57:47 - progress_bar.py[line:274] - INFO: epoch 001:  24706 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4237, wps=101.2, ups=0.46, wpb=109.8, bsz=40, num_updates=24670, lr=4.09915e-05, gnorm=0.24, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=101223
2023-01-09 02:58:08 - progress_bar.py[line:274] - INFO: epoch 001:  24716 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5049, wps=102.2, ups=0.47, wpb=108.9, bsz=40, num_updates=24680, lr=4.0987e-05, gnorm=0.181, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=101244
2023-01-09 02:58:30 - progress_bar.py[line:274] - INFO: epoch 001:  24726 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4631, wps=104.3, ups=0.47, wpb=109.9, bsz=40, num_updates=24690, lr=4.09825e-05, gnorm=0.196, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=101265
2023-01-09 02:58:52 - progress_bar.py[line:274] - INFO: epoch 001:  24736 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4928, wps=99.2, ups=0.46, wpb=108.1, bsz=40, num_updates=24700, lr=4.0978e-05, gnorm=0.304, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=101288
2023-01-09 02:59:14 - progress_bar.py[line:274] - INFO: epoch 001:  24746 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5052, wps=102.8, ups=0.46, wpb=111, bsz=40, num_updates=24710, lr=4.09735e-05, gnorm=0.362, clip=0, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=101309
2023-01-09 02:59:36 - progress_bar.py[line:274] - INFO: epoch 001:  24756 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4819, wps=101.5, ups=0.47, wpb=109, bsz=40, num_updates=24720, lr=4.09691e-05, gnorm=0.214, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=101331
2023-01-09 02:59:57 - progress_bar.py[line:274] - INFO: epoch 001:  24766 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4851, wps=102.2, ups=0.47, wpb=109.2, bsz=40, num_updates=24730, lr=4.09646e-05, gnorm=0.213, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=101353
2023-01-09 03:00:18 - progress_bar.py[line:274] - INFO: epoch 001:  24776 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4531, wps=106.8, ups=0.49, wpb=110, bsz=40, num_updates=24740, lr=4.09601e-05, gnorm=0.224, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=101374
2023-01-09 03:00:40 - progress_bar.py[line:274] - INFO: epoch 001:  24786 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4412, wps=100.2, ups=0.46, wpb=108.4, bsz=40, num_updates=24750, lr=4.09556e-05, gnorm=0.374, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=101396
2023-01-09 03:01:02 - progress_bar.py[line:274] - INFO: epoch 001:  24796 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4868, wps=101.1, ups=0.46, wpb=109.9, bsz=40, num_updates=24760, lr=4.09511e-05, gnorm=0.41, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=101418
2023-01-09 03:01:23 - progress_bar.py[line:274] - INFO: epoch 001:  24806 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.455, wps=102.2, ups=0.47, wpb=108.7, bsz=40, num_updates=24770, lr=4.09466e-05, gnorm=0.425, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=101439
2023-01-09 03:01:45 - progress_bar.py[line:274] - INFO: epoch 001:  24816 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4554, wps=101.3, ups=0.47, wpb=107.9, bsz=40, num_updates=24780, lr=4.09421e-05, gnorm=0.193, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=101461
2023-01-09 03:02:07 - progress_bar.py[line:274] - INFO: epoch 001:  24826 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.481, wps=100.4, ups=0.46, wpb=108.2, bsz=40, num_updates=24790, lr=4.09376e-05, gnorm=0.24, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=101483
2023-01-09 03:02:29 - progress_bar.py[line:274] - INFO: epoch 001:  24836 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4646, wps=102.3, ups=0.47, wpb=107.9, bsz=40, num_updates=24800, lr=4.09331e-05, gnorm=0.157, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=101504
2023-01-09 03:02:51 - progress_bar.py[line:274] - INFO: epoch 001:  24846 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4221, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=24810, lr=4.09286e-05, gnorm=0.184, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=101526
2023-01-09 03:03:13 - progress_bar.py[line:274] - INFO: epoch 001:  24856 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4162, wps=99.5, ups=0.46, wpb=109, bsz=40, num_updates=24820, lr=4.09241e-05, gnorm=0.21, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=101549
2023-01-09 03:03:35 - progress_bar.py[line:274] - INFO: epoch 001:  24866 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4455, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=24830, lr=4.09196e-05, gnorm=0.336, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=101570
2023-01-09 03:03:57 - progress_bar.py[line:274] - INFO: epoch 001:  24876 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4569, wps=98.8, ups=0.45, wpb=108.8, bsz=40, num_updates=24840, lr=4.09151e-05, gnorm=0.152, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=101593
2023-01-09 03:04:18 - progress_bar.py[line:274] - INFO: epoch 001:  24886 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4796, wps=103.9, ups=0.48, wpb=108.7, bsz=40, num_updates=24850, lr=4.09106e-05, gnorm=0.162, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=101614
2023-01-09 03:04:39 - progress_bar.py[line:274] - INFO: epoch 001:  24896 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3878, wps=105.3, ups=0.48, wpb=109.8, bsz=40, num_updates=24860, lr=4.09061e-05, gnorm=0.224, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=101635
2023-01-09 03:05:01 - progress_bar.py[line:274] - INFO: epoch 001:  24906 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4648, wps=98.5, ups=0.46, wpb=107.7, bsz=40, num_updates=24870, lr=4.09016e-05, gnorm=0.196, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=101657
2023-01-09 03:05:23 - progress_bar.py[line:274] - INFO: epoch 001:  24916 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.47, wps=102.6, ups=0.47, wpb=109.4, bsz=40, num_updates=24880, lr=4.08971e-05, gnorm=0.326, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=101679
2023-01-09 03:05:45 - progress_bar.py[line:274] - INFO: epoch 001:  24926 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4755, wps=101.7, ups=0.47, wpb=108.7, bsz=40, num_updates=24890, lr=4.08926e-05, gnorm=0.206, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=101701
2023-01-09 03:06:07 - progress_bar.py[line:274] - INFO: epoch 001:  24936 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4416, wps=101.4, ups=0.46, wpb=109.6, bsz=40, num_updates=24900, lr=4.08881e-05, gnorm=0.237, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=101722
2023-01-09 03:06:29 - progress_bar.py[line:274] - INFO: epoch 001:  24946 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4921, wps=101.6, ups=0.47, wpb=108.8, bsz=40, num_updates=24910, lr=4.08836e-05, gnorm=0.277, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=101744
2023-01-09 03:06:50 - progress_bar.py[line:274] - INFO: epoch 001:  24956 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4328, wps=104.6, ups=0.48, wpb=109.6, bsz=40, num_updates=24920, lr=4.08791e-05, gnorm=0.238, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=101766
2023-01-09 03:07:12 - progress_bar.py[line:274] - INFO: epoch 001:  24966 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4341, wps=99.5, ups=0.46, wpb=107.9, bsz=40, num_updates=24930, lr=4.08746e-05, gnorm=0.241, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=101788
2023-01-09 03:07:34 - progress_bar.py[line:274] - INFO: epoch 001:  24976 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4195, wps=101.6, ups=0.46, wpb=109.3, bsz=40, num_updates=24940, lr=4.08701e-05, gnorm=0.183, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=101809
2023-01-09 03:07:55 - progress_bar.py[line:274] - INFO: epoch 001:  24986 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4712, wps=104.1, ups=0.47, wpb=110.4, bsz=40, num_updates=24950, lr=4.08656e-05, gnorm=0.178, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=101831
2023-01-09 03:08:17 - progress_bar.py[line:274] - INFO: epoch 001:  24996 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4179, wps=101, ups=0.46, wpb=108.6, bsz=40, num_updates=24960, lr=4.08611e-05, gnorm=0.31, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=101853
2023-01-09 03:08:39 - progress_bar.py[line:274] - INFO: epoch 001:  25006 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5051, wps=100.5, ups=0.46, wpb=108.7, bsz=40, num_updates=24970, lr=4.08567e-05, gnorm=0.238, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=101875
2023-01-09 03:09:01 - progress_bar.py[line:274] - INFO: epoch 001:  25016 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4624, wps=102.4, ups=0.46, wpb=110.5, bsz=40, num_updates=24980, lr=4.08522e-05, gnorm=0.21, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=101896
2023-01-09 03:09:22 - progress_bar.py[line:274] - INFO: epoch 001:  25026 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4524, wps=100.6, ups=0.46, wpb=108.3, bsz=40, num_updates=24990, lr=4.08477e-05, gnorm=0.252, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=101918
2023-01-09 03:09:45 - progress_bar.py[line:274] - INFO: epoch 001:  25036 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4162, wps=101.2, ups=0.46, wpb=110.2, bsz=40, num_updates=25000, lr=4.08432e-05, gnorm=0.34, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=101940
2023-01-09 03:10:06 - progress_bar.py[line:274] - INFO: epoch 001:  25046 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3913, wps=102.2, ups=0.46, wpb=110.3, bsz=40, num_updates=25010, lr=4.08387e-05, gnorm=0.252, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=101962
2023-01-09 03:10:28 - progress_bar.py[line:274] - INFO: epoch 001:  25056 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4895, wps=101.7, ups=0.47, wpb=109.3, bsz=40, num_updates=25020, lr=4.08342e-05, gnorm=0.259, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=101984
2023-01-09 03:10:50 - progress_bar.py[line:274] - INFO: epoch 001:  25066 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4332, wps=97.5, ups=0.46, wpb=107.1, bsz=40, num_updates=25030, lr=4.08297e-05, gnorm=0.222, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=102006
2023-01-09 03:11:12 - progress_bar.py[line:274] - INFO: epoch 001:  25076 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4925, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=25040, lr=4.08252e-05, gnorm=0.211, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=102028
2023-01-09 03:11:33 - progress_bar.py[line:274] - INFO: epoch 001:  25086 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4905, wps=104.1, ups=0.48, wpb=109.2, bsz=40, num_updates=25050, lr=4.08207e-05, gnorm=0.197, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=102049
2023-01-09 03:11:56 - progress_bar.py[line:274] - INFO: epoch 001:  25096 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5282, wps=99, ups=0.45, wpb=109.6, bsz=40, num_updates=25060, lr=4.08162e-05, gnorm=0.383, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=102072
2023-01-09 03:12:17 - progress_bar.py[line:274] - INFO: epoch 001:  25106 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4129, wps=102.6, ups=0.47, wpb=108.4, bsz=40, num_updates=25070, lr=4.08117e-05, gnorm=0.236, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=102093
2023-01-09 03:12:39 - progress_bar.py[line:274] - INFO: epoch 001:  25116 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4798, wps=100.3, ups=0.46, wpb=109.2, bsz=40, num_updates=25080, lr=4.08072e-05, gnorm=0.173, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=102115
2023-01-09 03:13:01 - progress_bar.py[line:274] - INFO: epoch 001:  25126 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4712, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=25090, lr=4.08027e-05, gnorm=0.276, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=102137
2023-01-09 03:13:22 - progress_bar.py[line:274] - INFO: epoch 001:  25136 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4257, wps=105.2, ups=0.49, wpb=108.1, bsz=40, num_updates=25100, lr=4.07982e-05, gnorm=0.193, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=102158
2023-01-09 03:13:44 - progress_bar.py[line:274] - INFO: epoch 001:  25146 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5, wps=99.8, ups=0.46, wpb=107.8, bsz=40, num_updates=25110, lr=4.07937e-05, gnorm=0.275, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=102180
2023-01-09 03:14:06 - progress_bar.py[line:274] - INFO: epoch 001:  25156 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.7, nsentences=40, sample_size=106.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4266, wps=98.9, ups=0.46, wpb=106.7, bsz=40, num_updates=25120, lr=4.07892e-05, gnorm=0.401, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=102202
2023-01-09 03:14:27 - progress_bar.py[line:274] - INFO: epoch 001:  25166 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4171, wps=104.3, ups=0.48, wpb=109.1, bsz=40, num_updates=25130, lr=4.07847e-05, gnorm=0.264, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=102223
2023-01-09 03:14:49 - progress_bar.py[line:274] - INFO: epoch 001:  25176 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4767, wps=102.1, ups=0.47, wpb=109.6, bsz=40, num_updates=25140, lr=4.07802e-05, gnorm=0.294, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=102245
2023-01-09 03:15:11 - progress_bar.py[line:274] - INFO: epoch 001:  25186 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3608, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=25150, lr=4.07757e-05, gnorm=0.35, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=102266
2023-01-09 03:15:32 - progress_bar.py[line:274] - INFO: epoch 001:  25196 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4615, wps=101.2, ups=0.47, wpb=108, bsz=40, num_updates=25160, lr=4.07712e-05, gnorm=0.28, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=102288
2023-01-09 03:15:54 - progress_bar.py[line:274] - INFO: epoch 001:  25206 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4724, wps=103.7, ups=0.47, wpb=110, bsz=40, num_updates=25170, lr=4.07667e-05, gnorm=0.157, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=102309
2023-01-09 03:16:15 - progress_bar.py[line:274] - INFO: epoch 001:  25216 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4667, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=25180, lr=4.07622e-05, gnorm=0.308, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=102331
2023-01-09 03:16:37 - progress_bar.py[line:274] - INFO: epoch 001:  25226 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4124, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=25190, lr=4.07577e-05, gnorm=0.281, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=102353
2023-01-09 03:16:50 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 03:17:01 - progress_bar.py[line:274] - INFO: epoch 001:  25237 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.571, nsentences=40, sample_size=109.571, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4749, wps=99.4, ups=0.43, wpb=109.6, bsz=40, num_updates=25200, lr=4.07532e-05, gnorm=0.284, clip=0, loss_scale=256, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=102376
2023-01-09 03:17:22 - progress_bar.py[line:274] - INFO: epoch 001:  25247 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4433, wps=103.2, ups=0.47, wpb=110, bsz=40, num_updates=25210, lr=4.07488e-05, gnorm=0.223, clip=0, loss_scale=256, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=102398
2023-01-09 03:17:44 - progress_bar.py[line:274] - INFO: epoch 001:  25257 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4518, wps=99.2, ups=0.46, wpb=109, bsz=40, num_updates=25220, lr=4.07443e-05, gnorm=0.166, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=102420
2023-01-09 03:18:06 - progress_bar.py[line:274] - INFO: epoch 001:  25267 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4634, wps=102.9, ups=0.47, wpb=108.9, bsz=40, num_updates=25230, lr=4.07398e-05, gnorm=0.256, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=102442
2023-01-09 03:18:28 - progress_bar.py[line:274] - INFO: epoch 001:  25277 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3881, wps=102.8, ups=0.47, wpb=109.5, bsz=40, num_updates=25240, lr=4.07353e-05, gnorm=0.247, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=102463
2023-01-09 03:18:50 - progress_bar.py[line:274] - INFO: epoch 001:  25287 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5073, wps=100.4, ups=0.46, wpb=108.9, bsz=40, num_updates=25250, lr=4.07308e-05, gnorm=0.239, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=102485
2023-01-09 03:19:11 - progress_bar.py[line:274] - INFO: epoch 001:  25297 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.475, wps=104.7, ups=0.48, wpb=109, bsz=40, num_updates=25260, lr=4.07263e-05, gnorm=0.299, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=102506
2023-01-09 03:19:32 - progress_bar.py[line:274] - INFO: epoch 001:  25307 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5022, wps=102.4, ups=0.48, wpb=107.5, bsz=40, num_updates=25270, lr=4.07218e-05, gnorm=0.221, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=102528
2023-01-09 03:19:54 - progress_bar.py[line:274] - INFO: epoch 001:  25317 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4076, wps=102.1, ups=0.47, wpb=109, bsz=40, num_updates=25280, lr=4.07173e-05, gnorm=0.27, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=102549
2023-01-09 03:20:16 - progress_bar.py[line:274] - INFO: epoch 001:  25327 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4884, wps=100.7, ups=0.46, wpb=109.5, bsz=40, num_updates=25290, lr=4.07128e-05, gnorm=0.205, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=102572
2023-01-09 03:20:38 - progress_bar.py[line:274] - INFO: epoch 001:  25337 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4868, wps=102.1, ups=0.46, wpb=110, bsz=40, num_updates=25300, lr=4.07083e-05, gnorm=0.121, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=102593
2023-01-09 03:20:59 - progress_bar.py[line:274] - INFO: epoch 001:  25347 / 115845 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.4835, wps=105.9, ups=0.48, wpb=110.7, bsz=40, num_updates=25310, lr=4.07038e-05, gnorm=0.197, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=102615
2023-01-09 03:21:21 - progress_bar.py[line:274] - INFO: epoch 001:  25357 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4806, wps=100.3, ups=0.46, wpb=108.5, bsz=40, num_updates=25320, lr=4.06993e-05, gnorm=0.13, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=102636
2023-01-09 03:21:43 - progress_bar.py[line:274] - INFO: epoch 001:  25367 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4365, wps=98.9, ups=0.46, wpb=108.2, bsz=40, num_updates=25330, lr=4.06948e-05, gnorm=0.194, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=102659
2023-01-09 03:22:04 - progress_bar.py[line:274] - INFO: epoch 001:  25377 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4238, wps=104.4, ups=0.48, wpb=109.3, bsz=40, num_updates=25340, lr=4.06903e-05, gnorm=0.277, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=102680
2023-01-09 03:22:26 - progress_bar.py[line:274] - INFO: epoch 001:  25387 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4724, wps=99.8, ups=0.46, wpb=109.5, bsz=40, num_updates=25350, lr=4.06858e-05, gnorm=0.15, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=102702
2023-01-09 03:22:48 - progress_bar.py[line:274] - INFO: epoch 001:  25397 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4439, wps=100.7, ups=0.46, wpb=109.5, bsz=40, num_updates=25360, lr=4.06813e-05, gnorm=0.157, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=102724
2023-01-09 03:23:10 - progress_bar.py[line:274] - INFO: epoch 001:  25407 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4129, wps=102.2, ups=0.47, wpb=109.2, bsz=40, num_updates=25370, lr=4.06768e-05, gnorm=0.152, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=102746
2023-01-09 03:23:31 - progress_bar.py[line:274] - INFO: epoch 001:  25417 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3962, wps=103.3, ups=0.47, wpb=109.2, bsz=40, num_updates=25380, lr=4.06723e-05, gnorm=0.228, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=102767
2023-01-09 03:23:54 - progress_bar.py[line:274] - INFO: epoch 001:  25427 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3918, wps=99.7, ups=0.46, wpb=108.4, bsz=40, num_updates=25390, lr=4.06678e-05, gnorm=0.319, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=102789
2023-01-09 03:24:15 - progress_bar.py[line:274] - INFO: epoch 001:  25437 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4764, wps=103.9, ups=0.48, wpb=108, bsz=40, num_updates=25400, lr=4.06633e-05, gnorm=0.318, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=102810
2023-01-09 03:24:37 - progress_bar.py[line:274] - INFO: epoch 001:  25447 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4145, wps=101.4, ups=0.46, wpb=110.4, bsz=40, num_updates=25410, lr=4.06588e-05, gnorm=0.155, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=102832
2023-01-09 03:24:58 - progress_bar.py[line:274] - INFO: epoch 001:  25457 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4235, wps=103.3, ups=0.47, wpb=110.5, bsz=40, num_updates=25420, lr=4.06543e-05, gnorm=0.256, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=102854
2023-01-09 03:25:20 - progress_bar.py[line:274] - INFO: epoch 001:  25467 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4718, wps=100.7, ups=0.46, wpb=109.5, bsz=40, num_updates=25430, lr=4.06498e-05, gnorm=0.228, clip=0, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=102876
2023-01-09 03:25:42 - progress_bar.py[line:274] - INFO: epoch 001:  25477 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4641, wps=102.7, ups=0.47, wpb=108.8, bsz=40, num_updates=25440, lr=4.06453e-05, gnorm=0.206, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=102898
2023-01-09 03:26:03 - progress_bar.py[line:274] - INFO: epoch 001:  25487 / 115845 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.44, wps=104.5, ups=0.47, wpb=111.3, bsz=40, num_updates=25450, lr=4.06408e-05, gnorm=0.248, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=102919
2023-01-09 03:26:26 - progress_bar.py[line:274] - INFO: epoch 001:  25497 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.485, wps=99.2, ups=0.46, wpb=108.4, bsz=40, num_updates=25460, lr=4.06364e-05, gnorm=0.156, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=102941
2023-01-09 03:26:48 - progress_bar.py[line:274] - INFO: epoch 001:  25507 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4627, wps=100.2, ups=0.46, wpb=109.4, bsz=40, num_updates=25470, lr=4.06319e-05, gnorm=0.199, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=102963
2023-01-09 03:27:10 - progress_bar.py[line:274] - INFO: epoch 001:  25517 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.435, wps=101.3, ups=0.46, wpb=110.3, bsz=40, num_updates=25480, lr=4.06274e-05, gnorm=0.177, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=102986
2023-01-09 03:27:32 - progress_bar.py[line:274] - INFO: epoch 001:  25527 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5194, wps=98.6, ups=0.46, wpb=107.8, bsz=40, num_updates=25490, lr=4.06229e-05, gnorm=0.247, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=103008
2023-01-09 03:27:53 - progress_bar.py[line:274] - INFO: epoch 001:  25537 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4722, wps=104.2, ups=0.48, wpb=109.2, bsz=40, num_updates=25500, lr=4.06184e-05, gnorm=0.206, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=103029
2023-01-09 03:28:15 - progress_bar.py[line:274] - INFO: epoch 001:  25547 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4532, wps=102.3, ups=0.47, wpb=108.3, bsz=40, num_updates=25510, lr=4.06139e-05, gnorm=0.172, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=103050
2023-01-09 03:28:36 - progress_bar.py[line:274] - INFO: epoch 001:  25557 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4709, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=25520, lr=4.06094e-05, gnorm=0.16, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=103072
2023-01-09 03:28:58 - progress_bar.py[line:274] - INFO: epoch 001:  25567 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4663, wps=99, ups=0.46, wpb=107.7, bsz=40, num_updates=25530, lr=4.06049e-05, gnorm=0.343, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=103094
2023-01-09 03:29:20 - progress_bar.py[line:274] - INFO: epoch 001:  25577 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4619, wps=102.2, ups=0.48, wpb=107.4, bsz=40, num_updates=25540, lr=4.06004e-05, gnorm=0.18, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=103115
2023-01-09 03:29:41 - progress_bar.py[line:274] - INFO: epoch 001:  25587 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.481, wps=101.2, ups=0.47, wpb=108.2, bsz=40, num_updates=25550, lr=4.05959e-05, gnorm=0.359, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=103137
2023-01-09 03:30:04 - progress_bar.py[line:274] - INFO: epoch 001:  25597 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4439, wps=98.7, ups=0.45, wpb=108.8, bsz=40, num_updates=25560, lr=4.05914e-05, gnorm=0.252, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=103159
2023-01-09 03:30:26 - progress_bar.py[line:274] - INFO: epoch 001:  25607 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4439, wps=99.8, ups=0.46, wpb=108.7, bsz=40, num_updates=25570, lr=4.05869e-05, gnorm=0.257, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=103181
2023-01-09 03:30:48 - progress_bar.py[line:274] - INFO: epoch 001:  25617 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4337, wps=100.8, ups=0.46, wpb=109.4, bsz=40, num_updates=25580, lr=4.05824e-05, gnorm=0.185, clip=0, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=103203
2023-01-09 03:31:10 - progress_bar.py[line:274] - INFO: epoch 001:  25627 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4249, wps=100.7, ups=0.46, wpb=109.9, bsz=40, num_updates=25590, lr=4.05779e-05, gnorm=0.204, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=103226
2023-01-09 03:31:31 - progress_bar.py[line:274] - INFO: epoch 001:  25637 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4902, wps=102.4, ups=0.47, wpb=109.3, bsz=40, num_updates=25600, lr=4.05734e-05, gnorm=0.189, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=103247
2023-01-09 03:31:53 - progress_bar.py[line:274] - INFO: epoch 001:  25647 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4579, wps=103, ups=0.47, wpb=110.2, bsz=40, num_updates=25610, lr=4.05689e-05, gnorm=0.351, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=103269
2023-01-09 03:32:15 - progress_bar.py[line:274] - INFO: epoch 001:  25657 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4474, wps=101.3, ups=0.46, wpb=109.7, bsz=40, num_updates=25620, lr=4.05644e-05, gnorm=0.23, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=103291
2023-01-09 03:32:37 - progress_bar.py[line:274] - INFO: epoch 001:  25667 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4225, wps=102.9, ups=0.47, wpb=109.6, bsz=40, num_updates=25630, lr=4.05599e-05, gnorm=0.213, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=103312
2023-01-09 03:32:59 - progress_bar.py[line:274] - INFO: epoch 001:  25677 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4333, wps=100.8, ups=0.46, wpb=108.8, bsz=40, num_updates=25640, lr=4.05554e-05, gnorm=0.175, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=103334
2023-01-09 03:33:20 - progress_bar.py[line:274] - INFO: epoch 001:  25687 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.466, wps=101.8, ups=0.47, wpb=108.6, bsz=40, num_updates=25650, lr=4.05509e-05, gnorm=0.258, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=103356
2023-01-09 03:33:42 - progress_bar.py[line:274] - INFO: epoch 001:  25697 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4952, wps=102.1, ups=0.47, wpb=109.4, bsz=40, num_updates=25660, lr=4.05464e-05, gnorm=0.26, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=103378
2023-01-09 03:34:03 - progress_bar.py[line:274] - INFO: epoch 001:  25707 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5155, wps=102.7, ups=0.47, wpb=108.9, bsz=40, num_updates=25670, lr=4.05419e-05, gnorm=0.443, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=103399
2023-01-09 03:34:25 - progress_bar.py[line:274] - INFO: epoch 001:  25717 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5111, wps=102.2, ups=0.46, wpb=110.3, bsz=40, num_updates=25680, lr=4.05374e-05, gnorm=0.157, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=103421
2023-01-09 03:34:46 - progress_bar.py[line:274] - INFO: epoch 001:  25727 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4709, wps=104.4, ups=0.48, wpb=109.2, bsz=40, num_updates=25690, lr=4.05329e-05, gnorm=0.217, clip=0, loss_scale=256, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=103442
2023-01-09 03:35:08 - progress_bar.py[line:274] - INFO: epoch 001:  25737 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4747, wps=99.5, ups=0.46, wpb=107.5, bsz=40, num_updates=25700, lr=4.05285e-05, gnorm=0.318, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=103464
2023-01-09 03:35:30 - progress_bar.py[line:274] - INFO: epoch 001:  25747 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4623, wps=103.9, ups=0.47, wpb=110, bsz=40, num_updates=25710, lr=4.0524e-05, gnorm=0.237, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=103485
2023-01-09 03:35:52 - progress_bar.py[line:274] - INFO: epoch 001:  25757 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4916, wps=100.9, ups=0.46, wpb=109.7, bsz=40, num_updates=25720, lr=4.05195e-05, gnorm=0.249, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=103507
2023-01-09 03:36:14 - progress_bar.py[line:274] - INFO: epoch 001:  25767 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4889, wps=100.2, ups=0.46, wpb=109.8, bsz=40, num_updates=25730, lr=4.0515e-05, gnorm=0.176, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=103530
2023-01-09 03:36:36 - progress_bar.py[line:274] - INFO: epoch 001:  25777 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4607, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=25740, lr=4.05105e-05, gnorm=0.185, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=103551
2023-01-09 03:36:57 - progress_bar.py[line:274] - INFO: epoch 001:  25787 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4492, wps=103.7, ups=0.47, wpb=109.7, bsz=40, num_updates=25750, lr=4.0506e-05, gnorm=0.258, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=103573
2023-01-09 03:37:19 - progress_bar.py[line:274] - INFO: epoch 001:  25797 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5, wps=102.7, ups=0.47, wpb=109.5, bsz=40, num_updates=25760, lr=4.05015e-05, gnorm=0.193, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=103595
2023-01-09 03:37:40 - progress_bar.py[line:274] - INFO: epoch 001:  25807 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4175, wps=101.6, ups=0.47, wpb=108.8, bsz=40, num_updates=25770, lr=4.0497e-05, gnorm=0.243, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=103616
2023-01-09 03:38:02 - progress_bar.py[line:274] - INFO: epoch 001:  25817 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4183, wps=99.4, ups=0.46, wpb=108, bsz=40, num_updates=25780, lr=4.04925e-05, gnorm=0.152, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=103638
2023-01-09 03:38:24 - progress_bar.py[line:274] - INFO: epoch 001:  25827 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4874, wps=103.3, ups=0.47, wpb=109.3, bsz=40, num_updates=25790, lr=4.0488e-05, gnorm=0.183, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=103660
2023-01-09 03:38:46 - progress_bar.py[line:274] - INFO: epoch 001:  25837 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4833, wps=98.1, ups=0.46, wpb=107.8, bsz=40, num_updates=25800, lr=4.04835e-05, gnorm=0.223, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=103682
2023-01-09 03:39:08 - progress_bar.py[line:274] - INFO: epoch 001:  25847 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.44, wps=101, ups=0.46, wpb=109.2, bsz=40, num_updates=25810, lr=4.0479e-05, gnorm=0.152, clip=0, loss_scale=512, train_wall=22, gb_free=9.5, ema_decay=0.9999, wall=103704
2023-01-09 03:39:30 - progress_bar.py[line:274] - INFO: epoch 001:  25857 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4869, wps=102.3, ups=0.47, wpb=108.6, bsz=40, num_updates=25820, lr=4.04745e-05, gnorm=0.205, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=103725
2023-01-09 03:39:52 - progress_bar.py[line:274] - INFO: epoch 001:  25867 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4242, wps=99.8, ups=0.46, wpb=108.9, bsz=40, num_updates=25830, lr=4.047e-05, gnorm=0.203, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=103748
2023-01-09 03:40:14 - progress_bar.py[line:274] - INFO: epoch 001:  25877 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4272, wps=98.8, ups=0.46, wpb=108.4, bsz=40, num_updates=25840, lr=4.04655e-05, gnorm=0.226, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=103770
2023-01-09 03:40:35 - progress_bar.py[line:274] - INFO: epoch 001:  25887 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3963, wps=102.8, ups=0.47, wpb=108.3, bsz=40, num_updates=25850, lr=4.0461e-05, gnorm=0.246, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=103791
2023-01-09 03:40:57 - progress_bar.py[line:274] - INFO: epoch 001:  25897 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4755, wps=101.8, ups=0.47, wpb=108.2, bsz=40, num_updates=25860, lr=4.04565e-05, gnorm=0.181, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=103813
2023-01-09 03:41:19 - progress_bar.py[line:274] - INFO: epoch 001:  25907 / 115845 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.5083, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=25870, lr=4.0452e-05, gnorm=0.213, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=103835
2023-01-09 03:41:41 - progress_bar.py[line:274] - INFO: epoch 001:  25917 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4471, wps=99.1, ups=0.46, wpb=107.8, bsz=40, num_updates=25880, lr=4.04475e-05, gnorm=0.464, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=103857
2023-01-09 03:42:03 - progress_bar.py[line:274] - INFO: epoch 001:  25927 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4851, wps=97.5, ups=0.46, wpb=107, bsz=40, num_updates=25890, lr=4.0443e-05, gnorm=0.218, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=103879
2023-01-09 03:42:25 - progress_bar.py[line:274] - INFO: epoch 001:  25937 / 115845 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4302, wps=102.7, ups=0.46, wpb=110.7, bsz=40, num_updates=25900, lr=4.04385e-05, gnorm=0.228, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=103901
2023-01-09 03:42:47 - progress_bar.py[line:274] - INFO: epoch 001:  25947 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4615, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=25910, lr=4.0434e-05, gnorm=0.172, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=103923
2023-01-09 03:43:08 - progress_bar.py[line:274] - INFO: epoch 001:  25957 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4455, wps=101.5, ups=0.47, wpb=108.6, bsz=40, num_updates=25920, lr=4.04295e-05, gnorm=0.207, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=103944
2023-01-09 03:43:31 - progress_bar.py[line:274] - INFO: epoch 001:  25967 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4608, wps=99.6, ups=0.46, wpb=109.3, bsz=40, num_updates=25930, lr=4.0425e-05, gnorm=0.185, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=103966
2023-01-09 03:43:52 - progress_bar.py[line:274] - INFO: epoch 001:  25977 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4976, wps=102, ups=0.47, wpb=109, bsz=40, num_updates=25940, lr=4.04205e-05, gnorm=0.221, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=103988
2023-01-09 03:44:14 - progress_bar.py[line:274] - INFO: epoch 001:  25987 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4162, wps=102.8, ups=0.47, wpb=108.5, bsz=40, num_updates=25950, lr=4.04161e-05, gnorm=0.196, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=104009
2023-01-09 03:44:35 - progress_bar.py[line:274] - INFO: epoch 001:  25997 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4695, wps=102.1, ups=0.47, wpb=108.6, bsz=40, num_updates=25960, lr=4.04116e-05, gnorm=0.291, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=104031
2023-01-09 03:44:57 - progress_bar.py[line:274] - INFO: epoch 001:  26007 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4545, wps=99.4, ups=0.46, wpb=107.3, bsz=40, num_updates=25970, lr=4.04071e-05, gnorm=0.199, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=104053
2023-01-09 03:45:19 - progress_bar.py[line:274] - INFO: epoch 001:  26017 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4694, wps=101, ups=0.46, wpb=109.2, bsz=40, num_updates=25980, lr=4.04026e-05, gnorm=0.271, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=104075
2023-01-09 03:45:41 - progress_bar.py[line:274] - INFO: epoch 001:  26027 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4497, wps=102.4, ups=0.46, wpb=110.2, bsz=40, num_updates=25990, lr=4.03981e-05, gnorm=0.179, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=104097
2023-01-09 03:46:03 - progress_bar.py[line:274] - INFO: epoch 001:  26037 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4124, wps=102.4, ups=0.47, wpb=109.9, bsz=40, num_updates=26000, lr=4.03936e-05, gnorm=0.295, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=104119
2023-01-09 03:46:03 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-09 03:46:04 - train.py[line:549] - INFO: 0 / 4988
2023-01-09 03:46:04 - train.py[line:551] - INFO: load:1.11 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-09 03:48:37 - train.py[line:549] - INFO: 200 / 4988
2023-01-09 03:48:37 - train.py[line:551] - INFO: load:1.14 valid_run:152.48 task_valid:148.48 collect_output:2.89
2023-01-09 03:51:06 - train.py[line:549] - INFO: 400 / 4988
2023-01-09 03:51:06 - train.py[line:551] - INFO: load:1.17 valid_run:301.38 task_valid:291.48 collect_output:7.76
2023-01-09 03:53:39 - train.py[line:549] - INFO: 600 / 4988
2023-01-09 03:53:39 - train.py[line:551] - INFO: load:1.19 valid_run:454.33 task_valid:434.29 collect_output:16.87
2023-01-09 03:56:08 - train.py[line:549] - INFO: 800 / 4988
2023-01-09 03:56:08 - train.py[line:551] - INFO: load:1.22 valid_run:603.24 task_valid:578.85 collect_output:20.20
2023-01-09 03:58:40 - train.py[line:549] - INFO: 1000 / 4988
2023-01-09 03:58:40 - train.py[line:551] - INFO: load:1.25 valid_run:755.60 task_valid:726.18 collect_output:24.21
2023-01-09 04:01:12 - train.py[line:549] - INFO: 1200 / 4988
2023-01-09 04:01:12 - train.py[line:551] - INFO: load:1.28 valid_run:907.40 task_valid:871.41 collect_output:29.76
2023-01-09 04:03:46 - train.py[line:549] - INFO: 1400 / 4988
2023-01-09 04:03:46 - train.py[line:551] - INFO: load:1.30 valid_run:1060.79 task_valid:1016.95 collect_output:36.59
2023-01-09 04:06:17 - train.py[line:549] - INFO: 1600 / 4988
2023-01-09 04:06:17 - train.py[line:551] - INFO: load:1.33 valid_run:1212.00 task_valid:1157.66 collect_output:46.10
2023-01-09 04:08:47 - train.py[line:549] - INFO: 1800 / 4988
2023-01-09 04:08:47 - train.py[line:551] - INFO: load:1.36 valid_run:1361.74 task_valid:1302.24 collect_output:50.22
2023-01-09 04:11:15 - train.py[line:549] - INFO: 2000 / 4988
2023-01-09 04:11:15 - train.py[line:551] - INFO: load:1.39 valid_run:1510.34 task_valid:1445.00 collect_output:55.05
2023-01-09 04:13:45 - train.py[line:549] - INFO: 2200 / 4988
2023-01-09 04:13:45 - train.py[line:551] - INFO: load:1.41 valid_run:1659.81 task_valid:1589.40 collect_output:59.09
2023-01-09 04:16:15 - train.py[line:549] - INFO: 2400 / 4988
2023-01-09 04:16:15 - train.py[line:551] - INFO: load:1.44 valid_run:1809.63 task_valid:1733.81 collect_output:63.48
2023-01-09 04:18:45 - train.py[line:549] - INFO: 2600 / 4988
2023-01-09 04:18:45 - train.py[line:551] - INFO: load:1.47 valid_run:1959.68 task_valid:1875.51 collect_output:70.80
2023-01-09 04:21:16 - train.py[line:549] - INFO: 2800 / 4988
2023-01-09 04:21:16 - train.py[line:551] - INFO: load:1.50 valid_run:2110.23 task_valid:2020.60 collect_output:75.23
2023-01-09 04:23:45 - train.py[line:549] - INFO: 3000 / 4988
2023-01-09 04:23:45 - train.py[line:551] - INFO: load:1.52 valid_run:2259.98 task_valid:2166.60 collect_output:77.96
2023-01-09 04:26:16 - train.py[line:549] - INFO: 3200 / 4988
2023-01-09 04:26:16 - train.py[line:551] - INFO: load:1.55 valid_run:2409.97 task_valid:2310.45 collect_output:83.08
2023-01-09 04:28:47 - train.py[line:549] - INFO: 3400 / 4988
2023-01-09 04:28:47 - train.py[line:551] - INFO: load:1.58 valid_run:2561.76 task_valid:2455.72 collect_output:88.58
2023-01-09 04:31:18 - train.py[line:549] - INFO: 3600 / 4988
2023-01-09 04:31:18 - train.py[line:551] - INFO: load:1.61 valid_run:2712.24 task_valid:2602.25 collect_output:91.50
2023-01-09 04:33:46 - train.py[line:549] - INFO: 3800 / 4988
2023-01-09 04:33:46 - train.py[line:551] - INFO: load:1.64 valid_run:2860.65 task_valid:2743.44 collect_output:97.71
2023-01-09 04:36:17 - train.py[line:549] - INFO: 4000 / 4988
2023-01-09 04:36:17 - train.py[line:551] - INFO: load:1.66 valid_run:3010.92 task_valid:2888.23 collect_output:102.16
2023-01-09 04:38:49 - train.py[line:549] - INFO: 4200 / 4988
2023-01-09 04:38:49 - train.py[line:551] - INFO: load:1.69 valid_run:3163.04 task_valid:3032.60 collect_output:108.88
2023-01-09 04:41:18 - train.py[line:549] - INFO: 4400 / 4988
2023-01-09 04:41:18 - train.py[line:551] - INFO: load:1.72 valid_run:3312.47 task_valid:3176.84 collect_output:113.03
2023-01-09 04:43:50 - train.py[line:549] - INFO: 4600 / 4988
2023-01-09 04:43:50 - train.py[line:551] - INFO: load:1.75 valid_run:3463.64 task_valid:3322.62 collect_output:117.41
2023-01-09 04:46:21 - train.py[line:549] - INFO: 4800 / 4988
2023-01-09 04:46:21 - train.py[line:551] - INFO: load:1.78 valid_run:3614.78 task_valid:3468.63 collect_output:121.52

====================================================================================================
SGG eval:     R @ 50: 0.3662;     R @ 100: 0.4365;     R @ 500: 0.4583;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2315;    mR @ 100: 0.2864;    mR @ 500: 0.3012;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3049) (covered in:0.6875) (covering:0.3714) (eating:0.5882) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.6146) (playing:0.0000) (riding:0.4108) (says:0.0000) (sitting on:0.6911) (standing on:0.1800) (using:0.7000) (walking in:0.0000) (walking on:0.1622) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-09 04:48:51 - train.py[line:487] - INFO: 0.4364619047619048
2023-01-09 04:48:52 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.3662;     R @ 100: 0.4365;     R @ 500: 0.4583;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2315;    mR @ 100: 0.2864;    mR @ 500: 0.3012;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3049) (covered in:0.6875) (covering:0.3714) (eating:0.5882) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.6146) (playing:0.0000) (riding:0.4108) (says:0.0000) (sitting on:0.6911) (standing on:0.1800) (using:0.7000) (walking in:0.0000) (walking on:0.1622) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-09 04:48:52 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.382 | loss_v1 0 | loss_v2 0 | nll_loss 0.227 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.436462 | ppl 1.17 | vqa_score 0.3502 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 26000 | best_R@100 0.645421
2023-01-09 04:48:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 26000 updates
2023-01-09 04:48:52 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_26000.pt
2023-01-09 04:49:33 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_26000.pt
2023-01-09 04:51:00 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_26000.pt (epoch 1 @ 26000 updates, score 0.4364619047619048) (writing took 128.64607706852257 seconds)
2023-01-09 04:51:22 - progress_bar.py[line:274] - INFO: epoch 001:  26047 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4567, wps=0.6, ups=0, wpb=108.7, bsz=40, num_updates=26010, lr=4.03891e-05, gnorm=0.129, clip=0, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=108038
2023-01-09 04:51:44 - progress_bar.py[line:274] - INFO: epoch 001:  26057 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5152, wps=100, ups=0.46, wpb=108, bsz=40, num_updates=26020, lr=4.03846e-05, gnorm=0.336, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=108060
2023-01-09 04:52:06 - progress_bar.py[line:274] - INFO: epoch 001:  26067 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4657, wps=101.3, ups=0.47, wpb=108.1, bsz=40, num_updates=26030, lr=4.03801e-05, gnorm=0.192, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=108081
2023-01-09 04:52:27 - progress_bar.py[line:274] - INFO: epoch 001:  26077 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4465, wps=102.3, ups=0.47, wpb=108.3, bsz=40, num_updates=26040, lr=4.03756e-05, gnorm=0.204, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=108103
2023-01-09 04:52:49 - progress_bar.py[line:274] - INFO: epoch 001:  26087 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4734, wps=101.7, ups=0.47, wpb=109.2, bsz=40, num_updates=26050, lr=4.03711e-05, gnorm=0.188, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=108125
2023-01-09 04:53:10 - progress_bar.py[line:274] - INFO: epoch 001:  26097 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4242, wps=102.3, ups=0.47, wpb=109.4, bsz=40, num_updates=26060, lr=4.03666e-05, gnorm=0.207, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=108146
2023-01-09 04:53:32 - progress_bar.py[line:274] - INFO: epoch 001:  26107 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4141, wps=101.7, ups=0.46, wpb=109.8, bsz=40, num_updates=26070, lr=4.03621e-05, gnorm=0.282, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=108168
2023-01-09 04:53:54 - progress_bar.py[line:274] - INFO: epoch 001:  26117 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5067, wps=101.6, ups=0.47, wpb=109.2, bsz=40, num_updates=26080, lr=4.03576e-05, gnorm=0.191, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=108190
2023-01-09 04:54:16 - progress_bar.py[line:274] - INFO: epoch 001:  26127 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4394, wps=98.5, ups=0.45, wpb=109.5, bsz=40, num_updates=26090, lr=4.03531e-05, gnorm=0.195, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=108212
2023-01-09 04:54:38 - progress_bar.py[line:274] - INFO: epoch 001:  26137 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.3901, wps=103.3, ups=0.47, wpb=109.1, bsz=40, num_updates=26100, lr=4.03486e-05, gnorm=0.141, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=108234
2023-01-09 04:55:00 - progress_bar.py[line:274] - INFO: epoch 001:  26147 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.405, wps=101.6, ups=0.47, wpb=108.6, bsz=40, num_updates=26110, lr=4.03441e-05, gnorm=0.356, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=108255
2023-01-09 04:55:21 - progress_bar.py[line:274] - INFO: epoch 001:  26157 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4898, wps=102.6, ups=0.47, wpb=108.6, bsz=40, num_updates=26120, lr=4.03396e-05, gnorm=0.262, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=108277
2023-01-09 04:55:43 - progress_bar.py[line:274] - INFO: epoch 001:  26167 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.375, wps=103.7, ups=0.46, wpb=111.7, bsz=40, num_updates=26130, lr=4.03351e-05, gnorm=0.249, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=108299
2023-01-09 04:56:04 - progress_bar.py[line:274] - INFO: epoch 001:  26177 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4922, wps=103.8, ups=0.47, wpb=110, bsz=40, num_updates=26140, lr=4.03306e-05, gnorm=0.317, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=108320
2023-01-09 04:56:26 - progress_bar.py[line:274] - INFO: epoch 001:  26187 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4211, wps=101.2, ups=0.47, wpb=108, bsz=40, num_updates=26150, lr=4.03261e-05, gnorm=0.152, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=108342
2023-01-09 04:56:48 - progress_bar.py[line:274] - INFO: epoch 001:  26197 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4456, wps=99.8, ups=0.46, wpb=108.6, bsz=40, num_updates=26160, lr=4.03216e-05, gnorm=0.272, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=108364
2023-01-09 04:57:10 - progress_bar.py[line:274] - INFO: epoch 001:  26207 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.399, wps=101.1, ups=0.47, wpb=107.9, bsz=40, num_updates=26170, lr=4.03171e-05, gnorm=0.335, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=108385
2023-01-09 04:57:31 - progress_bar.py[line:274] - INFO: epoch 001:  26217 / 115845 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5266, wps=103.9, ups=0.48, wpb=109, bsz=40, num_updates=26180, lr=4.03126e-05, gnorm=0.189, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=108407
2023-01-09 04:57:53 - progress_bar.py[line:274] - INFO: epoch 001:  26227 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4897, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=26190, lr=4.03082e-05, gnorm=0.383, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=108428
2023-01-09 04:58:15 - progress_bar.py[line:274] - INFO: epoch 001:  26237 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4455, wps=101.6, ups=0.46, wpb=110.5, bsz=40, num_updates=26200, lr=4.03037e-05, gnorm=0.265, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=108451
2023-01-09 04:58:37 - progress_bar.py[line:274] - INFO: epoch 001:  26247 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4833, wps=96.9, ups=0.45, wpb=106.9, bsz=40, num_updates=26210, lr=4.02992e-05, gnorm=0.225, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=108473
2023-01-09 04:58:59 - progress_bar.py[line:274] - INFO: epoch 001:  26257 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4828, wps=100.5, ups=0.46, wpb=109.8, bsz=40, num_updates=26220, lr=4.02947e-05, gnorm=0.142, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=108495
2023-01-09 04:59:21 - progress_bar.py[line:274] - INFO: epoch 001:  26267 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4585, wps=100.1, ups=0.46, wpb=108.3, bsz=40, num_updates=26230, lr=4.02902e-05, gnorm=0.217, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=108517
2023-01-09 04:59:30 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-09 04:59:45 - progress_bar.py[line:274] - INFO: epoch 001:  26278 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.81, nsentences=40, sample_size=107.81, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4279, wps=95, ups=0.42, wpb=107.8, bsz=40, num_updates=26240, lr=4.02857e-05, gnorm=0.291, clip=0, loss_scale=512, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=108541
2023-01-09 05:00:07 - progress_bar.py[line:274] - INFO: epoch 001:  26288 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.445, wps=102.5, ups=0.48, wpb=107.6, bsz=40, num_updates=26250, lr=4.02812e-05, gnorm=0.141, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=108562
2023-01-09 05:00:28 - progress_bar.py[line:274] - INFO: epoch 001:  26298 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4439, wps=101.8, ups=0.46, wpb=109.7, bsz=40, num_updates=26260, lr=4.02767e-05, gnorm=0.215, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=108584
2023-01-09 05:00:49 - progress_bar.py[line:274] - INFO: epoch 001:  26308 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4663, wps=105.7, ups=0.48, wpb=109.7, bsz=40, num_updates=26270, lr=4.02722e-05, gnorm=0.216, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=108605
2023-01-09 05:01:11 - progress_bar.py[line:274] - INFO: epoch 001:  26318 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4265, wps=102.5, ups=0.48, wpb=107.4, bsz=40, num_updates=26280, lr=4.02677e-05, gnorm=0.153, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=108626
2023-01-09 05:01:32 - progress_bar.py[line:274] - INFO: epoch 001:  26328 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3941, wps=102.5, ups=0.47, wpb=108.4, bsz=40, num_updates=26290, lr=4.02632e-05, gnorm=0.23, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=108648
2023-01-09 05:01:53 - progress_bar.py[line:274] - INFO: epoch 001:  26338 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3589, wps=106.5, ups=0.49, wpb=109.6, bsz=40, num_updates=26300, lr=4.02587e-05, gnorm=0.305, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=108669
2023-01-09 05:02:15 - progress_bar.py[line:274] - INFO: epoch 001:  26348 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4078, wps=99.4, ups=0.46, wpb=107.5, bsz=40, num_updates=26310, lr=4.02542e-05, gnorm=0.343, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=108691
2023-01-09 05:02:37 - progress_bar.py[line:274] - INFO: epoch 001:  26358 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4145, wps=100.8, ups=0.46, wpb=109.8, bsz=40, num_updates=26320, lr=4.02497e-05, gnorm=0.234, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=108713
2023-01-09 05:02:59 - progress_bar.py[line:274] - INFO: epoch 001:  26368 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5076, wps=100.9, ups=0.46, wpb=109.4, bsz=40, num_updates=26330, lr=4.02452e-05, gnorm=0.412, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=108735
2023-01-09 05:03:21 - progress_bar.py[line:274] - INFO: epoch 001:  26378 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4703, wps=100, ups=0.46, wpb=109, bsz=40, num_updates=26340, lr=4.02407e-05, gnorm=0.218, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=108757
2023-01-09 05:03:42 - progress_bar.py[line:274] - INFO: epoch 001:  26388 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4526, wps=103.2, ups=0.47, wpb=109.2, bsz=40, num_updates=26350, lr=4.02362e-05, gnorm=0.192, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=108778
2023-01-09 05:04:04 - progress_bar.py[line:274] - INFO: epoch 001:  26398 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4923, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=26360, lr=4.02317e-05, gnorm=0.305, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=108800
2023-01-09 05:04:26 - progress_bar.py[line:274] - INFO: epoch 001:  26408 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.6, nsentences=40, sample_size=106.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5022, wps=100.1, ups=0.47, wpb=106.6, bsz=40, num_updates=26370, lr=4.02272e-05, gnorm=0.287, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=108822
2023-01-09 05:04:48 - progress_bar.py[line:274] - INFO: epoch 001:  26418 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4263, wps=101.4, ups=0.46, wpb=109, bsz=40, num_updates=26380, lr=4.02227e-05, gnorm=0.213, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=108843
2023-01-09 05:05:09 - progress_bar.py[line:274] - INFO: epoch 001:  26428 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4975, wps=100.9, ups=0.47, wpb=108.1, bsz=40, num_updates=26390, lr=4.02182e-05, gnorm=0.229, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=108865
2023-01-09 05:05:31 - progress_bar.py[line:274] - INFO: epoch 001:  26438 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4619, wps=101.3, ups=0.46, wpb=109.1, bsz=40, num_updates=26400, lr=4.02137e-05, gnorm=0.255, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=108887
2023-01-09 05:05:53 - progress_bar.py[line:274] - INFO: epoch 001:  26448 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3979, wps=104.1, ups=0.47, wpb=110.2, bsz=40, num_updates=26410, lr=4.02092e-05, gnorm=0.297, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=108908
2023-01-09 05:06:14 - progress_bar.py[line:274] - INFO: epoch 001:  26458 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4612, wps=99.4, ups=0.46, wpb=107, bsz=40, num_updates=26420, lr=4.02047e-05, gnorm=0.364, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=108930
2023-01-09 05:06:36 - progress_bar.py[line:274] - INFO: epoch 001:  26468 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4031, wps=104.4, ups=0.48, wpb=109.5, bsz=40, num_updates=26430, lr=4.02002e-05, gnorm=0.154, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=108951
2023-01-09 05:06:58 - progress_bar.py[line:274] - INFO: epoch 001:  26478 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3796, wps=98.5, ups=0.46, wpb=107.3, bsz=40, num_updates=26440, lr=4.01958e-05, gnorm=0.169, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=108973
2023-01-09 05:07:20 - progress_bar.py[line:274] - INFO: epoch 001:  26488 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4826, wps=99.1, ups=0.46, wpb=107.9, bsz=40, num_updates=26450, lr=4.01913e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=108996
2023-01-09 05:07:41 - progress_bar.py[line:274] - INFO: epoch 001:  26498 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4615, wps=103.2, ups=0.47, wpb=108.9, bsz=40, num_updates=26460, lr=4.01868e-05, gnorm=0.379, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=109017
2023-01-09 05:08:02 - progress_bar.py[line:274] - INFO: epoch 001:  26508 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4804, wps=104.4, ups=0.48, wpb=108.3, bsz=40, num_updates=26470, lr=4.01823e-05, gnorm=0.441, clip=10, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=109038
2023-01-09 05:08:24 - progress_bar.py[line:274] - INFO: epoch 001:  26518 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4729, wps=101.3, ups=0.47, wpb=108.5, bsz=40, num_updates=26480, lr=4.01778e-05, gnorm=0.563, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=109060
2023-01-09 05:08:45 - progress_bar.py[line:274] - INFO: epoch 001:  26528 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4507, wps=100.6, ups=0.47, wpb=107.5, bsz=40, num_updates=26490, lr=4.01733e-05, gnorm=0.31, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=109081
2023-01-09 05:09:07 - progress_bar.py[line:274] - INFO: epoch 001:  26538 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.49, wps=103.2, ups=0.47, wpb=109.1, bsz=40, num_updates=26500, lr=4.01688e-05, gnorm=0.251, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=109103
2023-01-09 05:09:28 - progress_bar.py[line:274] - INFO: epoch 001:  26548 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3889, wps=102.9, ups=0.47, wpb=109.5, bsz=40, num_updates=26510, lr=4.01643e-05, gnorm=0.167, clip=0, loss_scale=512, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=109124
2023-01-09 05:09:50 - progress_bar.py[line:274] - INFO: epoch 001:  26558 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4433, wps=102.3, ups=0.47, wpb=108.9, bsz=40, num_updates=26520, lr=4.01598e-05, gnorm=0.264, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=109146
2023-01-09 05:10:12 - progress_bar.py[line:274] - INFO: epoch 001:  26568 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5024, wps=99.1, ups=0.46, wpb=107.9, bsz=40, num_updates=26530, lr=4.01553e-05, gnorm=0.197, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=109168
2023-01-09 05:10:27 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 05:10:36 - progress_bar.py[line:274] - INFO: epoch 001:  26579 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.286, nsentences=40, sample_size=108.286, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4696, wps=95.6, ups=0.42, wpb=108.3, bsz=40, num_updates=26540, lr=4.01508e-05, gnorm=0.198, clip=0, loss_scale=256, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=109192
2023-01-09 05:10:58 - progress_bar.py[line:274] - INFO: epoch 001:  26589 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4068, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=26550, lr=4.01463e-05, gnorm=0.358, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=109214
2023-01-09 05:11:20 - progress_bar.py[line:274] - INFO: epoch 001:  26599 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3791, wps=101.7, ups=0.47, wpb=108.8, bsz=40, num_updates=26560, lr=4.01418e-05, gnorm=0.239, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=109235
2023-01-09 05:11:41 - progress_bar.py[line:274] - INFO: epoch 001:  26609 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4628, wps=100.6, ups=0.46, wpb=108.9, bsz=40, num_updates=26570, lr=4.01373e-05, gnorm=0.164, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=109257
2023-01-09 05:12:03 - progress_bar.py[line:274] - INFO: epoch 001:  26619 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4925, wps=104.2, ups=0.47, wpb=110.2, bsz=40, num_updates=26580, lr=4.01328e-05, gnorm=0.382, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=109279
2023-01-09 05:12:25 - progress_bar.py[line:274] - INFO: epoch 001:  26629 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4456, wps=101.8, ups=0.46, wpb=109.8, bsz=40, num_updates=26590, lr=4.01283e-05, gnorm=0.272, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=109301
2023-01-09 05:12:46 - progress_bar.py[line:274] - INFO: epoch 001:  26639 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.468, wps=105.7, ups=0.48, wpb=109.5, bsz=40, num_updates=26600, lr=4.01238e-05, gnorm=0.163, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=109322
2023-01-09 05:13:08 - progress_bar.py[line:274] - INFO: epoch 001:  26649 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.459, wps=99.9, ups=0.46, wpb=109.6, bsz=40, num_updates=26610, lr=4.01193e-05, gnorm=0.232, clip=0, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=109344
2023-01-09 05:13:30 - progress_bar.py[line:274] - INFO: epoch 001:  26659 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4335, wps=101.6, ups=0.46, wpb=110.6, bsz=40, num_updates=26620, lr=4.01148e-05, gnorm=0.393, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=109366
2023-01-09 05:13:52 - progress_bar.py[line:274] - INFO: epoch 001:  26669 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4521, wps=100.9, ups=0.46, wpb=108.6, bsz=40, num_updates=26630, lr=4.01103e-05, gnorm=0.225, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=109388
2023-01-09 05:14:14 - progress_bar.py[line:274] - INFO: epoch 001:  26679 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.375, wps=101.4, ups=0.47, wpb=108.9, bsz=40, num_updates=26640, lr=4.01058e-05, gnorm=0.305, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=109409
2023-01-09 05:14:35 - progress_bar.py[line:274] - INFO: epoch 001:  26689 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4599, wps=105.5, ups=0.48, wpb=110.5, bsz=40, num_updates=26650, lr=4.01013e-05, gnorm=0.564, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=109431
2023-01-09 05:14:57 - progress_bar.py[line:274] - INFO: epoch 001:  26699 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=105.9, nsentences=40, sample_size=105.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4259, wps=98.4, ups=0.46, wpb=105.9, bsz=40, num_updates=26660, lr=4.00968e-05, gnorm=0.241, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=109453
2023-01-09 05:15:19 - progress_bar.py[line:274] - INFO: epoch 001:  26709 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.402, wps=99.1, ups=0.45, wpb=109.3, bsz=40, num_updates=26670, lr=4.00923e-05, gnorm=0.205, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=109475
2023-01-09 05:15:41 - progress_bar.py[line:274] - INFO: epoch 001:  26719 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4783, wps=101.5, ups=0.47, wpb=108.9, bsz=40, num_updates=26680, lr=4.00879e-05, gnorm=0.211, clip=0, loss_scale=256, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=109497
2023-01-09 05:16:03 - progress_bar.py[line:274] - INFO: epoch 001:  26729 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=106.7, nsentences=40, sample_size=106.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4358, wps=99.3, ups=0.47, wpb=106.7, bsz=40, num_updates=26690, lr=4.00834e-05, gnorm=0.293, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=109518
2023-01-09 05:16:25 - progress_bar.py[line:274] - INFO: epoch 001:  26739 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.375, wps=100.7, ups=0.46, wpb=109.4, bsz=40, num_updates=26700, lr=4.00789e-05, gnorm=0.343, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=109540
2023-01-09 05:16:47 - progress_bar.py[line:274] - INFO: epoch 001:  26749 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4976, wps=99.7, ups=0.46, wpb=108.1, bsz=40, num_updates=26710, lr=4.00744e-05, gnorm=0.223, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=109563
2023-01-09 05:17:10 - progress_bar.py[line:274] - INFO: epoch 001:  26759 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4429, wps=98.5, ups=0.46, wpb=107.4, bsz=40, num_updates=26720, lr=4.00699e-05, gnorm=0.205, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=109585
2023-01-09 05:17:32 - progress_bar.py[line:274] - INFO: epoch 001:  26769 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4104, wps=99.2, ups=0.46, wpb=107.9, bsz=40, num_updates=26730, lr=4.00654e-05, gnorm=0.253, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=109608
2023-01-09 05:17:55 - progress_bar.py[line:274] - INFO: epoch 001:  26779 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5051, wps=98.9, ups=0.46, wpb=108.4, bsz=40, num_updates=26740, lr=4.00609e-05, gnorm=0.289, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=109630
2023-01-09 05:18:17 - progress_bar.py[line:274] - INFO: epoch 001:  26789 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4497, wps=103.3, ups=0.47, wpb=109.2, bsz=40, num_updates=26750, lr=4.00564e-05, gnorm=0.155, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=109652
2023-01-09 05:18:39 - progress_bar.py[line:274] - INFO: epoch 001:  26799 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4638, wps=100.1, ups=0.46, wpb=108.1, bsz=40, num_updates=26760, lr=4.00519e-05, gnorm=0.204, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=109675
2023-01-09 05:19:01 - progress_bar.py[line:274] - INFO: epoch 001:  26809 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4597, wps=102, ups=0.47, wpb=108, bsz=40, num_updates=26770, lr=4.00474e-05, gnorm=0.26, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=109697
2023-01-09 05:19:24 - progress_bar.py[line:274] - INFO: epoch 001:  26819 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4467, wps=99.8, ups=0.46, wpb=109, bsz=40, num_updates=26780, lr=4.00429e-05, gnorm=0.332, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=109719
2023-01-09 05:19:46 - progress_bar.py[line:274] - INFO: epoch 001:  26829 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.465, wps=100.4, ups=0.47, wpb=107.9, bsz=40, num_updates=26790, lr=4.00384e-05, gnorm=0.143, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=109741
2023-01-09 05:20:09 - progress_bar.py[line:274] - INFO: epoch 001:  26839 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4619, wps=99.3, ups=0.46, wpb=109.1, bsz=40, num_updates=26800, lr=4.00339e-05, gnorm=0.219, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=109764
2023-01-09 05:20:31 - progress_bar.py[line:274] - INFO: epoch 001:  26849 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4286, wps=100, ups=0.47, wpb=107.4, bsz=40, num_updates=26810, lr=4.00294e-05, gnorm=0.189, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=109786
2023-01-09 05:20:54 - progress_bar.py[line:274] - INFO: epoch 001:  26859 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4694, wps=98.6, ups=0.45, wpb=108.9, bsz=40, num_updates=26820, lr=4.00249e-05, gnorm=0.21, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=109809
2023-01-09 05:21:16 - progress_bar.py[line:274] - INFO: epoch 001:  26869 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4365, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=26830, lr=4.00204e-05, gnorm=0.234, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=109831
2023-01-09 05:21:39 - progress_bar.py[line:274] - INFO: epoch 001:  26879 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4559, wps=98.8, ups=0.46, wpb=108.5, bsz=40, num_updates=26840, lr=4.00159e-05, gnorm=0.181, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=109854
2023-01-09 05:22:01 - progress_bar.py[line:274] - INFO: epoch 001:  26889 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5096, wps=102.5, ups=0.47, wpb=108.8, bsz=40, num_updates=26850, lr=4.00114e-05, gnorm=0.203, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=109876
2023-01-09 05:22:23 - progress_bar.py[line:274] - INFO: epoch 001:  26899 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=106.7, nsentences=40, sample_size=106.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4623, wps=99.1, ups=0.46, wpb=106.7, bsz=40, num_updates=26860, lr=4.00069e-05, gnorm=0.218, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=109898
2023-01-09 05:22:45 - progress_bar.py[line:274] - INFO: epoch 001:  26909 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4162, wps=103.9, ups=0.47, wpb=110.7, bsz=40, num_updates=26870, lr=4.00024e-05, gnorm=0.23, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=109921
2023-01-09 05:23:07 - progress_bar.py[line:274] - INFO: epoch 001:  26919 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4062, wps=100.5, ups=0.47, wpb=107.8, bsz=40, num_updates=26880, lr=3.99979e-05, gnorm=0.186, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=109943
2023-01-09 05:23:29 - progress_bar.py[line:274] - INFO: epoch 001:  26929 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5103, wps=102.1, ups=0.47, wpb=108.7, bsz=40, num_updates=26890, lr=3.99934e-05, gnorm=0.237, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=109965
2023-01-09 05:23:52 - progress_bar.py[line:274] - INFO: epoch 001:  26939 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4975, wps=101.9, ups=0.47, wpb=108.9, bsz=40, num_updates=26900, lr=3.99889e-05, gnorm=0.319, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=109987
2023-01-09 05:24:14 - progress_bar.py[line:274] - INFO: epoch 001:  26949 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4368, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=26910, lr=3.99844e-05, gnorm=0.247, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=110009
2023-01-09 05:24:37 - progress_bar.py[line:274] - INFO: epoch 001:  26959 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3922, wps=99.9, ups=0.46, wpb=108.8, bsz=40, num_updates=26920, lr=3.99799e-05, gnorm=0.168, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=110032
2023-01-09 05:24:58 - progress_bar.py[line:274] - INFO: epoch 001:  26969 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4545, wps=104.1, ups=0.48, wpb=109.5, bsz=40, num_updates=26930, lr=3.99755e-05, gnorm=0.192, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=110054
2023-01-09 05:25:21 - progress_bar.py[line:274] - INFO: epoch 001:  26979 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4976, wps=101.9, ups=0.47, wpb=109.1, bsz=40, num_updates=26940, lr=3.9971e-05, gnorm=0.253, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=110076
2023-01-09 05:25:43 - progress_bar.py[line:274] - INFO: epoch 001:  26989 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=106.7, nsentences=40, sample_size=106.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5046, wps=98.8, ups=0.46, wpb=106.7, bsz=40, num_updates=26950, lr=3.99665e-05, gnorm=0.268, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=110098
2023-01-09 05:26:05 - progress_bar.py[line:274] - INFO: epoch 001:  26999 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=106.2, nsentences=40, sample_size=106.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4342, wps=101, ups=0.48, wpb=106.2, bsz=40, num_updates=26960, lr=3.9962e-05, gnorm=0.241, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=110120
2023-01-09 05:26:27 - progress_bar.py[line:274] - INFO: epoch 001:  27009 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4737, wps=100.9, ups=0.46, wpb=109.5, bsz=40, num_updates=26970, lr=3.99575e-05, gnorm=0.187, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=110143
2023-01-09 05:26:49 - progress_bar.py[line:274] - INFO: epoch 001:  27019 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4619, wps=105, ups=0.48, wpb=109.9, bsz=40, num_updates=26980, lr=3.9953e-05, gnorm=0.366, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=110164
2023-01-09 05:27:12 - progress_bar.py[line:274] - INFO: epoch 001:  27029 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4037, wps=98.7, ups=0.46, wpb=108.4, bsz=40, num_updates=26990, lr=3.99485e-05, gnorm=0.345, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=110187
2023-01-09 05:27:33 - progress_bar.py[line:274] - INFO: epoch 001:  27039 / 115845 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4632, wps=103.2, ups=0.47, wpb=109.2, bsz=40, num_updates=27000, lr=3.9944e-05, gnorm=0.331, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=110209
2023-01-09 05:27:55 - progress_bar.py[line:274] - INFO: epoch 001:  27049 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4636, wps=100.3, ups=0.47, wpb=107.2, bsz=40, num_updates=27010, lr=3.99395e-05, gnorm=0.179, clip=0, loss_scale=256, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=110231
2023-01-09 05:28:17 - progress_bar.py[line:274] - INFO: epoch 001:  27059 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4444, wps=102.8, ups=0.47, wpb=108.8, bsz=40, num_updates=27020, lr=3.9935e-05, gnorm=0.19, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=110253
2023-01-09 05:28:40 - progress_bar.py[line:274] - INFO: epoch 001:  27069 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4583, wps=101.7, ups=0.46, wpb=109.9, bsz=40, num_updates=27030, lr=3.99305e-05, gnorm=0.363, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=110275
2023-01-09 05:29:01 - progress_bar.py[line:274] - INFO: epoch 001:  27079 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.434, wps=102.5, ups=0.47, wpb=108.6, bsz=40, num_updates=27040, lr=3.9926e-05, gnorm=0.293, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=110297
2023-01-09 05:29:24 - progress_bar.py[line:274] - INFO: epoch 001:  27089 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4408, wps=100.5, ups=0.46, wpb=109, bsz=40, num_updates=27050, lr=3.99215e-05, gnorm=0.122, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=110319
2023-01-09 05:29:46 - progress_bar.py[line:274] - INFO: epoch 001:  27099 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.485, wps=100.1, ups=0.46, wpb=107.9, bsz=40, num_updates=27060, lr=3.9917e-05, gnorm=0.196, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=110341
2023-01-09 05:30:08 - progress_bar.py[line:274] - INFO: epoch 001:  27109 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4393, wps=99.8, ups=0.46, wpb=108.7, bsz=40, num_updates=27070, lr=3.99125e-05, gnorm=0.315, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=110364
2023-01-09 05:30:31 - progress_bar.py[line:274] - INFO: epoch 001:  27119 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.513, wps=102.6, ups=0.47, wpb=110.1, bsz=40, num_updates=27080, lr=3.9908e-05, gnorm=0.371, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=110386
2023-01-09 05:30:53 - progress_bar.py[line:274] - INFO: epoch 001:  27129 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4433, wps=101.1, ups=0.46, wpb=109.2, bsz=40, num_updates=27090, lr=3.99035e-05, gnorm=0.24, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=110408
2023-01-09 05:31:15 - progress_bar.py[line:274] - INFO: epoch 001:  27139 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4021, wps=102.5, ups=0.47, wpb=110.2, bsz=40, num_updates=27100, lr=3.9899e-05, gnorm=0.189, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=110430
2023-01-09 05:31:37 - progress_bar.py[line:274] - INFO: epoch 001:  27149 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4565, wps=100.2, ups=0.46, wpb=108.8, bsz=40, num_updates=27110, lr=3.98945e-05, gnorm=0.205, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=110453
2023-01-09 05:31:59 - progress_bar.py[line:274] - INFO: epoch 001:  27159 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4439, wps=102.6, ups=0.47, wpb=110.2, bsz=40, num_updates=27120, lr=3.989e-05, gnorm=0.447, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=110475
2023-01-09 05:32:22 - progress_bar.py[line:274] - INFO: epoch 001:  27169 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4686, wps=99.3, ups=0.46, wpb=108.2, bsz=40, num_updates=27130, lr=3.98855e-05, gnorm=0.288, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=110497
2023-01-09 05:32:44 - progress_bar.py[line:274] - INFO: epoch 001:  27179 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4673, wps=100.7, ups=0.47, wpb=107.6, bsz=40, num_updates=27140, lr=3.9881e-05, gnorm=0.177, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=110519
2023-01-09 05:33:06 - progress_bar.py[line:274] - INFO: epoch 001:  27189 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4607, wps=100.9, ups=0.46, wpb=110.5, bsz=40, num_updates=27150, lr=3.98765e-05, gnorm=0.198, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=110542
2023-01-09 05:33:28 - progress_bar.py[line:274] - INFO: epoch 001:  27199 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4213, wps=102.2, ups=0.48, wpb=107.3, bsz=40, num_updates=27160, lr=3.9872e-05, gnorm=0.378, clip=10, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=110563
2023-01-09 05:33:50 - progress_bar.py[line:274] - INFO: epoch 001:  27209 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4643, wps=100.8, ups=0.47, wpb=108.2, bsz=40, num_updates=27170, lr=3.98676e-05, gnorm=0.207, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=110585
2023-01-09 05:34:12 - progress_bar.py[line:274] - INFO: epoch 001:  27219 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.418, wps=99.4, ups=0.46, wpb=108.9, bsz=40, num_updates=27180, lr=3.98631e-05, gnorm=0.224, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=110608
2023-01-09 05:34:34 - progress_bar.py[line:274] - INFO: epoch 001:  27229 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5079, wps=101.9, ups=0.46, wpb=109.6, bsz=40, num_updates=27190, lr=3.98586e-05, gnorm=0.19, clip=0, loss_scale=512, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=110630
2023-01-09 05:34:57 - progress_bar.py[line:274] - INFO: epoch 001:  27239 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5026, wps=100.5, ups=0.46, wpb=109.3, bsz=40, num_updates=27200, lr=3.98541e-05, gnorm=0.195, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=110652
2023-01-09 05:35:19 - progress_bar.py[line:274] - INFO: epoch 001:  27249 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4058, wps=99.2, ups=0.46, wpb=108.1, bsz=40, num_updates=27210, lr=3.98496e-05, gnorm=0.255, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=110675
2023-01-09 05:35:42 - progress_bar.py[line:274] - INFO: epoch 001:  27259 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4378, wps=99.2, ups=0.46, wpb=109, bsz=40, num_updates=27220, lr=3.98451e-05, gnorm=0.207, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=110697
2023-01-09 05:36:04 - progress_bar.py[line:274] - INFO: epoch 001:  27269 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4019, wps=100.9, ups=0.47, wpb=107.8, bsz=40, num_updates=27230, lr=3.98406e-05, gnorm=0.4, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=110719
2023-01-09 05:36:26 - progress_bar.py[line:274] - INFO: epoch 001:  27279 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4554, wps=99.4, ups=0.46, wpb=108.2, bsz=40, num_updates=27240, lr=3.98361e-05, gnorm=0.207, clip=0, loss_scale=512, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=110742
2023-01-09 05:36:49 - progress_bar.py[line:274] - INFO: epoch 001:  27289 / 115845 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4942, wps=101.4, ups=0.46, wpb=110.5, bsz=40, num_updates=27250, lr=3.98316e-05, gnorm=0.151, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=110764
2023-01-09 05:37:11 - progress_bar.py[line:274] - INFO: epoch 001:  27299 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4718, wps=100.6, ups=0.46, wpb=108.6, bsz=40, num_updates=27260, lr=3.98271e-05, gnorm=0.156, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=110786
2023-01-09 05:37:33 - progress_bar.py[line:274] - INFO: epoch 001:  27309 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4343, wps=99.7, ups=0.46, wpb=107.7, bsz=40, num_updates=27270, lr=3.98226e-05, gnorm=0.254, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=110809
2023-01-09 05:37:55 - progress_bar.py[line:274] - INFO: epoch 001:  27319 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4036, wps=100.7, ups=0.47, wpb=107.4, bsz=40, num_updates=27280, lr=3.98181e-05, gnorm=0.345, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=110831
2023-01-09 05:38:18 - progress_bar.py[line:274] - INFO: epoch 001:  27329 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4556, wps=101.3, ups=0.46, wpb=110, bsz=40, num_updates=27290, lr=3.98136e-05, gnorm=0.3, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=110853
2023-01-09 05:38:40 - progress_bar.py[line:274] - INFO: epoch 001:  27339 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5189, wps=100.1, ups=0.46, wpb=108.1, bsz=40, num_updates=27300, lr=3.98091e-05, gnorm=0.173, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=110875
2023-01-09 05:39:01 - progress_bar.py[line:274] - INFO: epoch 001:  27349 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4628, wps=101.1, ups=0.46, wpb=109.9, bsz=40, num_updates=27310, lr=3.98046e-05, gnorm=0.235, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=110897
2023-01-09 05:39:23 - progress_bar.py[line:274] - INFO: epoch 001:  27359 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.488, wps=104, ups=0.47, wpb=110.6, bsz=40, num_updates=27320, lr=3.98001e-05, gnorm=0.343, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=110919
2023-01-09 05:39:44 - progress_bar.py[line:274] - INFO: epoch 001:  27369 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4258, wps=101.7, ups=0.47, wpb=108, bsz=40, num_updates=27330, lr=3.97956e-05, gnorm=0.224, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=110940
2023-01-09 05:40:06 - progress_bar.py[line:274] - INFO: epoch 001:  27379 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4236, wps=103.1, ups=0.47, wpb=109, bsz=40, num_updates=27340, lr=3.97911e-05, gnorm=0.226, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=110962
2023-01-09 05:40:27 - progress_bar.py[line:274] - INFO: epoch 001:  27389 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4848, wps=101.3, ups=0.47, wpb=108.4, bsz=40, num_updates=27350, lr=3.97866e-05, gnorm=0.179, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=110983
2023-01-09 05:40:49 - progress_bar.py[line:274] - INFO: epoch 001:  27399 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.45, wps=101.4, ups=0.47, wpb=108.3, bsz=40, num_updates=27360, lr=3.97821e-05, gnorm=0.194, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=111005
2023-01-09 05:41:11 - progress_bar.py[line:274] - INFO: epoch 001:  27409 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.443, wps=100.1, ups=0.47, wpb=107.5, bsz=40, num_updates=27370, lr=3.97776e-05, gnorm=0.291, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=111027
2023-01-09 05:41:32 - progress_bar.py[line:274] - INFO: epoch 001:  27419 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4413, wps=102, ups=0.47, wpb=107.7, bsz=40, num_updates=27380, lr=3.97731e-05, gnorm=0.326, clip=10, loss_scale=512, train_wall=21, gb_free=9.2, ema_decay=0.9999, wall=111048
2023-01-09 05:41:54 - progress_bar.py[line:274] - INFO: epoch 001:  27429 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4324, wps=99.5, ups=0.46, wpb=107.5, bsz=40, num_updates=27390, lr=3.97686e-05, gnorm=0.213, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=111070
2023-01-09 05:42:16 - progress_bar.py[line:274] - INFO: epoch 001:  27439 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4021, wps=100.7, ups=0.46, wpb=110.6, bsz=40, num_updates=27400, lr=3.97641e-05, gnorm=0.149, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=111092
2023-01-09 05:42:38 - progress_bar.py[line:274] - INFO: epoch 001:  27449 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3946, wps=103.1, ups=0.47, wpb=109.4, bsz=40, num_updates=27410, lr=3.97596e-05, gnorm=0.216, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=111114
2023-01-09 05:43:00 - progress_bar.py[line:274] - INFO: epoch 001:  27459 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4019, wps=100, ups=0.46, wpb=109, bsz=40, num_updates=27420, lr=3.97552e-05, gnorm=0.222, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=111136
2023-01-09 05:43:21 - progress_bar.py[line:274] - INFO: epoch 001:  27469 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4146, wps=102.4, ups=0.47, wpb=109.2, bsz=40, num_updates=27430, lr=3.97507e-05, gnorm=0.344, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=111157
2023-01-09 05:43:43 - progress_bar.py[line:274] - INFO: epoch 001:  27479 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4061, wps=100, ups=0.46, wpb=108.3, bsz=40, num_updates=27440, lr=3.97462e-05, gnorm=0.182, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=111179
2023-01-09 05:44:05 - progress_bar.py[line:274] - INFO: epoch 001:  27489 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4074, wps=99.8, ups=0.46, wpb=109.7, bsz=40, num_updates=27450, lr=3.97417e-05, gnorm=0.15, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=111201
2023-01-09 05:44:27 - progress_bar.py[line:274] - INFO: epoch 001:  27499 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4709, wps=100.3, ups=0.47, wpb=107.7, bsz=40, num_updates=27460, lr=3.97372e-05, gnorm=0.175, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=111223
2023-01-09 05:44:49 - progress_bar.py[line:274] - INFO: epoch 001:  27509 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4163, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=27470, lr=3.97327e-05, gnorm=0.235, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=111245
2023-01-09 05:45:11 - progress_bar.py[line:274] - INFO: epoch 001:  27519 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4219, wps=99.4, ups=0.46, wpb=109, bsz=40, num_updates=27480, lr=3.97282e-05, gnorm=0.146, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=111267
2023-01-09 05:45:32 - progress_bar.py[line:274] - INFO: epoch 001:  27529 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4346, wps=103.9, ups=0.48, wpb=109.1, bsz=40, num_updates=27490, lr=3.97237e-05, gnorm=0.149, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=111288
2023-01-09 05:45:54 - progress_bar.py[line:274] - INFO: epoch 001:  27539 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4365, wps=103.3, ups=0.47, wpb=110.5, bsz=40, num_updates=27500, lr=3.97192e-05, gnorm=0.268, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=111310
2023-01-09 05:46:15 - progress_bar.py[line:274] - INFO: epoch 001:  27549 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4392, wps=103.1, ups=0.47, wpb=109.3, bsz=40, num_updates=27510, lr=3.97147e-05, gnorm=0.278, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=111331
2023-01-09 05:46:37 - progress_bar.py[line:274] - INFO: epoch 001:  27559 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4532, wps=101.2, ups=0.46, wpb=108.8, bsz=40, num_updates=27520, lr=3.97102e-05, gnorm=0.153, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=111353
2023-01-09 05:46:59 - progress_bar.py[line:274] - INFO: epoch 001:  27569 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4205, wps=100.3, ups=0.46, wpb=108.8, bsz=40, num_updates=27530, lr=3.97057e-05, gnorm=0.458, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=111375
2023-01-09 05:47:20 - progress_bar.py[line:274] - INFO: epoch 001:  27579 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5098, wps=102.8, ups=0.47, wpb=108.8, bsz=40, num_updates=27540, lr=3.97012e-05, gnorm=0.281, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=111396
2023-01-09 05:47:42 - progress_bar.py[line:274] - INFO: epoch 001:  27589 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4792, wps=102.4, ups=0.46, wpb=110.2, bsz=40, num_updates=27550, lr=3.96967e-05, gnorm=0.271, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=111418
2023-01-09 05:48:04 - progress_bar.py[line:274] - INFO: epoch 001:  27599 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4481, wps=100.8, ups=0.47, wpb=108.4, bsz=40, num_updates=27560, lr=3.96922e-05, gnorm=0.209, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=111440
2023-01-09 05:48:26 - progress_bar.py[line:274] - INFO: epoch 001:  27609 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.476, wps=99.9, ups=0.46, wpb=109.3, bsz=40, num_updates=27570, lr=3.96877e-05, gnorm=0.267, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=111462
2023-01-09 05:48:48 - progress_bar.py[line:274] - INFO: epoch 001:  27619 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4876, wps=100.3, ups=0.46, wpb=109.4, bsz=40, num_updates=27580, lr=3.96832e-05, gnorm=0.263, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=111484
2023-01-09 05:49:10 - progress_bar.py[line:274] - INFO: epoch 001:  27629 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4178, wps=101.5, ups=0.46, wpb=109.3, bsz=40, num_updates=27590, lr=3.96787e-05, gnorm=0.178, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=111506
2023-01-09 05:49:23 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-09 05:49:34 - progress_bar.py[line:274] - INFO: epoch 001:  27640 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.333, nsentences=40, sample_size=109.333, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5093, wps=97.3, ups=0.42, wpb=109.3, bsz=40, num_updates=27600, lr=3.96742e-05, gnorm=0.19, clip=0, loss_scale=512, train_wall=24, gb_free=10.4, ema_decay=0.9999, wall=111530
2023-01-09 05:49:56 - progress_bar.py[line:274] - INFO: epoch 001:  27650 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4872, wps=100.1, ups=0.46, wpb=109.4, bsz=40, num_updates=27610, lr=3.96697e-05, gnorm=0.249, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=111552
2023-01-09 05:50:18 - progress_bar.py[line:274] - INFO: epoch 001:  27660 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4278, wps=100.4, ups=0.46, wpb=108.2, bsz=40, num_updates=27620, lr=3.96652e-05, gnorm=0.204, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=111573
2023-01-09 05:50:40 - progress_bar.py[line:274] - INFO: epoch 001:  27670 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4903, wps=99.7, ups=0.46, wpb=107.5, bsz=40, num_updates=27630, lr=3.96607e-05, gnorm=0.175, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=111595
2023-01-09 05:51:02 - progress_bar.py[line:274] - INFO: epoch 001:  27680 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4529, wps=96.5, ups=0.45, wpb=107.5, bsz=40, num_updates=27640, lr=3.96562e-05, gnorm=0.153, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=111618
2023-01-09 05:51:25 - progress_bar.py[line:274] - INFO: epoch 001:  27690 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4821, wps=99.6, ups=0.46, wpb=109.2, bsz=40, num_updates=27650, lr=3.96517e-05, gnorm=0.188, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=111640
2023-01-09 05:51:47 - progress_bar.py[line:274] - INFO: epoch 001:  27700 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.467, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=27660, lr=3.96473e-05, gnorm=0.199, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=111662
2023-01-09 05:52:09 - progress_bar.py[line:274] - INFO: epoch 001:  27710 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4346, wps=101.8, ups=0.46, wpb=109.7, bsz=40, num_updates=27670, lr=3.96428e-05, gnorm=0.305, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=111685
2023-01-09 05:52:31 - progress_bar.py[line:274] - INFO: epoch 001:  27720 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4564, wps=102.4, ups=0.46, wpb=110.4, bsz=40, num_updates=27680, lr=3.96383e-05, gnorm=0.328, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=111707
2023-01-09 05:52:53 - progress_bar.py[line:274] - INFO: epoch 001:  27730 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4612, wps=102.2, ups=0.47, wpb=108.5, bsz=40, num_updates=27690, lr=3.96338e-05, gnorm=0.251, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=111729
2023-01-09 05:53:15 - progress_bar.py[line:274] - INFO: epoch 001:  27740 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4416, wps=103.2, ups=0.47, wpb=109.2, bsz=40, num_updates=27700, lr=3.96293e-05, gnorm=0.127, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=111751
2023-01-09 05:53:38 - progress_bar.py[line:274] - INFO: epoch 001:  27750 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5231, wps=99.4, ups=0.46, wpb=108.2, bsz=40, num_updates=27710, lr=3.96248e-05, gnorm=0.289, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=111773
2023-01-09 05:54:00 - progress_bar.py[line:274] - INFO: epoch 001:  27760 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4171, wps=102.5, ups=0.46, wpb=110.3, bsz=40, num_updates=27720, lr=3.96203e-05, gnorm=0.235, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=111795
2023-01-09 05:54:22 - progress_bar.py[line:274] - INFO: epoch 001:  27770 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4862, wps=99.6, ups=0.46, wpb=108.6, bsz=40, num_updates=27730, lr=3.96158e-05, gnorm=0.267, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=111818
2023-01-09 05:54:44 - progress_bar.py[line:274] - INFO: epoch 001:  27780 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4944, wps=101.9, ups=0.46, wpb=110.1, bsz=40, num_updates=27740, lr=3.96113e-05, gnorm=0.242, clip=0, loss_scale=512, train_wall=22, gb_free=9.4, ema_decay=0.9999, wall=111840
2023-01-09 05:55:06 - progress_bar.py[line:274] - INFO: epoch 001:  27790 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4121, wps=102.9, ups=0.47, wpb=109.8, bsz=40, num_updates=27750, lr=3.96068e-05, gnorm=0.346, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=111862
2023-01-09 05:55:28 - progress_bar.py[line:274] - INFO: epoch 001:  27800 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4314, wps=101.3, ups=0.47, wpb=107.9, bsz=40, num_updates=27760, lr=3.96023e-05, gnorm=0.15, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=111884
2023-01-09 05:55:50 - progress_bar.py[line:274] - INFO: epoch 001:  27810 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4663, wps=102.7, ups=0.47, wpb=109.7, bsz=40, num_updates=27770, lr=3.95978e-05, gnorm=0.332, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=111906
2023-01-09 05:56:12 - progress_bar.py[line:274] - INFO: epoch 001:  27820 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4359, wps=102.4, ups=0.46, wpb=110.6, bsz=40, num_updates=27780, lr=3.95933e-05, gnorm=0.216, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=111928
2023-01-09 05:56:34 - progress_bar.py[line:274] - INFO: epoch 001:  27830 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3704, wps=104.3, ups=0.48, wpb=109.4, bsz=40, num_updates=27790, lr=3.95888e-05, gnorm=0.13, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=111949
2023-01-09 05:56:56 - progress_bar.py[line:274] - INFO: epoch 001:  27840 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5057, wps=101.6, ups=0.46, wpb=109.4, bsz=40, num_updates=27800, lr=3.95843e-05, gnorm=0.238, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=111971
2023-01-09 05:57:18 - progress_bar.py[line:274] - INFO: epoch 001:  27850 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4396, wps=100.8, ups=0.47, wpb=108, bsz=40, num_updates=27810, lr=3.95798e-05, gnorm=0.229, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=111993
2023-01-09 05:57:39 - progress_bar.py[line:274] - INFO: epoch 001:  27860 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4789, wps=105.8, ups=0.48, wpb=110.6, bsz=40, num_updates=27820, lr=3.95753e-05, gnorm=0.217, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=112015
2023-01-09 05:58:02 - progress_bar.py[line:274] - INFO: epoch 001:  27870 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4036, wps=98.4, ups=0.46, wpb=107.2, bsz=40, num_updates=27830, lr=3.95708e-05, gnorm=0.285, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=112037
2023-01-09 05:58:24 - progress_bar.py[line:274] - INFO: epoch 001:  27880 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4188, wps=100, ups=0.46, wpb=108.6, bsz=40, num_updates=27840, lr=3.95663e-05, gnorm=0.151, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=112060
2023-01-09 05:58:47 - progress_bar.py[line:274] - INFO: epoch 001:  27890 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.445, wps=99.2, ups=0.46, wpb=108.6, bsz=40, num_updates=27850, lr=3.95618e-05, gnorm=0.244, clip=0, loss_scale=512, train_wall=22, gb_free=9.6, ema_decay=0.9999, wall=112082
2023-01-09 05:59:08 - progress_bar.py[line:274] - INFO: epoch 001:  27900 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4061, wps=108.1, ups=0.49, wpb=109.7, bsz=40, num_updates=27860, lr=3.95573e-05, gnorm=0.252, clip=10, loss_scale=512, train_wall=20, gb_free=10.3, ema_decay=0.9999, wall=112103
2023-01-09 05:59:30 - progress_bar.py[line:274] - INFO: epoch 001:  27910 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4502, wps=101.1, ups=0.47, wpb=107.6, bsz=40, num_updates=27870, lr=3.95528e-05, gnorm=0.169, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=112125
2023-01-09 05:59:52 - progress_bar.py[line:274] - INFO: epoch 001:  27920 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4455, wps=101.1, ups=0.46, wpb=109.8, bsz=40, num_updates=27880, lr=3.95483e-05, gnorm=0.255, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=112148
2023-01-09 06:00:07 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 06:00:16 - progress_bar.py[line:274] - INFO: epoch 001:  27931 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.952, nsentences=40, sample_size=108.952, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4342, wps=97.3, ups=0.43, wpb=109, bsz=40, num_updates=27890, lr=3.95438e-05, gnorm=0.193, clip=0, loss_scale=256, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=112172
2023-01-09 06:00:39 - progress_bar.py[line:274] - INFO: epoch 001:  27941 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.46, wps=100.4, ups=0.46, wpb=110.1, bsz=40, num_updates=27900, lr=3.95393e-05, gnorm=0.26, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=112194
2023-01-09 06:01:01 - progress_bar.py[line:274] - INFO: epoch 001:  27951 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4731, wps=102.6, ups=0.47, wpb=109.1, bsz=40, num_updates=27910, lr=3.95349e-05, gnorm=0.172, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=112216
2023-01-09 06:01:23 - progress_bar.py[line:274] - INFO: epoch 001:  27961 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4615, wps=99.5, ups=0.46, wpb=108.5, bsz=40, num_updates=27920, lr=3.95304e-05, gnorm=0.116, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=112238
2023-01-09 06:01:45 - progress_bar.py[line:274] - INFO: epoch 001:  27971 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4576, wps=106.1, ups=0.48, wpb=111, bsz=40, num_updates=27930, lr=3.95259e-05, gnorm=0.225, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=112260
2023-01-09 06:02:07 - progress_bar.py[line:274] - INFO: epoch 001:  27981 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4409, wps=100.6, ups=0.46, wpb=109.4, bsz=40, num_updates=27940, lr=3.95214e-05, gnorm=0.242, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=112282
2023-01-09 06:02:29 - progress_bar.py[line:274] - INFO: epoch 001:  27991 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4163, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=27950, lr=3.95169e-05, gnorm=0.317, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=112304
2023-01-09 06:02:52 - progress_bar.py[line:274] - INFO: epoch 001:  28001 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4532, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=27960, lr=3.95124e-05, gnorm=0.315, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=112327
2023-01-09 06:03:14 - progress_bar.py[line:274] - INFO: epoch 001:  28011 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4058, wps=102.2, ups=0.47, wpb=109.3, bsz=40, num_updates=27970, lr=3.95079e-05, gnorm=0.29, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=112349
2023-01-09 06:03:36 - progress_bar.py[line:274] - INFO: epoch 001:  28021 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4278, wps=101, ups=0.46, wpb=109.6, bsz=40, num_updates=27980, lr=3.95034e-05, gnorm=0.301, clip=10, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=112371
2023-01-09 06:03:58 - progress_bar.py[line:274] - INFO: epoch 001:  28031 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4402, wps=102.7, ups=0.47, wpb=109.7, bsz=40, num_updates=27990, lr=3.94989e-05, gnorm=0.158, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=112393
2023-01-09 06:04:20 - progress_bar.py[line:274] - INFO: epoch 001:  28041 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=104.5, ups=0.48, wpb=109.6, bsz=40, num_updates=28000, lr=3.94944e-05, gnorm=0.246, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=112415
2023-01-09 06:04:20 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-09 06:04:21 - train.py[line:549] - INFO: 0 / 4988
2023-01-09 06:04:21 - train.py[line:551] - INFO: load:0.99 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-09 06:06:53 - train.py[line:549] - INFO: 200 / 4988
2023-01-09 06:06:53 - train.py[line:551] - INFO: load:1.02 valid_run:152.04 task_valid:148.38 collect_output:2.57
2023-01-09 06:09:22 - train.py[line:549] - INFO: 400 / 4988
2023-01-09 06:09:22 - train.py[line:551] - INFO: load:1.05 valid_run:300.36 task_valid:291.08 collect_output:7.17
2023-01-09 06:11:54 - train.py[line:549] - INFO: 600 / 4988
2023-01-09 06:11:54 - train.py[line:551] - INFO: load:1.07 valid_run:452.57 task_valid:433.77 collect_output:15.67
2023-01-09 06:14:23 - train.py[line:549] - INFO: 800 / 4988
2023-01-09 06:14:23 - train.py[line:551] - INFO: load:1.10 valid_run:601.46 task_valid:578.31 collect_output:19.02
2023-01-09 06:16:55 - train.py[line:549] - INFO: 1000 / 4988
2023-01-09 06:16:56 - train.py[line:551] - INFO: load:1.13 valid_run:753.93 task_valid:725.52 collect_output:23.28
2023-01-09 06:19:27 - train.py[line:549] - INFO: 1200 / 4988
2023-01-09 06:19:27 - train.py[line:551] - INFO: load:1.15 valid_run:905.50 task_valid:870.66 collect_output:28.68
2023-01-09 06:22:01 - train.py[line:549] - INFO: 1400 / 4988
2023-01-09 06:22:01 - train.py[line:551] - INFO: load:1.18 valid_run:1058.94 task_valid:1016.34 collect_output:35.42
2023-01-09 06:24:32 - train.py[line:549] - INFO: 1600 / 4988
2023-01-09 06:24:32 - train.py[line:551] - INFO: load:1.21 valid_run:1210.29 task_valid:1157.13 collect_output:44.98
2023-01-09 06:27:02 - train.py[line:549] - INFO: 1800 / 4988
2023-01-09 06:27:02 - train.py[line:551] - INFO: load:1.23 valid_run:1360.11 task_valid:1301.64 collect_output:49.28
2023-01-09 06:29:31 - train.py[line:549] - INFO: 2000 / 4988
2023-01-09 06:29:31 - train.py[line:551] - INFO: load:1.26 valid_run:1508.70 task_valid:1444.49 collect_output:54.01
2023-01-09 06:32:00 - train.py[line:549] - INFO: 2200 / 4988
2023-01-09 06:32:00 - train.py[line:551] - INFO: load:1.29 valid_run:1658.31 task_valid:1589.02 collect_output:58.08
2023-01-09 06:34:30 - train.py[line:549] - INFO: 2400 / 4988
2023-01-09 06:34:30 - train.py[line:551] - INFO: load:1.31 valid_run:1808.14 task_valid:1733.61 collect_output:62.32
2023-01-09 06:37:01 - train.py[line:549] - INFO: 2600 / 4988
2023-01-09 06:37:01 - train.py[line:551] - INFO: load:1.34 valid_run:1958.52 task_valid:1875.28 collect_output:69.99
2023-01-09 06:39:31 - train.py[line:549] - INFO: 2800 / 4988
2023-01-09 06:39:31 - train.py[line:551] - INFO: load:1.37 valid_run:2109.00 task_valid:2020.53 collect_output:74.22
2023-01-09 06:42:01 - train.py[line:549] - INFO: 3000 / 4988
2023-01-09 06:42:01 - train.py[line:551] - INFO: load:1.39 valid_run:2258.91 task_valid:2166.68 collect_output:76.96
2023-01-09 06:44:31 - train.py[line:549] - INFO: 3200 / 4988
2023-01-09 06:44:31 - train.py[line:551] - INFO: load:1.42 valid_run:2408.89 task_valid:2310.54 collect_output:82.08
2023-01-09 06:47:03 - train.py[line:549] - INFO: 3400 / 4988
2023-01-09 06:47:03 - train.py[line:551] - INFO: load:1.45 valid_run:2560.94 task_valid:2455.96 collect_output:87.67
2023-01-09 06:49:34 - train.py[line:549] - INFO: 3600 / 4988
2023-01-09 06:49:34 - train.py[line:551] - INFO: load:1.48 valid_run:2711.23 task_valid:2602.49 collect_output:90.42
2023-01-09 06:52:02 - train.py[line:549] - INFO: 3800 / 4988
2023-01-09 06:52:02 - train.py[line:551] - INFO: load:1.51 valid_run:2859.69 task_valid:2743.83 collect_output:96.50
2023-01-09 06:54:33 - train.py[line:549] - INFO: 4000 / 4988
2023-01-09 06:54:33 - train.py[line:551] - INFO: load:1.53 valid_run:3010.11 task_valid:2888.59 collect_output:101.16
2023-01-09 06:57:05 - train.py[line:549] - INFO: 4200 / 4988
2023-01-09 06:57:05 - train.py[line:551] - INFO: load:1.56 valid_run:3162.52 task_valid:3033.09 collect_output:108.05
2023-01-09 06:59:35 - train.py[line:549] - INFO: 4400 / 4988
2023-01-09 06:59:35 - train.py[line:551] - INFO: load:1.59 valid_run:3311.84 task_valid:3177.28 collect_output:112.16
2023-01-09 07:02:06 - train.py[line:549] - INFO: 4600 / 4988
2023-01-09 07:02:06 - train.py[line:551] - INFO: load:1.61 valid_run:3462.97 task_valid:3323.06 collect_output:116.49
2023-01-09 07:04:37 - train.py[line:549] - INFO: 4800 / 4988
2023-01-09 07:04:37 - train.py[line:551] - INFO: load:1.64 valid_run:3614.18 task_valid:3469.20 collect_output:120.55

====================================================================================================
SGG eval:     R @ 50: 0.3462;     R @ 100: 0.4107;     R @ 500: 0.4343;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2183;    mR @ 100: 0.2693;    mR @ 500: 0.2970;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2805) (covered in:0.6875) (covering:0.3714) (eating:0.6176) (flying in:0.0000) (growing on:0.0000) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.6146) (playing:0.0000) (riding:0.3039) (says:0.0000) (sitting on:0.7115) (standing on:0.1850) (using:0.7000) (walking in:0.0000) (walking on:0.0901) (watching:0.1389) 
--------------------------------------------------------
====================================================================================================

2023-01-09 07:07:08 - train.py[line:487] - INFO: 0.4107285714285714

====================================================================================================
SGG eval:     R @ 50: 0.3462;     R @ 100: 0.4107;     R @ 500: 0.4343;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2183;    mR @ 100: 0.2693;    mR @ 500: 0.2970;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2805) (covered in:0.6875) (covering:0.3714) (eating:0.6176) (flying in:0.0000) (growing on:0.0000) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.6146) (playing:0.0000) (riding:0.3039) (says:0.0000) (sitting on:0.7115) (standing on:0.1850) (using:0.7000) (walking in:0.0000) (walking on:0.0901) (watching:0.1389) 
--------------------------------------------------------
====================================================================================================

2023-01-09 07:07:08 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-09 07:07:08 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.403 | loss_v1 0 | loss_v2 0 | nll_loss 0.255 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.410729 | ppl 1.19 | vqa_score 0.3232 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 28000 | best_R@100 0.645421
2023-01-09 07:07:08 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 28000 updates
2023-01-09 07:07:08 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_28000.pt
2023-01-09 07:07:49 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_28000.pt
2023-01-09 07:09:19 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_28000.pt (epoch 1 @ 28000 updates, score 0.4107285714285714) (writing took 131.02087318710983 seconds)
2023-01-09 07:09:41 - progress_bar.py[line:274] - INFO: epoch 001:  28051 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5106, wps=0.6, ups=0, wpb=109.7, bsz=40, num_updates=28010, lr=3.94899e-05, gnorm=0.261, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=116336
2023-01-09 07:10:03 - progress_bar.py[line:274] - INFO: epoch 001:  28061 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4567, wps=103, ups=0.47, wpb=109.5, bsz=40, num_updates=28020, lr=3.94854e-05, gnorm=0.205, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=116358
2023-01-09 07:10:24 - progress_bar.py[line:274] - INFO: epoch 001:  28071 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4067, wps=103.8, ups=0.48, wpb=108.6, bsz=40, num_updates=28030, lr=3.94809e-05, gnorm=0.329, clip=10, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=116380
2023-01-09 07:10:46 - progress_bar.py[line:274] - INFO: epoch 001:  28081 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4715, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=28040, lr=3.94764e-05, gnorm=0.204, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=116402
2023-01-09 07:11:07 - progress_bar.py[line:274] - INFO: epoch 001:  28091 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4652, wps=101.2, ups=0.47, wpb=107.7, bsz=40, num_updates=28050, lr=3.94719e-05, gnorm=0.249, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=116423
2023-01-09 07:11:29 - progress_bar.py[line:274] - INFO: epoch 001:  28101 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4692, wps=99.7, ups=0.46, wpb=107.6, bsz=40, num_updates=28060, lr=3.94674e-05, gnorm=0.352, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=116445
2023-01-09 07:11:51 - progress_bar.py[line:274] - INFO: epoch 001:  28111 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4653, wps=99.8, ups=0.46, wpb=107.9, bsz=40, num_updates=28070, lr=3.94629e-05, gnorm=0.158, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=116467
2023-01-09 07:12:12 - progress_bar.py[line:274] - INFO: epoch 001:  28121 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.449, wps=104.8, ups=0.48, wpb=109.8, bsz=40, num_updates=28080, lr=3.94584e-05, gnorm=0.284, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=116488
2023-01-09 07:12:34 - progress_bar.py[line:274] - INFO: epoch 001:  28131 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4121, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=28090, lr=3.94539e-05, gnorm=0.239, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=116510
2023-01-09 07:12:56 - progress_bar.py[line:274] - INFO: epoch 001:  28141 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.447, wps=101.1, ups=0.47, wpb=108, bsz=40, num_updates=28100, lr=3.94494e-05, gnorm=0.303, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=116532
2023-01-09 07:13:18 - progress_bar.py[line:274] - INFO: epoch 001:  28151 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4227, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=28110, lr=3.94449e-05, gnorm=0.151, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=116554
2023-01-09 07:13:40 - progress_bar.py[line:274] - INFO: epoch 001:  28161 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4951, wps=100, ups=0.46, wpb=109.2, bsz=40, num_updates=28120, lr=3.94404e-05, gnorm=0.229, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=116576
2023-01-09 07:14:02 - progress_bar.py[line:274] - INFO: epoch 001:  28171 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4257, wps=99.9, ups=0.46, wpb=109.6, bsz=40, num_updates=28130, lr=3.94359e-05, gnorm=0.148, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=116598
2023-01-09 07:14:24 - progress_bar.py[line:274] - INFO: epoch 001:  28181 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4106, wps=100.1, ups=0.46, wpb=108.1, bsz=40, num_updates=28140, lr=3.94314e-05, gnorm=0.298, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=116620
2023-01-09 07:14:45 - progress_bar.py[line:274] - INFO: epoch 001:  28191 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4301, wps=104.4, ups=0.48, wpb=109.4, bsz=40, num_updates=28150, lr=3.9427e-05, gnorm=0.217, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=116641
2023-01-09 07:15:07 - progress_bar.py[line:274] - INFO: epoch 001:  28201 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4202, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=28160, lr=3.94225e-05, gnorm=0.241, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=116663
2023-01-09 07:15:29 - progress_bar.py[line:274] - INFO: epoch 001:  28211 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4904, wps=102.3, ups=0.47, wpb=109, bsz=40, num_updates=28170, lr=3.9418e-05, gnorm=0.249, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=116684
2023-01-09 07:15:50 - progress_bar.py[line:274] - INFO: epoch 001:  28221 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4677, wps=102.1, ups=0.47, wpb=108.5, bsz=40, num_updates=28180, lr=3.94135e-05, gnorm=0.14, clip=0, loss_scale=256, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=116706
2023-01-09 07:16:12 - progress_bar.py[line:274] - INFO: epoch 001:  28231 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4192, wps=103.6, ups=0.47, wpb=109.7, bsz=40, num_updates=28190, lr=3.9409e-05, gnorm=0.432, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=116727
2023-01-09 07:16:33 - progress_bar.py[line:274] - INFO: epoch 001:  28241 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4922, wps=102.9, ups=0.47, wpb=110.2, bsz=40, num_updates=28200, lr=3.94045e-05, gnorm=0.155, clip=0, loss_scale=256, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=116749
2023-01-09 07:16:55 - progress_bar.py[line:274] - INFO: epoch 001:  28251 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4844, wps=100.7, ups=0.46, wpb=108.9, bsz=40, num_updates=28210, lr=3.94e-05, gnorm=0.162, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=116771
2023-01-09 07:17:17 - progress_bar.py[line:274] - INFO: epoch 001:  28261 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5051, wps=101.2, ups=0.46, wpb=110, bsz=40, num_updates=28220, lr=3.93955e-05, gnorm=0.307, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=116793
2023-01-09 07:17:39 - progress_bar.py[line:274] - INFO: epoch 001:  28271 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4787, wps=100.7, ups=0.47, wpb=108.1, bsz=40, num_updates=28230, lr=3.9391e-05, gnorm=0.184, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=116815
2023-01-09 07:18:02 - progress_bar.py[line:274] - INFO: epoch 001:  28281 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4521, wps=102, ups=0.47, wpb=109.6, bsz=40, num_updates=28240, lr=3.93865e-05, gnorm=0.209, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=116836
2023-01-09 07:18:25 - progress_bar.py[line:274] - INFO: epoch 001:  28291 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4188, wps=101.6, ups=0.46, wpb=109.3, bsz=40, num_updates=28250, lr=3.9382e-05, gnorm=0.194, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=116859
2023-01-09 07:18:48 - progress_bar.py[line:274] - INFO: epoch 001:  28301 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4615, wps=99.7, ups=0.46, wpb=108.7, bsz=40, num_updates=28260, lr=3.93775e-05, gnorm=0.23, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=116883
2023-01-09 07:19:12 - progress_bar.py[line:274] - INFO: epoch 001:  28311 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3814, wps=99.7, ups=0.46, wpb=107.9, bsz=40, num_updates=28270, lr=3.9373e-05, gnorm=0.323, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=116906
2023-01-09 07:19:35 - progress_bar.py[line:274] - INFO: epoch 001:  28321 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5202, wps=101.7, ups=0.47, wpb=109.3, bsz=40, num_updates=28280, lr=3.93685e-05, gnorm=0.22, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=116929
2023-01-09 07:19:58 - progress_bar.py[line:274] - INFO: epoch 001:  28331 / 115845 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.5217, wps=102.5, ups=0.47, wpb=109.7, bsz=40, num_updates=28290, lr=3.9364e-05, gnorm=0.154, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=116952
2023-01-09 07:20:21 - progress_bar.py[line:274] - INFO: epoch 001:  28341 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3861, wps=102.7, ups=0.47, wpb=109, bsz=40, num_updates=28300, lr=3.93595e-05, gnorm=0.23, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=116975
2023-01-09 07:20:44 - progress_bar.py[line:274] - INFO: epoch 001:  28351 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4703, wps=100.4, ups=0.47, wpb=107.8, bsz=40, num_updates=28310, lr=3.9355e-05, gnorm=0.141, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=116998
2023-01-09 07:21:07 - progress_bar.py[line:274] - INFO: epoch 001:  28361 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4315, wps=103.4, ups=0.47, wpb=109.2, bsz=40, num_updates=28320, lr=3.93505e-05, gnorm=0.179, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=117022
2023-01-09 07:21:30 - progress_bar.py[line:274] - INFO: epoch 001:  28371 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4813, wps=101.4, ups=0.46, wpb=109.3, bsz=40, num_updates=28330, lr=3.9346e-05, gnorm=0.194, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=117044
2023-01-09 07:21:52 - progress_bar.py[line:274] - INFO: epoch 001:  28381 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4904, wps=102.9, ups=0.47, wpb=108.9, bsz=40, num_updates=28340, lr=3.93415e-05, gnorm=0.216, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=117067
2023-01-09 07:22:15 - progress_bar.py[line:274] - INFO: epoch 001:  28391 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.455, wps=105.4, ups=0.48, wpb=109.9, bsz=40, num_updates=28350, lr=3.9337e-05, gnorm=0.238, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=117089
2023-01-09 07:22:38 - progress_bar.py[line:274] - INFO: epoch 001:  28401 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5095, wps=99.2, ups=0.46, wpb=108.5, bsz=40, num_updates=28360, lr=3.93325e-05, gnorm=0.33, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=117113
2023-01-09 07:23:01 - progress_bar.py[line:274] - INFO: epoch 001:  28411 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4398, wps=100.9, ups=0.46, wpb=109.7, bsz=40, num_updates=28370, lr=3.9328e-05, gnorm=0.207, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=117136
2023-01-09 07:23:24 - progress_bar.py[line:274] - INFO: epoch 001:  28421 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4194, wps=101.7, ups=0.46, wpb=109.6, bsz=40, num_updates=28380, lr=3.93235e-05, gnorm=0.24, clip=0, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=117159
2023-01-09 07:23:47 - progress_bar.py[line:274] - INFO: epoch 001:  28431 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5285, wps=99.3, ups=0.45, wpb=109.2, bsz=40, num_updates=28390, lr=3.9319e-05, gnorm=0.242, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=117182
2023-01-09 07:24:10 - progress_bar.py[line:274] - INFO: epoch 001:  28441 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4256, wps=99.6, ups=0.46, wpb=108.3, bsz=40, num_updates=28400, lr=3.93146e-05, gnorm=0.248, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=117205
2023-01-09 07:24:33 - progress_bar.py[line:274] - INFO: epoch 001:  28451 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4488, wps=101, ups=0.47, wpb=107.9, bsz=40, num_updates=28410, lr=3.93101e-05, gnorm=0.321, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=117228
2023-01-09 07:24:56 - progress_bar.py[line:274] - INFO: epoch 001:  28461 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4221, wps=102.9, ups=0.47, wpb=108.7, bsz=40, num_updates=28420, lr=3.93056e-05, gnorm=0.449, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=117250
2023-01-09 07:25:19 - progress_bar.py[line:274] - INFO: epoch 001:  28471 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4922, wps=99.6, ups=0.45, wpb=109.5, bsz=40, num_updates=28430, lr=3.93011e-05, gnorm=0.208, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=117274
2023-01-09 07:25:42 - progress_bar.py[line:274] - INFO: epoch 001:  28481 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4865, wps=101.6, ups=0.47, wpb=109.2, bsz=40, num_updates=28440, lr=3.92966e-05, gnorm=0.176, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=117296
2023-01-09 07:25:59 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 07:26:07 - progress_bar.py[line:274] - INFO: epoch 001:  28492 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.429, nsentences=40, sample_size=108.429, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4753, wps=96.4, ups=0.42, wpb=108.4, bsz=40, num_updates=28450, lr=3.92921e-05, gnorm=0.272, clip=0, loss_scale=256, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=117321
2023-01-09 07:26:30 - progress_bar.py[line:274] - INFO: epoch 001:  28502 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4118, wps=102, ups=0.47, wpb=108.3, bsz=40, num_updates=28460, lr=3.92876e-05, gnorm=0.35, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=117344
2023-01-09 07:26:53 - progress_bar.py[line:274] - INFO: epoch 001:  28512 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4532, wps=102.2, ups=0.47, wpb=109.5, bsz=40, num_updates=28470, lr=3.92831e-05, gnorm=0.255, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=117367
2023-01-09 07:27:16 - progress_bar.py[line:274] - INFO: epoch 001:  28522 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4112, wps=99.4, ups=0.46, wpb=108, bsz=40, num_updates=28480, lr=3.92786e-05, gnorm=0.177, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=117391
2023-01-09 07:27:39 - progress_bar.py[line:274] - INFO: epoch 001:  28532 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4545, wps=98.8, ups=0.45, wpb=108.6, bsz=40, num_updates=28490, lr=3.92741e-05, gnorm=0.273, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=117414
2023-01-09 07:28:02 - progress_bar.py[line:274] - INFO: epoch 001:  28542 / 115845 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4462, wps=103.8, ups=0.47, wpb=109.8, bsz=40, num_updates=28500, lr=3.92696e-05, gnorm=0.151, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=117436
2023-01-09 07:28:26 - progress_bar.py[line:274] - INFO: epoch 001:  28552 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.408, wps=99.1, ups=0.46, wpb=108.6, bsz=40, num_updates=28510, lr=3.92651e-05, gnorm=0.283, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=117460
2023-01-09 07:28:50 - progress_bar.py[line:274] - INFO: epoch 001:  28562 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4975, wps=99.3, ups=0.45, wpb=109.4, bsz=40, num_updates=28520, lr=3.92606e-05, gnorm=0.167, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=117484
2023-01-09 07:29:13 - progress_bar.py[line:274] - INFO: epoch 001:  28572 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4536, wps=100.3, ups=0.46, wpb=108.9, bsz=40, num_updates=28530, lr=3.92561e-05, gnorm=0.324, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=117508
2023-01-09 07:29:36 - progress_bar.py[line:274] - INFO: epoch 001:  28582 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3744, wps=100.3, ups=0.46, wpb=108.4, bsz=40, num_updates=28540, lr=3.92516e-05, gnorm=0.241, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=117531
2023-01-09 07:29:59 - progress_bar.py[line:274] - INFO: epoch 001:  28592 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3697, wps=100.6, ups=0.46, wpb=108.4, bsz=40, num_updates=28550, lr=3.92471e-05, gnorm=0.199, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=117554
2023-01-09 07:30:22 - progress_bar.py[line:274] - INFO: epoch 001:  28602 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4241, wps=102.4, ups=0.47, wpb=109.7, bsz=40, num_updates=28560, lr=3.92426e-05, gnorm=0.279, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=117577
2023-01-09 07:30:45 - progress_bar.py[line:274] - INFO: epoch 001:  28612 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4385, wps=106.3, ups=0.48, wpb=110.9, bsz=40, num_updates=28570, lr=3.92381e-05, gnorm=0.217, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=117599
2023-01-09 07:31:07 - progress_bar.py[line:274] - INFO: epoch 001:  28622 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.445, wps=102.9, ups=0.47, wpb=109.7, bsz=40, num_updates=28580, lr=3.92336e-05, gnorm=0.213, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=117622
2023-01-09 07:31:30 - progress_bar.py[line:274] - INFO: epoch 001:  28632 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5217, wps=103.7, ups=0.48, wpb=109.1, bsz=40, num_updates=28590, lr=3.92291e-05, gnorm=0.182, clip=0, loss_scale=256, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=117644
2023-01-09 07:31:53 - progress_bar.py[line:274] - INFO: epoch 001:  28642 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5226, wps=100.8, ups=0.46, wpb=109.9, bsz=40, num_updates=28600, lr=3.92246e-05, gnorm=0.17, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=117668
2023-01-09 07:32:16 - progress_bar.py[line:274] - INFO: epoch 001:  28652 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4375, wps=99.8, ups=0.46, wpb=108.1, bsz=40, num_updates=28610, lr=3.92201e-05, gnorm=0.344, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=117691
2023-01-09 07:32:40 - progress_bar.py[line:274] - INFO: epoch 001:  28662 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4178, wps=98.9, ups=0.46, wpb=108.5, bsz=40, num_updates=28620, lr=3.92156e-05, gnorm=0.206, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=117714
2023-01-09 07:33:03 - progress_bar.py[line:274] - INFO: epoch 001:  28672 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4421, wps=101.9, ups=0.46, wpb=110, bsz=40, num_updates=28630, lr=3.92111e-05, gnorm=0.284, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=117737
2023-01-09 07:33:26 - progress_bar.py[line:274] - INFO: epoch 001:  28682 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4764, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=28640, lr=3.92067e-05, gnorm=0.129, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=117760
2023-01-09 07:33:49 - progress_bar.py[line:274] - INFO: epoch 001:  28692 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4567, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=28650, lr=3.92022e-05, gnorm=0.283, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=117784
2023-01-09 07:34:12 - progress_bar.py[line:274] - INFO: epoch 001:  28702 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=103.3, ups=0.47, wpb=109.5, bsz=40, num_updates=28660, lr=3.91977e-05, gnorm=0.153, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=117806
2023-01-09 07:34:35 - progress_bar.py[line:274] - INFO: epoch 001:  28712 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4472, wps=99.2, ups=0.46, wpb=109, bsz=40, num_updates=28670, lr=3.91932e-05, gnorm=0.213, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=117830
2023-01-09 07:34:59 - progress_bar.py[line:274] - INFO: epoch 001:  28722 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3871, wps=100.2, ups=0.46, wpb=110, bsz=40, num_updates=28680, lr=3.91887e-05, gnorm=0.131, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=117853
2023-01-09 07:35:22 - progress_bar.py[line:274] - INFO: epoch 001:  28732 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4732, wps=101.4, ups=0.47, wpb=108.5, bsz=40, num_updates=28690, lr=3.91842e-05, gnorm=0.241, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=117876
2023-01-09 07:35:45 - progress_bar.py[line:274] - INFO: epoch 001:  28742 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.7, nsentences=40, sample_size=106.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.445, wps=99.6, ups=0.47, wpb=106.7, bsz=40, num_updates=28700, lr=3.91797e-05, gnorm=0.386, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=117899
2023-01-09 07:36:08 - progress_bar.py[line:274] - INFO: epoch 001:  28752 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5025, wps=101.1, ups=0.46, wpb=109.3, bsz=40, num_updates=28710, lr=3.91752e-05, gnorm=0.207, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=117922
2023-01-09 07:36:30 - progress_bar.py[line:274] - INFO: epoch 001:  28762 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4615, wps=102.6, ups=0.47, wpb=108.2, bsz=40, num_updates=28720, lr=3.91707e-05, gnorm=0.159, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=117945
2023-01-09 07:36:53 - progress_bar.py[line:274] - INFO: epoch 001:  28772 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.45, wps=99.5, ups=0.46, wpb=107.8, bsz=40, num_updates=28730, lr=3.91662e-05, gnorm=0.131, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=117968
2023-01-09 07:37:15 - progress_bar.py[line:274] - INFO: epoch 001:  28782 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4541, wps=98.9, ups=0.46, wpb=107.9, bsz=40, num_updates=28740, lr=3.91617e-05, gnorm=0.509, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=117991
2023-01-09 07:37:36 - progress_bar.py[line:274] - INFO: epoch 001:  28792 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4495, wps=104, ups=0.48, wpb=108.9, bsz=40, num_updates=28750, lr=3.91572e-05, gnorm=0.241, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=118012
2023-01-09 07:37:58 - progress_bar.py[line:274] - INFO: epoch 001:  28802 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4327, wps=102.8, ups=0.47, wpb=108.5, bsz=40, num_updates=28760, lr=3.91527e-05, gnorm=0.32, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=118033
2023-01-09 07:38:19 - progress_bar.py[line:274] - INFO: epoch 001:  28812 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4739, wps=102.1, ups=0.47, wpb=108.9, bsz=40, num_updates=28770, lr=3.91482e-05, gnorm=0.26, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=118055
2023-01-09 07:38:40 - progress_bar.py[line:274] - INFO: epoch 001:  28822 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4731, wps=105.6, ups=0.48, wpb=110.5, bsz=40, num_updates=28780, lr=3.91437e-05, gnorm=0.25, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=118076
2023-01-09 07:39:02 - progress_bar.py[line:274] - INFO: epoch 001:  28832 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4977, wps=101.6, ups=0.47, wpb=108.9, bsz=40, num_updates=28790, lr=3.91392e-05, gnorm=0.308, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=118098
2023-01-09 07:39:24 - progress_bar.py[line:274] - INFO: epoch 001:  28842 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4257, wps=100.2, ups=0.46, wpb=109, bsz=40, num_updates=28800, lr=3.91347e-05, gnorm=0.369, clip=0, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=118120
2023-01-09 07:39:45 - progress_bar.py[line:274] - INFO: epoch 001:  28852 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4519, wps=104, ups=0.48, wpb=108.9, bsz=40, num_updates=28810, lr=3.91302e-05, gnorm=0.24, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=118141
2023-01-09 07:40:07 - progress_bar.py[line:274] - INFO: epoch 001:  28862 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4444, wps=102.2, ups=0.47, wpb=109.1, bsz=40, num_updates=28820, lr=3.91257e-05, gnorm=0.286, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=118163
2023-01-09 07:40:29 - progress_bar.py[line:274] - INFO: epoch 001:  28872 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4414, wps=99.2, ups=0.46, wpb=107.2, bsz=40, num_updates=28830, lr=3.91212e-05, gnorm=0.148, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=118185
2023-01-09 07:40:51 - progress_bar.py[line:274] - INFO: epoch 001:  28882 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4593, wps=99.9, ups=0.46, wpb=108.8, bsz=40, num_updates=28840, lr=3.91167e-05, gnorm=0.18, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=118207
2023-01-09 07:41:13 - progress_bar.py[line:274] - INFO: epoch 001:  28892 / 115845 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4865, wps=100.3, ups=0.46, wpb=110, bsz=40, num_updates=28850, lr=3.91122e-05, gnorm=0.146, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=118229
2023-01-09 07:41:35 - progress_bar.py[line:274] - INFO: epoch 001:  28902 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4493, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=28860, lr=3.91077e-05, gnorm=0.16, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=118250
2023-01-09 07:41:57 - progress_bar.py[line:274] - INFO: epoch 001:  28912 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4921, wps=101.5, ups=0.46, wpb=109.6, bsz=40, num_updates=28870, lr=3.91032e-05, gnorm=0.157, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=118272
2023-01-09 07:42:18 - progress_bar.py[line:274] - INFO: epoch 001:  28922 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4286, wps=103, ups=0.47, wpb=109.9, bsz=40, num_updates=28880, lr=3.90987e-05, gnorm=0.181, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=118294
2023-01-09 07:42:40 - progress_bar.py[line:274] - INFO: epoch 001:  28932 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4537, wps=103.4, ups=0.47, wpb=109.5, bsz=40, num_updates=28890, lr=3.90943e-05, gnorm=0.327, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=118315
2023-01-09 07:43:01 - progress_bar.py[line:274] - INFO: epoch 001:  28942 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4249, wps=101.6, ups=0.47, wpb=109, bsz=40, num_updates=28900, lr=3.90898e-05, gnorm=0.41, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=118337
2023-01-09 07:43:23 - progress_bar.py[line:274] - INFO: epoch 001:  28952 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3737, wps=100.9, ups=0.46, wpb=109.7, bsz=40, num_updates=28910, lr=3.90853e-05, gnorm=0.283, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=118359
2023-01-09 07:43:45 - progress_bar.py[line:274] - INFO: epoch 001:  28962 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4595, wps=100.8, ups=0.46, wpb=109.9, bsz=40, num_updates=28920, lr=3.90808e-05, gnorm=0.156, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=118381
2023-01-09 07:44:07 - progress_bar.py[line:274] - INFO: epoch 001:  28972 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.505, wps=102.1, ups=0.47, wpb=109.6, bsz=40, num_updates=28930, lr=3.90763e-05, gnorm=0.283, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=118403
2023-01-09 07:44:28 - progress_bar.py[line:274] - INFO: epoch 001:  28982 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4192, wps=102.7, ups=0.47, wpb=108.5, bsz=40, num_updates=28940, lr=3.90718e-05, gnorm=0.215, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=118424
2023-01-09 07:44:50 - progress_bar.py[line:274] - INFO: epoch 001:  28992 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5411, wps=104.1, ups=0.47, wpb=109.7, bsz=40, num_updates=28950, lr=3.90673e-05, gnorm=0.193, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=118446
2023-01-09 07:45:11 - progress_bar.py[line:274] - INFO: epoch 001:  29002 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4694, wps=102.9, ups=0.47, wpb=108.7, bsz=40, num_updates=28960, lr=3.90628e-05, gnorm=0.19, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=118467
2023-01-09 07:45:33 - progress_bar.py[line:274] - INFO: epoch 001:  29012 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4721, wps=100.7, ups=0.46, wpb=108.8, bsz=40, num_updates=28970, lr=3.90583e-05, gnorm=0.315, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=118489
2023-01-09 07:45:55 - progress_bar.py[line:274] - INFO: epoch 001:  29022 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4235, wps=100.5, ups=0.46, wpb=109.2, bsz=40, num_updates=28980, lr=3.90538e-05, gnorm=0.239, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=118511
2023-01-09 07:46:17 - progress_bar.py[line:274] - INFO: epoch 001:  29032 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4901, wps=100, ups=0.46, wpb=107.6, bsz=40, num_updates=28990, lr=3.90493e-05, gnorm=0.235, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=118533
2023-01-09 07:46:39 - progress_bar.py[line:274] - INFO: epoch 001:  29042 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4615, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=29000, lr=3.90448e-05, gnorm=0.297, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=118555
2023-01-09 07:47:01 - progress_bar.py[line:274] - INFO: epoch 001:  29052 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4286, wps=101.1, ups=0.46, wpb=108.8, bsz=40, num_updates=29010, lr=3.90403e-05, gnorm=0.171, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=118576
2023-01-09 07:47:23 - progress_bar.py[line:274] - INFO: epoch 001:  29062 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4262, wps=102.6, ups=0.46, wpb=110.8, bsz=40, num_updates=29020, lr=3.90358e-05, gnorm=0.212, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=118598
2023-01-09 07:47:44 - progress_bar.py[line:274] - INFO: epoch 001:  29072 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4663, wps=102.5, ups=0.47, wpb=109.5, bsz=40, num_updates=29030, lr=3.90313e-05, gnorm=0.192, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=118620
2023-01-09 07:48:06 - progress_bar.py[line:274] - INFO: epoch 001:  29082 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4585, wps=99.5, ups=0.46, wpb=109.1, bsz=40, num_updates=29040, lr=3.90268e-05, gnorm=0.343, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=118642
2023-01-09 07:48:28 - progress_bar.py[line:274] - INFO: epoch 001:  29092 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4742, wps=102.9, ups=0.47, wpb=110, bsz=40, num_updates=29050, lr=3.90223e-05, gnorm=0.184, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=118664
2023-01-09 07:48:50 - progress_bar.py[line:274] - INFO: epoch 001:  29102 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.476, wps=100.4, ups=0.46, wpb=109.3, bsz=40, num_updates=29060, lr=3.90178e-05, gnorm=0.151, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=118686
2023-01-09 07:49:12 - progress_bar.py[line:274] - INFO: epoch 001:  29112 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4663, wps=102.9, ups=0.47, wpb=109.4, bsz=40, num_updates=29070, lr=3.90133e-05, gnorm=0.159, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=118707
2023-01-09 07:49:33 - progress_bar.py[line:274] - INFO: epoch 001:  29122 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3938, wps=101.8, ups=0.47, wpb=109.2, bsz=40, num_updates=29080, lr=3.90088e-05, gnorm=0.148, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=118729
2023-01-09 07:49:55 - progress_bar.py[line:274] - INFO: epoch 001:  29132 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3827, wps=100.8, ups=0.46, wpb=108.9, bsz=40, num_updates=29090, lr=3.90043e-05, gnorm=0.178, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=118751
2023-01-09 07:50:17 - progress_bar.py[line:274] - INFO: epoch 001:  29142 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3704, wps=100.9, ups=0.46, wpb=109.6, bsz=40, num_updates=29100, lr=3.89998e-05, gnorm=0.259, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=118773
2023-01-09 07:50:39 - progress_bar.py[line:274] - INFO: epoch 001:  29152 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4313, wps=100.8, ups=0.46, wpb=109.5, bsz=40, num_updates=29110, lr=3.89953e-05, gnorm=0.201, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=118795
2023-01-09 07:51:01 - progress_bar.py[line:274] - INFO: epoch 001:  29162 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4147, wps=98.8, ups=0.46, wpb=107.5, bsz=40, num_updates=29120, lr=3.89908e-05, gnorm=0.182, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=118817
2023-01-09 07:51:23 - progress_bar.py[line:274] - INFO: epoch 001:  29172 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4375, wps=102, ups=0.47, wpb=108.5, bsz=40, num_updates=29130, lr=3.89864e-05, gnorm=0.185, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=118839
2023-01-09 07:51:44 - progress_bar.py[line:274] - INFO: epoch 001:  29182 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4262, wps=102.4, ups=0.47, wpb=109.5, bsz=40, num_updates=29140, lr=3.89819e-05, gnorm=0.161, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=118860
2023-01-09 07:52:06 - progress_bar.py[line:274] - INFO: epoch 001:  29192 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.467, wps=100.9, ups=0.47, wpb=108.4, bsz=40, num_updates=29150, lr=3.89774e-05, gnorm=0.156, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=118882
2023-01-09 07:52:28 - progress_bar.py[line:274] - INFO: epoch 001:  29202 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4439, wps=101.3, ups=0.46, wpb=109.7, bsz=40, num_updates=29160, lr=3.89729e-05, gnorm=0.331, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=118904
2023-01-09 07:52:50 - progress_bar.py[line:274] - INFO: epoch 001:  29212 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4112, wps=101.6, ups=0.46, wpb=109.4, bsz=40, num_updates=29170, lr=3.89684e-05, gnorm=0.183, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=118926
2023-01-09 07:53:12 - progress_bar.py[line:274] - INFO: epoch 001:  29222 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4461, wps=99.6, ups=0.46, wpb=108.6, bsz=40, num_updates=29180, lr=3.89639e-05, gnorm=0.377, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=118948
2023-01-09 07:53:33 - progress_bar.py[line:274] - INFO: epoch 001:  29232 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4138, wps=102.3, ups=0.47, wpb=109.2, bsz=40, num_updates=29190, lr=3.89594e-05, gnorm=0.618, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=118969
2023-01-09 07:53:55 - progress_bar.py[line:274] - INFO: epoch 001:  29242 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4737, wps=99.6, ups=0.46, wpb=108.7, bsz=40, num_updates=29200, lr=3.89549e-05, gnorm=0.33, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=118991
2023-01-09 07:54:17 - progress_bar.py[line:274] - INFO: epoch 001:  29252 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3962, wps=101.7, ups=0.47, wpb=107.7, bsz=40, num_updates=29210, lr=3.89504e-05, gnorm=0.193, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=119013
2023-01-09 07:54:39 - progress_bar.py[line:274] - INFO: epoch 001:  29262 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5104, wps=102.2, ups=0.46, wpb=109.9, bsz=40, num_updates=29220, lr=3.89459e-05, gnorm=0.172, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=119034
2023-01-09 07:55:00 - progress_bar.py[line:274] - INFO: epoch 001:  29272 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5567, wps=103.2, ups=0.47, wpb=110.8, bsz=40, num_updates=29230, lr=3.89414e-05, gnorm=0.401, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=119056
2023-01-09 07:55:22 - progress_bar.py[line:274] - INFO: epoch 001:  29282 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4652, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=29240, lr=3.89369e-05, gnorm=0.157, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=119078
2023-01-09 07:55:44 - progress_bar.py[line:274] - INFO: epoch 001:  29292 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.401, wps=102.8, ups=0.47, wpb=109.6, bsz=40, num_updates=29250, lr=3.89324e-05, gnorm=0.326, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=119100
2023-01-09 07:56:05 - progress_bar.py[line:274] - INFO: epoch 001:  29302 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4896, wps=102.7, ups=0.47, wpb=109.5, bsz=40, num_updates=29260, lr=3.89279e-05, gnorm=0.184, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=119121
2023-01-09 07:56:27 - progress_bar.py[line:274] - INFO: epoch 001:  29312 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4195, wps=99.5, ups=0.46, wpb=108.3, bsz=40, num_updates=29270, lr=3.89234e-05, gnorm=0.291, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=119143
2023-01-09 07:56:49 - progress_bar.py[line:274] - INFO: epoch 001:  29322 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4815, wps=102.1, ups=0.46, wpb=110.1, bsz=40, num_updates=29280, lr=3.89189e-05, gnorm=0.249, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=119165
2023-01-09 07:57:11 - progress_bar.py[line:274] - INFO: epoch 001:  29332 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4667, wps=102.1, ups=0.47, wpb=109.2, bsz=40, num_updates=29290, lr=3.89144e-05, gnorm=0.171, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=119187
2023-01-09 07:57:32 - progress_bar.py[line:274] - INFO: epoch 001:  29342 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5189, wps=100.8, ups=0.47, wpb=108.2, bsz=40, num_updates=29300, lr=3.89099e-05, gnorm=0.261, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=119208
2023-01-09 07:57:54 - progress_bar.py[line:274] - INFO: epoch 001:  29352 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5121, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=29310, lr=3.89054e-05, gnorm=0.168, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=119230
2023-01-09 07:58:16 - progress_bar.py[line:274] - INFO: epoch 001:  29362 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4301, wps=101.8, ups=0.46, wpb=109.8, bsz=40, num_updates=29320, lr=3.89009e-05, gnorm=0.438, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=119252
2023-01-09 07:58:38 - progress_bar.py[line:274] - INFO: epoch 001:  29372 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4567, wps=101.1, ups=0.46, wpb=108.8, bsz=40, num_updates=29330, lr=3.88964e-05, gnorm=0.207, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=119274
2023-01-09 07:58:59 - progress_bar.py[line:274] - INFO: epoch 001:  29382 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4314, wps=102.7, ups=0.48, wpb=107.1, bsz=40, num_updates=29340, lr=3.88919e-05, gnorm=0.102, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=119295
2023-01-09 07:59:20 - progress_bar.py[line:274] - INFO: epoch 001:  29392 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.455, wps=103.4, ups=0.47, wpb=109.8, bsz=40, num_updates=29350, lr=3.88874e-05, gnorm=0.177, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=119316
2023-01-09 07:59:42 - progress_bar.py[line:274] - INFO: epoch 001:  29402 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5169, wps=103.5, ups=0.47, wpb=109.3, bsz=40, num_updates=29360, lr=3.88829e-05, gnorm=0.207, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=119338
2023-01-09 08:00:04 - progress_bar.py[line:274] - INFO: epoch 001:  29412 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4929, wps=100.3, ups=0.46, wpb=108.9, bsz=40, num_updates=29370, lr=3.88784e-05, gnorm=0.224, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=119360
2023-01-09 08:00:26 - progress_bar.py[line:274] - INFO: epoch 001:  29422 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4085, wps=98.7, ups=0.46, wpb=107.5, bsz=40, num_updates=29380, lr=3.8874e-05, gnorm=0.142, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=119382
2023-01-09 08:00:48 - progress_bar.py[line:274] - INFO: epoch 001:  29432 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4826, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=29390, lr=3.88695e-05, gnorm=0.268, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=119403
2023-01-09 08:01:10 - progress_bar.py[line:274] - INFO: epoch 001:  29442 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4211, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=29400, lr=3.8865e-05, gnorm=0.321, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=119425
2023-01-09 08:01:31 - progress_bar.py[line:274] - INFO: epoch 001:  29452 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5253, wps=101.3, ups=0.47, wpb=108.1, bsz=40, num_updates=29410, lr=3.88605e-05, gnorm=0.246, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=119447
2023-01-09 08:01:53 - progress_bar.py[line:274] - INFO: epoch 001:  29462 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4773, wps=100.9, ups=0.47, wpb=108.1, bsz=40, num_updates=29420, lr=3.8856e-05, gnorm=0.223, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=119469
2023-01-09 08:02:15 - progress_bar.py[line:274] - INFO: epoch 001:  29472 / 115845 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4811, wps=101.9, ups=0.46, wpb=110.6, bsz=40, num_updates=29430, lr=3.88515e-05, gnorm=0.148, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=119491
2023-01-09 08:02:37 - progress_bar.py[line:274] - INFO: epoch 001:  29482 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4566, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=29440, lr=3.8847e-05, gnorm=0.181, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=119513
2023-01-09 08:02:58 - progress_bar.py[line:274] - INFO: epoch 001:  29492 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4789, wps=101.2, ups=0.46, wpb=108.8, bsz=40, num_updates=29450, lr=3.88425e-05, gnorm=0.191, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=119534
2023-01-09 08:03:20 - progress_bar.py[line:274] - INFO: epoch 001:  29502 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.385, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=29460, lr=3.8838e-05, gnorm=0.181, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=119556
2023-01-09 08:03:42 - progress_bar.py[line:274] - INFO: epoch 001:  29512 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4732, wps=101.2, ups=0.46, wpb=110.1, bsz=40, num_updates=29470, lr=3.88335e-05, gnorm=0.199, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=119578
2023-01-09 08:04:04 - progress_bar.py[line:274] - INFO: epoch 001:  29522 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4755, wps=102, ups=0.47, wpb=108.6, bsz=40, num_updates=29480, lr=3.8829e-05, gnorm=0.215, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=119600
2023-01-09 08:04:26 - progress_bar.py[line:274] - INFO: epoch 001:  29532 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5118, wps=102.3, ups=0.47, wpb=109.1, bsz=40, num_updates=29490, lr=3.88245e-05, gnorm=0.278, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=119621
2023-01-09 08:04:47 - progress_bar.py[line:274] - INFO: epoch 001:  29542 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4896, wps=101.5, ups=0.46, wpb=109.8, bsz=40, num_updates=29500, lr=3.882e-05, gnorm=0.294, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=119643
2023-01-09 08:05:10 - progress_bar.py[line:274] - INFO: epoch 001:  29552 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4479, wps=99.5, ups=0.46, wpb=109.3, bsz=40, num_updates=29510, lr=3.88155e-05, gnorm=0.163, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=119665
2023-01-09 08:05:32 - progress_bar.py[line:274] - INFO: epoch 001:  29562 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4837, wps=100.6, ups=0.46, wpb=110.3, bsz=40, num_updates=29520, lr=3.8811e-05, gnorm=0.281, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=119688
2023-01-09 08:05:54 - progress_bar.py[line:274] - INFO: epoch 001:  29572 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4831, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=29530, lr=3.88065e-05, gnorm=0.326, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=119709
2023-01-09 08:06:15 - progress_bar.py[line:274] - INFO: epoch 001:  29582 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4615, wps=102.7, ups=0.47, wpb=108.6, bsz=40, num_updates=29540, lr=3.8802e-05, gnorm=0.152, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=119731
2023-01-09 08:06:37 - progress_bar.py[line:274] - INFO: epoch 001:  29592 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4185, wps=100.7, ups=0.46, wpb=109.1, bsz=40, num_updates=29550, lr=3.87975e-05, gnorm=0.172, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=119753
2023-01-09 08:06:59 - progress_bar.py[line:274] - INFO: epoch 001:  29602 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4057, wps=103.8, ups=0.47, wpb=109.9, bsz=40, num_updates=29560, lr=3.8793e-05, gnorm=0.256, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=119774
2023-01-09 08:07:21 - progress_bar.py[line:274] - INFO: epoch 001:  29612 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.401, wps=100.5, ups=0.46, wpb=109.2, bsz=40, num_updates=29570, lr=3.87885e-05, gnorm=0.251, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=119796
2023-01-09 08:07:42 - progress_bar.py[line:274] - INFO: epoch 001:  29622 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4878, wps=102.4, ups=0.47, wpb=109.3, bsz=40, num_updates=29580, lr=3.8784e-05, gnorm=0.174, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=119818
2023-01-09 08:08:04 - progress_bar.py[line:274] - INFO: epoch 001:  29632 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.41, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=29590, lr=3.87795e-05, gnorm=0.138, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=119840
2023-01-09 08:08:26 - progress_bar.py[line:274] - INFO: epoch 001:  29642 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4721, wps=99.2, ups=0.46, wpb=108.4, bsz=40, num_updates=29600, lr=3.8775e-05, gnorm=0.225, clip=0, loss_scale=1024, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=119862
2023-01-09 08:08:48 - progress_bar.py[line:274] - INFO: epoch 001:  29652 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4537, wps=100.4, ups=0.46, wpb=108, bsz=40, num_updates=29610, lr=3.87705e-05, gnorm=0.138, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=119884
2023-01-09 08:09:10 - progress_bar.py[line:274] - INFO: epoch 001:  29662 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3535, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=29620, lr=3.87661e-05, gnorm=0.355, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=119906
2023-01-09 08:09:32 - progress_bar.py[line:274] - INFO: epoch 001:  29672 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4697, wps=100.5, ups=0.46, wpb=109, bsz=40, num_updates=29630, lr=3.87616e-05, gnorm=0.209, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=119927
2023-01-09 08:09:53 - progress_bar.py[line:274] - INFO: epoch 001:  29682 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5373, wps=101.3, ups=0.47, wpb=108.9, bsz=40, num_updates=29640, lr=3.87571e-05, gnorm=0.203, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=119949
2023-01-09 08:10:15 - progress_bar.py[line:274] - INFO: epoch 001:  29692 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5248, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=29650, lr=3.87526e-05, gnorm=0.135, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=119971
2023-01-09 08:10:37 - progress_bar.py[line:274] - INFO: epoch 001:  29702 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4728, wps=102.4, ups=0.47, wpb=109.6, bsz=40, num_updates=29660, lr=3.87481e-05, gnorm=0.255, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=119993
2023-01-09 08:10:59 - progress_bar.py[line:274] - INFO: epoch 001:  29712 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4045, wps=98.9, ups=0.46, wpb=106.9, bsz=40, num_updates=29670, lr=3.87436e-05, gnorm=0.184, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=120014
2023-01-09 08:11:21 - progress_bar.py[line:274] - INFO: epoch 001:  29722 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4976, wps=99.4, ups=0.46, wpb=109, bsz=40, num_updates=29680, lr=3.87391e-05, gnorm=0.263, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=120037
2023-01-09 08:11:43 - progress_bar.py[line:274] - INFO: epoch 001:  29732 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4667, wps=99.5, ups=0.46, wpb=107.8, bsz=40, num_updates=29690, lr=3.87346e-05, gnorm=0.205, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=120059
2023-01-09 08:12:05 - progress_bar.py[line:274] - INFO: epoch 001:  29742 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5166, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=29700, lr=3.87301e-05, gnorm=0.2, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=120080
2023-01-09 08:12:26 - progress_bar.py[line:274] - INFO: epoch 001:  29752 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5245, wps=103.8, ups=0.47, wpb=109.5, bsz=40, num_updates=29710, lr=3.87256e-05, gnorm=0.22, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=120102
2023-01-09 08:12:48 - progress_bar.py[line:274] - INFO: epoch 001:  29762 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.455, wps=100.8, ups=0.46, wpb=108.4, bsz=40, num_updates=29720, lr=3.87211e-05, gnorm=0.238, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=120123
2023-01-09 08:13:09 - progress_bar.py[line:274] - INFO: epoch 001:  29772 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.436, wps=102.5, ups=0.47, wpb=108.4, bsz=40, num_updates=29730, lr=3.87166e-05, gnorm=0.15, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=120145
2023-01-09 08:13:31 - progress_bar.py[line:274] - INFO: epoch 001:  29782 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4873, wps=99.5, ups=0.46, wpb=107.9, bsz=40, num_updates=29740, lr=3.87121e-05, gnorm=0.24, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=120167
2023-01-09 08:13:52 - progress_bar.py[line:274] - INFO: epoch 001:  29792 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4623, wps=102.2, ups=0.47, wpb=108.8, bsz=40, num_updates=29750, lr=3.87076e-05, gnorm=0.412, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=120188
2023-01-09 08:14:14 - progress_bar.py[line:274] - INFO: epoch 001:  29802 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4663, wps=103.7, ups=0.47, wpb=110, bsz=40, num_updates=29760, lr=3.87031e-05, gnorm=0.187, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=120210
2023-01-09 08:14:36 - progress_bar.py[line:274] - INFO: epoch 001:  29812 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4481, wps=99.1, ups=0.46, wpb=108, bsz=40, num_updates=29770, lr=3.86986e-05, gnorm=0.163, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=120232
2023-01-09 08:14:58 - progress_bar.py[line:274] - INFO: epoch 001:  29822 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4851, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=29780, lr=3.86941e-05, gnorm=0.396, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=120254
2023-01-09 08:15:20 - progress_bar.py[line:274] - INFO: epoch 001:  29832 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3929, wps=100, ups=0.46, wpb=108.5, bsz=40, num_updates=29790, lr=3.86896e-05, gnorm=0.195, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=120276
2023-01-09 08:15:41 - progress_bar.py[line:274] - INFO: epoch 001:  29842 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4216, wps=102.4, ups=0.47, wpb=109.4, bsz=40, num_updates=29800, lr=3.86851e-05, gnorm=0.259, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=120297
2023-01-09 08:16:03 - progress_bar.py[line:274] - INFO: epoch 001:  29852 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4862, wps=100.4, ups=0.46, wpb=108.2, bsz=40, num_updates=29810, lr=3.86806e-05, gnorm=0.152, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=120319
2023-01-09 08:16:25 - progress_bar.py[line:274] - INFO: epoch 001:  29862 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5245, wps=102.5, ups=0.47, wpb=110.1, bsz=40, num_updates=29820, lr=3.86761e-05, gnorm=0.206, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=120341
2023-01-09 08:16:47 - progress_bar.py[line:274] - INFO: epoch 001:  29872 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5051, wps=101.3, ups=0.46, wpb=109.6, bsz=40, num_updates=29830, lr=3.86716e-05, gnorm=0.243, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=120363
2023-01-09 08:17:09 - progress_bar.py[line:274] - INFO: epoch 001:  29882 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.484, wps=102.1, ups=0.47, wpb=109.3, bsz=40, num_updates=29840, lr=3.86671e-05, gnorm=0.187, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=120385
2023-01-09 08:17:31 - progress_bar.py[line:274] - INFO: epoch 001:  29892 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4365, wps=98.7, ups=0.45, wpb=108.9, bsz=40, num_updates=29850, lr=3.86626e-05, gnorm=0.182, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=120407
2023-01-09 08:17:53 - progress_bar.py[line:274] - INFO: epoch 001:  29902 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4715, wps=99.6, ups=0.46, wpb=109.1, bsz=40, num_updates=29860, lr=3.86581e-05, gnorm=0.293, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=120429
2023-01-09 08:18:15 - progress_bar.py[line:274] - INFO: epoch 001:  29912 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4592, wps=100.7, ups=0.46, wpb=109.2, bsz=40, num_updates=29870, lr=3.86537e-05, gnorm=0.162, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=120451
2023-01-09 08:18:37 - progress_bar.py[line:274] - INFO: epoch 001:  29922 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4515, wps=100, ups=0.46, wpb=108.7, bsz=40, num_updates=29880, lr=3.86492e-05, gnorm=0.135, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=120473
2023-01-09 08:18:59 - progress_bar.py[line:274] - INFO: epoch 001:  29932 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4615, wps=100.6, ups=0.46, wpb=109, bsz=40, num_updates=29890, lr=3.86447e-05, gnorm=0.142, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=120495
2023-01-09 08:19:21 - progress_bar.py[line:274] - INFO: epoch 001:  29942 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4492, wps=100, ups=0.45, wpb=110, bsz=40, num_updates=29900, lr=3.86402e-05, gnorm=0.117, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=120517
2023-01-09 08:19:43 - progress_bar.py[line:274] - INFO: epoch 001:  29952 / 115845 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4815, wps=103.7, ups=0.47, wpb=109.8, bsz=40, num_updates=29910, lr=3.86357e-05, gnorm=0.153, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=120539
2023-01-09 08:20:04 - progress_bar.py[line:274] - INFO: epoch 001:  29962 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4467, wps=101.9, ups=0.47, wpb=107.8, bsz=40, num_updates=29920, lr=3.86312e-05, gnorm=0.285, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=120560
2023-01-09 08:20:26 - progress_bar.py[line:274] - INFO: epoch 001:  29972 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4598, wps=101.8, ups=0.46, wpb=110.5, bsz=40, num_updates=29930, lr=3.86267e-05, gnorm=0.167, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=120582
2023-01-09 08:20:48 - progress_bar.py[line:274] - INFO: epoch 001:  29982 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.402, wps=103.9, ups=0.47, wpb=110, bsz=40, num_updates=29940, lr=3.86222e-05, gnorm=0.232, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=120603
2023-01-09 08:21:09 - progress_bar.py[line:274] - INFO: epoch 001:  29992 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4474, wps=104.2, ups=0.48, wpb=109.3, bsz=40, num_updates=29950, lr=3.86177e-05, gnorm=0.194, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=120625
2023-01-09 08:21:31 - progress_bar.py[line:274] - INFO: epoch 001:  30002 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4639, wps=101.4, ups=0.46, wpb=109.4, bsz=40, num_updates=29960, lr=3.86132e-05, gnorm=0.258, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=120646
2023-01-09 08:21:52 - progress_bar.py[line:274] - INFO: epoch 001:  30012 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.402, wps=104.7, ups=0.48, wpb=109.5, bsz=40, num_updates=29970, lr=3.86087e-05, gnorm=0.144, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=120667
2023-01-09 08:22:14 - progress_bar.py[line:274] - INFO: epoch 001:  30022 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4714, wps=98.9, ups=0.46, wpb=108.5, bsz=40, num_updates=29980, lr=3.86042e-05, gnorm=0.249, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=120690
2023-01-09 08:22:36 - progress_bar.py[line:274] - INFO: epoch 001:  30032 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4868, wps=101.1, ups=0.46, wpb=109.6, bsz=40, num_updates=29990, lr=3.85997e-05, gnorm=0.19, clip=0, loss_scale=2048, train_wall=22, gb_free=10, ema_decay=0.9999, wall=120712
2023-01-09 08:22:57 - progress_bar.py[line:274] - INFO: epoch 001:  30042 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.534, wps=102.2, ups=0.47, wpb=107.8, bsz=40, num_updates=30000, lr=3.85952e-05, gnorm=0.188, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=120733
2023-01-09 08:22:57 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-09 08:22:58 - train.py[line:549] - INFO: 0 / 4988
2023-01-09 08:22:58 - train.py[line:551] - INFO: load:0.99 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-09 08:25:30 - train.py[line:549] - INFO: 200 / 4988
2023-01-09 08:25:30 - train.py[line:551] - INFO: load:1.02 valid_run:151.46 task_valid:147.45 collect_output:2.98
2023-01-09 08:27:58 - train.py[line:549] - INFO: 400 / 4988
2023-01-09 08:27:58 - train.py[line:551] - INFO: load:1.04 valid_run:299.64 task_valid:290.03 collect_output:7.59
2023-01-09 08:30:31 - train.py[line:549] - INFO: 600 / 4988
2023-01-09 08:30:31 - train.py[line:551] - INFO: load:1.07 valid_run:452.12 task_valid:432.78 collect_output:16.33
2023-01-09 08:33:00 - train.py[line:549] - INFO: 800 / 4988
2023-01-09 08:33:00 - train.py[line:551] - INFO: load:1.09 valid_run:601.27 task_valid:577.40 collect_output:19.86
2023-01-09 08:35:32 - train.py[line:549] - INFO: 1000 / 4988
2023-01-09 08:35:32 - train.py[line:551] - INFO: load:1.12 valid_run:753.39 task_valid:724.46 collect_output:23.92
2023-01-09 08:38:04 - train.py[line:549] - INFO: 1200 / 4988
2023-01-09 08:38:04 - train.py[line:551] - INFO: load:1.14 valid_run:905.02 task_valid:869.52 collect_output:29.46
2023-01-09 08:40:38 - train.py[line:549] - INFO: 1400 / 4988
2023-01-09 08:40:38 - train.py[line:551] - INFO: load:1.16 valid_run:1058.71 task_valid:1015.26 collect_output:36.41
2023-01-09 08:43:09 - train.py[line:549] - INFO: 1600 / 4988
2023-01-09 08:43:09 - train.py[line:551] - INFO: load:1.19 valid_run:1210.23 task_valid:1155.91 collect_output:46.27
2023-01-09 08:45:39 - train.py[line:549] - INFO: 1800 / 4988
2023-01-09 08:45:39 - train.py[line:551] - INFO: load:1.21 valid_run:1359.75 task_valid:1300.09 collect_output:50.60
2023-01-09 08:48:07 - train.py[line:549] - INFO: 2000 / 4988
2023-01-09 08:48:07 - train.py[line:551] - INFO: load:1.24 valid_run:1508.21 task_valid:1442.78 collect_output:55.37
2023-01-09 08:50:37 - train.py[line:549] - INFO: 2200 / 4988
2023-01-09 08:50:37 - train.py[line:551] - INFO: load:1.27 valid_run:1657.68 task_valid:1587.19 collect_output:59.43
2023-01-09 08:53:07 - train.py[line:549] - INFO: 2400 / 4988
2023-01-09 08:53:07 - train.py[line:551] - INFO: load:1.29 valid_run:1807.83 task_valid:1731.86 collect_output:63.90
2023-01-09 08:55:37 - train.py[line:549] - INFO: 2600 / 4988
2023-01-09 08:55:37 - train.py[line:551] - INFO: load:1.32 valid_run:1957.73 task_valid:1873.15 collect_output:71.50
2023-01-09 08:58:08 - train.py[line:549] - INFO: 2800 / 4988
2023-01-09 08:58:08 - train.py[line:551] - INFO: load:1.34 valid_run:2108.09 task_valid:2018.23 collect_output:75.78
2023-01-09 09:00:37 - train.py[line:549] - INFO: 3000 / 4988
2023-01-09 09:00:37 - train.py[line:551] - INFO: load:1.37 valid_run:2257.81 task_valid:2164.24 collect_output:78.47
2023-01-09 09:03:08 - train.py[line:549] - INFO: 3200 / 4988
2023-01-09 09:03:08 - train.py[line:551] - INFO: load:1.40 valid_run:2408.07 task_valid:2308.09 collect_output:83.87
2023-01-09 09:05:39 - train.py[line:549] - INFO: 3400 / 4988
2023-01-09 09:05:39 - train.py[line:551] - INFO: load:1.42 valid_run:2559.69 task_valid:2453.13 collect_output:89.43
2023-01-09 09:08:10 - train.py[line:549] - INFO: 3600 / 4988
2023-01-09 09:08:10 - train.py[line:551] - INFO: load:1.45 valid_run:2710.05 task_valid:2599.72 collect_output:92.18
2023-01-09 09:10:38 - train.py[line:549] - INFO: 3800 / 4988
2023-01-09 09:10:38 - train.py[line:551] - INFO: load:1.48 valid_run:2858.58 task_valid:2740.92 collect_output:98.48
2023-01-09 09:13:09 - train.py[line:549] - INFO: 4000 / 4988
2023-01-09 09:13:09 - train.py[line:551] - INFO: load:1.50 valid_run:3009.27 task_valid:2885.78 collect_output:103.30
2023-01-09 09:15:41 - train.py[line:549] - INFO: 4200 / 4988
2023-01-09 09:15:41 - train.py[line:551] - INFO: load:1.53 valid_run:3161.33 task_valid:3029.96 collect_output:110.16
2023-01-09 09:18:11 - train.py[line:549] - INFO: 4400 / 4988
2023-01-09 09:18:11 - train.py[line:551] - INFO: load:1.55 valid_run:3310.51 task_valid:3174.03 collect_output:114.27
2023-01-09 09:20:42 - train.py[line:549] - INFO: 4600 / 4988
2023-01-09 09:20:42 - train.py[line:551] - INFO: load:1.58 valid_run:3461.65 task_valid:3319.83 collect_output:118.60
2023-01-09 09:23:13 - train.py[line:549] - INFO: 4800 / 4988
2023-01-09 09:23:13 - train.py[line:551] - INFO: load:1.61 valid_run:3613.27 task_valid:3466.21 collect_output:122.82

====================================================================================================
SGG eval:     R @ 50: 0.3417;     R @ 100: 0.3967;     R @ 500: 0.4193;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2226;    mR @ 100: 0.2723;    mR @ 500: 0.3009;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3049) (covered in:0.8125) (covering:0.3714) (eating:0.5882) (flying in:0.0000) (growing on:0.0000) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.5729) (playing:0.0000) (riding:0.2874) (says:0.0000) (sitting on:0.6979) (standing on:0.1550) (using:0.7000) (walking in:0.0000) (walking on:0.0901) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3417;     R @ 100: 0.3967;     R @ 500: 0.4193;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2226;    mR @ 100: 0.2723;    mR @ 500: 0.3009;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3049) (covered in:0.8125) (covering:0.3714) (eating:0.5882) (flying in:0.0000) (growing on:0.0000) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.5729) (playing:0.0000) (riding:0.2874) (says:0.0000) (sitting on:0.6979) (standing on:0.1550) (using:0.7000) (walking in:0.0000) (walking on:0.0901) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-09 09:25:44 - train.py[line:487] - INFO: 0.3966952380952381
2023-01-09 09:25:44 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-09 09:25:44 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.397 | loss_v1 0 | loss_v2 0 | nll_loss 0.247 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.396695 | ppl 1.19 | vqa_score 0.3108 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 30000 | best_R@100 0.645421
2023-01-09 09:25:45 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 30000 updates
2023-01-09 09:25:45 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_30000.pt
2023-01-09 09:26:24 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_30000.pt
2023-01-09 09:27:51 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_30000.pt (epoch 1 @ 30000 updates, score 0.3966952380952381) (writing took 125.9106528647244 seconds)
2023-01-09 09:28:12 - progress_bar.py[line:274] - INFO: epoch 001:  30052 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4925, wps=0.6, ups=0, wpb=108.7, bsz=40, num_updates=30010, lr=3.85907e-05, gnorm=0.246, clip=0, loss_scale=2048, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=124648
2023-01-09 09:28:34 - progress_bar.py[line:274] - INFO: epoch 001:  30062 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5437, wps=104.3, ups=0.48, wpb=109.4, bsz=40, num_updates=30020, lr=3.85862e-05, gnorm=0.246, clip=0, loss_scale=2048, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=124669
2023-01-09 09:28:56 - progress_bar.py[line:274] - INFO: epoch 001:  30072 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4355, wps=100.6, ups=0.46, wpb=109, bsz=40, num_updates=30030, lr=3.85817e-05, gnorm=0.18, clip=0, loss_scale=2048, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=124692
2023-01-09 09:29:18 - progress_bar.py[line:274] - INFO: epoch 001:  30082 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4975, wps=99.4, ups=0.46, wpb=108, bsz=40, num_updates=30040, lr=3.85772e-05, gnorm=0.385, clip=10, loss_scale=2048, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=124714
2023-01-09 09:29:40 - progress_bar.py[line:274] - INFO: epoch 001:  30092 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.401, wps=100.7, ups=0.46, wpb=108.6, bsz=40, num_updates=30050, lr=3.85727e-05, gnorm=0.212, clip=0, loss_scale=2048, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=124736
2023-01-09 09:29:47 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-09 09:30:04 - progress_bar.py[line:274] - INFO: epoch 001:  30103 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.762, nsentences=40, sample_size=109.762, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4589, wps=98.2, ups=0.43, wpb=109.8, bsz=40, num_updates=30060, lr=3.85682e-05, gnorm=0.232, clip=0, loss_scale=1024, train_wall=23, gb_free=10.6, ema_decay=0.9999, wall=124760
2023-01-09 09:30:26 - progress_bar.py[line:274] - INFO: epoch 001:  30113 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.485, wps=100.5, ups=0.47, wpb=107.9, bsz=40, num_updates=30070, lr=3.85637e-05, gnorm=0.206, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=124782
2023-01-09 09:30:48 - progress_bar.py[line:274] - INFO: epoch 001:  30123 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4976, wps=101.4, ups=0.47, wpb=109, bsz=40, num_updates=30080, lr=3.85592e-05, gnorm=0.433, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=124803
2023-01-09 09:31:10 - progress_bar.py[line:274] - INFO: epoch 001:  30133 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3938, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=30090, lr=3.85547e-05, gnorm=0.156, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=124825
2023-01-09 09:31:31 - progress_bar.py[line:274] - INFO: epoch 001:  30143 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4375, wps=101.3, ups=0.47, wpb=108.4, bsz=40, num_updates=30100, lr=3.85502e-05, gnorm=0.128, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=124847
2023-01-09 09:31:53 - progress_bar.py[line:274] - INFO: epoch 001:  30153 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5208, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=30110, lr=3.85458e-05, gnorm=0.221, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=124869
2023-01-09 09:32:15 - progress_bar.py[line:274] - INFO: epoch 001:  30163 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4427, wps=99.9, ups=0.46, wpb=109.1, bsz=40, num_updates=30120, lr=3.85413e-05, gnorm=0.199, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=124891
2023-01-09 09:32:37 - progress_bar.py[line:274] - INFO: epoch 001:  30173 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4739, wps=99.7, ups=0.46, wpb=108.5, bsz=40, num_updates=30130, lr=3.85368e-05, gnorm=0.29, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=124913
2023-01-09 09:32:59 - progress_bar.py[line:274] - INFO: epoch 001:  30183 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4476, wps=101.5, ups=0.46, wpb=109.4, bsz=40, num_updates=30140, lr=3.85323e-05, gnorm=0.169, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=124935
2023-01-09 09:33:20 - progress_bar.py[line:274] - INFO: epoch 001:  30193 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4615, wps=104, ups=0.47, wpb=110.1, bsz=40, num_updates=30150, lr=3.85278e-05, gnorm=0.176, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=124956
2023-01-09 09:33:42 - progress_bar.py[line:274] - INFO: epoch 001:  30203 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4778, wps=100.6, ups=0.47, wpb=108.2, bsz=40, num_updates=30160, lr=3.85233e-05, gnorm=0.18, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=124978
2023-01-09 09:34:04 - progress_bar.py[line:274] - INFO: epoch 001:  30213 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4878, wps=102.8, ups=0.47, wpb=109.2, bsz=40, num_updates=30170, lr=3.85188e-05, gnorm=0.18, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=124999
2023-01-09 09:34:25 - progress_bar.py[line:274] - INFO: epoch 001:  30223 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.49, wps=103, ups=0.47, wpb=109.9, bsz=40, num_updates=30180, lr=3.85143e-05, gnorm=0.297, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=125021
2023-01-09 09:34:48 - progress_bar.py[line:274] - INFO: epoch 001:  30233 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.404, wps=99, ups=0.45, wpb=109.1, bsz=40, num_updates=30190, lr=3.85098e-05, gnorm=0.251, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=125043
2023-01-09 09:35:10 - progress_bar.py[line:274] - INFO: epoch 001:  30243 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4593, wps=99.3, ups=0.46, wpb=108.8, bsz=40, num_updates=30200, lr=3.85053e-05, gnorm=0.249, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=125066
2023-01-09 09:35:32 - progress_bar.py[line:274] - INFO: epoch 001:  30253 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.427, wps=102.1, ups=0.46, wpb=111, bsz=40, num_updates=30210, lr=3.85008e-05, gnorm=0.129, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=125088
2023-01-09 09:35:54 - progress_bar.py[line:274] - INFO: epoch 001:  30263 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4581, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=30220, lr=3.84963e-05, gnorm=0.161, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=125110
2023-01-09 09:36:16 - progress_bar.py[line:274] - INFO: epoch 001:  30273 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4508, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=30230, lr=3.84918e-05, gnorm=0.28, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=125131
2023-01-09 09:36:37 - progress_bar.py[line:274] - INFO: epoch 001:  30283 / 115845 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4787, wps=103.3, ups=0.47, wpb=109.8, bsz=40, num_updates=30240, lr=3.84873e-05, gnorm=0.12, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=125153
2023-01-09 09:36:59 - progress_bar.py[line:274] - INFO: epoch 001:  30293 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3857, wps=102, ups=0.47, wpb=108.3, bsz=40, num_updates=30250, lr=3.84828e-05, gnorm=0.151, clip=0, loss_scale=1024, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=125175
2023-01-09 09:37:20 - progress_bar.py[line:274] - INFO: epoch 001:  30303 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4869, wps=103.6, ups=0.47, wpb=109.7, bsz=40, num_updates=30260, lr=3.84783e-05, gnorm=0.161, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=125196
2023-01-09 09:37:41 - progress_bar.py[line:274] - INFO: epoch 001:  30313 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.513, wps=105.9, ups=0.48, wpb=109.4, bsz=40, num_updates=30270, lr=3.84738e-05, gnorm=0.33, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=125217
2023-01-09 09:38:02 - progress_bar.py[line:274] - INFO: epoch 001:  30323 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4083, wps=104.2, ups=0.48, wpb=108.5, bsz=40, num_updates=30280, lr=3.84693e-05, gnorm=0.216, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=125238
2023-01-09 09:38:24 - progress_bar.py[line:274] - INFO: epoch 001:  30333 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4265, wps=99.1, ups=0.46, wpb=108.1, bsz=40, num_updates=30290, lr=3.84648e-05, gnorm=0.256, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=125260
2023-01-09 09:38:46 - progress_bar.py[line:274] - INFO: epoch 001:  30343 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5105, wps=103.2, ups=0.47, wpb=109.4, bsz=40, num_updates=30300, lr=3.84603e-05, gnorm=0.249, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=125282
2023-01-09 09:39:07 - progress_bar.py[line:274] - INFO: epoch 001:  30353 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4229, wps=103.5, ups=0.47, wpb=110.4, bsz=40, num_updates=30310, lr=3.84558e-05, gnorm=0.142, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=125303
2023-01-09 09:39:29 - progress_bar.py[line:274] - INFO: epoch 001:  30363 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4422, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=30320, lr=3.84513e-05, gnorm=0.173, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=125325
2023-01-09 09:39:50 - progress_bar.py[line:274] - INFO: epoch 001:  30373 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4272, wps=104.8, ups=0.49, wpb=107.9, bsz=40, num_updates=30330, lr=3.84468e-05, gnorm=0.286, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=125346
2023-01-09 09:40:12 - progress_bar.py[line:274] - INFO: epoch 001:  30383 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4478, wps=102.3, ups=0.47, wpb=109.5, bsz=40, num_updates=30340, lr=3.84423e-05, gnorm=0.204, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=125368
2023-01-09 09:40:34 - progress_bar.py[line:274] - INFO: epoch 001:  30393 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4829, wps=100.1, ups=0.46, wpb=108.5, bsz=40, num_updates=30350, lr=3.84378e-05, gnorm=0.237, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=125390
2023-01-09 09:40:55 - progress_bar.py[line:274] - INFO: epoch 001:  30403 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.44, wps=103.9, ups=0.48, wpb=108.7, bsz=40, num_updates=30360, lr=3.84334e-05, gnorm=0.207, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=125411
2023-01-09 09:41:17 - progress_bar.py[line:274] - INFO: epoch 001:  30413 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4513, wps=99.4, ups=0.45, wpb=110.1, bsz=40, num_updates=30370, lr=3.84289e-05, gnorm=0.152, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=125433
2023-01-09 09:41:39 - progress_bar.py[line:274] - INFO: epoch 001:  30423 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.45, wps=103.3, ups=0.47, wpb=109.5, bsz=40, num_updates=30380, lr=3.84244e-05, gnorm=0.266, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=125455
2023-01-09 09:42:01 - progress_bar.py[line:274] - INFO: epoch 001:  30433 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4332, wps=102, ups=0.46, wpb=110.3, bsz=40, num_updates=30390, lr=3.84199e-05, gnorm=0.136, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=125477
2023-01-09 09:42:07 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-09 09:42:24 - progress_bar.py[line:274] - INFO: epoch 001:  30444 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=108.286, nsentences=40, sample_size=108.286, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4824, wps=99.3, ups=0.44, wpb=108.3, bsz=40, num_updates=30400, lr=3.84154e-05, gnorm=0.177, clip=0, loss_scale=512, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=125500
2023-01-09 09:42:46 - progress_bar.py[line:274] - INFO: epoch 001:  30454 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4328, wps=101, ups=0.47, wpb=107.9, bsz=40, num_updates=30410, lr=3.84109e-05, gnorm=0.258, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=125521
2023-01-09 09:43:07 - progress_bar.py[line:274] - INFO: epoch 001:  30464 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4307, wps=100.8, ups=0.46, wpb=108.9, bsz=40, num_updates=30420, lr=3.84064e-05, gnorm=0.419, clip=10, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=125543
2023-01-09 09:43:29 - progress_bar.py[line:274] - INFO: epoch 001:  30474 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4925, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=30430, lr=3.84019e-05, gnorm=0.162, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=125565
2023-01-09 09:43:51 - progress_bar.py[line:274] - INFO: epoch 001:  30484 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.3979, wps=101.9, ups=0.46, wpb=110.6, bsz=40, num_updates=30440, lr=3.83974e-05, gnorm=0.339, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=125587
2023-01-09 09:44:13 - progress_bar.py[line:274] - INFO: epoch 001:  30494 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.505, wps=100.5, ups=0.46, wpb=108.5, bsz=40, num_updates=30450, lr=3.83929e-05, gnorm=0.138, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=125609
2023-01-09 09:44:35 - progress_bar.py[line:274] - INFO: epoch 001:  30504 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4667, wps=101.2, ups=0.46, wpb=110.3, bsz=40, num_updates=30460, lr=3.83884e-05, gnorm=0.202, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=125631
2023-01-09 09:44:57 - progress_bar.py[line:274] - INFO: epoch 001:  30514 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4396, wps=101.1, ups=0.46, wpb=109.5, bsz=40, num_updates=30470, lr=3.83839e-05, gnorm=0.266, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=125653
2023-01-09 09:45:19 - progress_bar.py[line:274] - INFO: epoch 001:  30524 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4167, wps=100.2, ups=0.46, wpb=108.5, bsz=40, num_updates=30480, lr=3.83794e-05, gnorm=0.292, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=125675
2023-01-09 09:45:41 - progress_bar.py[line:274] - INFO: epoch 001:  30534 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4306, wps=101.5, ups=0.47, wpb=109, bsz=40, num_updates=30490, lr=3.83749e-05, gnorm=0.21, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=125697
2023-01-09 09:46:02 - progress_bar.py[line:274] - INFO: epoch 001:  30544 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5118, wps=101.3, ups=0.47, wpb=107.9, bsz=40, num_updates=30500, lr=3.83704e-05, gnorm=0.153, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=125718
2023-01-09 09:46:25 - progress_bar.py[line:274] - INFO: epoch 001:  30554 / 115845 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5052, wps=100.5, ups=0.46, wpb=109.9, bsz=40, num_updates=30510, lr=3.83659e-05, gnorm=0.263, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=125740
2023-01-09 09:46:46 - progress_bar.py[line:274] - INFO: epoch 001:  30564 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3793, wps=100.7, ups=0.46, wpb=108.6, bsz=40, num_updates=30520, lr=3.83614e-05, gnorm=0.208, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=125762
2023-01-09 09:47:08 - progress_bar.py[line:274] - INFO: epoch 001:  30574 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4402, wps=102.1, ups=0.46, wpb=110.2, bsz=40, num_updates=30530, lr=3.83569e-05, gnorm=0.386, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=125784
2023-01-09 09:47:30 - progress_bar.py[line:274] - INFO: epoch 001:  30584 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.476, wps=102.9, ups=0.47, wpb=109.3, bsz=40, num_updates=30540, lr=3.83524e-05, gnorm=0.278, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=125806
2023-01-09 09:47:51 - progress_bar.py[line:274] - INFO: epoch 001:  30594 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4897, wps=103, ups=0.47, wpb=109.2, bsz=40, num_updates=30550, lr=3.83479e-05, gnorm=0.238, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=125827
2023-01-09 09:48:13 - progress_bar.py[line:274] - INFO: epoch 001:  30604 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.512, wps=101, ups=0.46, wpb=109, bsz=40, num_updates=30560, lr=3.83434e-05, gnorm=0.259, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=125849
2023-01-09 09:48:34 - progress_bar.py[line:274] - INFO: epoch 001:  30614 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5075, wps=103.7, ups=0.48, wpb=108, bsz=40, num_updates=30570, lr=3.83389e-05, gnorm=0.146, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=125870
2023-01-09 09:48:56 - progress_bar.py[line:274] - INFO: epoch 001:  30624 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4596, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=30580, lr=3.83344e-05, gnorm=0.18, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=125892
2023-01-09 09:49:18 - progress_bar.py[line:274] - INFO: epoch 001:  30634 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4337, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=30590, lr=3.83299e-05, gnorm=0.186, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=125913
2023-01-09 09:49:39 - progress_bar.py[line:274] - INFO: epoch 001:  30644 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4179, wps=102.3, ups=0.47, wpb=109, bsz=40, num_updates=30600, lr=3.83255e-05, gnorm=0.189, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=125935
2023-01-09 09:50:01 - progress_bar.py[line:274] - INFO: epoch 001:  30654 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4588, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=30610, lr=3.8321e-05, gnorm=0.217, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=125957
2023-01-09 09:50:23 - progress_bar.py[line:274] - INFO: epoch 001:  30664 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4091, wps=100.7, ups=0.47, wpb=107.7, bsz=40, num_updates=30620, lr=3.83165e-05, gnorm=0.251, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=125978
2023-01-09 09:50:45 - progress_bar.py[line:274] - INFO: epoch 001:  30674 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4439, wps=101.9, ups=0.46, wpb=110.4, bsz=40, num_updates=30630, lr=3.8312e-05, gnorm=0.2, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=126000
2023-01-09 09:51:06 - progress_bar.py[line:274] - INFO: epoch 001:  30684 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4352, wps=100.4, ups=0.46, wpb=108.5, bsz=40, num_updates=30640, lr=3.83075e-05, gnorm=0.184, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=126022
2023-01-09 09:51:28 - progress_bar.py[line:274] - INFO: epoch 001:  30694 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5026, wps=102.9, ups=0.47, wpb=108.9, bsz=40, num_updates=30650, lr=3.8303e-05, gnorm=0.389, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=126044
2023-01-09 09:51:49 - progress_bar.py[line:274] - INFO: epoch 001:  30704 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4869, wps=104.1, ups=0.47, wpb=110.5, bsz=40, num_updates=30660, lr=3.82985e-05, gnorm=0.211, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=126065
2023-01-09 09:52:11 - progress_bar.py[line:274] - INFO: epoch 001:  30714 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3854, wps=101.9, ups=0.46, wpb=110.5, bsz=40, num_updates=30670, lr=3.8294e-05, gnorm=0.152, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=126087
2023-01-09 09:52:34 - progress_bar.py[line:274] - INFO: epoch 001:  30724 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4485, wps=99.1, ups=0.45, wpb=109.9, bsz=40, num_updates=30680, lr=3.82895e-05, gnorm=0.108, clip=0, loss_scale=512, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=126109
2023-01-09 09:52:55 - progress_bar.py[line:274] - INFO: epoch 001:  30734 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4136, wps=100.7, ups=0.47, wpb=107.7, bsz=40, num_updates=30690, lr=3.8285e-05, gnorm=0.268, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=126131
2023-01-09 09:53:17 - progress_bar.py[line:274] - INFO: epoch 001:  30744 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4718, wps=100.8, ups=0.46, wpb=109.5, bsz=40, num_updates=30700, lr=3.82805e-05, gnorm=0.286, clip=10, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=126153
2023-01-09 09:53:39 - progress_bar.py[line:274] - INFO: epoch 001:  30754 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5405, wps=101.4, ups=0.47, wpb=107.5, bsz=40, num_updates=30710, lr=3.8276e-05, gnorm=0.176, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=126175
2023-01-09 09:54:00 - progress_bar.py[line:274] - INFO: epoch 001:  30764 / 115845 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4944, wps=104, ups=0.47, wpb=110.8, bsz=40, num_updates=30720, lr=3.82715e-05, gnorm=0.292, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=126196
2023-01-09 09:54:21 - progress_bar.py[line:274] - INFO: epoch 001:  30774 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4857, wps=105.2, ups=0.48, wpb=108.8, bsz=40, num_updates=30730, lr=3.8267e-05, gnorm=0.17, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=126217
2023-01-09 09:54:43 - progress_bar.py[line:274] - INFO: epoch 001:  30784 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5222, wps=100.5, ups=0.46, wpb=108.8, bsz=40, num_updates=30740, lr=3.82625e-05, gnorm=0.29, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=126239
2023-01-09 09:55:05 - progress_bar.py[line:274] - INFO: epoch 001:  30794 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4309, wps=102.6, ups=0.47, wpb=110.3, bsz=40, num_updates=30750, lr=3.8258e-05, gnorm=0.142, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=126261
2023-01-09 09:55:27 - progress_bar.py[line:274] - INFO: epoch 001:  30804 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4714, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=30760, lr=3.82535e-05, gnorm=0.241, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=126282
2023-01-09 09:55:49 - progress_bar.py[line:274] - INFO: epoch 001:  30814 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4317, wps=100.6, ups=0.46, wpb=109.6, bsz=40, num_updates=30770, lr=3.8249e-05, gnorm=0.133, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=126304
2023-01-09 09:56:10 - progress_bar.py[line:274] - INFO: epoch 001:  30824 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4343, wps=102.8, ups=0.47, wpb=110.4, bsz=40, num_updates=30780, lr=3.82445e-05, gnorm=0.157, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=126326
2023-01-09 09:56:32 - progress_bar.py[line:274] - INFO: epoch 001:  30834 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5126, wps=100.6, ups=0.46, wpb=108.9, bsz=40, num_updates=30790, lr=3.824e-05, gnorm=0.177, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=126348
2023-01-09 09:56:54 - progress_bar.py[line:274] - INFO: epoch 001:  30844 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4754, wps=102, ups=0.46, wpb=110.3, bsz=40, num_updates=30800, lr=3.82355e-05, gnorm=0.179, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=126370
2023-01-09 09:57:16 - progress_bar.py[line:274] - INFO: epoch 001:  30854 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4575, wps=99.9, ups=0.46, wpb=107.7, bsz=40, num_updates=30810, lr=3.8231e-05, gnorm=0.156, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=126392
2023-01-09 09:57:38 - progress_bar.py[line:274] - INFO: epoch 001:  30864 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.378, wps=100.6, ups=0.46, wpb=108.4, bsz=40, num_updates=30820, lr=3.82265e-05, gnorm=0.173, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=126414
2023-01-09 09:58:00 - progress_bar.py[line:274] - INFO: epoch 001:  30874 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4975, wps=102.8, ups=0.47, wpb=109.6, bsz=40, num_updates=30830, lr=3.8222e-05, gnorm=0.191, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=126436
2023-01-09 09:58:22 - progress_bar.py[line:274] - INFO: epoch 001:  30884 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5222, wps=103.7, ups=0.47, wpb=110.4, bsz=40, num_updates=30840, lr=3.82175e-05, gnorm=0.179, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=126457
2023-01-09 09:58:43 - progress_bar.py[line:274] - INFO: epoch 001:  30894 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4545, wps=100.7, ups=0.46, wpb=108.5, bsz=40, num_updates=30850, lr=3.82131e-05, gnorm=0.206, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=126479
2023-01-09 09:59:05 - progress_bar.py[line:274] - INFO: epoch 001:  30904 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4728, wps=102, ups=0.46, wpb=109.7, bsz=40, num_updates=30860, lr=3.82086e-05, gnorm=0.165, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=126501
2023-01-09 09:59:27 - progress_bar.py[line:274] - INFO: epoch 001:  30914 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4396, wps=101.6, ups=0.46, wpb=110.3, bsz=40, num_updates=30870, lr=3.82041e-05, gnorm=0.274, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=126523
2023-01-09 09:59:49 - progress_bar.py[line:274] - INFO: epoch 001:  30924 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4718, wps=101.8, ups=0.46, wpb=109.7, bsz=40, num_updates=30880, lr=3.81996e-05, gnorm=0.238, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=126545
2023-01-09 10:00:11 - progress_bar.py[line:274] - INFO: epoch 001:  30934 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4804, wps=98.7, ups=0.46, wpb=107.9, bsz=40, num_updates=30890, lr=3.81951e-05, gnorm=0.26, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=126567
2023-01-09 10:00:33 - progress_bar.py[line:274] - INFO: epoch 001:  30944 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5404, wps=101.1, ups=0.47, wpb=108.4, bsz=40, num_updates=30900, lr=3.81906e-05, gnorm=0.271, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=126588
2023-01-09 10:00:55 - progress_bar.py[line:274] - INFO: epoch 001:  30954 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4229, wps=101.7, ups=0.46, wpb=109.9, bsz=40, num_updates=30910, lr=3.81861e-05, gnorm=0.223, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=126610
2023-01-09 10:01:16 - progress_bar.py[line:274] - INFO: epoch 001:  30964 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4927, wps=104.1, ups=0.48, wpb=109, bsz=40, num_updates=30920, lr=3.81816e-05, gnorm=0.263, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=126632
2023-01-09 10:01:38 - progress_bar.py[line:274] - INFO: epoch 001:  30974 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4898, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=30930, lr=3.81771e-05, gnorm=0.147, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=126653
2023-01-09 10:01:59 - progress_bar.py[line:274] - INFO: epoch 001:  30984 / 115845 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4681, wps=102.3, ups=0.47, wpb=109.4, bsz=40, num_updates=30940, lr=3.81726e-05, gnorm=0.141, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=126675
2023-01-09 10:02:21 - progress_bar.py[line:274] - INFO: epoch 001:  30994 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4089, wps=99.5, ups=0.46, wpb=107.6, bsz=40, num_updates=30950, lr=3.81681e-05, gnorm=0.185, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=126697
2023-01-09 10:02:43 - progress_bar.py[line:274] - INFO: epoch 001:  31004 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=101.8, ups=0.46, wpb=109.7, bsz=40, num_updates=30960, lr=3.81636e-05, gnorm=0.126, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=126719
2023-01-09 10:03:05 - progress_bar.py[line:274] - INFO: epoch 001:  31014 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4469, wps=100, ups=0.46, wpb=109.5, bsz=40, num_updates=30970, lr=3.81591e-05, gnorm=0.164, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=126741
2023-01-09 10:03:27 - progress_bar.py[line:274] - INFO: epoch 001:  31024 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5143, wps=101.4, ups=0.47, wpb=108.2, bsz=40, num_updates=30980, lr=3.81546e-05, gnorm=0.128, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=126762
2023-01-09 10:03:49 - progress_bar.py[line:274] - INFO: epoch 001:  31034 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4206, wps=99.2, ups=0.46, wpb=107.6, bsz=40, num_updates=30990, lr=3.81501e-05, gnorm=0.218, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=126784
2023-01-09 10:04:10 - progress_bar.py[line:274] - INFO: epoch 001:  31044 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4925, wps=102.8, ups=0.47, wpb=108.8, bsz=40, num_updates=31000, lr=3.81456e-05, gnorm=0.141, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=126806
2023-01-09 10:04:31 - progress_bar.py[line:274] - INFO: epoch 001:  31054 / 115845 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5181, wps=104.4, ups=0.48, wpb=109.7, bsz=40, num_updates=31010, lr=3.81411e-05, gnorm=0.141, clip=0, loss_scale=1024, train_wall=21, gb_free=9.4, ema_decay=0.9999, wall=126827
2023-01-09 10:04:53 - progress_bar.py[line:274] - INFO: epoch 001:  31064 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4706, wps=102.4, ups=0.46, wpb=110.4, bsz=40, num_updates=31020, lr=3.81366e-05, gnorm=0.196, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=126849
2023-01-09 10:05:15 - progress_bar.py[line:274] - INFO: epoch 001:  31074 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5192, wps=101.4, ups=0.47, wpb=107.6, bsz=40, num_updates=31030, lr=3.81321e-05, gnorm=0.139, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=126870
2023-01-09 10:05:37 - progress_bar.py[line:274] - INFO: epoch 001:  31084 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4724, wps=99.4, ups=0.45, wpb=109.9, bsz=40, num_updates=31040, lr=3.81276e-05, gnorm=0.511, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=126893
2023-01-09 10:05:59 - progress_bar.py[line:274] - INFO: epoch 001:  31094 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4175, wps=99.9, ups=0.46, wpb=109.6, bsz=40, num_updates=31050, lr=3.81231e-05, gnorm=0.156, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=126915
2023-01-09 10:06:21 - progress_bar.py[line:274] - INFO: epoch 001:  31104 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5192, wps=101.5, ups=0.47, wpb=107.6, bsz=40, num_updates=31060, lr=3.81186e-05, gnorm=0.171, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=126936
2023-01-09 10:06:42 - progress_bar.py[line:274] - INFO: epoch 001:  31114 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4121, wps=101.8, ups=0.46, wpb=110.1, bsz=40, num_updates=31070, lr=3.81141e-05, gnorm=0.24, clip=0, loss_scale=1024, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=126958
2023-01-09 10:07:04 - progress_bar.py[line:274] - INFO: epoch 001:  31124 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4343, wps=102.9, ups=0.47, wpb=110.5, bsz=40, num_updates=31080, lr=3.81096e-05, gnorm=0.136, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=126980
2023-01-09 10:07:26 - progress_bar.py[line:274] - INFO: epoch 001:  31134 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5049, wps=100.9, ups=0.47, wpb=108.3, bsz=40, num_updates=31090, lr=3.81052e-05, gnorm=0.161, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=127002
2023-01-09 10:07:47 - progress_bar.py[line:274] - INFO: epoch 001:  31144 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5625, wps=103.1, ups=0.47, wpb=109.3, bsz=40, num_updates=31100, lr=3.81007e-05, gnorm=0.269, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=127023
2023-01-09 10:08:09 - progress_bar.py[line:274] - INFO: epoch 001:  31154 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4486, wps=103.5, ups=0.48, wpb=108.8, bsz=40, num_updates=31110, lr=3.80962e-05, gnorm=0.282, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=127045
2023-01-09 10:08:31 - progress_bar.py[line:274] - INFO: epoch 001:  31164 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4833, wps=100.6, ups=0.46, wpb=109.6, bsz=40, num_updates=31120, lr=3.80917e-05, gnorm=0.242, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=127067
2023-01-09 10:08:53 - progress_bar.py[line:274] - INFO: epoch 001:  31174 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4106, wps=99.7, ups=0.46, wpb=107.8, bsz=40, num_updates=31130, lr=3.80872e-05, gnorm=0.229, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=127088
2023-01-09 10:09:14 - progress_bar.py[line:274] - INFO: epoch 001:  31184 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.43, wps=102.7, ups=0.48, wpb=107.7, bsz=40, num_updates=31140, lr=3.80827e-05, gnorm=0.14, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=127110
2023-01-09 10:09:36 - progress_bar.py[line:274] - INFO: epoch 001:  31194 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4516, wps=101.3, ups=0.46, wpb=109.2, bsz=40, num_updates=31150, lr=3.80782e-05, gnorm=0.225, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=127131
2023-01-09 10:09:57 - progress_bar.py[line:274] - INFO: epoch 001:  31204 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3951, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=31160, lr=3.80737e-05, gnorm=0.146, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=127153
2023-01-09 10:10:19 - progress_bar.py[line:274] - INFO: epoch 001:  31214 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5342, wps=100.1, ups=0.46, wpb=108.2, bsz=40, num_updates=31170, lr=3.80692e-05, gnorm=0.167, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=127175
2023-01-09 10:10:41 - progress_bar.py[line:274] - INFO: epoch 001:  31224 / 115845 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4809, wps=102.2, ups=0.46, wpb=111.3, bsz=40, num_updates=31180, lr=3.80647e-05, gnorm=0.123, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=127197
2023-01-09 10:11:03 - progress_bar.py[line:274] - INFO: epoch 001:  31234 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.478, wps=103.2, ups=0.47, wpb=109.5, bsz=40, num_updates=31190, lr=3.80602e-05, gnorm=0.265, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=127218
2023-01-09 10:11:24 - progress_bar.py[line:274] - INFO: epoch 001:  31244 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5025, wps=101.3, ups=0.47, wpb=108.4, bsz=40, num_updates=31200, lr=3.80557e-05, gnorm=0.133, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=127240
2023-01-09 10:11:46 - progress_bar.py[line:274] - INFO: epoch 001:  31254 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4051, wps=99.6, ups=0.45, wpb=109.6, bsz=40, num_updates=31210, lr=3.80512e-05, gnorm=0.218, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=127262
2023-01-09 10:12:08 - progress_bar.py[line:274] - INFO: epoch 001:  31264 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4495, wps=101.4, ups=0.47, wpb=108.2, bsz=40, num_updates=31220, lr=3.80467e-05, gnorm=0.219, clip=10, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=127284
2023-01-09 10:12:30 - progress_bar.py[line:274] - INFO: epoch 001:  31274 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4692, wps=100.8, ups=0.47, wpb=107.6, bsz=40, num_updates=31230, lr=3.80422e-05, gnorm=0.134, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=127305
2023-01-09 10:12:51 - progress_bar.py[line:274] - INFO: epoch 001:  31284 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3646, wps=101.7, ups=0.47, wpb=108.4, bsz=40, num_updates=31240, lr=3.80377e-05, gnorm=0.238, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=127327
2023-01-09 10:13:13 - progress_bar.py[line:274] - INFO: epoch 001:  31294 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4476, wps=99.7, ups=0.46, wpb=108.3, bsz=40, num_updates=31250, lr=3.80332e-05, gnorm=0.267, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=127349
2023-01-09 10:13:35 - progress_bar.py[line:274] - INFO: epoch 001:  31304 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.445, wps=99.1, ups=0.46, wpb=107.8, bsz=40, num_updates=31260, lr=3.80287e-05, gnorm=0.223, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=127371
2023-01-09 10:13:57 - progress_bar.py[line:274] - INFO: epoch 001:  31314 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.466, wps=103.1, ups=0.47, wpb=109.4, bsz=40, num_updates=31270, lr=3.80242e-05, gnorm=0.275, clip=0, loss_scale=1024, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=127392
2023-01-09 10:14:18 - progress_bar.py[line:274] - INFO: epoch 001:  31324 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.445, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=31280, lr=3.80197e-05, gnorm=0.182, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=127414
2023-01-09 10:14:40 - progress_bar.py[line:274] - INFO: epoch 001:  31334 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4876, wps=99.1, ups=0.46, wpb=108, bsz=40, num_updates=31290, lr=3.80152e-05, gnorm=0.162, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=127436
2023-01-09 10:15:02 - progress_bar.py[line:274] - INFO: epoch 001:  31344 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4554, wps=99.8, ups=0.46, wpb=107.6, bsz=40, num_updates=31300, lr=3.80107e-05, gnorm=0.165, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=127458
2023-01-09 10:15:25 - progress_bar.py[line:274] - INFO: epoch 001:  31354 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4279, wps=102.2, ups=0.47, wpb=109.3, bsz=40, num_updates=31310, lr=3.80062e-05, gnorm=0.18, clip=0, loss_scale=1024, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=127479
2023-01-09 10:15:47 - progress_bar.py[line:274] - INFO: epoch 001:  31364 / 115845 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4722, wps=99.9, ups=0.45, wpb=109.8, bsz=40, num_updates=31320, lr=3.80017e-05, gnorm=0.143, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=127503
2023-01-09 10:16:09 - progress_bar.py[line:274] - INFO: epoch 001:  31374 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4483, wps=102.2, ups=0.47, wpb=109.5, bsz=40, num_updates=31330, lr=3.79972e-05, gnorm=0.253, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=127525
2023-01-09 10:16:32 - progress_bar.py[line:274] - INFO: epoch 001:  31384 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4619, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=31340, lr=3.79928e-05, gnorm=0.172, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=127547
2023-01-09 10:16:55 - progress_bar.py[line:274] - INFO: epoch 001:  31394 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4271, wps=99.6, ups=0.45, wpb=109.7, bsz=40, num_updates=31350, lr=3.79883e-05, gnorm=0.197, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=127570
2023-01-09 10:17:17 - progress_bar.py[line:274] - INFO: epoch 001:  31404 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4923, wps=100.1, ups=0.46, wpb=109, bsz=40, num_updates=31360, lr=3.79838e-05, gnorm=0.154, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=127593
2023-01-09 10:17:40 - progress_bar.py[line:274] - INFO: epoch 001:  31414 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.381, wps=100.6, ups=0.46, wpb=108.8, bsz=40, num_updates=31370, lr=3.79793e-05, gnorm=0.197, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=127615
2023-01-09 10:18:01 - progress_bar.py[line:274] - INFO: epoch 001:  31424 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5314, wps=104.3, ups=0.48, wpb=109.1, bsz=40, num_updates=31380, lr=3.79748e-05, gnorm=0.267, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=127637
2023-01-09 10:18:24 - progress_bar.py[line:274] - INFO: epoch 001:  31434 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4688, wps=102.2, ups=0.46, wpb=110, bsz=40, num_updates=31390, lr=3.79703e-05, gnorm=0.25, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=127659
2023-01-09 10:18:45 - progress_bar.py[line:274] - INFO: epoch 001:  31444 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4213, wps=101.3, ups=0.46, wpb=109, bsz=40, num_updates=31400, lr=3.79658e-05, gnorm=0.231, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=127681
2023-01-09 10:19:08 - progress_bar.py[line:274] - INFO: epoch 001:  31454 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4844, wps=98.9, ups=0.46, wpb=108.6, bsz=40, num_updates=31410, lr=3.79613e-05, gnorm=0.241, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=127703
2023-01-09 10:19:30 - progress_bar.py[line:274] - INFO: epoch 001:  31464 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5147, wps=100.7, ups=0.46, wpb=108.9, bsz=40, num_updates=31420, lr=3.79568e-05, gnorm=0.165, clip=0, loss_scale=2048, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=127726
2023-01-09 10:19:52 - progress_bar.py[line:274] - INFO: epoch 001:  31474 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4623, wps=102.8, ups=0.47, wpb=109.4, bsz=40, num_updates=31430, lr=3.79523e-05, gnorm=0.172, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=127747
2023-01-09 10:20:13 - progress_bar.py[line:274] - INFO: epoch 001:  31484 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4626, wps=100.9, ups=0.47, wpb=107.8, bsz=40, num_updates=31440, lr=3.79478e-05, gnorm=0.202, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=127769
2023-01-09 10:20:35 - progress_bar.py[line:274] - INFO: epoch 001:  31494 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.505, wps=101.9, ups=0.47, wpb=109.2, bsz=40, num_updates=31450, lr=3.79433e-05, gnorm=0.265, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=127791
2023-01-09 10:20:56 - progress_bar.py[line:274] - INFO: epoch 001:  31504 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4656, wps=102.2, ups=0.47, wpb=108.9, bsz=40, num_updates=31460, lr=3.79388e-05, gnorm=0.246, clip=10, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=127812
2023-01-09 10:21:18 - progress_bar.py[line:274] - INFO: epoch 001:  31514 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4455, wps=98.4, ups=0.46, wpb=107.3, bsz=40, num_updates=31470, lr=3.79343e-05, gnorm=0.17, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=127834
2023-01-09 10:21:40 - progress_bar.py[line:274] - INFO: epoch 001:  31524 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4352, wps=103, ups=0.47, wpb=110, bsz=40, num_updates=31480, lr=3.79298e-05, gnorm=0.167, clip=0, loss_scale=2048, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=127856
2023-01-09 10:22:02 - progress_bar.py[line:274] - INFO: epoch 001:  31534 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4804, wps=100.8, ups=0.46, wpb=109, bsz=40, num_updates=31490, lr=3.79253e-05, gnorm=0.325, clip=10, loss_scale=2048, train_wall=22, gb_free=10, ema_decay=0.9999, wall=127878
2023-01-09 10:22:23 - progress_bar.py[line:274] - INFO: epoch 001:  31544 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4767, wps=103.1, ups=0.47, wpb=110.1, bsz=40, num_updates=31500, lr=3.79208e-05, gnorm=0.234, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=127899
2023-01-09 10:22:46 - progress_bar.py[line:274] - INFO: epoch 001:  31554 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4293, wps=99, ups=0.45, wpb=109.5, bsz=40, num_updates=31510, lr=3.79163e-05, gnorm=0.109, clip=0, loss_scale=2048, train_wall=22, gb_free=10, ema_decay=0.9999, wall=127922
2023-01-09 10:23:07 - progress_bar.py[line:274] - INFO: epoch 001:  31564 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.467, wps=101.1, ups=0.47, wpb=108.5, bsz=40, num_updates=31520, lr=3.79118e-05, gnorm=0.248, clip=0, loss_scale=2048, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=127943
2023-01-09 10:23:29 - progress_bar.py[line:274] - INFO: epoch 001:  31574 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4372, wps=101, ups=0.46, wpb=110.1, bsz=40, num_updates=31530, lr=3.79073e-05, gnorm=0.137, clip=0, loss_scale=2048, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=127965
2023-01-09 10:23:51 - progress_bar.py[line:274] - INFO: epoch 001:  31584 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4869, wps=103.6, ups=0.47, wpb=109.6, bsz=40, num_updates=31540, lr=3.79028e-05, gnorm=0.258, clip=10, loss_scale=2048, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=127987
2023-01-09 10:24:12 - progress_bar.py[line:274] - INFO: epoch 001:  31594 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4484, wps=101.3, ups=0.47, wpb=107.2, bsz=40, num_updates=31550, lr=3.78983e-05, gnorm=0.157, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=128008
2023-01-09 10:24:34 - progress_bar.py[line:274] - INFO: epoch 001:  31604 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4309, wps=104.3, ups=0.47, wpb=110.1, bsz=40, num_updates=31560, lr=3.78938e-05, gnorm=0.185, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=128029
2023-01-09 10:24:55 - progress_bar.py[line:274] - INFO: epoch 001:  31614 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4229, wps=99.7, ups=0.46, wpb=107.6, bsz=40, num_updates=31570, lr=3.78893e-05, gnorm=0.193, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=128051
2023-01-09 10:25:18 - progress_bar.py[line:274] - INFO: epoch 001:  31624 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4739, wps=100.2, ups=0.46, wpb=109.7, bsz=40, num_updates=31580, lr=3.78849e-05, gnorm=0.212, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=128073
2023-01-09 10:25:39 - progress_bar.py[line:274] - INFO: epoch 001:  31634 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4667, wps=102.5, ups=0.47, wpb=108.6, bsz=40, num_updates=31590, lr=3.78804e-05, gnorm=0.216, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=128095
2023-01-09 10:26:01 - progress_bar.py[line:274] - INFO: epoch 001:  31644 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4853, wps=101, ups=0.46, wpb=108.7, bsz=40, num_updates=31600, lr=3.78759e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=128117
2023-01-09 10:26:22 - progress_bar.py[line:274] - INFO: epoch 001:  31654 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4646, wps=101.5, ups=0.47, wpb=108.4, bsz=40, num_updates=31610, lr=3.78714e-05, gnorm=0.237, clip=0, loss_scale=2048, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=128138
2023-01-09 10:26:44 - progress_bar.py[line:274] - INFO: epoch 001:  31664 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5025, wps=98.9, ups=0.46, wpb=108.5, bsz=40, num_updates=31620, lr=3.78669e-05, gnorm=0.237, clip=0, loss_scale=2048, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=128160
2023-01-09 10:27:06 - progress_bar.py[line:274] - INFO: epoch 001:  31674 / 115845 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.4971, wps=105.7, ups=0.48, wpb=110.7, bsz=40, num_updates=31630, lr=3.78624e-05, gnorm=0.145, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=128181
2023-01-09 10:27:27 - progress_bar.py[line:274] - INFO: epoch 001:  31684 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4612, wps=101.5, ups=0.47, wpb=108.7, bsz=40, num_updates=31640, lr=3.78579e-05, gnorm=0.249, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=128203
2023-01-09 10:27:49 - progress_bar.py[line:274] - INFO: epoch 001:  31694 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4272, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=31650, lr=3.78534e-05, gnorm=0.258, clip=0, loss_scale=2048, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=128225
2023-01-09 10:28:11 - progress_bar.py[line:274] - INFO: epoch 001:  31704 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4591, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=31660, lr=3.78489e-05, gnorm=0.195, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=128247
2023-01-09 10:28:32 - progress_bar.py[line:274] - INFO: epoch 001:  31714 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4523, wps=103.1, ups=0.47, wpb=109.4, bsz=40, num_updates=31670, lr=3.78444e-05, gnorm=0.277, clip=0, loss_scale=2048, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=128268
2023-01-09 10:28:54 - progress_bar.py[line:274] - INFO: epoch 001:  31724 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.1, nsentences=40, sample_size=106.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4469, wps=97.5, ups=0.46, wpb=106.1, bsz=40, num_updates=31680, lr=3.78399e-05, gnorm=0.156, clip=0, loss_scale=2048, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=128290
2023-01-09 10:29:16 - progress_bar.py[line:274] - INFO: epoch 001:  31734 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5, wps=102.9, ups=0.47, wpb=109.4, bsz=40, num_updates=31690, lr=3.78354e-05, gnorm=0.272, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=128312
2023-01-09 10:29:37 - progress_bar.py[line:274] - INFO: epoch 001:  31744 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4683, wps=102.2, ups=0.47, wpb=109.6, bsz=40, num_updates=31700, lr=3.78309e-05, gnorm=0.111, clip=0, loss_scale=2048, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=128333
2023-01-09 10:29:48 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-09 10:30:01 - progress_bar.py[line:274] - INFO: epoch 001:  31755 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.143, nsentences=40, sample_size=110.143, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5025, wps=98.7, ups=0.43, wpb=110.1, bsz=40, num_updates=31710, lr=3.78264e-05, gnorm=0.209, clip=0, loss_scale=1024, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=128357
2023-01-09 10:30:23 - progress_bar.py[line:274] - INFO: epoch 001:  31765 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5051, wps=101.8, ups=0.47, wpb=109.4, bsz=40, num_updates=31720, lr=3.78219e-05, gnorm=0.157, clip=0, loss_scale=1024, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=128379
2023-01-09 10:30:45 - progress_bar.py[line:274] - INFO: epoch 001:  31775 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4822, wps=100.7, ups=0.46, wpb=109.4, bsz=40, num_updates=31730, lr=3.78174e-05, gnorm=0.185, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=128401
2023-01-09 10:31:07 - progress_bar.py[line:274] - INFO: epoch 001:  31785 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4439, wps=100.2, ups=0.46, wpb=109.2, bsz=40, num_updates=31740, lr=3.78129e-05, gnorm=0.2, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=128423
2023-01-09 10:31:28 - progress_bar.py[line:274] - INFO: epoch 001:  31795 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4581, wps=102.2, ups=0.47, wpb=109.5, bsz=40, num_updates=31750, lr=3.78084e-05, gnorm=0.216, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=128444
2023-01-09 10:31:50 - progress_bar.py[line:274] - INFO: epoch 001:  31805 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4545, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=31760, lr=3.78039e-05, gnorm=0.162, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=128466
2023-01-09 10:32:12 - progress_bar.py[line:274] - INFO: epoch 001:  31815 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4485, wps=102.6, ups=0.47, wpb=108.7, bsz=40, num_updates=31770, lr=3.77994e-05, gnorm=0.183, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=128487
2023-01-09 10:32:33 - progress_bar.py[line:274] - INFO: epoch 001:  31825 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4433, wps=102.3, ups=0.47, wpb=109.6, bsz=40, num_updates=31780, lr=3.77949e-05, gnorm=0.208, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=128509
2023-01-09 10:32:55 - progress_bar.py[line:274] - INFO: epoch 001:  31835 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4235, wps=100.9, ups=0.46, wpb=108.6, bsz=40, num_updates=31790, lr=3.77904e-05, gnorm=0.165, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=128531
2023-01-09 10:33:17 - progress_bar.py[line:274] - INFO: epoch 001:  31845 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4455, wps=101.2, ups=0.47, wpb=107.8, bsz=40, num_updates=31800, lr=3.77859e-05, gnorm=0.281, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=128552
2023-01-09 10:33:38 - progress_bar.py[line:274] - INFO: epoch 001:  31855 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.401, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=31810, lr=3.77814e-05, gnorm=0.288, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=128574
2023-01-09 10:34:00 - progress_bar.py[line:274] - INFO: epoch 001:  31865 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4155, wps=101.6, ups=0.47, wpb=108.8, bsz=40, num_updates=31820, lr=3.77769e-05, gnorm=0.193, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=128596
2023-01-09 10:34:22 - progress_bar.py[line:274] - INFO: epoch 001:  31875 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4203, wps=98.7, ups=0.45, wpb=108.5, bsz=40, num_updates=31830, lr=3.77725e-05, gnorm=0.158, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=128618
2023-01-09 10:34:44 - progress_bar.py[line:274] - INFO: epoch 001:  31885 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4653, wps=100.5, ups=0.46, wpb=108.3, bsz=40, num_updates=31840, lr=3.7768e-05, gnorm=0.166, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=128640
2023-01-09 10:35:06 - progress_bar.py[line:274] - INFO: epoch 001:  31895 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5176, wps=101.5, ups=0.46, wpb=109.6, bsz=40, num_updates=31850, lr=3.77635e-05, gnorm=0.218, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=128662
2023-01-09 10:35:28 - progress_bar.py[line:274] - INFO: epoch 001:  31905 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4663, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=31860, lr=3.7759e-05, gnorm=0.231, clip=0, loss_scale=1024, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=128683
2023-01-09 10:35:49 - progress_bar.py[line:274] - INFO: epoch 001:  31915 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4356, wps=101.2, ups=0.47, wpb=108.4, bsz=40, num_updates=31870, lr=3.77545e-05, gnorm=0.246, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=128705
2023-01-09 10:36:11 - progress_bar.py[line:274] - INFO: epoch 001:  31925 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4932, wps=99.7, ups=0.46, wpb=107.6, bsz=40, num_updates=31880, lr=3.775e-05, gnorm=0.192, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=128727
2023-01-09 10:36:32 - progress_bar.py[line:274] - INFO: epoch 001:  31935 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.45, wps=103.3, ups=0.47, wpb=109.1, bsz=40, num_updates=31890, lr=3.77455e-05, gnorm=0.169, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=128748
2023-01-09 10:36:54 - progress_bar.py[line:274] - INFO: epoch 001:  31945 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4439, wps=103.8, ups=0.48, wpb=108.8, bsz=40, num_updates=31900, lr=3.7741e-05, gnorm=0.175, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=128769
2023-01-09 10:37:15 - progress_bar.py[line:274] - INFO: epoch 001:  31955 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5357, wps=100.9, ups=0.46, wpb=109.5, bsz=40, num_updates=31910, lr=3.77365e-05, gnorm=0.273, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=128791
2023-01-09 10:37:37 - progress_bar.py[line:274] - INFO: epoch 001:  31965 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4247, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=31920, lr=3.7732e-05, gnorm=0.128, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=128813
2023-01-09 10:37:59 - progress_bar.py[line:274] - INFO: epoch 001:  31975 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4828, wps=101.1, ups=0.47, wpb=108.5, bsz=40, num_updates=31930, lr=3.77275e-05, gnorm=0.18, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=128835
2023-01-09 10:38:21 - progress_bar.py[line:274] - INFO: epoch 001:  31985 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.425, wps=98.8, ups=0.46, wpb=108.3, bsz=40, num_updates=31940, lr=3.7723e-05, gnorm=0.265, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=128857
2023-01-09 10:38:43 - progress_bar.py[line:274] - INFO: epoch 001:  31995 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4921, wps=103, ups=0.47, wpb=110.2, bsz=40, num_updates=31950, lr=3.77185e-05, gnorm=0.225, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=128879
2023-01-09 10:39:04 - progress_bar.py[line:274] - INFO: epoch 001:  32005 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4101, wps=106, ups=0.48, wpb=110.4, bsz=40, num_updates=31960, lr=3.7714e-05, gnorm=0.174, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=128900
2023-01-09 10:39:25 - progress_bar.py[line:274] - INFO: epoch 001:  32015 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4663, wps=102, ups=0.47, wpb=108.1, bsz=40, num_updates=31970, lr=3.77095e-05, gnorm=0.206, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=128921
2023-01-09 10:39:47 - progress_bar.py[line:274] - INFO: epoch 001:  32025 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4789, wps=103.8, ups=0.47, wpb=110.7, bsz=40, num_updates=31980, lr=3.7705e-05, gnorm=0.224, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=128943
2023-01-09 10:40:08 - progress_bar.py[line:274] - INFO: epoch 001:  32035 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4682, wps=102.7, ups=0.47, wpb=108.8, bsz=40, num_updates=31990, lr=3.77005e-05, gnorm=0.279, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=128964
2023-01-09 10:40:30 - progress_bar.py[line:274] - INFO: epoch 001:  32045 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4976, wps=101.2, ups=0.46, wpb=109.9, bsz=40, num_updates=32000, lr=3.7696e-05, gnorm=0.236, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=128986
2023-01-09 10:40:30 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-09 10:40:32 - train.py[line:549] - INFO: 0 / 4988
2023-01-09 10:40:32 - train.py[line:551] - INFO: load:1.00 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-09 10:43:04 - train.py[line:549] - INFO: 200 / 4988
2023-01-09 10:43:04 - train.py[line:551] - INFO: load:1.03 valid_run:152.19 task_valid:148.11 collect_output:2.97
2023-01-09 10:45:33 - train.py[line:549] - INFO: 400 / 4988
2023-01-09 10:45:33 - train.py[line:551] - INFO: load:1.06 valid_run:300.62 task_valid:291.01 collect_output:7.45
2023-01-09 10:48:05 - train.py[line:549] - INFO: 600 / 4988
2023-01-09 10:48:05 - train.py[line:551] - INFO: load:1.08 valid_run:453.00 task_valid:433.78 collect_output:16.00
2023-01-09 10:50:34 - train.py[line:549] - INFO: 800 / 4988
2023-01-09 10:50:34 - train.py[line:551] - INFO: load:1.11 valid_run:601.96 task_valid:578.32 collect_output:19.38
2023-01-09 10:53:07 - train.py[line:549] - INFO: 1000 / 4988
2023-01-09 10:53:07 - train.py[line:551] - INFO: load:1.14 valid_run:754.54 task_valid:725.71 collect_output:23.52
2023-01-09 10:55:39 - train.py[line:549] - INFO: 1200 / 4988
2023-01-09 10:55:39 - train.py[line:551] - INFO: load:1.16 valid_run:906.37 task_valid:871.05 collect_output:28.94
2023-01-09 10:58:12 - train.py[line:549] - INFO: 1400 / 4988
2023-01-09 10:58:12 - train.py[line:551] - INFO: load:1.19 valid_run:1059.97 task_valid:1016.74 collect_output:35.84
2023-01-09 11:00:44 - train.py[line:549] - INFO: 1600 / 4988
2023-01-09 11:00:44 - train.py[line:551] - INFO: load:1.22 valid_run:1211.41 task_valid:1157.38 collect_output:45.56
2023-01-09 11:03:14 - train.py[line:549] - INFO: 1800 / 4988
2023-01-09 11:03:14 - train.py[line:551] - INFO: load:1.25 valid_run:1361.45 task_valid:1302.03 collect_output:49.89
2023-01-09 11:05:43 - train.py[line:549] - INFO: 2000 / 4988
2023-01-09 11:05:43 - train.py[line:551] - INFO: load:1.28 valid_run:1510.08 task_valid:1444.87 collect_output:54.64
2023-01-09 11:08:12 - train.py[line:549] - INFO: 2200 / 4988
2023-01-09 11:08:12 - train.py[line:551] - INFO: load:1.30 valid_run:1659.73 task_valid:1589.40 collect_output:58.70
2023-01-09 11:10:42 - train.py[line:549] - INFO: 2400 / 4988
2023-01-09 11:10:42 - train.py[line:551] - INFO: load:1.33 valid_run:1809.58 task_valid:1733.94 collect_output:62.96
2023-01-09 11:13:13 - train.py[line:549] - INFO: 2600 / 4988
2023-01-09 11:13:13 - train.py[line:551] - INFO: load:1.36 valid_run:1960.02 task_valid:1875.77 collect_output:70.52
2023-01-09 11:15:43 - train.py[line:549] - INFO: 2800 / 4988
2023-01-09 11:15:43 - train.py[line:551] - INFO: load:1.39 valid_run:2110.65 task_valid:2021.11 collect_output:74.77
2023-01-09 11:18:14 - train.py[line:549] - INFO: 3000 / 4988
2023-01-09 11:18:14 - train.py[line:551] - INFO: load:1.42 valid_run:2260.71 task_valid:2167.24 collect_output:77.62
2023-01-09 11:20:44 - train.py[line:549] - INFO: 3200 / 4988
2023-01-09 11:20:44 - train.py[line:551] - INFO: load:1.44 valid_run:2410.80 task_valid:2311.21 collect_output:82.68
2023-01-09 11:23:16 - train.py[line:549] - INFO: 3400 / 4988
2023-01-09 11:23:16 - train.py[line:551] - INFO: load:1.47 valid_run:2562.95 task_valid:2456.72 collect_output:88.27
2023-01-09 11:25:47 - train.py[line:549] - INFO: 3600 / 4988
2023-01-09 11:25:47 - train.py[line:551] - INFO: load:1.50 valid_run:2713.45 task_valid:2603.51 collect_output:90.92
2023-01-09 11:28:15 - train.py[line:549] - INFO: 3800 / 4988
2023-01-09 11:28:15 - train.py[line:551] - INFO: load:1.53 valid_run:2862.05 task_valid:2744.91 collect_output:97.06
2023-01-09 11:30:46 - train.py[line:549] - INFO: 4000 / 4988
2023-01-09 11:30:46 - train.py[line:551] - INFO: load:1.56 valid_run:3012.40 task_valid:2889.74 collect_output:101.52
2023-01-09 11:33:18 - train.py[line:549] - INFO: 4200 / 4988
2023-01-09 11:33:18 - train.py[line:551] - INFO: load:1.59 valid_run:3164.76 task_valid:3034.21 collect_output:108.36
2023-01-09 11:35:48 - train.py[line:549] - INFO: 4400 / 4988
2023-01-09 11:35:48 - train.py[line:551] - INFO: load:1.61 valid_run:3314.38 task_valid:3178.56 collect_output:112.56
2023-01-09 11:38:19 - train.py[line:549] - INFO: 4600 / 4988
2023-01-09 11:38:19 - train.py[line:551] - INFO: load:1.64 valid_run:3465.62 task_valid:3324.48 collect_output:116.80
2023-01-09 11:40:50 - train.py[line:549] - INFO: 4800 / 4988
2023-01-09 11:40:50 - train.py[line:551] - INFO: load:1.67 valid_run:3616.96 task_valid:3470.74 collect_output:120.82

====================================================================================================
SGG eval:     R @ 50: 0.3323;     R @ 100: 0.3869;     R @ 500: 0.4088;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2181;    mR @ 100: 0.2622;    mR @ 500: 0.2909;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2561) (covered in:0.8125) (covering:0.3714) (eating:0.5882) (flying in:0.0000) (growing on:0.0000) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.5729) (playing:0.0000) (riding:0.2859) (says:0.0000) (sitting on:0.7013) (standing on:0.1250) (using:0.7000) (walking in:0.0000) (walking on:0.0811) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-09 11:43:21 - train.py[line:487] - INFO: 0.38689523809523807

====================================================================================================
SGG eval:     R @ 50: 0.3323;     R @ 100: 0.3869;     R @ 500: 0.4088;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2181;    mR @ 100: 0.2622;    mR @ 500: 0.2909;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2561) (covered in:0.8125) (covering:0.3714) (eating:0.5882) (flying in:0.0000) (growing on:0.0000) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.5729) (playing:0.0000) (riding:0.2859) (says:0.0000) (sitting on:0.7013) (standing on:0.1250) (using:0.7000) (walking in:0.0000) (walking on:0.0811) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-09 11:43:21 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-09 11:43:22 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.384 | loss_v1 0 | loss_v2 0 | nll_loss 0.236 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.386895 | ppl 1.18 | vqa_score 0.3041 | wps 119 | wpb 89.9 | bsz 30 | num_updates 32000 | best_R@100 0.645421
2023-01-09 11:43:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 32000 updates
2023-01-09 11:43:22 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_32000.pt
2023-01-09 11:44:03 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_32000.pt
2023-01-09 11:45:29 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.95_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_32000.pt (epoch 1 @ 32000 updates, score 0.38689523809523807) (writing took 127.50606125593185 seconds)
2023-01-09 11:45:51 - progress_bar.py[line:274] - INFO: epoch 001:  32055 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4892, wps=0.6, ups=0, wpb=109.2, bsz=40, num_updates=32010, lr=3.76915e-05, gnorm=0.163, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=132907
2023-01-09 11:46:13 - progress_bar.py[line:274] - INFO: epoch 001:  32065 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4842, wps=98.8, ups=0.46, wpb=108.1, bsz=40, num_updates=32020, lr=3.7687e-05, gnorm=0.273, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=132929
2023-01-09 11:46:35 - progress_bar.py[line:274] - INFO: epoch 001:  32075 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4565, wps=101.8, ups=0.46, wpb=110.1, bsz=40, num_updates=32030, lr=3.76825e-05, gnorm=0.141, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=132951
2023-01-09 11:46:57 - progress_bar.py[line:274] - INFO: epoch 001:  32085 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4772, wps=101.5, ups=0.47, wpb=108.6, bsz=40, num_updates=32040, lr=3.7678e-05, gnorm=0.243, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=132973
2023-01-09 11:47:18 - progress_bar.py[line:274] - INFO: epoch 001:  32095 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4231, wps=103.1, ups=0.47, wpb=110.3, bsz=40, num_updates=32050, lr=3.76735e-05, gnorm=0.193, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=132994
2023-01-09 11:47:41 - progress_bar.py[line:274] - INFO: epoch 001:  32105 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.435, wps=98.3, ups=0.46, wpb=107.9, bsz=40, num_updates=32060, lr=3.7669e-05, gnorm=0.183, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=133016
2023-01-09 11:48:03 - progress_bar.py[line:274] - INFO: epoch 001:  32115 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4314, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=32070, lr=3.76646e-05, gnorm=0.296, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=133038
2023-01-09 11:48:25 - progress_bar.py[line:274] - INFO: epoch 001:  32125 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5174, wps=98.9, ups=0.46, wpb=107.7, bsz=40, num_updates=32080, lr=3.76601e-05, gnorm=0.216, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=133060
2023-01-09 11:48:47 - progress_bar.py[line:274] - INFO: epoch 001:  32135 / 115845 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4652, wps=102.6, ups=0.46, wpb=111.2, bsz=40, num_updates=32090, lr=3.76556e-05, gnorm=0.139, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=133082
2023-01-09 11:49:09 - progress_bar.py[line:274] - INFO: epoch 001:  32145 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3793, wps=99.6, ups=0.46, wpb=108.4, bsz=40, num_updates=32100, lr=3.76511e-05, gnorm=0.186, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=133104
2023-01-09 11:49:31 - progress_bar.py[line:274] - INFO: epoch 001:  32155 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4804, wps=99.2, ups=0.45, wpb=109.3, bsz=40, num_updates=32110, lr=3.76466e-05, gnorm=0.405, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=133127
2023-01-09 11:49:53 - progress_bar.py[line:274] - INFO: epoch 001:  32165 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5362, wps=100.4, ups=0.47, wpb=107.9, bsz=40, num_updates=32120, lr=3.76421e-05, gnorm=0.364, clip=10, loss_scale=1024, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=133148
2023-01-09 11:50:14 - progress_bar.py[line:274] - INFO: epoch 001:  32175 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4319, wps=102.9, ups=0.48, wpb=108, bsz=40, num_updates=32130, lr=3.76376e-05, gnorm=0.14, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=133170
2023-01-09 11:50:36 - progress_bar.py[line:274] - INFO: epoch 001:  32185 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.476, wps=99.8, ups=0.47, wpb=107.2, bsz=40, num_updates=32140, lr=3.76331e-05, gnorm=0.162, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=133191
2023-01-09 11:50:58 - progress_bar.py[line:274] - INFO: epoch 001:  32195 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4503, wps=101.2, ups=0.47, wpb=108.4, bsz=40, num_updates=32150, lr=3.76286e-05, gnorm=0.102, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=133213
2023-01-09 11:51:19 - progress_bar.py[line:274] - INFO: epoch 001:  32205 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5074, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=32160, lr=3.76241e-05, gnorm=0.181, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=133235
2023-01-09 11:51:41 - progress_bar.py[line:274] - INFO: epoch 001:  32215 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4455, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=32170, lr=3.76196e-05, gnorm=0.155, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=133257
2023-01-09 11:52:03 - progress_bar.py[line:274] - INFO: epoch 001:  32225 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4752, wps=101.6, ups=0.47, wpb=109.2, bsz=40, num_updates=32180, lr=3.76151e-05, gnorm=0.164, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=133279
2023-01-09 11:52:25 - progress_bar.py[line:274] - INFO: epoch 001:  32235 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4722, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=32190, lr=3.76106e-05, gnorm=0.283, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=133300
2023-01-09 11:52:46 - progress_bar.py[line:274] - INFO: epoch 001:  32245 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4429, wps=102.5, ups=0.47, wpb=108.6, bsz=40, num_updates=32200, lr=3.76061e-05, gnorm=0.173, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=133322
2023-01-09 11:53:08 - progress_bar.py[line:274] - INFO: epoch 001:  32255 / 115845 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.5602, wps=101.9, ups=0.46, wpb=109.8, bsz=40, num_updates=32210, lr=3.76016e-05, gnorm=0.138, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=133344
2023-01-09 11:53:30 - progress_bar.py[line:274] - INFO: epoch 001:  32265 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4424, wps=98.2, ups=0.45, wpb=107.9, bsz=40, num_updates=32220, lr=3.75971e-05, gnorm=0.229, clip=0, loss_scale=2048, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=133366
2023-01-09 11:53:52 - progress_bar.py[line:274] - INFO: epoch 001:  32275 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4569, wps=103.4, ups=0.47, wpb=111, bsz=40, num_updates=32230, lr=3.75926e-05, gnorm=0.221, clip=0, loss_scale=2048, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=133388
2023-01-09 11:54:14 - progress_bar.py[line:274] - INFO: epoch 001:  32285 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3831, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=32240, lr=3.75881e-05, gnorm=0.152, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=133409
2023-01-09 11:54:35 - progress_bar.py[line:274] - INFO: epoch 001:  32295 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4531, wps=102.8, ups=0.47, wpb=108.9, bsz=40, num_updates=32250, lr=3.75836e-05, gnorm=0.161, clip=0, loss_scale=2048, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=133431
2023-01-09 11:54:57 - progress_bar.py[line:274] - INFO: epoch 001:  32305 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4485, wps=101, ups=0.46, wpb=109.5, bsz=40, num_updates=32260, lr=3.75791e-05, gnorm=0.2, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=133453
2023-01-09 11:55:19 - progress_bar.py[line:274] - INFO: epoch 001:  32315 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4481, wps=100.3, ups=0.46, wpb=108.4, bsz=40, num_updates=32270, lr=3.75746e-05, gnorm=0.131, clip=0, loss_scale=2048, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=133475
2023-01-09 11:55:41 - progress_bar.py[line:274] - INFO: epoch 001:  32325 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.41, wps=100.3, ups=0.47, wpb=107.8, bsz=40, num_updates=32280, lr=3.75701e-05, gnorm=0.233, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=133497
2023-01-09 11:56:03 - progress_bar.py[line:274] - INFO: epoch 001:  32335 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4202, wps=99.3, ups=0.46, wpb=108.6, bsz=40, num_updates=32290, lr=3.75656e-05, gnorm=0.317, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=133519
2023-01-09 11:56:24 - progress_bar.py[line:274] - INFO: epoch 001:  32345 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4382, wps=104.5, ups=0.47, wpb=110.5, bsz=40, num_updates=32300, lr=3.75611e-05, gnorm=0.242, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=133540
2023-01-09 11:56:46 - progress_bar.py[line:274] - INFO: epoch 001:  32355 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4692, wps=102.5, ups=0.47, wpb=109.4, bsz=40, num_updates=32310, lr=3.75566e-05, gnorm=0.133, clip=0, loss_scale=2048, train_wall=21, gb_free=10, ema_decay=0.9999, wall=133562
2023-01-09 11:57:08 - progress_bar.py[line:274] - INFO: epoch 001:  32365 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3977, wps=101.7, ups=0.46, wpb=110.2, bsz=40, num_updates=32320, lr=3.75522e-05, gnorm=0.138, clip=0, loss_scale=2048, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=133584
2023-01-09 11:57:29 - progress_bar.py[line:274] - INFO: epoch 001:  32375 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4369, wps=101.9, ups=0.47, wpb=107.9, bsz=40, num_updates=32330, lr=3.75477e-05, gnorm=0.199, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=133605
2023-01-09 11:57:52 - progress_bar.py[line:274] - INFO: epoch 001:  32385 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4858, wps=99.3, ups=0.46, wpb=108.8, bsz=40, num_updates=32340, lr=3.75432e-05, gnorm=0.185, clip=0, loss_scale=2048, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=133627
2023-01-09 11:58:14 - progress_bar.py[line:274] - INFO: epoch 001:  32395 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4879, wps=99.9, ups=0.46, wpb=108.4, bsz=40, num_updates=32350, lr=3.75387e-05, gnorm=0.213, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=133649
2023-01-09 11:58:35 - progress_bar.py[line:274] - INFO: epoch 001:  32405 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4885, wps=101.9, ups=0.47, wpb=108.7, bsz=40, num_updates=32360, lr=3.75342e-05, gnorm=0.151, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=133671
2023-01-09 11:58:57 - progress_bar.py[line:274] - INFO: epoch 001:  32415 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4385, wps=100.9, ups=0.46, wpb=109.7, bsz=40, num_updates=32370, lr=3.75297e-05, gnorm=0.153, clip=0, loss_scale=2048, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=133693
2023-01-09 11:59:19 - progress_bar.py[line:274] - INFO: epoch 001:  32425 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4632, wps=100.7, ups=0.46, wpb=109.4, bsz=40, num_updates=32380, lr=3.75252e-05, gnorm=0.25, clip=10, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=133715
2023-01-09 11:59:41 - progress_bar.py[line:274] - INFO: epoch 001:  32435 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4242, wps=101.9, ups=0.47, wpb=108.2, bsz=40, num_updates=32390, lr=3.75207e-05, gnorm=0.261, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=133736
2023-01-09 12:00:03 - progress_bar.py[line:274] - INFO: epoch 001:  32445 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4828, wps=99.6, ups=0.46, wpb=109.2, bsz=40, num_updates=32400, lr=3.75162e-05, gnorm=0.316, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=133759
2023-01-09 12:00:24 - progress_bar.py[line:274] - INFO: epoch 001:  32455 / 115845 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4792, wps=102.9, ups=0.47, wpb=110.6, bsz=40, num_updates=32410, lr=3.75117e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=133780
2023-01-09 12:00:48 - progress_bar.py[line:274] - INFO: epoch 001:  32465 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4732, wps=98.8, ups=0.46, wpb=107.7, bsz=40, num_updates=32420, lr=3.75072e-05, gnorm=0.257, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=133802
2023-01-09 12:01:10 - progress_bar.py[line:274] - INFO: epoch 001:  32475 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4091, wps=101.5, ups=0.47, wpb=108.7, bsz=40, num_updates=32430, lr=3.75027e-05, gnorm=0.214, clip=10, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=133825
2023-01-09 12:01:33 - progress_bar.py[line:274] - INFO: epoch 001:  32485 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4598, wps=102.3, ups=0.46, wpb=110.4, bsz=40, num_updates=32440, lr=3.74982e-05, gnorm=0.208, clip=0, loss_scale=2048, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=133848
2023-01-09 12:01:42 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-09 12:01:59 - progress_bar.py[line:274] - INFO: epoch 001:  32496 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.905, nsentences=40, sample_size=108.905, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5067, wps=97.8, ups=0.43, wpb=108.9, bsz=40, num_updates=32450, lr=3.74937e-05, gnorm=0.122, clip=0, loss_scale=1024, train_wall=23, gb_free=10.1, ema_decay=0.9999, wall=133873
2023-01-09 12:02:21 - progress_bar.py[line:274] - INFO: epoch 001:  32506 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4798, wps=103.5, ups=0.48, wpb=108.4, bsz=40, num_updates=32460, lr=3.74892e-05, gnorm=0.315, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=133896
2023-01-09 12:02:45 - progress_bar.py[line:274] - INFO: epoch 001:  32516 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4563, wps=99.1, ups=0.46, wpb=107.5, bsz=40, num_updates=32470, lr=3.74847e-05, gnorm=0.144, clip=0, loss_scale=1024, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=133919
2023-01-09 12:03:07 - progress_bar.py[line:274] - INFO: epoch 001:  32526 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4912, wps=100.1, ups=0.47, wpb=107.1, bsz=40, num_updates=32480, lr=3.74802e-05, gnorm=0.433, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=133942
2023-01-09 12:03:30 - progress_bar.py[line:274] - INFO: epoch 001:  32536 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.424, wps=101.8, ups=0.47, wpb=108.7, bsz=40, num_updates=32490, lr=3.74757e-05, gnorm=0.213, clip=0, loss_scale=1024, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=133965
2023-01-09 12:03:53 - progress_bar.py[line:274] - INFO: epoch 001:  32546 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4698, wps=100.8, ups=0.46, wpb=108.9, bsz=40, num_updates=32500, lr=3.74712e-05, gnorm=0.185, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=133988
2023-01-09 12:04:17 - progress_bar.py[line:274] - INFO: epoch 001:  32556 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4, wps=102.1, ups=0.46, wpb=109.9, bsz=40, num_updates=32510, lr=3.74667e-05, gnorm=0.166, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=134011
2023-01-09 12:04:39 - progress_bar.py[line:274] - INFO: epoch 001:  32566 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4698, wps=104.1, ups=0.48, wpb=109.1, bsz=40, num_updates=32520, lr=3.74622e-05, gnorm=0.31, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=134034
2023-01-09 12:05:02 - progress_bar.py[line:274] - INFO: epoch 001:  32576 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4742, wps=101.5, ups=0.47, wpb=108.6, bsz=40, num_updates=32530, lr=3.74577e-05, gnorm=0.135, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=134056
2023-01-09 12:05:25 - progress_bar.py[line:274] - INFO: epoch 001:  32586 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3807, wps=103, ups=0.46, wpb=111.5, bsz=40, num_updates=32540, lr=3.74532e-05, gnorm=0.159, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=134080
2023-01-09 12:05:48 - progress_bar.py[line:274] - INFO: epoch 001:  32596 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4372, wps=102.3, ups=0.47, wpb=109.3, bsz=40, num_updates=32550, lr=3.74487e-05, gnorm=0.235, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=134102
2023-01-09 12:06:11 - progress_bar.py[line:274] - INFO: epoch 001:  32606 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4208, wps=101.5, ups=0.46, wpb=109.7, bsz=40, num_updates=32560, lr=3.74443e-05, gnorm=0.139, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=134125
2023-01-09 12:06:33 - progress_bar.py[line:274] - INFO: epoch 001:  32616 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4691, wps=101.7, ups=0.47, wpb=108.3, bsz=40, num_updates=32570, lr=3.74398e-05, gnorm=0.182, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=134148
2023-01-09 12:06:56 - progress_bar.py[line:274] - INFO: epoch 001:  32626 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4388, wps=104.4, ups=0.48, wpb=109.8, bsz=40, num_updates=32580, lr=3.74353e-05, gnorm=0.218, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=134170
2023-01-09 12:07:19 - progress_bar.py[line:274] - INFO: epoch 001:  32636 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4162, wps=101, ups=0.47, wpb=108.6, bsz=40, num_updates=32590, lr=3.74308e-05, gnorm=0.313, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=134193
2023-01-09 12:07:42 - progress_bar.py[line:274] - INFO: epoch 001:  32646 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4706, wps=100.8, ups=0.47, wpb=107.9, bsz=40, num_updates=32600, lr=3.74263e-05, gnorm=0.255, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=134216
2023-01-09 12:08:06 - progress_bar.py[line:274] - INFO: epoch 001:  32656 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.47, wps=99, ups=0.45, wpb=109.4, bsz=40, num_updates=32610, lr=3.74218e-05, gnorm=0.2, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=134240
2023-01-09 12:08:29 - progress_bar.py[line:274] - INFO: epoch 001:  32666 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4188, wps=105.2, ups=0.48, wpb=109.4, bsz=40, num_updates=32620, lr=3.74173e-05, gnorm=0.204, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=134263
2023-01-09 12:08:52 - progress_bar.py[line:274] - INFO: epoch 001:  32676 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4462, wps=103.8, ups=0.48, wpb=109.2, bsz=40, num_updates=32630, lr=3.74128e-05, gnorm=0.19, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=134286
2023-01-09 12:09:16 - progress_bar.py[line:274] - INFO: epoch 001:  32686 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4355, wps=98.9, ups=0.46, wpb=108.6, bsz=40, num_updates=32640, lr=3.74083e-05, gnorm=0.323, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=134310
2023-01-09 12:09:40 - progress_bar.py[line:274] - INFO: epoch 001:  32696 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4369, wps=99.8, ups=0.46, wpb=109.1, bsz=40, num_updates=32650, lr=3.74038e-05, gnorm=0.195, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=134334
2023-01-09 12:10:03 - progress_bar.py[line:274] - INFO: epoch 001:  32706 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4739, wps=98.4, ups=0.46, wpb=108.1, bsz=40, num_updates=32660, lr=3.73993e-05, gnorm=0.235, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=134358
2023-01-09 12:10:27 - progress_bar.py[line:274] - INFO: epoch 001:  32716 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4921, wps=100.5, ups=0.46, wpb=108.7, bsz=40, num_updates=32670, lr=3.73948e-05, gnorm=0.167, clip=0, loss_scale=1024, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=134381
2023-01-09 12:10:50 - progress_bar.py[line:274] - INFO: epoch 001:  32726 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4656, wps=101.2, ups=0.46, wpb=110.1, bsz=40, num_updates=32680, lr=3.73903e-05, gnorm=0.186, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=134405
2023-01-09 12:11:14 - progress_bar.py[line:274] - INFO: epoch 001:  32736 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4272, wps=99.1, ups=0.45, wpb=108.9, bsz=40, num_updates=32690, lr=3.73858e-05, gnorm=0.132, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=134428
2023-01-09 12:11:38 - progress_bar.py[line:274] - INFO: epoch 001:  32746 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5163, wps=98.2, ups=0.46, wpb=107.9, bsz=40, num_updates=32700, lr=3.73813e-05, gnorm=0.184, clip=0, loss_scale=1024, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=134452
2023-01-09 12:12:01 - progress_bar.py[line:274] - INFO: epoch 001:  32756 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4513, wps=103.1, ups=0.47, wpb=110.2, bsz=40, num_updates=32710, lr=3.73768e-05, gnorm=0.202, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=134475
2023-01-09 12:12:24 - progress_bar.py[line:274] - INFO: epoch 001:  32766 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4721, wps=103, ups=0.47, wpb=110.2, bsz=40, num_updates=32720, lr=3.73723e-05, gnorm=0.205, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=134498
2023-01-09 12:12:48 - progress_bar.py[line:274] - INFO: epoch 001:  32776 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4976, wps=102.2, ups=0.47, wpb=109.4, bsz=40, num_updates=32730, lr=3.73678e-05, gnorm=0.112, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=134522
2023-01-09 12:13:11 - progress_bar.py[line:274] - INFO: epoch 001:  32786 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4554, wps=101.4, ups=0.46, wpb=109.7, bsz=40, num_updates=32740, lr=3.73633e-05, gnorm=0.203, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=134545
2023-01-09 12:13:35 - progress_bar.py[line:274] - INFO: epoch 001:  32796 / 115845 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4457, wps=98.9, ups=0.45, wpb=109.4, bsz=40, num_updates=32750, lr=3.73588e-05, gnorm=0.126, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=134569
2023-01-09 12:13:58 - progress_bar.py[line:274] - INFO: epoch 001:  32806 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4554, wps=101.6, ups=0.47, wpb=109, bsz=40, num_updates=32760, lr=3.73543e-05, gnorm=0.255, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=134592
2023-01-09 12:14:21 - progress_bar.py[line:274] - INFO: epoch 001:  32816 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4684, wps=103.7, ups=0.47, wpb=110.4, bsz=40, num_updates=32770, lr=3.73498e-05, gnorm=0.216, clip=0, loss_scale=1024, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=134615
2023-01-09 12:14:43 - progress_bar.py[line:274] - INFO: epoch 001:  32826 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4777, wps=102.1, ups=0.47, wpb=107.6, bsz=40, num_updates=32780, lr=3.73453e-05, gnorm=0.156, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=134638
2023-01-09 12:15:06 - progress_bar.py[line:274] - INFO: epoch 001:  32836 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4529, wps=102.1, ups=0.47, wpb=108.1, bsz=40, num_updates=32790, lr=3.73408e-05, gnorm=0.199, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=134661
2023-01-09 12:15:30 - progress_bar.py[line:274] - INFO: epoch 001:  32846 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5052, wps=102.1, ups=0.46, wpb=110.7, bsz=40, num_updates=32800, lr=3.73363e-05, gnorm=0.284, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=134684
2023-01-09 12:15:53 - progress_bar.py[line:274] - INFO: epoch 001:  32856 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3781, wps=102.9, ups=0.47, wpb=110.3, bsz=40, num_updates=32810, lr=3.73319e-05, gnorm=0.179, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=134707
2023-01-09 12:16:16 - progress_bar.py[line:274] - INFO: epoch 001:  32866 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=106.8, nsentences=40, sample_size=106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4072, wps=98.6, ups=0.46, wpb=106.8, bsz=40, num_updates=32820, lr=3.73274e-05, gnorm=0.218, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=134730
2023-01-09 12:16:39 - progress_bar.py[line:274] - INFO: epoch 001:  32876 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5158, wps=103, ups=0.47, wpb=110, bsz=40, num_updates=32830, lr=3.73229e-05, gnorm=0.158, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=134753
2023-01-09 12:17:02 - progress_bar.py[line:274] - INFO: epoch 001:  32886 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4769, wps=100.9, ups=0.46, wpb=109.7, bsz=40, num_updates=32840, lr=3.73184e-05, gnorm=0.183, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=134777
2023-01-09 12:17:25 - progress_bar.py[line:274] - INFO: epoch 001:  32896 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4233, wps=104.9, ups=0.48, wpb=110.2, bsz=40, num_updates=32850, lr=3.73139e-05, gnorm=0.172, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=134799
2023-01-09 12:17:48 - progress_bar.py[line:274] - INFO: epoch 001:  32906 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4905, wps=100.6, ups=0.47, wpb=106.9, bsz=40, num_updates=32860, lr=3.73094e-05, gnorm=0.19, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=134822
2023-01-09 12:18:11 - progress_bar.py[line:274] - INFO: epoch 001:  32916 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4171, wps=101.1, ups=0.46, wpb=109.1, bsz=40, num_updates=32870, lr=3.73049e-05, gnorm=0.212, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=134845
2023-01-09 12:18:34 - progress_bar.py[line:274] - INFO: epoch 001:  32926 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4899, wps=103.3, ups=0.47, wpb=110.4, bsz=40, num_updates=32880, lr=3.73004e-05, gnorm=0.229, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=134868
2023-01-09 12:18:58 - progress_bar.py[line:274] - INFO: epoch 001:  32936 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5122, wps=97.8, ups=0.45, wpb=108.1, bsz=40, num_updates=32890, lr=3.72959e-05, gnorm=0.207, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=134892
2023-01-09 12:19:21 - progress_bar.py[line:274] - INFO: epoch 001:  32946 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4619, wps=104.3, ups=0.48, wpb=109.3, bsz=40, num_updates=32900, lr=3.72914e-05, gnorm=0.277, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=134915
2023-01-09 12:19:44 - progress_bar.py[line:274] - INFO: epoch 001:  32956 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4398, wps=103.1, ups=0.47, wpb=110.4, bsz=40, num_updates=32910, lr=3.72869e-05, gnorm=0.225, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=134938
2023-01-09 12:20:08 - progress_bar.py[line:274] - INFO: epoch 001:  32966 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.46, wps=99, ups=0.45, wpb=109.1, bsz=40, num_updates=32920, lr=3.72824e-05, gnorm=0.188, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=134962
2023-01-09 12:20:31 - progress_bar.py[line:274] - INFO: epoch 001:  32976 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3582, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=32930, lr=3.72779e-05, gnorm=0.223, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=134985
2023-01-09 12:20:53 - progress_bar.py[line:274] - INFO: epoch 001:  32986 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4976, wps=101.7, ups=0.46, wpb=109.4, bsz=40, num_updates=32940, lr=3.72734e-05, gnorm=0.217, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=135009
2023-01-09 12:21:15 - progress_bar.py[line:274] - INFO: epoch 001:  32996 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4363, wps=99.8, ups=0.46, wpb=107.6, bsz=40, num_updates=32950, lr=3.72689e-05, gnorm=0.134, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=135030
2023-01-09 12:21:37 - progress_bar.py[line:274] - INFO: epoch 001:  33006 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4764, wps=101, ups=0.46, wpb=109.4, bsz=40, num_updates=32960, lr=3.72644e-05, gnorm=0.216, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=135052
2023-01-09 12:21:56 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-09 12:22:00 - progress_bar.py[line:274] - INFO: epoch 001:  33017 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.408, wps=99.5, ups=0.43, wpb=111, bsz=40, num_updates=32970, lr=3.72599e-05, gnorm=0.171, clip=0, loss_scale=1024, train_wall=23, gb_free=10, ema_decay=0.9999, wall=135076
2023-01-09 12:22:22 - progress_bar.py[line:274] - INFO: epoch 001:  33027 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4683, wps=101, ups=0.47, wpb=108.2, bsz=40, num_updates=32980, lr=3.72554e-05, gnorm=0.169, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=135098
2023-01-09 12:22:44 - progress_bar.py[line:274] - INFO: epoch 001:  33037 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4478, wps=101.4, ups=0.46, wpb=110.6, bsz=40, num_updates=32990, lr=3.72509e-05, gnorm=0.112, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=135120
2023-01-09 12:23:06 - progress_bar.py[line:274] - INFO: epoch 001:  33047 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4358, wps=100.2, ups=0.46, wpb=108.6, bsz=40, num_updates=33000, lr=3.72464e-05, gnorm=0.211, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=135142
2023-01-09 12:23:28 - progress_bar.py[line:274] - INFO: epoch 001:  33057 / 115845 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4694, wps=100.7, ups=0.46, wpb=108.4, bsz=40, num_updates=33010, lr=3.72419e-05, gnorm=0.129, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=135163
2023-01-09 12:23:50 - progress_bar.py[line:274] - INFO: epoch 001:  33067 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4316, wps=99.5, ups=0.46, wpb=107.9, bsz=40, num_updates=33020, lr=3.72374e-05, gnorm=0.185, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=135185
2023-01-09 12:24:12 - progress_bar.py[line:274] - INFO: epoch 001:  33077 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.468, wps=100.6, ups=0.46, wpb=109.1, bsz=40, num_updates=33030, lr=3.72329e-05, gnorm=0.171, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=135207
2023-01-09 12:24:33 - progress_bar.py[line:274] - INFO: epoch 001:  33087 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4718, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=33040, lr=3.72284e-05, gnorm=0.118, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=135229
2023-01-09 12:24:55 - progress_bar.py[line:274] - INFO: epoch 001:  33097 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4409, wps=99.3, ups=0.46, wpb=107, bsz=40, num_updates=33050, lr=3.7224e-05, gnorm=0.364, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=135251
2023-01-09 12:25:16 - progress_bar.py[line:274] - INFO: epoch 001:  33107 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4278, wps=103.5, ups=0.47, wpb=109.2, bsz=40, num_updates=33060, lr=3.72195e-05, gnorm=0.2, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=135272
2023-01-09 12:25:38 - progress_bar.py[line:274] - INFO: epoch 001:  33117 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5185, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=33070, lr=3.7215e-05, gnorm=0.247, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=135294
2023-01-09 12:26:00 - progress_bar.py[line:274] - INFO: epoch 001:  33127 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.43, wps=100.3, ups=0.46, wpb=108.3, bsz=40, num_updates=33080, lr=3.72105e-05, gnorm=0.256, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=135316
2023-01-09 12:26:22 - progress_bar.py[line:274] - INFO: epoch 001:  33137 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4929, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=33090, lr=3.7206e-05, gnorm=0.268, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=135338
2023-01-09 12:26:44 - progress_bar.py[line:274] - INFO: epoch 001:  33147 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5, wps=100.7, ups=0.46, wpb=109.6, bsz=40, num_updates=33100, lr=3.72015e-05, gnorm=0.149, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=135360
2023-01-09 12:27:06 - progress_bar.py[line:274] - INFO: epoch 001:  33157 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4631, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=33110, lr=3.7197e-05, gnorm=0.213, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=135381
2023-01-09 12:27:27 - progress_bar.py[line:274] - INFO: epoch 001:  33167 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5, wps=100.7, ups=0.47, wpb=107.8, bsz=40, num_updates=33120, lr=3.71925e-05, gnorm=0.178, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=135403
2023-01-09 12:27:49 - progress_bar.py[line:274] - INFO: epoch 001:  33177 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4806, wps=100.9, ups=0.46, wpb=108.6, bsz=40, num_updates=33130, lr=3.7188e-05, gnorm=0.122, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=135425
2023-01-09 12:28:10 - progress_bar.py[line:274] - INFO: epoch 001:  33187 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4369, wps=103, ups=0.47, wpb=109, bsz=40, num_updates=33140, lr=3.71835e-05, gnorm=0.148, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=135446
2023-01-09 12:28:32 - progress_bar.py[line:274] - INFO: epoch 001:  33197 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4615, wps=103.3, ups=0.47, wpb=109.5, bsz=40, num_updates=33150, lr=3.7179e-05, gnorm=0.292, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=135468
2023-01-09 12:28:54 - progress_bar.py[line:274] - INFO: epoch 001:  33207 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4352, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=33160, lr=3.71745e-05, gnorm=0.339, clip=10, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=135490
2023-01-09 12:29:16 - progress_bar.py[line:274] - INFO: epoch 001:  33217 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4764, wps=101.3, ups=0.46, wpb=110.4, bsz=40, num_updates=33170, lr=3.717e-05, gnorm=0.221, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=135512
2023-01-09 12:29:38 - progress_bar.py[line:274] - INFO: epoch 001:  33227 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4646, wps=99.3, ups=0.46, wpb=108.8, bsz=40, num_updates=33180, lr=3.71655e-05, gnorm=0.162, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=135534
2023-01-09 12:30:00 - progress_bar.py[line:274] - INFO: epoch 001:  33237 / 115845 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.5084, wps=103.4, ups=0.47, wpb=110.6, bsz=40, num_updates=33190, lr=3.7161e-05, gnorm=0.206, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=135556
2023-01-09 12:30:22 - progress_bar.py[line:274] - INFO: epoch 001:  33247 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4623, wps=100.4, ups=0.46, wpb=108.6, bsz=40, num_updates=33200, lr=3.71565e-05, gnorm=0.198, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=135578
2023-01-09 12:30:44 - progress_bar.py[line:274] - INFO: epoch 001:  33257 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4497, wps=102, ups=0.46, wpb=109.8, bsz=40, num_updates=33210, lr=3.7152e-05, gnorm=0.243, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=135600
2023-01-09 12:31:06 - progress_bar.py[line:274] - INFO: epoch 001:  33267 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4569, wps=102.1, ups=0.46, wpb=109.8, bsz=40, num_updates=33220, lr=3.71475e-05, gnorm=0.157, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=135622
2023-01-09 12:31:28 - progress_bar.py[line:274] - INFO: epoch 001:  33277 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4433, wps=100.6, ups=0.46, wpb=110, bsz=40, num_updates=33230, lr=3.7143e-05, gnorm=0.237, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=135644
2023-01-09 12:31:50 - progress_bar.py[line:274] - INFO: epoch 001:  33287 / 115845 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.49, wps=103.1, ups=0.47, wpb=110.5, bsz=40, num_updates=33240, lr=3.71385e-05, gnorm=0.163, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=135666
2023-01-09 12:32:12 - progress_bar.py[line:274] - INFO: epoch 001:  33297 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4883, wps=99.3, ups=0.46, wpb=108.1, bsz=40, num_updates=33250, lr=3.7134e-05, gnorm=0.17, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=135688
2023-01-09 12:32:33 - progress_bar.py[line:274] - INFO: epoch 001:  33307 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4559, wps=104.6, ups=0.48, wpb=109.6, bsz=40, num_updates=33260, lr=3.71295e-05, gnorm=0.133, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=135709
2023-01-09 12:32:55 - progress_bar.py[line:274] - INFO: epoch 001:  33317 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4112, wps=100.7, ups=0.47, wpb=108, bsz=40, num_updates=33270, lr=3.7125e-05, gnorm=0.136, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=135731
2023-01-09 12:33:17 - progress_bar.py[line:274] - INFO: epoch 001:  33327 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4521, wps=102, ups=0.46, wpb=110.3, bsz=40, num_updates=33280, lr=3.71205e-05, gnorm=0.24, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=135752
2023-01-09 12:33:38 - progress_bar.py[line:274] - INFO: epoch 001:  33337 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4375, wps=100.5, ups=0.47, wpb=107.3, bsz=40, num_updates=33290, lr=3.7116e-05, gnorm=0.193, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=135774
2023-01-09 12:34:00 - progress_bar.py[line:274] - INFO: epoch 001:  33347 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4667, wps=100.9, ups=0.46, wpb=110.1, bsz=40, num_updates=33300, lr=3.71116e-05, gnorm=0.17, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=135796
2023-01-09 12:34:22 - progress_bar.py[line:274] - INFO: epoch 001:  33357 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.495, wps=101.4, ups=0.46, wpb=109.7, bsz=40, num_updates=33310, lr=3.71071e-05, gnorm=0.107, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=135818
2023-01-09 12:34:44 - progress_bar.py[line:274] - INFO: epoch 001:  33367 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4952, wps=100.6, ups=0.46, wpb=108.5, bsz=40, num_updates=33320, lr=3.71026e-05, gnorm=0.137, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=135840
2023-01-09 12:35:06 - progress_bar.py[line:274] - INFO: epoch 001:  33377 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4093, wps=101.4, ups=0.47, wpb=108.6, bsz=40, num_updates=33330, lr=3.70981e-05, gnorm=0.258, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=135862
2023-01-09 12:35:28 - progress_bar.py[line:274] - INFO: epoch 001:  33387 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.505, wps=99.1, ups=0.46, wpb=108.9, bsz=40, num_updates=33340, lr=3.70936e-05, gnorm=0.141, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=135884
2023-01-09 12:35:49 - progress_bar.py[line:274] - INFO: epoch 001:  33397 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.44, wps=102.8, ups=0.47, wpb=108.7, bsz=40, num_updates=33350, lr=3.70891e-05, gnorm=0.241, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=135905
2023-01-09 12:36:11 - progress_bar.py[line:274] - INFO: epoch 001:  33407 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4653, wps=101.5, ups=0.46, wpb=109.7, bsz=40, num_updates=33360, lr=3.70846e-05, gnorm=0.204, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=135927
2023-01-09 12:36:33 - progress_bar.py[line:274] - INFO: epoch 001:  33417 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4293, wps=101.9, ups=0.47, wpb=108.2, bsz=40, num_updates=33370, lr=3.70801e-05, gnorm=0.153, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=135949
2023-01-09 12:36:55 - progress_bar.py[line:274] - INFO: epoch 001:  33427 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4727, wps=99.2, ups=0.46, wpb=107, bsz=40, num_updates=33380, lr=3.70756e-05, gnorm=0.177, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=135970
2023-01-09 12:37:16 - progress_bar.py[line:274] - INFO: epoch 001:  33437 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4603, wps=102.5, ups=0.47, wpb=109.9, bsz=40, num_updates=33390, lr=3.70711e-05, gnorm=0.187, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=135992
2023-01-09 12:37:38 - progress_bar.py[line:274] - INFO: epoch 001:  33447 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.424, wps=101.4, ups=0.47, wpb=107.7, bsz=40, num_updates=33400, lr=3.70666e-05, gnorm=0.277, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=136014
2023-01-09 12:38:00 - progress_bar.py[line:274] - INFO: epoch 001:  33457 / 115845 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4828, wps=102.2, ups=0.46, wpb=111, bsz=40, num_updates=33410, lr=3.70621e-05, gnorm=0.253, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=136036
2023-01-09 12:38:22 - progress_bar.py[line:274] - INFO: epoch 001:  33467 / 115845 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.419, wps=100.8, ups=0.46, wpb=110.2, bsz=40, num_updates=33420, lr=3.70576e-05, gnorm=0.22, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=136058
2023-01-09 12:38:44 - progress_bar.py[line:274] - INFO: epoch 001:  33477 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4306, wps=102.5, ups=0.47, wpb=109.4, bsz=40, num_updates=33430, lr=3.70531e-05, gnorm=0.229, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=136079
2023-01-09 12:39:05 - progress_bar.py[line:274] - INFO: epoch 001:  33487 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4925, wps=101.7, ups=0.47, wpb=109.3, bsz=40, num_updates=33440, lr=3.70486e-05, gnorm=0.29, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=136101
2023-01-09 12:39:27 - progress_bar.py[line:274] - INFO: epoch 001:  33497 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.435, wps=99.5, ups=0.46, wpb=108.4, bsz=40, num_updates=33450, lr=3.70441e-05, gnorm=0.225, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=136123
2023-01-09 12:39:49 - progress_bar.py[line:274] - INFO: epoch 001:  33507 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3814, wps=100.8, ups=0.47, wpb=107.7, bsz=40, num_updates=33460, lr=3.70396e-05, gnorm=0.251, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=136145
2023-01-09 12:40:11 - progress_bar.py[line:274] - INFO: epoch 001:  33517 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4573, wps=102.5, ups=0.47, wpb=109.8, bsz=40, num_updates=33470, lr=3.70351e-05, gnorm=0.209, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=136167
2023-01-09 12:40:33 - progress_bar.py[line:274] - INFO: epoch 001:  33527 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4879, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=33480, lr=3.70306e-05, gnorm=0.191, clip=0, loss_scale=2048, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=136189
2023-01-09 12:40:55 - progress_bar.py[line:274] - INFO: epoch 001:  33537 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.467, wps=101.2, ups=0.46, wpb=110, bsz=40, num_updates=33490, lr=3.70261e-05, gnorm=0.164, clip=0, loss_scale=2048, train_wall=22, gb_free=10, ema_decay=0.9999, wall=136211
2023-01-09 12:41:16 - progress_bar.py[line:274] - INFO: epoch 001:  33547 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.55, wps=101.1, ups=0.47, wpb=108, bsz=40, num_updates=33500, lr=3.70216e-05, gnorm=0.268, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=136232
2023-01-09 12:41:39 - progress_bar.py[line:274] - INFO: epoch 001:  33557 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4398, wps=97.9, ups=0.46, wpb=107.3, bsz=40, num_updates=33510, lr=3.70171e-05, gnorm=0.164, clip=0, loss_scale=2048, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=136254
2023-01-09 12:42:00 - progress_bar.py[line:274] - INFO: epoch 001:  33567 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4312, wps=100, ups=0.47, wpb=106.9, bsz=40, num_updates=33520, lr=3.70126e-05, gnorm=0.269, clip=0, loss_scale=2048, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=136276
2023-01-09 12:42:22 - progress_bar.py[line:274] - INFO: epoch 001:  33577 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5118, wps=99.8, ups=0.47, wpb=107.3, bsz=40, num_updates=33530, lr=3.70081e-05, gnorm=0.173, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=136298
2023-01-09 12:42:43 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-09 12:42:46 - progress_bar.py[line:274] - INFO: epoch 001:  33588 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.857, nsentences=40, sample_size=108.857, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4787, wps=96.9, ups=0.42, wpb=108.9, bsz=40, num_updates=33540, lr=3.70037e-05, gnorm=0.13, clip=0, loss_scale=1024, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=136322
2023-01-09 12:43:08 - progress_bar.py[line:274] - INFO: epoch 001:  33598 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4129, wps=100.5, ups=0.46, wpb=108.9, bsz=40, num_updates=33550, lr=3.69992e-05, gnorm=0.238, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=136344
2023-01-09 12:43:30 - progress_bar.py[line:274] - INFO: epoch 001:  33608 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4928, wps=101.8, ups=0.46, wpb=109.6, bsz=40, num_updates=33560, lr=3.69947e-05, gnorm=0.327, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=136365
2023-01-09 12:43:51 - progress_bar.py[line:274] - INFO: epoch 001:  33618 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4011, wps=103.6, ups=0.46, wpb=111.6, bsz=40, num_updates=33570, lr=3.69902e-05, gnorm=0.142, clip=0, loss_scale=1024, train_wall=21, gb_free=9.3, ema_decay=0.9999, wall=136387
2023-01-09 12:44:13 - progress_bar.py[line:274] - INFO: epoch 001:  33628 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4532, wps=102.3, ups=0.47, wpb=109.2, bsz=40, num_updates=33580, lr=3.69857e-05, gnorm=0.159, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=136409
2023-01-09 12:44:35 - progress_bar.py[line:274] - INFO: epoch 001:  33638 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4673, wps=100.4, ups=0.46, wpb=108.8, bsz=40, num_updates=33590, lr=3.69812e-05, gnorm=0.203, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=136431
2023-01-09 12:44:57 - progress_bar.py[line:274] - INFO: epoch 001:  33648 / 115845 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.4451, wps=101.8, ups=0.46, wpb=110.2, bsz=40, num_updates=33600, lr=3.69767e-05, gnorm=0.115, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=136453
2023-01-09 12:45:19 - progress_bar.py[line:274] - INFO: epoch 001:  33658 / 115845 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5678, wps=99.4, ups=0.45, wpb=109.3, bsz=40, num_updates=33610, lr=3.69722e-05, gnorm=0.205, clip=0, loss_scale=1024, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=136475
2023-01-09 12:45:41 - progress_bar.py[line:274] - INFO: epoch 001:  33668 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4062, wps=102.9, ups=0.47, wpb=109.9, bsz=40, num_updates=33620, lr=3.69677e-05, gnorm=0.159, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=136497
2023-01-09 12:46:03 - progress_bar.py[line:274] - INFO: epoch 001:  33678 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4301, wps=99.3, ups=0.46, wpb=108.4, bsz=40, num_updates=33630, lr=3.69632e-05, gnorm=0.147, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=136519
2023-01-09 12:46:25 - progress_bar.py[line:274] - INFO: epoch 001:  33688 / 115845 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.5054, wps=101.4, ups=0.46, wpb=109.8, bsz=40, num_updates=33640, lr=3.69587e-05, gnorm=0.149, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=136541
2023-01-09 12:46:47 - progress_bar.py[line:274] - INFO: epoch 001:  33698 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4061, wps=101.3, ups=0.47, wpb=108.7, bsz=40, num_updates=33650, lr=3.69542e-05, gnorm=0.184, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=136563
2023-01-09 12:47:08 - progress_bar.py[line:274] - INFO: epoch 001:  33708 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4742, wps=101.3, ups=0.47, wpb=108.5, bsz=40, num_updates=33660, lr=3.69497e-05, gnorm=0.197, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=136584
2023-01-09 12:47:30 - progress_bar.py[line:274] - INFO: epoch 001:  33718 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4611, wps=104.5, ups=0.48, wpb=109.6, bsz=40, num_updates=33670, lr=3.69452e-05, gnorm=0.289, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=136605
2023-01-09 12:47:52 - progress_bar.py[line:274] - INFO: epoch 001:  33728 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5308, wps=101, ups=0.46, wpb=108.8, bsz=40, num_updates=33680, lr=3.69407e-05, gnorm=0.208, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=136627
2023-01-09 12:48:14 - progress_bar.py[line:274] - INFO: epoch 001:  33738 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4427, wps=100.8, ups=0.46, wpb=110.1, bsz=40, num_updates=33690, lr=3.69362e-05, gnorm=0.214, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=136649
2023-01-09 12:48:36 - progress_bar.py[line:274] - INFO: epoch 001:  33748 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4278, wps=101.1, ups=0.46, wpb=110.2, bsz=40, num_updates=33700, lr=3.69317e-05, gnorm=0.31, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=136671
2023-01-09 12:48:57 - progress_bar.py[line:274] - INFO: epoch 001:  33758 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4363, wps=102.4, ups=0.47, wpb=108.5, bsz=40, num_updates=33710, lr=3.69272e-05, gnorm=0.235, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=136693
2023-01-09 12:49:19 - progress_bar.py[line:274] - INFO: epoch 001:  33768 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4381, wps=101.3, ups=0.47, wpb=107.5, bsz=40, num_updates=33720, lr=3.69227e-05, gnorm=0.241, clip=10, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=136714
2023-01-09 12:49:40 - progress_bar.py[line:274] - INFO: epoch 001:  33778 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3548, wps=100.1, ups=0.47, wpb=107.2, bsz=40, num_updates=33730, lr=3.69182e-05, gnorm=0.144, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=136736
2023-01-09 12:50:03 - progress_bar.py[line:274] - INFO: epoch 001:  33788 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4384, wps=98.1, ups=0.45, wpb=108.3, bsz=40, num_updates=33740, lr=3.69137e-05, gnorm=0.302, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=136758
2023-01-09 12:50:24 - progress_bar.py[line:274] - INFO: epoch 001:  33798 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.432, wps=101.5, ups=0.47, wpb=108.4, bsz=40, num_updates=33750, lr=3.69092e-05, gnorm=0.229, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=136780
2023-01-09 12:50:46 - progress_bar.py[line:274] - INFO: epoch 001:  33808 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4545, wps=102.2, ups=0.46, wpb=109.9, bsz=40, num_updates=33760, lr=3.69047e-05, gnorm=0.19, clip=0, loss_scale=1024, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=136802
2023-01-09 12:51:08 - progress_bar.py[line:274] - INFO: epoch 001:  33818 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4396, wps=100.7, ups=0.46, wpb=108.5, bsz=40, num_updates=33770, lr=3.69002e-05, gnorm=0.143, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=136824
2023-01-09 12:51:30 - progress_bar.py[line:274] - INFO: epoch 001:  33828 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4627, wps=102, ups=0.47, wpb=109.3, bsz=40, num_updates=33780, lr=3.68957e-05, gnorm=0.146, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=136845
2023-01-09 12:51:52 - progress_bar.py[line:274] - INFO: epoch 001:  33838 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.392, wps=100.3, ups=0.46, wpb=108.4, bsz=40, num_updates=33790, lr=3.68913e-05, gnorm=0.158, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=136867
2023-01-09 12:52:13 - progress_bar.py[line:274] - INFO: epoch 001:  33848 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4573, wps=104.4, ups=0.48, wpb=109.8, bsz=40, num_updates=33800, lr=3.68868e-05, gnorm=0.159, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=136889
2023-01-09 12:52:35 - progress_bar.py[line:274] - INFO: epoch 001:  33858 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4158, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=33810, lr=3.68823e-05, gnorm=0.133, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=136910
2023-01-09 12:52:57 - progress_bar.py[line:274] - INFO: epoch 001:  33868 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4335, wps=100.2, ups=0.46, wpb=109, bsz=40, num_updates=33820, lr=3.68778e-05, gnorm=0.176, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=136932
2023-01-09 12:53:18 - progress_bar.py[line:274] - INFO: epoch 001:  33878 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4712, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=33830, lr=3.68733e-05, gnorm=0.173, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=136954
2023-01-09 12:53:40 - progress_bar.py[line:274] - INFO: epoch 001:  33888 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3961, wps=100.6, ups=0.46, wpb=108.9, bsz=40, num_updates=33840, lr=3.68688e-05, gnorm=0.141, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=136976
2023-01-09 12:54:03 - progress_bar.py[line:274] - INFO: epoch 001:  33898 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4103, wps=99.6, ups=0.46, wpb=108.8, bsz=40, num_updates=33850, lr=3.68643e-05, gnorm=0.215, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=136998
2023-01-09 12:54:24 - progress_bar.py[line:274] - INFO: epoch 001:  33908 / 115845 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.5622, wps=101.6, ups=0.46, wpb=109.4, bsz=40, num_updates=33860, lr=3.68598e-05, gnorm=0.185, clip=0, loss_scale=1024, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=137020
2023-01-09 12:54:47 - progress_bar.py[line:274] - INFO: epoch 001:  33918 / 115845 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4457, wps=99.8, ups=0.46, wpb=109.4, bsz=40, num_updates=33870, lr=3.68553e-05, gnorm=0.138, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=137042
2023-01-09 12:55:08 - progress_bar.py[line:274] - INFO: epoch 001:  33928 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4607, wps=102.2, ups=0.47, wpb=109.9, bsz=40, num_updates=33880, lr=3.68508e-05, gnorm=0.152, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=137064
2023-01-09 12:55:30 - progress_bar.py[line:274] - INFO: epoch 001:  33938 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4715, wps=102.5, ups=0.47, wpb=109.9, bsz=40, num_updates=33890, lr=3.68463e-05, gnorm=0.115, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=137086
2023-01-09 12:55:52 - progress_bar.py[line:274] - INFO: epoch 001:  33948 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4717, wps=101, ups=0.47, wpb=107.7, bsz=40, num_updates=33900, lr=3.68418e-05, gnorm=0.146, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=137108
2023-01-09 12:56:14 - progress_bar.py[line:274] - INFO: epoch 001:  33958 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4053, wps=100.2, ups=0.46, wpb=110, bsz=40, num_updates=33910, lr=3.68373e-05, gnorm=0.136, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=137130
2023-01-09 12:56:36 - progress_bar.py[line:274] - INFO: epoch 001:  33968 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4095, wps=101.3, ups=0.47, wpb=108.1, bsz=40, num_updates=33920, lr=3.68328e-05, gnorm=0.177, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=137151
2023-01-09 12:56:57 - progress_bar.py[line:274] - INFO: epoch 001:  33978 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4952, wps=101.7, ups=0.47, wpb=108.5, bsz=40, num_updates=33930, lr=3.68283e-05, gnorm=0.123, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=137173
2023-01-09 12:57:19 - progress_bar.py[line:274] - INFO: epoch 001:  33988 / 115845 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.44, wps=103.8, ups=0.47, wpb=110.6, bsz=40, num_updates=33940, lr=3.68238e-05, gnorm=0.23, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=137195
2023-01-09 12:57:41 - progress_bar.py[line:274] - INFO: epoch 001:  33998 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3991, wps=101.8, ups=0.46, wpb=109.8, bsz=40, num_updates=33950, lr=3.68193e-05, gnorm=0.182, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=137216
2023-01-09 12:58:02 - progress_bar.py[line:274] - INFO: epoch 001:  34008 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4478, wps=101.4, ups=0.47, wpb=108.3, bsz=40, num_updates=33960, lr=3.68148e-05, gnorm=0.17, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=137238
2023-01-09 12:58:24 - progress_bar.py[line:274] - INFO: epoch 001:  34018 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4611, wps=100.9, ups=0.46, wpb=109.7, bsz=40, num_updates=33970, lr=3.68103e-05, gnorm=0.196, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=137260
2023-01-09 12:58:47 - progress_bar.py[line:274] - INFO: epoch 001:  34028 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4493, wps=99.1, ups=0.46, wpb=108.6, bsz=40, num_updates=33980, lr=3.68058e-05, gnorm=0.125, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=137282
2023-01-09 12:59:09 - progress_bar.py[line:274] - INFO: epoch 001:  34038 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4907, wps=100.1, ups=0.46, wpb=108.9, bsz=40, num_updates=33990, lr=3.68013e-05, gnorm=0.147, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=137304
2023-01-09 12:59:31 - progress_bar.py[line:274] - INFO: epoch 001:  34048 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5, wps=98.9, ups=0.46, wpb=107.5, bsz=40, num_updates=34000, lr=3.67968e-05, gnorm=0.134, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=137326
2023-01-09 12:59:31 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-09 12:59:32 - train.py[line:549] - INFO: 0 / 4988
2023-01-09 12:59:32 - train.py[line:551] - INFO: load:1.06 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-09 13:02:04 - train.py[line:549] - INFO: 200 / 4988
2023-01-09 13:02:04 - train.py[line:551] - INFO: load:1.09 valid_run:151.88 task_valid:148.35 collect_output:2.36
2023-01-09 13:04:33 - train.py[line:549] - INFO: 400 / 4988
2023-01-09 13:04:33 - train.py[line:551] - INFO: load:1.12 valid_run:300.38 task_valid:291.43 collect_output:6.71
2023-01-09 13:07:05 - train.py[line:549] - INFO: 600 / 4988
2023-01-09 13:07:05 - train.py[line:551] - INFO: load:1.15 valid_run:453.00 task_valid:434.85 collect_output:14.81
2023-01-09 13:09:35 - train.py[line:549] - INFO: 800 / 4988
2023-01-09 13:09:35 - train.py[line:551] - INFO: load:1.18 valid_run:602.34 task_valid:579.76 collect_output:18.15
2023-01-09 13:12:07 - train.py[line:549] - INFO: 1000 / 4988
2023-01-09 13:12:07 - train.py[line:551] - INFO: load:1.21 valid_run:754.56 task_valid:727.09 collect_output:21.99
2023-01-09 13:14:39 - train.py[line:549] - INFO: 1200 / 4988
2023-01-09 13:14:39 - train.py[line:551] - INFO: load:1.24 valid_run:906.41 task_valid:872.58 collect_output:27.29
2023-01-09 13:17:13 - train.py[line:549] - INFO: 1400 / 4988
2023-01-09 13:17:13 - train.py[line:551] - INFO: load:1.27 valid_run:1060.21 task_valid:1018.75 collect_output:33.86
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 3304332
Killing subprocess 3304333
Main process received SIGINT, exiting
train_vqa_base_distributed-A100-node4.sh: line 183: inference_type}: command not found
